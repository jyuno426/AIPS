{"R. H. Y. So": [0.5, ["Effects of Base-Frequency and Spectral Envelope on Deep-Learning Speech Separation and Recognition Models", ["J. Hui", "Y. Wei", "S. T. Chen", "R. H. Y. So"], "https://doi.org/10.21437/Interspeech.2019-1715", 5, "interspeech", 2019]], "Kyogu Lee": [0.942917138338089, ["Adversarially Trained End-to-End Korean Singing Voice Synthesis System", ["Juheon Lee", "Hyeong-Seok Choi", "Chang-Bin Jeon", "Junghyun Koo", "Kyogu Lee"], "https://doi.org/10.21437/Interspeech.2019-1722", 5, "interspeech", 2019]], "Ha-Jin Yu": [0.7287916094064713, ["Acoustic Scene Classification Using Teacher-Student Learning with Soft-Labels", ["Hee-Soo Heo", "Jee-weon Jung", "Hye-jin Shim", "Ha-Jin Yu"], "https://doi.org/10.21437/Interspeech.2019-1989", 5, "interspeech", 2019], ["Replay Attack Detection with Complementary High-Resolution Information Using End-to-End DNN for the ASVspoof 2019 Challenge", ["Jee-weon Jung", "Hye-jin Shim", "Hee-Soo Heo", "Ha-Jin Yu"], "https://doi.org/10.21437/Interspeech.2019-1991", 5, "interspeech", 2019], ["RawNet: Advanced End-to-End Deep Neural Network Using Raw Waveforms for Text-Independent Speaker Verification", ["Jee-weon Jung", "Hee-Soo Heo", "Ju-ho Kim", "Hye-jin Shim", "Ha-Jin Yu"], "https://doi.org/10.21437/Interspeech.2019-1982", 5, "interspeech", 2019], ["End-to-End Losses Based on Speaker Basis Vectors and All-Speaker Hard Negative Mining for Speaker Verification", ["Hee-Soo Heo", "Jee-weon Jung", "Il-Ho Yang", "Sung-Hyun Yoon", "Hye-jin Shim", "Ha-Jin Yu"], "https://doi.org/10.21437/Interspeech.2019-1986", 5, "interspeech", 2019]], "Minhwa Chung": [0.9872890114784241, ["Self-Imitating Feedback Generation Using GAN for Computer-Assisted Pronunciation Training", ["Seung Hee Yang", "Minhwa Chung"], "https://doi.org/10.21437/Interspeech.2019-1478", 5, "interspeech", 2019]], "Taesu Kim": [0.9277801364660263, ["Large-Scale Speaker Retrieval on Random Speaker Variability Subspace", ["Suwon Shon", "Younggun Lee", "Taesu Kim"], "https://doi.org/10.21437/Interspeech.2019-1498", 5, "interspeech", 2019]], "Ji-Hwan Kim": [0.9722291678190231, ["Shortcut Connections Based Deep Speaker Embeddings for End-to-End Speaker Verification System", ["Soonshin Seo", "Daniel Jun Rim", "Minkyu Lim", "Donghyun Lee", "Hosung Park", "Junseok Oh", "Changmin Kim", "Ji-Hwan Kim"], "https://doi.org/10.21437/Interspeech.2019-2195", 5, "interspeech", 2019]], "Insoo Oh": [0.9920652210712433, ["Robust Keyword Spotting via Recycle-Pooling for Mobile Game", ["Shounan An", "Youngsoo Kim", "Hu Xu", "Jinwoo Lee", "Myungwoo Lee", "Insoo Oh"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8010.html", 2, "interspeech", 2019]], "Sungjoo Ha": [0.9988091886043549, ["Temporal Convolution for Real-Time Keyword Spotting on Mobile Devices", ["Seungwoo Choi", "Seokjun Seo", "Beomjun Shin", "Hyeongmin Byun", "Martin Kersner", "Beomsu Kim", "Dongyoung Kim", "Sungjoo Ha"], "https://doi.org/10.21437/Interspeech.2019-1363", 5, "interspeech", 2019]], "Joon-Hyuk Chang": [0.999975860118866, ["Joint Optimization of Neural Acoustic Beamforming and Dereverberation with x-Vectors for Robust Speaker Verification", ["Joon-Young Yang", "Joon-Hyuk Chang"], "https://doi.org/10.21437/Interspeech.2019-1356", 5, "interspeech", 2019]], "Oh-Wook Kwon": [0.9998743832111359, ["Extending an Acoustic Data-Driven Phone Set for Spontaneous Speech Recognition", ["Jeong-Uk Bang", "Mu-Yeol Choi", "Sang-Hun Kim", "Oh-Wook Kwon"], "https://doi.org/10.21437/Interspeech.2019-1979", 5, "interspeech", 2019]], "Jungwon Lee": [0.9839506894350052, ["Deep Multitask Acoustic Echo Cancellation", ["Amin Fazel", "Mostafa El-Khamy", "Jungwon Lee"], "https://doi.org/10.21437/Interspeech.2019-2908", 5, "interspeech", 2019]], "Kyuwoong Hwang": [0.9981933534145355, ["An End-to-End Text-Independent Speaker Verification Framework with a Keyword Adversarial Network", ["Sungrack Yun", "Janghoon Cho", "Jungyun Eum", "Wonil Chang", "Kyuwoong Hwang"], "https://doi.org/10.21437/Interspeech.2019-2208", 5, "interspeech", 2019]], "Seungji Lee": [0.9998576194047928, ["Large-Scale Multilingual Speech Recognition with a Streaming End-to-End Model", ["Anjuli Kannan", "Arindrima Datta", "Tara N. Sainath", "Eugene Weinstein", "Bhuvana Ramabhadran", "Yonghui Wu", "Ankur Bapna", "Zhifeng Chen", "Seungji Lee"], "https://doi.org/10.21437/Interspeech.2019-2858", 5, "interspeech", 2019]], "Taehwan Kim": [0.925512820482254, ["One-Shot Voice Conversion with Disentangled Representations by Leveraging Phonetic Posteriorgrams", ["Seyed Hamidreza Mohammadi", "Taehwan Kim"], "https://doi.org/10.21437/Interspeech.2019-1798", 5, "interspeech", 2019]], "Jeesun Kim": [0.9742622375488281, ["Perceiving Older Adults Producing Clear and Lombard Speech", ["Chris Davis", "Jeesun Kim"], "https://doi.org/10.21437/Interspeech.2019-2210", 5, "interspeech", 2019]], "Nam Soo Kim": [1, ["End-to-End Multi-Channel Speech Enhancement Using Inter-Channel Time-Restricted Attention on Raw Waveform", ["Hyeon Seung Lee", "Hyung Yong Kim", "Woo Hyun Kang", "Jeunghun Kim", "Nam Soo Kim"], "https://doi.org/10.21437/Interspeech.2019-2397", 5, "interspeech", 2019]], "Y. Wang": [0.5, ["Impact of ASR Performance on Spoken Grammatical Error Detection", ["Yiting Lu", "Mark J. F. Gales", "Kate M. Knill", "P. P. Manakul", "Linlin Wang", "Y. Wang"], "https://doi.org/10.21437/Interspeech.2019-1706", 5, "interspeech", 2019]], "Soo-Young Lee": [0.9948376417160034, ["Adjusting Pleasure-Arousal-Dominance for Continuous Emotional Text-to-Speech Synthesizer", ["Azam Rabiee", "Tae-Ho Kim", "Soo-Young Lee"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8045.html", 2, "interspeech", 2019]], "Yong-cheol Lee": [0.9995790272951126, ["Automatic Detection of Prosodic Focus in American English", ["Sunghye Cho", "Mark Liberman", "Yong-cheol Lee"], "https://doi.org/10.21437/Interspeech.2019-1668", 5, "interspeech", 2019]], "Yonghui Wu": [0.6403691470623016, ["Direct Speech-to-Speech Translation with a Sequence-to-Sequence Model", ["Ye Jia", "Ron J. Weiss", "Fadi Biadsy", "Wolfgang Macherey", "Melvin Johnson", "Zhifeng Chen", "Yonghui Wu"], "https://doi.org/10.21437/Interspeech.2019-1951", 5, "interspeech", 2019], ["LibriTTS: A Corpus Derived from LibriSpeech for Text-to-Speech", ["Heiga Zen", "Viet Dang", "Rob Clark", "Yu Zhang", "Ron J. Weiss", "Ye Jia", "Zhifeng Chen", "Yonghui Wu"], "https://doi.org/10.21437/Interspeech.2019-2441", 5, "interspeech", 2019]], "Chanwoo Kim": [0.9085521399974823, ["Multi-Task Multi-Resolution Char-to-BPE Cross-Attention Decoder for End-to-End Speech Recognition", ["Dhananjaya Gowda", "Abhinav Garg", "Kwangyoun Kim", "Mehul Kumar", "Chanwoo Kim"], "https://doi.org/10.21437/Interspeech.2019-3216", 5, "interspeech", 2019]], "Hong-Goo Kang": [1, ["Parameter Enhancement for MELP Speech Codec in Noisy Communication Environment", ["Min-Jae Hwang", "Hong-Goo Kang"], "https://doi.org/10.21437/Interspeech.2019-3249", 5, "interspeech", 2019]], "Minje Kim": [0.867972731590271, ["Cascaded Cross-Module Residual Learning Towards Lightweight End-to-End Speech Coding", ["Kai Zhen", "Jongmo Sung", "Mi Suk Lee", "Seungkwon Beack", "Minje Kim"], "https://doi.org/10.21437/Interspeech.2019-1816", 5, "interspeech", 2019]], "Chin-Hui Lee": [0.5, ["Acoustic Model Ensembling Using Effective Data Augmentation for CHiME-5 Challenge", ["Feng Ma", "Li Chai", "Jun Du", "Diyuan Liu", "Zhongfu Ye", "Chin-Hui Lee"], "https://doi.org/10.21437/Interspeech.2019-2601", 5, "interspeech", 2019], ["KL-Divergence Regularized Deep Neural Network Adaptation for Low-Resource Speaker-Dependent Speech Enhancement", ["Li Chai", "Jun Du", "Chin-Hui Lee"], "https://doi.org/10.21437/Interspeech.2019-2426", 5, "interspeech", 2019], ["A Cross-Entropy-Guided (CEG) Measure for Speech Enhancement Front-End Assessing Performances of Back-End Automatic Speech Recognition", ["Li Chai", "Jun Du", "Chin-Hui Lee"], "https://doi.org/10.21437/Interspeech.2019-2511", 5, "interspeech", 2019], ["A Hybrid Approach to Acoustic Scene Classification Based on Universal Acoustic Models", ["Xue Bai", "Jun Du", "Zi-Rui Wang", "Chin-Hui Lee"], "https://doi.org/10.21437/Interspeech.2019-2171", 5, "interspeech", 2019]], "Jae-Min Kim": [0.9150348603725433, ["Probability Density Distillation with Generative Adversarial Networks for High-Quality Parallel Waveform Generation", ["Ryuichi Yamamoto", "Eunwoo Song", "Jae-Min Kim"], "https://doi.org/10.21437/Interspeech.2019-1965", 5, "interspeech", 2019]], "Hong Kook Kim": [0.9972290098667145, ["Directional Audio Rendering Using a Neural Network Based Personalized HRTF", ["Geon Woo Lee", "Jung Hyuk Lee", "Seong Ju Kim", "Hong Kook Kim"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8005.html", 2, "interspeech", 2019]], "Icksang Han": [0.9961989969015121, ["Who Said That?: Audio-Visual Speaker Diarisation of Real-World Meetings", ["Joon Son Chung", "Bong-Jin Lee", "Icksang Han"], "https://doi.org/10.21437/Interspeech.2019-3116", 5, "interspeech", 2019]]}