{"Sandeep Nallan Chakravarthula": [0, ["Modeling Interpersonal Influence of Verbal Behavior in Couples Therapy Dyadic Interactions", ["Sandeep Nallan Chakravarthula", "Brian R. Baucom", "Panayiotis G. Georgiou"], "https://doi.org/10.21437/Interspeech.2018-1562", 5, "interspeech", 2018]], "Sei Ueno": [0, ["Encoder Transfer for Attention-based Acoustic-to-word Speech Recognition", ["Sei Ueno", "Takafumi Moriya", "Masato Mimura", "Shinsuke Sakai", "Yusuke Shinohara", "Yoshikazu Yamaguchi", "Yushi Aono", "Tatsuya Kawahara"], "https://doi.org/10.21437/Interspeech.2018-1424", 5, "interspeech", 2018]], "Jing Han": [0.0677884966135025, ["Bags in Bag: Generating Context-Aware Bags for Tracking Emotions from Speech", ["Jing Han", "Zixing Zhang", "Maximilian Schmitt", "Zhao Ren", "Fabien Ringeval", "Bjorn W. Schuller"], "https://doi.org/10.21437/Interspeech.2018-996", 5, "interspeech", 2018]], "Albert Zeyer": [0, ["Improved Training of End-to-end Attention Models for Speech Recognition", ["Albert Zeyer", "Kazuki Irie", "Ralf Schluter", "Hermann Ney"], "https://doi.org/10.21437/Interspeech.2018-1616", 5, "interspeech", 2018]], "Nattanun Chanchaochai": [0, ["GlobalTIMIT: Acoustic-Phonetic Datasets for the World's Languages", ["Nattanun Chanchaochai", "Christopher Cieri", "Japhet Debrah", "Hongwei Ding", "Yue Jiang", "Sishi Liao", "Mark Liberman", "Jonathan Wright", "Jiahong Yuan", "Juhong Zhan", "Yuqing Zhan"], "https://doi.org/10.21437/Interspeech.2018-1185", 5, "interspeech", 2018]], "Takashi Fukuda": [0, ["Data Augmentation Improves Recognition of Foreign Accented Speech", ["Takashi Fukuda", "Raul Fernandez", "Andrew Rosenberg", "Samuel Thomas", "Bhuvana Ramabhadran", "Alexander Sorin", "Gakuto Kurata"], "https://doi.org/10.21437/Interspeech.2018-1211", 5, "interspeech", 2018]], "Hao Zhang": [0, ["Deep Learning for Acoustic Echo Cancellation in Noisy and Double-Talk Scenarios", ["Hao Zhang", "DeLiang Wang"], "https://doi.org/10.21437/Interspeech.2018-1484", 5, "interspeech", 2018]], "Madhusudan Singh": [0, ["Linear Prediction Residual based Short-term Cepstral Features for Replay Attacks Detection", ["Madhusudan Singh", "Debadatta Pati"], "https://doi.org/10.21437/Interspeech.2018-1128", 5, "interspeech", 2018]], "Mahesh Kumar Nandwana": [0, ["Robust Speaker Recognition from Distant Speech under Real Reverberant Environments Using Speaker Embeddings", ["Mahesh Kumar Nandwana", "Julien van Hout", "Mitchell McLaren", "Allen R. Stauffer", "Colleen Richey", "Aaron Lawson", "Martin Graciarena"], "https://doi.org/10.21437/Interspeech.2018-2221", 5, "interspeech", 2018], ["Analysis of Complementary Information Sources in the Speaker Embeddings Framework", ["Mahesh Kumar Nandwana", "Mitchell McLaren", "Diego Castan", "Julien van Hout", "Aaron Lawson"], "https://doi.org/10.21437/Interspeech.2018-1102", 5, "interspeech", 2018]], "Pengcheng Li": [0, ["An Attention Pooling Based Representation Learning Method for Speech Emotion Recognition", ["Pengcheng Li", "Yan Song", "Ian Vince McLoughlin", "Wu Guo", "Lirong Dai"], "https://doi.org/10.21437/Interspeech.2018-1242", 5, "interspeech", 2018]], "Kamini Sabu": [0, ["Automatic Detection of Expressiveness in Oral Reading", ["Kamini Sabu", "Kanhaiya Kumar", "Preeti Rao"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3026.html", 2, "interspeech", 2018]], "Wolfgang Mack": [0, ["Single-Channel Dereverberation Using Direct MMSE Optimization and Bidirectional LSTM Networks", ["Wolfgang Mack", "Soumitro Chakrabarty", "Fabian-Robert Stoter", "Sebastian Braun", "Bernd Edler", "Emanuel A. P. Habets"], "https://doi.org/10.21437/Interspeech.2018-1296", 5, "interspeech", 2018]], "Pramit Saha": [0, ["Towards Automatic Speech Identification from Vocal Tract Shape Dynamics in Real-time MRI", ["Pramit Saha", "Praneeth Srungarapu", "Sidney Fels"], "https://doi.org/10.21437/Interspeech.2018-2537", 5, "interspeech", 2018]], "Xiao Zhou": [0, ["Learning and Modeling Unit Embeddings for Improving HMM-based Unit Selection Speech Synthesis", ["Xiao Zhou", "Zhen-Hua Ling", "Zhi-Ping Zhou", "Li-Rong Dai"], "https://doi.org/10.21437/Interspeech.2018-1198", 5, "interspeech", 2018]], "Jason Lilley": [0, ["The Use of Machine Learning and Phonetic Endophenotypes to Discover Genetic Variants Associated with Speech Sound Disorder", ["Jason Lilley", "Erin Crowgey", "H. Timothy Bunnell"], "https://doi.org/10.21437/Interspeech.2018-2398", 5, "interspeech", 2018]], "Anuroop Sriram": [0, ["Cold Fusion: Training Seq2Seq Models Together with Language Models", ["Anuroop Sriram", "Heewoo Jun", "Sanjeev Satheesh", "Adam Coates"], "https://doi.org/10.21437/Interspeech.2018-1392", 5, "interspeech", 2018]], "Bo Xiao": [0, ["Play Duration Based User-Entity Affinity Modeling in Spoken Dialog System", ["Bo Xiao", "Nicholas Monath", "Shankar Ananthakrishnan", "Abishek Ravi"], "https://doi.org/10.21437/Interspeech.2018-1100", 5, "interspeech", 2018]], "Yu Gu": [0.002284156798850745, ["Multi-task WaveNet: A Multi-task Generative Model for Statistical Parametric Speech Synthesis without Fundamental Frequency Conditions", ["Yu Gu", "Yongguo Kang"], "https://doi.org/10.21437/Interspeech.2018-1506", 5, "interspeech", 2018]], "Ashutosh Pandey": [0, ["A New Framework for Supervised Speech Enhancement in the Time Domain", ["Ashutosh Pandey", "DeLiang Wang"], "https://doi.org/10.21437/Interspeech.2018-1223", 5, "interspeech", 2018]], "Tifani Warnita": [0, ["Detecting Alzheimer's Disease Using Gated Convolutional Neural Network from Audio Data", ["Tifani Warnita", "Nakamasa Inoue", "Koichi Shinoda"], "https://doi.org/10.21437/Interspeech.2018-1713", 5, "interspeech", 2018]], "Mate Akos Tundik": [0, ["User-centric Evaluation of Automatic Punctuation in ASR Closed Captioning", ["Mate Akos Tundik", "Gyorgy Szaszak", "Gabor Gosztolya", "Andras Beke"], "https://doi.org/10.21437/Interspeech.2018-1352", 5, "interspeech", 2018]], "Prasad Tapkir": [0, ["Novel Empirical Mode Decomposition Cepstral Features for Replay Spoof Detection", ["Prasad Tapkir", "Hemant A. Patil"], "https://doi.org/10.21437/Interspeech.2018-1661", 5, "interspeech", 2018]], "Tanumay Mandal": [0, ["Classification of Disorders in Vocal Folds Using Electroglottographic Signal", ["Tanumay Mandal", "K. Sreenivasa Rao", "Sanjay Kumar Gupta"], "https://doi.org/10.21437/Interspeech.2018-1967", 5, "interspeech", 2018]], "Enea Ceolini": [0, ["Speaker Activity Detection and Minimum Variance Beamforming for Source Separation", ["Enea Ceolini", "Jithendar Anumula", "Adrian E. G. Huber", "Ilya Kiselev", "Shih-Chii Liu"], "https://doi.org/10.21437/Interspeech.2018-1606", 5, "interspeech", 2018]], "Zack Hodari": [0, ["Learning Interpretable Control Dimensions for Speech Synthesis by Using External Data", ["Zack Hodari", "Oliver Watts", "Srikanth Ronanki", "Simon King"], "https://doi.org/10.21437/Interspeech.2018-2075", 5, "interspeech", 2018]], "Jane Wottawa": [0, ["Studying Vowel Variation in French-Algerian Arabic Code-switched Speech", ["Jane Wottawa", "Djegdjiga Amazouz", "Martine Adda-Decker", "Lori Lamel"], "https://doi.org/10.21437/Interspeech.2018-2381", 5, "interspeech", 2018]], "Rini A. Sharon": [0, ["Correlational Networks for Speaker Normalization in Automatic Speech Recognition", ["Rini A. Sharon", "Sandeep Reddy Kothinti", "Srinivasan Umesh"], "https://doi.org/10.21437/Interspeech.2018-1612", 5, "interspeech", 2018]], "Laxmi Pandey": [0, ["LSTM Based Attentive Fusion of Spectral and Prosodic Information for Keyword Spotting in Hindi Language", ["Laxmi Pandey", "Karan Nathwani"], "https://doi.org/10.21437/Interspeech.2018-1016", 5, "interspeech", 2018], ["Monoaural Audio Source Separation Using Variational Autoencoders", ["Laxmi Pandey", "Anurendra Kumar", "Vinay Namboodiri"], "https://doi.org/10.21437/Interspeech.2018-1140", 5, "interspeech", 2018]], "Minghui Zhang": [0, ["Pitch or Phonation: on the Glottalization in Tone Productions in the Ruokeng Hui Chinese Dialect", ["Minghui Zhang", "Fang Hu"], "https://doi.org/10.21437/Interspeech.2018-1638", 5, "interspeech", 2018]], "Xiaofei Wang": [3.716871946231055e-15, ["Stream Attention for Distributed Multi-Microphone Speech Recognition", ["Xiaofei Wang", "Ruizhi Li", "Hynek Hermansky"], "https://doi.org/10.21437/Interspeech.2018-1037", 5, "interspeech", 2018]], "Weipeng He": [0, ["Joint Localization and Classification of Multiple Sound Sources Using a Multi-task Neural Network", ["Weipeng He", "Petr Motlicek", "Jean-Marc Odobez"], "https://doi.org/10.21437/Interspeech.2018-1269", 5, "interspeech", 2018]], "Bastian Schnell": [0, ["A Neural Model to Predict Parameters for a Generalized Command Response Model of Intonation", ["Bastian Schnell", "Philip N. Garner"], "https://doi.org/10.21437/Interspeech.2018-1904", 5, "interspeech", 2018]], "Ruibo Fu": [0, ["Transfer Learning Based Progressive Neural Networks for Acoustic Modeling in Statistical Parametric Speech Synthesis", ["Ruibo Fu", "Jianhua Tao", "Yibin Zheng", "Zhengqi Wen"], "https://doi.org/10.21437/Interspeech.2018-1265", 5, "interspeech", 2018], ["Deep Metric Learning for the Target Cost in Unit-Selection Speech Synthesizer", ["Ruibo Fu", "Jianhua Tao", "Yibin Zheng", "Zhengqi Wen"], "https://doi.org/10.21437/Interspeech.2018-1305", 5, "interspeech", 2018]], "Madhu R. Kamble": [0, ["Effectiveness of Speech Demodulation-Based Features for Replay Detection", ["Madhu R. Kamble", "Hemlata Tak", "Hemant A. Patil"], "https://doi.org/10.21437/Interspeech.2018-1675", 5, "interspeech", 2018], ["Novel Variable Length Energy Separation Algorithm Using Instantaneous Amplitude Features for Replay Detection", ["Madhu R. Kamble", "Hemant A. Patil"], "https://doi.org/10.21437/Interspeech.2018-1687", 5, "interspeech", 2018]], "Saurabh Sahu": [0, ["On Enhancing Speech Emotion Recognition Using Generative Adversarial Networks", ["Saurabh Sahu", "Rahul Gupta", "Carol Y. Espy-Wilson"], "https://doi.org/10.21437/Interspeech.2018-1883", 5, "interspeech", 2018]], "Shahram Ghorbani": [0, ["Leveraging Native Language Information for Improved Accented Speech Recognition", ["Shahram Ghorbani", "John H. L. Hansen"], "https://doi.org/10.21437/Interspeech.2018-1378", 5, "interspeech", 2018]], "Keelan Evanini": [0, ["Game-based Spoken Dialog Language Learning Applications for Young Students", ["Keelan Evanini", "Veronika Timpe-Laughlin", "Eugene Tsuprun", "Ian Blood", "Jeremy Lee", "James V. Bruno", "Vikram Ramanarayanan", "Patrick L. Lange", "David Suendermann-Oeft"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3045.html", 2, "interspeech", 2018], ["Improvements to an Automated Content Scoring System for Spoken CALL Responses: the ETS Submission to the Second Spoken CALL Shared Task", ["Keelan Evanini", "Matthew Mulholland", "Rutuja Ubale", "Yao Qian", "Robert A. Pugh", "Vikram Ramanarayanan", "Aoife Cahill"], "https://doi.org/10.21437/Interspeech.2018-2362", 5, "interspeech", 2018]], "Szu-Jui Chen": [0, ["Building State-of-the-art Distant Speech Recognition Using the CHiME-4 Challenge with a Setup of Speech Enhancement Baseline", ["Szu-Jui Chen", "Aswin Shanmugam Subramanian", "Hainan Xu", "Shinji Watanabe"], "https://doi.org/10.21437/Interspeech.2018-1262", 5, "interspeech", 2018]], "Matthias Sperber": [0, ["Self-Attentional Acoustic Models", ["Matthias Sperber", "Jan Niehues", "Graham Neubig", "Sebastian Stuker", "Alex Waibel"], "https://doi.org/10.21437/Interspeech.2018-1910", 5, "interspeech", 2018]], "Maren Kucza": [0, ["Term Extraction via Neural Sequence Labeling a Comparative Evaluation of Strategies Using Recurrent Neural Networks", ["Maren Kucza", "Jan Niehues", "Thomas Zenkel", "Alex Waibel", "Sebastian Stuker"], "https://doi.org/10.21437/Interspeech.2018-2017", 5, "interspeech", 2018]], "Kazuhiro Kondo": [0, ["Binaural Speech Intelligibility Estimation Using Deep Neural Networks", ["Kazuhiro Kondo", "Kazuya Taira", "Yosuke Kobayashi"], "https://doi.org/10.21437/Interspeech.2018-27", 5, "interspeech", 2018]], "Avik Ray": [0, ["Robust Spoken Language Understanding via Paraphrasing", ["Avik Ray", "Yilin Shen", "Hongxia Jin"], "https://doi.org/10.21437/Interspeech.2018-2358", 5, "interspeech", 2018]], "Takuya Yoshioka": [0, ["Recognizing Overlapped Speech in Meetings: A Multichannel Separation Approach Using Neural Networks", ["Takuya Yoshioka", "Hakan Erdogan", "Zhuo Chen", "Xiong Xiao", "Fil Alleva"], "https://doi.org/10.21437/Interspeech.2018-2284", 5, "interspeech", 2018]], "Thomas Glarner": [0, ["Full Bayesian Hidden Markov Model Variational Autoencoder for Acoustic Unit Discovery", ["Thomas Glarner", "Patrick Hanebrink", "Janek Ebbers", "Reinhold Haeb-Umbach"], "https://doi.org/10.21437/Interspeech.2018-2148", 5, "interspeech", 2018]], "Rajat Hebbar": [0, ["Improving Gender Identification in Movie Audio Using Cross-Domain Data", ["Rajat Hebbar", "Krishna Somandepalli", "Shrikanth Narayanan"], "https://doi.org/10.21437/Interspeech.2018-1462", 5, "interspeech", 2018]], "Ivan Himawan": [0, ["Deep Learning Techniques for Koala Activity Detection", ["Ivan Himawan", "Michael Towsey", "Bradley Law", "Paul Roe"], "https://doi.org/10.21437/Interspeech.2018-1143", 5, "interspeech", 2018]], "Rohith Aralikatti": [0, ["Global SNR Estimation of Speech Signals Using Entropy and Uncertainty Estimates from Dropout Networks", ["Rohith Aralikatti", "Dilip Kumar Margam", "Tanay Sharma", "Abhinav Thanda", "Shankar M. Venkatesan"], "https://doi.org/10.21437/Interspeech.2018-1884", 5, "interspeech", 2018]], "Takuma Mori": [0, ["Compressing End-to-end ASR Networks by Tensor-Train Decomposition", ["Takuma Mori", "Andros Tjandra", "Sakriani Sakti", "Satoshi Nakamura"], "https://doi.org/10.21437/Interspeech.2018-1543", 5, "interspeech", 2018]], "Alp Oktem": [0, ["Visualizing Punctuation Restoration in Speech Transcripts with Prosograph", ["Alp Oktem", "Mireia Farrus", "Antonio Bonafonte"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3028.html", 2, "interspeech", 2018]], "Preeti Rao": [0, ["A Study of Lexical and Prosodic Cues to Segmentation in a Hindi-English Code-switched Discourse", ["Preeti Rao", "Mugdha Pandya", "Kamini Sabu", "Kanhaiya Kumar", "Nandini Bondale"], "https://doi.org/10.21437/Interspeech.2018-1600", 5, "interspeech", 2018]], "Colleen Richey": [0, ["Voices Obscured in Complex Environmental Settings (VOiCES) Corpus", ["Colleen Richey", "Maria Auxiliadora Barrios", "Zeb Armstrong", "Chris Bartels", "Horacio Franco", "Martin Graciarena", "Aaron Lawson", "Mahesh Kumar Nandwana", "Allen R. Stauffer", "Julien van Hout", "Paul Gamble", "Jeffrey Hetherly", "Cory Stephenson", "Karl Ni"], "https://doi.org/10.21437/Interspeech.2018-1454", 5, "interspeech", 2018]], "Nauman Dawalatabad": [0, ["Information Bottleneck Based Percussion Instrument Diarization System for Taniavartanam Segments of Carnatic Music Concerts", ["Nauman Dawalatabad", "Jom Kuriakose", "Chellu Chandra Sekhar", "Hema A. Murthy"], "https://doi.org/10.21437/Interspeech.2018-1203", 5, "interspeech", 2018]], "Mirco Ravanelli": [0, ["Twin Regularization for Online Speech Recognition", ["Mirco Ravanelli", "Dmitriy Serdyuk", "Yoshua Bengio"], "https://doi.org/10.21437/Interspeech.2018-1407", 5, "interspeech", 2018]], "Sankar Mukherjee": [0, ["Analyzing Vocal Tract Movements During Speech Accommodation", ["Sankar Mukherjee", "Thierry Legou", "Leonardo Lancia", "Pauline Hilt", "Alice Tomassini", "Luciano Fadiga", "Alessandro DAusilio", "Leonardo Badino", "Noel Nguyen"], "https://doi.org/10.21437/Interspeech.2018-2084", 5, "interspeech", 2018]], "Srinivas Parthasarathy": [0, ["Preference-Learning with Qualitative Agreement for Sentence Level Emotional Annotations", ["Srinivas Parthasarathy", "Carlos Busso"], "https://doi.org/10.21437/Interspeech.2018-2478", 5, "interspeech", 2018], ["Ladder Networks for Emotion Recognition: Using Unsupervised Auxiliary Tasks to Improve Predictions of Emotional Attributes", ["Srinivas Parthasarathy", "Carlos Busso"], "https://doi.org/10.21437/Interspeech.2018-1391", 5, "interspeech", 2018]], "Raquel Norel": [0, ["Detection of Amyotrophic Lateral Sclerosis (ALS) via Acoustic Analysis", ["Raquel Norel", "Mary Pietrowicz", "Carla Agurto", "Shay Rishoni", "Guillermo A. Cecchi"], "https://doi.org/10.21437/Interspeech.2018-2389", 5, "interspeech", 2018]], "Shahin Amiriparian": [0, ["Recognition of Echolalic Autistic Child Vocalisations Utilising Convolutional Recurrent Neural Networks", ["Shahin Amiriparian", "Alice Baird", "Sahib Julka", "Alyssa Alcorn", "Sandra Ottl", "Suncica Petrovic", "Eloise Ainger", "Nicholas Cummins", "Bjorn W. Schuller"], "https://doi.org/10.21437/Interspeech.2018-1772", 5, "interspeech", 2018]], "Surbhi Sakshi": [0, ["Analysis of Variational Mode Functions for Robust Detection of Vowels", ["Surbhi Sakshi", "Avinash Kumar", "Gayadhar Pradhan"], "https://doi.org/10.21437/Interspeech.2018-1947", 5, "interspeech", 2018]], "Elisabet Eir Cortes": [0, ["Articulatory Consequences of Vocal Effort Elicitation Method", ["Elisabet Eir Cortes", "Marcin Wlodarczak", "Juraj Simko"], "https://doi.org/10.21437/Interspeech.2018-1038", 5, "interspeech", 2018]], "Songxiang Liu": [0, ["Voice Conversion Across Arbitrary Speakers Based on a Single Target-Speaker Utterance", ["Songxiang Liu", "Jinghua Zhong", "Lifa Sun", "Xixin Wu", "Xunying Liu", "Helen Meng"], "https://doi.org/10.21437/Interspeech.2018-1504", 5, "interspeech", 2018]], "Marek Hruz": [0, ["Multimodal Name Recognition in Live TV Subtitling", ["Marek Hruz", "Ales Prazak", "Michal Busta"], "https://doi.org/10.21437/Interspeech.2018-1748", 4, "interspeech", 2018]], "Danqing Luo": [0, ["Investigation on Joint Representation Learning for Robust Feature Extraction in Speech Emotion Recognition", ["Danqing Luo", "Yuexian Zou", "Dongyan Huang"], "https://doi.org/10.21437/Interspeech.2018-1832", 5, "interspeech", 2018]], "Jishnu Sadasivan": [0, ["Speech Enhancement Using the Minimum-probability-of-error Criterion", ["Jishnu Sadasivan", "Subhadip Mukherjee", "Chandra Sekhar Seelamantula"], "https://doi.org/10.21437/Interspeech.2018-1294", 5, "interspeech", 2018]], "Siddique Latif": [0, ["Transfer Learning for Improving Speech Emotion Classification Accuracy", ["Siddique Latif", "Rajib Rana", "Shahzad Younis", "Junaid Qadir", "Julien Epps"], "https://doi.org/10.21437/Interspeech.2018-1625", 5, "interspeech", 2018], ["Variational Autoencoders for Learning Latent Representations of Speech Emotion: A Preliminary Study", ["Siddique Latif", "Rajib Rana", "Junaid Qadir", "Julien Epps"], "https://doi.org/10.21437/Interspeech.2018-1568", 5, "interspeech", 2018]], "M. V. Achuth Rao": [0, ["Automatic Glottis Localization and Segmentation in Stroboscopic Videos Using Deep Neural Network", ["M. V. Achuth Rao", "Rahul Krishnamurthy", "Pebbili Gopikishore", "Veeramani Priyadharshini", "Prasanta Kumar Ghosh"], "https://doi.org/10.21437/Interspeech.2018-2572", 5, "interspeech", 2018]], "RaviShankar Prasad": [0, ["Discriminating Nasals and Approximants in English Language Using Zero Time Windowing", ["RaviShankar Prasad", "Sudarsana Reddy Kadiri", "Suryakanth V. Gangashetty", "Bayya Yegnanarayana"], "https://doi.org/10.21437/Interspeech.2018-1032", 5, "interspeech", 2018], ["Identification and Classification of Fricatives in Speech Using Zero Time Windowing Method", ["RaviShankar Prasad", "Bayya Yegnanarayana"], "https://doi.org/10.21437/Interspeech.2018-1958", 5, "interspeech", 2018]], "Weicheng Cai": [0, ["Analysis of Length Normalization in End-to-End Speaker Verification System", ["Weicheng Cai", "Jinkun Chen", "Ming Li"], "https://doi.org/10.21437/Interspeech.2018-92", 5, "interspeech", 2018]], "Eva-Maria Rathner": [0, ["State of Mind: Classification through Self-reported Affect and Word Use in Speech", ["Eva-Maria Rathner", "Yannik Terhorst", "Nicholas Cummins", "Bjorn W. Schuller", "Harald Baumeister"], "https://doi.org/10.21437/Interspeech.2018-2043", 5, "interspeech", 2018], ["How Did You like 2017? Detection of Language Markers of Depression and Narcissism in Personal Narratives", ["Eva-Maria Rathner", "Julia Djamali", "Yannik Terhorst", "Bjorn W. Schuller", "Nicholas Cummins", "Gudrun Salamon", "Christina Hunger-Schoppe", "Harald Baumeister"], "https://doi.org/10.21437/Interspeech.2018-2040", 5, "interspeech", 2018]], "Ram Charan Chandra Shekar": [0, ["Testing Paradigms for Assistive Hearing Devices in Diverse Acoustic Environments", ["Ram Charan Chandra Shekar", "Hussnain Ali", "John H. L. Hansen"], "https://doi.org/10.21437/Interspeech.2018-1471", 5, "interspeech", 2018]], "Ganesh Sivaraman": [0, ["Speech Synthesis in the Wild", ["Ganesh Sivaraman", "Parav Nagarsheth", "Elie Khoury"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3050.html", 2, "interspeech", 2018]], "B. Ganga Gowri": [0, ["Improved Epoch Extraction from Telephonic Speech Using Chebfun and Zero Frequency Filtering", ["B. Ganga Gowri", "Soman K. P", "D. Govind"], "https://doi.org/10.21437/Interspeech.2018-1173", 5, "interspeech", 2018]], "Eugen Beck": [0, ["Segmental Encoder-Decoder Models for Large Vocabulary Automatic Speech Recognition", ["Eugen Beck", "Mirko Hannemann", "Patrick Dotsch", "Ralf Schluter", "Hermann Ney"], "https://doi.org/10.21437/Interspeech.2018-1212", 5, "interspeech", 2018]], "Iksoo Choi": [0.9707764834165573, ["Character-level Language Modeling with Gated Hierarchical Recurrent Neural Networks", ["Iksoo Choi", "Jinhwan Park", "Wonyong Sung"], "https://doi.org/10.21437/Interspeech.2018-1727", 5, "interspeech", 2018]], "Margarita Kotti": [0, ["A Case Study on the Importance of Belief State Representation for Dialogue Policy Management", ["Margarita Kotti", "Vassilios Diakoloukas", "Alexandros Papangelis", "Michail Lagoudakis", "Yannis Stylianou"], "https://doi.org/10.21437/Interspeech.2018-1293", 5, "interspeech", 2018]], "Jinxi Guo": [0, ["Filter Sampling and Combination CNN (FSC-CNN): A Compact CNN Model for Small-footprint ASR Acoustic Modeling Using Raw Waveforms", ["Jinxi Guo", "Ning Xu", "Xin Chen", "Yang Shi", "Kaiyuan Xu", "Abeer Alwan"], "https://doi.org/10.21437/Interspeech.2018-1370", 5, "interspeech", 2018]], "Yuanjun Zhao": [0, ["Spoofing Detection Using Adaptive Weighting Framework and Clustering Analysis", ["Yuanjun Zhao", "Roberto Togneri", "Victor Sreeram"], "https://doi.org/10.21437/Interspeech.2018-1042", 5, "interspeech", 2018]], "Seyed Hamidreza Mohammadi": [0, ["Investigation of Using Disentangled and Interpretable Representations for One-shot Cross-lingual Voice Conversion", ["Seyed Hamidreza Mohammadi", "Taehwan Kim"], "https://doi.org/10.21437/Interspeech.2018-2525", 5, "interspeech", 2018]], "Norbert Braunschweiler": [0, ["Comparison of an End-to-end Trainable Dialogue System with a Modular Statistical Dialogue System", ["Norbert Braunschweiler", "Alexandros Papangelis"], "https://doi.org/10.21437/Interspeech.2018-1679", 5, "interspeech", 2018]], "Sameer Bansal": [0, ["Low-Resource Speech-to-Text Translation", ["Sameer Bansal", "Herman Kamper", "Karen Livescu", "Adam Lopez", "Sharon Goldwater"], "https://doi.org/10.21437/Interspeech.2018-1326", 5, "interspeech", 2018]], "Itshak Lapidot": [0, ["Speech Database and Protocol Validation Using Waveform Entropy", ["Itshak Lapidot", "Hector Delgado", "Massimiliano Todisco", "Nicholas W. D. Evans", "Jean-Francois Bonastre"], "https://doi.org/10.21437/Interspeech.2018-2330", 5, "interspeech", 2018]], "Andros Tjandra": [0, ["Machine Speech Chain with One-shot Speaker Adaptation", ["Andros Tjandra", "Sakriani Sakti", "Satoshi Nakamura"], "https://doi.org/10.21437/Interspeech.2018-1558", 5, "interspeech", 2018]], "Adithya Renduchintala": [0, ["Multi-Modal Data Augmentation for End-to-end ASR", ["Adithya Renduchintala", "Shuoyang Ding", "Matthew Wiesner", "Shinji Watanabe"], "https://doi.org/10.21437/Interspeech.2018-2456", 5, "interspeech", 2018]], "Pei-Hung Chung": [6.687654240522534e-05, ["Joint Learning of Interactive Spoken Content Retrieval and Trainable User Simulator", ["Pei-Hung Chung", "Kuan Tung", "Ching-Lun Tai", "Hung-yi Lee"], "https://doi.org/10.21437/Interspeech.2018-1346", 5, "interspeech", 2018]], "Karttikeya Mangalam": [0, ["Learning Spontaneity to Improve Emotion Recognition in Speech", ["Karttikeya Mangalam", "Tanaya Guha"], "https://doi.org/10.21437/Interspeech.2018-1872", 5, "interspeech", 2018]], "Kyu J. Han": [0.11794104427099228, ["Densely Connected Networks for Conversational Speech Recognition", ["Kyu J. Han", "Akshay Chandrashekaran", "Jungsuk Kim", "Ian Lane"], "https://doi.org/10.21437/Interspeech.2018-1486", 5, "interspeech", 2018]], "Pengcheng Guo": [0, ["Study of Semi-supervised Approaches to Improving English-Mandarin Code-Switching Speech Recognition", ["Pengcheng Guo", "Haihua Xu", "Lei Xie", "Eng Siong Chng"], "https://doi.org/10.21437/Interspeech.2018-1974", 5, "interspeech", 2018]], "Sarith Fernando": [0, ["Sub-band Envelope Features Using Frequency Domain Linear Prediction for Short Duration Language Identification", ["Sarith Fernando", "Vidhyasaharan Sethu", "Eliathamby Ambikairajah"], "https://doi.org/10.21437/Interspeech.2018-1805", 5, "interspeech", 2018]], "Bhamini Sharma": [0, ["Effects of Homophone Density on Spoken Word Recognition in Mandarin Chinese", ["Bhamini Sharma"], "https://doi.org/10.21437/Interspeech.2018-2114", 4, "interspeech", 2018]], "Julien Meyer": [0, ["Loud and Shouted Speech Perception at Variable Distances in a Forest", ["Julien Meyer", "Fanny Meunier", "Laure Dentel", "Noelia Do Carmo Blanco", "Frederic Sebe"], "https://doi.org/10.21437/Interspeech.2018-2089", 5, "interspeech", 2018]], "Ivan Kraljevski": [0, ["Classification of Correction Turns in Multilingual Dialogue Corpus", ["Ivan Kraljevski", "Diane Hirschfeld"], "https://doi.org/10.21437/Interspeech.2018-1348", 5, "interspeech", 2018]], "Chetan Naik": [0, ["Contextual Slot Carryover for Disparate Schemas", ["Chetan Naik", "Arpit Gupta", "Hancheng Ge", "Lambert Mathias", "Ruhi Sarikaya"], "https://doi.org/10.21437/Interspeech.2018-1035", 5, "interspeech", 2018]], "Chieh-Chi Kao": [0, ["R-CRNN: Region-based Convolutional Recurrent Neural Network for Audio Event Detection", ["Chieh-Chi Kao", "Weiran Wang", "Ming Sun", "Chao Wang"], "https://doi.org/10.21437/Interspeech.2018-2323", 5, "interspeech", 2018]], "Rohit M. A": [0, ["Acoustic-Prosodic Features of Tabla Bol Recitation and Correspondence with the Tabla Imitation", ["Rohit M. A", "Preeti Rao"], "https://doi.org/10.21437/Interspeech.2018-1692", 5, "interspeech", 2018]], "Farzaneh Ahmadi": [0, ["Designing a Pneumatic Bionic Voice Prosthesis - A Statistical Approach for Source Excitation Generation", ["Farzaneh Ahmadi", "Tomoki Toda"], "https://doi.org/10.21437/Interspeech.2018-1043", 5, "interspeech", 2018]], "Ruifang Ji": [2.161666498068371e-05, ["An End-to-End Text-Independent Speaker Identification System on Short Utterances", ["Ruifang Ji", "Xinyuan Cai", "Xu Bo"], "https://doi.org/10.21437/Interspeech.2018-1058", 5, "interspeech", 2018]], "Raghav Menon": [0, ["Fast ASR-free and Almost Zero-resource Keyword Spotting Using DTW and CNNs for Humanitarian Monitoring", ["Raghav Menon", "Herman Kamper", "John Quinn", "Thomas Niesler"], "https://doi.org/10.21437/Interspeech.2018-1580", 5, "interspeech", 2018]], "Dan Aharon": [0, ["Voice-powered Solutions with Cloud AI", ["Dan Aharon"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3049.html", 1, "interspeech", 2018]], "Marie-Lou Barnaud": [0, ["COSMO SylPhon: A Bayesian Perceptuo-motor Model to Assess Phonological Learning", ["Marie-Lou Barnaud", "Julien Diard", "Pierre Bessiere", "Jean-Luc Schwartz"], "https://doi.org/10.21437/Interspeech.2018-73", 5, "interspeech", 2018]], "M. S. Saranya": [0, ["Decision-level Feature Switching as a Paradigm for Replay Attack Detection", ["M. S. Saranya", "Hema A. Murthy"], "https://doi.org/10.21437/Interspeech.2018-1494", 5, "interspeech", 2018]], "Tsuyoki Ujiro": [0, ["Detection of Dementia from Responses to Atypical Questions Asked by Embodied Conversational Agents", ["Tsuyoki Ujiro", "Hiroki Tanaka", "Hiroyoshi Adachi", "Hiroaki Kazui", "Manabu Ikeda", "Takashi Kudo", "Satoshi Nakamura"], "https://doi.org/10.21437/Interspeech.2018-1514", 5, "interspeech", 2018]], "Chadi Farah": [0, ["Prosodic Focus Acquisition in French Early Cochlear Implanted Children", ["Chadi Farah", "Stephane Roman", "Mariapaola DImperio"], "https://doi.org/10.21437/Interspeech.2018-1320", 5, "interspeech", 2018]], "Yun Liu": [0, ["Using Shifted Real Spectrum Mask as Training Target for Supervised Speech Separation", ["Yun Liu", "Hui Zhang", "Xueliang Zhang"], "https://doi.org/10.21437/Interspeech.2018-1650", 5, "interspeech", 2018]], "Tsukasa Yoshida": [0, ["Automatic DNN Node Pruning Using Mixture Distribution-based Group Regularization", ["Tsukasa Yoshida", "Takafumi Moriya", "Kazuho Watanabe", "Yusuke Shinohara", "Yoshikazu Yamaguchi", "Yushi Aono"], "https://doi.org/10.21437/Interspeech.2018-2062", 5, "interspeech", 2018]], "Fasih Haider": [0, ["An Active Feature Transformation Method for Attitude Recognition of Video Bloggers", ["Fasih Haider", "Fahim A. Salim", "Owen Conlan", "Saturnino Luz"], "https://doi.org/10.21437/Interspeech.2018-1222", 5, "interspeech", 2018], ["Improving Response Time of Active Speaker Detection Using Visual Prosody Information Prior to Articulation", ["Fasih Haider", "Saturnino Luz", "Carl Vogel", "Nick Campbell"], "https://doi.org/10.21437/Interspeech.2018-2310", 5, "interspeech", 2018]], "Dongbo Li": [0, ["Multiple Phase Information Combination for Replay Attacks Detection", ["Dongbo Li", "Longbiao Wang", "Jianwu Dang", "Meng Liu", "Zeyan Oo", "Seiichi Nakagawa", "Haotian Guan", "Xiangang Li"], "https://doi.org/10.21437/Interspeech.2018-2001", 5, "interspeech", 2018]], "Jinfu Ni": [0, ["Multilingual Grapheme-to-Phoneme Conversion with Global Character Vectors", ["Jinfu Ni", "Yoshinori Shiga", "Hisashi Kawai"], "https://doi.org/10.21437/Interspeech.2018-1626", 5, "interspeech", 2018]], "Nagendra Kumar Goel": [0, ["Extracting Speaker's Gender, Accent, Age and Emotional State from Speech", ["Nagendra Kumar Goel", "Mousmita Sarma", "Tejendra Kushwah", "Dharmesh Agarwal", "Zikra Iqbal", "Surbhi Chauhan"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3036.html", 2, "interspeech", 2018]], "Natalie Boll-Avetisyan": [0, ["Neural Response Development During Distributional Learning", ["Natalie Boll-Avetisyan", "Jessie S. Nixon", "Tomas O. Lentz", "Liquan Liu", "Sandrien van Ommen", "Cagri Coltekin", "Jacolien van Rij"], "https://doi.org/10.21437/Interspeech.2018-2072", 5, "interspeech", 2018]], "Sourish Chaudhuri": [0, ["AVA-Speech: A Densely Labeled Dataset of Speech Activity in Movies", ["Sourish Chaudhuri", "Joseph Roth", "Daniel P. W. Ellis", "Andrew C. Gallagher", "Liat Kaver", "Radhika Marvin", "Caroline Pantofaru", "Nathan Reale", "Loretta Guarino Reid", "Kevin W. Wilson", "Zhonghua Xi"], "https://doi.org/10.21437/Interspeech.2018-2028", 5, "interspeech", 2018]], "Hemlata Tak": [0, ["Novel Linear Frequency Residual Cepstral Features for Replay Attack Detection", ["Hemlata Tak", "Hemant A. Patil"], "https://doi.org/10.21437/Interspeech.2018-1702", 5, "interspeech", 2018]], "Zixiaofan Yang": [1.3875621835380487e-18, ["Predicting Arousal and Valence from Waveforms and Spectrograms Using Deep Neural Networks", ["Zixiaofan Yang", "Julia Hirschberg"], "https://doi.org/10.21437/Interspeech.2018-2397", 5, "interspeech", 2018]], "Yosi Mass": [0, ["Word Emphasis Prediction for Expressive Text to Speech", ["Yosi Mass", "Slava Shechtman", "Moran Mordechay", "Ron Hoory", "Oren Sar Shalom", "Guy Lev", "David Konopnicki"], "https://doi.org/10.21437/Interspeech.2018-1159", 5, "interspeech", 2018]], "Weiran Wang": [0.0030166752403602004, ["A Simple Model for Detection of Rare Sound Events", ["Weiran Wang", "Chieh-Chi Kao", "Chao Wang"], "https://doi.org/10.21437/Interspeech.2018-2338", 5, "interspeech", 2018]], "Benjamin Parrell": [0, ["FACTS: A Hierarchical Task-based Control Model of Speech Incorporating Sensory Feedback", ["Benjamin Parrell", "Vikram Ramanarayanan", "Srikantan S. Nagarajan", "John F. Houde"], "https://doi.org/10.21437/Interspeech.2018-2087", 5, "interspeech", 2018]], "Zhong Meng": [0, ["Cycle-Consistent Speech Enhancement", ["Zhong Meng", "Jinyu Li", "Yifan Gong", "Biing-Hwang Fred Juang"], "https://doi.org/10.21437/Interspeech.2018-2409", 5, "interspeech", 2018], ["Adversarial Feature-Mapping for Speech Enhancement", ["Zhong Meng", "Jinyu Li", "Yifan Gong", "Biing-Hwang Fred Juang"], "https://doi.org/10.21437/Interspeech.2018-2461", 5, "interspeech", 2018]], "Erica Gold": [0, ["Articulation Rate as a Speaker Discriminant in British English", ["Erica Gold"], "https://doi.org/10.21437/Interspeech.2018-1384", 5, "interspeech", 2018], ["The 'West Yorkshire Regional English Database': Investigations into the Generalizability of Reference Populations for Forensic Speaker Comparison Casework", ["Erica Gold", "Sula Ross", "Kate Earnshaw"], "https://doi.org/10.21437/Interspeech.2018-65", 5, "interspeech", 2018]], "Noor Fathima": [0, ["TDNN-based Multilingual Speech Recognition System for Low Resource Indian Languages", ["Noor Fathima", "Tanvina Patel", "Mahima C", "Anuroop Iyengar"], "https://doi.org/10.21437/Interspeech.2018-2117", 5, "interspeech", 2018]], "Okko Rasanen": [0, ["Comparison of Syllabification Algorithms and Training Strategies for Robust Word Count Estimation across Different Languages and Recording Conditions", ["Okko Rasanen", "Shreyas Seshadri", "Marisa Casillas"], "https://doi.org/10.21437/Interspeech.2018-1047", 5, "interspeech", 2018]], "Girija Ramesan Karthik": [0, ["Subband Weighting for Binaural Speech Source Localization", ["Girija Ramesan Karthik", "Parth Suresh", "Prasanta Kumar Ghosh"], "https://doi.org/10.21437/Interspeech.2018-2173", 5, "interspeech", 2018]], "Gayathri G": [0, ["Mobile Application for Learning Languages for the Unlettered", ["Gayathri G", "N. Mohana", "Radhika Pal", "Hema A. Murthy"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3012.html", 2, "interspeech", 2018]], "Jeroen Zegers": [0, ["Memory Time Span in LSTMs for Multi-Speaker Source Separation", ["Jeroen Zegers", "Hugo Van hamme"], "https://doi.org/10.21437/Interspeech.2018-2082", 5, "interspeech", 2018]], "Constantinos Papayiannis": [0, ["Detecting Media Sound Presence in Acoustic Scenes", ["Constantinos Papayiannis", "Justice Amoh", "Viktor Rozgic", "Shiva Sundaram", "Chao Wang"], "https://doi.org/10.21437/Interspeech.2018-2559", 5, "interspeech", 2018]], "Jasper Ooster": [0, ["Prediction of Perceived Speech Quality Using Deep Machine Listening", ["Jasper Ooster", "Rainer Huber", "Bernd T. Meyer"], "https://doi.org/10.21437/Interspeech.2018-1374", 5, "interspeech", 2018]], "Mohammad Sadegh Rasooli": [0, ["Entity-Aware Language Model as an Unsupervised Reranker", ["Mohammad Sadegh Rasooli", "Sarangarajan Parthasarathy"], "https://doi.org/10.21437/Interspeech.2018-62", 5, "interspeech", 2018]], "Xuankai Chang": [1.0287378045779894e-12, ["Monaural Multi-Talker Speech Recognition with Attention Mechanism and Gated Convolutional Networks", ["Xuankai Chang", "Yanmin Qian", "Dong Yu"], "https://doi.org/10.21437/Interspeech.2018-1547", 5, "interspeech", 2018]], "Vincent Hughes": [0, ["The Individual and the System: Assessing the Stability of the Output of a Semi-automatic Forensic Voice Comparison System", ["Vincent Hughes", "Philip Harrison", "Paul Foulkes", "Peter French", "Colleen Kavanagh", "Eugenia San Segundo Fernandez"], "https://doi.org/10.21437/Interspeech.2018-1649", 5, "interspeech", 2018]], "Leonid Velikovich": [0, ["Semantic Lattice Processing in Contextual Automatic Speech Recognition for Google Assistant", ["Leonid Velikovich", "Ian Williams", "Justin Scheiner", "Petar S. Aleksic", "Pedro J. Moreno", "Michael Riley"], "https://doi.org/10.21437/Interspeech.2018-2453", 5, "interspeech", 2018]], "Oscar Chen": [0, ["Active Memory Networks for Language Modeling", ["Oscar Chen", "Anton Ragni", "Mark J. F. Gales", "Xie Chen"], "https://doi.org/10.21437/Interspeech.2018-78", 5, "interspeech", 2018]], "Gary Yeung": [0, ["On the Difficulties of Automatic Speech Recognition for Kindergarten-Aged Children", ["Gary Yeung", "Abeer Alwan"], "https://doi.org/10.21437/Interspeech.2018-2297", 5, "interspeech", 2018]], "Jacqueline Vaissiere": [0, ["Universal Tendencies for Cross-Linguistic Prosodic Tendencies: A Review and Some New Proposals", ["Jacqueline Vaissiere"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/4002.html", 1, "interspeech", 2018]], "Enno Hermann": [0, ["Multilingual Bottleneck Features for Subword Modeling in Zero-resource Languages", ["Enno Hermann", "Sharon Goldwater"], "https://doi.org/10.21437/Interspeech.2018-2334", 5, "interspeech", 2018]], "Chitralekha Gupta": [0, ["Automatic Pronunciation Evaluation of Singing", ["Chitralekha Gupta", "Haizhou Li", "Ye Wang"], "https://doi.org/10.21437/Interspeech.2018-1267", 5, "interspeech", 2018]], "Zhen Qin": [0, ["Long Distance Voice Channel Diagnosis Using Deep Neural Networks", ["Zhen Qin", "Tom Ko", "Guangjian Tian"], "https://doi.org/10.21437/Interspeech.2018-1428", 4, "interspeech", 2018]], "Seyed Omid Sadjadi": [0, ["Performance Analysis of the 2017 NIST Language Recognition Evaluation", ["Seyed Omid Sadjadi", "Timothee Kheyrkhah", "Craig S. Greenberg", "Elliot Singer", "Douglas A. Reynolds", "Lisa P. Mason", "Jaime Hernandez-Cordero"], "https://doi.org/10.21437/Interspeech.2018-69", 5, "interspeech", 2018]], "Anton Ragni": [0, ["Automatic Speech Recognition System Development in the \"Wild\"", ["Anton Ragni", "Mark J. F. Gales"], "https://doi.org/10.21437/Interspeech.2018-1085", 5, "interspeech", 2018]], "Srikanth R. Madikeri": [0, ["Analysis of Language Dependent Front-End for Speaker Recognition", ["Srikanth R. Madikeri", "Subhadeep Dey", "Petr Motlicek"], "https://doi.org/10.21437/Interspeech.2018-2071", 5, "interspeech", 2018]], "Jeng-Lin Li": [0, ["Encoding Individual Acoustic Features Using Dyad-Augmented Deep Variational Representations for Dialog-level Emotion Recognition", ["Jeng-Lin Li", "Chi-Chun Lee"], "https://doi.org/10.21437/Interspeech.2018-1455", 5, "interspeech", 2018], ["Learning Conditional Acoustic Latent Representation with Gender and Age Attributes for Automatic Pain Level Recognition", ["Jeng-Lin Li", "Yi-Ming Weng", "Chip-Jin Ng", "Chi-Chun Lee"], "https://doi.org/10.21437/Interspeech.2018-1298", 5, "interspeech", 2018]], "Chenxing Li": [0, ["Single-channel Speech Dereverberation via Generative Adversarial Training", ["Chenxing Li", "Tieqiang Wang", "Shuang Xu", "Bo Xu"], "https://doi.org/10.21437/Interspeech.2018-1234", 5, "interspeech", 2018]], "Kwanghoon An": [0.9998938739299774, ["Automatic Early Detection of Amyotrophic Lateral Sclerosis from Intelligible Speech Using Convolutional Neural Networks", ["Kwanghoon An", "Myung Jong Kim", "Kristin Teplansky", "Jordan R. Green", "Thomas Campbell", "Yana Yunusova", "Daragh Heitzman", "Jun Wang"], "https://doi.org/10.21437/Interspeech.2018-2496", 5, "interspeech", 2018]], "Hieu-Thi Luong": [0, ["Investigating Accuracy of Pitch-accent Annotations in Neural Network-based Speech Synthesis and Denoising Effects", ["Hieu-Thi Luong", "Xin Wang", "Junichi Yamagishi", "Nobuyuki Nishizawa"], "https://doi.org/10.21437/Interspeech.2018-1227", 5, "interspeech", 2018], ["Multimodal Speech Synthesis Architecture for Unsupervised Speaker Adaptation", ["Hieu-Thi Luong", "Junichi Yamagishi"], "https://doi.org/10.21437/Interspeech.2018-1791", 5, "interspeech", 2018]], "Lixia Hao": [0, ["A Preliminary Study on Tonal Coarticulation in Continuous Speech", ["Lixia Hao", "Wei Zhang", "Yanlu Xie", "Jinsong Zhang"], "https://doi.org/10.21437/Interspeech.2018-1849", 5, "interspeech", 2018]], "Bogdan Vlasenko": [0, ["Implementing Fusion Techniques for the Classification of Paralinguistic Information", ["Bogdan Vlasenko", "Jilt Sebastian", "Pavan Kumar D. S.", "Mathew Magimai-Doss"], "https://doi.org/10.21437/Interspeech.2018-2360", 5, "interspeech", 2018]], "Mark Huckvale": [0, ["Neural Network Architecture That Combines Temporal and Summative Features for Infant Cry Classification in the Interspeech 2018 Computational Paralinguistics Challenge", ["Mark Huckvale"], "https://doi.org/10.21437/Interspeech.2018-1959", 5, "interspeech", 2018]], "Rongfeng Su": [0, ["Semi-supervised Cross-domain Visual Feature Learning for Audio-Visual Broadcast Speech Transcription", ["Rongfeng Su", "Xunying Liu", "Lan Wang"], "https://doi.org/10.21437/Interspeech.2018-1063", 5, "interspeech", 2018]], "Tomohiro Tanaka": [0, ["Neural Error Corrective Language Models for Automatic Speech Recognition", ["Tomohiro Tanaka", "Ryo Masumura", "Hirokazu Masataki", "Yushi Aono"], "https://doi.org/10.21437/Interspeech.2018-1430", 5, "interspeech", 2018]], "Nassima Fezza": [0, ["The Role of Temporal Variation in Narrative Organization", ["Nassima Fezza"], "https://doi.org/10.21437/Interspeech.2018-1725", 5, "interspeech", 2018]], "Anna Silnova": [0, ["Fast Variational Bayes for Heavy-tailed PLDA Applied to i-vectors and x-vectors", ["Anna Silnova", "Niko Brummer", "Daniel Garcia-Romero", "David Snyder", "Lukas Burget"], "https://doi.org/10.21437/Interspeech.2018-2128", 5, "interspeech", 2018]], "Mauro Nicolao": [0, ["Improved Acoustic Modelling for Automatic Literacy Assessment of Children", ["Mauro Nicolao", "Michiel Sanders", "Thomas Hain"], "https://doi.org/10.21437/Interspeech.2018-2118", 5, "interspeech", 2018]], "Zhihua Su": [0, ["Tongue Segmentation with Geometrically Constrained Snake Model", ["Zhihua Su", "Jianguo Wei", "Qiang Fang", "Jianrong Wang", "Kiyoshi Honda"], "https://doi.org/10.21437/Interspeech.2018-1108", 5, "interspeech", 2018]], "Wenjie Li": [0, ["Investigation on the Combination of Batch Normalization and Dropout in BLSTM-based Acoustic Modeling for ASR", ["Wenjie Li", "Gaofeng Cheng", "Fengpei Ge", "Pengyuan Zhang", "Yonghong Yan"], "https://doi.org/10.21437/Interspeech.2018-1597", 5, "interspeech", 2018]], "Zhongxin Bai": [1.279472527926373e-08, ["Cosine Metric Learning for Speaker Verification in the I-vector Space", ["Zhongxin Bai", "Xiao-Lei Zhang", "Jingdong Chen"], "https://doi.org/10.21437/Interspeech.2018-1593", 5, "interspeech", 2018]], "Joun Yeop Lee": [0.9999985694885254, ["Acoustic Modeling Using Adversarially Trained Variational Recurrent Neural Network for Speech Synthesis", ["Joun Yeop Lee", "Sung Jun Cheon", "Byoung Jin Choi", "Nam Soo Kim", "Eunwoo Song"], "https://doi.org/10.21437/Interspeech.2018-1598", 5, "interspeech", 2018]], "Hakan Erdogan": [0, ["Investigations on Data Augmentation and Loss Functions for Deep Learning Based Speech-Background Separation", ["Hakan Erdogan", "Takuya Yoshioka"], "https://doi.org/10.21437/Interspeech.2018-2441", 5, "interspeech", 2018]], "Youhyun Shin": [0.979451596736908, ["Slot Filling with Delexicalized Sentence Generation", ["Youhyun Shin", "Kang Min Yoo", "Sang-goo Lee"], "https://doi.org/10.21437/Interspeech.2018-1808", 5, "interspeech", 2018]], "Xixin Wu": [1.2604690624584691e-08, ["Rapid Style Adaptation Using Residual Error Embedding for Expressive Speech Synthesis", ["Xixin Wu", "Yuewen Cao", "Mu Wang", "Songxiang Liu", "Shiyin Kang", "Zhiyong Wu", "Xunying Liu", "Dan Su", "Dong Yu", "Helen Meng"], "https://doi.org/10.21437/Interspeech.2018-1991", 5, "interspeech", 2018]], "Ke Wang": [0.00021147707593627274, ["Investigating Generative Adversarial Networks Based Speech Dereverberation for Robust Speech Recognition", ["Ke Wang", "Junbo Zhang", "Sining Sun", "Yujun Wang", "Fei Xiang", "Lei Xie"], "https://doi.org/10.21437/Interspeech.2018-1780", 5, "interspeech", 2018], ["Empirical Evaluation of Speaker Adaptation on DNN Based Acoustic Model", ["Ke Wang", "Junbo Zhang", "Yujun Wang", "Lei Xie"], "https://doi.org/10.21437/Interspeech.2018-1897", 5, "interspeech", 2018]], "Lu Yin": [0, ["Multi-talker Speech Separation Based on Permutation Invariant Training and Beamforming", ["Lu Yin", "Ziteng Wang", "Risheng Xia", "Junfeng Li", "Yonghong Yan"], "https://doi.org/10.21437/Interspeech.2018-1739", 5, "interspeech", 2018]], "Ankit Raj": [0, ["Leveraging Second-Order Log-Linear Model for Improved Deep Learning Based ASR Performance", ["Ankit Raj", "Shakti P. Rath", "Jithendra Vepa"], "https://doi.org/10.21437/Interspeech.2018-1156", 5, "interspeech", 2018]], "Konstantinos Kyriakopoulos": [0, ["A Deep Learning Approach to Assessing Non-native Pronunciation of English Using Phone Distances", ["Konstantinos Kyriakopoulos", "Kate Knill", "Mark J. F. Gales"], "https://doi.org/10.21437/Interspeech.2018-1087", 5, "interspeech", 2018]], "Lorenz Diener": [0, ["Investigating Objective Intelligibility in Real-Time EMG-to-Speech Conversion", ["Lorenz Diener", "Tanja Schultz"], "https://doi.org/10.21437/Interspeech.2018-2080", 5, "interspeech", 2018]], "Daniel Povey": [0, ["Semi-Orthogonal Low-Rank Matrix Factorization for Deep Neural Networks", ["Daniel Povey", "Gaofeng Cheng", "Yiming Wang", "Ke Li", "Hainan Xu", "Mahsa Yarmohammadi", "Sanjeev Khudanpur"], "https://doi.org/10.21437/Interspeech.2018-1417", 5, "interspeech", 2018]], "Tiina Murtola": [0, ["Interaction Mechanisms between Glottal Source and Vocal Tract in Pitch Glides", ["Tiina Murtola", "Jarmo Malinen"], "https://doi.org/10.21437/Interspeech.2018-1827", 5, "interspeech", 2018]], "Alessandra Cervone": [0, ["Coherence Models for Dialogue", ["Alessandra Cervone", "Evgeny A. Stepanov", "Giuseppe Riccardi"], "https://doi.org/10.21437/Interspeech.2018-2446", 5, "interspeech", 2018]], "Jinyu Li": [0, ["Layer Trajectory LSTM", ["Jinyu Li", "Changliang Liu", "Yifan Gong"], "https://doi.org/10.21437/Interspeech.2018-1485", 5, "interspeech", 2018]], "Yulun Du": [0, ["Multimodal Polynomial Fusion for Detecting Driver Distraction", ["Yulun Du", "Alan W. Black", "Louis-Philippe Morency", "Maxine Eskenazi"], "https://doi.org/10.21437/Interspeech.2018-2011", 5, "interspeech", 2018]], "Heewoong Park": [0.9999277591705322, ["Training Utterance-level Embedding Networks for Speaker Identification and Verification", ["Heewoong Park", "Sukhyun Cho", "Kyubyong Park", "Namju Kim", "Jonghun Park"], "https://doi.org/10.21437/Interspeech.2018-1044", 5, "interspeech", 2018]], "Joao Freitas": [0, ["Machine Learning Powered Data Platform for High-Quality Speech and NLP Workflows", ["Joao Freitas", "Jorge Ribeiro", "Daan Baldewijns", "Sara Oliveira", "Daniela Braga"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3033.html", 2, "interspeech", 2018]], "Olympia Simantiraki": [0, ["Impact of Different Speech Types on Listening Effort", ["Olympia Simantiraki", "Martin Cooke", "Simon King"], "https://doi.org/10.21437/Interspeech.2018-1358", 5, "interspeech", 2018]], "Dieter Maurer": [0, ["The Zurich Corpus of Vowel and Voice Quality, Version 1.0", ["Dieter Maurer", "Christian dHeureuse", "Heidy Suter", "Volker Dellwo", "Daniel Friedrichs", "Thayabaran Kathiresan"], "https://doi.org/10.21437/Interspeech.2018-1542", 5, "interspeech", 2018]], "Zhong-Qiu Wang": [1.0870333767235701e-12, ["Robust TDOA Estimation Based on Time-Frequency Masking and Deep Neural Networks", ["Zhong-Qiu Wang", "Xueliang Zhang", "DeLiang Wang"], "https://doi.org/10.21437/Interspeech.2018-1652", 5, "interspeech", 2018], ["End-to-End Speech Separation with Unfolded Iterative Phase Reconstruction", ["Zhong-Qiu Wang", "Jonathan Le Roux", "DeLiang Wang", "John R. Hershey"], "https://doi.org/10.21437/Interspeech.2018-1629", 5, "interspeech", 2018], ["Integrating Spectral and Spatial Features for Multi-Channel Speaker Separation", ["Zhong-Qiu Wang", "DeLiang Wang"], "https://doi.org/10.21437/Interspeech.2018-1940", 5, "interspeech", 2018], ["All-Neural Multi-Channel Speech Enhancement", ["Zhong-Qiu Wang", "DeLiang Wang"], "https://doi.org/10.21437/Interspeech.2018-1664", 5, "interspeech", 2018]], "Martin Karafiat": [0, ["BUT OpenSAT 2017 Speech Recognition System", ["Martin Karafiat", "Murali Karthick Baskar", "Igor Szoke", "Vladimir Malenovsky", "Karel Vesely", "Frantisek Grezl", "Lukas Burget", "Jan Cernocky"], "https://doi.org/10.21437/Interspeech.2018-2457", 5, "interspeech", 2018]], "Jilt Sebastian": [0, ["Denoising and Raw-waveform Networks for Weakly-Supervised Gender Identification on Noisy Speech", ["Jilt Sebastian", "Manoj Kumar", "Pavan Kumar D. S.", "Mathew Magimai-Doss", "Hema A. Murthy", "Shrikanth Narayanan"], "https://doi.org/10.21437/Interspeech.2018-2321", 5, "interspeech", 2018]], "Wei Xia": [0, ["Speaker Recognition with Nonlinear Distortion: Clipping Analysis and Impact", ["Wei Xia", "John H. L. Hansen"], "https://doi.org/10.21437/Interspeech.2018-2430", 5, "interspeech", 2018]], "Manoj Kumar": [0, ["A Knowledge Driven Structural Segmentation Approach for Play-Talk Classification During Autism Assessment", ["Manoj Kumar", "Pooja Chebolu", "So Hyun Kim", "Kassandra Martinez", "Catherine Lord", "Shrikanth Narayanan"], "https://doi.org/10.21437/Interspeech.2018-1516", 5, "interspeech", 2018]], "G. R. Kasthuri": [0, ["Early Vocabulary Development Through Picture-based Software Solutions", ["G. R. Kasthuri", "Prabha Ramanathan", "Hema A. Murthy", "Namita Jacob", "Anil Prabhakar"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3022.html", 2, "interspeech", 2018]], "Sudarsana Reddy Kadiri": [0, ["Breathy to Tense Voice Discrimination using Zero-Time Windowing Cepstral Coefficients (ZTWCCs)", ["Sudarsana Reddy Kadiri", "Bayya Yegnanarayana"], "https://doi.org/10.21437/Interspeech.2018-2498", 5, "interspeech", 2018], ["Analysis and Detection of Phonation Modes in Singing Voice using Excitation Source Features and Single Frequency Filtering Cepstral Coefficients (SFFCC)", ["Sudarsana Reddy Kadiri", "Bayya Yegnanarayana"], "https://doi.org/10.21437/Interspeech.2018-2502", 5, "interspeech", 2018], ["Estimation of Fundamental Frequency from Singing Voice Using Harmonics of Impulse-like Excitation Source", ["Sudarsana Reddy Kadiri", "Bayya Yegnanarayana"], "https://doi.org/10.21437/Interspeech.2018-2495", 5, "interspeech", 2018]], "Jie Li": [0, ["Gated Recurrent Unit Based Acoustic Modeling with Future Context", ["Jie Li", "Xiaorui Wang", "Yuanyuan Zhao", "Yan Li"], "https://doi.org/10.21437/Interspeech.2018-1544", 5, "interspeech", 2018]], "Nam Le": [0, ["Robust and Discriminative Speaker Embedding via Intra-Class Distance Variance Regularization", ["Nam Le", "Jean-Marc Odobez"], "https://doi.org/10.21437/Interspeech.2018-1685", 5, "interspeech", 2018]], "Bhavik Vachhani": [0, ["Data Augmentation Using Healthy Speech for Dysarthric Speech Recognition", ["Bhavik Vachhani", "Chitralekha Bhat", "Sunil Kumar Kopparapu"], "https://doi.org/10.21437/Interspeech.2018-1751", 5, "interspeech", 2018]], "Jennifer Sloboda": [0, ["Vocal Biomarkers for Cognitive Performance Estimation in a Working Memory Task", ["Jennifer Sloboda", "Adam C. Lammert", "James R. Williamson", "Christopher J. Smalt", "Daryush D. Mehta", "C. O. L. Ian Curry", "Kristin Heaton", "Jeff Palmer", "Thomas F. Quatieri"], "https://doi.org/10.21437/Interspeech.2018-2418", 5, "interspeech", 2018]], "Loren Lugosch": [0, ["Tone Recognition Using Lifters and CTC", ["Loren Lugosch", "Vikrant Singh Tomar"], "https://doi.org/10.21437/Interspeech.2018-2293", 5, "interspeech", 2018]], "Volker Dellwo": [0, ["Influences of Fundamental Oscillation on Speaker Identification in Vocalic Utterances by Humans and Computers", ["Volker Dellwo", "Thayabaran Kathiresan", "Elisa Pellegrino", "Lei He", "Sandra Schwab", "Dieter Maurer"], "https://doi.org/10.21437/Interspeech.2018-2331", 5, "interspeech", 2018]], "Harishchandra Dubey": [0, ["Robust Speaker Clustering using Mixtures of von Mises-Fisher Distributions for Naturalistic Audio Streams", ["Harishchandra Dubey", "Abhijeet Sangwan", "John H. L. Hansen"], "https://doi.org/10.21437/Interspeech.2018-50", 5, "interspeech", 2018]], "Aravind Illa": [0, ["Low Resource Acoustic-to-articulatory Inversion Using Bi-directional Long Short Term Memory", ["Aravind Illa", "Prasanta Kumar Ghosh"], "https://doi.org/10.21437/Interspeech.2018-1843", 5, "interspeech", 2018]], "Keisuke Tanihara": [0, ["Implementation of Respiration in Articulatory Synthesis Using a Pressure-Volume Lung Model", ["Keisuke Tanihara", "Shogo Yonekura", "Yasuo Kuniyoshi"], "https://doi.org/10.21437/Interspeech.2018-1080", 5, "interspeech", 2018]], "Lukas Mateju": [0, ["Using Deep Neural Networks for Identification of Slavic Languages from Acoustic Signal", ["Lukas Mateju", "Petr Cerva", "Jindrich Zdansky", "Radek Safarik"], "https://doi.org/10.21437/Interspeech.2018-1165", 5, "interspeech", 2018]], "Yike Zhang": [0, ["Improving Language Modeling with an Adversarial Critic for Automatic Speech Recognition", ["Yike Zhang", "Pengyuan Zhang", "Yonghong Yan"], "https://doi.org/10.21437/Interspeech.2018-1111", 5, "interspeech", 2018]], "Haoran Wu": [0.02372580673545599, ["Analyzing Effect of Physical Expression on English Proficiency for Multimodal Computer-Assisted Language Learning", ["Haoran Wu", "Yuya Chiba", "Takashi Nose", "Akinori Ito"], "https://doi.org/10.21437/Interspeech.2018-1425", 5, "interspeech", 2018]], "Jiahong Yuan": [0, ["Pitch Characteristics of L2 English Speech by Chinese Speakers: A Large-scale Study", ["Jiahong Yuan", "Qiusi Dong", "Fei Wu", "Huan Luan", "Xiaofei Yang", "Hui Lin", "Yang Liu"], "https://doi.org/10.21437/Interspeech.2018-1556", 5, "interspeech", 2018]], "Yujia Xiao": [0, ["Paired Phone-Posteriors Approach to ESL Pronunciation Quality Assessment", ["Yujia Xiao", "Frank K. Soong", "Wenping Hu"], "https://doi.org/10.21437/Interspeech.2018-1270", 5, "interspeech", 2018]], "Francis Tom": [0, ["End-To-End Audio Replay Attack Detection Using Deep Convolutional Networks with Attention", ["Francis Tom", "Mohit Jain", "Prasenjit Dey"], "https://doi.org/10.21437/Interspeech.2018-2279", 5, "interspeech", 2018]], "Takayuki Arai": [0, ["Flexible Tongue Housed in a Static Model of the Vocal Tract With Jaws, Lips and Teeth", ["Takayuki Arai"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3004.html", 2, "interspeech", 2018]], "Raphael Cohen": [0, ["Fully Automatic Speaker Separation System, with Automatic Enrolling of Recurrent Speakers", ["Raphael Cohen", "Orgad Keller", "Jason Levy", "Russell Levy", "Micha Breakstone", "Amit Ashkenazi"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3034.html", 2, "interspeech", 2018]], "Mengzhe Chen": [0, ["Compact Feedforward Sequential Memory Networks for Small-footprint Keyword Spotting", ["Mengzhe Chen", "Shiliang Zhang", "Ming Lei", "Yong Liu", "Haitao Yao", "Jie Gao"], "https://doi.org/10.21437/Interspeech.2018-1204", 5, "interspeech", 2018]], "Antonios Anastasopoulos": [0, ["Leveraging Translations for Speech Transcription in Low-resource Settings", ["Antonios Anastasopoulos", "David Chiang"], "https://doi.org/10.21437/Interspeech.2018-2162", 5, "interspeech", 2018]], "Anjuli Kannan": [0, ["Semi-supervised Learning for Information Extraction from Dialogue", ["Anjuli Kannan", "Kai Chen", "Diana Jaunzeikare", "Alvin Rajkomar"], "https://doi.org/10.21437/Interspeech.2018-1318", 5, "interspeech", 2018]], "Cuiling Zhang": [0, ["Acoustic Analysis of Whispery Voice Disguise in Mandarin Chinese", ["Cuiling Zhang", "Bin Li", "Si Chen", "Yike Yang"], "https://doi.org/10.21437/Interspeech.2018-2598", 4, "interspeech", 2018]], "Dengke Tang": [0, ["An End-to-End Deep Learning Framework for Speech Emotion Recognition of Atypical Individuals", ["Dengke Tang", "Junlin Zeng", "Ming Li"], "https://doi.org/10.21437/Interspeech.2018-2581", 5, "interspeech", 2018]], "Linhao Dong": [2.5628809453337453e-05, ["Extending Recurrent Neural Aligner for Streaming End-to-End Speech Recognition in Mandarin", ["Linhao Dong", "Shiyu Zhou", "Wei Chen", "Bo Xu"], "https://doi.org/10.21437/Interspeech.2018-1086", 5, "interspeech", 2018]], "Soo Jin Park": [0.9360999912023544, ["Using Voice Quality Supervectors for Affect Identification", ["Soo Jin Park", "Amber Afshan", "Zhi Ming Chua", "Abeer Alwan"], "https://doi.org/10.21437/Interspeech.2018-1401", 5, "interspeech", 2018]], "Yixin Zhang": [0, ["Emotional Prosody Perception in Mandarin-speaking Congenital Amusics", ["Yixin Zhang", "Tianzhu Geng", "Jinsong Zhang"], "https://doi.org/10.21437/Interspeech.2018-91", 5, "interspeech", 2018]], "Midia Yousefi": [0, ["Assessing Speaker Engagement in 2-Person Debates: Overlap Detection in United States Presidential Debates", ["Midia Yousefi", "Navid Shokouhi", "John H. L. Hansen"], "https://doi.org/10.21437/Interspeech.2018-1463", 5, "interspeech", 2018]], "Peixin Chen": [0, ["Gated Convolutional Neural Network for Sentence Matching", ["Peixin Chen", "Wu Guo", "Zhi Chen", "Jian Sun", "Lanhua You"], "https://doi.org/10.21437/Interspeech.2018-70", 5, "interspeech", 2018]], "Ishwar Chandra Yadav": [0, ["Non-Uniform Spectral Smoothing for Robust Children's Speech Recognition", ["Ishwar Chandra Yadav", "Avinash Kumar", "Syed Shahnawazuddin", "Gayadhar Pradhan"], "https://doi.org/10.21437/Interspeech.2018-1828", 5, "interspeech", 2018]], "Marc Antony Hullebus": [0, ["Speaker-specific Structure in German Voiceless Stop Voice Onset Times", ["Marc Antony Hullebus", "Stephen J. Tobin", "Adamantios I. Gafos"], "https://doi.org/10.21437/Interspeech.2018-2288", 5, "interspeech", 2018]], "Ying Qin": [0, ["Automatic Speech Assessment for People with Aphasia Using TDNN-BLSTM with Multi-Task Learning", ["Ying Qin", "Tan Lee", "Siyuan Feng", "Anthony Pak-Hin Kong"], "https://doi.org/10.21437/Interspeech.2018-1630", 5, "interspeech", 2018]], "Nikhil Mohanan": [0, ["A Non-convolutive NMF Model for Speech Dereverberation", ["Nikhil Mohanan", "Rajbabu Velmurugan", "Preeti Rao"], "https://doi.org/10.21437/Interspeech.2018-1834", 5, "interspeech", 2018]], "Brij Mohan Lal Srivastava": [0, ["Homophone Identification and Merging for Code-switched Speech Recognition", ["Brij Mohan Lal Srivastava", "Sunayana Sitaram"], "https://doi.org/10.21437/Interspeech.2018-1171", 5, "interspeech", 2018]], "Francisco Teixeira": [0, ["Patient Privacy in Paralinguistic Tasks", ["Francisco Teixeira", "Alberto Abad", "Isabel Trancoso"], "https://doi.org/10.21437/Interspeech.2018-2186", 5, "interspeech", 2018]], "Savitha Murthy": [0, ["Effect of TTS Generated Audio on OOV Detection and Word Error Rate in ASR for Low-resource Languages", ["Savitha Murthy", "Dinkar Sitaram", "Sunayana Sitaram"], "https://doi.org/10.21437/Interspeech.2018-1555", 5, "interspeech", 2018]], "Yilin Shen": [0, ["User Information Augmented Semantic Frame Parsing Using Progressive Neural Networks", ["Yilin Shen", "Xiangyu Zeng", "Yu Wang", "Hongxia Jin"], "https://doi.org/10.21437/Interspeech.2018-1149", 5, "interspeech", 2018]], "Bjorn W. Schuller": [0, ["The INTERSPEECH 2018 Computational Paralinguistics Challenge: Atypical & Self-Assessed Affect, Crying & Heart Beats", ["Bjorn W. Schuller", "Stefan Steidl", "Anton Batliner", "Peter B. Marschik", "Harald Baumeister", "Fengquan Dong", "Simone Hantke", "Florian B. Pokorny", "Eva-Maria Rathner", "Katrin D. Bartl-Pokorny", "Christa Einspieler", "Dajie Zhang", "Alice Baird", "Shahin Amiriparian", "Kun Qian", "Zhao Ren", "Maximilian Schmitt", "Panagiotis Tzirakis", "Stefanos Zafeiriou"], "https://doi.org/10.21437/Interspeech.2018-51", 5, "interspeech", 2018]], "Jan Niehues": [0, ["Low-Latency Neural Speech Translation", ["Jan Niehues", "Ngoc-Quan Pham", "Thanh-Le Ha", "Matthias Sperber", "Alex Waibel"], "https://doi.org/10.21437/Interspeech.2018-1055", 5, "interspeech", 2018]], "Sibo Tong": [0, ["Fast Language Adaptation Using Phonological Information", ["Sibo Tong", "Philip N. Garner", "Herve Bourlard"], "https://doi.org/10.21437/Interspeech.2018-1990", 5, "interspeech", 2018]], "Ehsan Hosseini-Asl": [0, ["A Multi-Discriminator CycleGAN for Unsupervised Non-Parallel Speech Domain Adaptation", ["Ehsan Hosseini-Asl", "Yingbo Zhou", "Caiming Xiong", "Richard Socher"], "https://doi.org/10.21437/Interspeech.2018-1535", 5, "interspeech", 2018]], "Che-Wei Huang": [0, ["Stochastic Shake-Shake Regularization for Affective Learning from Speech", ["Che-Wei Huang", "Shrikanth Narayanan"], "https://doi.org/10.21437/Interspeech.2018-1327", 5, "interspeech", 2018]], "Emre Yilmaz": [0, ["Building a Unified Code-Switching ASR System for South African Languages", ["Emre Yilmaz", "Astik Biswas", "Ewald van der Westhuizen", "Febe de Wet", "Thomas Niesler"], "https://doi.org/10.21437/Interspeech.2018-1966", 5, "interspeech", 2018], ["Acoustic and Textual Data Augmentation for Improved ASR of Code-Switching Speech", ["Emre Yilmaz", "Henk van den Heuvel", "David A. van Leeuwen"], "https://doi.org/10.21437/Interspeech.2018-52", 5, "interspeech", 2018], ["Articulatory Features for ASR of Pathological Speech", ["Emre Yilmaz", "Vikramjit Mitra", "Chris Bartels", "Horacio Franco"], "https://doi.org/10.21437/Interspeech.2018-67", 5, "interspeech", 2018]], "Chih Chi Hu": [0, ["Online Incremental Learning for Speaker-Adaptive Language Models", ["Chih Chi Hu", "Bing Liu", "John Shen", "Ian Lane"], "https://doi.org/10.21437/Interspeech.2018-2259", 5, "interspeech", 2018]], "Madhab Pal": [0, ["PannoMulloKathan: Voice Enabled Mobile App for Agricultural Commodity Price Dissemination in Bengali Language", ["Madhab Pal", "Rajib Roy", "Soma Khan", "Milton Samirakshma Bepari", "Joyanta Basu"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3027.html", 2, "interspeech", 2018]], "Umesh Sachdev": [0, ["auMina\u2122 - Enterprise Speech Analytics", ["Umesh Sachdev", "Rajagopal Jayaraman", "Zainab Millwala"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3016.html", 2, "interspeech", 2018], ["akeira\u2122 - Virtual Assistant", ["Umesh Sachdev", "Rajagopal Jayaraman", "Zainab Millwala"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3018.html", 2, "interspeech", 2018]], "Shoufeng Lin": [0, ["A New Frequency Coverage Metric and a New Subband Encoding Model, with an Application in Pitch Estimation", ["Shoufeng Lin"], "https://doi.org/10.21437/Interspeech.2018-2590", 5, "interspeech", 2018]], "Suliang Bu": [0, ["A Probability Weighted Beamformer for Noise Robust ASR", ["Suliang Bu", "Yunxin Zhao", "Mei-Yuh Hwang", "Sining Sun"], "https://doi.org/10.21437/Interspeech.2018-2427", 5, "interspeech", 2018]], "Chao Zhang": [0, ["Semi-tied Units for Efficient Gating in LSTM and Highway Networks", ["Chao Zhang", "Philip C. Woodland"], "https://doi.org/10.21437/Interspeech.2018-2158", 5, "interspeech", 2018]], "Odette Scharenborg": [0, ["Visualizing Phoneme Category Adaptation in Deep Neural Networks", ["Odette Scharenborg", "Sebastian Tiesmeyer", "Mark Hasegawa-Johnson", "Najim Dehak"], "https://doi.org/10.21437/Interspeech.2018-1707", 5, "interspeech", 2018], ["The Conversation Continues: the Effect of Lyrics and Music Complexity of Background Music on Spoken-Word Recognition", ["Odette Scharenborg", "Martha Larson"], "https://doi.org/10.21437/Interspeech.2018-1088", 5, "interspeech", 2018]], "Longfei Yang": [5.717766364543575e-11, ["Improving Mandarin Tone Recognition Using Convolutional Bidirectional Long Short-Term Memory with Attention", ["Longfei Yang", "Yanlu Xie", "Jinsong Zhang"], "https://doi.org/10.21437/Interspeech.2018-2561", 5, "interspeech", 2018]], "M. Joana Correia": [0, ["Mining Multimodal Repositories for Speech Affecting Diseases", ["M. Joana Correia", "Bhiksha Raj", "Isabel Trancoso", "Francisco Teixeira"], "https://doi.org/10.21437/Interspeech.2018-1806", 5, "interspeech", 2018]], "Lani Mathew": [0, ["Voice Analysis Using Acoustic and Throat Microphones for Speech Therapy", ["Lani Mathew", "K. Gopakumar"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3005.html", 2, "interspeech", 2018]], "Claudia Baur": [0, ["Overview of the 2018 Spoken CALL Shared Task", ["Claudia Baur", "Andrew Caines", "Cathy Chua", "Johanna Gerlach", "Mengjie Qian", "Manny Rayner", "Martin J. Russell", "Helmer Strik", "Xizi Wei"], "https://doi.org/10.21437/Interspeech.2018-97", 5, "interspeech", 2018]], "Karel Benes": [0, ["i-Vectors in Language Modeling: An Efficient Way of Domain Adaptation for Feed-Forward Models", ["Karel Benes", "Santosh Kesiraju", "Lukas Burget"], "https://doi.org/10.21437/Interspeech.2018-1070", 5, "interspeech", 2018]], "Changhao Shan": [0, ["Attention-based End-to-End Models for Small-Footprint Keyword Spotting", ["Changhao Shan", "Junbo Zhang", "Yujun Wang", "Lei Xie"], "https://doi.org/10.21437/Interspeech.2018-1777", 5, "interspeech", 2018]], "Padmasundari": [0, ["Intent Discovery Through Unsupervised Semantic Text Clustering", ["Padmasundari", "Srinivas Bangalore"], "https://doi.org/10.21437/Interspeech.2018-2436", 5, "interspeech", 2018]], "Yasin Ozkanca": [0, ["Multi-Lingual Depression-Level Assessment from Conversational Speech Using Acoustic and Text Features", ["Yasin Ozkanca", "Cenk Demiroglu", "Asli Besirli", "Selime Celik"], "https://doi.org/10.21437/Interspeech.2018-2169", 5, "interspeech", 2018]], "Berrak Sisman": [0, ["Wavelet Analysis of Speaker Dependent and Independent Prosody for Voice Conversion", ["Berrak Sisman", "Haizhou Li"], "https://doi.org/10.21437/Interspeech.2018-1499", 5, "interspeech", 2018], ["A Voice Conversion Framework with Tandem Feature Sparse Representation and Speaker-Adapted WaveNet Vocoder", ["Berrak Sisman", "Mingyang Zhang", "Haizhou Li"], "https://doi.org/10.21437/Interspeech.2018-1131", 5, "interspeech", 2018]], "Kate Earnshaw": [0, ["Variation in the FACE Vowel across West Yorkshire: Implications for Forensic Speaker Comparisons", ["Kate Earnshaw", "Erica Gold"], "https://doi.org/10.21437/Interspeech.2018-1944", 5, "interspeech", 2018]], "John S. Novak III": [0, ["Effects of User Controlled Speech Rate on Intelligibility in Noisy Environments", ["John S. Novak III", "Robert V. Kenyon"], "https://doi.org/10.21437/Interspeech.2018-63", 5, "interspeech", 2018]], "Katsuhiko Yamamoto": [0, ["Multi-resolution Gammachirp Envelope Distortion Index for Intelligibility Prediction of Noisy Speech", ["Katsuhiko Yamamoto", "Toshio Irino", "Narumi Ohashi", "Shoko Araki", "Keisuke Kinoshita", "Tomohiro Nakatani"], "https://doi.org/10.21437/Interspeech.2018-1291", 5, "interspeech", 2018]], "Yibin Zheng": [0, ["BLSTM-CRF Based End-to-End Prosodic Boundary Prediction with Context Sensitive Embeddings in a Text-to-Speech Front-End", ["Yibin Zheng", "Jianhua Tao", "Zhengqi Wen", "Ya Li"], "https://doi.org/10.21437/Interspeech.2018-1472", 5, "interspeech", 2018], ["On the Application and Compression of Deep Time Delay Neural Network for Embedded Statistical Parametric Speech Synthesis", ["Yibin Zheng", "Jianhua Tao", "Zhengqi Wen", "Ruibo Fu"], "https://doi.org/10.21437/Interspeech.2018-1970", 5, "interspeech", 2018]], "Yangyang Xia": [0, ["A Priori SNR Estimation Based on a Recurrent Neural Network for Robust Speech Enhancement", ["Yangyang Xia", "Richard Stern"], "https://doi.org/10.21437/Interspeech.2018-2423", 5, "interspeech", 2018]], "Hossein Hadian": [0, ["End-to-end Speech Recognition Using Lattice-free MMI", ["Hossein Hadian", "Hossein Sameti", "Daniel Povey", "Sanjeev Khudanpur"], "https://doi.org/10.21437/Interspeech.2018-1423", 5, "interspeech", 2018]], "James R. Williamson": [0, ["The Effect of Exposure to High Altitude and Heat on Speech Articulatory Coordination", ["James R. Williamson", "Thomas F. Quatieri", "Adam C. Lammert", "Katherine Mitchell", "Katherine Finkelstein", "Nicole Ekon", "Caitlin Dillon", "Robert Kenefick", "Kristin Heaton"], "https://doi.org/10.21437/Interspeech.2018-2372", 5, "interspeech", 2018]], "Evgeny Dmitriev": [0, ["LOCUST - Longitudinal Corpus and Toolset for Speaker Verification", ["Evgeny Dmitriev", "Yulia Kim", "Anastasia Matveeva", "Claude Montacie", "Yannick Boulard", "Yadviga Sinyavskaya", "Yulia Zhukova", "Adam Zarazinski", "Egor Akhanov", "Ilya I. Viksnin", "Andrei A. Shlykov", "Maria Usova"], "https://doi.org/10.21437/Interspeech.2018-2412", 5, "interspeech", 2018]], "Xuanda Chen": [0, ["The Trajectory of Voice Onset Time with Vocal Aging", ["Xuanda Chen", "Ziyu Xiong", "Jian Hu"], "https://doi.org/10.21437/Interspeech.2018-60", 5, "interspeech", 2018]], "Alexander Sorin": [0, ["The IBM Virtual Voice Creator", ["Alexander Sorin", "Slava Shechtman", "Zvi Kons", "Ron Hoory", "Shay Ben-David", "Joe Pavitt", "Shai Rozenberg", "Carmel Rabinovitz", "Tal Drory"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3011.html", 2, "interspeech", 2018]], "Adnan Haider": [0, ["Combining Natural Gradient with Hessian Free Methods for Sequence Training", ["Adnan Haider", "Philip C. Woodland"], "https://doi.org/10.21437/Interspeech.2018-2335", 5, "interspeech", 2018]], "Yun-Shao Lin": [0, ["An Interlocutor-Modulated Attentional LSTM for Differentiating between Subgroups of Autism Spectrum Disorder", ["Yun-Shao Lin", "Susan Shur-Fen Gau", "Chi-Chun Lee"], "https://doi.org/10.21437/Interspeech.2018-1288", 5, "interspeech", 2018]], "Herve Bourlard": [0, ["Evolution of Neural Network Architectures for Speech Recognition", ["Herve Bourlard"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/4003.html", 1, "interspeech", 2018]], "Masaki Yokoyama": [0, ["Effects of Dimensional Input on Paralinguistic Information Perceived from Synthesized Dialogue Speech with Neural Network", ["Masaki Yokoyama", "Tomohiro Nagata", "Hiroki Mori"], "https://doi.org/10.21437/Interspeech.2018-2042", 4, "interspeech", 2018]], "Ziping Zhao": [0, ["Exploring Spatio-Temporal Representations by Integrating Attention-based Bidirectional-LSTM-RNNs and FCNs for Speech Emotion Recognition", ["Ziping Zhao", "Yu Zheng", "Zixing Zhang", "Haishuai Wang", "Yiqin Zhao", "Chao Li"], "https://doi.org/10.21437/Interspeech.2018-1477", 5, "interspeech", 2018]], "Yuan Gong": [0.18233120441436768, ["Impact of Aliasing on Deep CNN-Based End-to-End Acoustic Models", ["Yuan Gong", "Christian Poellabauer"], "https://doi.org/10.21437/Interspeech.2018-1371", 5, "interspeech", 2018]], "Ming Tu": [0, ["Investigating the Role of L1 in Automatic Pronunciation Evaluation of L2 Speech", ["Ming Tu", "Anna Grabek", "Julie Liss", "Visar Berisha"], "https://doi.org/10.21437/Interspeech.2018-1350", 5, "interspeech", 2018]], "Keiko Ochi": [0, ["Automatic Evaluation of Soft Articulatory Contact for Stuttering Treatment", ["Keiko Ochi", "Koichi Mori", "Naomi Sakai"], "https://doi.org/10.21437/Interspeech.2018-2544", 5, "interspeech", 2018]], "Disong Wang": [0.01610933756455779, ["Joint Noise and Reverberation Adaptive Learning for Robust Speaker DOA Estimation with an Acoustic Vector Sensor", ["Disong Wang", "Yuexian Zou"], "https://doi.org/10.21437/Interspeech.2018-1135", 5, "interspeech", 2018]], "Tharshini Gunendradasan": [0, ["Detection of Replay-Spoofing Attacks Using Frequency Modulation Features", ["Tharshini Gunendradasan", "Buddhi Wickramasinghe", "Phu Ngoc Le", "Eliathamby Ambikairajah", "Julien Epps"], "https://doi.org/10.21437/Interspeech.2018-1473", 5, "interspeech", 2018]], "Abhilash Sainathan": [0, ["An Optimization Framework for Recovery of Speech from Phase-Encoded Spectrograms", ["Abhilash Sainathan", "Sunil Rudresh", "Chandra Sekhar Seelamantula"], "https://doi.org/10.21437/Interspeech.2018-1987", 5, "interspeech", 2018]], "Antonio Bonafonte": [0, ["Spanish Statistical Parametric Speech Synthesis Using a Neural Vocoder", ["Antonio Bonafonte", "Santiago Pascual", "Georgina Dorca"], "https://doi.org/10.21437/Interspeech.2018-2417", 4, "interspeech", 2018]], "Shefali Waldekar": [0, ["Wavelet Transform Based Mel-scaled Features for Acoustic Scene Classification", ["Shefali Waldekar", "Goutam Saha"], "https://doi.org/10.21437/Interspeech.2018-2083", 5, "interspeech", 2018]], "Puyang Geng": [0, ["Acoustic and Perceptual Characteristics of Mandarin Speech in Homosexual and Heterosexual Male Speakers", ["Puyang Geng", "Wentao Gu", "Hiroya Fujisaki"], "https://doi.org/10.21437/Interspeech.2018-2225", 5, "interspeech", 2018]], "Huan Song": [0.09555121511220932, ["Triplet Network with Attention for Speaker Diarization", ["Huan Song", "Megan M. Willi", "Jayaraman J. Thiagarajan", "Visar Berisha", "Andreas Spanias"], "https://doi.org/10.21437/Interspeech.2018-2305", 5, "interspeech", 2018]], "Brecht Desplanques": [0, ["Cross-lingual Speech Emotion Recognition through Factor Analysis", ["Brecht Desplanques", "Kris Demuynck"], "https://doi.org/10.21437/Interspeech.2018-1778", 5, "interspeech", 2018]], "Jesus Andres-Ferrer": [0, ["Efficient Language Model Adaptation with Noise Contrastive Estimation and Kullback-Leibler Regularization", ["Jesus Andres-Ferrer", "Nathan Bodenstab", "Paul Vozila"], "https://doi.org/10.21437/Interspeech.2018-1345", 5, "interspeech", 2018]], "Daniil Kocharov": [0, ["Language-Dependent Melody Embeddings", ["Daniil Kocharov", "Alla Menshikova"], "https://doi.org/10.21437/Interspeech.2018-1962", 4, "interspeech", 2018]], "Shuai Nie": [0, ["Deep Noise Tracking Network: A Hybrid Signal Processing/Deep Learning Approach to Speech Enhancement", ["Shuai Nie", "Shan Liang", "Bin Liu", "Yaping Zhang", "Wenju Liu", "Jianhua Tao"], "https://doi.org/10.21437/Interspeech.2018-1020", 5, "interspeech", 2018]], "Sri Harsha Dumpala": [0, ["Analysis of the Effect of Speech-Laugh on Speaker Recognition System", ["Sri Harsha Dumpala", "Ashish Panda", "Sunil Kumar Kopparapu"], "https://doi.org/10.21437/Interspeech.2018-2090", 5, "interspeech", 2018]], "Shigeki Karita": [0, ["Semi-Supervised End-to-End Speech Recognition", ["Shigeki Karita", "Shinji Watanabe", "Tomoharu Iwata", "Atsunori Ogawa", "Marc Delcroix"], "https://doi.org/10.21437/Interspeech.2018-1746", 5, "interspeech", 2018]], "Quy-Thao Truong": [0, ["Automatic Assessment of L2 English Word Prosody Using Weighted Distances of F0 and Intensity Contours", ["Quy-Thao Truong", "Tsuneo Kato", "Seiichi Yamamoto"], "https://doi.org/10.21437/Interspeech.2018-1386", 5, "interspeech", 2018]], "Rachid Ridouane": [0, ["Length Contrast and Covarying Features: Whistled Speech as a Case Study", ["Rachid Ridouane", "Giuseppina Turco", "Julien Meyer"], "https://doi.org/10.21437/Interspeech.2018-1060", 5, "interspeech", 2018]], "T. V. Ananthapadmanabha": [0, ["Estimation of the Vocal Tract Length of Vowel Sounds Based on the Frequency of the Significant Spectral Valley", ["T. V. Ananthapadmanabha", "Ramakrishnan A. G."], "https://doi.org/10.21437/Interspeech.2018-1105", 5, "interspeech", 2018]], "Erfan Loweimi": [0, ["On the Usefulness of the Speech Phase Spectrum for Pitch Extraction", ["Erfan Loweimi", "Jon Barker", "Thomas Hain"], "https://doi.org/10.21437/Interspeech.2018-1062", 5, "interspeech", 2018]], "Tom Backstrom": [0, ["Dithered Quantization for Frequency-Domain Speech and Audio Coding", ["Tom Backstrom", "Johannes Fischer", "Sneha Das"], "https://doi.org/10.21437/Interspeech.2018-46", 5, "interspeech", 2018]], "Eleanor Chodroff": [0, ["Information Structure, Affect and Prenuclear Prominence in American English", ["Eleanor Chodroff", "Jennifer Cole"], "https://doi.org/10.21437/Interspeech.2018-1529", 5, "interspeech", 2018]], "Megan M. Willi": [0, ["A Discriminative Acoustic-Prosodic Approach for Measuring Local Entrainment", ["Megan M. Willi", "Stephanie A. Borrie", "Tyson S. Barrett", "Ming Tu", "Visar Berisha"], "https://doi.org/10.21437/Interspeech.2018-1419", 5, "interspeech", 2018]], "Tuarik Buanzur": [0, ["A First Investigation of the Timing of Turn-taking in Ruuli", ["Tuarik Buanzur", "Margaret Zellers", "Saudah Namyalo", "Alena Witzlack-Makarevich"], "https://doi.org/10.21437/Interspeech.2018-1254", 5, "interspeech", 2018]], "Huiyi Wu": [4.652872689803189e-06, ["A Deep Learning Method for Pathological Voice Detection Using Convolutional Deep Belief Networks", ["Huiyi Wu", "John J. Soraghan", "Anja Lowit", "Gaetano Di Caterina"], "https://doi.org/10.21437/Interspeech.2018-1351", 5, "interspeech", 2018]], "Anand P. A": [0, ["Intonation tutor by SPIRE (In-SPIRE): An Online Tool for an Automatic Feedback to the Second Language Learners in Learning Intonation", ["Anand P. A", "Chiranjeevi Yarra", "N. K. Kausthubha", "Prasanta Kumar Ghosh"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3008.html", 2, "interspeech", 2018]], "Yu-Huai Peng": [0, ["Exemplar-Based Spectral Detail Compensation for Voice Conversion", ["Yu-Huai Peng", "Hsin-Te Hwang", "Yi-Chiao Wu", "Yu Tsao", "Hsin-Min Wang"], "https://doi.org/10.21437/Interspeech.2018-1662", 5, "interspeech", 2018]], "Naoya Takahashi": [0, ["PhaseNet: Discretized Phase Modeling with Deep Neural Networks for Audio Source Separation", ["Naoya Takahashi", "Purvi Agrawal", "Nabarun Goswami", "Yuki Mitsufuji"], "https://doi.org/10.21437/Interspeech.2018-1773", 5, "interspeech", 2018]], "Sneha Das": [0, ["Postfiltering with Complex Spectral Correlations for Speech and Audio Coding", ["Sneha Das", "Tom Backstrom"], "https://doi.org/10.21437/Interspeech.2018-1026", 5, "interspeech", 2018], ["Postfiltering Using Log-Magnitude Spectrum for Speech and Audio Coding", ["Sneha Das", "Tom Backstrom"], "https://doi.org/10.21437/Interspeech.2018-1027", 5, "interspeech", 2018]], "Akhilesh Kumar Dubey": [0, ["Pitch-Adaptive Front-end Feature for Hypernasality Detection", ["Akhilesh Kumar Dubey", "S. R. Mahadeva Prasanna", "Samarendra Dandapat"], "https://doi.org/10.21437/Interspeech.2018-1251", 5, "interspeech", 2018]], "Wang Zhang": [0, ["Acoustic Features Associated with Sustained Vowel and Continuous Speech Productions by Chinese Children with Functional Articulation Disorders", ["Wang Zhang", "Xiangquan Gui", "Tianqi Wang", "Manwa L. Ng", "Feng Yang", "Lan Wang", "Nan Yan"], "https://doi.org/10.21437/Interspeech.2018-1521", 5, "interspeech", 2018]], "Na Li": [0, ["Deep Discriminative Embeddings for Duration Robust Speaker Verification", ["Na Li", "Deyi Tuo", "Dan Su", "Zhifeng Li", "Dong Yu"], "https://doi.org/10.21437/Interspeech.2018-1769", 5, "interspeech", 2018]], "Timo Baumann": [0, ["Analysing the Focus of a Hierarchical Attention Network: the Importance of Enjambments When Classifying Post-modern Poetry", ["Timo Baumann", "Hussein Hussein", "Burkhard Meyer-Sickendiek"], "https://doi.org/10.21437/Interspeech.2018-2533", 5, "interspeech", 2018]], "Ke Li": [0, ["Recurrent Neural Network Language Model Adaptation for Conversational Speech Recognition", ["Ke Li", "Hainan Xu", "Yiming Wang", "Daniel Povey", "Sanjeev Khudanpur"], "https://doi.org/10.21437/Interspeech.2018-1413", 5, "interspeech", 2018]], "Cristina Gorrostieta": [0, ["Attention-based Sequence Classification for Affect Detection", ["Cristina Gorrostieta", "Richard Brutti", "Kye Taylor", "Avi Shapiro", "Joseph Moran", "Ali Azarbayejani", "John Kane"], "https://doi.org/10.21437/Interspeech.2018-1610", 5, "interspeech", 2018]], "Somnath Roy": [0, ["A Hybrid Approach to Grapheme to Phoneme Conversion in Assamese", ["Somnath Roy", "Shakuntala Mahanta"], "https://doi.org/10.21437/Interspeech.2018-1694", 5, "interspeech", 2018]], "John H. L. Hansen": [0, ["Fearless Steps: Apollo-11 Corpus Advancements for Speech Technologies from Earth to the Moon", ["John H. L. Hansen", "Abhijeet Sangwan", "Aditya Joglekar", "Ahmet Emin Bulut", "Lakshmish Kaushik", "Chengzhu Yu"], "https://doi.org/10.21437/Interspeech.2018-1942", 5, "interspeech", 2018]], "Vikram C. M.": [0, ["Detection of Glottal Activity Errors in Production of Stop Consonants in Children with Cleft Lip and Palate", ["Vikram C. M.", "S. R. Mahadeva Prasanna", "Ajish K. Abraham", "Pushpavathi M", "Girish K. S"], "https://doi.org/10.21437/Interspeech.2018-1665", 5, "interspeech", 2018], ["Estimation of Hypernasality Scores from Cleft Lip and Palate Speech", ["Vikram C. M.", "Ayush Tripathi", "Sishir Kalita", "S. R. Mahadeva Prasanna"], "https://doi.org/10.21437/Interspeech.2018-1631", 5, "interspeech", 2018], ["Epoch Extraction from Pathological Children Speech Using Single Pole Filtering Approach", ["Vikram C. M.", "S. R. Mahadeva Prasanna"], "https://doi.org/10.21437/Interspeech.2018-1613", 5, "interspeech", 2018]], "Li Chai": [0, ["Error Modeling via Asymmetric Laplace Distribution for Deep Neural Network Based Single-Channel Speech Enhancement", ["Li Chai", "Jun Du", "Chin-Hui Lee"], "https://doi.org/10.21437/Interspeech.2018-1439", 5, "interspeech", 2018]], "Annam Naresh": [0, ["HoloCompanion: An MR Friend for EveryOne", ["Annam Naresh", "Rushabh Gandhi", "Mallikarjuna Rao Bellamkonda", "Mithun Das Gupta"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3017.html", 2, "interspeech", 2018]], "Emilia Parada-Cabaleiro": [0, ["Categorical vs Dimensional Perception of Italian Emotional Speech", ["Emilia Parada-Cabaleiro", "Giovanni Costantini", "Anton Batliner", "Alice Baird", "Bjorn W. Schuller"], "https://doi.org/10.21437/Interspeech.2018-47", 5, "interspeech", 2018]], "Dravyansh Sharma": [0, ["On Training and Evaluation of Grapheme-to-Phoneme Mappings with Limited Data", ["Dravyansh Sharma"], "https://doi.org/10.21437/Interspeech.2018-1920", 5, "interspeech", 2018]], "Meng Yu": [0.0010469693806953728, ["Text-Dependent Speech Enhancement for Small-Footprint Robust Keyword Detection", ["Meng Yu", "Xuan Ji", "Yi Gao", "Lianwu Chen", "Jie Chen", "Jimeng Zheng", "Dan Su", "Dong Yu"], "https://doi.org/10.21437/Interspeech.2018-1668", 5, "interspeech", 2018]], "Yi Liu": [0, ["Speaker Embedding Extraction with Phonetic Information", ["Yi Liu", "Liang He", "Jia Liu", "Michael T. Johnson"], "https://doi.org/10.21437/Interspeech.2018-1226", 5, "interspeech", 2018]], "Filip Nenadic": [0, ["Implementing DIANA to Model Isolated Auditory Word Recognition in English", ["Filip Nenadic", "Louis ten Bosch", "Benjamin V. Tucker"], "https://doi.org/10.21437/Interspeech.2018-2081", 5, "interspeech", 2018]], "Jeffrey Hetherly": [0, ["Deep Speech Denoising with Vector Space Projections", ["Jeffrey Hetherly", "Paul Gamble", "Maria Alejandra Barrios", "Cory Stephenson", "Karl Ni"], "https://doi.org/10.21437/Interspeech.2018-83", 5, "interspeech", 2018]], "Ignacio Vinals": [0, ["Estimation of the Number of Speakers with Variational Bayesian PLDA in the DIHARD Diarization Challenge", ["Ignacio Vinals", "Pablo Gimeno", "Alfonso Ortega", "Antonio Miguel", "Eduardo Lleida"], "https://doi.org/10.21437/Interspeech.2018-1841", 5, "interspeech", 2018]], "Kei Akuzawa": [0, ["Expressive Speech Synthesis via Modeling Expressions with Variational Autoencoder", ["Kei Akuzawa", "Yusuke Iwasawa", "Yutaka Matsuo"], "https://doi.org/10.21437/Interspeech.2018-1113", 5, "interspeech", 2018]], "Khe Chai Sim": [1.1623309546848759e-05, ["Domain Adaptation Using Factorized Hidden Layer for Robust Automatic Speech Recognition", ["Khe Chai Sim", "Arun Narayanan", "Ananya Misra", "Anshuman Tripathi", "Golan Pundak", "Tara N. Sainath", "Parisa Haghani", "Bo Li", "Michiel Bacchiani"], "https://doi.org/10.21437/Interspeech.2018-2246", 5, "interspeech", 2018]], "Pavlos Papadopoulos": [0, ["Exploring the Relationship between Conic Affinity of NMF Dictionaries and Speech Enhancement Metrics", ["Pavlos Papadopoulos", "Colin Vaz", "Shrikanth Narayanan"], "https://doi.org/10.21437/Interspeech.2018-1387", 5, "interspeech", 2018]], "Antoine Bruguier": [0, ["Sequence-to-sequence Neural Network Model with 2D Attention for Learning Japanese Pitch Accents", ["Antoine Bruguier", "Heiga Zen", "Arkady Arkhangorodsky"], "https://doi.org/10.21437/Interspeech.2018-1381", 4, "interspeech", 2018], ["Dictionary Augmented Sequence-to-Sequence Neural Network for Grapheme to Phoneme Prediction", ["Antoine Bruguier", "Anton Bakhtin", "Dravyansh Sharma"], "https://doi.org/10.21437/Interspeech.2018-2061", 5, "interspeech", 2018]], "Manjunath Mulimani": [0, ["Robust Acoustic Event Classification Using Bag-of-Visual-Words", ["Manjunath Mulimani", "Shashidhar G. Koolagudi"], "https://doi.org/10.21437/Interspeech.2018-1905", 4, "interspeech", 2018]], "Hari Krishna Vydana": [0, ["An Exploration towards Joint Acoustic Modeling for Indian Languages: IIIT-H Submission for Low Resource Speech Recognition Challenge for Indian Languages, INTERSPEECH 2018", ["Hari Krishna Vydana", "Krishna Gurugubelli", "Vishnu Vidyadhara Raju Vegesna", "Anil Kumar Vuppala"], "https://doi.org/10.21437/Interspeech.2018-1584", 5, "interspeech", 2018]], "Kimberley Mulder": [0, ["Analyzing EEG Signals in Auditory Speech Comprehension Using Temporal Response Functions and Generalized Additive Models", ["Kimberley Mulder", "Louis ten Bosch", "Lou Boves"], "https://doi.org/10.21437/Interspeech.2018-1676", 5, "interspeech", 2018]], "Agha Ali Raza": [0, ["Rapid Collection of Spontaneous Speech Corpora Using Telephonic Community Forums", ["Agha Ali Raza", "Awais Athar", "Shan Randhawa", "Zain Tariq", "Muhammad Bilal Saleem", "Haris Bin Zia", "Umar Saif", "Roni Rosenfeld"], "https://doi.org/10.21437/Interspeech.2018-1139", 5, "interspeech", 2018]], "Sriram Ganapathy": [0, ["Far-Field Speech Recognition Using Multivariate Autoregressive Models", ["Sriram Ganapathy", "Madhumita Harish"], "https://doi.org/10.21437/Interspeech.2018-2003", 5, "interspeech", 2018], ["Speaker and Language Recognition - From Laboratory Technologies to the Wild", ["Sriram Ganapathy"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/4008.html", 1, "interspeech", 2018]], "Yu-An Chung": [0.18233120441436768, ["Speech2Vec: A Sequence-to-Sequence Framework for Learning Word Embeddings from Speech", ["Yu-An Chung", "James R. Glass"], "https://doi.org/10.21437/Interspeech.2018-2341", 5, "interspeech", 2018]], "Gabriel Mittag": [0, ["Detecting Packet-Loss Concealment Using Formant Features and Decision Tree Learning", ["Gabriel Mittag", "Sebastian Moller"], "https://doi.org/10.21437/Interspeech.2018-1098", 5, "interspeech", 2018]], "Daniel Williams": [0, ["Perceptual Sensitivity to Spectral Change in Australian English Close Front Vowels: An Electroencephalographic Investigation", ["Daniel Williams", "Paola Escudero", "Adamantios I. Gafos"], "https://doi.org/10.21437/Interspeech.2018-2505", 5, "interspeech", 2018]], "Jacques C. Koreman": [0, ["Category Similarity in Multilingual Pronunciation Training", ["Jacques C. Koreman"], "https://doi.org/10.21437/Interspeech.2018-1938", 5, "interspeech", 2018]], "Koji Inoue": [0, ["Engagement Recognition in Spoken Dialogue via Neural Network by Aggregating Different Annotators' Models", ["Koji Inoue", "Divesh Lala", "Katsuya Takanashi", "Tatsuya Kawahara"], "https://doi.org/10.21437/Interspeech.2018-2067", 5, "interspeech", 2018]], "Jose Patino": [0, ["The EURECOM Submission to the First DIHARD Challenge", ["Jose Patino", "Hector Delgado", "Nicholas W. D. Evans"], "https://doi.org/10.21437/Interspeech.2018-2172", 5, "interspeech", 2018]], "Ching Hua Lee": [9.075021983884213e-11, ["Bone-Conduction Sensor Assisted Noise Estimation for Improved Speech Enhancement", ["Ching Hua Lee", "Bhaskar D. Rao", "Harinath Garudadri"], "https://doi.org/10.21437/Interspeech.2018-1046", 5, "interspeech", 2018]], "Kaiyu Shi": [0, ["Structured Word Embedding for Low Memory Neural Network Language Model", ["Kaiyu Shi", "Kai Yu"], "https://doi.org/10.21437/Interspeech.2018-1057", 5, "interspeech", 2018]], "Wei-Ning Hsu": [0, ["Scalable Factorized Hierarchical Variational Autoencoder Training", ["Wei-Ning Hsu", "James R. Glass"], "https://doi.org/10.21437/Interspeech.2018-1034", 5, "interspeech", 2018], ["Unsupervised Adaptation with Interpretable Disentangled Representations for Distant Conversational Speech Recognition", ["Wei-Ning Hsu", "Hao Tang", "James R. Glass"], "https://doi.org/10.21437/Interspeech.2018-1097", 5, "interspeech", 2018]], "Lucas D. Terissi": [0, ["A French-Spanish Multimodal Speech Communication Corpus Incorporating Acoustic Data, Facial, Hands and Arms Gestures Information", ["Lucas D. Terissi", "Gonzalo D. Sad", "Mauricio Cerda", "Slim Ouni", "Rodrigo Galvez", "Juan Carlos Gomez", "Bernard Girau", "Nancy Hitschfeld-Kahler"], "https://doi.org/10.21437/Interspeech.2018-2212", 5, "interspeech", 2018]], "Olga Maxwell": [0, ["Homogeneity vs Heterogeneity in Indian English: Investigating Influences of L1 on f0 Range", ["Olga Maxwell", "Elinor Payne", "Rosey Billington"], "https://doi.org/10.21437/Interspeech.2018-1476", 5, "interspeech", 2018]], "Ganji Sreeram": [0, ["A Novel Approach for Effective Recognition of the Code-Switched Data on Monolingual Language Model", ["Ganji Sreeram", "Rohit Sinha"], "https://doi.org/10.21437/Interspeech.2018-1259", 5, "interspeech", 2018]], "Hao Li": [0, ["EMPHASIS: An Emotional Phoneme-based Acoustic Model for Speech Synthesis System", ["Hao Li", "Yongguo Kang", "Zhenyu Wang"], "https://doi.org/10.21437/Interspeech.2018-1511", 5, "interspeech", 2018]], "Kusha Sridhar": [0, ["Role of Regularization in the Prediction of Valence from Speech", ["Kusha Sridhar", "Srinivas Parthasarathy", "Carlos Busso"], "https://doi.org/10.21437/Interspeech.2018-2508", 5, "interspeech", 2018]], "Albert Haque": [0, ["Conditional End-to-End Audio Transforms", ["Albert Haque", "Michelle Guo", "Prateek Verma"], "https://doi.org/10.21437/Interspeech.2018-38", 5, "interspeech", 2018]], "Arjun Pankajakshan": [0, ["All-Conv Net for Bird Activity Detection: Significance of Learned Pooling", ["Arjun Pankajakshan", "Anshul Thakur", "Daksh Thapar", "Padmanabhan Rajan", "Aditya Nigam"], "https://doi.org/10.21437/Interspeech.2018-1522", 5, "interspeech", 2018]], "Takaaki Shochi": [0, ["Cultural Differences in Pattern Matching: Multisensory Recognition of Socio-affective Prosody", ["Takaaki Shochi", "Jean-Luc Rouas", "Marine Guerry", "Donna Erickson"], "https://doi.org/10.21437/Interspeech.2018-1795", 5, "interspeech", 2018]], "Ahmed Imtiaz Humayun": [0, ["An Ensemble of Transfer, Semi-supervised and Supervised Learning Methods for Pathological Heart Sound Classification", ["Ahmed Imtiaz Humayun", "Md. Tauhiduzzaman Khan", "Shabnam Ghaffarzadegan", "Zhe Feng", "Taufiq Hasan"], "https://doi.org/10.21437/Interspeech.2018-2413", 5, "interspeech", 2018]], "Rong Gong": [0.01968786818906665, ["Singing Voice Phoneme Segmentation by Hierarchically Inferring Syllable and Phoneme Onset Positions", ["Rong Gong", "Xavier Serra"], "https://doi.org/10.21437/Interspeech.2018-1224", 5, "interspeech", 2018]], "Nanxin Chen": [0, ["An Investigation of Non-linear i-vectors for Speaker Verification", ["Nanxin Chen", "Jesus Villalba", "Najim Dehak"], "https://doi.org/10.21437/Interspeech.2018-2474", 5, "interspeech", 2018]], "Vishwas M. Shetty": [0, ["Articulatory and Stacked Bottleneck Features for Low Resource Speech Recognition", ["Vishwas M. Shetty", "Rini A. Sharon", "Basil Abraham", "Tejaswi Seeram", "Anusha Prakash", "Nithya Ravi", "Srinivasan Umesh"], "https://doi.org/10.21437/Interspeech.2018-2226", 5, "interspeech", 2018]], "Yun Wang": [0.0668149832636118, ["Comparing the Max and Noisy-Or Pooling Functions in Multiple Instance Learning for Weakly Supervised Sequence Learning Tasks", ["Yun Wang", "Juncheng Li", "Florian Metze"], "https://doi.org/10.21437/Interspeech.2018-990", 5, "interspeech", 2018]], "Lei Sun": [0.001596404705196619, ["Speaker Diarization with Enhancing Speech for the First DIHARD Challenge", ["Lei Sun", "Jun Du", "Chao Jiang", "Xueyang Zhang", "Shan He", "Bing Yin", "Chin-Hui Lee"], "https://doi.org/10.21437/Interspeech.2018-1742", 5, "interspeech", 2018]], "Monika Podsiadlo": [0, ["Experiments with Training Corpora for Statistical Text-to-speech Systems", ["Monika Podsiadlo", "Victor Ungureanu"], "https://doi.org/10.21437/Interspeech.2018-2400", 5, "interspeech", 2018]], "Meredith Moore": [0, ["Whistle-blowing ASRs: Evaluating the Need for More Inclusive Speech Recognition Systems", ["Meredith Moore", "Hemanth Venkateswara", "Sethuraman Panchanathan"], "https://doi.org/10.21437/Interspeech.2018-2391", 5, "interspeech", 2018]], "Qiguang Lin": [0, ["A Novel Normalization Method for Autocorrelation Function for Pitch Detection and for Speech Activity Detection", ["Qiguang Lin", "Yiwen Shao"], "https://doi.org/10.21437/Interspeech.2018-45", 5, "interspeech", 2018]], "Neil Zeghidour": [0, ["End-to-End Speech Recognition from the Raw Waveform", ["Neil Zeghidour", "Nicolas Usunier", "Gabriel Synnaeve", "Ronan Collobert", "Emmanuel Dupoux"], "https://doi.org/10.21437/Interspeech.2018-2414", 5, "interspeech", 2018]], "Sunit Sivasankaran": [0, ["Keyword Based Speaker Localization: Localizing a Target Speaker in a Multi-speaker Environment", ["Sunit Sivasankaran", "Emmanuel Vincent", "Dominique Fohr"], "https://doi.org/10.21437/Interspeech.2018-1526", 5, "interspeech", 2018]], "Katlin Aare": [0, ["Creak in the Respiratory Cycle", ["Katlin Aare", "Partel Lippus", "Marcin Wlodarczak", "Mattias Heldner"], "https://doi.org/10.21437/Interspeech.2018-2165", 5, "interspeech", 2018]], "N. P. Narendra": [0, ["Dysarthric Speech Classification Using Glottal Features Computed from Non-words, Words and Sentences", ["N. P. Narendra", "Paavo Alku"], "https://doi.org/10.21437/Interspeech.2018-1059", 5, "interspeech", 2018]], "Kuan Chen": [0, ["High-quality Voice Conversion Using Spectrogram-Based WaveNet Vocoder", ["Kuan Chen", "Bo Chen", "Jiahao Lai", "Kai Yu"], "https://doi.org/10.21437/Interspeech.2018-1528", 5, "interspeech", 2018]], "Yue Deng": [0, ["Training Recurrent Neural Network through Moment Matching for NLP Applications", ["Yue Deng", "Yilin Shen", "KaWai Chen", "Hongxia Jin"], "https://doi.org/10.21437/Interspeech.2018-1369", 5, "interspeech", 2018]], "Guanlong Zhao": [0, ["L2-ARCTIC: A Non-native English Speech Corpus", ["Guanlong Zhao", "Sinem Sonsaat", "Alif Silpachai", "Ivana Lucic", "Evgeny Chukharev-Hudilainen", "John Levis", "Ricardo Gutierrez-Osuna"], "https://doi.org/10.21437/Interspeech.2018-1110", 5, "interspeech", 2018]], "Chandrakant Bothe": [0, ["Conversational Analysis Using Utterance-level Attention-based Bidirectional Recurrent Neural Networks", ["Chandrakant Bothe", "Sven Magg", "Cornelius Weber", "Stefan Wermter"], "https://doi.org/10.21437/Interspeech.2018-2527", 5, "interspeech", 2018]], "Moquan Wan": [0, ["Waveform-Based Speaker Representations for Speech Synthesis", ["Moquan Wan", "Gilles Degottex", "Mark J. F. Gales"], "https://doi.org/10.21437/Interspeech.2018-1154", 5, "interspeech", 2018]], "Arne Kohn": [0, ["An Empirical Analysis of the Correlation of Syntax and Prosody", ["Arne Kohn", "Timo Baumann", "Oskar Dorfler"], "https://doi.org/10.21437/Interspeech.2018-2530", 5, "interspeech", 2018]], "Zoltan Tuske": [0, ["Investigation on LSTM Recurrent N-gram Language Models for Speech Recognition", ["Zoltan Tuske", "Ralf Schluter", "Hermann Ney"], "https://doi.org/10.21437/Interspeech.2018-2476", 5, "interspeech", 2018]], "Min-Jae Hwang": [0.8463334739208221, ["A Unified Framework for the Generation of Glottal Signals in Deep Learning-based Parametric Speech Synthesis Systems", ["Min-Jae Hwang", "Eunwoo Song", "Jin-Seob Kim", "Hong-Goo Kang"], "https://doi.org/10.21437/Interspeech.2018-1590", 5, "interspeech", 2018]], "Chanwoo Kim": [0.9085521399974823, ["Efficient Implementation of the Room Simulator for Training Deep Neural Network Acoustic Models", ["Chanwoo Kim", "Ehsan Variani", "Arun Narayanan", "Michiel Bacchiani"], "https://doi.org/10.21437/Interspeech.2018-2566", 5, "interspeech", 2018]], "Jian Cheng": [0, ["Real-Time Scoring of an Oral Reading Assessment on Mobile Devices", ["Jian Cheng"], "https://doi.org/10.21437/Interspeech.2018-34", 5, "interspeech", 2018], ["Modeling Self-Reported and Observed Affect from Speech", ["Jian Cheng", "Jared Bernstein", "Elizabeth Rosenfeld", "Peter W. Foltz", "Alex S. Cohen", "Terje B. Holmlund", "Brita Elvevag"], "https://doi.org/10.21437/Interspeech.2018-2222", 5, "interspeech", 2018]], "Siddharth Sigtia": [0, ["Efficient Voice Trigger Detection for Low Resource Hardware", ["Siddharth Sigtia", "Rob Haynes", "Hywel Richards", "Erik Marchi", "John Bridle"], "https://doi.org/10.21437/Interspeech.2018-2204", 5, "interspeech", 2018]], "Madhavaraj Ayyavu": [0, ["Online Speech Translation System for Tamil", ["Madhavaraj Ayyavu", "Shiva Kumar H. R", "Ramakrishnan A. G"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3035.html", 2, "interspeech", 2018]], "Nirmesh J. Shah": [0, ["Effectiveness of Dynamic Features in INCA and Temporal Context-INCA", ["Nirmesh J. Shah", "Hemant A. Patil"], "https://doi.org/10.21437/Interspeech.2018-1538", 5, "interspeech", 2018], ["Unsupervised Vocal Tract Length Warped Posterior Features for Non-Parallel Voice Conversion", ["Nirmesh J. Shah", "Maulik C. Madhavi", "Hemant A. Patil"], "https://doi.org/10.21437/Interspeech.2018-1712", 5, "interspeech", 2018]], "Bin Zhao": [0, ["Revealing Spatiotemporal Brain Dynamics of Speech Production Based on EEG and Eye Movement", ["Bin Zhao", "Jinfeng Huang", "Gaoyan Zhang", "Jianwu Dang", "Minbo Chen", "YingjianFu", "Longbiao Wang"], "https://doi.org/10.21437/Interspeech.2018-1908", 5, "interspeech", 2018]], "Neil Shah": [0, ["Effectiveness of Generative Adversarial Network for Non-Audible Murmur-to-Whisper Speech Conversion", ["Neil Shah", "Nirmesh J. Shah", "Hemant A. Patil"], "https://doi.org/10.21437/Interspeech.2018-1565", 5, "interspeech", 2018]], "Shreyas Ramoji": [0, ["Supervised I-vector Modeling - Theory and Applications", ["Shreyas Ramoji", "Sriram Ganapathy"], "https://doi.org/10.21437/Interspeech.2018-2012", 5, "interspeech", 2018]], "Li-Juan Liu": [0, ["WaveNet Vocoder with Limited Training Data for Voice Conversion", ["Li-Juan Liu", "Zhen-Hua Ling", "Yuan Jiang", "Ming Zhou", "Li-Rong Dai"], "https://doi.org/10.21437/Interspeech.2018-1190", 5, "interspeech", 2018]], "Hannah Muckenhirn": [0, ["On Learning Vocal Tract System Related Speaker Discriminative Information from Raw Signal Using CNNs", ["Hannah Muckenhirn", "Mathew Magimai-Doss", "Sebastien Marcel"], "https://doi.org/10.21437/Interspeech.2018-1696", 5, "interspeech", 2018]], "David Greenwood": [0, ["Joint Learning of Facial Expression and Head Pose from Speech", ["David Greenwood", "Iain Matthews", "Stephen D. Laycock"], "https://doi.org/10.21437/Interspeech.2018-2587", 5, "interspeech", 2018]], "Mousmita Sarma": [0, ["Emotion Identification from Raw Speech Signals Using DNNs", ["Mousmita Sarma", "Pegah Ghahremani", "Daniel Povey", "Nagendra Kumar Goel", "Kandarpa Kumar Sarma", "Najim Dehak"], "https://doi.org/10.21437/Interspeech.2018-1353", 5, "interspeech", 2018]], "Soheil Khorram": [0, ["The PRIORI Emotion Dataset: Linking Mood to Emotion Detected In-the-Wild", ["Soheil Khorram", "Mimansa Jaiswal", "John Gideon", "Melvin G. McInnis", "Emily Mower Provost"], "https://doi.org/10.21437/Interspeech.2018-2355", 5, "interspeech", 2018]], "Linxue Bai": [2.363286899509376e-08, ["Exploring How Phone Classification Neural Networks Learn Phonetic Information by Visualising and Interpreting Bottleneck Features", ["Linxue Bai", "Philip Weber", "Peter Jancovic", "Martin J. Russell"], "https://doi.org/10.21437/Interspeech.2018-2462", 5, "interspeech", 2018]], "G. Nisha Meenakshi": [0, ["Whispered Speech to Neutral Speech Conversion Using Bidirectional LSTMs", ["G. Nisha Meenakshi", "Prasanta Kumar Ghosh"], "https://doi.org/10.21437/Interspeech.2018-1487", 5, "interspeech", 2018]], "Hideki Kawahara": [0, ["Frequency Domain Variants of Velvet Noise and Their Application to Speech Processing and Synthesis", ["Hideki Kawahara", "Ken-Ichi Sakakibara", "Masanori Morise", "Hideki Banno", "Tomoki Toda", "Toshio Irino"], "https://doi.org/10.21437/Interspeech.2018-43", 5, "interspeech", 2018]], "Natalia Dyrenko": [0, ["The Diphthongs of Formal Nigerian English: A Preliminary Acoustic Analysis", ["Natalia Dyrenko", "Robert Fuchs"], "https://doi.org/10.21437/Interspeech.2018-2373", 5, "interspeech", 2018]], "Ruoming Pang": [0, ["Compression of End-to-End Models", ["Ruoming Pang", "Tara N. Sainath", "Rohit Prabhavalkar", "Suyog Gupta", "Yonghui Wu", "Shuyuan Zhang", "Chung-Cheng Chiu"], "https://doi.org/10.21437/Interspeech.2018-1025", 5, "interspeech", 2018]], "Bhuvana Ramabhadran": [0, ["Open Problems in Speech Recognition", ["Bhuvana Ramabhadran"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/4006.html", 1, "interspeech", 2018]], "Kohei Hara": [0, ["Prediction of Turn-taking Using Multitask Learning with Prediction of Backchannels and Fillers", ["Kohei Hara", "Koji Inoue", "Katsuya Takanashi", "Tatsuya Kawahara"], "https://doi.org/10.21437/Interspeech.2018-1442", 5, "interspeech", 2018]], "Ramya Viswanathan": [0, ["Hierarchical Accent Determination and Application in a Large Scale ASR System", ["Ramya Viswanathan", "Periyasamy Paramasivam", "Jithendra Vepa"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3030.html", 2, "interspeech", 2018]], "Mehmet Ali Tugtekin Turan": [0, ["Monitoring Infant's Emotional Cry in Domestic Environments Using the Capsule Network Architecture", ["Mehmet Ali Tugtekin Turan", "Engin Erzin"], "https://doi.org/10.21437/Interspeech.2018-2187", 5, "interspeech", 2018]], "Gurunath Reddy M.": [0, ["Harmonic-Percussive Source Separation of Polyphonic Music by Suppressing Impulsive Noise Events", ["Gurunath Reddy M.", "K. Sreenivasa Rao", "Partha Pratim Das"], "https://doi.org/10.21437/Interspeech.2018-1310", 5, "interspeech", 2018]], "Vikram Ramanarayanan": [0, ["Toward Scalable Dialog Technology for Conversational Language Learning: Case Study of the TOEFL\u00ae MOOC", ["Vikram Ramanarayanan", "David Pautler", "Patrick L. Lange", "Eugene Tsuprun", "Rutuja Ubale", "Keelan Evanini", "David Suendermann-Oeft"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3032.html", 2, "interspeech", 2018]], "Simone Hantke": [0, ["Annotator Trustability-based Cooperative Learning Solutions for Intelligent Audio Analysis", ["Simone Hantke", "Christoph Stemp", "Bjorn W. Schuller"], "https://doi.org/10.21437/Interspeech.2018-1019", 5, "interspeech", 2018]], "B. H. V. S. Narayanamurthy": [0, ["Determining Speaker Location from Speech in a Practical Environment", ["B. H. V. S. Narayanamurthy", "J. V. Satyanarayana", "Bayya Yegnanarayana"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3042.html", 2, "interspeech", 2018]], "Hansjorg Mixdorff": [0, ["Cross-cultural (A)symmetries in Audio-visual Attitude Perception", ["Hansjorg Mixdorff", "Albert Rilliard", "Tan Lee", "Matthew K. H. Ma", "Angelika Honemann"], "https://doi.org/10.21437/Interspeech.2018-1373", 5, "interspeech", 2018]], "Teun F. Krikke": [0, ["Who Said That? a Comparative Study of Non-negative Matrix Factorization Techniques", ["Teun F. Krikke", "Frank Broz", "David Lane"], "https://doi.org/10.21437/Interspeech.2018-1807", 5, "interspeech", 2018]], "Ming-Hsiang Su": [0, ["Follow-up Question Generation Using Pattern-based Seq2seq with a Small Corpus for Interview Coaching", ["Ming-Hsiang Su", "Chung-Hsien Wu", "Kun-Yi Huang", "Qian-Bei Hong", "Huai-Hung Huang"], "https://doi.org/10.21437/Interspeech.2018-1007", 5, "interspeech", 2018]], "Moez Ajili": [0, ["Voice Comparison and Rhythm: Behavioral Differences between Target and Non-target Comparisons", ["Moez Ajili", "Jean-Francois Bonastre", "Solange Rossato"], "https://doi.org/10.21437/Interspeech.2018-61", 5, "interspeech", 2018]], "Yu-Wun Wang": [0.9930607676506042, ["Discourse Marker Detection for Hesitation Events on Mandarin Conversation", ["Yu-Wun Wang", "Hen-Hsen Huang", "Kuan-Yu Chen", "Hsin-Hsi Chen"], "https://doi.org/10.21437/Interspeech.2018-2129", 5, "interspeech", 2018]], "Wenhao Ding": [0, ["MTGAN: Speaker Verification through Multitasking Triplet Generative Adversarial Networks", ["Wenhao Ding", "Liang He"], "https://doi.org/10.21437/Interspeech.2018-1023", 5, "interspeech", 2018]], "Qinglin Meng": [0, ["Weighting Pitch Contour and Loudness Contour in Mandarin Tone Perception in Cochlear Implant Listeners", ["Qinglin Meng", "Nengheng Zheng", "Ambika Prasad Mishra", "Jacinta Dan Luo", "Jan W. H. Schnupp"], "https://doi.org/10.21437/Interspeech.2018-1245", 4, "interspeech", 2018]], "Zafi Sherhan Syed": [0, ["Computational Paralinguistics: Automatic Assessment of Emotions, Mood and Behavioural State from Acoustics of Speech", ["Zafi Sherhan Syed", "Julien Schroeter", "Kirill A. Sidorov", "A. David Marshall"], "https://doi.org/10.21437/Interspeech.2018-2019", 5, "interspeech", 2018]], "Pamir Gogoi": [0, ["Analysis of Breathiness in Contextual Vowel of Voiceless Nasals in Mizo", ["Pamir Gogoi", "Sishir Kalita", "Parismita Gogoi", "Ratree Wayland", "Priyankoo Sarmah", "S. R. Mahadeva Prasanna"], "https://doi.org/10.21437/Interspeech.2018-1899", 5, "interspeech", 2018]], "Yujiang Li": [0, ["Cross-Lingual Multi-Task Neural Architecture for Spoken Language Understanding", ["Yujiang Li", "Xuemin Zhao", "Weiqun Xu", "Yonghong Yan"], "https://doi.org/10.21437/Interspeech.2018-1039", 5, "interspeech", 2018]], "Nagapuri Srinivas": [0, ["Enhancement of Noisy Speech Signal by Non-Local Means Estimation of Variational Mode Functions", ["Nagapuri Srinivas", "Gayadhar Pradhan", "Syed Shahnawazuddin"], "https://doi.org/10.21437/Interspeech.2018-1928", 5, "interspeech", 2018]], "Veronique Delvaux": [0, ["Towards a Better Characterization of Parkinsonian Speech: A Multidimensional Acoustic Study", ["Veronique Delvaux", "Kathy Huet", "Myriam Piccaluga", "Sophie van Malderen", "Bernard Harmegnies"], "https://doi.org/10.21437/Interspeech.2018-1054", 5, "interspeech", 2018]], "Abhishek Dey": [0, ["Robust Mizo Continuous Speech Recognition", ["Abhishek Dey", "Biswajit Dev Sarma", "Wendy Lalhminghlui", "Lalnunsiami Ngente", "Parismita Gogoi", "Priyankoo Sarmah", "S. R. Mahadeva Prasanna", "Rohit Sinha", "S. R. Nirmala"], "https://doi.org/10.21437/Interspeech.2018-2125", 5, "interspeech", 2018], ["AGROASSAM: A Web Based Assamese Speech Recognition Application for Retrieving Agricultural Commodity Price and Weather Information", ["Abhishek Dey", "Abhash Deka", "Siddika Imani", "Barsha Deka", "Rohit Sinha", "S. R. Mahadeva Prasanna", "Priyankoo Sarmah", "K. Samudravijaya", "S. R. Nirmala"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3048.html", 2, "interspeech", 2018]], "Rob van Son": [1.6504676292328213e-08, ["Vowel Space as a Tool to Evaluate Articulation Problems", ["Rob van Son", "Catherine Middag", "Kris Demuynck"], "https://doi.org/10.21437/Interspeech.2018-68", 5, "interspeech", 2018]], "Ian Vince McLoughlin": [0, ["Early Detection of Continuous and Partial Audio Events Using CNN", ["Ian Vince McLoughlin", "Yan Song", "Lam Dang Pham", "Ramaswamy Palaniappan", "Huy Phan", "Yue Lang"], "https://doi.org/10.21437/Interspeech.2018-1821", 5, "interspeech", 2018]], "Patrick Meyer": [0, ["What Do Classifiers Actually Learn? a Case Study on Emotion Recognition Datasets", ["Patrick Meyer", "Eric Buschermohle", "Tim Fingscheidt"], "https://doi.org/10.21437/Interspeech.2018-1851", 5, "interspeech", 2018]], "Leda Sari": [0, ["Speaker Adaptive Audio-Visual Fusion for the Open-Vocabulary Section of AVICAR", ["Leda Sari", "Mark Hasegawa-Johnson", "Kumaran S", "Georg Stemmer", "Krishnakumar N. Nair"], "https://doi.org/10.21437/Interspeech.2018-2359", 5, "interspeech", 2018]], "Rajath Kumar": [0, ["Music Source Activity Detection and Separation Using Deep Attractor Network", ["Rajath Kumar", "Yi Luo", "Nima Mesgarani"], "https://doi.org/10.21437/Interspeech.2018-2326", 5, "interspeech", 2018], ["On Convolutional LSTM Modeling for Joint Wake-Word Detection and Text Dependent Speaker Verification", ["Rajath Kumar", "Vaishnavi Yeruva", "Sriram Ganapathy"], "https://doi.org/10.21437/Interspeech.2018-1759", 5, "interspeech", 2018]], "Lei Wang": [0.001596404705196619, ["Wuxi Speakers' Production and Perception of Coda Nasals in Mandarin", ["Lei Wang", "Jie Cui", "Ying Chen"], "https://doi.org/10.21437/Interspeech.2018-2224", 4, "interspeech", 2018]], "Naoyuki Kanda": [0, ["Lattice-free State-level Minimum Bayes Risk Training of Acoustic Models", ["Naoyuki Kanda", "Yusuke Fujita", "Kenji Nagamatsu"], "https://doi.org/10.21437/Interspeech.2018-79", 5, "interspeech", 2018]], "Tuka Al Hanai": [0, ["Detecting Depression with Audio/Text Sequence Modeling of Interviews", ["Tuka Al Hanai", "Mohammad M. Ghassemi", "James R. Glass"], "https://doi.org/10.21437/Interspeech.2018-2522", 5, "interspeech", 2018]], "Yijia Xu": [0, ["Infant Emotional Outbursts Detection in Infant-parent Spoken Interactions", ["Yijia Xu", "Mark Hasegawa-Johnson", "Nancy McElwain"], "https://doi.org/10.21437/Interspeech.2018-2429", 5, "interspeech", 2018]], "Jeena J. Prakash": [0, ["Transcription Correction for Indian Languages Using Acoustic Signatures", ["Jeena J. Prakash", "Golda Brunet Rajan", "Hema A. Murthy"], "https://doi.org/10.21437/Interspeech.2018-1188", 5, "interspeech", 2018]], "Mandar Gogate": [0, ["DNN Driven Speaker Independent Audio-Visual Mask Estimation for Speech Separation", ["Mandar Gogate", "Ahsan Adeel", "Ricard Marxer", "Jon Barker", "Amir Hussain"], "https://doi.org/10.21437/Interspeech.2018-2516", 5, "interspeech", 2018]], "Adrien Le Franc": [0, ["The ACLEW DiViMe: An Easy-to-use Diarization Tool", ["Adrien Le Franc", "Eric Riebling", "Julien Karadayi", "Yun Wang", "Camila Scaff", "Florian Metze", "Alejandrina Cristia"], "https://doi.org/10.21437/Interspeech.2018-2324", 5, "interspeech", 2018]], "Peter Guzewich": [0, ["Cross-Corpora Convolutional Deep Neural Network Dereverberation Preprocessing for Speaker Verification and Speech Enhancement", ["Peter Guzewich", "Stephen A. Zahorian", "Xiao Chen", "Hao Zhang"], "https://doi.org/10.21437/Interspeech.2018-2238", 5, "interspeech", 2018]], "Gautam Bhattacharya": [0, ["Deeply Fused Speaker Embeddings for Text-Independent Speaker Verification", ["Gautam Bhattacharya", "Md. Jahangir Alam", "Vishwa Gupta", "Patrick Kenny"], "https://doi.org/10.21437/Interspeech.2018-1688", 5, "interspeech", 2018]], "Victor Soto": [0, ["The Role of Cognate Words, POS Tags and Entrainment in Code-Switching", ["Victor Soto", "Nishmar Cestero", "Julia Hirschberg"], "https://doi.org/10.21437/Interspeech.2018-1099", 5, "interspeech", 2018]], "Pallavi Baljekar": [0, ["An Investigation of Convolution Attention Based Models for Multilingual Speech Synthesis of Indian Languages", ["Pallavi Baljekar", "Sai Krishna Rallabandi", "Alan W. Black"], "https://doi.org/10.21437/Interspeech.2018-1869", 5, "interspeech", 2018]], "Ina Kodrasi": [0, ["Single-channel Late Reverberation Power Spectral Density Estimation Using Denoising Autoencoders", ["Ina Kodrasi", "Herve Bourlard"], "https://doi.org/10.21437/Interspeech.2018-1660", 5, "interspeech", 2018]], "Buddhi Wickramasinghe": [0, ["Frequency Domain Linear Prediction Features for Replay Spoofing Attack Detection", ["Buddhi Wickramasinghe", "Saad Irtza", "Eliathamby Ambikairajah", "Julien Epps"], "https://doi.org/10.21437/Interspeech.2018-1574", 5, "interspeech", 2018]], "Gregory P. Finley": [0, ["An Automated Assistant for Medical Scribes", ["Gregory P. Finley", "Erik Edwards", "Amanda Robinson", "Najmeh Sadoughi", "James Fone", "Mark Miller", "David Suendermann-Oeft", "Michael Brenndoerfer", "Nico Axtmann"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3047.html", 2, "interspeech", 2018]], "Marc Delcroix": [0, ["Auxiliary Feature Based Adaptation of End-to-end ASR Systems", ["Marc Delcroix", "Shinji Watanabe", "Atsunori Ogawa", "Shigeki Karita", "Tomohiro Nakatani"], "https://doi.org/10.21437/Interspeech.2018-1438", 5, "interspeech", 2018]], "Yi-Chiao Wu": [6.146273167338418e-14, ["Collapsed Speech Segment Detection and Suppression for WaveNet Vocoder", ["Yi-Chiao Wu", "Kazuhiro Kobayashi", "Tomoki Hayashi", "Patrick Lumban Tobing", "Tomoki Toda"], "https://doi.org/10.21437/Interspeech.2018-1210", 5, "interspeech", 2018]], "Ragesh Rajan M": [0, ["Prediction of Aesthetic Elements in Karnatic Music: A Machine Learning Approach", ["Ragesh Rajan M", "Ashwin Vijayakumar", "Deepu Vijayasenan"], "https://doi.org/10.21437/Interspeech.2018-991", 5, "interspeech", 2018]], "Youngmoon Jung": [0.9995688796043396, ["Joint Learning Using Denoising Variational Autoencoders for Voice Activity Detection", ["Youngmoon Jung", "Younggwan Kim", "Yeunju Choi", "Hoirin Kim"], "https://doi.org/10.21437/Interspeech.2018-1151", 5, "interspeech", 2018]], "Jessie S. Nixon": [0, ["Effective Acoustic Cue Learning Is Not Just Statistical, It Is Discriminative", ["Jessie S. Nixon"], "https://doi.org/10.21437/Interspeech.2018-1024", 5, "interspeech", 2018]], "Joao Cabral": [0, ["Estimation of the Asymmetry Parameter of the Glottal Flow Waveform Using the Electroglottographic Signal", ["Joao Cabral"], "https://doi.org/10.21437/Interspeech.2018-2371", 5, "interspeech", 2018]], "Rachel E. Bouserhal": [0, ["Classification of Nonverbal Human Produced Audio Events: A Pilot Study", ["Rachel E. Bouserhal", "Philippe Chabot", "Milton Sarria Paja", "Patrick Cardinal", "Jeremie Voix"], "https://doi.org/10.21437/Interspeech.2018-2299", 5, "interspeech", 2018]], "Tae Jin Park": [0.8472927659749985, ["Multimodal Speaker Segmentation and Diarization Using Lexical and Acoustic Cues via Sequence to Sequence Neural Networks", ["Tae Jin Park", "Panayiotis G. Georgiou"], "https://doi.org/10.21437/Interspeech.2018-1364", 5, "interspeech", 2018]], "Hagai Taitelbaum": [0, ["Adding New Classes without Access to the Original Training Data with Applications to Language Identification", ["Hagai Taitelbaum", "Ehud Ben-Reuven", "Jacob Goldberger"], "https://doi.org/10.21437/Interspeech.2018-1342", 5, "interspeech", 2018]], "Selen Hande Kabil": [0, ["On Learning to Identify Genders from Raw Speech Signal Using CNNs", ["Selen Hande Kabil", "Hannah Muckenhirn", "Mathew Magimai-Doss"], "https://doi.org/10.21437/Interspeech.2018-1240", 5, "interspeech", 2018]], "Akihiro Kato": [0, ["Waveform to Single Sinusoid Regression to Estimate the F0 Contour from Noisy Speech Using Recurrent Deep Neural Networks", ["Akihiro Kato", "Tomi Kinnunen"], "https://doi.org/10.21437/Interspeech.2018-1671", 5, "interspeech", 2018]], "Gaofeng Cheng": [0, ["Output-Gate Projected Gated Recurrent Unit for Speech Recognition", ["Gaofeng Cheng", "Daniel Povey", "Lu Huang", "Ji Xu", "Sanjeev Khudanpur", "Yonghong Yan"], "https://doi.org/10.21437/Interspeech.2018-1403", 5, "interspeech", 2018]], "Yanhua Long": [0, ["Active Learning for LF-MMI Trained Neural Networks in ASR", ["Yanhua Long", "Hong Ye", "Yijie Li", "Jiaen Liang"], "https://doi.org/10.21437/Interspeech.2018-1162", 5, "interspeech", 2018]], "Max W. Y. Lam": [0, ["Gaussian Process Neural Networks for Speech Recognition", ["Max W. Y. Lam", "Shoukang Hu", "Xurong Xie", "Shansong Liu", "Jianwei Yu", "Rongfeng Su", "Xunying Liu", "Helen Meng"], "https://doi.org/10.21437/Interspeech.2018-1823", 5, "interspeech", 2018]], "Aciel Eshky": [0, ["UltraSuite: A Repository of Ultrasound and Acoustic Data from Child Speech Therapy Sessions", ["Aciel Eshky", "Manuel Sam Ribeiro", "Joanne Cleland", "Korin Richmond", "Zoe Roxburgh", "James M. Scobbie", "Alan Wrench"], "https://doi.org/10.21437/Interspeech.2018-1736", 5, "interspeech", 2018]], "Chandana S": [0, ["Automatic Visual Augmentation for Concatenation Based Synthesized Articulatory Videos from Real-time MRI Data for Spoken Language Training", ["Chandana S", "Chiranjeevi Yarra", "Ritu Aggarwal", "Sanjeev Kumar Mittal", "N. K. Kausthubha", "Raseena K. T", "Astha Singh", "Prasanta Kumar Ghosh"], "https://doi.org/10.21437/Interspeech.2018-1570", 5, "interspeech", 2018]], "Mia Atcheson": [0, ["Demonstrating and Modelling Systematic Time-varying Annotator Disagreement in Continuous Emotion Annotation", ["Mia Atcheson", "Vidhyasaharan Sethu", "Julien Epps"], "https://doi.org/10.21437/Interspeech.2018-1933", 5, "interspeech", 2018]], "Wenda Chen": [0, ["Topic and Keyword Identification for Low-resourced Speech Using Cross-Language Transfer Learning", ["Wenda Chen", "Mark Hasegawa-Johnson", "Nancy F. Chen"], "https://doi.org/10.21437/Interspeech.2018-1283", 5, "interspeech", 2018]], "Anne Hermes": [0, ["Structural Effects on Properties of Consonantal Gestures in Tashlhiyt", ["Anne Hermes", "Doris Mucke", "Bastian Auris", "Rachid Ridouane"], "https://doi.org/10.21437/Interspeech.2018-1074", 5, "interspeech", 2018], ["Age-related Effects on Sensorimotor Control of Speech Production", ["Anne Hermes", "Jane Mertens", "Doris Mucke"], "https://doi.org/10.21437/Interspeech.2018-1233", 5, "interspeech", 2018]], "Ferdinand Brasser": [0, ["VoiceGuard: Secure and Private Speech Processing", ["Ferdinand Brasser", "Tommaso Frassetto", "Korbinian Riedhammer", "Ahmad-Reza Sadeghi", "Thomas Schneider", "Christian Weinert"], "https://doi.org/10.21437/Interspeech.2018-2032", 5, "interspeech", 2018]], "Jesin James": [0, ["An Open Source Emotional Speech Corpus for Human Robot Interaction Applications", ["Jesin James", "Li Tian", "Catherine Inez Watson"], "https://doi.org/10.21437/Interspeech.2018-1349", 5, "interspeech", 2018]], "Barbara E. Bullock": [0, ["Should Code-switching Models Be Asymmetric?", ["Barbara E. Bullock", "Gualberto A. Guzman", "Jacqueline Serigos", "Almeida Jacqueline Toribio"], "https://doi.org/10.21437/Interspeech.2018-1284", 5, "interspeech", 2018]], "Yang Cui": [0, ["A New Glottal Neural Vocoder for Speech Synthesis", ["Yang Cui", "Xi Wang", "Lei He", "Frank K. Soong"], "https://doi.org/10.21437/Interspeech.2018-1757", 5, "interspeech", 2018]], "Joshua Penney": [0, ["Weighting of Coda Voicing Cues: Glottalisation and Vowel Duration", ["Joshua Penney", "Felicity Cox", "Anita Szakay"], "https://doi.org/10.21437/Interspeech.2018-1677", 5, "interspeech", 2018]], "Karan Singla": [0, ["Using Prosodic and Lexical Information for Learning Utterance-level Behaviors in Psychotherapy", ["Karan Singla", "Zhuohao Chen", "Nikolaos Flemotomos", "James Gibson", "Dogan Can", "David C. Atkins", "Shrikanth Narayanan"], "https://doi.org/10.21437/Interspeech.2018-2551", 5, "interspeech", 2018]], "Ruiqing Yin": [0, ["Neural Speech Turn Segmentation and Affinity Propagation for Speaker Diarization", ["Ruiqing Yin", "Herve Bredin", "Claude Barras"], "https://doi.org/10.21437/Interspeech.2018-1750", 5, "interspeech", 2018]], "Phil Rose": [0, ["Dialect-geographical Acoustic-Tonetics: Five Disyllabic Tone Sandhi Patterns in Cognate Words from the Wu Dialects of Zh\u00e8Ji\u0101Ng Province", ["Phil Rose"], "https://doi.org/10.21437/Interspeech.2018-1130", 5, "interspeech", 2018]], "Longting Xu": [0, ["Co-whitening of I-vectors for Short and Long Duration Speaker Verification", ["Longting Xu", "Kong-Aik Lee", "Haizhou Li", "Zhen Yang"], "https://doi.org/10.21437/Interspeech.2018-1246", 5, "interspeech", 2018]], "Elnaz Shafaei-Bajestan": [0, ["Wide Learning for Auditory Comprehension", ["Elnaz Shafaei-Bajestan", "R. Harald Baayen"], "https://doi.org/10.21437/Interspeech.2018-2420", 5, "interspeech", 2018]], "Maharajan Chellapriyadharshini": [0, ["Semi-supervised and Active-learning Scenarios: Efficient Acoustic Model Refinement for a Low Resource Indian Language", ["Maharajan Chellapriyadharshini", "Anoop Toffy", "Srinivasa Raghavan K. M.", "V. Ramasubramanian"], "https://doi.org/10.21437/Interspeech.2018-2486", 5, "interspeech", 2018]], "Andreas Soeborg Kirkedal": [0, ["Multilingual Deep Neural Network Training Using Cyclical Learning Rate", ["Andreas Soeborg Kirkedal", "Yeon-Jun Kim"], "https://doi.org/10.21437/Interspeech.2018-1891", 5, "interspeech", 2018]], "Karel Vesely": [0, ["Lightly Supervised vs. Semi-supervised Training of Acoustic Model on Luxembourgish for Low-resource Automatic Speech Recognition", ["Karel Vesely", "Carlos Segura", "Igor Szoke", "Jordi Luque", "Jan Cernocky"], "https://doi.org/10.21437/Interspeech.2018-2361", 5, "interspeech", 2018]], "Haihua Xu": [0, ["Mandarin-English Code-switching Speech Recognition", ["Haihua Xu", "Van Tung Pham", "Zin Tun Kyaw", "Zhi Hao Lim", "Eng Siong Chng", "Haizhou Li"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3014.html", 2, "interspeech", 2018]], "Thomas Zenkel": [0, ["Subword and Crossword Units for CTC Acoustic Models", ["Thomas Zenkel", "Ramon Sanabria", "Florian Metze", "Alex Waibel"], "https://doi.org/10.21437/Interspeech.2018-2057", 5, "interspeech", 2018]], "Matthew C. Kelley": [0, ["A Comparison of Input Types to a Deep Neural Network-based Forced Aligner", ["Matthew C. Kelley", "Benjamin V. Tucker"], "https://doi.org/10.21437/Interspeech.2018-1115", 5, "interspeech", 2018]], "Subhadeep Dey": [0, ["End-to-end Text-dependent Speaker Verification Using Novel Distance Measures", ["Subhadeep Dey", "Srikanth R. Madikeri", "Petr Motlicek"], "https://doi.org/10.21437/Interspeech.2018-2300", 5, "interspeech", 2018]], "Stefan Braun": [0, ["Multi-channel Attention for End-to-End Speech Recognition", ["Stefan Braun", "Daniel Neil", "Jithendar Anumula", "Enea Ceolini", "Shih-Chii Liu"], "https://doi.org/10.21437/Interspeech.2018-1301", 5, "interspeech", 2018]], "Matthew Perez": [0, ["Classification of Huntington Disease Using Acoustic and Lexical Features", ["Matthew Perez", "Wenyu Jin", "Duc Le", "Noelle Carlozzi", "Praveen Dayalu", "Angela Roberts", "Emily Mower Provost"], "https://doi.org/10.21437/Interspeech.2018-2029", 5, "interspeech", 2018]], "Reza Lotfian": [0, ["Predicting Categorical Emotions by Jointly Learning Primary and Secondary Emotions through Multitask Learning", ["Reza Lotfian", "Carlos Busso"], "https://doi.org/10.21437/Interspeech.2018-2464", 5, "interspeech", 2018]], "Chenglin Xu": [0, ["A Shifted Delta Coefficient Objective for Monaural Speech Separation Using Multi-task Learning", ["Chenglin Xu", "Wei Rao", "Eng Siong Chng", "Haizhou Li"], "https://doi.org/10.21437/Interspeech.2018-1150", 5, "interspeech", 2018]], "William F. Katz": [0, ["Sensorimotor Response to Tongue Displacement Imagery by Talkers with Parkinson's Disease", ["William F. Katz", "Patrick Reidy", "Divya Prabhakaran"], "https://doi.org/10.21437/Interspeech.2018-2592", 5, "interspeech", 2018]], "Chao Weng": [0, ["Improving Attention Based Sequence-to-Sequence Models for End-to-End English Conversational Speech Recognition", ["Chao Weng", "Jia Cui", "Guangsen Wang", "Jun Wang", "Chengzhu Yu", "Dan Su", "Dong Yu"], "https://doi.org/10.21437/Interspeech.2018-1030", 5, "interspeech", 2018]], "Fahimeh Bahmaninezhad": [0, ["Compensation for Domain Mismatch in Text-independent Speaker Recognition", ["Fahimeh Bahmaninezhad", "John H. L. Hansen"], "https://doi.org/10.21437/Interspeech.2018-1446", 5, "interspeech", 2018]], "Piotr Zelasko": [0, ["Punctuation Prediction Model for Conversational Speech", ["Piotr Zelasko", "Piotr Szymanski", "Jan Mizgajski", "Adrian Szymczak", "Yishay Carmiel", "Najim Dehak"], "https://doi.org/10.21437/Interspeech.2018-1096", 5, "interspeech", 2018]], "Sadeen Alharbi": [0, ["A Lightly Supervised Approach to Detect Stuttering in Children's Speech", ["Sadeen Alharbi", "Madina Hasan", "Anthony J. H. Simons", "Shelagh Brumfitt", "Phil D. Green"], "https://doi.org/10.21437/Interspeech.2018-2155", 5, "interspeech", 2018]], "Hardik B. Sailor": [0, ["Auditory Filterbank Learning for Temporal Modulation Features in Replay Spoof Speech Detection", ["Hardik B. Sailor", "Madhu R. Kamble", "Hemant A. Patil"], "https://doi.org/10.21437/Interspeech.2018-1651", 5, "interspeech", 2018], ["Auditory Filterbank Learning Using ConvRBM for Infant Cry Classification", ["Hardik B. Sailor", "Hemant A. Patil"], "https://doi.org/10.21437/Interspeech.2018-1536", 5, "interspeech", 2018], ["DA-IICT/IIITV System for Low Resource Speech Recognition Challenge 2018", ["Hardik B. Sailor", "Maddala Venkata Siva Krishna", "Diksha Chhabra", "Ankur T. Patil", "Madhu R. Kamble", "Hemant A. Patil"], "https://doi.org/10.21437/Interspeech.2018-1553", 5, "interspeech", 2018]], "Nils Holzenberger": [0, ["Learning Word Embeddings: Unsupervised Methods for Fixed-size Representations of Variable-length Speech Segments", ["Nils Holzenberger", "Mingxing Du", "Julien Karadayi", "Rachid Riad", "Emmanuel Dupoux"], "https://doi.org/10.21437/Interspeech.2018-2364", 5, "interspeech", 2018]], "Phani Sankar Nidadavolu": [0, ["Investigation on Bandwidth Extension for Speaker Recognition", ["Phani Sankar Nidadavolu", "Cheng-I Lai", "Jesus Villalba", "Najim Dehak"], "https://doi.org/10.21437/Interspeech.2018-2394", 5, "interspeech", 2018]], "Gajan Suthokumar": [0, ["Modulation Dynamic Features for the Detection of Replay Attacks", ["Gajan Suthokumar", "Vidhyasaharan Sethu", "Chamith Wijenayake", "Eliathamby Ambikairajah"], "https://doi.org/10.21437/Interspeech.2018-1846", 5, "interspeech", 2018]], "Ke Tan": [0, ["A Convolutional Recurrent Neural Network for Real-Time Speech Enhancement", ["Ke Tan", "DeLiang Wang"], "https://doi.org/10.21437/Interspeech.2018-1405", 5, "interspeech", 2018], ["A Two-Stage Approach to Noisy Cochannel Speech Separation with Gated Residual Networks", ["Ke Tan", "DeLiang Wang"], "https://doi.org/10.21437/Interspeech.2018-1406", 5, "interspeech", 2018]], "Hirak Dasgupta": [0, ["Detection of Glottal Excitation Epochs in Speech Signal Using Hilbert Envelope", ["Hirak Dasgupta", "Prem C. Pandey", "K. S. Nataraj"], "https://doi.org/10.21437/Interspeech.2018-2014", 5, "interspeech", 2018]], "Purvi Agrawal": [0, ["Comparison of Unsupervised Modulation Filter Learning Methods for ASR", ["Purvi Agrawal", "Sriram Ganapathy"], "https://doi.org/10.21437/Interspeech.2018-1972", 5, "interspeech", 2018]], "Danny Merkx": [0, ["Articulatory Feature Classification Using Convolutional Neural Networks", ["Danny Merkx", "Odette Scharenborg"], "https://doi.org/10.21437/Interspeech.2018-2275", 5, "interspeech", 2018]], "Chris Davis": [0, ["Characterizing Rhythm Differences between Strong and Weak Accented L2 Speech", ["Chris Davis", "Jeesun Kim"], "https://doi.org/10.21437/Interspeech.2018-1798", 5, "interspeech", 2018]], "Michael Levit": [0, ["What to Expect from Expected Kneser-Ney Smoothing", ["Michael Levit", "Sarangarajan Parthasarathy", "Shuangyu Chang"], "https://doi.org/10.21437/Interspeech.2018-84", 5, "interspeech", 2018]], "Promod Yenigalla": [0, ["Speech Emotion Recognition Using Spectrogram & Phoneme Embedding", ["Promod Yenigalla", "Abhay Kumar", "Suraj Tripathi", "Chirag Singh", "Sibsambhu Kar", "Jithendra Vepa"], "https://doi.org/10.21437/Interspeech.2018-1811", 5, "interspeech", 2018]], "Chung-Cheng Chiu": [0, ["Speech Recognition for Medical Conversations", ["Chung-Cheng Chiu", "Anshuman Tripathi", "Katherine Chou", "Chris Co", "Navdeep Jaitly", "Diana Jaunzeikare", "Anjuli Kannan", "Patrick Nguyen", "Hasim Sak", "Ananth Sankar", "Justin Tansuwan", "Nathan Wan", "Yonghui Wu", "Xuedong Zhang"], "https://doi.org/10.21437/Interspeech.2018-40", 5, "interspeech", 2018]], "Yaxing Li": [0, ["Multi-frame Quantization of LSF Parameters Using a Deep Autoencoder and Pyramid Vector Quantizer", ["Yaxing Li", "Eshete Derb Emiru", "Shengwu Xiong", "Anna Zhu", "Pengfei Duan", "Yichang Li"], "https://doi.org/10.21437/Interspeech.2018-2577", 5, "interspeech", 2018], ["Multi-frame Coding of LSF Parameters Using Block-Constrained Trellis Coded Vector Quantization", ["Yaxing Li", "Shan Xu", "Shengwu Xiong", "Anna Zhu", "Pengfei Duan", "Yueming Ding"], "https://doi.org/10.21437/Interspeech.2018-2578", 5, "interspeech", 2018]], "Aswin Shanmugam Subramanian": [0, ["Student-Teacher Learning for BLSTM Mask-based Speech Enhancement", ["Aswin Shanmugam Subramanian", "Szu-Jui Chen", "Shinji Watanabe"], "https://doi.org/10.21437/Interspeech.2018-2440", 5, "interspeech", 2018]], "Ali Raza Syed": [0, ["Concatenative Resynthesis with Improved Training Signals for Speech Enhancement", ["Ali Raza Syed", "Viet Anh Trinh", "Michael I. Mandel"], "https://doi.org/10.21437/Interspeech.2018-2439", 5, "interspeech", 2018]], "Hangting Chen": [0, ["Deep Convolutional Neural Network with Scalogram for Audio Scene Modeling", ["Hangting Chen", "Pengyuan Zhang", "Haichuan Bai", "Qingsheng Yuan", "Xiuguo Bao", "Yonghong Yan"], "https://doi.org/10.21437/Interspeech.2018-1524", 5, "interspeech", 2018]], "Dominik Julg": [0, ["The CSU-K Rule-Based System for the 2nd Edition Spoken CALL Shared Task", ["Dominik Julg", "Mario Kunstek", "Cem Philipp Freimoser", "Kay Berkling", "Mengjie Qian"], "https://doi.org/10.21437/Interspeech.2018-1000", 5, "interspeech", 2018]], "Manu Airaksinen": [0, ["Time-regularized Linear Prediction for Noise-robust Extraction of the Spectral Envelope of Speech", ["Manu Airaksinen", "Lauri Juvela", "Okko Rasanen", "Paavo Alku"], "https://doi.org/10.21437/Interspeech.2018-1230", 5, "interspeech", 2018]], "Hongwei Song": [9.227629860220077e-08, ["A Compact and Discriminative Feature Based on Auditory Summary Statistics for Acoustic Scene Classification", ["Hongwei Song", "Jiqing Han", "Shiwen Deng"], "https://doi.org/10.21437/Interspeech.2018-1299", 5, "interspeech", 2018]], "Efthymios Tzinis": [0, ["Integrating Recurrence Dynamics for Speech Emotion Recognition", ["Efthymios Tzinis", "Georgios Paraskevopoulos", "Christos Baziotis", "Alexandros Potamianos"], "https://doi.org/10.21437/Interspeech.2018-1377", 5, "interspeech", 2018]], "Soumi Maiti": [0, ["Large Vocabulary Concatenative Resynthesis", ["Soumi Maiti", "Joey Ching", "Michael I. Mandel"], "https://doi.org/10.21437/Interspeech.2018-2383", 5, "interspeech", 2018]], "Deepak Baby": [0, ["Biophysically-inspired Features Improve the Generalizability of Neural Network-based Speech Enhancement Systems", ["Deepak Baby", "Sarah Verhulst"], "https://doi.org/10.21437/Interspeech.2018-1237", 5, "interspeech", 2018]], "Astha Singh": [0, ["Relating Articulatory Motions in Different Speaking Rates", ["Astha Singh", "G. Nisha Meenakshi", "Prasanta Kumar Ghosh"], "https://doi.org/10.21437/Interspeech.2018-1862", 5, "interspeech", 2018]], "Yang Yue": [0, ["Vowels and Diphthongs in Hangzhou Wu Chinese Dialect", ["Yang Yue", "Fang Hu"], "https://doi.org/10.21437/Interspeech.2018-1225", 5, "interspeech", 2018]], "Matthew Roddy": [0, ["Investigating Speech Features for Continuous Turn-Taking Prediction Using LSTMs", ["Matthew Roddy", "Gabriel Skantze", "Naomi Harte"], "https://doi.org/10.21437/Interspeech.2018-2124", 5, "interspeech", 2018]], "Jaesung Bae": [0.9978321045637131, ["End-to-End Speech Command Recognition with Capsule Network", ["Jaesung Bae", "Dae-Shik Kim"], "https://doi.org/10.21437/Interspeech.2018-1888", 5, "interspeech", 2018]], "Li Liu": [0, ["Visual Recognition of Continuous Cued Speech Using a Tandem CNN-HMM Approach", ["Li Liu", "Thomas Hueber", "Gang Feng", "Denis Beautemps"], "https://doi.org/10.21437/Interspeech.2018-2434", 5, "interspeech", 2018]], "Heini Kallio": [0, ["Prominence-based Evaluation of L2 Prosody", ["Heini Kallio", "Antti Suni", "Paivi Virkkunen", "Juraj Simko"], "https://doi.org/10.21437/Interspeech.2018-1873", 5, "interspeech", 2018]], "Anju Leela Thomas": [0, ["Code-switching in Indic Speech Synthesisers", ["Anju Leela Thomas", "Anusha Prakash", "Arun Baby", "Hema A. Murthy"], "https://doi.org/10.21437/Interspeech.2018-1178", 5, "interspeech", 2018]], "Jenny Yu": [7.454775868609431e-06, ["Truncation and Compression in Southern German and Australian English", ["Jenny Yu", "Katharina Zahner"], "https://doi.org/10.21437/Interspeech.2018-2513", 5, "interspeech", 2018]], "Ian Williams": [0, ["Contextual Speech Recognition in End-to-end Neural Network Systems Using Beam Search", ["Ian Williams", "Anjuli Kannan", "Petar S. Aleksic", "David Rybach", "Tara N. Sainath"], "https://doi.org/10.21437/Interspeech.2018-2416", 5, "interspeech", 2018]], "Bo-Hao Su": [0, ["Self-Assessed Affect Recognition Using Fusion of Attentional BLSTM and Static Acoustic Features", ["Bo-Hao Su", "Sung-Lin Yeh", "Ming-Ya Ko", "Huan-Yu Chen", "Shun-Chang Zhong", "Jeng-Lin Li", "Chi-Chun Lee"], "https://doi.org/10.21437/Interspeech.2018-2261", 5, "interspeech", 2018]], "Paul Kranzusch": [0, ["Prediction of Subjective Listening Effort from Acoustic Data with Non-Intrusive Deep Models", ["Paul Kranzusch", "Rainer Huber", "Melanie Kruger", "Birger Kollmeier", "Bernd T. Meyer"], "https://doi.org/10.21437/Interspeech.2018-1375", 5, "interspeech", 2018]], "Shaojin Ding": [0, ["Improving Sparse Representations in Exemplar-Based Voice Conversion with a Phoneme-Selective Objective Function", ["Shaojin Ding", "Guanlong Zhao", "Christopher Liberatore", "Ricardo Gutierrez-Osuna"], "https://doi.org/10.21437/Interspeech.2018-1272", 5, "interspeech", 2018], ["Learning Structured Dictionaries for Exemplar-based Voice Conversion", ["Shaojin Ding", "Christopher Liberatore", "Ricardo Gutierrez-Osuna"], "https://doi.org/10.21437/Interspeech.2018-1295", 5, "interspeech", 2018]], "Siyuan Feng": [0, ["Improving Cross-Lingual Knowledge Transferability Using Multilingual TDNN-BLSTM with Language-Dependent Pre-Final Layer", ["Siyuan Feng", "Tan Lee"], "https://doi.org/10.21437/Interspeech.2018-1182", 5, "interspeech", 2018], ["Exploiting Speaker and Phonetic Diversity of Mismatched Language Resources for Unsupervised Subword Modeling", ["Siyuan Feng", "Tan Lee"], "https://doi.org/10.21437/Interspeech.2018-1081", 5, "interspeech", 2018]], "Hui Xie": [0, ["Visual Timing Information in Audiovisual Speech Perception: Evidence from Lexical Tone Contour", ["Hui Xie", "Biao Zeng", "Rui Wang"], "https://doi.org/10.21437/Interspeech.2018-1285", 5, "interspeech", 2018]], "Nadee Seneviratne": [0, ["Noise Robust Acoustic to Articulatory Speech Inversion", ["Nadee Seneviratne", "Ganesh Sivaraman", "Vikramjit Mitra", "Carol Y. Espy-Wilson"], "https://doi.org/10.21437/Interspeech.2018-1509", 5, "interspeech", 2018]], "Natalia A. Tomashenko": [0, ["Speaker Adaptive Training and Mixup Regularization for Neural Network Acoustic Models in Automatic Speech Recognition", ["Natalia A. Tomashenko", "Yuri Y. Khokhlov", "Yannick Esteve"], "https://doi.org/10.21437/Interspeech.2018-2209", 5, "interspeech", 2018]], "Toru Nakashika": [0, ["LSTBM: A Novel Sequence Representation of Speech Spectra Using Restricted Boltzmann Machine with Long Short-Term Memory", ["Toru Nakashika"], "https://doi.org/10.21437/Interspeech.2018-1753", 5, "interspeech", 2018]], "Chiranjeevi Yarra": [0, ["SPIRE-SST: An Automatic Web-based Self-learning Tool for Syllable Stress Tutoring (SST) to the Second Language Learners", ["Chiranjeevi Yarra", "Anand P. A", "N. K. Kausthubha", "Prasanta Kumar Ghosh"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3009.html", 2, "interspeech", 2018]], "Toshiko Isei-Jaakkola": [0, ["Respiratory and Respiratory Muscular Control in JL1's and JL2's Text Reading Utilizing 4-RSTs and a Soft Respiratory Mask with a Two-Way Bulb", ["Toshiko Isei-Jaakkola", "Keiko Ochi", "Keikichi Hirose"], "https://doi.org/10.21437/Interspeech.2018-1948", 5, "interspeech", 2018]], "Anirudh Raju": [0, ["Contextual Language Model Adaptation for Conversational Agents", ["Anirudh Raju", "Behnam Hedayatnia", "Linda Liu", "Ankur Gandhe", "Chandra Khatri", "Angeliki Metallinou", "Anu Venkatesh", "Ariya Rastrow"], "https://doi.org/10.21437/Interspeech.2018-1122", 5, "interspeech", 2018]], "Aku Rouhe": [0, ["Captaina: Integrated Pronunciation Practice and Data Collection Portal", ["Aku Rouhe", "Reima Karhila", "Aija Elg", "Minnaleena Toivola", "Peter Smit", "Anna-Riikka Smolander", "Mikko Kurimo"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3015.html", 2, "interspeech", 2018]], "Kimiko Tsukada": [0, ["Cross-language Perception of Mandarin Lexical Tones by Mongolian-speaking Bilinguals in the Inner Mongolia Autonomous Region, China", ["Kimiko Tsukada", "Yu Rong"], "https://doi.org/10.21437/Interspeech.2018-48", 5, "interspeech", 2018]], "Markus Kitza": [0, ["Comparison of BLSTM-Layer-Specific Affine Transformations for Speaker Adaptation", ["Markus Kitza", "Ralf Schluter", "Hermann Ney"], "https://doi.org/10.21437/Interspeech.2018-2022", 5, "interspeech", 2018]], "Chitralekha Bhat": [0, ["Dysarthric Speech Recognition Using Time-delay Neural Network Based Denoising Autoencoder", ["Chitralekha Bhat", "Biswajit Das", "Bhavik Vachhani", "Sunil Kumar Kopparapu"], "https://doi.org/10.21437/Interspeech.2018-1754", 5, "interspeech", 2018]], "Srihari Maruthachalam": [0, ["Brain-Computer Interface using Electroencephalogram Signatures of Eye Blinks", ["Srihari Maruthachalam", "Sidharth Aggarwal", "Mari Ganesh Kumar", "Mriganka Sur", "Hema A. Murthy"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3019.html", 2, "interspeech", 2018]], "Ladislav Mosner": [0, ["Dereverberation and Beamforming in Robust Far-Field Speaker Recognition", ["Ladislav Mosner", "Oldrich Plchot", "Pavel Matejka", "Ondrej Novotny", "Jan Cernocky"], "https://doi.org/10.21437/Interspeech.2018-2306", 5, "interspeech", 2018]], "Yufan Du": [0, ["Measuring the Band Importance Function for Mandarin Chinese with a Bayesian Adaptive Procedure", ["Yufan Du", "Yi Shen", "Hongying Yang", "Xihong Wu", "Jing Chen"], "https://doi.org/10.21437/Interspeech.2018-1825", 5, "interspeech", 2018]], "Kaavya Sriskandaraja": [0, ["Deep Siamese Architecture Based Replay Detection for Secure Voice Biometric", ["Kaavya Sriskandaraja", "Vidhyasaharan Sethu", "Eliathamby Ambikairajah"], "https://doi.org/10.21437/Interspeech.2018-1819", 5, "interspeech", 2018]], "Danny Websdale": [0, ["The Effect of Real-Time Constraints on Automatic Speech Animation", ["Danny Websdale", "Sarah Taylor", "Ben Milner"], "https://doi.org/10.21437/Interspeech.2018-2066", 5, "interspeech", 2018]], "Andy Murphy": [0, ["Voice Source Contribution to Prominence Perception: Rd Implementation", ["Andy Murphy", "Irena Yanushevskaya", "Ailbhe Ni Chasaide", "Christer Gobl"], "https://doi.org/10.21437/Interspeech.2018-2352", 5, "interspeech", 2018]], "Ioana Vasilescu": [0, ["Exploring Temporal Reduction in Dialectal Spanish: A Large-scale Study of Lenition of Voiced Stops and Coda-s", ["Ioana Vasilescu", "Nidia Hernandez", "Bianca Vieru", "Lori Lamel"], "https://doi.org/10.21437/Interspeech.2018-1256", 5, "interspeech", 2018]], "Valter Akira Miasato Filho": [0, ["Joint Discriminative Embedding Learning, Speech Activity and Overlap Detection for the DIHARD Speaker Diarization Challenge", ["Valter Akira Miasato Filho", "Diego Augusto Silva", "Luis Gustavo Depra Cuozzo"], "https://doi.org/10.21437/Interspeech.2018-2304", 5, "interspeech", 2018]], "Mingkun Huang": [0, ["Knowledge Distillation for Sequence Model", ["Mingkun Huang", "Yongbin You", "Zhehuai Chen", "Yanmin Qian", "Kai Yu"], "https://doi.org/10.21437/Interspeech.2018-1589", 5, "interspeech", 2018]], "Franck Dernoncourt": [0, ["A Framework for Speech Recognition Benchmarking", ["Franck Dernoncourt", "Trung Bui", "Walter Chang"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3003.html", 2, "interspeech", 2018]], "Yuan Jia": [0, ["Stress Distribution of Given Information in Chinese Reading Texts", ["Yuan Jia", "Xiaoxiao Ma"], "https://doi.org/10.21437/Interspeech.2018-1602", 5, "interspeech", 2018]], "Kanru Hua": [0, ["Nebula: F0 Estimation and Voicing Detection by Modeling the Statistical Properties of Feature Extractors", ["Kanru Hua"], "https://doi.org/10.21437/Interspeech.2018-1258", 5, "interspeech", 2018]], "Zhaocheng Huang": [0, ["Depression Detection from Short Utterances via Diverse Smartphones in Natural Environmental Conditions", ["Zhaocheng Huang", "Julien Epps", "Dale Joachim", "Michael Chen"], "https://doi.org/10.21437/Interspeech.2018-1743", 5, "interspeech", 2018]], "Di He": [0, ["Improved ASR for Under-resourced Languages through Multi-task Learning with Acoustic Landmarks", ["Di He", "Boon Pang Lim", "Xuesong Yang", "Mark Hasegawa-Johnson", "Deming Chen"], "https://doi.org/10.21437/Interspeech.2018-1124", 5, "interspeech", 2018]], "P. V. Muhammed Shifas": [0, ["Speech Intelligibility Enhancement Based on a Non-causal Wavenet-like Model", ["P. V. Muhammed Shifas", "Vassilis Tsiaras", "Yannis Stylianou"], "https://doi.org/10.21437/Interspeech.2018-2119", 5, "interspeech", 2018]], "Evdokia Kazimirova": [0, ["Automatic Detection of Multi-speaker Fragments with High Time Resolution", ["Evdokia Kazimirova", "Andrey Belyaev"], "https://doi.org/10.21437/Interspeech.2018-1878", 5, "interspeech", 2018]], "Avashna Govender": [0, ["Using Pupillometry to Measure the Cognitive Load of Synthetic Speech", ["Avashna Govender", "Simon King"], "https://doi.org/10.21437/Interspeech.2018-1174", 5, "interspeech", 2018], ["Measuring the Cognitive Load of Synthetic Speech Using a Dual Task Paradigm", ["Avashna Govender", "Simon King"], "https://doi.org/10.21437/Interspeech.2018-1199", 5, "interspeech", 2018]], "Marija Tabain": [0, ["Formant Measures of Vowels Adjacent to Alveolar and Retroflex Consonants in Arrernte: Stressed and Unstressed Position", ["Marija Tabain", "Richard Beare", "Andrew Butcher"], "https://doi.org/10.21437/Interspeech.2018-1126", 5, "interspeech", 2018]], "Peter Sibbern Frederiksen": [0, ["Effectiveness of Single-Channel BLSTM Enhancement for Language Identification", ["Peter Sibbern Frederiksen", "Jesus Villalba", "Shinji Watanabe", "Zheng-Hua Tan", "Najim Dehak"], "https://doi.org/10.21437/Interspeech.2018-2458", 5, "interspeech", 2018]], "Sri Harish Reddy Mallidi": [0, ["Device-directed Utterance Detection", ["Sri Harish Reddy Mallidi", "Roland Maas", "Kyle Goehner", "Ariya Rastrow", "Spyros Matsoukas", "Bjorn Hoffmeister"], "https://doi.org/10.21437/Interspeech.2018-1531", 4, "interspeech", 2018]], "Shereen Oraby": [0, ["Neural MultiVoice Models for Expressing Novel Personalities in Dialog", ["Shereen Oraby", "Lena Reed", "Sharath T. S.", "Shubhangi Tandon", "Marilyn A. Walker"], "https://doi.org/10.21437/Interspeech.2018-2174", 5, "interspeech", 2018]], "Mostafa Ali Shahin": [0, ["Anomaly Detection Approach for Pronunciation Verification of Disordered Speech Using Speech Attribute Features", ["Mostafa Ali Shahin", "Beena Ahmed", "Jim X. Ji", "Kirrie J. Ballard"], "https://doi.org/10.21437/Interspeech.2018-1319", 5, "interspeech", 2018]], "Priya Pallavi": [0, ["Phase-locked Loop (PLL) Based Phase Estimation in Single Channel Speech Enhancement", ["Priya Pallavi", "Ch. V. Rama Rao"], "https://doi.org/10.21437/Interspeech.2018-1950", 4, "interspeech", 2018]], "Hiroki Murakami": [0, ["Naturalness Improvement Algorithm for Reconstructed Glossectomy Patient's Speech Using Spectral Differential Modification in Voice Conversion", ["Hiroki Murakami", "Sunao Hara", "Masanobu Abe", "Masaaki Sato", "Shogo Minagi"], "https://doi.org/10.21437/Interspeech.2018-1239", 5, "interspeech", 2018]], "Nima Mesgarani": [0, ["Speech Processing in the Human Brain Meets Deep Learning", ["Nima Mesgarani"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/4007.html", 1, "interspeech", 2018]], "Heysem Kaya": [0, ["LSTM Based Cross-corpus and Cross-task Acoustic Emotion Recognition", ["Heysem Kaya", "Dmitrii Fedotov", "Ali Yesilkanat", "Oxana Verkholyak", "Yang Zhang", "Alexey Karpov"], "https://doi.org/10.21437/Interspeech.2018-2298", 5, "interspeech", 2018]], "Imed Laaridh": [0, ["Automatic Evaluation of Speech Intelligibility Based on I-vectors in the Context of Head and Neck Cancers", ["Imed Laaridh", "Corinne Fredouille", "Alain Ghio", "Muriel Lalain", "Virginie Woisard"], "https://doi.org/10.21437/Interspeech.2018-1266", 5, "interspeech", 2018], ["Perceptual and Automatic Evaluations of the Intelligibility of Speech Degraded by Noise Induced Hearing Loss Simulation", ["Imed Laaridh", "Julien Tardieu", "Cynthia Magnen", "Pascal Gaillard", "Jerome Farinas", "Julien Pinquier"], "https://doi.org/10.21437/Interspeech.2018-1264", 5, "interspeech", 2018]], "Lauri Juvela": [0, ["Speaker-independent Raw Waveform Model for Glottal Excitation", ["Lauri Juvela", "Vassilis Tsiaras", "Bajibabu Bollepalli", "Manu Airaksinen", "Junichi Yamagishi", "Paavo Alku"], "https://doi.org/10.21437/Interspeech.2018-1635", 5, "interspeech", 2018]], "Alejandrina Cristia": [0, ["Talker Diarization in the Wild: the Case of Child-centered Daylong Audio-recordings", ["Alejandrina Cristia", "Shobhana Ganesh", "Marisa Casillas", "Sriram Ganapathy"], "https://doi.org/10.21437/Interspeech.2018-2078", 5, "interspeech", 2018]], "Deepanway Ghosal": [0, ["Music Genre Recognition Using Deep Neural Networks and Transfer Learning", ["Deepanway Ghosal", "Maheshkumar H. Kolekar"], "https://doi.org/10.21437/Interspeech.2018-2045", 5, "interspeech", 2018]], "Lianwu Chen": [0, ["Permutation Invariant Training of Generative Adversarial Network for Monaural Speech Separation", ["Lianwu Chen", "Meng Yu", "Yanmin Qian", "Dan Su", "Dong Yu"], "https://doi.org/10.21437/Interspeech.2018-1603", 5, "interspeech", 2018]], "Mahesh M": [0, ["Resyllabification in Indian Languages and Its Implications in Text-to-speech Systems", ["Mahesh M", "Jeena J. Prakash", "Hema A. Murthy"], "https://doi.org/10.21437/Interspeech.2018-1176", 5, "interspeech", 2018]], "Satoshi Tamura": [0, ["Audio-visual Voice Conversion Using Deep Canonical Correlation Analysis for Deep Bottleneck Features", ["Satoshi Tamura", "Kento Horio", "Hajime Endo", "Satoru Hayamizu", "Tomoki Toda"], "https://doi.org/10.21437/Interspeech.2018-2286", 5, "interspeech", 2018]], "Dheeraj Sai D. V. L. N": [0, ["Speech Source Separation Using ICA in Constant Q Transform Domain", ["Dheeraj Sai D. V. L. N", "Kishor K. S", "Sri Rama Murty Kodukula"], "https://doi.org/10.21437/Interspeech.2018-1732", 5, "interspeech", 2018]], "Jun Wang": [0.07243982143700123, ["Deep Extractor Network for Target Speaker Recovery from Single Channel Speech Mixtures", ["Jun Wang", "Jie Chen", "Dan Su", "Lianwu Chen", "Meng Yu", "Yanmin Qian", "Dong Yu"], "https://doi.org/10.21437/Interspeech.2018-1205", 5, "interspeech", 2018]], "Abinay Reddy N": [0, ["Reconstructing Neutral Speech from Tracheoesophageal Speech", ["Abinay Reddy N", "M. V. Achuth Rao", "G. Nisha Meenakshi", "Prasanta Kumar Ghosh"], "https://doi.org/10.21437/Interspeech.2018-1907", 5, "interspeech", 2018]], "Markus Muller": [0, ["Neural Language Codes for Multilingual Acoustic Models", ["Markus Muller", "Sebastian Stuker", "Alex Waibel"], "https://doi.org/10.21437/Interspeech.2018-1241", 5, "interspeech", 2018]], "Michael Wand": [0, ["Domain-Adversarial Training for Session Independent EMG-based Speech Recognition", ["Michael Wand", "Tanja Schultz", "Jurgen Schmidhuber"], "https://doi.org/10.21437/Interspeech.2018-2318", 5, "interspeech", 2018]], "Sheng Li": [0, ["Improving CTC-based Acoustic Model with Very Deep Residual Time-delay Neural Networks", ["Sheng Li", "Xugang Lu", "Ryoichi Takashima", "Peng Shen", "Tatsuya Kawahara", "Hisashi Kawai"], "https://doi.org/10.21437/Interspeech.2018-1475", 5, "interspeech", 2018]], "Bahman Mirheidari": [0, ["Detecting Signs of Dementia Using Word Vector Representations", ["Bahman Mirheidari", "Daniel Blackburn", "Traci Walker", "Annalena Venneri", "Markus Reuber", "Heidi Christensen"], "https://doi.org/10.21437/Interspeech.2018-1764", 5, "interspeech", 2018]], "Christer Gobl": [0, ["On the Relationship between Glottal Pulse Shape and Its Spectrum: Correlations of Open Quotient, Pulse Skew and Peak Flow with Source Harmonic Amplitudes", ["Christer Gobl", "Andy Murphy", "Irena Yanushevskaya", "Ailbhe Ni Chasaide"], "https://doi.org/10.21437/Interspeech.2018-2532", 5, "interspeech", 2018]], "Shao-Yen Tseng": [0, ["Multiple Instance Deep Learning for Weakly Supervised Small-Footprint Audio Event Detection", ["Shao-Yen Tseng", "Juncheng Li", "Yun Wang", "Florian Metze", "Joseph Szurley", "Samarjit Das"], "https://doi.org/10.21437/Interspeech.2018-1120", 5, "interspeech", 2018]], "Iroro Orife": [0, ["Attentive Sequence-to-Sequence Learning for Diacritic Restoration of Yor\u00f9B\u00e1 Language Text", ["Iroro Orife"], "https://doi.org/10.21437/Interspeech.2018-42", 5, "interspeech", 2018]], "Sahar Ghannay": [0, ["Task Specific Sentence Embeddings for ASR Error Detection", ["Sahar Ghannay", "Yannick Esteve", "Nathalie Camelin"], "https://doi.org/10.21437/Interspeech.2018-2211", 5, "interspeech", 2018]], "Viet Anh Trinh": [0, ["Bubble Cooperative Networks for Identifying Important Speech Cues", ["Viet Anh Trinh", "Brian McFee", "Michael I. Mandel"], "https://doi.org/10.21437/Interspeech.2018-2377", 5, "interspeech", 2018]], "Masayuki Suzuki": [0, ["Inference-Invariant Transformation of Batch Normalization for Domain Adaptation of Acoustic Models", ["Masayuki Suzuki", "Tohru Nagano", "Gakuto Kurata", "Samuel Thomas"], "https://doi.org/10.21437/Interspeech.2018-1563", 5, "interspeech", 2018]], "Markus Toman": [0, ["Data Requirements, Selection and Augmentation for DNN-based Speech Synthesis from Crowdsourced Data", ["Markus Toman", "Geoffrey S. Meltzner", "Rupal Patel"], "https://doi.org/10.21437/Interspeech.2018-1316", 5, "interspeech", 2018]], "Yu Wang": [0, ["Speaker Adaptation and Adaptive Training for Jointly Optimised Tandem Systems", ["Yu Wang", "Chao Zhang", "Mark J. F. Gales", "Philip C. Woodland"], "https://doi.org/10.21437/Interspeech.2018-2432", 5, "interspeech", 2018], ["A Deep Reinforcement Learning Based Multimodal Coaching Model (DCM) for Slot Filling in Spoken Language Understanding(SLU)", ["Yu Wang", "Abhishek Patel", "Yilin Shen", "Hongxia Jin"], "https://doi.org/10.21437/Interspeech.2018-1379", 5, "interspeech", 2018]], "Aaron Nicolson": [0, ["Bidirectional Long-Short Term Memory Network-based Estimation of Reliable Spectral Component Locations", ["Aaron Nicolson", "Kuldip K. Paliwal"], "https://doi.org/10.21437/Interspeech.2018-1134", 5, "interspeech", 2018]], "Moira-Phoebe Huet": [0, ["Who Are You Listening to? Towards a Dynamic Measure of Auditory Attention to Speech-on-speech", ["Moira-Phoebe Huet", "Christophe Micheyl", "Etienne Gaudrain", "Etienne Parizet"], "https://doi.org/10.21437/Interspeech.2018-2053", 4, "interspeech", 2018]], "Maida Percival": [0, ["An Ultrasound Study of Gemination in Coronal Stops in Eastern Oromo", ["Maida Percival", "Alexei Kochetov", "Yoonjung Kang"], "https://doi.org/10.21437/Interspeech.2018-2512", 5, "interspeech", 2018]], "Debadatta Dash": [0, ["Automatic Speech Recognition with Articulatory Information and a Unified Dictionary for Hindi, Marathi, Bengali and Oriya", ["Debadatta Dash", "Myung Jong Kim", "Kristin Teplansky", "Jun Wang"], "https://doi.org/10.21437/Interspeech.2018-2122", 5, "interspeech", 2018]], "Rui Liu": [0, ["Improving Mongolian Phrase Break Prediction by Using Syllable and Morphological Embeddings with BiLSTM Model", ["Rui Liu", "Feilong Bao", "Guanglai Gao", "Hui Zhang", "Yonghe Wang"], "https://doi.org/10.21437/Interspeech.2018-1706", 5, "interspeech", 2018]], "Da-Rong Liu": [0, ["Completely Unsupervised Phoneme Recognition by Adversarially Learning Mapping Relationships from Audio Embeddings", ["Da-Rong Liu", "Kuan-Yu Chen", "Hung-yi Lee", "Lin-Shan Lee"], "https://doi.org/10.21437/Interspeech.2018-1800", 5, "interspeech", 2018]], "Jinhwan Park": [0.9726525098085403, ["Hierarchical Recurrent Neural Networks for Acoustic Modeling", ["Jinhwan Park", "Iksoo Choi", "Yoonho Boo", "Wonyong Sung"], "https://doi.org/10.21437/Interspeech.2018-1797", 5, "interspeech", 2018]], "Ajay Srinivasamurthy": [0, ["Iterative Learning of Speech Recognition Models for Air Traffic Control", ["Ajay Srinivasamurthy", "Petr Motlicek", "Mittul Singh", "Youssef Oualil", "Matthias Kleinert", "Heiko Ehr", "Hartmut Helmke"], "https://doi.org/10.21437/Interspeech.2018-1447", 5, "interspeech", 2018]], "Andrea Bandini": [0, ["Automatic Detection of Orofacial Impairment in Stroke", ["Andrea Bandini", "Jordan R. Green", "Brian Richburg", "Yana Yunusova"], "https://doi.org/10.21437/Interspeech.2018-2475", 5, "interspeech", 2018]], "Myung Jong Kim": [0.9044821113348007, ["Dysarthric Speech Recognition Using Convolutional LSTM Neural Network", ["Myung Jong Kim", "Beiming Cao", "Kwanghoon An", "Jun Wang"], "https://doi.org/10.21437/Interspeech.2018-2250", 5, "interspeech", 2018]], "Xiaotong Zhang": [0, ["Imbalance Learning-based Framework for Fear Recognition in the MediaEval Emotional Impact of Movies Task", ["Xiaotong Zhang", "Xingliang Cheng", "Mingxing Xu", "Thomas Fang Zheng"], "https://doi.org/10.21437/Interspeech.2018-1744", 5, "interspeech", 2018]], "K. E. Manjunath": [0, ["Indian Languages ASR: A Multilingual Phone Recognition Framework with IPA Based Common Phone-set, Predicted Articulatory Features and Feature fusion", ["K. E. Manjunath", "K. Sreenivasa Rao", "Dinesh Babu Jayagopi", "V. Ramasubramanian"], "https://doi.org/10.21437/Interspeech.2018-2529", 5, "interspeech", 2018]], "Jian Huang": [0, ["Speech Emotion Recognition from Variable-Length Inputs with Triplet Loss Function", ["Jian Huang", "Ya Li", "Jianhua Tao", "Zhen Lian"], "https://doi.org/10.21437/Interspeech.2018-1432", 5, "interspeech", 2018]], "Joon Son Chung": [0.7989451438188553, ["VoxCeleb2: Deep Speaker Recognition", ["Joon Son Chung", "Arsha Nagrani", "Andrew Zisserman"], "https://doi.org/10.21437/Interspeech.2018-1929", 5, "interspeech", 2018]], "Arpita Gang": [3.9162862406141863e-13, ["Towards Automated Single Channel Source Separation Using Neural Networks", ["Arpita Gang", "Pravesh Biyani", "Akshay Soni"], "https://doi.org/10.21437/Interspeech.2018-2065", 5, "interspeech", 2018]], "Balamurali B. T": [0, ["Automated Classification of Vowel-Gesture Parameters Using External Broadband Excitation", ["Balamurali B. T", "Jer-Ming Chen"], "https://doi.org/10.21437/Interspeech.2018-1756", 4, "interspeech", 2018]], "Takafumi Moriya": [0, ["Multi-task Learning with Augmentation Strategy for Acoustic-to-word Attention-based Encoder-decoder Speech Recognition", ["Takafumi Moriya", "Sei Ueno", "Yusuke Shinohara", "Marc Delcroix", "Yoshikazu Yamaguchi", "Yushi Aono"], "https://doi.org/10.21437/Interspeech.2018-1866", 5, "interspeech", 2018]], "Gregory Sell": [0, ["Diarization is Hard: Some Experiences and Lessons Learned for the JHU Team in the Inaugural DIHARD Challenge", ["Gregory Sell", "David Snyder", "Alan McCree", "Daniel Garcia-Romero", "Jesus Villalba", "Matthew Maciejewski", "Vimal Manohar", "Najim Dehak", "Daniel Povey", "Shinji Watanabe", "Sanjeev Khudanpur"], "https://doi.org/10.21437/Interspeech.2018-1893", 5, "interspeech", 2018]], "Arindam Jati": [0, ["An Unsupervised Neural Prediction Framework for Learning Speaker Embeddings Using Recurrent Neural Networks", ["Arindam Jati", "Panayiotis G. Georgiou"], "https://doi.org/10.21437/Interspeech.2018-1363", 5, "interspeech", 2018]], "Xugang Lu": [0, ["Temporal Attentive Pooling for Acoustic Event Detection", ["Xugang Lu", "Peng Shen", "Sheng Li", "Yu Tsao", "Hisashi Kawai"], "https://doi.org/10.21437/Interspeech.2018-1552", 4, "interspeech", 2018]], "Xingfeng Li": [0, ["A Three-Layer Emotion Perception Model for Valence and Arousal-Based Detection from Multilingual Speech", ["Xingfeng Li", "Masato Akagi"], "https://doi.org/10.21437/Interspeech.2018-1820", 5, "interspeech", 2018]], "Dilek Hakkani-Tur": [0, ["Deep Learning based Situated Goal-oriented Dialogue Systems", ["Dilek Hakkani-Tur"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/4005.html", 1, "interspeech", 2018]], "Wenjing Han": [0.00020490603492362425, ["Towards Temporal Modelling of Categorical Speech Emotion Recognition", ["Wenjing Han", "Huabin Ruan", "Xiaomin Chen", "Zhixiang Wang", "Haifeng Li", "Bjorn W. Schuller"], "https://doi.org/10.21437/Interspeech.2018-1858", 5, "interspeech", 2018]], "Yoon Seok Hong": [0.9519332945346832, ["Automatic Miscue Detection Using RNN Based Models with Data Augmentation", ["Yoon Seok Hong", "Kyung Seo Ki", "Gahgene Gweon"], "https://doi.org/10.21437/Interspeech.2018-1644", 5, "interspeech", 2018]], "Yasuhito Ohsugi": [0, ["A Comparative Study of Statistical Conversion of Face to Voice Based on Their Subjective Impressions", ["Yasuhito Ohsugi", "Daisuke Saito", "Nobuaki Minematsu"], "https://doi.org/10.21437/Interspeech.2018-2005", 5, "interspeech", 2018]], "Kai-Zhan Lee": [2.626446352071987e-10, ["A Comparison of Speaker-based and Utterance-based Data Selection for Text-to-Speech Synthesis", ["Kai-Zhan Lee", "Erica Cooper", "Julia Hirschberg"], "https://doi.org/10.21437/Interspeech.2018-1313", 5, "interspeech", 2018]], "Vincent Renkens": [0, ["Capsule Networks for Low Resource Spoken Language Understanding", ["Vincent Renkens", "Hugo Van hamme"], "https://doi.org/10.21437/Interspeech.2018-1013", 5, "interspeech", 2018]], "Rachid Riad": [0, ["Sampling Strategies in Siamese Networks for Unsupervised Speech Representation Learning", ["Rachid Riad", "Corentin Dancette", "Julien Karadayi", "Neil Zeghidour", "Thomas Schatz", "Emmanuel Dupoux"], "https://doi.org/10.21437/Interspeech.2018-2384", 5, "interspeech", 2018]], "C. A. Valliappan": [0, ["Air-Tissue Boundary Segmentation in Real-Time Magnetic Resonance Imaging Video Using Semantic Segmentation with Fully Convolutional Networks", ["C. A. Valliappan", "Renuka Mannem", "Prasanta Kumar Ghosh"], "https://doi.org/10.21437/Interspeech.2018-1939", 5, "interspeech", 2018]], "Lanhua You": [0, ["Improved Supervised Locality Preserving Projection for I-vector Based Speaker Verification", ["Lanhua You", "Wu Guo", "Yan Song", "Sheng Zhang"], "https://doi.org/10.21437/Interspeech.2018-41", 5, "interspeech", 2018]], "Gabor Gosztolya": [0, ["General Utterance-Level Feature Extraction for Classifying Crying Sounds, Atypical & Self-Assessed Affect and Heart Beats", ["Gabor Gosztolya", "Tamas Grosz", "Laszlo Toth"], "https://doi.org/10.21437/Interspeech.2018-1076", 5, "interspeech", 2018], ["Identifying Schizophrenia Based on Temporal Parameters in Spontaneous Speech", ["Gabor Gosztolya", "Anita Bagi", "Szilvia Szaloki", "Istvan Szendi", "Ildiko Hoffmann"], "https://doi.org/10.21437/Interspeech.2018-1079", 5, "interspeech", 2018]], "Akshay Raj Maggu": [0, ["Learning Two Tone Languages Enhances the Brainstem Encoding of Lexical Tones", ["Akshay Raj Maggu", "Wenqing Zong", "Vina Law", "Patrick C. M. Wong"], "https://doi.org/10.21437/Interspeech.2018-2130", 5, "interspeech", 2018], ["Experience-dependent Influence of Music and Language on Lexical Pitch Learning Is Not Additive", ["Akshay Raj Maggu", "Patrick C. M. Wong", "Hanjun Liu", "Francis C. K. Wong"], "https://doi.org/10.21437/Interspeech.2018-2104", 4, "interspeech", 2018]], "Raffaele Tavarone": [0, ["Conditional-Computation-Based Recurrent Neural Networks for Computationally Efficient Acoustic Modelling", ["Raffaele Tavarone", "Leonardo Badino"], "https://doi.org/10.21437/Interspeech.2018-2195", 5, "interspeech", 2018]], "Sarthak Yadav": [0, ["Learning Discriminative Features for Speaker Identification and Verification", ["Sarthak Yadav", "Atul Rai"], "https://doi.org/10.21437/Interspeech.2018-1015", 5, "interspeech", 2018]], "Shuai Yang": [2.6364129013245474e-07, ["Detection of Glottal Closure Instants from Speech Signals: A Convolutional Neural Network Based Method", ["Shuai Yang", "Zhiyong Wu", "Binbin Shen", "Helen Meng"], "https://doi.org/10.21437/Interspeech.2018-1281", 5, "interspeech", 2018]], "Ivan Medennikov": [0, ["An Investigation of Mixup Training Strategies for Acoustic Models in ASR", ["Ivan Medennikov", "Yuri Y. Khokhlov", "Aleksei Romanenko", "Dmitry Popov", "Natalia A. Tomashenko", "Ivan Sorokin", "Alexander Zatvornitskiy"], "https://doi.org/10.21437/Interspeech.2018-2191", 5, "interspeech", 2018]], "Kwanchiva Thangthai": [0, ["Building Large-vocabulary Speaker-independent Lipreading Systems", ["Kwanchiva Thangthai", "Richard W. Harvey"], "https://doi.org/10.21437/Interspeech.2018-2112", 5, "interspeech", 2018]], "Ondrej Klejch": [0, ["Learning to Adapt: A Meta-learning Approach for Speaker Adaptation", ["Ondrej Klejch", "Joachim Fainberg", "Peter Bell"], "https://doi.org/10.21437/Interspeech.2018-1244", 5, "interspeech", 2018]], "Joo-Kyung Kim": [0.9997486770153046, ["Joint Learning of Domain Classification and Out-of-Domain Detection with Dynamic Class Weighting for Satisficing False Acceptance Rates", ["Joo-Kyung Kim", "Young-Bum Kim"], "https://doi.org/10.21437/Interspeech.2018-1581", 5, "interspeech", 2018]], "Masato Mimura": [0, ["Forward-Backward Attention Decoder", ["Masato Mimura", "Shinsuke Sakai", "Tatsuya Kawahara"], "https://doi.org/10.21437/Interspeech.2018-1160", 5, "interspeech", 2018]], "Guan-Ting Liou": [0, ["An Exploration of Local Speaking Rate Variations in Mandarin Read Speech", ["Guan-Ting Liou", "Chen-Yu Chiang", "Yih-Ru Wang", "Sin-Horng Chen"], "https://doi.org/10.21437/Interspeech.2018-1214", 5, "interspeech", 2018]], "Alice Baird": [0, ["The Perception and Analysis of the Likeability and Human Likeness of Synthesized Speech", ["Alice Baird", "Emilia Parada-Cabaleiro", "Simone Hantke", "Felix Burkhardt", "Nicholas Cummins", "Bjorn W. Schuller"], "https://doi.org/10.21437/Interspeech.2018-1093", 5, "interspeech", 2018]], "Ziwei Zhu": [0, ["Siamese Recurrent Auto-Encoder Representation for Query-by-Example Spoken Term Detection", ["Ziwei Zhu", "Zhiyong Wu", "Runnan Li", "Helen Meng", "Lianhong Cai"], "https://doi.org/10.21437/Interspeech.2018-1788", 5, "interspeech", 2018]], "Chia-Hsuan Lee": [6.758944295361894e-15, ["Spoken SQuAD: A Study of Mitigating the Impact of Speech Recognition Errors on Listening Comprehension", ["Chia-Hsuan Lee", "Szu-Lin Wu", "Chi-Liang Liu", "Hung-yi Lee"], "https://doi.org/10.21437/Interspeech.2018-1714", 5, "interspeech", 2018]], "Grant P. Strimel": [0, ["Statistical Model Compression for Small-Footprint Natural Language Understanding", ["Grant P. Strimel", "Kanthashree Mysore Sathyendra", "Stanislav Peshterliev"], "https://doi.org/10.21437/Interspeech.2018-1333", 5, "interspeech", 2018]], "Ju-Chieh Chou": [0, ["Multi-target Voice Conversion without Parallel Data by Adversarially Learning Disentangled Audio Representations", ["Ju-Chieh Chou", "Cheng-chieh Yeh", "Hung-yi Lee", "Lin-Shan Lee"], "https://doi.org/10.21437/Interspeech.2018-1830", 5, "interspeech", 2018]], "Pulkit Sharma": [0, ["ASe: Acoustic Scene Embedding Using Deep Archetypal Analysis and GMM", ["Pulkit Sharma", "Vinayak Abrol", "Anshul Thakur"], "https://doi.org/10.21437/Interspeech.2018-1481", 5, "interspeech", 2018]], "Triantafyllos Afouras": [0, ["The Conversation: Deep Audio-Visual Speech Enhancement", ["Triantafyllos Afouras", "Joon Son Chung", "Andrew Zisserman"], "https://doi.org/10.21437/Interspeech.2018-1400", 5, "interspeech", 2018], ["Deep Lip Reading: A Comparison of Models and an Online Application", ["Triantafyllos Afouras", "Joon Son Chung", "Andrew Zisserman"], "https://doi.org/10.21437/Interspeech.2018-1943", 5, "interspeech", 2018]], "Suyoun Kim": [0.9995113462209702, ["Improved Training for Online End-to-end Speech Recognition Systems", ["Suyoun Kim", "Michael L. Seltzer", "Jinyu Li", "Rui Zhao"], "https://doi.org/10.21437/Interspeech.2018-2517", 5, "interspeech", 2018]], "Shiliang Zhang": [0, ["Acoustic Modeling with DFSMN-CTC and Joint CTC-CE Learning", ["Shiliang Zhang", "Ming Lei"], "https://doi.org/10.21437/Interspeech.2018-1049", 5, "interspeech", 2018]], "Wei Li": [0, ["Fast Derivation of Cross-lingual Document Vectors from Self-attentive Neural Machine Translation Model", ["Wei Li", "Brian Mak"], "https://doi.org/10.21437/Interspeech.2018-1459", 5, "interspeech", 2018]], "Jindrich Matousek": [0, ["Glottal Closure Instant Detection from Speech Signal Using Voting Classifier and Recursive Feature Elimination", ["Jindrich Matousek", "Daniel Tihelka"], "https://doi.org/10.21437/Interspeech.2018-1147", 5, "interspeech", 2018]], "Debayan Ghosh": [0, ["Robust Voice Activity Detection Using Frequency Domain Long-Term Differential Entropy", ["Debayan Ghosh", "Muralishankar R", "Sanjeev Gurugopinath"], "https://doi.org/10.21437/Interspeech.2018-1431", 5, "interspeech", 2018]], "John Kim": [1, ["Emotion Recognition from Human Speech Using Temporal Information and Deep Learning", ["John Kim", "Rif A. Saurous"], "https://doi.org/10.21437/Interspeech.2018-1132", 4, "interspeech", 2018]], "Yougen Yuan": [0, ["Learning Acoustic Word Embeddings with Temporal Context for Query-by-Example Speech Search", ["Yougen Yuan", "Cheung-Chi Leung", "Lei Xie", "Hongjie Chen", "Bin Ma", "Haizhou Li"], "https://doi.org/10.21437/Interspeech.2018-1010", 5, "interspeech", 2018]], "Chengzhu Yu": [1.484971062382101e-05, ["A Multistage Training Framework for Acoustic-to-Word Model", ["Chengzhu Yu", "Chunlei Zhang", "Chao Weng", "Jia Cui", "Dong Yu"], "https://doi.org/10.21437/Interspeech.2018-1452", 5, "interspeech", 2018]], "Zbynek Zajic": [0, ["ZCU-NTIS Speaker Diarization System for the DIHARD 2018 Challenge", ["Zbynek Zajic", "Marie Kunesova", "Jan Zelinka", "Marek Hruz"], "https://doi.org/10.21437/Interspeech.2018-1252", 5, "interspeech", 2018]], "Vera Cabarrao": [0, ["Acoustic-prosodic Entrainment in Structural Metadata Events", ["Vera Cabarrao", "Fernando Batista", "Helena Moniz", "Isabel Trancoso", "Ana Isabel Mata"], "https://doi.org/10.21437/Interspeech.2018-2366", 5, "interspeech", 2018]], "Louis ten Bosch": [0, ["Analyzing Reaction Time Sequences from Human Participants in Auditory Experiments", ["Louis ten Bosch", "Mirjam Ernestus", "Lou Boves"], "https://doi.org/10.21437/Interspeech.2018-1728", 5, "interspeech", 2018], ["Information Encoding by Deep Neural Networks: What Can We Learn?", ["Louis ten Bosch", "Lou Boves"], "https://doi.org/10.21437/Interspeech.2018-1896", 5, "interspeech", 2018]], "Claude Montacie": [0, ["Vocalic, Lexical and Prosodic Cues for the INTERSPEECH 2018 Self-Assessed Affect Challenge", ["Claude Montacie", "Marie-Jose Caraty"], "https://doi.org/10.21437/Interspeech.2018-1331", 5, "interspeech", 2018]], "Prasanna V. Kothalkar": [0, ["Fusing Text-dependent Word-level i-Vector Models to Screen 'at Risk' Child Speech", ["Prasanna V. Kothalkar", "Johanna Rudolph", "Christine Dollaghan", "Jennifer McGlothlin", "Thomas F. Campbell", "John H. L. Hansen"], "https://doi.org/10.21437/Interspeech.2018-1465", 5, "interspeech", 2018]], "Sining Sun": [0.010369112715125084, ["Training Augmentation with Adversarial Examples for Robust Speech Recognition", ["Sining Sun", "Ching-Feng Yeh", "Mari Ostendorf", "Mei-Yuh Hwang", "Lei Xie"], "https://doi.org/10.21437/Interspeech.2018-1247", 5, "interspeech", 2018]], "Kishalay Chakraborty": [0, ["Glotto Vibrato Graph: A Device and Method for Recording, Analysis and Visualization of Glottal Activity", ["Kishalay Chakraborty", "Senjam Shantirani Devi", "Sanjeevan Devnath", "S. R. Mahadeva Prasanna", "Priyankoo Sarmah"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3046.html", 2, "interspeech", 2018]], "Cong Zhou": [0, ["Voice Conversion with Conditional SampleRNN", ["Cong Zhou", "Michael Horgan", "Vivek Kumar", "Cristina Vasco", "Dan Darcy"], "https://doi.org/10.21437/Interspeech.2018-1121", 5, "interspeech", 2018]], "Kevin Vythelingum": [0, ["Acoustic-dependent Phonemic Transcription for Text-to-speech Synthesis", ["Kevin Vythelingum", "Yannick Esteve", "Olivier Rosec"], "https://doi.org/10.21437/Interspeech.2018-1306", 5, "interspeech", 2018]], "Ravi Shankar": [0, ["Spoken Keyword Detection Using Joint DTW-CNN", ["Ravi Shankar", "Vikram C. M.", "S. R. Mahadeva Prasanna"], "https://doi.org/10.21437/Interspeech.2018-1436", 5, "interspeech", 2018]], "Luciana Ferrer": [0, ["A Generalization of PLDA for Joint Modeling of Speaker Identity and Multiple Nuisance Conditions", ["Luciana Ferrer", "Mitchell McLaren"], "https://doi.org/10.21437/Interspeech.2018-1280", 5, "interspeech", 2018]], "Liwen Zhang": [0, ["Unsupervised Temporal Feature Learning Based on Sparse Coding Embedded BoAW for Acoustic Event Recognition", ["Liwen Zhang", "Jiqing Han", "Shiwen Deng"], "https://doi.org/10.21437/Interspeech.2018-1243", 5, "interspeech", 2018]], "Kate Knill": [0, ["Impact of ASR Performance on Free Speaking Language Assessment", ["Kate Knill", "Mark J. F. Gales", "Konstantinos Kyriakopoulos", "Andrey Malinin", "Anton Ragni", "Yu Wang", "Andrew Caines"], "https://doi.org/10.21437/Interspeech.2018-1312", 5, "interspeech", 2018]], "Juntae Kim": [0.9839552938938141, ["Korean Singing Voice Synthesis Based on an LSTM Recurrent Neural Network", ["Juntae Kim", "Heejin Choi", "Jinuk Park", "Minsoo Hahn", "Sang-Jin Kim", "Jong-Jin Kim"], "https://doi.org/10.21437/Interspeech.2018-1575", 5, "interspeech", 2018]], "Lili Guo": [0, ["Speech Emotion Recognition by Combining Amplitude and Phase Information Using Convolutional Neural Network", ["Lili Guo", "Longbiao Wang", "Jianwu Dang", "Linjuan Zhang", "Haotian Guan", "Xiangang Li"], "https://doi.org/10.21437/Interspeech.2018-2156", 5, "interspeech", 2018]], "Benjamin Milde": [0, ["Unspeech: Unsupervised Speech Context Embeddings", ["Benjamin Milde", "Chris Biemann"], "https://doi.org/10.21437/Interspeech.2018-2194", 5, "interspeech", 2018]], "Teng Zhang": [0, ["Temporal Transformer Networks for Acoustic Scene Classification", ["Teng Zhang", "Kailai Zhang", "Ji Wu"], "https://doi.org/10.21437/Interspeech.2018-1152", 5, "interspeech", 2018], ["Data Independent Sequence Augmentation Method for Acoustic Scene Classification", ["Teng Zhang", "Kailai Zhang", "Ji Wu"], "https://doi.org/10.21437/Interspeech.2018-1250", 5, "interspeech", 2018], ["Multi-modal Attention Mechanisms in LSTM and Its Application to Acoustic Scene Classification", ["Teng Zhang", "Kailai Zhang", "Ji Wu"], "https://doi.org/10.21437/Interspeech.2018-1138", 5, "interspeech", 2018]], "Laszlo Toth": [0, ["Multi-Task Learning of Speech Recognition and Speech Synthesis Parameters for Ultrasound-based Silent Speech Interfaces", ["Laszlo Toth", "Gabor Gosztolya", "Tamas Grosz", "Alexandra Marko", "Tamas Gabor Csapo"], "https://doi.org/10.21437/Interspeech.2018-1078", 5, "interspeech", 2018]], "Aviv Gabbay": [0, ["Visual Speech Enhancement", ["Aviv Gabbay", "Asaph Shamir", "Shmuel Peleg"], "https://doi.org/10.21437/Interspeech.2018-1955", 5, "interspeech", 2018]], "Amber Afshan": [0, ["Effectiveness of Voice Quality Features in Detecting Depression", ["Amber Afshan", "Jinxi Guo", "Soo Jin Park", "Vijay Ravi", "Jonathan Flint", "Abeer Alwan"], "https://doi.org/10.21437/Interspeech.2018-1399", 5, "interspeech", 2018]], "Sishir Kalita": [0, ["Self-similarity Matrix Based Intelligibility Assessment of Cleft Lip and Palate Speech", ["Sishir Kalita", "S. R. Mahadeva Prasanna", "Samarendra Dandapat"], "https://doi.org/10.21437/Interspeech.2018-1125", 5, "interspeech", 2018]], "Jeesun Kim": [0.9742622375488281, ["Investigating the Role of Familiar Face and Voice Cues in Speech Processing in Noise", ["Jeesun Kim", "Sonya Karisma", "Vincent Aubanel", "Chris Davis"], "https://doi.org/10.21437/Interspeech.2018-1812", 4, "interspeech", 2018]], "Chong Cao": [0, ["Interactions between Vowels and Nasal Codas in Mandarin Speakers' Perception of Nasal Finals", ["Chong Cao", "Wei Wei", "Wei Wang", "Yanlu Xie", "Jinsong Zhang"], "https://doi.org/10.21437/Interspeech.2018-2025", 5, "interspeech", 2018]], "Lyan Verwimp": [0, ["State Gradients for RNN Memory Analysis", ["Lyan Verwimp", "Hugo Van hamme", "Vincent Renkens", "Patrick Wambacq"], "https://doi.org/10.21437/Interspeech.2018-1153", 5, "interspeech", 2018]], "Zhiheng Ouyang": [0, ["A Deep Neural Network Based Harmonic Noise Model for Speech Enhancement", ["Zhiheng Ouyang", "Hongjiang Yu", "Wei-Ping Zhu", "Benoit Champagne"], "https://doi.org/10.21437/Interspeech.2018-1114", 5, "interspeech", 2018]], "Eva Fringi": [0, ["Analysis of Phone Errors Attributable to Phonological Effects Associated With Language Acquisition Through Bottleneck Feature Visualisations", ["Eva Fringi", "Martin J. Russell"], "https://doi.org/10.21437/Interspeech.2018-2422", 5, "interspeech", 2018]], "Anshul Thakur": [0, ["Deep Convex Representations: Feature Representations for Bioacoustics Classification", ["Anshul Thakur", "Vinayak Abrol", "Pulkit Sharma", "Padmanabhan Rajan"], "https://doi.org/10.21437/Interspeech.2018-1705", 5, "interspeech", 2018]], "Jee-weon Jung": [0.9995425939559937, ["Avoiding Speaker Overfitting in End-to-End DNNs Using Raw Waveform for Text-Independent Speaker Verification", ["Jee-weon Jung", "Hee-Soo Heo", "Il-Ho Yang", "Hye-jin Shim", "Ha-Jin Yu"], "https://doi.org/10.21437/Interspeech.2018-1608", 5, "interspeech", 2018]], "Xiaoke Qi": [0, ["Sparsity-Constrained Weight Mapping for Head-Related Transfer Functions Individualization from Anthropometric Features", ["Xiaoke Qi", "Jianhua Tao"], "https://doi.org/10.21437/Interspeech.2018-1615", 5, "interspeech", 2018]], "Cong-Thanh Do": [3.3881790386658395e-06, ["Weighting Time-Frequency Representation of Speech Using Auditory Saliency for Automatic Speech Recognition", ["Cong-Thanh Do", "Yannis Stylianou"], "https://doi.org/10.21437/Interspeech.2018-1721", 5, "interspeech", 2018]], "Lorenzo Spreafico": [0, ["UltraFit: A Speaker-friendly Headset for Ultrasound Recordings in Speech Science", ["Lorenzo Spreafico", "Michael Pucher", "Anna Matosova"], "https://doi.org/10.21437/Interspeech.2018-995", 4, "interspeech", 2018]], "Lukas Drude": [0, ["Integrating Neural Network Based Beamforming and Weighted Prediction Error Dereverberation", ["Lukas Drude", "Christoph Boddeker", "Jahn Heymann", "Reinhold Haeb-Umbach", "Keisuke Kinoshita", "Marc Delcroix", "Tomohiro Nakatani"], "https://doi.org/10.21437/Interspeech.2018-2196", 5, "interspeech", 2018]], "Ji-Chen Yang": [0.00023265991330845281, ["Feature with Complementarity of Statistics and Principal Information for Spoofing Detection", ["Ji-Chen Yang", "Changhuai You", "Qianhua He"], "https://doi.org/10.21437/Interspeech.2018-1693", 5, "interspeech", 2018]], "Alexander Koller": [0, ["DialogOS: Simple and Extensible Dialogue Modeling", ["Alexander Koller", "Timo Baumann", "Arne Kohn"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3002.html", 2, "interspeech", 2018]], "Arijit Biswas": [0, ["Temporal Noise Shaping with Companding", ["Arijit Biswas", "Per Hedelin", "Lars F. Villemoes", "Vinay Melkote"], "https://doi.org/10.21437/Interspeech.2018-2096", 5, "interspeech", 2018]], "Jiacen Zhang": [0, ["I-vector Transformation Using Conditional Generative Adversarial Networks for Short Utterance Speaker Verification", ["Jiacen Zhang", "Nakamasa Inoue", "Koichi Shinoda"], "https://doi.org/10.21437/Interspeech.2018-1680", 5, "interspeech", 2018]], "Hao Tang": [0, ["A Study of Enhancement, Augmentation and Autoencoder Methods for Domain Adaptation in Distant Speech Recognition", ["Hao Tang", "Wei-Ning Hsu", "Francois Grondin", "James R. Glass"], "https://doi.org/10.21437/Interspeech.2018-2030", 5, "interspeech", 2018]], "Fu-Sheng Tsai": [0, ["Automatic Assessment of Individual Culture Attribute of Power Distance Using a Social Context-Enhanced Prosodic Network Representation", ["Fu-Sheng Tsai", "Hao-Chun Yang", "Wei-Wen Chang", "Chi-Chun Lee"], "https://doi.org/10.21437/Interspeech.2018-1523", 5, "interspeech", 2018]], "Bekir Berker Turker": [0, ["Audio-Visual Prediction of Head-Nod and Turn-Taking Events in Dyadic Interactions", ["Bekir Berker Turker", "Engin Erzin", "Yucel Yemez", "T. Metin Sezgin"], "https://doi.org/10.21437/Interspeech.2018-2215", 5, "interspeech", 2018]], "Zixing Zhang": [0, ["Evolving Learning for Analysing Mood-Related Infant Vocalisation", ["Zixing Zhang", "Jing Han", "Kun Qian", "Bjorn W. Schuller"], "https://doi.org/10.21437/Interspeech.2018-1914", 5, "interspeech", 2018], ["Automated Classification of Children's Linguistic versus Non-Linguistic Vocalisations", ["Zixing Zhang", "Alejandrina Cristia", "Anne A. Warlaumont", "Bjorn W. Schuller"], "https://doi.org/10.21437/Interspeech.2018-2523", 5, "interspeech", 2018]], "Jianwei Yu": [1.7882772346267117e-10, ["Development of the CUHK Dysarthric Speech Recognition System for the UA Speech Corpus", ["Jianwei Yu", "Xurong Xie", "Shansong Liu", "Shoukang Hu", "Max W. Y. Lam", "Xixin Wu", "Ka Ho Wong", "Xunying Liu", "Helen Meng"], "https://doi.org/10.21437/Interspeech.2018-1541", 5, "interspeech", 2018]], "Oliver Watts": [0, ["Exemplar-based Speech Waveform Generation", ["Oliver Watts", "Cassia Valentini-Botinhao", "Felipe Espic", "Simon King"], "https://doi.org/10.21437/Interspeech.2018-1857", 5, "interspeech", 2018]], "Lionel Fontan": [0, ["Automatically Measuring L2 Speech Fluency without the Need of ASR: A Proof-of-concept Study with Japanese Learners of French", ["Lionel Fontan", "Maxime Le Coz", "Sylvain Detey"], "https://doi.org/10.21437/Interspeech.2018-1336", 5, "interspeech", 2018]], "Zhifu Gao": [0, ["An Improved Deep Embedding Learning Method for Short Duration Speaker Verification", ["Zhifu Gao", "Yan Song", "Ian Vince McLoughlin", "Wu Guo", "Lirong Dai"], "https://doi.org/10.21437/Interspeech.2018-1515", 5, "interspeech", 2018]], "Tiphaine Caudrelier": [0, ["Picture Naming or Word Reading: Does the Modality Affect Speech Motor Adaptation and Its Transfer?", ["Tiphaine Caudrelier", "Pascal Perrier", "Jean-Luc Schwartz", "Amelie Rochet-Capellan"], "https://doi.org/10.21437/Interspeech.2018-1760", 5, "interspeech", 2018]], "Matthew Wiesner": [0, ["Automatic Speech Recognition and Topic Identification from Speech for Almost-Zero-Resource Languages", ["Matthew Wiesner", "Chunxi Liu", "Lucas Ondel", "Craig Harman", "Vimal Manohar", "Jan Trmal", "Zhongqiang Huang", "Najim Dehak", "Sanjeev Khudanpur"], "https://doi.org/10.21437/Interspeech.2018-1836", 5, "interspeech", 2018]], "Xu Li": [0, ["Unsupervised Discovery of Non-native Phonetic Patterns in L2 English Speech for Mispronunciation Detection and Diagnosis", ["Xu Li", "Shaoguang Mao", "Xixin Wu", "Kun Li", "Xunying Liu", "Helen Meng"], "https://doi.org/10.21437/Interspeech.2018-2027", 5, "interspeech", 2018]], "Atsushi Ando": [0, ["Automatic Question Detection from Acoustic and Phonetic Features Using Feature-wise Pre-training", ["Atsushi Ando", "Reine Asakawa", "Ryo Masumura", "Hosana Kamiyama", "Satoshi Kobashikawa", "Yushi Aono"], "https://doi.org/10.21437/Interspeech.2018-1755", 5, "interspeech", 2018]], "Pankaj Joshi": [0, ["Time Aggregation Operators for Multi-label Audio Event Detection", ["Pankaj Joshi", "Digvijaysingh Gautam", "Ganesh Ramakrishnan", "Preethi Jyothi"], "https://doi.org/10.21437/Interspeech.2018-1637", 5, "interspeech", 2018]], "Pierre Godard": [0, ["Unsupervised Word Segmentation from Speech with Attention", ["Pierre Godard", "Marcely Zanon Boito", "Lucas Ondel", "Alexandre Berard", "Francois Yvon", "Aline Villavicencio", "Laurent Besacier"], "https://doi.org/10.21437/Interspeech.2018-1308", 5, "interspeech", 2018]], "Titouan Parcollet": [0, ["Quaternion Convolutional Neural Networks for End-to-End Automatic Speech Recognition", ["Titouan Parcollet", "Ying Zhang", "Mohamed Morchid", "Chiheb Trabelsi", "Georges Linares", "Renato de Mori", "Yoshua Bengio"], "https://doi.org/10.21437/Interspeech.2018-1898", 5, "interspeech", 2018]], "Saketh Sharma": [0, ["Implementation of Digital Hearing Aid as a Smartphone Application", ["Saketh Sharma", "Nitya Tiwari", "Prem C. Pandey"], "https://doi.org/10.21437/Interspeech.2018-2031", 5, "interspeech", 2018]], "Mireia Diez": [0, ["BUT System for DIHARD Speech Diarization Challenge 2018", ["Mireia Diez", "Federico Landini", "Lukas Burget", "Johan Rohdin", "Anna Silnova", "Katerina Zmolikova", "Ondrej Novotny", "Karel Vesely", "Ondrej Glembek", "Oldrich Plchot", "Ladislav Mosner", "Pavel Matejka"], "https://doi.org/10.21437/Interspeech.2018-1749", 5, "interspeech", 2018]], "Juan Camilo Vasquez-Correa": [0, ["A Multitask Learning Approach to Assess the Dysarthria Severity in Patients with Parkinson's Disease", ["Juan Camilo Vasquez-Correa", "Tomas Arias-Vergara", "Juan Rafael Orozco-Arroyave", "Elmar Noth"], "https://doi.org/10.21437/Interspeech.2018-1988", 5, "interspeech", 2018]], "Tomoya Yanagita": [0, ["Incremental TTS for Japanese Language", ["Tomoya Yanagita", "Sakriani Sakti", "Satoshi Nakamura"], "https://doi.org/10.21437/Interspeech.2018-1561", 5, "interspeech", 2018]], "Jian Tang": [0, ["Acoustic Modeling with Densely Connected Residual Network for Multichannel Speech Recognition", ["Jian Tang", "Yan Song", "Lirong Dai", "Ian Vince McLoughlin"], "https://doi.org/10.21437/Interspeech.2018-1089", 5, "interspeech", 2018]], "Fei Tao": [0, ["Audiovisual Speech Activity Detection with Advanced Long Short-Term Memory", ["Fei Tao", "Carlos Busso"], "https://doi.org/10.21437/Interspeech.2018-2490", 5, "interspeech", 2018]], "Yusuke Inoue": [0, ["A Study of Objective Measurement of Comprehensibility through Native Speakers' Shadowing of Learners' Utterances", ["Yusuke Inoue", "Suguru Kabashima", "Daisuke Saito", "Nobuaki Minematsu", "Kumi Kanamura", "Yutaka Yamauchi"], "https://doi.org/10.21437/Interspeech.2018-1860", 5, "interspeech", 2018]], "Szu-Wei Fu": [0, ["Quality-Net: An End-to-End Non-intrusive Speech Quality Assessment Model Based on BLSTM", ["Szu-Wei Fu", "Yu Tsao", "Hsin-Te Hwang", "Hsin-Min Wang"], "https://doi.org/10.21437/Interspeech.2018-1802", 5, "interspeech", 2018]], "Kentaro Sone": [0, ["DNN-based Speech Synthesis for Small Data Sets Considering Bidirectional Speech-Text Conversion", ["Kentaro Sone", "Toru Nakashika"], "https://doi.org/10.21437/Interspeech.2018-1460", 5, "interspeech", 2018]], "Sergey Novoselov": [0, ["Triplet Loss Based Cosine Similarity Metric Learning for Text-independent Speaker Recognition", ["Sergey Novoselov", "Vadim Shchemelinin", "Andrey Shulipa", "Alexander Kozlov", "Ivan Kremnev"], "https://doi.org/10.21437/Interspeech.2018-1209", 5, "interspeech", 2018]], "Mithul Mathivanan": [0, ["CACTAS - Collaborative Audio Categorization and Transcription for ASR Systems", ["Mithul Mathivanan", "Kinnera Saranu", "Abhishek Pandey", "Jithendra Vepa"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3029.html", 2, "interspeech", 2018]], "Saurabh Garg": [0, ["Dual Language Models for Code Switched Speech Recognition", ["Saurabh Garg", "Tanmay Parekh", "Preethi Jyothi"], "https://doi.org/10.21437/Interspeech.2018-1343", 5, "interspeech", 2018]], "Helen Meng": [0, ["Speech and Language Processing for Learning and Wellbeing", ["Helen Meng"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/4004.html", 1, "interspeech", 2018]], "Md. Nasir": [0, ["Towards an Unsupervised Entrainment Distance in Conversational Speech Using Deep Neural Networks", ["Md. Nasir", "Brian R. Baucom", "Shrikanth Narayanan", "Panayiotis G. Georgiou"], "https://doi.org/10.21437/Interspeech.2018-1395", 5, "interspeech", 2018]], "Nikolaos Flemotomos": [0, ["Combined Speaker Clustering and Role Recognition in Conversational Speech", ["Nikolaos Flemotomos", "Pavlos Papadopoulos", "James Gibson", "Shrikanth Narayanan"], "https://doi.org/10.21437/Interspeech.2018-1654", 5, "interspeech", 2018], ["Language Features for Automated Evaluation of Cognitive Behavior Psychotherapy Sessions", ["Nikolaos Flemotomos", "Victor R. Martinez", "James Gibson", "David C. Atkins", "Torrey Creed", "Shrikanth Narayanan"], "https://doi.org/10.21437/Interspeech.2018-1518", 5, "interspeech", 2018]], "Afsaneh Asaei": [0, ["Phonological Posterior Hashing for Query by Example Spoken Term Detection", ["Afsaneh Asaei", "Dhananjay Ram", "Herve Bourlard"], "https://doi.org/10.21437/Interspeech.2018-1973", 5, "interspeech", 2018]], "Koji Okabe": [0, ["Attentive Statistics Pooling for Deep Speaker Embedding", ["Koji Okabe", "Takafumi Koshinaka", "Koichi Shinoda"], "https://doi.org/10.21437/Interspeech.2018-993", 5, "interspeech", 2018]], "Yi Luo": [0, ["Real-time Single-channel Dereverberation and Separation with Time-domain Audio Separation Network", ["Yi Luo", "Nima Mesgarani"], "https://doi.org/10.21437/Interspeech.2018-2290", 5, "interspeech", 2018]], "Noelia Do Carmo Blanco": [0, ["Phoneme Resistance and Phoneme Confusion in Noise: Impact of Dyslexia", ["Noelia Do Carmo Blanco", "Julien Meyer", "Michel Hoen", "Fanny Meunier"], "https://doi.org/10.21437/Interspeech.2018-1271", 5, "interspeech", 2018]], "Abhinav Jain": [0, ["Improved Accented Speech Recognition Using Accent Embeddings and Multi-task Learning", ["Abhinav Jain", "Minali Upreti", "Preethi Jyothi"], "https://doi.org/10.21437/Interspeech.2018-1864", 5, "interspeech", 2018]], "Huy Nguyen": [0, ["Liulishuo's System for the Spoken CALL Shared Task 2018", ["Huy Nguyen", "Lei Chen", "Ramon Prieto", "Chuan Wang", "Yang Liu"], "https://doi.org/10.21437/Interspeech.2018-1309", 5, "interspeech", 2018]], "Mohammad Ateeq": [0, ["An Optimization Based Approach for Solving Spoken CALL Shared Task", ["Mohammad Ateeq", "Abualsoud Hanani", "Aziz Qaroush"], "https://doi.org/10.21437/Interspeech.2018-1328", 5, "interspeech", 2018]], "Nick K. Chibuye": [0, ["Cross-language Phoneme Mapping for Low-resource Languages: An Exploration of Benefits and Trade-offs", ["Nick K. Chibuye", "Todd Rosenstock", "Brian DeRenzi"], "https://doi.org/10.21437/Interspeech.2018-2454", 5, "interspeech", 2018]], "Mengjie Qian": [0, ["The University of Birmingham 2018 Spoken CALL Shared Task Systems", ["Mengjie Qian", "Xizi Wei", "Peter Jancovic", "Martin J. Russell"], "https://doi.org/10.21437/Interspeech.2018-1372", 5, "interspeech", 2018], ["Phone Recognition Using a Non-Linear Manifold with Broad Phone Class Dependent DNNs", ["Mengjie Qian", "Linxue Bai", "Peter Jancovic", "Martin J. Russell"], "https://doi.org/10.21437/Interspeech.2018-1376", 5, "interspeech", 2018]], "Anderson R. Avila": [0, ["Investigating Speech Enhancement and Perceptual Quality for Speech Emotion Recognition", ["Anderson R. Avila", "Md. Jahangir Alam", "Douglas D. OShaughnessy", "Tiago H. Falk"], "https://doi.org/10.21437/Interspeech.2018-2350", 5, "interspeech", 2018]], "Kazuki Irie": [0, ["Investigation on Estimation of Sentence Probability by Combining Forward, Backward and Bi-directional LSTM-RNNs", ["Kazuki Irie", "Zhihong Lei", "Liuhui Deng", "Ralf Schluter", "Hermann Ney"], "https://doi.org/10.21437/Interspeech.2018-1766", 4, "interspeech", 2018]], "Igor Jauk": [0, ["Expressive Speech Synthesis Using Sentiment Embeddings", ["Igor Jauk", "Jaime Lorenzo-Trueba", "Junichi Yamagishi", "Antonio Bonafonte"], "https://doi.org/10.21437/Interspeech.2018-2467", 5, "interspeech", 2018]], "Phil Howson": [0, ["Gestural Lenition of Rhotics Captures Variation in Brazilian Portuguese", ["Phil Howson", "Alexei Kochetov"], "https://doi.org/10.21437/Interspeech.2018-1404", 5, "interspeech", 2018]], "Yingke Zhu": [0, ["Self-Attentive Speaker Embeddings for Text-Independent Speaker Verification", ["Yingke Zhu", "Tom Ko", "David Snyder", "Brian Mak", "Daniel Povey"], "https://doi.org/10.21437/Interspeech.2018-1158", 5, "interspeech", 2018]], "Hong Liu": [0, ["Multiple Concurrent Sound Source Tracking Based on Observation-Guided Adaptive Particle Filter", ["Hong Liu", "Haipeng Lan", "Bing Yang", "Cheng Pang"], "https://doi.org/10.21437/Interspeech.2018-1248", 5, "interspeech", 2018]], "Dhananjay Ram": [0, ["CNN Based Query by Example Spoken Term Detection", ["Dhananjay Ram", "Lesly Miculicich Werlen", "Herve Bourlard"], "https://doi.org/10.21437/Interspeech.2018-1722", 5, "interspeech", 2018]], "Jochen Weiner": [0, ["Investigating the Effect of Audio Duration on Dementia Detection Using Acoustic Features", ["Jochen Weiner", "Miguel Angrick", "Srinivasan Umesh", "Tanja Schultz"], "https://doi.org/10.21437/Interspeech.2018-57", 5, "interspeech", 2018]], "Shi-wook Lee": [0.6669017821550369, ["Empirical Analysis of Score Fusion Application to Combined Neural Networks for Open Vocabulary Spoken Term Detection", ["Shi-wook Lee", "Kazuyo Tanaka", "Yoshiaki Itoh"], "https://doi.org/10.21437/Interspeech.2018-1776", 5, "interspeech", 2018]], "Yue Sun": [0.006344831781461835, ["Analysis of L2 Learners' Progress of Distinguishing Mandarin Tone 2 and Tone 3", ["Yue Sun", "Win Thuzar Kyaw", "Jinsong Zhang", "Yoshinori Sagisaka"], "https://doi.org/10.21437/Interspeech.2018-1983", 5, "interspeech", 2018]], "Md. Hafizur Rahman": [0, ["Employing Phonetic Information in DNN Speaker Embeddings to Improve Speaker Recognition Performance", ["Md. Hafizur Rahman", "Ivan Himawan", "Mitchell McLaren", "Clinton Fookes", "Sridha Sridharan"], "https://doi.org/10.21437/Interspeech.2018-1804", 5, "interspeech", 2018]], "Tomoki Hayashi": [0, ["Multi-Head Decoder for End-to-End Speech Recognition", ["Tomoki Hayashi", "Shinji Watanabe", "Tomoki Toda", "Kazuya Takeda"], "https://doi.org/10.21437/Interspeech.2018-1655", 5, "interspeech", 2018]], "Bishnu S. Atal": [0, ["From Vocoders to Code-Excited Linear Prediction: Learning How We Hear What We Hear", ["Bishnu S. Atal"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/4001.html", 1, "interspeech", 2018]], "Paul Magron": [0, ["Reducing Interference with Phase Recovery in DNN-based Monaural Singing Voice Separation", ["Paul Magron", "Konstantinos Drossos", "Stylianos Ioannis Mimilakis", "Tuomas Virtanen"], "https://doi.org/10.21437/Interspeech.2018-1845", 5, "interspeech", 2018], ["Expectation-Maximization Algorithms for Itakura-Saito Nonnegative Matrix Factorization", ["Paul Magron", "Tuomas Virtanen"], "https://doi.org/10.21437/Interspeech.2018-1840", 5, "interspeech", 2018]], "Amit Das": [0, ["Improving DNNs Trained with Non-Native Transcriptions Using Knowledge Distillation and Target Interpolation", ["Amit Das", "Mark Hasegawa-Johnson"], "https://doi.org/10.21437/Interspeech.2018-1450", 5, "interspeech", 2018]], "Zhehuai Chen": [0, ["A GPU-based WFST Decoder with Exact Lattice Generation", ["Zhehuai Chen", "Justin Luitjens", "Hainan Xu", "Yiming Wang", "Daniel Povey", "Sanjeev Khudanpur"], "https://doi.org/10.21437/Interspeech.2018-1339", 5, "interspeech", 2018]], "Jon Barker": [0, ["The Fifth 'CHiME' Speech Separation and Recognition Challenge: Dataset, Task and Baselines", ["Jon Barker", "Shinji Watanabe", "Emmanuel Vincent", "Jan Trmal"], "https://doi.org/10.21437/Interspeech.2018-1768", 5, "interspeech", 2018]], "Shiyu Zhou": [0, ["Syllable-Based Sequence-to-Sequence Speech Recognition with the Transformer in Mandarin Chinese", ["Shiyu Zhou", "Linhao Dong", "Shuang Xu", "Bo Xu"], "https://doi.org/10.21437/Interspeech.2018-1107", 5, "interspeech", 2018]], "Jaejin Cho": [0.962470218539238, ["Deep Neural Networks for Emotion Recognition Combining Audio and Transcripts", ["Jaejin Cho", "Raghavendra Pappagari", "Purva Kulkarni", "Jesus Villalba", "Yishay Carmiel", "Najim Dehak"], "https://doi.org/10.21437/Interspeech.2018-2466", 5, "interspeech", 2018]], "Kumud Tripathi": [0, ["Analysis of sparse representation based feature on speech mode classification", ["Kumud Tripathi", "K. Sreenivasa Rao"], "https://doi.org/10.21437/Interspeech.2018-1921", 5, "interspeech", 2018]], "Fumiaki Taguchi": [0, ["Articulatory-to-speech Conversion Using Bi-directional Long Short-term Memory", ["Fumiaki Taguchi", "Tokihiko Kaburagi"], "https://doi.org/10.21437/Interspeech.2018-999", 5, "interspeech", 2018]], "Zili Huang": [0, ["Angular Softmax for Short-Duration Text-independent Speaker Verification", ["Zili Huang", "Shuai Wang", "Kai Yu"], "https://doi.org/10.21437/Interspeech.2018-1545", 5, "interspeech", 2018]], "Peng Shen": [0, ["Feature Representation of Short Utterances Based on Knowledge Distillation for Spoken Language Identification", ["Peng Shen", "Xugang Lu", "Sheng Li", "Hisashi Kawai"], "https://doi.org/10.21437/Interspeech.2018-1519", 5, "interspeech", 2018]], "Hong Zhang": [0, ["Analyzing Thai Tone Distribution through Functional Data Analysis", ["Hong Zhang"], "https://doi.org/10.21437/Interspeech.2018-2115", 5, "interspeech", 2018]], "Jayadev Billa": [0, ["ISI ASR System for the Low Resource Speech Recognition Challenge for Indian Languages", ["Jayadev Billa"], "https://doi.org/10.21437/Interspeech.2018-2473", 5, "interspeech", 2018]], "Beiming Cao": [0, ["Articulation-to-Speech Synthesis Using Articulatory Flesh Point Sensors' Orientation Information", ["Beiming Cao", "Myung Jong Kim", "Jun R. Wang", "Jan P. H. van Santen", "Ted Mau", "Jun Wang"], "https://doi.org/10.21437/Interspeech.2018-2484", 5, "interspeech", 2018]], "Anil Ramakrishna": [0, ["Computational Modeling of Conversational Humor in Psychotherapy", ["Anil Ramakrishna", "Timothy Greer", "David C. Atkins", "Shrikanth Narayanan"], "https://doi.org/10.21437/Interspeech.2018-1583", 5, "interspeech", 2018]], "Massimiliano Todisco": [0, ["Integrated Presentation Attack Detection and Automatic Speaker Verification: Common Features and Gaussian Back-end Fusion", ["Massimiliano Todisco", "Hector Delgado", "Kong-Aik Lee", "Md. Sahidullah", "Nicholas W. D. Evans", "Tomi Kinnunen", "Junichi Yamagishi"], "https://doi.org/10.21437/Interspeech.2018-2289", 5, "interspeech", 2018]], "Pierre-Alexandre Broux": [0, ["S4D: Speaker Diarization Toolkit in Python", ["Pierre-Alexandre Broux", "Florent Desnous", "Anthony Larcher", "Simon Petitrenaud", "Jean Carrive", "Sylvain Meignier"], "https://doi.org/10.21437/Interspeech.2018-1232", 5, "interspeech", 2018]], "Yerbolat Khassanov": [0, ["Unsupervised and Efficient Vocabulary Expansion for Recurrent Neural Network Language Models in ASR", ["Yerbolat Khassanov", "Eng Siong Chng"], "https://doi.org/10.21437/Interspeech.2018-1021", 5, "interspeech", 2018]], "Xi Ma": [0, ["Emotion Recognition from Variable-Length Speech Segments Using Deep Learning on Spectrograms", ["Xi Ma", "Zhiyong Wu", "Jia Jia", "Mingxing Xu", "Helen Meng", "Lianhong Cai"], "https://doi.org/10.21437/Interspeech.2018-2228", 5, "interspeech", 2018]], "Pegah Ghahremani": [0, ["End-to-end Deep Neural Network Age Estimation", ["Pegah Ghahremani", "Phani Sankar Nidadavolu", "Nanxin Chen", "Jesus Villalba", "Daniel Povey", "Sanjeev Khudanpur", "Najim Dehak"], "https://doi.org/10.21437/Interspeech.2018-2015", 5, "interspeech", 2018], ["Acoustic Modeling from Frequency Domain Representations of Speech", ["Pegah Ghahremani", "Hossein Hadian", "Hang Lv", "Daniel Povey", "Sanjeev Khudanpur"], "https://doi.org/10.21437/Interspeech.2018-1453", 5, "interspeech", 2018]], "Bhargav Pulugundla": [0, ["BUT System for Low Resource Indian Language ASR", ["Bhargav Pulugundla", "Murali Karthick Baskar", "Santosh Kesiraju", "Ekaterina Egorova", "Martin Karafiat", "Lukas Burget", "Jan Cernocky"], "https://doi.org/10.21437/Interspeech.2018-1302", 5, "interspeech", 2018]], "Raghav Gupta": [0, ["An Efficient Approach to Encoding Context for Spoken Language Understanding", ["Raghav Gupta", "Abhinav Rastogi", "Dilek Hakkani-Tur"], "https://doi.org/10.21437/Interspeech.2018-2403", 5, "interspeech", 2018]], "Adrian Leemann": [0, ["Regional Variation of /r/ in Swiss German Dialects", ["Adrian Leemann", "Stephan Schmid", "Dieter Studer-Joho", "Marie-Jose Kolly"], "https://doi.org/10.21437/Interspeech.2018-1065", 5, "interspeech", 2018]], "Dean Luo": [0, ["Factorized Deep Neural Network Adaptation for Automatic Scoring of L2 Speech in English Speaking Tests", ["Dean Luo", "Chunxiao Zhang", "Linzhong Xia", "Lixin Wang"], "https://doi.org/10.21437/Interspeech.2018-2138", 5, "interspeech", 2018]], "Alejandro Gomez Alanis": [0, ["A Deep Identity Representation for Noise Robust Spoofing Detection", ["Alejandro Gomez Alanis", "Antonio M. Peinado", "Jose A. Gonzalez", "Angel M. Gomez"], "https://doi.org/10.21437/Interspeech.2018-1909", 5, "interspeech", 2018]], "Alexei Kochetov": [0, ["The Retroflex-dental Contrast in Punjabi Stops and Nasals: A Principal Component Analysis of Ultrasound Images", ["Alexei Kochetov", "Matthew Faytak", "Kiranpreet Nara"], "https://doi.org/10.21437/Interspeech.2018-1457", 5, "interspeech", 2018]], "Ziqiang Shi": [0, ["Double Joint Bayesian Modeling of DNN Local I-Vector for Text Dependent Speaker Verification with Random Digit Strings", ["Ziqiang Shi", "Huibin Lin", "Liu Liu", "Rujie Liu"], "https://doi.org/10.21437/Interspeech.2018-1103", 5, "interspeech", 2018], ["Joint Learning of J-Vector Extractor and Joint Bayesian Model for Text Dependent Speaker Verification", ["Ziqiang Shi", "Liu Liu", "Huibin Lin", "Rujie Liu"], "https://doi.org/10.21437/Interspeech.2018-1500", 5, "interspeech", 2018], ["Latent Factor Analysis of Deep Bottleneck Features for Speaker Verification with Random Digit Strings", ["Ziqiang Shi", "Huibin Lin", "Liu Liu", "Rujie Liu"], "https://doi.org/10.21437/Interspeech.2018-1422", 5, "interspeech", 2018]], "Ryo Masumura": [0, ["Role Play Dialogue Aware Language Models Based on Conditional Hierarchical Recurrent Encoder-Decoder", ["Ryo Masumura", "Tomohiro Tanaka", "Atsushi Ando", "Hirokazu Masataki", "Yushi Aono"], "https://doi.org/10.21437/Interspeech.2018-2185", 5, "interspeech", 2018]], "Branislav Gerazov": [0, ["A Weighted Superposition of Functional Contours Model for Modelling Contextual Prominence of Elementary Prosodic Contours", ["Branislav Gerazov", "Gerard Bailly", "Yi Xu"], "https://doi.org/10.21437/Interspeech.2018-1286", 5, "interspeech", 2018]], "Astik Biswas": [0, ["Multilingual Neural Network Acoustic Modelling for ASR of Under-Resourced English-isiZulu Code-Switched Speech", ["Astik Biswas", "Febe de Wet", "Ewald van der Westhuizen", "Emre Yilmaz", "Thomas Niesler"], "https://doi.org/10.21437/Interspeech.2018-1711", 5, "interspeech", 2018]], "Guozhen An": [1.6238163157850094e-11, ["Deep Personality Recognition for Deception Detection", ["Guozhen An", "Sarah Ita Levitan", "Julia Hirschberg", "Rivka Levitan"], "https://doi.org/10.21437/Interspeech.2018-2269", 5, "interspeech", 2018], ["Lexical and Acoustic Deep Learning Model for Personality Recognition", ["Guozhen An", "Rivka Levitan"], "https://doi.org/10.21437/Interspeech.2018-2263", 5, "interspeech", 2018]], "Samuel Myer": [0, ["Efficient Keyword Spotting Using Time Delay Neural Networks", ["Samuel Myer", "Vikrant Singh Tomar"], "https://doi.org/10.21437/Interspeech.2018-1979", 5, "interspeech", 2018]], "Jitendra Kumar Dhiman": [0, ["Multicomponent 2-D AM-FM Modeling of Speech Spectrograms", ["Jitendra Kumar Dhiman", "Neeraj Sharma", "Chandra Sekhar Seelamantula"], "https://doi.org/10.21437/Interspeech.2018-1937", 5, "interspeech", 2018]], "Tanvina Patel": [0, ["Development of Large Vocabulary Speech Recognition System with Keyword Search for Manipuri", ["Tanvina Patel", "Krishna D. N", "Noor Fathima", "Nisar Shah", "Mahima C", "Deepak Kumar", "Anuroop Iyengar"], "https://doi.org/10.21437/Interspeech.2018-2133", 5, "interspeech", 2018], ["An Automatic Speech Transcription System for Manipuri Language", ["Tanvina Patel", "Krishna D. N", "Noor Fathima", "Nisar Shah", "Mahima C", "Deepak Kumar", "Anuroop Iyengar"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3043.html", 2, "interspeech", 2018]], "Sarah Ita Levitan": [0, ["Acoustic-Prosodic Indicators of Deception and Trust in Interview Dialogues", ["Sarah Ita Levitan", "Angel Maredia", "Julia Hirschberg"], "https://doi.org/10.21437/Interspeech.2018-2443", 5, "interspeech", 2018]], "Pavan Karjol": [0, ["Speech Enhancement Using Deep Mixture of Experts Based on Hard Expectation Maximization", ["Pavan Karjol", "Prasanta Kumar Ghosh"], "https://doi.org/10.21437/Interspeech.2018-1730", 5, "interspeech", 2018]], "Sai Krishna Rallabandi": [0, ["Investigating Utterance Level Representations for Detecting Intent from Acoustics", ["Sai Krishna Rallabandi", "Bhavya Karki", "Carla Viegas", "Eric Nyberg", "Alan W. Black"], "https://doi.org/10.21437/Interspeech.2018-2149", 5, "interspeech", 2018]], "Vishwa Gupta": [0, ["CRIM's System for the MGB-3 English Multi-Genre Broadcast Media Transcription", ["Vishwa Gupta", "Gilles Boulianne"], "https://doi.org/10.21437/Interspeech.2018-2079", 5, "interspeech", 2018]], "Nicanor Garcia": [0, ["Multimodal I-vectors to Detect and Evaluate Parkinson's Disease", ["Nicanor Garcia", "Juan Camilo Vasquez-Correa", "Juan Rafael Orozco-Arroyave", "Elmar Noth"], "https://doi.org/10.21437/Interspeech.2018-2295", 5, "interspeech", 2018]], "Shinji Watanabe": [0, ["ESPnet: End-to-End Speech Processing Toolkit", ["Shinji Watanabe", "Takaaki Hori", "Shigeki Karita", "Tomoki Hayashi", "Jiro Nishitoba", "Yuya Unno", "Nelson Enrique Yalta Soplin", "Jahn Heymann", "Matthew Wiesner", "Nanxin Chen", "Adithya Renduchintala", "Tsubasa Ochiai"], "https://doi.org/10.21437/Interspeech.2018-1456", 5, "interspeech", 2018]], "Johannes Wagner": [0, ["Deep Learning in Paralinguistic Recognition Tasks: Are Hand-crafted Features Still Relevant?", ["Johannes Wagner", "Dominik Schiller", "Andreas Seiderer", "Elisabeth Andre"], "https://doi.org/10.21437/Interspeech.2018-1238", 5, "interspeech", 2018]], "Sarfaraz Jelil": [0, ["Exploration of Compressed ILPR Features for Replay Attack Detection", ["Sarfaraz Jelil", "Sishir Kalita", "S. R. Mahadeva Prasanna", "Rohit Sinha"], "https://doi.org/10.21437/Interspeech.2018-1297", 5, "interspeech", 2018]], "Pramod B. Bachhav": [0, ["Artificial Bandwidth Extension with Memory Inclusion Using Semi-supervised Stacked Auto-encoders", ["Pramod B. Bachhav", "Massimiliano Todisco", "Nicholas W. D. Evans"], "https://doi.org/10.21437/Interspeech.2018-2213", 5, "interspeech", 2018]], "Frederic Bechet": [0, ["Is ATIS Too Shallow to Go Deeper for Benchmarking Spoken Language Understanding Models?", ["Frederic Bechet", "Christian Raymond"], "https://doi.org/10.21437/Interspeech.2018-2256", 5, "interspeech", 2018]], "Theo Biasutto-Lervat": [0, ["Phoneme-to-Articulatory Mapping Using Bidirectional Gated RNN", ["Theo Biasutto-Lervat", "Slim Ouni"], "https://doi.org/10.21437/Interspeech.2018-1202", 5, "interspeech", 2018]], "Gunnam Aneeja": [0, ["Detection of Glottal Closure Instants in Degraded Speech Using Single Frequency Filtering Analysis", ["Gunnam Aneeja", "Sudarsana Reddy Kadiri", "Bayya Yegnanarayana"], "https://doi.org/10.21437/Interspeech.2018-1018", 5, "interspeech", 2018]], "Protima Nomo Sudro": [0, ["Processing Transition Regions of Glottal Stop Substituted /S/ for Intelligibility Enhancement of Cleft Palate Speech", ["Protima Nomo Sudro", "Sishir Kalita", "S. R. Mahadeva Prasanna"], "https://doi.org/10.21437/Interspeech.2018-1646", 5, "interspeech", 2018]], "Manny Rayner": [0, ["A Robust Context-Dependent Speech-to-Speech Phraselator Toolkit for Alexa", ["Manny Rayner", "Nikos Tsourakis", "Jan Stanek"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3006.html", 2, "interspeech", 2018]]}