{"Uffe Schjoedt": [0, ["God as Interlocutor - Real or Imaginary? Prosodic Markers of Dialogue Speech and Expected Efficacy in Spoken Prayer", ["Oliver Niebuhr", "Uffe Schjoedt"], "https://doi.org/10.21437/Interspeech.2019-1193", 5, "interspeech", 2019]], "Basil Abraham": [0, ["Exploiting Monolingual Speech Corpora for Code-Mixed Speech Recognition", ["Karan Taneja", "Satarupa Guha", "Preethi Jyothi", "Basil Abraham"], "https://doi.org/10.21437/Interspeech.2019-1959", 5, "interspeech", 2019]], "Xiao-Ping Steven Zhang": [0, ["Automatic Detection of the Temporal Segmentation of Hand Movements in British English Cued Speech", ["Li Liu", "Jianze Li", "Gang Feng", "Xiao-Ping Steven Zhang"], "https://doi.org/10.21437/Interspeech.2019-2353", 5, "interspeech", 2019]], "Ha-Jin Yu": [0.7287916094064713, ["Acoustic Scene Classification Using Teacher-Student Learning with Soft-Labels", ["Hee-Soo Heo", "Jee-weon Jung", "Hye-jin Shim", "Ha-Jin Yu"], "https://doi.org/10.21437/Interspeech.2019-1989", 5, "interspeech", 2019], ["Replay Attack Detection with Complementary High-Resolution Information Using End-to-End DNN for the ASVspoof 2019 Challenge", ["Jee-weon Jung", "Hye-jin Shim", "Hee-Soo Heo", "Ha-Jin Yu"], "https://doi.org/10.21437/Interspeech.2019-1991", 5, "interspeech", 2019], ["RawNet: Advanced End-to-End Deep Neural Network Using Raw Waveforms for Text-Independent Speaker Verification", ["Jee-weon Jung", "Hee-Soo Heo", "Ju-ho Kim", "Hye-jin Shim", "Ha-Jin Yu"], "https://doi.org/10.21437/Interspeech.2019-1982", 5, "interspeech", 2019], ["End-to-End Losses Based on Speaker Basis Vectors and All-Speaker Hard Negative Mining for Speaker Verification", ["Hee-Soo Heo", "Jee-weon Jung", "Il-Ho Yang", "Sung-Hyun Yoon", "Hye-jin Shim", "Ha-Jin Yu"], "https://doi.org/10.21437/Interspeech.2019-1986", 5, "interspeech", 2019]], "Renee Seward": [0, ["Using Ultrasound Imaging to Create Augmented Visual Biofeedback for Articulatory Practice", ["Colin T. Annand", "Maurice Lamb", "Sarah Dugan", "Sarah R. Li", "Hannah M. Woeste", "T. Douglas Mast", "Michael A. Riley", "Jack A. Masterson", "Neeraja Mahalingam", "Kathryn J. Eary", "Caroline Spencer", "Suzanne Boyce", "Stephanie Jackson", "Anoosha Baxi", "Renee Seward"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8036.html", 2, "interspeech", 2019]], "Alvaro Martin Iturralde Zurita": [0, ["Compensation for French Liquid Deletion During Auditory Sentence Processing", ["Sharon Peperkamp", "Alvaro Martin Iturralde Zurita"], "https://doi.org/10.21437/Interspeech.2019-2950", 5, "interspeech", 2019]], "Anna Lukaszewicz": [0, ["An Acoustic Study of Vowel Undershoot in a System with Several Degrees of Prominence", ["Janina Molczanow", "Beata Lukaszewicz", "Anna Lukaszewicz"], "https://doi.org/10.21437/Interspeech.2019-1806", 5, "interspeech", 2019]], "Taesu Kim": [0.9277801364660263, ["Large-Scale Speaker Retrieval on Random Speaker Variability Subspace", ["Suwon Shon", "Younggun Lee", "Taesu Kim"], "https://doi.org/10.21437/Interspeech.2019-1498", 5, "interspeech", 2019]], "Yanmin Qian": [0, ["Knowledge Distillation for End-to-End Monaural Multi-Talker ASR System", ["Wangyou Zhang", "Xuankai Chang", "Yanmin Qian"], "https://doi.org/10.21437/Interspeech.2019-3192", 5, "interspeech", 2019], ["Robust DOA Estimation Based on Convolutional Neural Network and Time-Frequency Masking", ["Wangyou Zhang", "Ying Zhou", "Yanmin Qian"], "https://doi.org/10.21437/Interspeech.2019-3158", 5, "interspeech", 2019], ["Prosody Usage Optimization for Children Speech Recognition with Zero Resource Children Speech", ["Chenda Li", "Yanmin Qian"], "https://doi.org/10.21437/Interspeech.2019-2659", 5, "interspeech", 2019]], "Yong Ma": [0, ["Code-Switching Sentence Generation by Bert and Generative Adversarial Networks", ["Yingying Gao", "Junlan Feng", "Ying Liu", "Leijing Hou", "Xin Pan", "Yong Ma"], "https://doi.org/10.21437/Interspeech.2019-2501", 5, "interspeech", 2019]], "Bowen Zhou": [0, ["Direct-Path Signal Cross-Correlation Estimation for Sound Source Localization in Reverberation", ["Wei Xue", "Ying Tong", "Guohong Ding", "Chao Zhang", "Tao Ma", "Xiaodong He", "Bowen Zhou"], "https://doi.org/10.21437/Interspeech.2019-1488", 5, "interspeech", 2019], ["Multi-Stride Self-Attention for Speech Recognition", ["Kyu J. Han", "Jing Huang", "Yun Tang", "Xiaodong He", "Bowen Zhou"], "https://doi.org/10.21437/Interspeech.2019-1973", 5, "interspeech", 2019]], "Hema A. Murthy": [0, ["Zero Resource Speech Synthesis Using Transcripts Derived from Perceptual Acoustic Units", ["Karthik Pandia D. S", "Hema A. Murthy"], "https://doi.org/10.21437/Interspeech.2019-2336", 5, "interspeech", 2019]], "Joakim Gusafsson": [0, ["Spot the Pleasant People! Navigating the Cocktail Party Buzz", ["Christina Tannander", "Per Fallgren", "Jens Edlund", "Joakim Gusafsson"], "https://doi.org/10.21437/Interspeech.2019-1553", 5, "interspeech", 2019]], "Maria Julia Carbajal": [0, ["Liquid Deletion in French Child-Directed Speech", ["Sharon Peperkamp", "Monica Hegde", "Maria Julia Carbajal"], "https://doi.org/10.21437/Interspeech.2019-2838", 5, "interspeech", 2019]], "Alexander Zatvornitskiy": [0, ["The STC ASR System for the VOiCES from a Distance Challenge 2019", ["Ivan Medennikov", "Yuri Y. Khokhlov", "Aleksei Romanenko", "Ivan Sorokin", "Anton Mitrofanov", "Vladimir Bataev", "Andrei Andrusenko", "Tatiana Prisyach", "Mariya Korenevskaya", "Oleg Petrov", "Alexander Zatvornitskiy"], "https://doi.org/10.21437/Interspeech.2019-1574", 5, "interspeech", 2019], ["The STC ASR System for the VOiCES from a Distance Challenge 2019", ["Ivan Medennikov", "Yuri Y. Khokhlov", "Aleksei Romanenko", "Ivan Sorokin", "Anton Mitrofanov", "Vladimir Bataev", "Andrei Andrusenko", "Tatiana Prisyach", "Mariya Korenevskaya", "Oleg Petrov", "Alexander Zatvornitskiy"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/abs17.html", 0, "interspeech", 2019]], "Panayiotis G. Georgiou": [0, ["Spoken Language Intent Detection Using Confusion2Vec", ["Prashanth Gurunath Shivakumar", "Mu Yang", "Panayiotis G. Georgiou"], "https://doi.org/10.21437/Interspeech.2019-2226", 5, "interspeech", 2019], ["Predicting Behavior in Cancer-Afflicted Patient and Spouse Interactions Using Speech and Language", ["Sandeep Nallan Chakravarthula", "Haoqi Li", "Shao-Yen Tseng", "Maija Reblin", "Panayiotis G. Georgiou"], "https://doi.org/10.21437/Interspeech.2019-1888", 5, "interspeech", 2019]], "Andreas K. Maier": [0, ["Analysis by Adversarial Synthesis - A Novel Approach for Speech Vocoding", ["Ahmed Mustafa", "Arijit Biswas", "Christian Bergler", "Julia Schottenhamml", "Andreas K. Maier"], "https://doi.org/10.21437/Interspeech.2019-1195", 5, "interspeech", 2019]], "Patrick Nguyen": [0, ["On the Choice of Modeling Unit for Sequence-to-Sequence Speech Recognition", ["Kazuki Irie", "Rohit Prabhavalkar", "Anjuli Kannan", "Antoine Bruguier", "David Rybach", "Patrick Nguyen"], "https://doi.org/10.21437/Interspeech.2019-2277", 5, "interspeech", 2019]], "Kyle Williams": [0, ["Zero Shot Intent Classification Using Long-Short Term Memory Networks", ["Kyle Williams"], "https://doi.org/10.21437/Interspeech.2019-1274", 5, "interspeech", 2019]], "Okko Rasanen": [0, ["Augmented CycleGANs for Continuous Scale Normal-to-Lombard Speaking Style Conversion", ["Shreyas Seshadri", "Lauri Juvela", "Paavo Alku", "Okko Rasanen"], "https://doi.org/10.21437/Interspeech.2019-1681", 5, "interspeech", 2019]], "Mikhail Belkin": [0, ["Kernel Machines Beat Deep Neural Networks on Mask-Based Single-Channel Speech Enhancement", ["Like Hui", "Siyuan Ma", "Mikhail Belkin"], "https://doi.org/10.21437/Interspeech.2019-1344", 5, "interspeech", 2019]], "Qin Jin": [8.872806574800052e-05, ["Speech Emotion Recognition in Dyadic Dialogues with Attentive Interaction Modeling", ["Jinming Zhao", "Shizhe Chen", "Jingjun Liang", "Qin Jin"], "https://doi.org/10.21437/Interspeech.2019-2103", 5, "interspeech", 2019]], "Jaime Hernandez-Cordero": [0, ["The 2018 NIST Speaker Recognition Evaluation", ["Seyed Omid Sadjadi", "Craig S. Greenberg", "Elliot Singer", "Douglas A. Reynolds", "Lisa P. Mason", "Jaime Hernandez-Cordero"], "https://doi.org/10.21437/Interspeech.2019-1351", 5, "interspeech", 2019]], "Chun-Wei Wang": [0.00011971311323577538, ["Self Attention in Variational Sequential Learning for Summarization", ["Jen-Tzung Chien", "Chun-Wei Wang"], "https://doi.org/10.21437/Interspeech.2019-1548", 5, "interspeech", 2019]], "Bjorn W. Schuller": [0, ["Attention-Enhanced Connectionist Temporal Classification for Discrete Speech Emotion Recognition", ["Ziping Zhao", "Zhongtian Bao", "Zixing Zhang", "Nicholas Cummins", "Haishuai Wang", "Bjorn W. Schuller"], "https://doi.org/10.21437/Interspeech.2019-1649", 5, "interspeech", 2019], ["A Hierarchical Attention Network-Based Approach for Depression Detection from Transcribed Clinical Interviews", ["Adria Mallol-Ragolta", "Ziping Zhao", "Lukas Stappen", "Nicholas Cummins", "Bjorn W. Schuller"], "https://doi.org/10.21437/Interspeech.2019-2036", 5, "interspeech", 2019], ["Using Speech to Predict Sequentially Measured Cortisol Levels During a Trier Social Stress Test", ["Alice Baird", "Shahin Amiriparian", "Nicholas Cummins", "Sarah Sturmbauer", "Johanna Janson", "Eva-Maria Messner", "Harald Baumeister", "Nicolas Rohleder", "Bjorn W. Schuller"], "https://doi.org/10.21437/Interspeech.2019-1352", 5, "interspeech", 2019], ["Sincerity in Acted Speech: Presenting the Sincere Apology Corpus and Results", ["Alice Baird", "Eduardo Coutinho", "Julia Hirschberg", "Bjorn W. Schuller"], "https://doi.org/10.21437/Interspeech.2019-1349", 5, "interspeech", 2019], ["Autonomous Emotion Learning in Speech: A View of Zero-Shot Speech Emotion Recognition", ["Xinzhou Xu", "Jun Deng", "Nicholas Cummins", "Zixing Zhang", "Li Zhao", "Bjorn W. Schuller"], "https://doi.org/10.21437/Interspeech.2019-2406", 5, "interspeech", 2019], ["Towards Robust Speech Emotion Recognition Using Deep Residual Networks for Speech Enhancement", ["Andreas Triantafyllopoulos", "Gil Keren", "Johannes Wagner", "Ingmar Steiner", "Bjorn W. Schuller"], "https://doi.org/10.21437/Interspeech.2019-1811", 5, "interspeech", 2019], ["Speech Augmentation via Speaker-Specific Noise in Unseen Environment", ["Yanan Guo", "Ziping Zhao", "Yide Ma", "Bjorn W. Schuller"], "https://doi.org/10.21437/Interspeech.2019-2712", 5, "interspeech", 2019], ["Continuous Emotion Recognition in Speech - Do We Need Recurrence?", ["Maximilian Schmitt", "Nicholas Cummins", "Bjorn W. Schuller"], "https://doi.org/10.21437/Interspeech.2019-2710", 5, "interspeech", 2019], ["Robust Speech Emotion Recognition Under Different Encoding Conditions", ["Christopher Oates", "Andreas Triantafyllopoulos", "Ingmar Steiner", "Bjorn W. Schuller"], "https://doi.org/10.21437/Interspeech.2019-1658", 5, "interspeech", 2019]], "Jen-Tzung Chien": [0, ["Variational Domain Adversarial Learning for Speaker Verification", ["Youzhi Tu", "Man-Wai Mak", "Jen-Tzung Chien"], "https://doi.org/10.21437/Interspeech.2019-2168", 5, "interspeech", 2019]], "Hisami Suzuki": [0, ["Speech-Based Web Navigation for Limited Mobility Users", ["Vasiliy Radostev", "Serge Berger", "Justin Tabrizi", "Pasha Kamyshev", "Hisami Suzuki"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8042.html", 2, "interspeech", 2019]], "Volker Leutnant": [0, ["Acoustic Model Bootstrapping Using Semi-Supervised Learning", ["Langzhou Chen", "Volker Leutnant"], "https://doi.org/10.21437/Interspeech.2019-2818", 5, "interspeech", 2019]], "Gennaro Cordasco": [0, ["The Dependability of Voice on Elders' Acceptance of Humanoid Agents", ["Anna Esposito", "Terry Amorese", "Marialucia Cuciniello", "Maria Teresa Riviello", "Antonietta Maria Esposito", "Alda Troncone", "Gennaro Cordasco"], "https://doi.org/10.21437/Interspeech.2019-1734", 5, "interspeech", 2019]], "Jun Wang": [0.07243982143700123, ["Towards a Speaker Independent Speech-BCI Using Speaker Adaptation", ["Debadatta Dash", "Alan Wisler", "Paul Ferrari", "Jun Wang"], "https://doi.org/10.21437/Interspeech.2019-3109", 5, "interspeech", 2019], ["Spatial and Spectral Fingerprint in the Brain: Speaker Identification from Single Trial MEG Signals", ["Debadatta Dash", "Paul Ferrari", "Jun Wang"], "https://doi.org/10.21437/Interspeech.2019-3105", 5, "interspeech", 2019]], "Zoraida Callejas": [0, ["Discovering Dialog Rules by Means of an Evolutionary Approach", ["David Griol", "Zoraida Callejas"], "https://doi.org/10.21437/Interspeech.2019-2230", 5, "interspeech", 2019]], "Julie Carson-Berndsen": [0, ["The Effect of Phoneme Distribution on Perceptual Similarity in English", ["Emma ONeill", "Julie Carson-Berndsen"], "https://doi.org/10.21437/Interspeech.2019-3042", 5, "interspeech", 2019]], "Kenji Nagamatsu": [0, ["Multimodal Response Obligation Detection with Unsupervised Online Domain Adaptation", ["Shota Horiguchi", "Naoyuki Kanda", "Kenji Nagamatsu"], "https://doi.org/10.21437/Interspeech.2019-1313", 5, "interspeech", 2019]], "A. Kanagasundaram": [0, ["LEAP Diarization System for the Second DIHARD Challenge", ["Prachi Singh", "Harsha Vardhan", "Sriram Ganapathy", "A. Kanagasundaram"], "https://doi.org/10.21437/Interspeech.2019-2716", 5, "interspeech", 2019]], "Javier Hernando": [0, ["Auto-Encoding Nearest Neighbor i-Vectors for Speaker Verification", ["Umair Khan", "Miquel India", "Javier Hernando"], "https://doi.org/10.21437/Interspeech.2019-1444", 5, "interspeech", 2019], ["Self Multi-Head Attention for Speaker Recognition", ["Miquel India", "Pooyan Safari", "Javier Hernando"], "https://doi.org/10.21437/Interspeech.2019-2616", 5, "interspeech", 2019]], "Ye Jia": [0, ["Parrotron: An End-to-End Speech-to-Speech Conversion Model and its Applications to Hearing-Impaired Speech and Speech Separation", ["Fadi Biadsy", "Ron J. Weiss", "Pedro J. Moreno", "Dimitri Kanvesky", "Ye Jia"], "https://doi.org/10.21437/Interspeech.2019-1789", 5, "interspeech", 2019]], "Hsin-Min Wang": [0.0006203114317031577, ["Investigation of F0 Conditioning and Fully Convolutional Networks in Variational Autoencoder Based Voice Conversion", ["Wen-Chin Huang", "Yi-Chiao Wu", "Chen-Chou Lo", "Patrick Lumban Tobing", "Tomoki Hayashi", "Kazuhiro Kobayashi", "Tomoki Toda", "Yu Tsao", "Hsin-Min Wang"], "https://doi.org/10.21437/Interspeech.2019-1774", 5, "interspeech", 2019], ["MOSNet: Deep Learning-Based Objective Assessment for Voice Conversion", ["Chen-Chou Lo", "Szu-Wei Fu", "Wen-Chin Huang", "Xin Wang", "Junichi Yamagishi", "Yu Tsao", "Hsin-Min Wang"], "https://doi.org/10.21437/Interspeech.2019-2003", 5, "interspeech", 2019], ["Exploring the Encoder Layers of Discriminative Autoencoders for LVCSR", ["Pin-Tuan Huang", "Hung-Shin Lee", "Syu-Siang Wang", "Kuan-Yu Chen", "Yu Tsao", "Hsin-Min Wang"], "https://doi.org/10.21437/Interspeech.2019-1717", 5, "interspeech", 2019], ["Noise Adaptive Speech Enhancement Using Domain Adversarial Training", ["Chien-Feng Liao", "Yu Tsao", "Hung-yi Lee", "Hsin-Min Wang"], "https://doi.org/10.21437/Interspeech.2019-1519", 5, "interspeech", 2019]], "Ben G. Shirley": [0, ["R2SPIN: Re-Recording the Revised Speech Perception in Noise Test", ["Lauren Ward", "Catherine Robinson", "Matthew Paradis", "Katherine M. Tucker", "Ben G. Shirley"], "https://doi.org/10.21437/Interspeech.2019-1281", 5, "interspeech", 2019]], "Keiichi Tokuda": [0, ["Statistical Approach to Speech Synthesis: Past, Present and Future", ["Keiichi Tokuda"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/abs1.html", 0, "interspeech", 2019]], "Yannis Stylianou": [0, ["Non-Parallel Voice Conversion Using Weighted Generative Adversarial Networks", ["Dipjyoti Paul", "Yannis Pantazis", "Yannis Stylianou"], "https://doi.org/10.21437/Interspeech.2019-2869", 5, "interspeech", 2019], ["Speech Enhancement for Noise-Robust Speech Synthesis Using Wasserstein GAN", ["Nagaraj Adiga", "Yannis Pantazis", "Vassilis Tsiaras", "Yannis Stylianou"], "https://doi.org/10.21437/Interspeech.2019-2648", 5, "interspeech", 2019], ["A Non-Causal FFTNet Architecture for Speech Enhancement", ["P. V. Muhammed Shifas", "Nagaraj Adiga", "Vassilis Tsiaras", "Yannis Stylianou"], "https://doi.org/10.21437/Interspeech.2019-2622", 5, "interspeech", 2019]], "Elisabet Eir Cortes": [0, ["No Distributional Learning in Adults from Attended Listening to Non-Speech", ["Ellen Marklund", "Johan Sjons", "Lisa Gustavsson", "Elisabet Eir Cortes"], "https://doi.org/10.21437/Interspeech.2019-1674", 5, "interspeech", 2019]], "Oleg Petrov": [0, ["R-Vectors: New Technique for Adaptation to Room Acoustics", ["Yuri Y. Khokhlov", "Alexander Zatvornitskiy", "Ivan Medennikov", "Ivan Sorokin", "Tatiana Prisyach", "Aleksei Romanenko", "Anton Mitrofanov", "Vladimir Bataev", "Andrei Andrusenko", "Mariya Korenevskaya", "Oleg Petrov"], "https://doi.org/10.21437/Interspeech.2019-2645", 5, "interspeech", 2019]], "Ingmar Steiner": [0, ["Phonetic Accommodation in a Wizard-of-Oz Experiment: Intonation and Segments", ["Iona Gessinger", "Bernd Mobius", "Bistra Andreeva", "Eran Raveh", "Ingmar Steiner"], "https://doi.org/10.21437/Interspeech.2019-2445", 5, "interspeech", 2019]], "Herve Bourlard": [0, ["Unbiased Semi-Supervised LF-MMI Training Using Dropout", ["Sibo Tong", "Apoorv Vyas", "Philip N. Garner", "Herve Bourlard"], "https://doi.org/10.21437/Interspeech.2019-2678", 5, "interspeech", 2019], ["Spectral Subspace Analysis for Automatic Assessment of Pathological Speech Intelligibility", ["Parvaneh Janbakhshi", "Ina Kodrasi", "Herve Bourlard"], "https://doi.org/10.21437/Interspeech.2019-2791", 5, "interspeech", 2019]], "Keelan Evanini": [0, ["Development of Robust Automated Scoring Models Using Adversarial Input for Oral Proficiency Assessment", ["Su-Youn Yoon", "Chong Min Lee", "Klaus Zechner", "Keelan Evanini"], "https://doi.org/10.21437/Interspeech.2019-1711", 5, "interspeech", 2019]], "Michal Zapotoczny": [0, ["Towards Using Context-Dependent Symbols in CTC Without State-Tying Decision Trees", ["Jan Chorowski", "Adrian Lancucki", "Bartosz Kostka", "Michal Zapotoczny"], "https://doi.org/10.21437/Interspeech.2019-2720", 5, "interspeech", 2019]], "Saturnino Luz": [0, ["A System for Real-Time Privacy Preserving Data Collection for Ambient Assisted Living", ["Fasih Haider", "Saturnino Luz"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8037.html", 2, "interspeech", 2019]], "Zhiyuan Peng": [0, ["Combining Adversarial Training and Disentangled Speech Representation for Robust Zero-Resource Subword Modeling", ["Siyuan Feng", "Tan Lee", "Zhiyuan Peng"], "https://doi.org/10.21437/Interspeech.2019-1337", 5, "interspeech", 2019]], "Jon Barker": [0, ["Automatic Lyric Transcription from Karaoke Vocal Tracks: Resources and a Baseline System", ["Gerardo Roa Dabike", "Jon Barker"], "https://doi.org/10.21437/Interspeech.2019-2378", 5, "interspeech", 2019]], "Peter Balazs": [0, ["Harmonic-Aligned Frame Mask Based on Non-Stationary Gabor Transform with Application to Content-Dependent Speaker Comparison", ["Feng Huang", "Peter Balazs"], "https://doi.org/10.21437/Interspeech.2019-1327", 5, "interspeech", 2019]], "Kyuwoong Hwang": [0.9981933534145355, ["An End-to-End Text-Independent Speaker Verification Framework with a Keyword Adversarial Network", ["Sungrack Yun", "Janghoon Cho", "Jungyun Eum", "Wonil Chang", "Kyuwoong Hwang"], "https://doi.org/10.21437/Interspeech.2019-2208", 5, "interspeech", 2019]], "Laurianne Georgeton": [0, ["Are IP Initial Vowels Acoustically More Distinct? Results from LDA and CNN Classifications", ["Fanny Guitard-Ivent", "Gabriele Chignoli", "Cecile Fougeron", "Laurianne Georgeton"], "https://doi.org/10.21437/Interspeech.2019-2153", 5, "interspeech", 2019]], "Hanumant Singh Shekhawat": [0, ["Artificial Bandwidth Extension Using H\u221e Optimization", ["Deepika Gupta", "Hanumant Singh Shekhawat"], "https://doi.org/10.21437/Interspeech.2019-1580", 5, "interspeech", 2019]], "Jordan R. Green": [0, ["Early Identification of Speech Changes Due to Amyotrophic Lateral Sclerosis Using Machine Classification", ["Sarah E. Gutz", "Jun Wang", "Yana Yunusova", "Jordan R. Green"], "https://doi.org/10.21437/Interspeech.2019-2967", 5, "interspeech", 2019], ["Profiling Speech Motor Impairments in Persons with Amyotrophic Lateral Sclerosis: An Acoustic-Based Approach", ["Hannah P. Rowe", "Jordan R. Green"], "https://doi.org/10.21437/Interspeech.2019-2911", 5, "interspeech", 2019], ["Reduced Task Adaptation in Alternating Motion Rate Tasks as an Early Marker of Bulbar Involvement in Amyotrophic Lateral Sclerosis", ["Marziye Eshghi", "Panying Rong", "Antje S. Mefferd", "Kaila L. Stipancic", "Yana Yunusova", "Jordan R. Green"], "https://doi.org/10.21437/Interspeech.2019-2546", 5, "interspeech", 2019]], "Chang Liu": [0, ["Diagnosing Dysarthria with Long Short-Term Memory Networks", ["Alex Mayle", "Zhiwei Mou", "Razvan C. Bunescu", "Sadegh Mirshekarian", "Li Xu", "Chang Liu"], "https://doi.org/10.21437/Interspeech.2019-2903", 5, "interspeech", 2019]], "Eoin Mahon": [0, ["Unified Verbalization for Speech Recognition & Synthesis Across Languages", ["Sandy Ritchie", "Richard Sproat", "Kyle Gorman", "Daan van Esch", "Christian Schallhart", "Nikos Bampounis", "Benoit Brard", "Jonas Fromseier Mortensen", "Millie Holt", "Eoin Mahon"], "https://doi.org/10.21437/Interspeech.2019-2807", 5, "interspeech", 2019]], "Esther de Leeuw": [0, ["An Articulatory-Acoustic Investigation into GOOSE-Fronting in German-English Bilinguals Residing in London, UK", ["Scott Lewis", "Adib Mehrabi", "Esther de Leeuw"], "https://doi.org/10.21437/Interspeech.2019-2637", 5, "interspeech", 2019]], "Danny Crookes": [0, ["Full-Sentence Correlation: A Method to Handle Unpredictable Noise for Robust Speech Recognition", ["Ji Ming", "Danny Crookes"], "https://doi.org/10.21437/Interspeech.2019-2127", 5, "interspeech", 2019]], "Kate Saunders": [0, ["A Path Signature Approach for Speech Emotion Recognition", ["Bo Wang", "Maria Liakata", "Hao Ni", "Terry Lyons", "Alejo J. Nevado-Holgado", "Kate Saunders"], "https://doi.org/10.21437/Interspeech.2019-2624", 5, "interspeech", 2019]], "Gakuto Kurata": [0, ["Direct Neuron-Wise Fusion of Cognate Neural Networks", ["Takashi Fukuda", "Masayuki Suzuki", "Gakuto Kurata"], "https://doi.org/10.21437/Interspeech.2019-1930", 5, "interspeech", 2019]], "Farinaz Koushanfar": [0, ["Universal Adversarial Perturbations for Speech Recognition Systems", ["Paarth Neekhara", "Shehzeen Hussain", "Prakhar Pandey", "Shlomo Dubnov", "Julian J. McAuley", "Farinaz Koushanfar"], "https://doi.org/10.21437/Interspeech.2019-1353", 5, "interspeech", 2019]], "Claude Montacie": [0, ["Spatial, Temporal and Spectral Multiresolution Analysis for the INTERSPEECH 2019 ComParE Challenge", ["Marie-Jose Caraty", "Claude Montacie"], "https://doi.org/10.21437/Interspeech.2019-1693", 5, "interspeech", 2019]], "Vishwas Mruthyunjaya": [0, ["Optimizing Voice Activity Detection for Noisy Conditions", ["Ruixi Lin", "Charles Costello", "Charles Jankowski", "Vishwas Mruthyunjaya"], "https://doi.org/10.21437/Interspeech.2019-1776", 5, "interspeech", 2019]], "Antonio Bonafonte": [0, ["Towards Generalized Speech Enhancement with Generative Adversarial Networks", ["Santiago Pascual", "Joan Serra", "Antonio Bonafonte"], "https://doi.org/10.21437/Interspeech.2019-2688", 5, "interspeech", 2019], ["Prosodic Phrase Alignment for Machine Dubbing", ["Alp Oktem", "Mireia Farrus", "Antonio Bonafonte"], "https://doi.org/10.21437/Interspeech.2019-1621", 5, "interspeech", 2019]], "Florian Schiel": [0, ["Styrian Dialect Classification: Comparing and Fusing Classifiers Based on a Feature Selection Using a Genetic Algorithm", ["Thomas Kisler", "Raphael Winkelmann", "Florian Schiel"], "https://doi.org/10.21437/Interspeech.2019-2540", 5, "interspeech", 2019]], "Nobuaki Minematsu": [0, ["Analysis of Native Listeners' Facial Microexpressions While Shadowing Non-Native Speech - Potential of Shadowers' Facial Expressions for Comprehensibility Prediction", ["Tasavat Trisitichoke", "Shintaro Ando", "Daisuke Saito", "Nobuaki Minematsu"], "https://doi.org/10.21437/Interspeech.2019-1953", 5, "interspeech", 2019]], "Georges Linares": [0, ["M2H-GAN: A GAN-Based Mapping from Machine to Human Transcripts for Speech Understanding", ["Titouan Parcollet", "Mohamed Morchid", "Xavier Bost", "Georges Linares"], "https://doi.org/10.21437/Interspeech.2019-2662", 5, "interspeech", 2019]], "Eric Nyberg": [0, ["Ordinal Triplet Loss: Investigating Sleepiness Detection from Speech", ["Peter Wu", "Sai Krishna Rallabandi", "Alan W. Black", "Eric Nyberg"], "https://doi.org/10.21437/Interspeech.2019-2278", 5, "interspeech", 2019]], "Archana Venkataraman": [0, ["VESUS: A Crowd-Annotated Database to Study Emotion Production and Perception in Spoken English", ["Jacob Sager", "Ravi Shankar", "Jacob Reinhold", "Archana Venkataraman"], "https://doi.org/10.21437/Interspeech.2019-1413", 5, "interspeech", 2019], ["Weakly Supervised Syllable Segmentation by Vowel-Consonant Peak Classification", ["Ravi Shankar", "Archana Venkataraman"], "https://doi.org/10.21437/Interspeech.2019-1450", 5, "interspeech", 2019], ["A Multi-Speaker Emotion Morphing Model Using Highway Networks and Maximum Likelihood Objective", ["Ravi Shankar", "Jacob Sager", "Archana Venkataraman"], "https://doi.org/10.21437/Interspeech.2019-2512", 5, "interspeech", 2019], ["Automated Emotion Morphing in Speech Based on Diffeomorphic Curve Registration and Highway Networks", ["Ravi Shankar", "Hsi-Wei Hsieh", "Nicolas Charon", "Archana Venkataraman"], "https://doi.org/10.21437/Interspeech.2019-2386", 5, "interspeech", 2019]], "Tiago H. Falk": [0, ["Blind Channel Response Estimation for Replay Attack Detection", ["Anderson R. Avila", "Md. Jahangir Alam", "Douglas D. OShaughnessy", "Tiago H. Falk"], "https://doi.org/10.21437/Interspeech.2019-2956", 5, "interspeech", 2019], ["Combining Speaker Recognition and Metric Learning for Speaker-Dependent Representation Learning", ["Joao Monteiro", "Md. Jahangir Alam", "Tiago H. Falk"], "https://doi.org/10.21437/Interspeech.2019-2974", 5, "interspeech", 2019]], "S. R. Mahadeva Prasanna": [0, ["Modification of Devoicing Error in Cleft Lip and Palate Speech", ["Protima Nomo Sudro", "S. R. Mahadeva Prasanna"], "https://doi.org/10.21437/Interspeech.2019-2604", 5, "interspeech", 2019]], "Dilek Hakkani-Tur": [0, ["Towards Universal Dialogue Act Tagging for Task-Oriented Dialogues", ["Shachi Paul", "Rahul Goel", "Dilek Hakkani-Tur"], "https://doi.org/10.21437/Interspeech.2019-1866", 5, "interspeech", 2019], ["HyST: A Hybrid Approach for Flexible and Accurate Dialogue State Tracking", ["Rahul Goel", "Shachi Paul", "Dilek Hakkani-Tur"], "https://doi.org/10.21437/Interspeech.2019-1863", 5, "interspeech", 2019], ["Topical-Chat: Towards Knowledge-Grounded Open-Domain Conversations", ["Karthik Gopalakrishnan", "Behnam Hedayatnia", "Qinglang Chen", "Anna Gottardi", "Sanjeev Kwatra", "Anu Venkatesh", "Raefer Gabriel", "Dilek Hakkani-Tur"], "https://doi.org/10.21437/Interspeech.2019-3079", 5, "interspeech", 2019]], "Marzena Zyla-Hoppe": [0, ["Avaya Conversational Intelligence: A Real-Time System for Spoken Language Understanding in Human-Human Call Center Conversations", ["Jan Mizgajski", "Adrian Szymczak", "Robert Glowski", "Piotr Szymanski", "Piotr Zelasko", "Lukasz Augustyniak", "Mikolaj Morzy", "Yishay Carmiel", "Jeff Hodson", "Lukasz Wojciak", "Daniel Smoczyk", "Adam Wrobel", "Bartosz Borowik", "Adam Artajew", "Marcin Baran", "Cezary Kwiatkowski", "Marzena Zyla-Hoppe"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8002.html", 2, "interspeech", 2019]], "Danwei Cai": [0, ["Survey Talk: End-to-End Deep Neural Network Based Speaker and Language Recognition", ["Ming Li", "Weicheng Cai", "Danwei Cai"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/abs10.html", 0, "interspeech", 2019]], "Kuang-Ching Wang": [7.571926232685655e-07, ["Speech Enhancement Using Forked Generative Adversarial Networks with Spectral Subtraction", ["Ju Lin", "Sufeng Niu", "Zice Wei", "Xiang Lan", "Adriaan J. van Wijngaarden", "Melissa C. Smith", "Kuang-Ching Wang"], "https://doi.org/10.21437/Interspeech.2019-2954", 5, "interspeech", 2019]], "Zhijie Yan": [0, ["Investigation of Transformer Based Spelling Correction Model for CTC-Based End-to-End Mandarin Speech Recognition", ["Shiliang Zhang", "Ming Lei", "Zhijie Yan"], "https://doi.org/10.21437/Interspeech.2019-1290", 5, "interspeech", 2019]], "Yuhang Cao": [0, ["Investigation of Cost Function for Supervised Monaural Speech Separation", ["Yun Liu", "Hui Zhang", "Xueliang Zhang", "Yuhang Cao"], "https://doi.org/10.21437/Interspeech.2019-1897", 5, "interspeech", 2019]], "Ailbhe Ni Chasaide": [0, ["Time to Frequency Domain Mapping of the Voice Source: The Influence of Open Quotient and Glottal Skew on the Low End of the Source Spectrum", ["Christer Gobl", "Ailbhe Ni Chasaide"], "https://doi.org/10.21437/Interspeech.2019-2888", 5, "interspeech", 2019]], "Jinchuan Zhang": [0, ["Latent Topic Attention for Domain Classification", ["Peisong Huang", "Peijie Huang", "Wencheng Ai", "Jiande Ding", "Jinchuan Zhang"], "https://doi.org/10.21437/Interspeech.2019-2228", 5, "interspeech", 2019]], "Bob L. Sturm": [0, ["Ensemble Models for Spoofing Detection in Automatic Speaker Verification", ["Bhusan Chettri", "Daniel Stoller", "Veronica Morfi", "Marco A. Martinez Ramirez", "Emmanouil Benetos", "Bob L. Sturm"], "https://doi.org/10.21437/Interspeech.2019-2505", 5, "interspeech", 2019]], "Jahangir Alam": [0, ["CRIM's Speech Transcription and Call Sign Detection System for the ATC Airbus Challenge Task", ["Vishwa Gupta", "Lise Rebout", "Gilles Boulianne", "Pierre Andre Menard", "Jahangir Alam"], "https://doi.org/10.21437/Interspeech.2019-1131", 5, "interspeech", 2019]], "Daniel Garcia-Romero": [0, ["Speaker Diarization Using Leave-One-Out Gaussian PLDA Clustering of DNN Embeddings", ["Alan McCree", "Gregory Sell", "Daniel Garcia-Romero"], "https://doi.org/10.21437/Interspeech.2019-2912", 5, "interspeech", 2019]], "Mirjam Broersma": [0, ["Foreign-Language Knowledge Enhances Artificial-Language Segmentation", ["Annie Tremblay", "Mirjam Broersma"], "https://doi.org/10.21437/Interspeech.2019-2446", 5, "interspeech", 2019], ["Lexically Guided Perceptual Learning of a Vowel Shift in an Interactive L2 Listening Context", ["E. Felker", "Mirjam Ernestus", "Mirjam Broersma"], "https://doi.org/10.21437/Interspeech.2019-1414", 5, "interspeech", 2019]], "Xu-Cheng Yin": [0, ["Pyramid Memory Block and Timestep Attention for Speech Emotion Recognition", ["Miao Cao", "Chun Yang", "Fang Zhou", "Xu-Cheng Yin"], "https://doi.org/10.21437/Interspeech.2019-3140", 5, "interspeech", 2019]], "Alan W. Black": [0, ["Unsupervised Phonetic and Word Level Discovery for Speech to Speech Translation for Unwritten Languages", ["Steven Hillis", "Anushree Prasanna Kumar", "Alan W. Black"], "https://doi.org/10.21437/Interspeech.2019-3026", 5, "interspeech", 2019], ["Bag-of-Acoustic-Words for Mental Health Assessment: A Deep Autoencoding Approach", ["Wenchao Du", "Louis-Philippe Morency", "Jeffrey F. Cohn", "Alan W. Black"], "https://doi.org/10.21437/Interspeech.2019-3059", 5, "interspeech", 2019], ["Variational Attention Using Articulatory Priors for Generating Code Mixed Speech Using Monolingual Corpora", ["Sai Krishna Rallabandi", "Alan W. Black"], "https://doi.org/10.21437/Interspeech.2019-1103", 5, "interspeech", 2019]], "Adrian Skilling": [0, ["Neural Network-Based Modeling of Phonetic Durations", ["Xizi Wei", "Melvyn Hunt", "Adrian Skilling"], "https://doi.org/10.21437/Interspeech.2019-2102", 5, "interspeech", 2019]], "Shengwu Xiong": [0, ["A Convolutional Neural Network with Non-Local Module for Speech Enhancement", ["Xiaoqi Li", "Yaxing Li", "Meng Li", "Shan Xu", "Yuanjie Dong", "Xinrong Sun", "Shengwu Xiong"], "https://doi.org/10.21437/Interspeech.2019-2472", 5, "interspeech", 2019]], "Elisabetta Farella": [0, ["Neural Network Distillation on IoT Platforms for Sound Event Detection", ["Gianmarco Cerutti", "Rahul Prasad", "Alessio Brutti", "Elisabetta Farella"], "https://doi.org/10.21437/Interspeech.2019-2394", 5, "interspeech", 2019]], "Murat Saraclar": [0, ["Temporally-Aware Acoustic Unit Discovery for Zerospeech 2019 Challenge", ["Bolaji Yusuf", "Alican Gok", "Batuhan Gundogdu", "Oyku Deniz Kose", "Murat Saraclar"], "https://doi.org/10.21437/Interspeech.2019-1430", 5, "interspeech", 2019], ["An Empirical Evaluation of DTW Subsampling Methods for Keyword Search", ["Bolaji Yusuf", "Murat Saraclar"], "https://doi.org/10.21437/Interspeech.2019-2413", 5, "interspeech", 2019]], "H. Wood": [0, ["Splash: Speech and Language Assessment in Schools and Homes", ["A. Miwardelli", "I. Gallagher", "J. Gibson", "Napoleon Katsos", "Kate M. Knill", "H. Wood"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8027.html", 2, "interspeech", 2019]], "Qiang Huo": [0, ["Compression of CTC-Trained Acoustic Models by Dynamic Frame-Wise Distillation or Segment-Wise N-Best Hypotheses Imitation", ["Haisong Ding", "Kai Chen", "Qiang Huo"], "https://doi.org/10.21437/Interspeech.2019-2182", 5, "interspeech", 2019]], "Jianwu Dang": [0, ["Acoustic and Articulatory Study of Ewe Vowels: A Comparative Study of Male and Female", ["Kowovi Comivi Alowonou", "Jianguo Wei", "Wenhuan Lu", "Zhicheng Liu", "Kiyoshi Honda", "Jianwu Dang"], "https://doi.org/10.21437/Interspeech.2019-2196", 5, "interspeech", 2019]], "Ahmad Al-Dahle": [0, ["Coarse-to-Fine Optimization for Speech Enhancement", ["Jian Yao", "Ahmad Al-Dahle"], "https://doi.org/10.21437/Interspeech.2019-2792", 5, "interspeech", 2019]], "Georgia Zellou": [0, ["Expressiveness Influences Human Vocal Alignment Toward voice-AI", ["Michelle Cohn", "Georgia Zellou"], "https://doi.org/10.21437/Interspeech.2019-1368", 5, "interspeech", 2019], ["Individual Variation in Cognitive Processing Style Predicts Differences in Phonetic Imitation of Device and Human Voices", ["Cathryn Snyder", "Michelle Cohn", "Georgia Zellou"], "https://doi.org/10.21437/Interspeech.2019-2669", 5, "interspeech", 2019], ["Perceptual Adaptation to Device and Human Voices: Learning and Generalization of a Phonetic Shift Across Real and Voice-AI Talkers", ["Bruno Ferenc Segedin", "Michelle Cohn", "Georgia Zellou"], "https://doi.org/10.21437/Interspeech.2019-1433", 5, "interspeech", 2019]], "Jan Svec": [0, ["Multimodal Dialog with the MALACH Audiovisual Archive", ["Adam Chylek", "Lubos Smidl", "Jan Svec"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8011.html", 2, "interspeech", 2019]], "Joseph Keshet": [0, ["Dr.VOT: Measuring Positive and Negative Voice Onset Time in the Wild", ["Yosi Shrem", "Matthew Goldrick", "Joseph Keshet"], "https://doi.org/10.21437/Interspeech.2019-1735", 5, "interspeech", 2019], ["SpeechYOLO: Detection and Localization of Speech Objects", ["Yael Segal", "Tzeviya Sylvia Fuchs", "Joseph Keshet"], "https://doi.org/10.21437/Interspeech.2019-1749", 5, "interspeech", 2019]], "Ricardo Gutierrez-Osuna": [0, ["Group Latent Embedding for Vector Quantized Variational Autoencoder in Non-Parallel Voice Conversion", ["Shaojin Ding", "Ricardo Gutierrez-Osuna"], "https://doi.org/10.21437/Interspeech.2019-1198", 5, "interspeech", 2019], ["Foreign Accent Conversion by Synthesizing Speech from Phonetic Posteriorgrams", ["Guanlong Zhao", "Shaojin Ding", "Ricardo Gutierrez-Osuna"], "https://doi.org/10.21437/Interspeech.2019-1778", 5, "interspeech", 2019]], "Anthony Pak-Hin Kong": [5.5142583207934415e-12, ["Automatic Assessment of Language Impairment Based on Raw ASR Output", ["Ying Qin", "Tan Lee", "Anthony Pak-Hin Kong"], "https://doi.org/10.21437/Interspeech.2019-1688", 5, "interspeech", 2019]], "Solen Quiniou": [0, ["Qualitative Evaluation of ASR Adaptation in a Lecture Context: Application to the PASTEL Corpus", ["Salima Mdhaffar", "Yannick Esteve", "Nicolas Hernandez", "Antoine Laurent", "Richard Dufour", "Solen Quiniou"], "https://doi.org/10.21437/Interspeech.2019-2661", 5, "interspeech", 2019]], "Emmanouil Benetos": [0, ["Towards Joint Sound Scene and Polyphonic Sound Event Recognition", ["Helen L. Bear", "Ines Nolasco", "Emmanouil Benetos"], "https://doi.org/10.21437/Interspeech.2019-2169", 5, "interspeech", 2019]], "Dijana Petrovska-Delacretaz": [0, ["Comparison of Telephone Recordings and Professional Microphone Recordings for Early Detection of Parkinson's Disease, Using Mel-Frequency Cepstral Coefficients with Gaussian Mixture Models", ["Laetitia Jeancolas", "Graziella Mangone", "Jean-Christophe Corvol", "Marie Vidailhet", "Stephane Lehericy", "Badr-Eddine Benkelfat", "Habib Benali", "Dijana Petrovska-Delacretaz"], "https://doi.org/10.21437/Interspeech.2019-2825", 5, "interspeech", 2019]], "Dhananjaya Gowda": [0, ["Improved Vocal Tract Length Perturbation for a State-of-the-Art End-to-End Speech Recognition System", ["Chanwoo Kim", "Minkyu Shin", "Abhinav Garg", "Dhananjaya Gowda"], "https://doi.org/10.21437/Interspeech.2019-3227", 5, "interspeech", 2019]], "Yong-cheol Lee": [0.9995790272951126, ["Automatic Detection of Prosodic Focus in American English", ["Sunghye Cho", "Mark Liberman", "Yong-cheol Lee"], "https://doi.org/10.21437/Interspeech.2019-1668", 5, "interspeech", 2019]], "Tomohiro Nakatani": [0, ["End-to-End SpeakerBeam for Single Channel Target Speech Recognition", ["Marc Delcroix", "Shinji Watanabe", "Tsubasa Ochiai", "Keisuke Kinoshita", "Shigeki Karita", "Atsunori Ogawa", "Tomohiro Nakatani"], "https://doi.org/10.21437/Interspeech.2019-1856", 5, "interspeech", 2019], ["Improving Transformer-Based End-to-End Speech Recognition with Connectionist Temporal Classification and Language Model Integration", ["Shigeki Karita", "Nelson Enrique Yalta Soplin", "Shinji Watanabe", "Marc Delcroix", "Atsunori Ogawa", "Tomohiro Nakatani"], "https://doi.org/10.21437/Interspeech.2019-1938", 5, "interspeech", 2019], ["Multimodal SpeakerBeam: Single Channel Target Speech Extraction with Audio-Visual Speaker Clues", ["Tsubasa Ochiai", "Marc Delcroix", "Keisuke Kinoshita", "Atsunori Ogawa", "Tomohiro Nakatani"], "https://doi.org/10.21437/Interspeech.2019-1513", 5, "interspeech", 2019], ["Improved Deep Duel Model for Rescoring N-Best Speech Recognition List Using Backward LSTMLM and Ensemble Encoders", ["Atsunori Ogawa", "Marc Delcroix", "Shigeki Karita", "Tomohiro Nakatani"], "https://doi.org/10.21437/Interspeech.2019-1949", 5, "interspeech", 2019]], "Robert V. Kenyon": [0, ["The Effects of Time Expansion on English as a Second Language Individuals", ["John S. Novak III", "Daniel Bunn", "Robert V. Kenyon"], "https://doi.org/10.21437/Interspeech.2019-2763", 5, "interspeech", 2019]], "Jing Xiao": [0, ["Cross-Lingual, Multi-Speaker Text-To-Speech Synthesis Using Neural Speaker Embedding", ["Mengnan Chen", "Minchuan Chen", "Shuang Liang", "Jun Ma", "Lei Chen", "Shaojun Wang", "Jing Xiao"], "https://doi.org/10.21437/Interspeech.2019-1632", 5, "interspeech", 2019]], "Toshio Irino": [0, ["Predicting Speech Intelligibility of Enhanced Speech Using Phone Accuracy of DNN-Based ASR System", ["Kenichi Arai", "Shoko Araki", "Atsunori Ogawa", "Keisuke Kinoshita", "Tomohiro Nakatani", "Katsuhiko Yamamoto", "Toshio Irino"], "https://doi.org/10.21437/Interspeech.2019-1381", 5, "interspeech", 2019]], "Florian Metze": [0, ["Multilingual Speech Recognition with Corpus Relatedness Sampling", ["Xinjian Li", "Siddharth Dalmia", "Alan W. Black", "Florian Metze"], "https://doi.org/10.21437/Interspeech.2019-3052", 5, "interspeech", 2019], ["Survey Talk: Multimodal Processing of Speech and Language", ["Florian Metze"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/abs22.html", 0, "interspeech", 2019], ["SANTLR: Speech Annotation Toolkit for Low Resource Languages", ["Xinjian Li", "Zhong Zhou", "Siddharth Dalmia", "Alan W. Black", "Florian Metze"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8040.html", 2, "interspeech", 2019], ["Cross-Attention End-to-End ASR for Two-Party Conversations", ["Suyoun Kim", "Siddharth Dalmia", "Florian Metze"], "https://doi.org/10.21437/Interspeech.2019-3173", 5, "interspeech", 2019]], "Juan Soler Company": [0, ["PyToBI: A Toolkit for ToBI Labeling Under Python", ["Monica Dominguez", "Patrick Louis Rohrer", "Juan Soler Company"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8021.html", 2, "interspeech", 2019]], "Michael Picheny": [0, ["Large-Scale Mixed-Bandwidth Deep Neural Network Acoustic Modeling for Automatic Speech Recognition", ["Khoi-Nguyen C. Mac", "Xiaodong Cui", "Wei Zhang", "Michael Picheny"], "https://doi.org/10.21437/Interspeech.2019-2641", 5, "interspeech", 2019], ["Acoustic Model Optimization Based on Evolutionary Stochastic Gradient Descent with Anchors for Automatic Speech Recognition", ["Xiaodong Cui", "Michael Picheny"], "https://doi.org/10.21437/Interspeech.2019-2620", 5, "interspeech", 2019], ["Forget a Bit to Learn Better: Soft Forgetting for CTC-Based Automatic Speech Recognition", ["Kartik Audhkhasi", "George Saon", "Zoltan Tuske", "Brian Kingsbury", "Michael Picheny"], "https://doi.org/10.21437/Interspeech.2019-2841", 5, "interspeech", 2019], ["A Highly Efficient Distributed Deep Learning System for Automatic Speech Recognition", ["Wei Zhang", "Xiaodong Cui", "Ulrich Finkler", "George Saon", "Abdullah Kayi", "Alper Buyuktosunoglu", "Brian Kingsbury", "David S. Kung", "Michael Picheny"], "https://doi.org/10.21437/Interspeech.2019-2700", 5, "interspeech", 2019], ["Detection and Recovery of OOVs for Improved English Broadcast News Captioning", ["Samuel Thomas", "Kartik Audhkhasi", "Zoltan Tuske", "Yinghui Huang", "Michael Picheny"], "https://doi.org/10.21437/Interspeech.2019-2793", 5, "interspeech", 2019]], "Gabor Gosztolya": [0, ["Using Fisher Vector and Bag-of-Audio-Words Representations to Identify Styrian Dialects, Sleepiness, Baby & Orca Sounds", ["Gabor Gosztolya"], "https://doi.org/10.21437/Interspeech.2019-1726", 5, "interspeech", 2019], ["Assessing Parkinson's Disease from Speech Using Fisher Vectors", ["Jose Vicente Egas Lopez", "Juan Rafael Orozco-Arroyave", "Gabor Gosztolya"], "https://doi.org/10.21437/Interspeech.2019-2217", 5, "interspeech", 2019], ["Using the Bag-of-Audio-Word Feature Representation of ASR DNN Posteriors for Paralinguistic Classification", ["Gabor Gosztolya"], "https://doi.org/10.21437/Interspeech.2019-1163", 5, "interspeech", 2019]], "Jan Niehues": [0, ["Survey Talk: A Survey on Speech Translation", ["Jan Niehues"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/abs9.html", 0, "interspeech", 2019]], "Paavo Alku": [0, ["GELP: GAN-Excited Linear Prediction for Speech Synthesis from Mel-Spectrogram", ["Lauri Juvela", "Bajibabu Bollepalli", "Junichi Yamagishi", "Paavo Alku"], "https://doi.org/10.21437/Interspeech.2019-2008", 5, "interspeech", 2019], ["Mel-Frequency Cepstral Coefficients of Voice Source Waveforms for Classification of Phonation Types in Speech", ["Sudarsana Reddy Kadiri", "Paavo Alku"], "https://doi.org/10.21437/Interspeech.2019-2863", 5, "interspeech", 2019], ["Lombard Speech Synthesis Using Transfer Learning in a Tacotron Text-to-Speech System", ["Bajibabu Bollepalli", "Lauri Juvela", "Paavo Alku"], "https://doi.org/10.21437/Interspeech.2019-1333", 5, "interspeech", 2019]], "Tatsuya Kawahara": [0, ["Improved End-to-End Speech Emotion Recognition Using Self Attention Mechanism and Multitask Learning", ["Yuanchao Li", "Tianyu Zhao", "Tatsuya Kawahara"], "https://doi.org/10.21437/Interspeech.2019-2594", 5, "interspeech", 2019], ["Turn-Taking Prediction Based on Detection of Transition Relevance Place", ["Kohei Hara", "Koji Inoue", "Katsuya Takanashi", "Tatsuya Kawahara"], "https://doi.org/10.21437/Interspeech.2019-1537", 5, "interspeech", 2019], ["Analysis of Effect and Timing of Fillers in Natural Turn-Taking", ["Divesh Lala", "Shizuka Nakamura", "Tatsuya Kawahara"], "https://doi.org/10.21437/Interspeech.2019-1527", 5, "interspeech", 2019]], "Roger Zimmermann": [0, ["MobiVSR : Efficient and Light-Weight Neural Network for Visual Speech Recognition on Mobile Devices", ["Nilay Shrivastava", "Astitwa Saxena", "Yaman Kumar", "Rajiv Ratn Shah", "Amanda Stent", "Debanjan Mahata", "Preeti Kaur", "Roger Zimmermann"], "https://doi.org/10.21437/Interspeech.2019-3273", 5, "interspeech", 2019]], "Shan Liu": [0, ["Pre-Trained Text Representations for Improving Front-End Text Processing in Mandarin Text-to-Speech Synthesis", ["Bing Yang", "Jiaqi Zhong", "Shan Liu"], "https://doi.org/10.21437/Interspeech.2019-1418", 5, "interspeech", 2019]], "McKenzie Braley": [0, ["Analyzing Verbal and Nonverbal Features for Predicting Group Performance", ["Uliyana Kubasova", "Gabriel Murray", "McKenzie Braley"], "https://doi.org/10.21437/Interspeech.2019-3062", 5, "interspeech", 2019]], "Priyankoo Sarmah": [0, ["Vowel-Tone Interaction in Two Tibeto-Burman Languages", ["Wendy Lalhminghlui", "Viyazonuo Terhiija", "Priyankoo Sarmah"], "https://doi.org/10.21437/Interspeech.2019-2808", 5, "interspeech", 2019]], "Hiyon Yoo": [0.17531684786081314, ["Phonological Awareness of French Rising Contours in Japanese Learners", ["Rachel Albar", "Hiyon Yoo"], "https://doi.org/10.21437/Interspeech.2019-2856", 5, "interspeech", 2019]], "Bhuvana Ramabhadran": [0, ["Learning to Speak Fluently in a Foreign Language: Multilingual Speech Synthesis and Cross-Language Voice Cloning", ["Yu Zhang", "Ron J. Weiss", "Heiga Zen", "Yonghui Wu", "Zhifeng Chen", "R. J. Skerry-Ryan", "Ye Jia", "Andrew Rosenberg", "Bhuvana Ramabhadran"], "https://doi.org/10.21437/Interspeech.2019-2668", 5, "interspeech", 2019]], "Mathew Magimai-Doss": [0, ["Using Speech Production Knowledge for Raw Waveform Modelling Based Styrian Dialect Identification", ["S. Pavankumar Dubagunta", "Mathew Magimai-Doss"], "https://doi.org/10.21437/Interspeech.2019-2398", 5, "interspeech", 2019]], "Francesco Cangemi": [0, ["Acoustic Cues to Topic and Narrow Focus in Egyptian Arabic", ["Dina El Zarka", "Barbara Schuppler", "Francesco Cangemi"], "https://doi.org/10.21437/Interspeech.2019-1189", 5, "interspeech", 2019]], "Y. Wang": [0.5, ["Impact of ASR Performance on Spoken Grammatical Error Detection", ["Yiting Lu", "Mark J. F. Gales", "Kate M. Knill", "P. P. Manakul", "Linlin Wang", "Y. Wang"], "https://doi.org/10.21437/Interspeech.2019-1706", 5, "interspeech", 2019]], "Volker Fischer": [0, ["Speaker-Corrupted Embeddings for Online Speaker Diarization", ["Omid Ghahabi", "Volker Fischer"], "https://doi.org/10.21437/Interspeech.2019-2756", 5, "interspeech", 2019]], "Xiangang Li": [0, ["Environment-Dependent Attention-Driven Recurrent Convolutional Neural Network for Robust Speech Enhancement", ["Meng Ge", "Longbiao Wang", "Nan Li", "Hao Shi", "Jianwu Dang", "Xiangang Li"], "https://doi.org/10.21437/Interspeech.2019-1477", 5, "interspeech", 2019], ["Learning Alignment for Multimodal Emotion Recognition from Speech", ["Haiyang Xu", "Hui Zhang", "Kun Han", "Yun Wang", "Yiping Peng", "Xiangang Li"], "https://doi.org/10.21437/Interspeech.2019-3247", 5, "interspeech", 2019]], "Antoine Bruguier": [0, ["Better Morphology Prediction for Better Speech Systems", ["Dravyansh Sharma", "Melissa Wilson", "Antoine Bruguier"], "https://doi.org/10.21437/Interspeech.2019-3207", 5, "interspeech", 2019]], "Daan Wissing": [0, ["Online Speech Processing and Analysis Suite", ["Wikus Pienaar", "Daan Wissing"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8007.html", 2, "interspeech", 2019]], "Masafumi Nishimura": [0, ["Knowledge Distillation for Throat Microphone Speech Recognition", ["Takahito Suzuki", "Jun Ogata", "Takashi Tsunakawa", "Masafumi Nishida", "Masafumi Nishimura"], "https://doi.org/10.21437/Interspeech.2019-1597", 5, "interspeech", 2019]], "Thomas Drugman": [0, ["Fine-Grained Robust Prosody Transfer for Single-Speaker Neural Text-To-Speech", ["Viacheslav Klimkov", "Srikanth Ronanki", "Jonas Rohnke", "Thomas Drugman"], "https://doi.org/10.21437/Interspeech.2019-2571", 5, "interspeech", 2019]], "Golan Pundak": [0, ["Phoneme-Based Contextualization for Cross-Lingual Speech Recognition in End-to-End Models", ["Ke Hu", "Antoine Bruguier", "Tara N. Sainath", "Rohit Prabhavalkar", "Golan Pundak"], "https://doi.org/10.21437/Interspeech.2019-1868", 5, "interspeech", 2019]], "Louis Boves": [0, ["Phase Synchronization Between EEG Signals as a Function of Differences Between Stimuli Characteristics", ["Louis ten Bosch", "Kimberley Mulder", "Louis Boves"], "https://doi.org/10.21437/Interspeech.2019-2443", 5, "interspeech", 2019]], "Dong Wang": [0.1973298266530037, ["VAE-Based Regularization for Deep Speaker Embedding", ["Yang Zhang", "Lantian Li", "Dong Wang"], "https://doi.org/10.21437/Interspeech.2019-2486", 5, "interspeech", 2019]], "Yao Qian": [0, ["Automatic Detection of Off-Topic Spoken Responses Using Very Deep Convolutional Neural Networks", ["Xinhao Wang", "Su-Youn Yoon", "Keelan Evanini", "Klaus Zechner", "Yao Qian"], "https://doi.org/10.21437/Interspeech.2019-1848", 5, "interspeech", 2019]], "Ying-Hui Lai": [0, ["Consonant Classification in Mandarin Based on the Depth Image Feature: A Pilot Study", ["Han-Chi Hsieh", "Wei-Zhong Zheng", "Ko-Chiang Chen", "Ying-Hui Lai"], "https://doi.org/10.21437/Interspeech.2019-1893", 5, "interspeech", 2019]], "Maja Pantic": [0, ["Investigating the Lombard Effect Influence on End-to-End Audio-Visual Speech Recognition", ["Pingchuan Ma", "Stavros Petridis", "Maja Pantic"], "https://doi.org/10.21437/Interspeech.2019-2726", 5, "interspeech", 2019], ["Video-Driven Speech Reconstruction Using Generative Adversarial Networks", ["Konstantinos Vougioukas", "Pingchuan Ma", "Stavros Petridis", "Maja Pantic"], "https://doi.org/10.21437/Interspeech.2019-1445", 5, "interspeech", 2019]], "Andreas Nautsch": [0, ["Survey Talk: Preserving Privacy in Speaker and Speech Characterisation", ["Andreas Nautsch"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/abs11.html", 0, "interspeech", 2019]], "Rainer Martin": [0, ["Privacy-Preserving Siamese Feature Extraction for Gender Recognition versus Speaker Identification", ["Alexandru Nelus", "Silas Rech", "Timm Koppelmann", "Henrik Biermann", "Rainer Martin"], "https://doi.org/10.21437/Interspeech.2019-1148", 5, "interspeech", 2019], ["Privacy-Preserving Variational Information Feature Extraction for Domestic Activity Monitoring versus Speaker Identification", ["Alexandru Nelus", "Janek Ebbers", "Reinhold Haeb-Umbach", "Rainer Martin"], "https://doi.org/10.21437/Interspeech.2019-1703", 5, "interspeech", 2019]], "Agustin Gravano": [0, ["Voice Quality as a Turn-Taking Cue", ["Mattias Heldner", "Marcin Wlodarczak", "Stefan Benus", "Agustin Gravano"], "https://doi.org/10.21437/Interspeech.2019-1592", 5, "interspeech", 2019]], "Jan Volin": [0, ["Perceptual Evaluation of Early versus Late F0 Peaks in the Intonation Structure of Czech Question-Word Questions", ["Pavel Sturm", "Jan Volin"], "https://doi.org/10.21437/Interspeech.2019-2082", 5, "interspeech", 2019]], "Chao Wang": [0.3783327341079712, ["Sub-Band Convolutional Neural Networks for Small-Footprint Spoken Term Classification", ["Chieh-Chi Kao", "Ming Sun", "Yixin Gao", "Shiv Vitaladevuni", "Chao Wang"], "https://doi.org/10.21437/Interspeech.2019-1766", 5, "interspeech", 2019], ["Compression of Acoustic Event Detection Models with Quantized Distillation", ["Bowen Shi", "Ming Sun", "Chieh-Chi Kao", "Viktor Rozgic", "Spyros Matsoukas", "Chao Wang"], "https://doi.org/10.21437/Interspeech.2019-1747", 5, "interspeech", 2019]], "Aurobinda Routray": [0, ["Automatic Detection of Breath Using Voice Activity Detection and SVM Classifier with Application on News Reports", ["Mohamed Ismail Yasar Arafath K", "Aurobinda Routray"], "https://doi.org/10.21437/Interspeech.2019-2434", 5, "interspeech", 2019]], "Volker Dellwo": [0, ["Formant Pattern and Spectral Shape Ambiguity of Vowel Sounds, and Related Phenomena of Vowel Acoustics - Exemplary Evidence", ["Dieter Maurer", "Heidy Suter", "Christian dHereuse", "Volker Dellwo"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8017.html", 2, "interspeech", 2019], ["Fundamental Frequency Accommodation in Multi-Party Human-Robot Game Interactions: The Effect of Winning or Losing", ["Omnia Ibrahim", "Gabriel Skantze", "Sabine Stoll", "Volker Dellwo"], "https://doi.org/10.21437/Interspeech.2019-2496", 5, "interspeech", 2019]], "Javier Ferreiros Lopez": [0, ["Attention-Based Word Vector Prediction with LSTMs and its Application to the OOV Problem in ASR", ["Alejandro Coucheiro-Limeres", "Fernando Fernandez-Martinez", "Ruben San Segundo", "Javier Ferreiros Lopez"], "https://doi.org/10.21437/Interspeech.2019-2347", 5, "interspeech", 2019]], "Doina Precup": [0, ["Neural Transfer Learning for Cry-Based Diagnosis of Perinatal Asphyxia", ["Charles C. Onu", "Jonathan Lebensold", "William L. Hamilton", "Doina Precup"], "https://doi.org/10.21437/Interspeech.2019-2340", 5, "interspeech", 2019]], "Masato Akagi": [0, ["The Contribution of Acoustic Features Analysis to Model Emotion Perceptual Process for Language Diversity", ["Xingfeng Li", "Masato Akagi"], "https://doi.org/10.21437/Interspeech.2019-2229", 5, "interspeech", 2019]], "Jordan L. Boyd-Graber": [0, ["Mitigating Noisy Inputs for Question Answering", ["Denis Peskov", "Joe Barrow", "Pedro Rodriguez", "Graham Neubig", "Jordan L. Boyd-Graber"], "https://doi.org/10.21437/Interspeech.2019-3154", 5, "interspeech", 2019]], "Wentao Gu": [1.1605677252557456e-09, ["Prosodic Characteristics of Mandarin Declarative and Interrogative Utterances in Parkinson's Disease", ["Lei Liu", "Meng Jian", "Wentao Gu"], "https://doi.org/10.21437/Interspeech.2019-3276", 5, "interspeech", 2019]], "Shugong Xu": [0, ["Two-Stage Training for Chinese Dialect Recognition", ["Zongze Ren", "Guofu Yang", "Shugong Xu"], "https://doi.org/10.21437/Interspeech.2019-1522", 5, "interspeech", 2019]], "Philipp Meer": [0, ["Sibilant Variation in New Englishes: A Comparative Sociophonetic Study of Trinidadian and American English /s(tr)/-Retraction", ["Wiebke Ahlers", "Philipp Meer"], "https://doi.org/10.21437/Interspeech.2019-1821", 5, "interspeech", 2019]], "Mohammed Sidi Yakoub": [0, ["Linear Discriminant Differential Evolution for Feature Selection in Emotional Speech Recognition", ["Soumaya Gharsellaoui", "Sid-Ahmed Selouani", "Mohammed Sidi Yakoub"], "https://doi.org/10.21437/Interspeech.2019-1218", 5, "interspeech", 2019]], "Julia Hirschberg": [0, ["Predicting Humor by Learning from Time-Aligned Comments", ["Zixiaofan Yang", "Bingyan Hu", "Julia Hirschberg"], "https://doi.org/10.21437/Interspeech.2019-3113", 5, "interspeech", 2019], ["Linguistically-Informed Training of Acoustic Word Embeddings for Low-Resource Languages", ["Zixiaofan Yang", "Julia Hirschberg"], "https://doi.org/10.21437/Interspeech.2019-3119", 5, "interspeech", 2019], ["Improving Code-Switched Language Modeling Performance Using Cognate Features", ["Victor Soto", "Julia Hirschberg"], "https://doi.org/10.21437/Interspeech.2019-2681", 5, "interspeech", 2019]], "Sonja Rossi": [0, ["The Influence of Distraction on Speech Processing: How Selective is Selective Attention?", ["Sandra I. Parhammer", "Miriam Ebersberg", "Jenny Tippmann", "Katja Stark", "Andreas Opitz", "Barbara Hinger", "Sonja Rossi"], "https://doi.org/10.21437/Interspeech.2019-2699", 5, "interspeech", 2019]], "Peter Bell": [0, ["Lattice-Based Lightly-Supervised Acoustic Model Training", ["Joachim Fainberg", "Ondrej Klejch", "Steve Renals", "Peter Bell"], "https://doi.org/10.21437/Interspeech.2019-2533", 5, "interspeech", 2019]], "Ralf Schluter": [0, ["Survey Talk: Modeling in Automatic Speech Recognition: Beyond Hidden Markov Models", ["Ralf Schluter"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/abs4.html", 0, "interspeech", 2019]], "Premkumar Natarajan": [0, ["NIESR: Nuisance Invariant End-to-End Speech Recognition", ["I-Hung Hsu", "Ayush Jaiswal", "Premkumar Natarajan"], "https://doi.org/10.21437/Interspeech.2019-1836", 5, "interspeech", 2019]], "Nam Soo Kim": [1, ["End-to-End Multi-Channel Speech Enhancement Using Inter-Channel Time-Restricted Attention on Raw Waveform", ["Hyeon Seung Lee", "Hyung Yong Kim", "Woo Hyun Kang", "Jeunghun Kim", "Nam Soo Kim"], "https://doi.org/10.21437/Interspeech.2019-2397", 5, "interspeech", 2019]], "Ming Li": [0, ["The DKU Replay Detection System for the ASVspoof 2019 Challenge: On Data Augmentation, Feature Representation, Classification, and Fusion", ["Weicheng Cai", "Haiwei Wu", "Danwei Cai", "Ming Li"], "https://doi.org/10.21437/Interspeech.2019-1230", 5, "interspeech", 2019], ["Polyphone Disambiguation for Mandarin Chinese Using Conditional Neural Network with Multi-Level Embedding Features", ["Zexin Cai", "Yaogen Yang", "Chuxiong Zhang", "Xiaoyi Qin", "Ming Li"], "https://doi.org/10.21437/Interspeech.2019-1235", 5, "interspeech", 2019], ["The DKU-LENOVO Systems for the INTERSPEECH 2019 Computational Paralinguistic Challenge", ["Haiwei Wu", "Weiqing Wang", "Ming Li"], "https://doi.org/10.21437/Interspeech.2019-1386", 5, "interspeech", 2019], ["The DKU System for the Speaker Recognition Task of the 2019 VOiCES from a Distance Challenge", ["Danwei Cai", "Xiaoyi Qin", "Weicheng Cai", "Ming Li"], "https://doi.org/10.21437/Interspeech.2019-1435", 5, "interspeech", 2019], ["Far-Field End-to-End Text-Dependent Speaker Verification Based on Mixed Training Data with Transfer Learning and Enrollment Data Augmentation", ["Xiaoyi Qin", "Danwei Cai", "Ming Li"], "https://doi.org/10.21437/Interspeech.2019-1542", 5, "interspeech", 2019], ["Multi-Channel Training for End-to-End Speaker Recognition Under Reverberant and Noisy Environment", ["Danwei Cai", "Xiaoyi Qin", "Ming Li"], "https://doi.org/10.21437/Interspeech.2019-1437", 5, "interspeech", 2019], ["The DKU-SMIIP System for NIST 2018 Speaker Recognition Evaluation", ["Danwei Cai", "Weicheng Cai", "Ming Li"], "https://doi.org/10.21437/Interspeech.2019-1436", 5, "interspeech", 2019]], "Jan Skoglund": [0, ["Salient Speech Representations Based on Cloned Networks", ["W. Bastiaan Kleijn", "Felicia S. C. Lim", "Michael Chinen", "Jan Skoglund"], "https://doi.org/10.21437/Interspeech.2019-1861", 5, "interspeech", 2019], ["A Real-Time Wideband Neural Vocoder at 1.6kb/s Using LPCNet", ["Jean-Marc Valin", "Jan Skoglund"], "https://doi.org/10.21437/Interspeech.2019-1255", 5, "interspeech", 2019]], "DeLiang Wang": [0.0001271415312658064, ["Bridging the Gap Between Monaural Speech Enhancement and Recognition with Distortion-Independent Acoustic Modeling", ["Peidong Wang", "Ke Tan", "DeLiang Wang"], "https://doi.org/10.21437/Interspeech.2019-1495", 5, "interspeech", 2019], ["Enhanced Spectral Features for Distortion-Independent Acoustic Modeling", ["Peidong Wang", "DeLiang Wang"], "https://doi.org/10.21437/Interspeech.2019-1493", 5, "interspeech", 2019], ["Deep Learning Based Multi-Channel Speaker Recognition in Noisy and Reverberant Environments", ["Hassan Taherian", "Zhong-Qiu Wang", "DeLiang Wang"], "https://doi.org/10.21437/Interspeech.2019-1428", 5, "interspeech", 2019], ["Deep Learning for Joint Acoustic Echo and Noise Cancellation with Nonlinear Distortions", ["Hao Zhang", "Ke Tan", "DeLiang Wang"], "https://doi.org/10.21437/Interspeech.2019-2651", 5, "interspeech", 2019]], "Lei He": [0, ["Robust Sequence-to-Sequence Acoustic Modeling with Stepwise Monotonic Attention for Neural TTS", ["Mutian He", "Yan Deng", "Lei He"], "https://doi.org/10.21437/Interspeech.2019-1972", 5, "interspeech", 2019]], "Alfons Juan": [0, ["Real-Time One-Pass Decoder for Speech Recognition Using LSTM Language Models", ["Javier Jorge", "Adria Gimenez", "Javier Iranzo-Sanchez", "Jorge Civera", "Albert Sanchis", "Alfons Juan"], "https://doi.org/10.21437/Interspeech.2019-2798", 5, "interspeech", 2019]], "Christophe Cerisara": [0, ["Multi-Lingual Dialogue Act Recognition with Deep Learning Methods", ["Jiri Martinek", "Pavel Kral", "Ladislav Lenc", "Christophe Cerisara"], "https://doi.org/10.21437/Interspeech.2019-1691", 5, "interspeech", 2019]], "Heidi Christensen": [0, ["Automatic Hierarchical Attention Neural Network for Detecting AD", ["Yilin Pan", "Bahman Mirheidari", "Markus Reuber", "Annalena Venneri", "Daniel Blackburn", "Heidi Christensen"], "https://doi.org/10.21437/Interspeech.2019-1799", 5, "interspeech", 2019]], "Yucel Yemez": [0, ["Speech Driven Backchannel Generation Using Deep Q-Network for Enhancing Engagement in Human-Robot Interaction", ["Nusrah Hussain", "Engin Erzin", "T. Metin Sezgin", "Yucel Yemez"], "https://doi.org/10.21437/Interspeech.2019-2521", 5, "interspeech", 2019]], "Renato De Mori": [0, ["Real to H-Space Encoder for Speech Recognition", ["Titouan Parcollet", "Mohamed Morchid", "Georges Linares", "Renato De Mori"], "https://doi.org/10.21437/Interspeech.2019-1539", 5, "interspeech", 2019]], "Emmanuel Ferragne": [0, ["The Contribution of Lip Protrusion to Anglo-English /r/: Evidence from Hyper- and Non-Hyperarticulated Speech", ["Hannah King", "Emmanuel Ferragne"], "https://doi.org/10.21437/Interspeech.2019-2851", 5, "interspeech", 2019]], "Youjue He": [0, ["Frication as a Vowel Feature? - Evidence from the Rui'an Wu Chinese Dialect", ["Fang Hu", "Youjue He"], "https://doi.org/10.21437/Interspeech.2019-1134", 5, "interspeech", 2019]], "Kai Yu": [0.007579648867249489, ["The SJTU Robust Anti-Spoofing System for the ASVspoof 2019 Challenge", ["Yexin Yang", "Hongji Wang", "Heinrich Dinkel", "Zhengyang Chen", "Shuai Wang", "Yanmin Qian", "Kai Yu"], "https://doi.org/10.21437/Interspeech.2019-2170", 5, "interspeech", 2019], ["Data Augmentation Using Variational Autoencoder for Embedding Based Speaker Verification", ["Zhanghao Wu", "Shuai Wang", "Yanmin Qian", "Kai Yu"], "https://doi.org/10.21437/Interspeech.2019-2248", 5, "interspeech", 2019], ["Joint Decoding of CTC Based Systems for Speech Recognition", ["Jiaqi Guo", "Yongbin You", "Yanmin Qian", "Kai Yu"], "https://doi.org/10.21437/Interspeech.2019-2026", 5, "interspeech", 2019], ["Cross-Domain Replay Spoofing Attack Detection Using Domain Adversarial Training", ["Hongji Wang", "Heinrich Dinkel", "Shuai Wang", "Yanmin Qian", "Kai Yu"], "https://doi.org/10.21437/Interspeech.2019-2120", 5, "interspeech", 2019]], "Aaron Lawson": [0, ["The VOiCES from a Distance Challenge 2019", ["Mahesh Kumar Nandwana", "Julien van Hout", "Colleen Richey", "Mitchell McLaren", "Maria Auxiliadora Barrios", "Aaron Lawson"], "https://doi.org/10.21437/Interspeech.2019-1837", 5, "interspeech", 2019], ["The VOiCES from a Distance Challenge 2019", ["Mahesh Kumar Nandwana", "Julien van Hout", "Colleen Richey", "Mitchell McLaren", "Maria Alejandra Barrios", "Aaron Lawson"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/abs14.html", 0, "interspeech", 2019], ["Analysis of Critical Metadata Factors for the Calibration of Speaker Recognition Systems", ["Mahesh Kumar Nandwana", "Luciana Ferrer", "Mitchell McLaren", "Diego Castan", "Aaron Lawson"], "https://doi.org/10.21437/Interspeech.2019-1808", 5, "interspeech", 2019]], "Yossi Matias": [0, ["Personalizing ASR for Dysarthric and Accented Speech with Limited Data", ["Joel Shor", "Dotan Emanuel", "Oran Lang", "Omry Tuval", "Michael Brenner", "Julie Cattiau", "Fernando Vieira", "Maeve McNally", "Taylor Charbonneau", "Melissa Nollstadt", "Avinatan Hassidim", "Yossi Matias"], "https://doi.org/10.21437/Interspeech.2019-1427", 5, "interspeech", 2019]], "Rebecca Nissen": [0, ["Using Real-Time Visual Biofeedback for Second Language Instruction", ["Shawn L. Nissen", "Rebecca Nissen"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8016.html", 2, "interspeech", 2019]], "Chandra Sekhar Seelamantula": [0, ["On the Suitability of the Riesz Spectro-Temporal Envelope for WaveNet Based Speech Synthesis", ["Jitendra Kumar Dhiman", "Nagaraj Adiga", "Chandra Sekhar Seelamantula"], "https://doi.org/10.21437/Interspeech.2019-2626", 5, "interspeech", 2019]], "Thomas Mulc": [0, ["CSS10: A Collection of Single Speaker Speech Datasets for 10 Languages", ["Kyubyong Park", "Thomas Mulc"], "https://doi.org/10.21437/Interspeech.2019-1500", 5, "interspeech", 2019]], "Shan Luo": [0, ["Phonetic Detail Encoding in Explaining the Size of Speech Planning Window", ["Shan Luo"], "https://doi.org/10.21437/Interspeech.2019-1412", 5, "interspeech", 2019]], "Prathosh A. P.": [0, ["Detection of Glottal Closure Instants from Raw Speech Using Convolutional Neural Networks", ["Mohit Goyal", "Varun Srivastava", "Prathosh A. P."], "https://doi.org/10.21437/Interspeech.2019-2587", 5, "interspeech", 2019]], "Vatsal Aggarwal": [0, ["Towards Achieving Robust Universal Neural Vocoding", ["Jaime Lorenzo-Trueba", "Thomas Drugman", "Javier Latorre", "Thomas Merritt", "Bartosz Putrycz", "Roberto Barra-Chicote", "Alexis Moinet", "Vatsal Aggarwal"], "https://doi.org/10.21437/Interspeech.2019-1424", 5, "interspeech", 2019]], "Tao Ma": [0, ["Survey Talk: When Attention Meets Speech Applications: Speech & Speaker Recognition Perspective", ["Kyu J. Han", "Ramon Prieto", "Tao Ma"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/abs5.html", 0, "interspeech", 2019]], "Changliang Li": [0, ["Jointly Adversarial Enhancement Training for Robust End-to-End Speech Recognition", ["Bin Liu", "Shuai Nie", "Shan Liang", "Wenju Liu", "Meng Yu", "Lianwu Chen", "Shouye Peng", "Changliang Li"], "https://doi.org/10.21437/Interspeech.2019-1242", 5, "interspeech", 2019], ["Direction-Aware Speaker Beam for Multi-Channel Speaker Extraction", ["Guanjun Li", "Shan Liang", "Shuai Nie", "Wenju Liu", "Meng Yu", "Lianwu Chen", "Shouye Peng", "Changliang Li"], "https://doi.org/10.21437/Interspeech.2019-1474", 5, "interspeech", 2019]], "Tran Huy Dat": [0, ["The I2R's ASR System for the VOiCES from a Distance Challenge 2019", ["Tze Yuang Chong", "Kye Min Tan", "Kah Kuan Teh", "Chang Huai You", "Hanwu Sun", "Tran Huy Dat"], "https://doi.org/10.21437/Interspeech.2019-2130", 5, "interspeech", 2019], ["The I2R's ASR System for the VOiCES from a Distance Challenge 2019", ["Tze Yuang Chong", "Kye Min Tan", "Kah Kuan Teh", "Chang Huai You", "Hanwu Sun", "Tran Huy Dat"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/abs18.html", 0, "interspeech", 2019], ["The I2R's Submission to VOiCES Distance Speaker Recognition Challenge 2019", ["Hanwu Sun", "Kah Kuan Teh", "Ivan Kukanov", "Tran Huy Dat"], "https://doi.org/10.21437/Interspeech.2019-1997", 5, "interspeech", 2019]], "Reinhold Haeb-Umbach": [0, ["Guided Source Separation Meets a Strong ASR Backend: Hitachi/Paderborn University Joint Investigation for Dinner Party ASR", ["Naoyuki Kanda", "Christoph Boddeker", "Jens Heitkaemper", "Yusuke Fujita", "Shota Horiguchi", "Kenji Nagamatsu", "Reinhold Haeb-Umbach"], "https://doi.org/10.21437/Interspeech.2019-1167", 5, "interspeech", 2019], ["Unsupervised Training of Neural Mask-Based Beamforming", ["Lukas Drude", "Jahn Heymann", "Reinhold Haeb-Umbach"], "https://doi.org/10.21437/Interspeech.2019-2549", 5, "interspeech", 2019]], "Mark Liberman": [0, ["The Second DIHARD Diarization Challenge: Dataset, Task, and Baselines", ["Neville Ryant", "Kenneth Church", "Christopher Cieri", "Alejandrina Cristia", "Jun Du", "Sriram Ganapathy", "Mark Liberman"], "https://doi.org/10.21437/Interspeech.2019-1268", 5, "interspeech", 2019]], "Daniele Giacobello": [0, ["Exploiting Multi-Channel Speech Presence Probability in Parametric Multi-Channel Wiener Filter", ["Saeed Bagheri", "Daniele Giacobello"], "https://doi.org/10.21437/Interspeech.2019-2665", 5, "interspeech", 2019]], "John Sabatini": [0, ["Automated Estimation of Oral Reading Fluency During Summer Camp e-Book Reading with MyTurnToRead", ["Anastassia Loukina", "Beata Beigman Klebanov", "Patrick L. Lange", "Yao Qian", "Binod Gyawali", "Nitin Madnani", "Abhinav Misra", "Klaus Zechner", "Zuowei Wang", "John Sabatini"], "https://doi.org/10.21437/Interspeech.2019-2889", 5, "interspeech", 2019]], "Nigel Cannings": [0, ["Explaining Sentiment Classification", ["Marvin Rajwadi", "Cornelius Glackin", "Julie A. Wall", "Gerard Chollet", "Nigel Cannings"], "https://doi.org/10.21437/Interspeech.2019-2743", 5, "interspeech", 2019]], "Shrikanth Narayanan": [0, ["Data Augmentation Using GANs for Speech Emotion Recognition", ["Aggelina Chatziagapi", "Georgios Paraskevopoulos", "Dimitris Sgouropoulos", "Georgios Pantazopoulos", "Malvina Nikandrou", "Theodoros Giannakopoulos", "Athanasios Katsamanis", "Alexandros Potamianos", "Shrikanth Narayanan"], "https://doi.org/10.21437/Interspeech.2019-2561", 5, "interspeech", 2019], ["Speaker Diarization with Lexical Information", ["Tae Jin Park", "Kyu J. Han", "Jing Huang", "Xiaodong He", "Bowen Zhou", "Panayiotis G. Georgiou", "Shrikanth Narayanan"], "https://doi.org/10.21437/Interspeech.2019-1947", 5, "interspeech", 2019], ["The Second DIHARD Challenge: System Description for USC-SAIL Team", ["Tae Jin Park", "Manoj Kumar", "Nikolaos Flemotomos", "Monisankha Pal", "Raghuveer Peri", "Rimita Lahiri", "Panayiotis G. Georgiou", "Shrikanth Narayanan"], "https://doi.org/10.21437/Interspeech.2019-1903", 5, "interspeech", 2019], ["Modeling Interpersonal Linguistic Coordination in Conversations Using Word Mover's Distance", ["Md. Nasir", "Sandeep Nallan Chakravarthula", "Brian R. W. Baucom", "David C. Atkins", "Panayiotis G. Georgiou", "Shrikanth Narayanan"], "https://doi.org/10.21437/Interspeech.2019-1900", 5, "interspeech", 2019], ["Identifying Therapist and Client Personae for Therapeutic Alliance Estimation", ["Victor R. Martinez", "Nikolaos Flemotomos", "Victor Ardulov", "Krishna Somandepalli", "Simon B. Goldberg", "Zac E. Imel", "David C. Atkins", "Shrikanth Narayanan"], "https://doi.org/10.21437/Interspeech.2019-2829", 5, "interspeech", 2019], ["Multiview Shared Subspace Learning Across Speakers and Speech Commands", ["Krishna Somandepalli", "Naveen Kumar", "Arindam Jati", "Panayiotis G. Georgiou", "Shrikanth Narayanan"], "https://doi.org/10.21437/Interspeech.2019-3130", 5, "interspeech", 2019], ["Multi-Task Discriminative Training of Hybrid DNN-TVM Model for Speaker Verification with Noisy and Far-Field Speech", ["Arindam Jati", "Raghuveer Peri", "Monisankha Pal", "Tae Jin Park", "Naveen Kumar", "Ruchir Travadi", "Panayiotis G. Georgiou", "Shrikanth Narayanan"], "https://doi.org/10.21437/Interspeech.2019-3010", 5, "interspeech", 2019]], "Olaitan Olaleye": [0, ["Nonparallel Emotional Speech Conversion", ["Jian Gao", "Deep Chakraborty", "Hamidou Tembine", "Olaitan Olaleye"], "https://doi.org/10.21437/Interspeech.2019-2878", 5, "interspeech", 2019]], "Chung-Cheng Chiu": [0, ["Two-Pass End-to-End Speech Recognition", ["Tara N. Sainath", "Ruoming Pang", "David Rybach", "Yanzhang He", "Rohit Prabhavalkar", "Wei Li", "Mirko Visontai", "Qiao Liang", "Trevor Strohman", "Yonghui Wu", "Ian McGraw", "Chung-Cheng Chiu"], "https://doi.org/10.21437/Interspeech.2019-1341", 5, "interspeech", 2019]], "Nikko Strom": [0, ["Two Tiered Distributed Training Algorithm for Acoustic Modeling", ["Pranav Ladkat", "Oleg Rybakov", "Radhika Arava", "Sree Hari Krishnan Parthasarathi", "I-Fan Chen", "Nikko Strom"], "https://doi.org/10.21437/Interspeech.2019-1859", 5, "interspeech", 2019]], "Takafumi Koshinaka": [0, ["Unleashing the Unused Potential of i-Vectors Enabled by GPU Acceleration", ["Ville Vestman", "Kong Aik Lee", "Tomi H. Kinnunen", "Takafumi Koshinaka"], "https://doi.org/10.21437/Interspeech.2019-1955", 5, "interspeech", 2019], ["Speaker Augmentation and Bandwidth Extension for Deep Speaker Embedding", ["Hitoshi Yamamoto", "Kong Aik Lee", "Koji Okabe", "Takafumi Koshinaka"], "https://doi.org/10.21437/Interspeech.2019-1508", 5, "interspeech", 2019]], "Pierre Lanchantin": [0, ["Investigating the Effects of Noisy and Reverberant Speech in Text-to-Speech Systems", ["David Ayllon", "Hector A. Sanchez-Hevia", "Carol Figueroa", "Pierre Lanchantin"], "https://doi.org/10.21437/Interspeech.2019-3104", 5, "interspeech", 2019], ["Selection and Training Schemes for Improving TTS Voice Built on Found Data", ["Fang-Yu Kuo", "Iris Chuoying Ouyang", "Sandesh Aryal", "Pierre Lanchantin"], "https://doi.org/10.21437/Interspeech.2019-2816", 5, "interspeech", 2019], ["A Strategy for Improved Phone-Level Lyrics-to-Audio Alignment for Speech-to-Singing Synthesis", ["David Ayllon", "Fernando Villavicencio", "Pierre Lanchantin"], "https://doi.org/10.21437/Interspeech.2019-3049", 5, "interspeech", 2019]], "Hong Kook Kim": [0.9972290098667145, ["Directional Audio Rendering Using a Neural Network Based Personalized HRTF", ["Geon Woo Lee", "Jung Hyuk Lee", "Seong Ju Kim", "Hong Kook Kim"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8005.html", 2, "interspeech", 2019]], "Nan Yan": [0, ["Towards the Speech Features of Mild Cognitive Impairment: Universal Evidence from Structured and Unstructured Connected Speech of Chinese", ["Tianqi Wang", "Chongyuan Lian", "Jingshen Pan", "Quanlei Yan", "Feiqi Zhu", "Manwa L. Ng", "Lan Wang", "Nan Yan"], "https://doi.org/10.21437/Interspeech.2019-2414", 5, "interspeech", 2019], ["Towards the Speech Features of Early-Stage Dementia: Design and Application of the Mandarin Elderly Cognitive Speech Database", ["Tianqi Wang", "Quanlei Yan", "Jingshen Pan", "Feiqi Zhu", "Rongfeng Su", "Yi Guo", "Lan Wang", "Nan Yan"], "https://doi.org/10.21437/Interspeech.2019-2453", 5, "interspeech", 2019]], "Giuseppe Riccardi": [0, ["Active Annotation: Bootstrapping Annotation Lexicon and Guidelines for Supervised NLU Learning", ["Federico Marinelli", "Alessandra Cervone", "Giuliano Tortoreto", "Evgeny A. Stepanov", "Giuseppe Di Fabbrizio", "Giuseppe Riccardi"], "https://doi.org/10.21437/Interspeech.2019-2537", 5, "interspeech", 2019], ["Modeling User Context for Valence Prediction from Narratives", ["Aniruddha Tammewar", "Alessandra Cervone", "Eva-Maria Messner", "Giuseppe Riccardi"], "https://doi.org/10.21437/Interspeech.2019-2489", 5, "interspeech", 2019], ["An Incremental Turn-Taking Model for Task-Oriented Dialog Systems", ["Andrei C. Coman", "Koichiro Yoshino", "Yukitoshi Murase", "Satoshi Nakamura", "Giuseppe Riccardi"], "https://doi.org/10.21437/Interspeech.2019-1826", 5, "interspeech", 2019]], "Dong Yu": [0.1973298266530037, ["Large Margin Training for Attention Based End-to-End Speech Recognition", ["Peidong Wang", "Jia Cui", "Chao Weng", "Dong Yu"], "https://doi.org/10.21437/Interspeech.2019-1680", 5, "interspeech", 2019], ["Improved Speaker-Dependent Separation for CHiME-5 Challenge", ["Jian Wu", "Yong Xu", "Shi-Xiong Zhang", "Lianwu Chen", "Meng Yu", "Lei Xie", "Dong Yu"], "https://doi.org/10.21437/Interspeech.2019-1569", 5, "interspeech", 2019], ["Extract, Adapt and Recognize: An End-to-End Neural Network for Corrupted Monaural Speech Recognition", ["Max W. Y. Lam", "Jun Wang", "Xunying Liu", "Helen Meng", "Dan Su", "Dong Yu"], "https://doi.org/10.21437/Interspeech.2019-1626", 5, "interspeech", 2019], ["Neural Spatial Filter: Target Speaker Speech Separation Assisted with Directional Information", ["Rongzhi Gu", "Lianwu Chen", "Shi-Xiong Zhang", "Jimeng Zheng", "Yong Xu", "Meng Yu", "Dan Su", "Yuexian Zou", "Dong Yu"], "https://doi.org/10.21437/Interspeech.2019-2266", 5, "interspeech", 2019], ["A Comprehensive Study of Speech Separation: Spectrogram vs Waveform Separation", ["Fahimeh Bahmaninezhad", "Jian Wu", "Rongzhi Gu", "Shi-Xiong Zhang", "Yong Xu", "Meng Yu", "Dong Yu"], "https://doi.org/10.21437/Interspeech.2019-3181", 5, "interspeech", 2019]], "Abhijeet Sangwan": [0, ["The 2019 Inaugural Fearless Steps Challenge: A Giant Leap for Naturalistic Audio", ["John H. L. Hansen", "Aditya Joglekar", "Meena Chandra Shekhar", "Vinay Kothapally", "Chengzhu Yu", "Lakshmish Kaushik", "Abhijeet Sangwan"], "https://doi.org/10.21437/Interspeech.2019-2301", 5, "interspeech", 2019]], "Bo Xu": [0, ["Boosting Character-Based Chinese Speech Synthesis via Multi-Task Learning and Dictionary Tutoring", ["Yuxiang Zou", "Linhao Dong", "Bo Xu"], "https://doi.org/10.21437/Interspeech.2019-3233", 5, "interspeech", 2019], ["Ectc-Docd: An End-to-End Structure with CTC Encoder and OCD Decoder for Speech Recognition", ["Cheng Yi", "Feng Wang", "Bo Xu"], "https://doi.org/10.21437/Interspeech.2019-1212", 5, "interspeech", 2019], ["Which Ones Are Speaking? Speaker-Inferred Model for Multi-Talker Speech Separation", ["Jing Shi", "Jiaming Xu", "Bo Xu"], "https://doi.org/10.21437/Interspeech.2019-1591", 5, "interspeech", 2019]], "Thomas Hain": [0, ["Detecting Mismatch Between Speech and Transcription Using Cross-Modal Attention", ["Qiang Huang", "Thomas Hain"], "https://doi.org/10.21437/Interspeech.2019-2125", 5, "interspeech", 2019], ["Learning Temporal Clusters Using Capsule Routing for Speech Emotion Recognition", ["Md Asif Jalal", "Erfan Loweimi", "Roger K. Moore", "Thomas Hain"], "https://doi.org/10.21437/Interspeech.2019-3068", 5, "interspeech", 2019], ["Latent Dirichlet Allocation Based Acoustic Data Selection for Automatic Speech Recognition", ["Mortaza Doulaty", "Thomas Hain"], "https://doi.org/10.21437/Interspeech.2019-1797", 5, "interspeech", 2019]], "Cheryl Corcoran": [0, ["A New Approach for Automating Analysis of Responses on Verbal Fluency Tests from Subjects At-Risk for Schizophrenia", ["Mary Pietrowicz", "Carla Agurto", "Raquel Norel", "Elif Eyigoz", "Guillermo A. Cecchi", "Zarina R. Bilgrami", "Cheryl Corcoran"], "https://doi.org/10.21437/Interspeech.2019-2987", 5, "interspeech", 2019]], "Ian Vince McLoughlin": [0, ["GFM-Voc: A Real-Time Voice Quality Modification System", ["Olivier Perrotin", "Ian Vince McLoughlin"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8018.html", 2, "interspeech", 2019]], "Hugo Van hamme": [0, ["Practical Applicability of Deep Neural Networks for Overlapping Speaker Separation", ["Pieter Appeltans", "Jeroen Zegers", "Hugo Van hamme"], "https://doi.org/10.21437/Interspeech.2019-1807", 5, "interspeech", 2019], ["CNN-LSTM Models for Multi-Speaker Source Separation Using Bayesian Hyper Parameter Optimization", ["Jeroen Zegers", "Hugo Van hamme"], "https://doi.org/10.21437/Interspeech.2019-2423", 5, "interspeech", 2019]], "Bjorn Hoffmeister": [0, ["Improving ASR Confidence Scores for Alexa Using Acoustic and Hypothesis Embeddings", ["Prakhar Swarup", "Roland Maas", "Sri Garimella", "Sri Harish Mallidi", "Bjorn Hoffmeister"], "https://doi.org/10.21437/Interspeech.2019-1241", 5, "interspeech", 2019], ["A Study for Improving Device-Directed Speech Detection Toward Frictionless Human-Machine Interaction", ["Che-Wei Huang", "Roland Maas", "Sri Harish Mallidi", "Bjorn Hoffmeister"], "https://doi.org/10.21437/Interspeech.2019-2840", 5, "interspeech", 2019]], "Taehwan Kim": [0.925512820482254, ["One-Shot Voice Conversion with Disentangled Representations by Leveraging Phonetic Posteriorgrams", ["Seyed Hamidreza Mohammadi", "Taehwan Kim"], "https://doi.org/10.21437/Interspeech.2019-1798", 5, "interspeech", 2019]], "Christopher Dromey": [0, ["Listeners' Ability to Identify the Gender of Preadolescent Children in Different Linguistic Contexts", ["Shawn L. Nissen", "Sharalee Blunck", "Anita Dromey", "Christopher Dromey"], "https://doi.org/10.21437/Interspeech.2019-1865", 5, "interspeech", 2019]], "Frederic Bechet": [0, ["Adapting a FrameNet Semantic Parser for Spoken Language Understanding Using Adversarial Learning", ["Gabriel Marzinotto", "Geraldine Damnati", "Frederic Bechet"], "https://doi.org/10.21437/Interspeech.2019-2732", 5, "interspeech", 2019]], "Jon Gudnason": [0, ["F0 Variability Measures Based on Glottal Closure Instants", ["Yu-Ren Chien", "Michal Borsky", "Jon Gudnason"], "https://doi.org/10.21437/Interspeech.2019-1326", 4, "interspeech", 2019], ["The Althingi ASR System", ["Inga Run Helgadottir", "Anna Bjork Nikulasdottir", "Michal Borsky", "Judy Y. Fong", "Robert Kjaran", "Jon Gudnason"], "https://doi.org/10.21437/Interspeech.2019-1248", 5, "interspeech", 2019], ["Lattice Re-Scoring During Manual Editing for Automatic Error Correction of ASR Transcripts", ["Anna V. Runarsdottir", "Inga Run Helgadottir", "Jon Gudnason"], "https://doi.org/10.21437/Interspeech.2019-1790", 5, "interspeech", 2019], ["Bootstrapping a Text Normalization System for an Inflected Language. Numbers as a Test Case", ["Anna Bjork Nikulasdottir", "Jon Gudnason"], "https://doi.org/10.21437/Interspeech.2019-2367", 5, "interspeech", 2019]], "Gianpiero Francesca": [0, ["Detecting Topic-Oriented Speaker Stance in Conversational Speech", ["Catherine Lai", "Beatrice Alex", "Johanna D. Moore", "Leimin Tian", "Tatsuro Hori", "Gianpiero Francesca"], "https://doi.org/10.21437/Interspeech.2019-2632", 5, "interspeech", 2019]], "Manna Wang": [0.007606753846630454, ["Acoustic Characteristics of Lexical Tone Disruption in Mandarin Speakers After Brain Damage", ["Wenjun Chen", "Jeroen van de Weijer", "Shuangshuang Zhu", "Qian Qian", "Manna Wang"], "https://doi.org/10.21437/Interspeech.2019-2432", 5, "interspeech", 2019]], "Wu-Jun Li": [0, ["Deep Hashing for Speaker Identification and Retrieval", ["Lei Fan", "Qing-Yuan Jiang", "Ya-Qi Yu", "Wu-Jun Li"], "https://doi.org/10.21437/Interspeech.2019-2457", 5, "interspeech", 2019]], "Hiromitsu Nishizaki": [0, ["Audio Classification of Bit-Representation Waveform", ["Masaki Okawa", "Takuya Saito", "Naoki Sawada", "Hiromitsu Nishizaki"], "https://doi.org/10.21437/Interspeech.2019-1855", 5, "interspeech", 2019]], "Kerstin Fischer": [0, ["Do not Hesitate! - Unless You Do it Shortly or Nasally: How the Phonetics of Filled Pauses Determine Their Subjective Frequency and Perceived Speaker Performance", ["Oliver Niebuhr", "Kerstin Fischer"], "https://doi.org/10.21437/Interspeech.2019-1194", 5, "interspeech", 2019]], "Ville Hautamaki": [0, ["Towards Debugging Deep Neural Networks by Generating Speech Utterances", ["Bilal Soomro", "Anssi Kanervisto", "Trung Ngo Trong", "Ville Hautamaki"], "https://doi.org/10.21437/Interspeech.2019-2339", 5, "interspeech", 2019]], "Alex Waibel": [0, ["Very Deep Self-Attention Networks for End-to-End Speech Recognition", ["Ngoc-Quan Pham", "Thai-Son Nguyen", "Jan Niehues", "Markus Muller", "Alex Waibel"], "https://doi.org/10.21437/Interspeech.2019-2702", 5, "interspeech", 2019]], "Tomoki Morita": [0, ["Lyrics Recognition from Singing Voice Focused on Correspondence Between Voice and Notes", ["Motoyuki Suzuki", "Sho Tomita", "Tomoki Morita"], "https://doi.org/10.21437/Interspeech.2019-1318", 4, "interspeech", 2019]], "Qiang Yang": [0.004053857177495956, ["Topic-Aware Dialogue Speech Recognition with Transfer Learning", ["Yuanfeng Song", "Di Jiang", "Xueyang Wu", "Qian Xu", "Raymond Chi-Wing Wong", "Qiang Yang"], "https://doi.org/10.21437/Interspeech.2019-1694", 5, "interspeech", 2019]], "Kikuo Maekawa": [0, ["Speech Organ Contour Extraction Using Real-Time MRI and Machine Learning Method", ["Hironori Takemoto", "Tsubasa Goto", "Yuya Hagihara", "Sayaka Hamanaka", "Tatsuya Kitamura", "Yukiko Nota", "Kikuo Maekawa"], "https://doi.org/10.21437/Interspeech.2019-1593", 5, "interspeech", 2019]], "Michael Auli": [0, ["wav2vec: Unsupervised Pre-Training for Speech Recognition", ["Steffen Schneider", "Alexei Baevski", "Ronan Collobert", "Michael Auli"], "https://doi.org/10.21437/Interspeech.2019-1873", 5, "interspeech", 2019]], "Philipp Aichinger": [0, ["Aerodynamics and Lumped-Masses Combined with Delay Lines for Modeling Vertical and Anterior-Posterior Phase Differences in Pathological Vocal Fold Vibration", ["Carlo Drioli", "Philipp Aichinger"], "https://doi.org/10.21437/Interspeech.2019-2338", 5, "interspeech", 2019], ["Analysis and Synthesis of Vocal Flutter and Vocal Jitter", ["Jean Schoentgen", "Philipp Aichinger"], "https://doi.org/10.21437/Interspeech.2019-1998", 5, "interspeech", 2019]], "Parav Nagarsheth": [0, ["Pindrop Labs' Submission to the First Multi-Target Speaker Detection and Identification Challenge", ["Elie Khoury", "Khaled Lakhdhar", "Andrew Vaughan", "Ganesh Sivaraman", "Parav Nagarsheth"], "https://doi.org/10.21437/Interspeech.2019-3179", 4, "interspeech", 2019]], "Balint Gyires-Toth": [0, ["Transformer Based Grapheme-to-Phoneme Conversion", ["Sevinj Yolchuyeva", "Geza Nemeth", "Balint Gyires-Toth"], "https://doi.org/10.21437/Interspeech.2019-1954", 5, "interspeech", 2019]], "Yushi Aono": [0, ["Improving Conversation-Context Language Models with Multiple Spoken Language Understanding Models", ["Ryo Masumura", "Tomohiro Tanaka", "Atsushi Ando", "Hosana Kamiyama", "Takanobu Oba", "Satoshi Kobashikawa", "Yushi Aono"], "https://doi.org/10.21437/Interspeech.2019-1534", 5, "interspeech", 2019], ["A Joint End-to-End and DNN-HMM Hybrid Automatic Speech Recognition System with Transferring Sharable Knowledge", ["Tomohiro Tanaka", "Ryo Masumura", "Takafumi Moriya", "Takanobu Oba", "Yushi Aono"], "https://doi.org/10.21437/Interspeech.2019-2263", 5, "interspeech", 2019], ["Speech Emotion Recognition Based on Multi-Label Emotion Existence Model", ["Atsushi Ando", "Ryo Masumura", "Hosana Kamiyama", "Satoshi Kobashikawa", "Yushi Aono"], "https://doi.org/10.21437/Interspeech.2019-2524", 5, "interspeech", 2019], ["Neural Whispered Speech Detection with Imbalanced Learning", ["Takanori Ashihara", "Yusuke Shinohara", "Hiroshi Sato", "Takafumi Moriya", "Kiyoaki Matsui", "Takaaki Fukutomi", "Yoshikazu Yamaguchi", "Yushi Aono"], "https://doi.org/10.21437/Interspeech.2019-2161", 5, "interspeech", 2019], ["Joint Maximization Decoder with Neural Converters for Fully Neural Network-Based Japanese Speech Recognition", ["Takafumi Moriya", "Jian Wang", "Tomohiro Tanaka", "Ryo Masumura", "Yusuke Shinohara", "Yoshikazu Yamaguchi", "Yushi Aono"], "https://doi.org/10.21437/Interspeech.2019-1558", 5, "interspeech", 2019]], "John R. Hershey": [0, ["End-to-End Multilingual Multi-Speaker Speech Recognition", ["Hiroshi Seki", "Takaaki Hori", "Shinji Watanabe", "Jonathan Le Roux", "John R. Hershey"], "https://doi.org/10.21437/Interspeech.2019-3038", 5, "interspeech", 2019]], "Rivka Levitan": [0, ["Mitigating Gender and L1 Differences to Improve State and Trait Recognition", ["Guozhen An", "Rivka Levitan"], "https://doi.org/10.21437/Interspeech.2019-2868", 4, "interspeech", 2019]], "Hermann Ney": [0, ["RWTH ASR Systems for LibriSpeech: Hybrid vs Attention", ["Christoph Luscher", "Eugen Beck", "Kazuki Irie", "Markus Kitza", "Wilfried Michel", "Albert Zeyer", "Ralf Schluter", "Hermann Ney"], "https://doi.org/10.21437/Interspeech.2019-1780", 5, "interspeech", 2019], ["Cumulative Adaptation for BLSTM Acoustic Models", ["Markus Kitza", "Pavel Golik", "Ralf Schluter", "Hermann Ney"], "https://doi.org/10.21437/Interspeech.2019-2162", 5, "interspeech", 2019], ["An Analysis of Local Monotonic Attention Variants", ["Andre Merboldt", "Albert Zeyer", "Ralf Schluter", "Hermann Ney"], "https://doi.org/10.21437/Interspeech.2019-2879", 5, "interspeech", 2019], ["Comparison of Lattice-Free and Lattice-Based Sequence Discriminative Training Criteria for LVCSR", ["Wilfried Michel", "Ralf Schluter", "Hermann Ney"], "https://doi.org/10.21437/Interspeech.2019-2254", 5, "interspeech", 2019], ["Analysis of Deep Clustering as Preprocessing for Automatic Speech Recognition of Sparsely Overlapping Speech", ["Tobias Menne", "Ilya Sklyar", "Ralf Schluter", "Hermann Ney"], "https://doi.org/10.21437/Interspeech.2019-1728", 5, "interspeech", 2019], ["Language Modeling with Deep Transformers", ["Kazuki Irie", "Albert Zeyer", "Ralf Schluter", "Hermann Ney"], "https://doi.org/10.21437/Interspeech.2019-2225", 5, "interspeech", 2019], ["Rescoring Keyword Search Confidence Estimates with Graph-Based Re-Ranking Using Acoustic Word Embeddings", ["Anna Piunova", "Eugen Beck", "Ralf Schluter", "Hermann Ney"], "https://doi.org/10.21437/Interspeech.2019-1817", 5, "interspeech", 2019]], "Yonghong Yan": [0, ["Speaker-Invariant Feature-Mapping for Distant Speech Recognition via Adversarial Teacher-Student Learning", ["Long Wu", "Hangting Chen", "Li Wang", "Pengyuan Zhang", "Yonghong Yan"], "https://doi.org/10.21437/Interspeech.2019-2136", 5, "interspeech", 2019], ["Multi-Accent Adaptation Based on Gate Mechanism", ["Han Zhu", "Li Wang", "Pengyuan Zhang", "Yonghong Yan"], "https://doi.org/10.21437/Interspeech.2019-3155", 5, "interspeech", 2019], ["Online Hybrid CTC/Attention Architecture for End-to-End Speech Recognition", ["Haoran Miao", "Gaofeng Cheng", "Pengyuan Zhang", "Ta Li", "Yonghong Yan"], "https://doi.org/10.21437/Interspeech.2019-2018", 5, "interspeech", 2019], ["Target Speaker Recovery and Recognition Network with Average x-Vector and Global Training", ["Wenjie Li", "Pengyuan Zhang", "Yonghong Yan"], "https://doi.org/10.21437/Interspeech.2019-1692", 5, "interspeech", 2019], ["Character-Aware Sub-Word Level Language Modeling for Uyghur and Turkish ASR", ["Chang Liu", "Zhen Zhang", "Pengyuan Zhang", "Yonghong Yan"], "https://doi.org/10.21437/Interspeech.2019-1484", 5, "interspeech", 2019], ["A New Time-Frequency Attention Mechanism for TDNN and CNN-LSTM-TDNN, with Application to Language Identification", ["Xiaoxiao Miao", "Ian McLoughlin", "Yonghong Yan"], "https://doi.org/10.21437/Interspeech.2019-1256", 5, "interspeech", 2019]], "Johannes Gehrke": [0, ["A Scalable Noisy Speech Dataset and Online Subjective Test Framework", ["Chandan K. A. Reddy", "Ebrahim Beyrami", "Jamie Pool", "Ross Cutler", "Sriram Srinivasan", "Johannes Gehrke"], "https://doi.org/10.21437/Interspeech.2019-3087", 5, "interspeech", 2019], ["Supervised Classifiers for Audio Impairments with Noisy Labels", ["Chandan K. A. Reddy", "Ross Cutler", "Johannes Gehrke"], "https://doi.org/10.21437/Interspeech.2019-3074", 5, "interspeech", 2019]], "Xavier Serra": [0, ["End-to-End Music Source Separation: Is it Possible in the Waveform Domain?", ["Francesc Lluis", "Jordi Pons", "Xavier Serra"], "https://doi.org/10.21437/Interspeech.2019-1177", 5, "interspeech", 2019]], "S. Dandapat": [0, ["Hypernasality Severity Detection Using Constant Q Cepstral Coefficients", ["Akhilesh Kumar Dubey", "S. R. Mahadeva Prasanna", "S. Dandapat"], "https://doi.org/10.21437/Interspeech.2019-2151", 5, "interspeech", 2019]], "Anqi Xu": [0, ["Sentence Prosody and Wh-Indeterminates in Taiwan Mandarin", ["Yu-Yin Hsu", "Anqi Xu"], "https://doi.org/10.21437/Interspeech.2019-2545", 5, "interspeech", 2019]], "Ngoc Thang Vu": [0, ["Automatic Compression of Subtitles with Neural Networks and its Effect on User Experience", ["Katrin Angerbauer", "Heike Adel", "Ngoc Thang Vu"], "https://doi.org/10.21437/Interspeech.2019-1750", 5, "interspeech", 2019], ["CycleGAN-Based Emotion Style Transfer as Data Augmentation for Speech Emotion Recognition", ["Fang Bao", "Michael Neumann", "Ngoc Thang Vu"], "https://doi.org/10.21437/Interspeech.2019-2293", 5, "interspeech", 2019], ["Multimodal Articulation-Based Pronunciation Error Detection with Spectrogram and Acoustic Features", ["Sabrina Jenne", "Ngoc Thang Vu"], "https://doi.org/10.21437/Interspeech.2019-1677", 5, "interspeech", 2019], ["End-to-End Multi-Speaker Speech Recognition Using Speaker Embeddings and Transfer Learning", ["Pavel Denisov", "Ngoc Thang Vu"], "https://doi.org/10.21437/Interspeech.2019-1130", 5, "interspeech", 2019]], "Zhihao Du": [0, ["Acoustic Scene Classification by Implicitly Identifying Distinct Sound Events", ["Hongwei Song", "Jiqing Han", "Shiwen Deng", "Zhihao Du"], "https://doi.org/10.21437/Interspeech.2019-2231", 5, "interspeech", 2019]], "Lin-Shan Lee": [3.882123622567235e-09, ["Improved Speech Separation with Time-and-Frequency Cross-Domain Joint Embedding and Clustering", ["Gene-Ping Yang", "Chao-I Tuan", "Hung-yi Lee", "Lin-Shan Lee"], "https://doi.org/10.21437/Interspeech.2019-2181", 5, "interspeech", 2019], ["Completely Unsupervised Phoneme Recognition by a Generative Adversarial Network Harmonized with Iteratively Refined Hidden Markov Models", ["Kuan-Yu Chen", "Che-Ping Tsai", "Da-Rong Liu", "Hung-yi Lee", "Lin-Shan Lee"], "https://doi.org/10.21437/Interspeech.2019-2068", 5, "interspeech", 2019]], "Lan Wang": [0.0072339854668825865, ["Fast DNN Acoustic Model Speaker Adaptation by Learning Hidden Unit Contribution Features", ["Xurong Xie", "Xunying Liu", "Tan Lee", "Lan Wang"], "https://doi.org/10.21437/Interspeech.2019-2050", 5, "interspeech", 2019]], "Matthew Purver": [0, ["Detecting Depression with Word-Level Multimodal Fusion", ["Morteza Rohanian", "Julian Hough", "Matthew Purver"], "https://doi.org/10.21437/Interspeech.2019-2283", 5, "interspeech", 2019]], "Hynek Hermansky": [0, ["Performance Monitoring for End-to-End Speech Recognition", ["Ruizhi Li", "Gregory Sell", "Hynek Hermansky"], "https://doi.org/10.21437/Interspeech.2019-3137", 5, "interspeech", 2019], ["Exploring Methods for the Automatic Detection of Errors in Manual Transcription", ["Xiaofei Wang", "Jinyi Yang", "Ruizhi Li", "Samik Sadhu", "Hynek Hermansky"], "https://doi.org/10.21437/Interspeech.2019-1343", 5, "interspeech", 2019], ["Modulation Vectors as Robust Feature Representation for ASR in Domain Mismatched Conditions", ["Samik Sadhu", "Hynek Hermansky"], "https://doi.org/10.21437/Interspeech.2019-2723", 5, "interspeech", 2019]], "Yun Lei": [0, ["Towards a Fault-Tolerant Speaker Verification System: A Regularization Approach to Reduce the Condition Number", ["Siqi Zheng", "Gang Liu", "Hongbin Suo", "Yun Lei"], "https://doi.org/10.21437/Interspeech.2019-1442", 5, "interspeech", 2019], ["Autoencoder-Based Semi-Supervised Curriculum Learning for Out-of-Domain Speaker Verification", ["Siqi Zheng", "Gang Liu", "Hongbin Suo", "Yun Lei"], "https://doi.org/10.21437/Interspeech.2019-1440", 5, "interspeech", 2019]], "Samarendra Dandapat": [0, ["Nasal Air Emission in Sibilant Fricatives of Cleft Lip and Palate Speech", ["Sishir Kalita", "Protima Nomo Sudro", "S. R. Mahadeva Prasanna", "Samarendra Dandapat"], "https://doi.org/10.21437/Interspeech.2019-2345", 5, "interspeech", 2019]], "Horia Cucu": [0, ["Kite: Automatic Speech Recognition for Unmanned Aerial Vehicles", ["Dan Oneata", "Horia Cucu"], "https://doi.org/10.21437/Interspeech.2019-1390", 5, "interspeech", 2019]], "Franck Dernoncourt": [0, ["Exploiting Semi-Supervised Training Through a Dropout Regularization in End-to-End Speech Recognition", ["Subhadeep Dey", "Petr Motlicek", "Trung Bui", "Franck Dernoncourt"], "https://doi.org/10.21437/Interspeech.2019-3246", 5, "interspeech", 2019]], "Srinivas Bangalore": [0, ["Neural Transition Systems for Modeling Hierarchical Semantic Representations", ["Riyaz Ahmad Bhat", "John Chen", "Rashmi Prasad", "Srinivas Bangalore"], "https://doi.org/10.21437/Interspeech.2019-3075", 5, "interspeech", 2019]], "Ken-Ichi Sakakibara": [0, ["Investigating the Physiological and Acoustic Contrasts Between Choral and Operatic Singing", ["Hiroko Terasawa", "Kenta Wakasa", "Hideki Kawahara", "Ken-Ichi Sakakibara"], "https://doi.org/10.21437/Interspeech.2019-1864", 5, "interspeech", 2019]], "Mikko Kurimo": [0, ["Transparent Pronunciation Scoring Using Articulatorily Weighted Phoneme Edit Distance", ["Reima Karhila", "Anna-Riikka Smolander", "Sari Ylinen", "Mikko Kurimo"], "https://doi.org/10.21437/Interspeech.2019-1785", 5, "interspeech", 2019], ["Subword RNNLM Approximations for Out-Of-Vocabulary Keyword Search", ["Mittul Singh", "Sami Virpioja", "Peter Smit", "Mikko Kurimo"], "https://doi.org/10.21437/Interspeech.2019-1329", 5, "interspeech", 2019]], "Rohit Sinha": [0, ["SpeechMarker: A Voice Based Multi-Level Attendance Application", ["Sarfaraz Jelil", "Abhishek Shrivastava", "Rohan Kumar Das", "S. R. Mahadeva Prasanna", "Rohit Sinha"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8014.html", 2, "interspeech", 2019]], "Nicolas Audibert": [0, ["\" Gra[f] e!\" Word-Final Devoicing of Obstruents in Standard French: An Acoustic Study Based on Large Corpora", ["Adele Jatteau", "Ioana Vasilescu", "Lori Lamel", "Martine Adda-Decker", "Nicolas Audibert"], "https://doi.org/10.21437/Interspeech.2019-2329", 5, "interspeech", 2019]], "Michael T. Barbe": [0, ["Intragestural Variation in Natural Sentence Production: Essential Tremor Patients Treated with DBS", ["Anne Hermes", "Doris Mucke", "Tabea Thies", "Michael T. Barbe"], "https://doi.org/10.21437/Interspeech.2019-2389", 5, "interspeech", 2019]], "Simon King": [0, ["Evaluating Near End Listening Enhancement Algorithms in Realistic Environments", ["Carol Chermaz", "Cassia Valentini-Botinhao", "Henning F. Schepker", "Simon King"], "https://doi.org/10.21437/Interspeech.2019-1800", 5, "interspeech", 2019], ["Investigating the Robustness of Sequence-to-Sequence Text-to-Speech Models to Imperfectly-Transcribed Training Data", ["Jason Fong", "Pilar Oplustil Gallegos", "Zack Hodari", "Simon King"], "https://doi.org/10.21437/Interspeech.2019-1824", 5, "interspeech", 2019], ["Using Pupil Dilation to Measure Cognitive Load When Listening to Text-to-Speech in Quiet and in Noise", ["Avashna Govender", "Anita E. Wagner", "Simon King"], "https://doi.org/10.21437/Interspeech.2019-1783", 5, "interspeech", 2019], ["Disentangling Style Factors from Speaker Representations", ["Jennifer Williams", "Simon King"], "https://doi.org/10.21437/Interspeech.2019-1769", 5, "interspeech", 2019], ["Improving Speech Synthesis with Discourse Relations", ["Adele Aubin", "Alessandra Cervone", "Oliver Watts", "Simon King"], "https://doi.org/10.21437/Interspeech.2019-1945", 5, "interspeech", 2019]], "Dmytro Tkanov": [0, ["Attention Model for Articulatory Features Detection", ["Ievgen Karaulov", "Dmytro Tkanov"], "https://doi.org/10.21437/Interspeech.2019-3020", 5, "interspeech", 2019]], "Senthil Mani": [0, ["Adversarial Black-Box Attacks on Automatic Speech Recognition Systems Using Multi-Objective Evolutionary Optimization", ["Shreya Khare", "Rahul Aralikatte", "Senthil Mani"], "https://doi.org/10.21437/Interspeech.2019-2420", 5, "interspeech", 2019]], "Anat Lerner": [0, ["A Storyteller's Tale: Literature Audiobooks Genre Classification Using CNN and RNN Architectures", ["Nehory Carmi", "Azaria Cohen", "Mireille Avigal", "Anat Lerner"], "https://doi.org/10.21437/Interspeech.2019-1154", 4, "interspeech", 2019]], "Li Wan": [0, ["Multi-Microphone Adaptive Noise Cancellation for Robust Hotword Detection", ["Yiteng Huang", "Turaj Zakizadeh Shabestary", "Alexander Gruenstein", "Li Wan"], "https://doi.org/10.21437/Interspeech.2019-3006", 5, "interspeech", 2019]], "Tomoki Toda": [0, ["Quasi-Periodic WaveNet Vocoder: A Pitch Dependent Dilated Convolution Model for Parametric Speech Generation", ["Yi-Chiao Wu", "Tomoki Hayashi", "Patrick Lumban Tobing", "Kazuhiro Kobayashi", "Tomoki Toda"], "https://doi.org/10.21437/Interspeech.2019-1232", 5, "interspeech", 2019], ["Non-Parallel Voice Conversion with Cyclic Variational Autoencoder", ["Patrick Lumban Tobing", "Yi-Chiao Wu", "Tomoki Hayashi", "Kazuhiro Kobayashi", "Tomoki Toda"], "https://doi.org/10.21437/Interspeech.2019-2307", 5, "interspeech", 2019], ["Robustness of Statistical Voice Conversion Based on Direct Waveform Modification Against Background Sounds", ["Yusuke Kurita", "Kazuhiro Kobayashi", "Kazuya Takeda", "Tomoki Toda"], "https://doi.org/10.21437/Interspeech.2019-2206", 5, "interspeech", 2019]], "Paul Warren": [0, ["Tracking the New Zealand English NEAR/SQUARE Merger Using Functional Principal Components Analysis", ["Michele Gubian", "Jonathan Harrington", "Mary Stevens", "Florian Schiel", "Paul Warren"], "https://doi.org/10.21437/Interspeech.2019-2115", 5, "interspeech", 2019]], "Shankar Ananthakrishnan": [0, ["One-vs-All Models for Asynchronous Training: An Empirical Analysis", ["Rahul Gupta", "Aman Alok", "Shankar Ananthakrishnan"], "https://doi.org/10.21437/Interspeech.2019-2760", 5, "interspeech", 2019]], "Herman Kamper": [0, ["Unsupervised Acoustic Unit Discovery for Speech Synthesis Using Discrete Latent-Variable Neural Networks", ["Ryan Eloff", "Andre Nortje", "Benjamin van Niekerk", "Avashna Govender", "Leanne Nortje", "Arnu Pretorius", "Elan Van Biljon", "Ewald van der Westhuizen", "Lisa van Staden", "Herman Kamper"], "https://doi.org/10.21437/Interspeech.2019-1518", 5, "interspeech", 2019]], "Oriol Guasch": [0, ["Survey Talk: Realistic Physics-Based Computational Voice Production", ["Oriol Guasch"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/abs24.html", 0, "interspeech", 2019]], "Antonio Miguel": [0, ["Language Recognition Using Triplet Neural Networks", ["Victoria Mingote", "Diego Castan", "Mitchell McLaren", "Mahesh Kumar Nandwana", "Alfonso Ortega Gimenez", "Eduardo Lleida", "Antonio Miguel"], "https://doi.org/10.21437/Interspeech.2019-2437", 5, "interspeech", 2019]], "Nigel G. Ward": [0, ["Survey Talk: Prosody Research and Applications: The State of the Art", ["Nigel G. Ward"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/abs20.html", 0, "interspeech", 2019]], "Jean-Francois Bonastre": [0, ["Effects of Waveform PMF on Anti-Spoofing Detection", ["Itshak Lapidot", "Jean-Francois Bonastre"], "https://doi.org/10.21437/Interspeech.2019-2607", 5, "interspeech", 2019]], "Insoo Oh": [0.9920652210712433, ["Robust Keyword Spotting via Recycle-Pooling for Mobile Game", ["Shounan An", "Youngsoo Kim", "Hu Xu", "Jinwoo Lee", "Myungwoo Lee", "Insoo Oh"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8010.html", 2, "interspeech", 2019]], "Takanobu Oba": [0, ["End-to-End Automatic Speech Recognition with a Reconstruction Criterion Using Speech-to-Text and Text-to-Speech Encoder-Decoders", ["Ryo Masumura", "Hiroshi Sato", "Tomohiro Tanaka", "Takafumi Moriya", "Yusuke Ijima", "Takanobu Oba"], "https://doi.org/10.21437/Interspeech.2019-2111", 5, "interspeech", 2019]], "Meysam Asgari": [0, ["Improving ASR Systems for Children with Autism and Language Impairment Using Domain-Focused DNN Transfer Techniques", ["Robert Gale", "Liu Chen", "Jill Dolata", "Jan P. H. van Santen", "Meysam Asgari"], "https://doi.org/10.21437/Interspeech.2019-3161", 5, "interspeech", 2019]], "Silke Hamann": [0, ["Vietnamese Learners Tackling the German /\u0283t/ in Perception", ["Anke Sennema", "Silke Hamann"], "https://doi.org/10.21437/Interspeech.2019-2832", 4, "interspeech", 2019]], "Fei Huang": [0, ["Noisy BiLSTM-Based Models for Disfluency Detection", ["Nguyen Bach", "Fei Huang"], "https://doi.org/10.21437/Interspeech.2019-1336", 5, "interspeech", 2019]], "Chin-Hui Lee": [0.5, ["Acoustic Model Ensembling Using Effective Data Augmentation for CHiME-5 Challenge", ["Feng Ma", "Li Chai", "Jun Du", "Diyuan Liu", "Zhongfu Ye", "Chin-Hui Lee"], "https://doi.org/10.21437/Interspeech.2019-2601", 5, "interspeech", 2019], ["KL-Divergence Regularized Deep Neural Network Adaptation for Low-Resource Speaker-Dependent Speech Enhancement", ["Li Chai", "Jun Du", "Chin-Hui Lee"], "https://doi.org/10.21437/Interspeech.2019-2426", 5, "interspeech", 2019], ["A Cross-Entropy-Guided (CEG) Measure for Speech Enhancement Front-End Assessing Performances of Back-End Automatic Speech Recognition", ["Li Chai", "Jun Du", "Chin-Hui Lee"], "https://doi.org/10.21437/Interspeech.2019-2511", 5, "interspeech", 2019], ["A Hybrid Approach to Acoustic Scene Classification Based on Universal Acoustic Models", ["Xue Bai", "Jun Du", "Zi-Rui Wang", "Chin-Hui Lee"], "https://doi.org/10.21437/Interspeech.2019-2171", 5, "interspeech", 2019]], "Yaping Yang": [4.951884875481483e-06, ["ToneNet: A CNN Model of Tone Classification of Mandarin Chinese", ["Qiang Gao", "Shutao Sun", "Yaping Yang"], "https://doi.org/10.21437/Interspeech.2019-1483", 5, "interspeech", 2019]], "Jian Huang": [0, ["Conversational Emotion Analysis via Attention Mechanisms", ["Zheng Lian", "Jianhua Tao", "Bin Liu", "Jian Huang"], "https://doi.org/10.21437/Interspeech.2019-1577", 5, "interspeech", 2019], ["Unsupervised Representation Learning with Future Observation Prediction for Speech Emotion Recognition", ["Zheng Lian", "Jianhua Tao", "Bin Liu", "Jian Huang"], "https://doi.org/10.21437/Interspeech.2019-1582", 5, "interspeech", 2019]], "Liang He": [0, ["Multi-Scale Time-Frequency Attention for Acoustic Event Detection", ["Jingyang Zhang", "Wenhao Ding", "Jintao Kang", "Liang He"], "https://doi.org/10.21437/Interspeech.2019-1587", 5, "interspeech", 2019]], "Eduardo Lleida": [0, ["ViVoLAB Speaker Diarization System for the DIHARD 2019 Challenge", ["Ignacio Vinals", "Pablo Gimeno", "Alfonso Ortega Gimenez", "Antonio Miguel", "Eduardo Lleida"], "https://doi.org/10.21437/Interspeech.2019-2462", 5, "interspeech", 2019], ["Speech Enhancement with Wide Residual Networks in Reverberant Environments", ["Jorge Llombart", "Dayana Ribas", "Antonio Miguel", "Luis Vicente", "Alfonso Ortega Gimenez", "Eduardo Lleida"], "https://doi.org/10.21437/Interspeech.2019-1745", 5, "interspeech", 2019], ["Optimization of False Acceptance/Rejection Rates and Decision Threshold for End-to-End Text-Dependent Speaker Verification Systems", ["Victoria Mingote", "Antonio Miguel", "Dayana Ribas", "Alfonso Ortega Gimenez", "Eduardo Lleida"], "https://doi.org/10.21437/Interspeech.2019-2550", 5, "interspeech", 2019], ["Progressive Speech Enhancement with Residual Connections", ["Jorge Llombart", "Dayana Ribas", "Antonio Miguel", "Luis Vicente", "Alfonso Ortega Gimenez", "Eduardo Lleida"], "https://doi.org/10.21437/Interspeech.2019-1748", 5, "interspeech", 2019], ["Phonetically-Aware Embeddings, Wide Residual Networks with Time-Delay Neural Networks and Self Attention Models for the 2018 NIST Speaker Recognition Evaluation", ["Ignacio Vinals", "Dayana Ribas", "Victoria Mingote", "Jorge Llombart", "Pablo Gimeno", "Antonio Miguel", "Alfonso Ortega Gimenez", "Eduardo Lleida"], "https://doi.org/10.21437/Interspeech.2019-2417", 5, "interspeech", 2019]], "Sina Zarriess": [0, ["Do Hesitations Facilitate Processing of Partially Defective System Utterances? An Exploratory Eye Tracking Study", ["Kristin Haake", "Sarah Schimke", "Simon Betz", "Sina Zarriess"], "https://doi.org/10.21437/Interspeech.2019-2820", 5, "interspeech", 2019]], "Daan van Esch": [0, ["Developing Pronunciation Models in New Languages Faster by Exploiting Common Grapheme-to-Phoneme Correspondences Across Languages", ["Harry Bleyan", "Sandy Ritchie", "Jonas Fromseier Mortensen", "Daan van Esch"], "https://doi.org/10.21437/Interspeech.2019-1781", 5, "interspeech", 2019]], "Alexei Kochetov": [0, ["Articulatory Characteristics of Secondary Palatalization in Romanian Fricatives", ["Laura Spinu", "Maida Percival", "Alexei Kochetov"], "https://doi.org/10.21437/Interspeech.2019-3039", 5, "interspeech", 2019]], "Erik P. Bucy": [0, ["Multi-Modal Sentiment Analysis Using Deep Canonical Correlation Analysis", ["Zhongkai Sun", "Prathusha Kameswara Sarma", "William A. Sethares", "Erik P. Bucy"], "https://doi.org/10.21437/Interspeech.2019-2482", 5, "interspeech", 2019]], "Hiroshi Fujimura": [0, ["Slot Filling with Weighted Multi-Encoders for Out-of-Domain Values", ["Yuka Kobayashi", "Takami Yoshida", "Kenji Iwata", "Hiroshi Fujimura"], "https://doi.org/10.21437/Interspeech.2019-1226", 5, "interspeech", 2019]], "Jing Chen": [0, ["Effects of Spectral and Temporal Cues to Mandarin Concurrent-Vowels Identification for Normal-Hearing and Hearing-Impaired Listeners", ["Zhen Fu", "Xihong Wu", "Jing Chen"], "https://doi.org/10.21437/Interspeech.2019-3209", 5, "interspeech", 2019]], "Chaitanya Narisetty": [0, ["A Unified Bayesian Source Modelling for Determined Blind Source Separation", ["Chaitanya Narisetty"], "https://doi.org/10.21437/Interspeech.2019-1272", 5, "interspeech", 2019]], "Christian Raymond": [0, ["Mining Polysemous Triplets with Recurrent Neural Networks for Spoken Language Understanding", ["Vedran Vukotic", "Christian Raymond"], "https://doi.org/10.21437/Interspeech.2019-2977", 5, "interspeech", 2019], ["Benchmarking Benchmarks: Introducing New Automatic Indicators for Benchmarking Spoken Language Understanding Corpora", ["Frederic Bechet", "Christian Raymond"], "https://doi.org/10.21437/Interspeech.2019-3033", 5, "interspeech", 2019]], "Elisabeth Andre": [0, ["Relevance-Based Feature Masking: Improving Neural Network Based Whale Classification Through Explainable Artificial Intelligence", ["Dominik Schiller", "Tobias Huber", "Florian Lingenfelser", "Michael Dietz", "Andreas Seiderer", "Elisabeth Andre"], "https://doi.org/10.21437/Interspeech.2019-2707", 5, "interspeech", 2019]], "Francis Nolan": [0, ["Articulation Rate as a Metric in Spoken Language Assessment", ["Calbert Graham", "Francis Nolan"], "https://doi.org/10.21437/Interspeech.2019-2098", 5, "interspeech", 2019]], "Rachid Ridouane": [0, ["A Perceptual Study of CV Syllables in Both Spoken and Whistled Speech: A Tashlhiyt Berber Perspective", ["Julien Meyer", "Laure Dentel", "Silvain Gerber", "Rachid Ridouane"], "https://doi.org/10.21437/Interspeech.2019-2251", 5, "interspeech", 2019]], "Jonathan Chevelu": [0, ["Corpus Design Using Convolutional Auto-Encoder Embeddings for Audio-Book Synthesis", ["Meysam Shamsi", "Damien Lolive", "Nelly Barbot", "Jonathan Chevelu"], "https://doi.org/10.21437/Interspeech.2019-2190", 5, "interspeech", 2019]], "Jurgen Riedler": [0, ["The SAIL LABS Media Mining Indexer and the CAVA Framework", ["Erinc Dikici", "Gerhard Backfried", "Jurgen Riedler"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8029.html", 2, "interspeech", 2019]], "Hiroshi Shimodaira": [0, ["Direct F0 Estimation with Neural-Network-Based Regression", ["Shuzhuang Xu", "Hiroshi Shimodaira"], "https://doi.org/10.21437/Interspeech.2019-3267", 5, "interspeech", 2019]], "Yannick Esteve": [0, ["Investigating Adaptation and Transfer Learning for End-to-End Spoken Language Understanding from Speech", ["Natalia Tomashenko", "Antoine Caubriere", "Yannick Esteve"], "https://doi.org/10.21437/Interspeech.2019-2158", 5, "interspeech", 2019], ["Curriculum-Based Transfer Learning for an Effective End-to-End Spoken Language Understanding and Domain Portability", ["Antoine Caubriere", "Natalia A. Tomashenko", "Antoine Laurent", "Emmanuel Morin", "Nathalie Camelin", "Yannick Esteve"], "https://doi.org/10.21437/Interspeech.2019-1832", 5, "interspeech", 2019]], "Joanna Rownicka": [0, ["Speech Replay Detection with x-Vector Attack Embeddings and Spectral Features", ["Jennifer Williams", "Joanna Rownicka"], "https://doi.org/10.21437/Interspeech.2019-1760", 5, "interspeech", 2019]], "Mark Antoniou": [0, ["Cognitive Factors in Thai-Na\u00efve Mandarin Speakers' Imitation of Thai Lexical Tones", ["Juqiang Chen", "Catherine T. Best", "Mark Antoniou"], "https://doi.org/10.21437/Interspeech.2019-1403", 5, "interspeech", 2019]], "Richard Sproat": [0, ["Dual Encoder Classifier Models as Constraints in Neural Text Normalization", ["Ajda Gokcen", "Hao Zhang", "Richard Sproat"], "https://doi.org/10.21437/Interspeech.2019-1135", 5, "interspeech", 2019]], "Hitoshi Aoki": [0, ["Extending the E-Model Towards Super-Wideband and Fullband Speech Communication Scenarios", ["Sebastian Moller", "Gabriel Mittag", "Thilo Michael", "Vincent Barriac", "Hitoshi Aoki"], "https://doi.org/10.21437/Interspeech.2019-1340", 5, "interspeech", 2019]], "Gang Liu": [0, ["An Online Attention-Based Model for Speech Recognition", ["Ruchao Fan", "Pan Zhou", "Wei Chen", "Jia Jia", "Gang Liu"], "https://doi.org/10.21437/Interspeech.2019-2218", 5, "interspeech", 2019]], "Regine Andre-Obrecht": [0, ["Char+CV-CTC: Combining Graphemes and Consonant/Vowel Units for CTC-Based ASR Using Multitask Learning", ["Abdelwahab Heba", "Thomas Pellegrini", "Jean-Pierre Lorre", "Regine Andre-Obrecht"], "https://doi.org/10.21437/Interspeech.2019-1975", 5, "interspeech", 2019]], "Junichi Yamagishi": [0, ["Joint Training Framework for Text-to-Speech and Voice Conversion Using Multi-Source Tacotron and WaveNet", ["Mingyang Zhang", "Xin Wang", "Fuming Fang", "Haizhou Li", "Junichi Yamagishi"], "https://doi.org/10.21437/Interspeech.2019-1357", 5, "interspeech", 2019]], "Jilong Kuang": [0, ["DeepLung: Smartphone Convolutional Neural Network-Based Inference of Lung Anomalies for Pulmonary Patients", ["Mohsin Y. Ahmed", "Md. Mahbubur Rahman", "Jilong Kuang"], "https://doi.org/10.21437/Interspeech.2019-2953", 5, "interspeech", 2019]], "Xuedong Huang": [0, ["Meeting Transcription Using Asynchronous Distant Microphones", ["Takuya Yoshioka", "Dimitrios Dimitriadis", "Andreas Stolcke", "William Hinthorn", "Zhuo Chen", "Michael Zeng", "Xuedong Huang"], "https://doi.org/10.21437/Interspeech.2019-3088", 5, "interspeech", 2019]], "Shinji Watanabe": [0, ["Auxiliary Interference Speaker Loss for Target-Speaker Speech Recognition", ["Naoyuki Kanda", "Shota Horiguchi", "Ryoichi Takashima", "Yusuke Fujita", "Kenji Nagamatsu", "Shinji Watanabe"], "https://doi.org/10.21437/Interspeech.2019-1126", 5, "interspeech", 2019], ["End-to-End Neural Speaker Diarization with Permutation-Free Objectives", ["Yusuke Fujita", "Naoyuki Kanda", "Shota Horiguchi", "Kenji Nagamatsu", "Shinji Watanabe"], "https://doi.org/10.21437/Interspeech.2019-2899", 5, "interspeech", 2019]], "Benjamin Ricaud": [0, ["Evaluating Audiovisual Source Separation in the Context of Video Conferencing", ["Berkay Inan", "Milos Cernak", "Helmut Grabner", "Helena Peic Tukuljac", "Rodrigo C. G. Pena", "Benjamin Ricaud"], "https://doi.org/10.21437/Interspeech.2019-2671", 5, "interspeech", 2019]], "Jianhua Tao": [0, ["Forward-Backward Decoding for Regularizing End-to-End TTS", ["Yibin Zheng", "Xi Wang", "Lei He", "Shifeng Pan", "Frank K. Soong", "Zhengqi Wen", "Jianhua Tao"], "https://doi.org/10.21437/Interspeech.2019-2325", 5, "interspeech", 2019]], "Nizar Habash": [0, ["Towards Variability Resistant Dialectal Speech Evaluation", ["Ahmed Ali", "Salam Khalifa", "Nizar Habash"], "https://doi.org/10.21437/Interspeech.2019-2692", 5, "interspeech", 2019]], "Jinsong Zhang": [0, ["Capturing L1 Influence on L2 Pronunciation by Simulating Perceptual Space Using Acoustic Features", ["Shuju Shi", "Chilin Shih", "Jinsong Zhang"], "https://doi.org/10.21437/Interspeech.2019-3183", 5, "interspeech", 2019], ["The Production of Chinese Affricates /ts/ and /tsh/ by Native Urdu Speakers", ["Dan Du", "Jinsong Zhang"], "https://doi.org/10.21437/Interspeech.2019-1638", 5, "interspeech", 2019]], "Tanja Schultz": [0, ["Comparative Analysis of Think-Aloud Methods for Everyday Activities in the Context of Cognitive Robotics", ["Moritz Meier", "Celeste Mason", "Felix Putze", "Tanja Schultz"], "https://doi.org/10.21437/Interspeech.2019-3072", 5, "interspeech", 2019], ["Biosignal Processing for Human-Machine Interaction", ["Tanja Schultz"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/abs6.html", 0, "interspeech", 2019]], "Kara D. Federmeier": [0, ["The Neural Correlates Underlying Lexically-Guided Perceptual Learning", ["Odette Scharenborg", "Jiska Koemans", "Cybelle Smith", "Mark A. Hasegawa-Johnson", "Kara D. Federmeier"], "https://doi.org/10.21437/Interspeech.2019-2328", 5, "interspeech", 2019]], "Ian Lane": [0, ["BERT-DST: Scalable End-to-End Dialogue State Tracking with Bidirectional Encoder Representations from Transformer", ["Guan-Lin Chao", "Ian Lane"], "https://doi.org/10.21437/Interspeech.2019-1355", 5, "interspeech", 2019]], "Jenifer Vega Rodriguez": [0, ["The Vowel System of Korebaju", ["Jenifer Vega Rodriguez"], "https://doi.org/10.21437/Interspeech.2019-3210", 5, "interspeech", 2019]], "Omri Allouche": [0, ["GECKO - A Tool for Effective Annotation of Human Conversations", ["Golan Levy", "Raquel Sitman", "Ido Amir", "Eduard Golshtein", "Ran Mochary", "Eilon Reshef", "Roi Reichart", "Omri Allouche"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8025.html", 2, "interspeech", 2019]], "Ron Hoory": [0, ["High Quality, Lightweight and Adaptable TTS Using LPCNet", ["Zvi Kons", "Slava Shechtman", "Alexander Sorin", "Carmel Rabinovitz", "Ron Hoory"], "https://doi.org/10.21437/Interspeech.2019-1705", 5, "interspeech", 2019]], "Hung-yi Lee": [5.747688737756107e-05, ["Code-Switching Sentence Generation by Generative Adversarial Networks and its Application to Data Augmentation", ["Ching-Ting Chang", "Shun-Po Chuang", "Hung-yi Lee"], "https://doi.org/10.21437/Interspeech.2019-3214", 5, "interspeech", 2019], ["One-Shot Voice Conversion by Separating Speaker and Content Representations with Instance Normalization", ["Ju-Chieh Chou", "Hung-yi Lee"], "https://doi.org/10.21437/Interspeech.2019-2663", 5, "interspeech", 2019], ["Unsupervised End-to-End Learning of Discrete Linguistic Units for Voice Conversion", ["Andy T. Liu", "Po-chun Hsu", "Hung-yi Lee"], "https://doi.org/10.21437/Interspeech.2019-2048", 5, "interspeech", 2019], ["End-to-End Text-to-Speech for Low-Resource Languages by Cross-Lingual Transfer Learning", ["Yuan-Jui Chen", "Tao Tu", "Cheng-chieh Yeh", "Hung-yi Lee"], "https://doi.org/10.21437/Interspeech.2019-2730", 5, "interspeech", 2019], ["Personalized Dialogue Response Generation Learned from Monologues", ["Feng-Guang Su", "Aliyah R. Hsu", "Yi-Lin Tuan", "Hung-yi Lee"], "https://doi.org/10.21437/Interspeech.2019-1696", 5, "interspeech", 2019]], "Lu Wang": [8.899776003090665e-05, ["Parameter-Transfer Learning for Low-Resource Individualization of Head-Related Transfer Functions", ["Xiaoke Qi", "Lu Wang"], "https://doi.org/10.21437/Interspeech.2019-2558", 5, "interspeech", 2019]], "Irit Opher": [0, ["Identifying Distinctive Acoustic and Spectral Features in Parkinson's Disease", ["Yermiyahu Hauptman", "Ruth Aloni-Lavi", "Itshak Lapidot", "Tanya Gurevich", "Yael Manor", "Stav Naor", "Noa Diamant", "Irit Opher"], "https://doi.org/10.21437/Interspeech.2019-2465", 5, "interspeech", 2019]], "Julien Epps": [0, ["Biologically Inspired Adaptive-Q Filterbanks for Replay Spoofing Attack Detection", ["Buddhi Wickramasinghe", "Eliathamby Ambikairajah", "Julien Epps"], "https://doi.org/10.21437/Interspeech.2019-1535", 5, "interspeech", 2019], ["Direct Modelling of Speech Emotion from Raw Speech", ["Siddique Latif", "Rajib Rana", "Sara Khalifa", "Raja Jurdak", "Julien Epps"], "https://doi.org/10.21437/Interspeech.2019-3252", 5, "interspeech", 2019]], "Li-Rong Dai": [0, ["Improving Aggregation and Loss Function for Better Embedding Learning in End-to-End Speaker Verification System", ["Zhifu Gao", "Yan Song", "Ian McLoughlin", "Pengcheng Li", "Yiheng Jiang", "Li-Rong Dai"], "https://doi.org/10.21437/Interspeech.2019-1489", 5, "interspeech", 2019], ["A Chinese Dataset for Identifying Speakers in Novels", ["Jia-Xiang Chen", "Zhen-Hua Ling", "Li-Rong Dai"], "https://doi.org/10.21437/Interspeech.2019-1614", 5, "interspeech", 2019], ["Singing Voice Synthesis Using Deep Autoregressive Neural Networks for Acoustic Modeling", ["Yuan-Hao Yi", "Yang Ai", "Zhen-Hua Ling", "Li-Rong Dai"], "https://doi.org/10.21437/Interspeech.2019-1563", 5, "interspeech", 2019], ["An Effective Deep Embedding Learning Architecture for Speaker Verification", ["Yiheng Jiang", "Yan Song", "Ian McLoughlin", "Zhifu Gao", "Li-Rong Dai"], "https://doi.org/10.21437/Interspeech.2019-1606", 5, "interspeech", 2019]], "Soo-Young Lee": [0.9948376417160034, ["Adjusting Pleasure-Arousal-Dominance for Continuous Emotional Text-to-Speech Synthesizer", ["Azam Rabiee", "Tae-Ho Kim", "Soo-Young Lee"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8045.html", 2, "interspeech", 2019]], "Diane J. Litman": [0, ["Identifying Personality Traits Using Overlap Dynamics in Multiparty Dialogue", ["Mingzhi Yu", "Emer Gilmartin", "Diane J. Litman"], "https://doi.org/10.21437/Interspeech.2019-1886", 5, "interspeech", 2019]], "Devang Naik": [0, ["Leveraging Acoustic Cues and Paralinguistic Embeddings to Detect Expression from Voice", ["Vikramjit Mitra", "Sue Booker", "Erik Marchi", "David Scott Farrar", "Ute Dorothea Peitz", "Bridget Cheng", "Ermine Teves", "Anuj Mehta", "Devang Naik"], "https://doi.org/10.21437/Interspeech.2019-2998", 5, "interspeech", 2019]], "R. H. Y. So": [0.5, ["Effects of Base-Frequency and Spectral Envelope on Deep-Learning Speech Separation and Recognition Models", ["J. Hui", "Y. Wei", "S. T. Chen", "R. H. Y. So"], "https://doi.org/10.21437/Interspeech.2019-1715", 5, "interspeech", 2019]], "Huy Dat Tran": [0, ["Device Feature Extractor for Replay Spoofing Detection", ["Chang Huai You", "Jichen Yang", "Huy Dat Tran"], "https://doi.org/10.21437/Interspeech.2019-2137", 5, "interspeech", 2019]], "Emmanuel Vincent": [0, ["A Statistically Principled and Computationally Efficient Approach to Speech Enhancement Using Variational Autoencoders", ["Manuel Pariente", "Antoine Deleforge", "Emmanuel Vincent"], "https://doi.org/10.21437/Interspeech.2019-1398", 5, "interspeech", 2019], ["Privacy-Preserving Adversarial Representation Learning in ASR: Reality or Illusion?", ["Brij Mohan Lal Srivastava", "Aurelien Bellet", "Marc Tommasi", "Emmanuel Vincent"], "https://doi.org/10.21437/Interspeech.2019-2415", 5, "interspeech", 2019]], "Sunil Kumar Kopparapu": [0, ["End-to-End Spoken Language Understanding: Bootstrapping in Low Resource Scenarios", ["Swapnil Bhosale", "Imran Sheikh", "Sri Harsha Dumpala", "Sunil Kumar Kopparapu"], "https://doi.org/10.21437/Interspeech.2019-2366", 5, "interspeech", 2019], ["Front-End Feature Compensation and Denoising for Noise Robust Speech Emotion Recognition", ["Rupayan Chakraborty", "Ashish Panda", "Meghna Pandharipande", "Sonal Joshi", "Sunil Kumar Kopparapu"], "https://doi.org/10.21437/Interspeech.2019-2243", 5, "interspeech", 2019]], "Wei-Qiang Zhang": [0, ["Towards Discriminative Representations and Unbiased Predictions: Class-Specific Angular Softmax for Speech Emotion Recognition", ["Zhixuan Li", "Liang He", "Jingyang Li", "Li Wang", "Wei-Qiang Zhang"], "https://doi.org/10.21437/Interspeech.2019-1683", 5, "interspeech", 2019], ["Learning How to Listen: A Temporal-Frequential Attention Model for Sound Event Detection", ["Yu-Han Shen", "Ke-Xin He", "Wei-Qiang Zhang"], "https://doi.org/10.21437/Interspeech.2019-2045", 5, "interspeech", 2019], ["Music Genre Classification Using Duplicated Convolutional Layers in Neural Networks", ["Hansi Yang", "Wei-Qiang Zhang"], "https://doi.org/10.21437/Interspeech.2019-1298", 5, "interspeech", 2019], ["Hierarchical Pooling Structure for Weakly Labeled Sound Event Detection", ["Ke-Xin He", "Yu-Han Shen", "Wei-Qiang Zhang"], "https://doi.org/10.21437/Interspeech.2019-2049", 5, "interspeech", 2019]], "Susanne Fuchs": [0, ["Temporal Coordination of Articulatory and Respiratory Events Prior to Speech Initiation", ["Oksana Rasskazova", "Christine Mooshammer", "Susanne Fuchs"], "https://doi.org/10.21437/Interspeech.2019-2876", 5, "interspeech", 2019]], "Jindrich Matousek": [0, ["Web-Based Speech Synthesis Editor", ["Martin Gruber", "Jakub Vit", "Jindrich Matousek"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8013.html", 2, "interspeech", 2019], ["Framework for Conducting Tasks Requiring Human Assessment", ["Martin Gruber", "Adam Chylek", "Jindrich Matousek"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8009.html", 2, "interspeech", 2019]], "Mads G. Christensen": [0, ["Validation of the Non-Intrusive Codebook-Based Short Time Objective Intelligibility Metric for Processed Speech", ["Charlotte Sorensen", "Jesper B. Boldt", "Mads G. Christensen"], "https://doi.org/10.21437/Interspeech.2019-1625", 5, "interspeech", 2019]], "Anyan Shi": [0, ["Deep Attention Gated Dilated Temporal Convolutional Networks with Intra-Parallel Convolutional Modules for End-to-End Monaural Speech Separation", ["Ziqiang Shi", "Huibin Lin", "Liu Liu", "Rujie Liu", "Jiqing Han", "Anyan Shi"], "https://doi.org/10.21437/Interspeech.2019-1373", 5, "interspeech", 2019]], "Kimberley Mulder": [0, ["Analyzing Reaction Time and Error Sequences in Lexical Decision Experiments", ["Louis ten Bosch", "Lou Boves", "Kimberley Mulder"], "https://doi.org/10.21437/Interspeech.2019-2611", 5, "interspeech", 2019]], "Sethuraman Panchanathan": [0, ["Say What? A Dataset for Exploring the Error Patterns That Two ASR Engines Make", ["Meredith Moore", "Michael Saxon", "Hemanth Venkateswara", "Visar Berisha", "Sethuraman Panchanathan"], "https://doi.org/10.21437/Interspeech.2019-3096", 5, "interspeech", 2019]], "Julian J. McAuley": [0, ["Expediting TTS Synthesis with Adversarial Vocoding", ["Paarth Neekhara", "Chris Donahue", "Miller S. Puckette", "Shlomo Dubnov", "Julian J. McAuley"], "https://doi.org/10.21437/Interspeech.2019-3099", 5, "interspeech", 2019]], "Axel Roebel": [0, ["Fully-Convolutional Network for Pitch Estimation of Speech Signals", ["Luc Ardaillon", "Axel Roebel"], "https://doi.org/10.21437/Interspeech.2019-2815", 5, "interspeech", 2019]], "Joon-Hyuk Chang": [0.999975860118866, ["Joint Optimization of Neural Acoustic Beamforming and Dereverberation with x-Vectors for Robust Speaker Verification", ["Joon-Young Yang", "Joon-Hyuk Chang"], "https://doi.org/10.21437/Interspeech.2019-1356", 5, "interspeech", 2019]], "Thomas Schultze": [0, ["Towards the Prosody of Persuasion in Competitive Negotiation. The Relationship Between f0 and Negotiation Success in Same Sex Sales Tasks", ["Jan Michalsky", "Heike Schoormann", "Thomas Schultze"], "https://doi.org/10.21437/Interspeech.2019-3031", 5, "interspeech", 2019]], "W. Bastiaan Kleijn": [0, ["Speech Enhancement with Variance Constrained Autoencoders", ["Daniel T. Braithwaite", "W. Bastiaan Kleijn"], "https://doi.org/10.21437/Interspeech.2019-1809", 5, "interspeech", 2019], ["Maximum a posteriori Speech Enhancement Based on Double Spectrum", ["Pejman Mowlaee", "Daniel Scheran", "Johannes Stahl", "Sean U. N. Wood", "W. Bastiaan Kleijn"], "https://doi.org/10.21437/Interspeech.2019-1197", 5, "interspeech", 2019]], "Qingyang Hong": [0.0002346530818613246, ["Anti-Spoofing Speaker Verification System with Multi-Feature Integration and Multi-Task Learning", ["Rongjin Li", "Miao Zhao", "Zheng Li", "Lin Li", "Qingyang Hong"], "https://doi.org/10.21437/Interspeech.2019-1698", 5, "interspeech", 2019], ["Deep Speaker Embedding Extraction with Channel-Wise Feature Responses and Additive Supervision Softmax Loss Function", ["Jianfeng Zhou", "Tao Jiang", "Zheng Li", "Lin Li", "Qingyang Hong"], "https://doi.org/10.21437/Interspeech.2019-1704", 5, "interspeech", 2019]], "Tetsuji Ogawa": [0, ["Multi-Channel Speech Enhancement Using Time-Domain Convolutional Denoising Autoencoder", ["Naohiro Tawara", "Tetsunori Kobayashi", "Tetsuji Ogawa"], "https://doi.org/10.21437/Interspeech.2019-3197", 5, "interspeech", 2019], ["Speaker Adversarial Training of DPGMM-Based Feature Extractor for Zero-Resource Languages", ["Yosuke Higuchi", "Naohiro Tawara", "Tetsunori Kobayashi", "Tetsuji Ogawa"], "https://doi.org/10.21437/Interspeech.2019-2052", 5, "interspeech", 2019]], "Julia Parish-Morris": [0, ["Automatic Detection of Autism Spectrum Disorder in Children Using Acoustic and Text Features from Brief Natural Conversations", ["Sunghye Cho", "Mark Liberman", "Neville Ryant", "Meredith Cola", "Robert T. Schultz", "Julia Parish-Morris"], "https://doi.org/10.21437/Interspeech.2019-1452", 5, "interspeech", 2019]], "Alejandrina Cristia": [0, ["Towards Detection of Canonical Babbling by Citizen Scientists: Performance as a Function of Clip Length", ["Amanda Seidl", "Anne S. Warlaumont", "Alejandrina Cristia"], "https://doi.org/10.21437/Interspeech.2019-1773", 5, "interspeech", 2019]], "Eng Siong Chng": [0, ["Enriching Rare Word Representations in Neural Language Models by Embedding Matrix Augmentation", ["Yerbolat Khassanov", "Zhiping Zeng", "Van Tung Pham", "Haihua Xu", "Eng Siong Chng"], "https://doi.org/10.21437/Interspeech.2019-1858", 5, "interspeech", 2019]], "Batushiren": [0, ["UNetGAN: A Robust Speech Enhancement Approach in Time Domain for Extremely Low Signal-to-Noise Ratio Condition", ["Xiang Hao", "Xiangdong Su", "Zhiyu Wang", "Hui Zhang", "Batushiren"], "https://doi.org/10.21437/Interspeech.2019-1567", 5, "interspeech", 2019]], "Thierry Dutoit": [0, ["Visualization and Interpretation of Latent Spaces for Controlling Expressive Speech Synthesis Through Audio Analysis", ["Noe Tits", "Fengna Wang", "Kevin El Haddad", "Vincent Pagel", "Thierry Dutoit"], "https://doi.org/10.21437/Interspeech.2019-1426", 5, "interspeech", 2019]], "Helen Meng": [0, ["One-Shot Voice Conversion with Global Speaker Embeddings", ["Hui Lu", "Zhiyong Wu", "Dongyang Dai", "Runnan Li", "Shiyin Kang", "Jia Jia", "Helen Meng"], "https://doi.org/10.21437/Interspeech.2019-2365", 5, "interspeech", 2019], ["Jointly Trained Conversion Model and WaveNet Vocoder for Non-Parallel Voice Conversion Using Mel-Spectrograms and Phonetic Posteriorgrams", ["Songxiang Liu", "Yuewen Cao", "Xixin Wu", "Lifa Sun", "Xunying Liu", "Helen Meng"], "https://doi.org/10.21437/Interspeech.2019-1316", 5, "interspeech", 2019], ["Disambiguation of Chinese Polyphones in an End-to-End Framework with Semantic Features Extracted by Pre-Trained BERT", ["Dongyang Dai", "Zhiyong Wu", "Shiyin Kang", "Xixin Wu", "Jia Jia", "Dan Su", "Dong Yu", "Helen Meng"], "https://doi.org/10.21437/Interspeech.2019-2292", 5, "interspeech", 2019], ["LF-MMI Training of Bayesian and Gaussian Process Time Delay Neural Networks for Speech Recognition", ["Shoukang Hu", "Xurong Xie", "Shansong Liu", "Max W. Y. Lam", "Jianwei Yu", "Xixin Wu", "Xunying Liu", "Helen Meng"], "https://doi.org/10.21437/Interspeech.2019-2379", 5, "interspeech", 2019], ["Unsupervised Methods for Audio Classification from Lecture Discussion Recordings", ["Hang Su", "Borislav Dzodzo", "Xixin Wu", "Xunying Liu", "Helen Meng"], "https://doi.org/10.21437/Interspeech.2019-2384", 5, "interspeech", 2019], ["Comparative Study of Parametric and Representation Uncertainty Modeling for Recurrent Neural Network Language Models", ["Jianwei Yu", "Max W. Y. Lam", "Shoukang Hu", "Xixin Wu", "Xu Li", "Yuewen Cao", "Xunying Liu", "Helen Meng"], "https://doi.org/10.21437/Interspeech.2019-1927", 5, "interspeech", 2019], ["The CUHK Dysarthric Speech Recognition Systems for English and Cantonese", ["Shoukang Hu", "Shansong Liu", "Heng Fai Chang", "Mengzhe Geng", "Jiani Chen", "Lau Wing Chung", "To Ka Hei", "Jianwei Yu", "Ka Ho Wong", "Xunying Liu", "Helen Meng"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8047.html", 2, "interspeech", 2019], ["Exploiting Visual Features Using Bayesian Gated Neural Networks for Disordered Speech Recognition", ["Shansong Liu", "Shoukang Hu", "Yi Wang", "Jianwei Yu", "Rongfeng Su", "Xunying Liu", "Helen Meng"], "https://doi.org/10.21437/Interspeech.2019-1536", 5, "interspeech", 2019], ["On the Use of Pitch Features for Disordered Speech Recognition", ["Shansong Liu", "Shoukang Hu", "Xunying Liu", "Helen Meng"], "https://doi.org/10.21437/Interspeech.2019-2609", 5, "interspeech", 2019], ["Knowledge-Based Linguistic Encoding for End-to-End Mandarin Text-to-Speech Synthesis", ["Jingbei Li", "Zhiyong Wu", "Runnan Li", "Pengpeng Zhi", "Song Yang", "Helen Meng"], "https://doi.org/10.21437/Interspeech.2019-1118", 5, "interspeech", 2019]], "Stefan Werner": [0, ["Recognition of Creaky Voice from Emergency Calls", ["Lauri Tavi", "Tanel Alumae", "Stefan Werner"], "https://doi.org/10.21437/Interspeech.2019-1253", 5, "interspeech", 2019]], "Norihide Kitaoka": [0, ["Small-Footprint Magic Word Detection Method Using Convolutional LSTM Neural Network", ["Taiki Yamamoto", "Ryota Nishimura", "Masayuki Misaki", "Norihide Kitaoka"], "https://doi.org/10.21437/Interspeech.2019-1662", 5, "interspeech", 2019]], "Steve Renals": [0, ["Ultrasound Tongue Imaging for Diarization and Alignment of Child Speech Therapy Sessions", ["Manuel Sam Ribeiro", "Aciel Eshky", "Korin Richmond", "Steve Renals"], "https://doi.org/10.21437/Interspeech.2019-2612", 5, "interspeech", 2019], ["Untranscribed Web Audio for Low Resource Speech Recognition", ["Andrea Carmantini", "Peter Bell", "Steve Renals"], "https://doi.org/10.21437/Interspeech.2019-2623", 5, "interspeech", 2019], ["Trainable Dynamic Subsampling for End-to-End Speech Recognition", ["Shucong Zhang", "Erfan Loweimi", "Yumo Xu", "Peter Bell", "Steve Renals"], "https://doi.org/10.21437/Interspeech.2019-2778", 5, "interspeech", 2019], ["On Learning Interpretable CNNs with Parametric Modulated Kernel-Based Filters", ["Erfan Loweimi", "Peter Bell", "Steve Renals"], "https://doi.org/10.21437/Interspeech.2019-1257", 5, "interspeech", 2019], ["Synchronising Audio and Ultrasound by Learning Cross-Modal Embeddings", ["Aciel Eshky", "Manuel Sam Ribeiro", "Korin Richmond", "Steve Renals"], "https://doi.org/10.21437/Interspeech.2019-1804", 5, "interspeech", 2019]], "Ruoming Pang": [0, ["Shallow-Fusion End-to-End Contextual Biasing", ["Ding Zhao", "Tara N. Sainath", "David Rybach", "Pat Rondon", "Deepti Bhatia", "Bo Li", "Ruoming Pang"], "https://doi.org/10.21437/Interspeech.2019-1209", 5, "interspeech", 2019]], "Helmer Strik": [0, ["Deep Sensing of Breathing Signal During Conversational Speech", ["Venkata Srikanth Nallanthighal", "Aki Harma", "Helmer Strik"], "https://doi.org/10.21437/Interspeech.2019-1796", 5, "interspeech", 2019]], "Chi-Chun Lee": [0.2932860553264618, ["Attentive to Individual: A Multimodal Emotion Recognition Network with Personalized Attention Profile", ["Jeng-Lin Li", "Chi-Chun Lee"], "https://doi.org/10.21437/Interspeech.2019-2044", 5, "interspeech", 2019], ["Predicting Group Performances Using a Personality Composite-Network Architecture During Collaborative Task", ["Shun-Chang Zhong", "Yun-Shao Lin", "Chun-Min Chang", "Yi-Ching Liu", "Chi-Chun Lee"], "https://doi.org/10.21437/Interspeech.2019-2087", 5, "interspeech", 2019], ["Enforcing Semantic Consistency for Cross Corpus Valence Regression from Speech Using Adversarial Discrepancy Learning", ["Gao-Yi Chao", "Yun-Shao Lin", "Chun-Min Chang", "Chi-Chun Lee"], "https://doi.org/10.21437/Interspeech.2019-2037", 5, "interspeech", 2019], ["Using Attention Networks and Adversarial Augmentation for Styrian Dialect Continuous Sleepiness and Baby Sound Recognition", ["Sung-Lin Yeh", "Gao-Yi Chao", "Bo-Hao Su", "Yu-Lin Huang", "Meng-Han Lin", "Yin-Chun Tsai", "Yu-Wen Tai", "Zheng-Chi Lu", "Chieh-Yu Chen", "Tsung-Ming Tai", "Chiu-Wang Tseng", "Cheng-Kuang Lee", "Chi-Chun Lee"], "https://doi.org/10.21437/Interspeech.2019-2110", 5, "interspeech", 2019], ["Investigating the Variability of Voice Quality and Pain Levels as a Function of Multiple Clinical Parameters", ["Hui-Ting Hong", "Jeng-Lin Li", "Yi-Ming Weng", "Chip-Jin Ng", "Chi-Chun Lee"], "https://doi.org/10.21437/Interspeech.2019-2247", 5, "interspeech", 2019]], "Sanjeev Khudanpur": [0, ["Advances in Automatic Speech Recognition for Child Speech Using Factored Time Delay Neural Network", ["Fei Wu", "Leibny Paola Garcia-Perera", "Daniel Povey", "Sanjeev Khudanpur"], "https://doi.org/10.21437/Interspeech.2019-2980", 5, "interspeech", 2019], ["Multi-PLDA Diarization on Children's Speech", ["Jiamin Xie", "Leibny Paola Garcia-Perera", "Daniel Povey", "Sanjeev Khudanpur"], "https://doi.org/10.21437/Interspeech.2019-2961", 5, "interspeech", 2019], ["x-Vector DNN Refinement with Full-Length Recordings for Speaker Recognition", ["Daniel Garcia-Romero", "David Snyder", "Gregory Sell", "Alan McCree", "Daniel Povey", "Sanjeev Khudanpur"], "https://doi.org/10.21437/Interspeech.2019-2205", 4, "interspeech", 2019], ["Speaker Recognition Benchmark Using the CHiME-5 Corpus", ["Daniel Garcia-Romero", "David Snyder", "Shinji Watanabe", "Gregory Sell", "Alan McCree", "Daniel Povey", "Sanjeev Khudanpur"], "https://doi.org/10.21437/Interspeech.2019-2174", 5, "interspeech", 2019], ["The JHU Speaker Recognition System for the VOiCES 2019 Challenge", ["David Snyder", "Jesus Villalba", "Nanxin Chen", "Daniel Povey", "Gregory Sell", "Najim Dehak", "Sanjeev Khudanpur"], "https://doi.org/10.21437/Interspeech.2019-2979", 5, "interspeech", 2019], ["The JHU ASR System for VOiCES from a Distance Challenge 2019", ["Yiming Wang", "David Snyder", "Hainan Xu", "Vimal Manohar", "Phani Sankar Nidadavolu", "Daniel Povey", "Sanjeev Khudanpur"], "https://doi.org/10.21437/Interspeech.2019-1948", 5, "interspeech", 2019], ["Pretraining by Backtranslation for End-to-End ASR in Low-Resource Settings", ["Matthew Wiesner", "Adithya Renduchintala", "Shinji Watanabe", "Chunxi Liu", "Najim Dehak", "Sanjeev Khudanpur"], "https://doi.org/10.21437/Interspeech.2019-3254", 5, "interspeech", 2019]], "Diane Hirschfeld": [0, ["Cross-Lingual Transfer Learning for Affective Spoken Dialogue Systems", ["Kristijan Gjoreski", "Aleksandar Gjoreski", "Ivan Kraljevski", "Diane Hirschfeld"], "https://doi.org/10.21437/Interspeech.2019-2163", 5, "interspeech", 2019]], "John H. L. Hansen": [0, ["Toeplitz Inverse Covariance Based Robust Speaker Clustering for Naturalistic Audio Streams", ["Harishchandra Dubey", "Abhijeet Sangwan", "John H. L. Hansen"], "https://doi.org/10.21437/Interspeech.2019-1102", 5, "interspeech", 2019], ["A Machine Learning Based Clustering Protocol for Determining Hearing Aid Initial Configurations from Pure-Tone Audiograms", ["Chelzy Belitz", "Hussnain Ali", "John H. L. Hansen"], "https://doi.org/10.21437/Interspeech.2019-3091", 5, "interspeech", 2019], ["Quantifying Cochlear Implant Users' Ability for Speaker Identification Using CI Auditory Stimuli", ["Nursadul Mamun", "Ria Ghosh", "John H. L. Hansen"], "https://doi.org/10.21437/Interspeech.2019-1852", 5, "interspeech", 2019], ["Adversarial Regularization for End-to-End Robust Speaker Verification", ["Qing Wang", "Pengcheng Guo", "Sining Sun", "Lei Xie", "John H. L. Hansen"], "https://doi.org/10.21437/Interspeech.2019-2983", 5, "interspeech", 2019], ["Convolutional Neural Network-Based Speech Enhancement for Cochlear Implant Recipients", ["Nursadul Mamun", "Soheil Khorram", "John H. L. Hansen"], "https://doi.org/10.21437/Interspeech.2019-1850", 5, "interspeech", 2019], ["Probabilistic Permutation Invariant Training for Speech Separation", ["Midia Yousefi", "Soheil Khorram", "John H. L. Hansen"], "https://doi.org/10.21437/Interspeech.2019-1827", 5, "interspeech", 2019]], "Visar Berisha": [0, ["Objective Assessment of Social Skills Using Automated Language Analysis for Identification of Schizophrenia and Bipolar Disorder", ["Rohit Voleti", "Stephanie Woolridge", "Julie M. Liss", "Melissa Milanovic", "Christopher R. Bowie", "Visar Berisha"], "https://doi.org/10.21437/Interspeech.2019-2960", 5, "interspeech", 2019], ["Do Conversational Partners Entrain on Articulatory Precision?", ["Nichola Lubold", "Stephanie A. Borrie", "Tyson S. Barrett", "Megan M. Willi", "Visar Berisha"], "https://doi.org/10.21437/Interspeech.2019-1786", 5, "interspeech", 2019]], "Janet Wiles": [0, ["Elpis, an Accessible Speech-to-Text Tool", ["Ben Foley", "Alina Rakhi", "Nicholas Lambourne", "Nicholas Buckeridge", "Janet Wiles"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8006.html", 2, "interspeech", 2019]], "Ronan Collobert": [0, ["Sequence-to-Sequence Speech Recognition with Time-Depth Separable Convolutions", ["Awni Hannun", "Ann Lee", "Qiantong Xu", "Ronan Collobert"], "https://doi.org/10.21437/Interspeech.2019-2460", 5, "interspeech", 2019], ["Who Needs Words? Lexicon-Free Speech Recognition", ["Tatiana Likhomanenko", "Gabriel Synnaeve", "Ronan Collobert"], "https://doi.org/10.21437/Interspeech.2019-3107", 5, "interspeech", 2019]], "Yoshua Bengio": [0, ["Learning Problem-Agnostic Speech Representations from Multiple Self-Supervised Tasks", ["Santiago Pascual", "Mirco Ravanelli", "Joan Serra", "Antonio Bonafonte", "Yoshua Bengio"], "https://doi.org/10.21437/Interspeech.2019-2605", 5, "interspeech", 2019], ["Speech Model Pre-Training for End-to-End Spoken Language Understanding", ["Loren Lugosch", "Mirco Ravanelli", "Patrick Ignoto", "Vikrant Singh Tomar", "Yoshua Bengio"], "https://doi.org/10.21437/Interspeech.2019-2396", 5, "interspeech", 2019], ["Learning Speaker Representations with Mutual Information", ["Mirco Ravanelli", "Yoshua Bengio"], "https://doi.org/10.21437/Interspeech.2019-2380", 5, "interspeech", 2019]], "Odette Scharenborg": [0, ["Survey Talk: Reaching Over the Gap: Cross- and Interdisciplinary Research on Human and Automatic Speech Processing", ["Odette Scharenborg"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/abs25.html", 0, "interspeech", 2019]], "Ravi Teja Gadde": [0, ["Jasper: An End-to-End Convolutional Neural Acoustic Model", ["Jason Li", "Vitaly Lavrukhin", "Boris Ginsburg", "Ryan Leary", "Oleksii Kuchaiev", "Jonathan M. Cohen", "Huyen Nguyen", "Ravi Teja Gadde"], "https://doi.org/10.21437/Interspeech.2019-1819", 5, "interspeech", 2019]], "Mark A. Hasegawa-Johnson": [0, ["Learning Speaker Aware Offsets for Speaker Adaptation of Neural Networks", ["Leda Sari", "Samuel Thomas", "Mark A. Hasegawa-Johnson"], "https://doi.org/10.21437/Interspeech.2019-1788", 5, "interspeech", 2019], ["Multimodal Word Discovery and Retrieval with Phone Sequence and Image Concepts", ["Liming Wang", "Mark A. Hasegawa-Johnson"], "https://doi.org/10.21437/Interspeech.2019-1487", 5, "interspeech", 2019]], "Tokihiko Kaburagi": [0, ["A Study of Soprano Singing in Light of the Source-Filter Interaction", ["Tokihiko Kaburagi"], "https://doi.org/10.21437/Interspeech.2019-1153", 5, "interspeech", 2019]], "Jason D. Williams": [0, ["Active Learning for Domain Classification in a Commercial Spoken Personal Assistant", ["Xi C. Chen", "Adithya Sagar", "Justine T. Kao", "Tony Y. Li", "Christopher Klein", "Stephen Pulman", "Ashish Garg", "Jason D. Williams"], "https://doi.org/10.21437/Interspeech.2019-1315", 5, "interspeech", 2019]], "Haizhou Li": [0, ["A Speaker-Dependent WaveNet for Voice Conversion with Non-Parallel Data", ["Xiaohai Tian", "Eng Siong Chng", "Haizhou Li"], "https://doi.org/10.21437/Interspeech.2019-1514", 5, "interspeech", 2019], ["A Combination of Model-Based and Feature-Based Strategy for Speech-to-Singing Alignment", ["Bidisha Sharma", "Haizhou Li"], "https://doi.org/10.21437/Interspeech.2019-1942", 5, "interspeech", 2019], ["Long Range Acoustic Features for Spoofed Speech Detection", ["Rohan Kumar Das", "Jichen Yang", "Haizhou Li"], "https://doi.org/10.21437/Interspeech.2019-1887", 5, "interspeech", 2019], ["Target Speaker Extraction for Multi-Talker Speaker Verification", ["Wei Rao", "Chenglin Xu", "Eng Siong Chng", "Haizhou Li"], "https://doi.org/10.21437/Interspeech.2019-1410", 5, "interspeech", 2019], ["Multi-Level Adaptive Speech Activity Detector for Speech in Naturalistic Environments", ["Bidisha Sharma", "Rohan Kumar Das", "Haizhou Li"], "https://doi.org/10.21437/Interspeech.2019-1928", 5, "interspeech", 2019], ["On the Importance of Audio-Source Separation for Singer Identification in Polyphonic Music", ["Bidisha Sharma", "Rohan Kumar Das", "Haizhou Li"], "https://doi.org/10.21437/Interspeech.2019-1925", 5, "interspeech", 2019], ["Acoustic Modeling for Automatic Lyrics-to-Audio Alignment", ["Chitralekha Gupta", "Emre Yilmaz", "Haizhou Li"], "https://doi.org/10.21437/Interspeech.2019-1520", 5, "interspeech", 2019], ["On the End-to-End Solution to Mandarin-English Code-Switching Speech Recognition", ["Zhiping Zeng", "Yerbolat Khassanov", "Van Tung Pham", "Haihua Xu", "Eng Siong Chng", "Haizhou Li"], "https://doi.org/10.21437/Interspeech.2019-1429", 5, "interspeech", 2019], ["NUS Speak-to-Sing: A Web Platform for Personalized Speech-to-Singing Conversion", ["Chitralekha Gupta", "Karthika Vijayan", "Bidisha Sharma", "Xiaoxue Gao", "Haizhou Li"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8041.html", 2, "interspeech", 2019], ["Instantaneous Phase and Long-Term Acoustic Cues for Orca Activity Detection", ["Rohan Kumar Das", "Haizhou Li"], "https://doi.org/10.21437/Interspeech.2019-1894", 5, "interspeech", 2019], ["An Adaptive-Q Cochlear Model for Replay Spoofing Detection", ["Tharshini Gunendradasan", "Eliathamby Ambikairajah", "Julien Epps", "Haizhou Li"], "https://doi.org/10.21437/Interspeech.2019-2361", 5, "interspeech", 2019], ["Robust Sound Recognition: A Neuromorphic Approach", ["Jibin Wu", "Zihan Pan", "Malu Zhang", "Rohan Kumar Das", "Yansong Chua", "Haizhou Li"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8032.html", 2, "interspeech", 2019], ["Linguistically Motivated Parallel Data Augmentation for Code-Switch Language Modeling", ["Grandee Lee", "Xianghu Yue", "Haizhou Li"], "https://doi.org/10.21437/Interspeech.2019-1382", 5, "interspeech", 2019], ["Code-Switching Detection Using ASR-Generated Language Posteriors", ["Qinyi Wang", "Emre Yilmaz", "Adem Derinel", "Haizhou Li"], "https://doi.org/10.21437/Interspeech.2019-1161", 5, "interspeech", 2019], ["Multi-Graph Decoding for Code-Switching ASR", ["Emre Yilmaz", "Samuel Cohen", "Xianghu Yue", "David A. van Leeuwen", "Haizhou Li"], "https://doi.org/10.21437/Interspeech.2019-1125", 5, "interspeech", 2019], ["A Unified Framework for Speaker and Utterance Verification", ["Tianchi Liu", "Maulik C. Madhavi", "Rohan Kumar Das", "Haizhou Li"], "https://doi.org/10.21437/Interspeech.2019-1994", 5, "interspeech", 2019]], "Nurmemet Yolwas": [0, ["Multimedia Simultaneous Translation System for Minority Language Communication with Mandarin", ["Shen Huang", "Bojie Hu", "Shan Huang", "Pengfei Hu", "Jian Kang", "Zhiqiang Lv", "Jinghao Yan", "Qi Ju", "Shiyin Kang", "Deyi Tuo", "Guangzhi Li", "Nurmemet Yolwas"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8020.html", 2, "interspeech", 2019]], "Changchun Bao": [0, ["Masking Estimation with Phase Restoration of Clean Speech for Monaural Speech Enhancement", ["Xianyun Wang", "Changchun Bao"], "https://doi.org/10.21437/Interspeech.2019-1141", 5, "interspeech", 2019]], "Christian Fuegen": [0, ["Joint Grapheme and Phoneme Embeddings for Contextual End-to-End ASR", ["Zhehuai Chen", "Mahaveer Jain", "Yongqiang Wang", "Michael L. Seltzer", "Christian Fuegen"], "https://doi.org/10.21437/Interspeech.2019-1434", 5, "interspeech", 2019]], "Ramaswamy Palaniappan": [0, ["A Robust Framework for Acoustic Scene Classification", ["Lam Dang Pham", "Ian Vince McLoughlin", "Huy Phan", "Ramaswamy Palaniappan"], "https://doi.org/10.21437/Interspeech.2019-1841", 5, "interspeech", 2019]], "Claude Barras": [0, ["LSTM Based Similarity Measurement with Spectral Clustering for Speaker Diarization", ["Qingjian Lin", "Ruiqing Yin", "Ming Li", "Herve Bredin", "Claude Barras"], "https://doi.org/10.21437/Interspeech.2019-1388", 5, "interspeech", 2019]], "Harinath Garudadri": [0, ["On Mitigating Acoustic Feedback in Hearing Aids with Frequency Warping by All-Pass Networks", ["Ching Hua Lee", "Kuan-Lin Chen", "Fredric J. Harris", "Bhaskar D. Rao", "Harinath Garudadri"], "https://doi.org/10.21437/Interspeech.2019-3195", 5, "interspeech", 2019]], "Tobias Bocklet": [0, ["Ultra-Compact NLU: Neuronal Network Binarization as Regularization", ["Munir Georges", "Krzysztof Czarnowski", "Tobias Bocklet"], "https://doi.org/10.21437/Interspeech.2019-2591", 5, "interspeech", 2019], ["Intel Far-Field Speaker Recognition System for VOiCES Challenge 2019", ["Jonathan Huang", "Tobias Bocklet"], "https://doi.org/10.21437/Interspeech.2019-2894", 5, "interspeech", 2019]], "Hiroshi Ishiguro": [0, ["A Neural Turn-Taking Model without RNN", ["Chaoran Liu", "Carlos Toshinori Ishi", "Hiroshi Ishiguro"], "https://doi.org/10.21437/Interspeech.2019-2270", 5, "interspeech", 2019]], "Bin Ma": [0, ["Fast Learning for Non-Parallel Many-to-Many Voice Conversion with Residual Star Generative Adversarial Networks", ["Shengkui Zhao", "Trung Hieu Nguyen", "Hao Wang", "Bin Ma"], "https://doi.org/10.21437/Interspeech.2019-2067", 5, "interspeech", 2019], ["Multi-Task Multi-Network Joint-Learning of Deep Residual Networks and Cycle-Consistency Generative Adversarial Networks for Robust Speech Recognition", ["Shengkui Zhao", "Chongjia Ni", "Rong Tong", "Bin Ma"], "https://doi.org/10.21437/Interspeech.2019-2078", 5, "interspeech", 2019], ["Constrained Output Embeddings for End-to-End Code-Switching Speech Recognition with Only Monolingual Data", ["Yerbolat Khassanov", "Haihua Xu", "Van Tung Pham", "Zhiping Zeng", "Eng Siong Chng", "Chongjia Ni", "Bin Ma"], "https://doi.org/10.21437/Interspeech.2019-1867", 5, "interspeech", 2019]], "Alexandr Kozlov": [0, ["Speaker Diarization with Deep Speaker Embeddings for DIHARD Challenge II", ["Sergey Novoselov", "Aleksei Gusev", "Artem Ivanov", "Timur Pekhovsky", "Andrey Shulipa", "Anastasia Avdeeva", "Artem Gorlanov", "Alexandr Kozlov"], "https://doi.org/10.21437/Interspeech.2019-2757", 5, "interspeech", 2019], ["STC Antispoofing Systems for the ASVspoof2019 Challenge", ["Galina Lavrentyeva", "Sergey Novoselov", "Andzhukaev Tseren", "Marina Volkova", "Artem Gorlanov", "Alexandr Kozlov"], "https://doi.org/10.21437/Interspeech.2019-1768", 5, "interspeech", 2019], ["STC Speaker Recognition Systems for the VOiCES from a Distance Challenge", ["Sergey Novoselov", "Aleksei Gusev", "Artem Ivanov", "Timur Pekhovsky", "Andrey Shulipa", "Galina Lavrentyeva", "Vladimir Volokhov", "Alexandr Kozlov"], "https://doi.org/10.21437/Interspeech.2019-2783", 5, "interspeech", 2019], ["STC Speaker Recognition Systems for the VOiCES from a Distance Challenge", ["Sergey Novoselov", "Aleksei Gusev", "Artem Ivanov", "Timur Pekhovsky", "Andrey Shulipa", "Galina Lavrentyeva", "Vladimir Volokhov", "Alexandr Kozlov"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/abs15.html", 0, "interspeech", 2019]], "Marco Turchi": [0, ["Adapting Transformer to End-to-End Spoken Language Translation", ["Mattia Antonino Di Gangi", "Matteo Negri", "Marco Turchi"], "https://doi.org/10.21437/Interspeech.2019-3045", 5, "interspeech", 2019]], "Timo Gerkmann": [0, ["On Nonlinear Spatial Filtering in Multichannel Speech Enhancement", ["Kristina Tesch", "Robert Rehr", "Timo Gerkmann"], "https://doi.org/10.21437/Interspeech.2019-2751", 5, "interspeech", 2019], ["Influence of Speaker-Specific Parameters on Speech Separation Systems", ["David Ditter", "Timo Gerkmann"], "https://doi.org/10.21437/Interspeech.2019-2459", 5, "interspeech", 2019]], "Oguz H. Elibol": [0, ["Semi-Supervised Voice Conversion with Amortized Variational Inference", ["Cory Stephenson", "Gokce Keskin", "Anil Thomas", "Oguz H. Elibol"], "https://doi.org/10.21437/Interspeech.2019-1840", 5, "interspeech", 2019]], "Ali Etemad": [0, ["A Deep Neural Network for Short-Segment Speaker Recognition", ["Amirhossein Hajavi", "Ali Etemad"], "https://doi.org/10.21437/Interspeech.2019-2240", 5, "interspeech", 2019]], "Cyril Allauzen": [0, ["Contextual Recovery of Out-of-Lattice Named Entities in Automatic Speech Recognition", ["Jack Serrino", "Leonid Velikovich", "Petar S. Aleksic", "Cyril Allauzen"], "https://doi.org/10.21437/Interspeech.2019-2962", 5, "interspeech", 2019]], "Jungwon Lee": [0.9839506894350052, ["Deep Multitask Acoustic Echo Cancellation", ["Amin Fazel", "Mostafa El-Khamy", "Jungwon Lee"], "https://doi.org/10.21437/Interspeech.2019-2908", 5, "interspeech", 2019]], "Tei-Wei Kuo": [0, ["IA-NET: Acceleration and Compression of Speech Enhancement Using Integer-Adder Deep Neural Network", ["Yu-Chen Lin", "Yi-Te Hsu", "Szu-Wei Fu", "Yu Tsao", "Tei-Wei Kuo"], "https://doi.org/10.21437/Interspeech.2019-1207", 5, "interspeech", 2019]], "James R. Glass": [0, ["Analyzing Phonetic and Graphemic Representations in End-to-End Automatic Speech Recognition", ["Yonatan Belinkov", "Ahmed Ali", "James R. Glass"], "https://doi.org/10.21437/Interspeech.2019-2599", 5, "interspeech", 2019], ["An Unsupervised Autoregressive Model for Speech Representation Learning", ["Yu-An Chung", "Wei-Ning Hsu", "Hao Tang", "James R. Glass"], "https://doi.org/10.21437/Interspeech.2019-1473", 5, "interspeech", 2019], ["Towards Bilingual Lexicon Discovery From Visually Grounded Speech Audio", ["Emmanuel Azuh", "David Harwath", "James R. Glass"], "https://doi.org/10.21437/Interspeech.2019-1718", 5, "interspeech", 2019], ["MCE 2018: The 1st Multi-Target Speaker Detection and Identification Challenge Evaluation", ["Suwon Shon", "Najim Dehak", "Douglas A. Reynolds", "James R. Glass"], "https://doi.org/10.21437/Interspeech.2019-1572", 5, "interspeech", 2019], ["A Comparison of Deep Learning Methods for Language Understanding", ["Mandy Korpusik", "Zoe Liu", "James R. Glass"], "https://doi.org/10.21437/Interspeech.2019-1262", 5, "interspeech", 2019], ["A Deep Residual Network for Large-Scale Acoustic Scene Analysis", ["Logan Ford", "Hao Tang", "Francois Grondin", "James R. Glass"], "https://doi.org/10.21437/Interspeech.2019-2731", 5, "interspeech", 2019], ["Multiple Sound Source Localization with SVD-PHAT", ["Francois Grondin", "James R. Glass"], "https://doi.org/10.21437/Interspeech.2019-2653", 5, "interspeech", 2019], ["VoiceID Loss: Speech Enhancement for Speaker Verification", ["Suwon Shon", "Hao Tang", "James R. Glass"], "https://doi.org/10.21437/Interspeech.2019-1496", 5, "interspeech", 2019], ["Transfer Learning from Audio-Visual Grounding to Speech Recognition", ["Wei-Ning Hsu", "David Harwath", "James R. Glass"], "https://doi.org/10.21437/Interspeech.2019-1227", 5, "interspeech", 2019]], "Slim Ouni": [0, ["Conditional Variational Auto-Encoder for Text-Driven Expressive AudioVisual Speech Synthesis", ["Sara Dahmani", "Vincent Colotte", "Valerian Girard", "Slim Ouni"], "https://doi.org/10.21437/Interspeech.2019-2848", 5, "interspeech", 2019], ["Modeling Labial Coarticulation with Bidirectional Gated Recurrent Networks and Transfer Learning", ["Theo Biasutto-Lervat", "Sara Dahmani", "Slim Ouni"], "https://doi.org/10.21437/Interspeech.2019-2097", 5, "interspeech", 2019]], "Amanda Stent": [0, ["Hush-Hush Speak: Speech Reconstruction Using Silent Videos", ["Shashwat Uttam", "Yaman Kumar", "Dhruva Sahrawat", "Mansi Aggarwal", "Rajiv Ratn Shah", "Debanjan Mahata", "Amanda Stent"], "https://doi.org/10.21437/Interspeech.2019-3269", 5, "interspeech", 2019]], "Lucy Skidmore": [0, ["On the Use/Misuse of the Term 'Phoneme'", ["Roger K. Moore", "Lucy Skidmore"], "https://doi.org/10.21437/Interspeech.2019-2711", 5, "interspeech", 2019]], "Patrick Kenny": [0, ["Deep Speaker Recognition: Modular or Monolithic?", ["Gautam Bhattacharya", "Md. Jahangir Alam", "Patrick Kenny"], "https://doi.org/10.21437/Interspeech.2019-3146", 5, "interspeech", 2019]], "Preslav Nakov": [0, ["Predicting the Leading Political Ideology of YouTube Channels Using Acoustic, Textual, and Metadata Information", ["Yoan Dinkov", "Ahmed Ali", "Ivan Koychev", "Preslav Nakov"], "https://doi.org/10.21437/Interspeech.2019-2965", 5, "interspeech", 2019]], "Juraj Simko": [0, ["Comparative Analysis of Prosodic Characteristics Using WaveNet Embeddings", ["Antti Suni", "Marcin Wlodarczak", "Martti Vainio", "Juraj Simko"], "https://doi.org/10.21437/Interspeech.2019-2373", 5, "interspeech", 2019]], "Elizabeth Shriberg": [0, ["Optimizing Speech-Input Length for Speaker-Independent Depression Classification", ["Tomasz Rutowski", "Amir Harati", "Yang Lu", "Elizabeth Shriberg"], "https://doi.org/10.21437/Interspeech.2019-3095", 5, "interspeech", 2019]], "Hong-Goo Kang": [1, ["Parameter Enhancement for MELP Speech Codec in Noisy Communication Environment", ["Min-Jae Hwang", "Hong-Goo Kang"], "https://doi.org/10.21437/Interspeech.2019-3249", 5, "interspeech", 2019]], "Hemant A. Patil": [0, ["Phone Aware Nearest Neighbor Technique Using Spectral Transition Measure for Non-Parallel Voice Conversion", ["Nirmesh J. Shah", "Hemant A. Patil"], "https://doi.org/10.21437/Interspeech.2019-1504", 5, "interspeech", 2019], ["Whether to Pretrain DNN or not?: An Empirical Analysis for Voice Conversion", ["Nirmesh J. Shah", "Hardik B. Sailor", "Hemant A. Patil"], "https://doi.org/10.21437/Interspeech.2019-2608", 5, "interspeech", 2019], ["Energy Separation-Based Instantaneous Frequency Estimation for Cochlear Cepstral Feature for Replay Spoof Detection", ["Ankur T. Patil", "Rajul Acharya", "Pulikonda Krishna Aditya Sai", "Hemant A. Patil"], "https://doi.org/10.21437/Interspeech.2019-2742", 5, "interspeech", 2019]], "Ariya Rastrow": [0, ["Neural Machine Translation for Multilingual Grapheme-to-Phoneme Conversion", ["Alex Sokolov", "Tracy Rohlin", "Ariya Rastrow"], "https://doi.org/10.21437/Interspeech.2019-3176", 5, "interspeech", 2019], ["Scalable Multi Corpora Neural Language Models for ASR", ["Anirudh Raju", "Denis Filimonov", "Gautam Tiwari", "Guitang Lan", "Ariya Rastrow"], "https://doi.org/10.21437/Interspeech.2019-3060", 5, "interspeech", 2019]], "Janet Beck": [0, ["Reliability of Clinical Voice Parameters Captured with Smartphones - Measurements of Added Noise and Spectral Tilt", ["Felix Schaeffler", "Stephen Jannetts", "Janet Beck"], "https://doi.org/10.21437/Interspeech.2019-2910", 5, "interspeech", 2019]], "Alexandra Marko": [0, ["Ultrasound-Based Silent Speech Interface Built on a Continuous Vocoder", ["Tamas Gabor Csapo", "Mohammed Salah Al-Radhi", "Geza Nemeth", "Gabor Gosztolya", "Tamas Grosz", "Laszlo Toth", "Alexandra Marko"], "https://doi.org/10.21437/Interspeech.2019-2046", 5, "interspeech", 2019], ["V-to-V Coarticulation Induced Acoustic and Articulatory Variability of Vowels: The Effect of Pitch-Accent", ["Andrea Deme", "Marton Bartok", "Tekla Etelka Graczi", "Tamas Gabor Csapo", "Alexandra Marko"], "https://doi.org/10.21437/Interspeech.2019-2890", 5, "interspeech", 2019]], "Tom Backstrom": [0, ["End-to-End Optimization of Source Models for Speech and Audio Coding Using a Machine Learning Framework", ["Tom Backstrom"], "https://doi.org/10.21437/Interspeech.2019-1284", 5, "interspeech", 2019], ["Super-Wideband Spectral Envelope Modeling for Speech Coding", ["Guillaume Fuchs", "Chamran Ashour", "Tom Backstrom"], "https://doi.org/10.21437/Interspeech.2019-1620", 5, "interspeech", 2019]], "Kai Chen": [0, ["Speech Separation Using Independent Vector Analysis with an Amplitude Variable Gaussian Mixture Model", ["Zhaoyi Gu", "Jing Lu", "Kai Chen"], "https://doi.org/10.21437/Interspeech.2019-2076", 5, "interspeech", 2019]], "Vijay Ramaseshan Chandrasekhar": [0, ["Semi-Supervised Audio Classification with Consistency-Based Regularization", ["Kangkang Lu", "Chuan-Sheng Foo", "Kah Kuan Teh", "Huy Dat Tran", "Vijay Ramaseshan Chandrasekhar"], "https://doi.org/10.21437/Interspeech.2019-1231", 5, "interspeech", 2019]], "Jonathan S. Brumberg": [0, ["Monaural Speech Enhancement with Dilated Convolutions", ["Shadi Pirhosseinloo", "Jonathan S. Brumberg"], "https://doi.org/10.21437/Interspeech.2019-2782", 5, "interspeech", 2019]], "Hitoshi Kiya": [0, ["Investigation on Blind Bandwidth Extension with a Non-Linear Function and its Evaluation of x-Vector-Based Speaker Verification", ["Ryota Kaminishi", "Haruna Miyamoto", "Sayaka Shiota", "Hitoshi Kiya"], "https://doi.org/10.21437/Interspeech.2019-1510", 5, "interspeech", 2019]], "Manfred Kaltenbacher": [0, ["Physiology and Physics of Voice Production", ["Manfred Kaltenbacher"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/abs12.html", 0, "interspeech", 2019]], "Santiago Barreda": [0, ["The Role of Musical Experience in the Perceptual Weighting of Acoustic Cues for the Obstruent Coda Voicing Contrast in American English", ["Michelle Cohn", "Georgia Zellou", "Santiago Barreda"], "https://doi.org/10.21437/Interspeech.2019-3103", 5, "interspeech", 2019]], "Yi Shen": [0, ["Listener Preference on the Local Criterion for Ideal Binary-Masked Speech", ["Zhuohuang Zhang", "Yi Shen"], "https://doi.org/10.21437/Interspeech.2019-1369", 5, "interspeech", 2019]], "Lukas Burget": [0, ["Self-Supervised Speaker Embeddings", ["Themos Stafylakis", "Johan Rohdin", "Oldrich Plchot", "Petr Mizera", "Lukas Burget"], "https://doi.org/10.21437/Interspeech.2019-2842", 5, "interspeech", 2019], ["Factorization of Discriminatively Trained i-Vector Extractor for Speaker Recognition", ["Ondrej Novotny", "Oldrich Plchot", "Ondrej Glembek", "Lukas Burget"], "https://doi.org/10.21437/Interspeech.2019-1757", 5, "interspeech", 2019]], "Yifan Gong": [0.0002331648356630467, ["Speaker Adaptation for Attention-Based End-to-End Speech Recognition", ["Zhong Meng", "Yashesh Gaur", "Jinyu Li", "Yifan Gong"], "https://doi.org/10.21437/Interspeech.2019-3135", 5, "interspeech", 2019], ["Layer Trajectory BLSTM", ["Eric Sun", "Jinyu Li", "Yifan Gong"], "https://doi.org/10.21437/Interspeech.2019-2971", 5, "interspeech", 2019], ["Acoustic-to-Phrase Models for Speech Recognition", ["Yashesh Gaur", "Jinyu Li", "Zhong Meng", "Yifan Gong"], "https://doi.org/10.21437/Interspeech.2019-3056", 5, "interspeech", 2019], ["Self-Teaching Networks", ["Liang Lu", "Eric Sun", "Yifan Gong"], "https://doi.org/10.21437/Interspeech.2019-1467", 5, "interspeech", 2019]], "Shashidhar G. Koolagudi": [0, ["NITK Kids' Speech Corpus", ["Pravin Bhaskar Ramteke", "Sujata Supanekar", "Pradyoth Hegde", "Hanna Nelson", "Venkataraja Aithal", "Shashidhar G. Koolagudi"], "https://doi.org/10.21437/Interspeech.2019-2061", 5, "interspeech", 2019], ["Locality-Constrained Linear Coding Based Fused Visual Features for Robust Acoustic Event Classification", ["Manjunath Mulimani", "Shashidhar G. Koolagudi"], "https://doi.org/10.21437/Interspeech.2019-1421", 5, "interspeech", 2019]], "Nando de Freitas": [0, ["Large-Scale Visual Speech Recognition", ["Brendan Shillingford", "Yannis M. Assael", "Matthew W. Hoffman", "Thomas Paine", "Cian Hughes", "Utsav Prabhu", "Hank Liao", "Hasim Sak", "Kanishka Rao", "Lorrayne Bennett", "Marie Mulville", "Misha Denil", "Ben Coppin", "Ben Laurie", "Andrew W. Senior", "Nando de Freitas"], "https://doi.org/10.21437/Interspeech.2019-1669", 5, "interspeech", 2019]], "Simon Stone": [0, ["Perceptual Optimization of an Enhanced Geometric Vocal Fold Model for Articulatory Speech Synthesis", ["Peter Birkholz", "Susanne Drechsel", "Simon Stone"], "https://doi.org/10.21437/Interspeech.2019-2410", 5, "interspeech", 2019]], "Nicholas W. D. Evans": [0, ["Privacy-Preserving Speaker Recognition with Cohort Score Normalisation", ["Andreas Nautsch", "Jose Patino", "Amos Treiber", "Themos Stafylakis", "Petr Mizera", "Massimiliano Todisco", "Thomas Schneider", "Nicholas W. D. Evans"], "https://doi.org/10.21437/Interspeech.2019-2638", 5, "interspeech", 2019], ["The GDPR & Speech Data: Reflections of Legal and Technology Communities, First Steps Towards a Common Understanding", ["Andreas Nautsch", "Catherine Jasserand", "Els Kindt", "Massimiliano Todisco", "Isabel Trancoso", "Nicholas W. D. Evans"], "https://doi.org/10.21437/Interspeech.2019-2647", 5, "interspeech", 2019]], "Bernd T. Meyer": [0, ["\"Computer, Test My Hearing\": Accurate Speech Audiometry with Smart Speakers", ["Jasper Ooster", "Pia Nancy Porysek Moreta", "Jorg-Hendrik Bach", "Inga Holube", "Bernd T. Meyer"], "https://doi.org/10.21437/Interspeech.2019-2118", 5, "interspeech", 2019]], "Antonio M. Peinado": [0, ["Multi-Channel Block-Online Source Extraction Based on Utterance Adaptation", ["Juan M. Martin-Donas", "Jens Heitkaemper", "Reinhold Haeb-Umbach", "Angel M. Gomez", "Antonio M. Peinado"], "https://doi.org/10.21437/Interspeech.2019-2244", 5, "interspeech", 2019]], "Kris Tjaden": [0, ["Using a Manifold Vocoder for Spectral Voice and Style Conversion", ["Tuan Dinh", "Alexander Kain", "Kris Tjaden"], "https://doi.org/10.21437/Interspeech.2019-1176", 5, "interspeech", 2019]], "John Kane": [0, ["Gender De-Biasing in Speech Emotion Recognition", ["Cristina Gorrostieta", "Reza Lotfian", "Kye Taylor", "Richard Brutti", "John Kane"], "https://doi.org/10.21437/Interspeech.2019-1708", 5, "interspeech", 2019]], "William Speier": [0, ["Identifying Input Features for Development of Real-Time Translation of Neural Signals to Text", ["Janaki Sheth", "Ariel Tankus", "Michelle Tran", "Lindy Comstock", "Itzhak Fried", "William Speier"], "https://doi.org/10.21437/Interspeech.2019-3092", 5, "interspeech", 2019]], "Roger K. Moore": [0, ["Using Alexa for Flashcard-Based Learning", ["Lucy Skidmore", "Roger K. Moore"], "https://doi.org/10.21437/Interspeech.2019-2893", 5, "interspeech", 2019]], "Matthew Sharifi": [0, ["Fr\u00e9chet Audio Distance: A Reference-Free Metric for Evaluating Music Enhancement Algorithms", ["Kevin Kilgour", "Mauricio Zuluaga", "Dominik Roblek", "Matthew Sharifi"], "https://doi.org/10.21437/Interspeech.2019-2219", 5, "interspeech", 2019], ["Low-Dimensional Bottleneck Features for On-Device Continuous Speech Recognition", ["David B. Ramsay", "Kevin Kilgour", "Dominik Roblek", "Matthew Sharifi"], "https://doi.org/10.21437/Interspeech.2019-2193", 4, "interspeech", 2019]], "Sebastien Marcel": [0, ["Understanding and Visualizing Raw Waveform-Based CNNs", ["Hannah Muckenhirn", "Vinayak Abrol", "Mathew Magimai-Doss", "Sebastien Marcel"], "https://doi.org/10.21437/Interspeech.2019-2341", 5, "interspeech", 2019]], "Christer Gobl": [0, ["The Role of Voice Quality in the Perception of Prominence in Synthetic Speech", ["Andy Murphy", "Irena Yanushevskaya", "Ailbhe Ni Chasaide", "Christer Gobl"], "https://doi.org/10.21437/Interspeech.2019-2761", 5, "interspeech", 2019]], "Oh-Wook Kwon": [0.9998743832111359, ["Extending an Acoustic Data-Driven Phone Set for Spontaneous Speech Recognition", ["Jeong-Uk Bang", "Mu-Yeol Choi", "Sang-Hun Kim", "Oh-Wook Kwon"], "https://doi.org/10.21437/Interspeech.2019-1979", 5, "interspeech", 2019]], "Mari Ostendorf": [0, ["Disfluencies and Human Speech Transcription Errors", ["Vicky Zayats", "Trang Tran", "Richard A. Wright", "Courtney Mansfield", "Mari Ostendorf"], "https://doi.org/10.21437/Interspeech.2019-3134", 5, "interspeech", 2019], ["On the Role of Style in Parsing Speech with Neural Models", ["Trang Tran", "Jiahong Yuan", "Yang Liu", "Mari Ostendorf"], "https://doi.org/10.21437/Interspeech.2019-3122", 5, "interspeech", 2019]], "Anders Eriksson": [0, ["Quantifying Fundamental Frequency Modulation as a Function of Language, Speaking Style and Speaker", ["Pablo Arantes", "Anders Eriksson"], "https://doi.org/10.21437/Interspeech.2019-2857", 5, "interspeech", 2019]], "Cunhang Fan": [0, ["A Time Delay Neural Network with Shared Weight Self-Attention for Small-Footprint Keyword Spotting", ["Ye Bai", "Jiangyan Yi", "Jianhua Tao", "Zhengqi Wen", "Zhengkun Tian", "Chenghao Zhao", "Cunhang Fan"], "https://doi.org/10.21437/Interspeech.2019-1676", 5, "interspeech", 2019], ["Automatic Depression Level Detection via \u2113p-Norm Pooling", ["Mingyue Niu", "Jianhua Tao", "Bin Liu", "Cunhang Fan"], "https://doi.org/10.21437/Interspeech.2019-1617", 5, "interspeech", 2019]], "Jian Luan": [0, ["Vocal Pitch Extraction in Polyphonic Music Using Convolutional Residual Network", ["Mingye Dong", "Jie Wu", "Jian Luan"], "https://doi.org/10.21437/Interspeech.2019-2286", 5, "interspeech", 2019]], "Partha Pratim Das": [0, ["Glottal Closure Instants Detection from Speech Signal by Deep Features Extracted from Raw Speech and Linear Prediction Residual", ["Gurunath Reddy M.", "K. Sreenivasa Rao", "Partha Pratim Das"], "https://doi.org/10.21437/Interspeech.2019-1981", 5, "interspeech", 2019]], "Alexander Gutkin": [0, ["Sampling from Stochastic Finite Automata with Applications to CTC Decoding", ["Martin Jansche", "Alexander Gutkin"], "https://doi.org/10.21437/Interspeech.2019-2740", 5, "interspeech", 2019]], "Jonas Fromseier Mortensen": [0, ["Building Large-Vocabulary ASR Systems for Languages Without Any Audio Training Data", ["Manasa Prasad", "Daan van Esch", "Sandy Ritchie", "Jonas Fromseier Mortensen"], "https://doi.org/10.21437/Interspeech.2019-1775", 5, "interspeech", 2019]], "Satoshi Kobashikawa": [0, ["Does the Lombard Effect Improve Emotional Communication in Noise? - Analysis of Emotional Speech Acted in Noise", ["Yi Zhao", "Atsushi Ando", "Shinji Takaki", "Junichi Yamagishi", "Satoshi Kobashikawa"], "https://doi.org/10.21437/Interspeech.2019-1605", 5, "interspeech", 2019]], "Wei Xiang Lieow": [0, ["Meta Learning for Hyperparameter Optimization in Dialogue System", ["Jen-Tzung Chien", "Wei Xiang Lieow"], "https://doi.org/10.21437/Interspeech.2019-1383", 5, "interspeech", 2019]], "Nobuyuki Nishizawa": [0, ["Training Multi-Speaker Neural Text-to-Speech Systems Using Speaker-Imbalanced Speech Corpora", ["Hieu-Thi Luong", "Xin Wang", "Junichi Yamagishi", "Nobuyuki Nishizawa"], "https://doi.org/10.21437/Interspeech.2019-1311", 5, "interspeech", 2019]], "Gerasimos Potamianos": [0, ["End-to-End Convolutional Sequence Learning for ASL Fingerspelling Recognition", ["Katerina Papadimitriou", "Gerasimos Potamianos"], "https://doi.org/10.21437/Interspeech.2019-2422", 5, "interspeech", 2019], ["MobiLipNet: Resource-Efficient Deep Learning Based Lipreading", ["Alexandros Koumparoulis", "Gerasimos Potamianos"], "https://doi.org/10.21437/Interspeech.2019-2618", 5, "interspeech", 2019]], "Juan Manuel Montero": [0, ["A Saliency-Based Attention LSTM Model for Cognitive Load Classification from Speech", ["Ascension Gallardo-Antolin", "Juan Manuel Montero"], "https://doi.org/10.21437/Interspeech.2019-1603", 5, "interspeech", 2019]], "Don McAllaster": [0, ["Bandwidth Embeddings for Mixed-Bandwidth Speech Recognition", ["Gautam Mantena", "Ozlem Kalinli", "Ossama Abdel-Hamid", "Don McAllaster"], "https://doi.org/10.21437/Interspeech.2019-2589", 5, "interspeech", 2019]], "Nicholas Apostoloff": [0, ["Mirroring to Build Trust in Digital Assistants", ["Katherine Metcalf", "Barry-John Theobald", "Garrett Weinberg", "Robert Lee", "Ing-Marie Jonsson", "Russ Webb", "Nicholas Apostoloff"], "https://doi.org/10.21437/Interspeech.2019-1829", 5, "interspeech", 2019]], "Yonghui Wu": [0.6403691470623016, ["Direct Speech-to-Speech Translation with a Sequence-to-Sequence Model", ["Ye Jia", "Ron J. Weiss", "Fadi Biadsy", "Wolfgang Macherey", "Melvin Johnson", "Zhifeng Chen", "Yonghui Wu"], "https://doi.org/10.21437/Interspeech.2019-1951", 5, "interspeech", 2019], ["LibriTTS: A Corpus Derived from LibriSpeech for Text-to-Speech", ["Heiga Zen", "Viet Dang", "Rob Clark", "Yu Zhang", "Ron J. Weiss", "Ye Jia", "Zhifeng Chen", "Yonghui Wu"], "https://doi.org/10.21437/Interspeech.2019-2441", 5, "interspeech", 2019]], "Ashish Panda": [0, ["Label Driven Time-Frequency Masking for Robust Continuous Speech Recognition", ["Meet H. Soni", "Ashish Panda"], "https://doi.org/10.21437/Interspeech.2019-2172", 5, "interspeech", 2019], ["Generative Noise Modeling and Channel Simulation for Robust Speech Recognition in Unseen Conditions", ["Meet H. Soni", "Sonal Joshi", "Ashish Panda"], "https://doi.org/10.21437/Interspeech.2019-2090", 5, "interspeech", 2019]], "Yu Tsao": [0, ["Generative Adversarial Networks for Unpaired Voice Transformation on Impaired Speech", ["Li-Wei Chen", "Hung-yi Lee", "Yu Tsao"], "https://doi.org/10.21437/Interspeech.2019-1265", 5, "interspeech", 2019], ["Specialized Speech Enhancement Model Selection Based on Learned Non-Intrusive Quality Assessment Metric", ["Ryandhimas E. Zezario", "Szu-Wei Fu", "Xugang Lu", "Hsin-Min Wang", "Yu Tsao"], "https://doi.org/10.21437/Interspeech.2019-2425", 5, "interspeech", 2019]], "Martti Vainio": [0, ["Prosodic Representations of Prominence Classification Neural Networks and Autoencoders Using Bottleneck Features", ["Sofoklis Kakouros", "Antti Suni", "Juraj Simko", "Martti Vainio"], "https://doi.org/10.21437/Interspeech.2019-2984", 5, "interspeech", 2019]], "Minje Kim": [0.867972731590271, ["Cascaded Cross-Module Residual Learning Towards Lightweight End-to-End Speech Coding", ["Kai Zhen", "Jongmo Sung", "Mi Suk Lee", "Seungkwon Beack", "Minje Kim"], "https://doi.org/10.21437/Interspeech.2019-1816", 5, "interspeech", 2019]], "Vladlen Koltun": [0, ["Speech Denoising with Deep Feature Losses", ["Francois G. Germain", "Qifeng Chen", "Vladlen Koltun"], "https://doi.org/10.21437/Interspeech.2019-1924", 5, "interspeech", 2019]], "Brian Vaughan": [0, ["An Investigation of Therapeutic Rapport Through Prosody in Brief Psychodynamic Psychotherapy", ["Carolina De Pasquale", "Charlie Cullen", "Brian Vaughan"], "https://doi.org/10.21437/Interspeech.2019-2551", 5, "interspeech", 2019]], "Marin Schroer": [0, ["Pitch Accent Trajectories Across Different Conditions of Visibility and Information Structure - Evidence from Spontaneous Dyadic Interaction", ["Petra Wagner", "Nataliya Bryhadyr", "Marin Schroer"], "https://doi.org/10.21437/Interspeech.2019-1619", 5, "interspeech", 2019]], "Daniela Figueiredo": [0, ["Age-Related Changes in European Portuguese Vowel Acoustics", ["Luciana Albuquerque", "Catarina Oliveira", "Antonio J. S. Teixeira", "Pedro Sa-Couto", "Daniela Figueiredo"], "https://doi.org/10.21437/Interspeech.2019-1818", 5, "interspeech", 2019]], "Klara Vicsi": [0, ["Depression State Assessment: Application for Detection of Depression by Speech", ["Gabor Kiss", "David Sztaho", "Klara Vicsi"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8004.html", 2, "interspeech", 2019]], "Nobukatsu Hojo": [0, ["StarGAN-VC2: Rethinking Conditional Methods for StarGAN-Based Voice Conversion", ["Takuhiro Kaneko", "Hirokazu Kameoka", "Kou Tanaka", "Nobukatsu Hojo"], "https://doi.org/10.21437/Interspeech.2019-2236", 5, "interspeech", 2019]], "Francois Lancelot": [0, ["The Airbus Air Traffic Control Speech Recognition 2018 Challenge: Towards ATC Automatic Transcription and Call Sign Detection", ["Thomas Pellegrini", "Jerome Farinas", "Estelle Delpech", "Francois Lancelot"], "https://doi.org/10.21437/Interspeech.2019-1962", 5, "interspeech", 2019]], "Ying-Ying Tan": [0, ["Building the Singapore English National Speech Corpus", ["Jia Xin Koh", "Aqilah Mislan", "Kevin Khoo", "Brian Ang", "Wilson Ang", "Charmaine Ng", "Ying-Ying Tan"], "https://doi.org/10.21437/Interspeech.2019-1525", 5, "interspeech", 2019]], "Yuan Jia": [0, ["Influence of Contextuality on Prosodic Realization of Information Structure in Chinese Dialogues", ["Bin Li", "Yuan Jia"], "https://doi.org/10.21437/Interspeech.2019-2291", 5, "interspeech", 2019]], "George Saon": [0, ["Challenging the Boundaries of Speech Recognition: The MALACH Corpus", ["Michael Picheny", "Zoltan Tuske", "Brian Kingsbury", "Kartik Audhkhasi", "Xiaodong Cui", "George Saon"], "https://doi.org/10.21437/Interspeech.2019-1907", 5, "interspeech", 2019], ["Advancing Sequence-to-Sequence Based Speech Recognition", ["Zoltan Tuske", "Kartik Audhkhasi", "George Saon"], "https://doi.org/10.21437/Interspeech.2019-3018", 5, "interspeech", 2019]], "Thomas Niesler": [0, ["Improved Low-Resource Somali Speech Recognition by Semi-Supervised Acoustic and Language Model Training", ["Astik Biswas", "Raghav Menon", "Ewald van der Westhuizen", "Thomas Niesler"], "https://doi.org/10.21437/Interspeech.2019-1328", 5, "interspeech", 2019], ["Feature Exploration for Almost Zero-Resource ASR-Free Keyword Spotting Using a Multilingual Bottleneck Extractor and Correspondence Autoencoders", ["Raghav Menon", "Herman Kamper", "Ewald van der Westhuizen", "John Quinn", "Thomas Niesler"], "https://doi.org/10.21437/Interspeech.2019-1665", 5, "interspeech", 2019], ["Improving Automatically Induced Lexicons for Highly Agglutinating Languages Using Data-Driven Morphological Segmentation", ["Wiehan Agenbag", "Thomas Niesler"], "https://doi.org/10.21437/Interspeech.2019-2164", 5, "interspeech", 2019], ["Semi-Supervised Acoustic Model Training for Five-Lingual Code-Switched ASR", ["Astik Biswas", "Emre Yilmaz", "Febe de Wet", "Ewald van der Westhuizen", "Thomas Niesler"], "https://doi.org/10.21437/Interspeech.2019-1325", 5, "interspeech", 2019]], "Kyogu Lee": [0.942917138338089, ["Adversarially Trained End-to-End Korean Singing Voice Synthesis System", ["Juheon Lee", "Hyeong-Seok Choi", "Chang-Bin Jeon", "Junghyun Koo", "Kyogu Lee"], "https://doi.org/10.21437/Interspeech.2019-1722", 5, "interspeech", 2019]], "Adriana Stan": [0, ["All Together Now: The Living Audio Dataset", ["David A. Braude", "Matthew P. Aylett", "Caoimhin Laoide-Kemp", "Simone Ashby", "Kristen M. Scott", "Brian O Raghallaigh", "Anna Braudo", "Alex Brouwer", "Adriana Stan"], "https://doi.org/10.21437/Interspeech.2019-2448", 5, "interspeech", 2019]], "Toshiyuki Kumakura": [0, ["End-to-End Adaptation with Backpropagation Through WFST for On-Device Speech Recognition System", ["Emiru Tsunoo", "Yosuke Kashiwagi", "Satoshi Asakawa", "Toshiyuki Kumakura"], "https://doi.org/10.21437/Interspeech.2019-1880", 5, "interspeech", 2019]], "Ji-Hwan Kim": [0.9722291678190231, ["Shortcut Connections Based Deep Speaker Embeddings for End-to-End Speaker Verification System", ["Soonshin Seo", "Daniel Jun Rim", "Minkyu Lim", "Donghyun Lee", "Hosung Park", "Junseok Oh", "Changmin Kim", "Ji-Hwan Kim"], "https://doi.org/10.21437/Interspeech.2019-2195", 5, "interspeech", 2019]], "Chaitali Chakrabarti": [0, ["Residual + Capsule Networks (ResCap) for Simultaneous Single-Channel Overlapped Keyword Recognition", ["Yan Xiong", "Visar Berisha", "Chaitali Chakrabarti"], "https://doi.org/10.21437/Interspeech.2019-2913", 5, "interspeech", 2019]], "Barbara Gili Fivela": [0, ["L2 Pronunciation Accuracy and Context: A Pilot Study on the Realization of Geminates in Italian as L2 by French Learners", ["Sonia DApolito", "Barbara Gili Fivela"], "https://doi.org/10.21437/Interspeech.2019-2934", 5, "interspeech", 2019]], "Philip C. Woodland": [0, ["Multi-Span Acoustic Modelling Using Raw Waveform Signals", ["Patrick von Platen", "Chao Zhang", "Philip C. Woodland"], "https://doi.org/10.21437/Interspeech.2019-2454", 5, "interspeech", 2019]], "Yoshiko Arimoto": [0, ["Conversational and Social Laughter Synthesis with WaveNet", ["Hiroki Mori", "Tomohiro Nagata", "Yoshiko Arimoto"], "https://doi.org/10.21437/Interspeech.2019-2131", 4, "interspeech", 2019]], "Marcus Liwicki": [0, ["Examining the Combination of Multi-Band Processing and Channel Dropout for Robust Speech Recognition", ["Gyorgy Kovacs", "Laszlo Toth", "Dirk Van Compernolle", "Marcus Liwicki"], "https://doi.org/10.21437/Interspeech.2019-3215", 5, "interspeech", 2019]], "Prasanta Kumar Ghosh": [0, ["An Investigation on Speaker Specific Articulatory Synthesis with Speaker Independent Articulatory Inversion", ["Aravind Illa", "Prasanta Kumar Ghosh"], "https://doi.org/10.21437/Interspeech.2019-2664", 5, "interspeech", 2019], ["ASR Inspired Syllable Stress Detection for Pronunciation Evaluation Without Using a Supervised Classifier and Syllable Level Features", ["Manoj Kumar Ramanathi", "Chiranjeevi Yarra", "Prasanta Kumar Ghosh"], "https://doi.org/10.21437/Interspeech.2019-2091", 5, "interspeech", 2019], ["Acoustic and Articulatory Feature Based Speech Rate Estimation Using a Convolutional Dense Neural Network", ["Renuka Mannem", "Jhansi Mallela", "Aravind Illa", "Prasanta Kumar Ghosh"], "https://doi.org/10.21437/Interspeech.2019-2295", 5, "interspeech", 2019], ["An Improved Goodness of Pronunciation (GoP) Measure for Pronunciation Evaluation with DNN-HMM System Considering HMM Transition Probabilities", ["Sweekar Sudhakara", "Manoj Kumar Ramanathi", "Chiranjeevi Yarra", "Prasanta Kumar Ghosh"], "https://doi.org/10.21437/Interspeech.2019-2363", 5, "interspeech", 2019], ["Low Resource Automatic Intonation Classification Using Gated Recurrent Unit (GRU) Networks Pre-Trained with Synthesized Pitch Patterns", ["Atreyee Saha", "Chiranjeevi Yarra", "Prasanta Kumar Ghosh"], "https://doi.org/10.21437/Interspeech.2019-2351", 5, "interspeech", 2019], ["SPIRE-fluent: A Self-Learning App for Tutoring Oral Fluency to Second Language English Learners", ["Chiranjeevi Yarra", "Aparna Srinivasan", "Sravani Gottimukkala", "Prasanta Kumar Ghosh"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8008.html", 2, "interspeech", 2019], ["Whisper to Neutral Mapping Using Cosine Similarity Maximization in i-Vector Space for Speaker Verification", ["Abinay Reddy Naini", "Achuth Rao M. V", "Prasanta Kumar Ghosh"], "https://doi.org/10.21437/Interspeech.2019-2280", 5, "interspeech", 2019], ["Comparison of Speech Tasks and Recording Devices for Voice Based Automatic Classification of Healthy Subjects and Patients with Amyotrophic Lateral Sclerosis", ["Suhas B. N.", "Deep Patel", "Nithin Rao Koluguri", "Yamini Belur", "Pradeep Reddy", "Atchayaram Nalini", "Ravi Yadav", "Dipanjan Gope", "Prasanta Kumar Ghosh"], "https://doi.org/10.21437/Interspeech.2019-1285", 5, "interspeech", 2019]], "Steffen Illium": [0, ["Deep Neural Baselines for Computational Paralinguistics", ["Daniel Elsner", "Stefan Langer", "Fabian Ritz", "Robert Muller", "Steffen Illium"], "https://doi.org/10.21437/Interspeech.2019-2478", 5, "interspeech", 2019]], "Kong Aik Lee": [2.7774383966061578e-06, ["ASVspoof 2019: Future Horizons in Spoofed and Fake Audio Detection", ["Massimiliano Todisco", "Xin Wang", "Ville Vestman", "Md. Sahidullah", "Hector Delgado", "Andreas Nautsch", "Junichi Yamagishi", "Nicholas W. D. Evans", "Tomi H. Kinnunen", "Kong Aik Lee"], "https://doi.org/10.21437/Interspeech.2019-2249", 5, "interspeech", 2019]], "Judith Gaspers": [0, ["Neural Named Entity Recognition from Subword Units", ["Abdalghani Abujabal", "Judith Gaspers"], "https://doi.org/10.21437/Interspeech.2019-1305", 5, "interspeech", 2019]], "Robert Fuchs": [0, ["The Monophthongs of Formal Nigerian English: An Acoustic Analysis", ["Nisad Jamakovic", "Robert Fuchs"], "https://doi.org/10.21437/Interspeech.2019-2866", 5, "interspeech", 2019]], "Quoc V. Le": [0, ["SpecAugment: A Simple Data Augmentation Method for Automatic Speech Recognition", ["Daniel S. Park", "William Chan", "Yu Zhang", "Chung-Cheng Chiu", "Barret Zoph", "Ekin D. Cubuk", "Quoc V. Le"], "https://doi.org/10.21437/Interspeech.2019-2680", 5, "interspeech", 2019]], "Ilya Oparin": [0, ["Connecting and Comparing Language Model Interpolation Techniques", ["Ernest Pusateri", "Christophe Van Gysel", "Rami Botros", "Sameer Badaskar", "Mirko Hannemann", "Youssef Oualil", "Ilya Oparin"], "https://doi.org/10.21437/Interspeech.2019-1822", 5, "interspeech", 2019]], "Min Tang": [0, ["Hybrid Arbitration Using Raw ASR String and NLU Information - Taking the Best of Both Embedded World and Cloud World", ["Min Tang"], "https://doi.org/10.21437/Interspeech.2019-2586", 5, "interspeech", 2019]], "Pavel A. Skrelin": [0, ["Prosodic Factors Influencing Vowel Reduction in Russian", ["Daniil Kocharov", "Tatiana Kachkovskaia", "Pavel A. Skrelin"], "https://doi.org/10.21437/Interspeech.2019-2918", 5, "interspeech", 2019]], "Alexandros Lazaridis": [0, ["Self-Attention for Speech Emotion Recognition", ["Lorenzo Tarantino", "Philip N. Garner", "Alexandros Lazaridis"], "https://doi.org/10.21437/Interspeech.2019-2822", 5, "interspeech", 2019]], "Jeesun Kim": [0.9742622375488281, ["Perceiving Older Adults Producing Clear and Lombard Speech", ["Chris Davis", "Jeesun Kim"], "https://doi.org/10.21437/Interspeech.2019-2210", 5, "interspeech", 2019]], "Dinesh Manocha": [0, ["Regression and Classification for Direction-of-Arrival Estimation with Convolutional Recurrent Neural Networks", ["Zhenyu Tang", "John D. Kanu", "Kevin Hogan", "Dinesh Manocha"], "https://doi.org/10.21437/Interspeech.2019-1111", 5, "interspeech", 2019]], "Alexander Rakowski": [0, ["Robust Bayesian and Light Neural Networks for Voice Spoofing Detection", ["Radoslaw Bialobrzeski", "Michal Kosmider", "Mateusz Matuszewski", "Marcin Plata", "Alexander Rakowski"], "https://doi.org/10.21437/Interspeech.2019-2676", 5, "interspeech", 2019]], "Lior Wolf": [0, ["Unsupervised Singing Voice Conversion", ["Eliya Nachmani", "Lior Wolf"], "https://doi.org/10.21437/Interspeech.2019-1761", 5, "interspeech", 2019]], "Yves Laprie": [0, ["Towards a Method of Dynamic Vocal Tract Shapes Generation by Combining Static 3D and Dynamic 2D MRI Speech Data", ["Ioannis K. Douros", "Anastasiia Tsukanova", "Karyna Isaieva", "Pierre-Andre Vuissoz", "Yves Laprie"], "https://doi.org/10.21437/Interspeech.2019-2880", 5, "interspeech", 2019]], "Jan Vanek": [0, ["UWB-NTIS Speaker Diarization System for the DIHARD II 2019 Challenge", ["Zbynek Zajic", "Marie Kunesova", "Marek Hruz", "Jan Vanek"], "https://doi.org/10.21437/Interspeech.2019-1385", 5, "interspeech", 2019]], "Yuichi Kageyama": [0, ["GPU-Based WFST Decoding with Extra Large Language Model", ["Daisuke Fukunaga", "Yoshiki Tanaka", "Yuichi Kageyama"], "https://doi.org/10.21437/Interspeech.2019-2101", 5, "interspeech", 2019]], "Franz Pernkopf": [0, ["Acoustic Scene Classification with Mismatched Devices Using CliqueNets and Mixup Data Augmentation", ["Truc Nguyen", "Franz Pernkopf"], "https://doi.org/10.21437/Interspeech.2019-3002", 5, "interspeech", 2019]], "Ann R. Bradlow": [0, ["Survey Talk: Recognition of Foreign-Accented Speech: Challenges and Opportunities for Human and Computer Speech Communication", ["Ann R. Bradlow"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/abs21.html", 0, "interspeech", 2019], ["Speaking Rate, Information Density, and Information Rate in First-Language and Second-Language Speech", ["Ann R. Bradlow"], "https://doi.org/10.21437/Interspeech.2019-1150", 5, "interspeech", 2019]], "Mate Akos Tundik": [0, ["Leveraging a Character, Word and Prosody Triplet for an ASR Error Robust and Agglutination Friendly Punctuation Approach", ["Gyorgy Szaszak", "Mate Akos Tundik"], "https://doi.org/10.21437/Interspeech.2019-2132", 5, "interspeech", 2019]], "Jer-Ming Chen": [0, ["Analyzing Intra-Speaker and Inter-Speaker Vocal Tract Impedance Characteristics in a Low-Dimensional Feature Space Using t-SNE", ["Balamurali B. T.", "Jer-Ming Chen"], "https://doi.org/10.21437/Interspeech.2019-1492", 4, "interspeech", 2019]], "Tetsunori Kobayashi": [0, ["Recognition of Intentions of Users' Short Responses for Conversational News Delivery System", ["Hiroaki Takatsu", "Katsuya Yokoyama", "Yoichi Matsuyama", "Hiroshi Honda", "Shinya Fujie", "Tetsunori Kobayashi"], "https://doi.org/10.21437/Interspeech.2019-2121", 5, "interspeech", 2019]], "Piero Pierucci": [0, ["Fusion Techniques for Utterance-Level Emotion Recognition Combining Speech and Transcripts", ["Jilt Sebastian", "Piero Pierucci"], "https://doi.org/10.21437/Interspeech.2019-3201", 5, "interspeech", 2019]], "Nicholas D. Lane": [0, ["ShrinkML: End-to-End ASR Model Compression Using Reinforcement Learning", ["Lukasz Dudziak", "Mohamed S. Abdelfattah", "Ravichander Vipperla", "Stefanos Laskaridis", "Nicholas D. Lane"], "https://doi.org/10.21437/Interspeech.2019-2811", 5, "interspeech", 2019]], "Rejisha T. M.": [0, ["Design and Development of a Multi-Lingual Speech Corpora (TaMaR-EmoDB) for Emotion Analysis", ["Rajeev Rajan", "Haritha U. G.", "Sujitha A. C.", "Rejisha T. M."], "https://doi.org/10.21437/Interspeech.2019-2034", 5, "interspeech", 2019]], "Ming Lei": [0, ["Audio Tagging with Compact Feedforward Sequential Memory Network and Audio-to-Audio Ratio Based Data Augmentation", ["Zhiying Huang", "Shiliang Zhang", "Ming Lei"], "https://doi.org/10.21437/Interspeech.2019-1302", 5, "interspeech", 2019]], "R. J. J. H. van Son": [4.967731911165174e-05, ["CNN-Based Phoneme Classifier from Vocal Tract MRI Learns Embedding Consistent with Articulatory Topology", ["K. G. van Leeuwen", "P. Bos", "Stefano Trebeschi", "Maarten J. A. van Alphen", "Luuk Voskuilen", "Ludi E. Smeele", "Ferdi van der Heijden", "R. J. J. H. van Son"], "https://doi.org/10.21437/Interspeech.2019-1173", 5, "interspeech", 2019]], "Sharon Peperkamp": [0, ["The Different Roles of Expectations in Phonetic and Lexical Processing", ["Shiri Lev-Ari", "Robin Dodsworth", "Jeff Mielke", "Sharon Peperkamp"], "https://doi.org/10.21437/Interspeech.2019-1795", 5, "interspeech", 2019]], "Margaret Zellers": [0, ["Prosodic Effects on Plosive Duration in German and Austrian German", ["Barbara Schuppler", "Margaret Zellers"], "https://doi.org/10.21437/Interspeech.2019-2197", 5, "interspeech", 2019], ["A Preliminary Study of Charismatic Speech on YouTube: Correlating Prosodic Variation with Counts of Subscribers, Views and Likes", ["Stephanie Berger", "Oliver Niebuhr", "Margaret Zellers"], "https://doi.org/10.21437/Interspeech.2019-1664", 5, "interspeech", 2019]], "Leonardo Brambilla": [0, ["EpaDB: A Database for Development of Pronunciation Assessment Systems", ["Jazmin Vidal", "Luciana Ferrer", "Leonardo Brambilla"], "https://doi.org/10.21437/Interspeech.2019-1839", 5, "interspeech", 2019]], "Kathleen Currie Hall": [0, ["SLP-AA: Tools for Sign Language Phonetic and Phonological Research", ["Roger Yu-Hsiang Lo", "Kathleen Currie Hall"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8028.html", 2, "interspeech", 2019]], "Yuki Mitsufuji": [0, ["Recursive Speech Separation for Unknown Number of Speakers", ["Naoya Takahashi", "Sudarsanam Parthasaarathy", "Nabarun Goswami", "Yuki Mitsufuji"], "https://doi.org/10.21437/Interspeech.2019-1550", 5, "interspeech", 2019]], "Chris Biemann": [0, ["SparseSpeech: Unsupervised Acoustic Unit Discovery with Memory-Augmented Sequence Autoencoders", ["Benjamin Milde", "Chris Biemann"], "https://doi.org/10.21437/Interspeech.2019-2938", 5, "interspeech", 2019]], "Khiet P. Truong": [0, ["An Acoustic and Lexical Analysis of Emotional Valence in Spontaneous Speech: Autobiographical Memory Recall in Older Adults", ["Deniece S. Nazareth", "Ellen Tournier", "Sarah Leimkotter", "Esther Janse", "Dirk Heylen", "Gerben J. Westerhof", "Khiet P. Truong"], "https://doi.org/10.21437/Interspeech.2019-1823", 5, "interspeech", 2019]], "Andrew Zisserman": [0, ["My Lips Are Concealed: Audio-Visual Speech Enhancement Through Obstructions", ["Triantafyllos Afouras", "Joon Son Chung", "Andrew Zisserman"], "https://doi.org/10.21437/Interspeech.2019-3114", 5, "interspeech", 2019]], "Barbara Schuppler": [0, ["Acoustic Correlates of Phonation Type in Chichimec", ["Anneliese Kelterer", "Barbara Schuppler"], "https://doi.org/10.21437/Interspeech.2019-2066", 5, "interspeech", 2019]], "Angel M. Gomez": [0, ["A Light Convolutional GRU-RNN Deep Feature Extractor for ASV Spoofing Detection", ["Alejandro Gomez Alanis", "Antonio M. Peinado", "Jose A. Gonzalez", "Angel M. Gomez"], "https://doi.org/10.21437/Interspeech.2019-2212", 5, "interspeech", 2019]], "Zhengqi Wen": [0, ["Learn Spelling from Teachers: Transferring Knowledge from Language Models to Sequence-to-Sequence Speech Recognition", ["Ye Bai", "Jiangyan Yi", "Jianhua Tao", "Zhengkun Tian", "Zhengqi Wen"], "https://doi.org/10.21437/Interspeech.2019-1554", 5, "interspeech", 2019], ["Self-Attention Transducers for End-to-End Speech Recognition", ["Zhengkun Tian", "Jiangyan Yi", "Jianhua Tao", "Ye Bai", "Zhengqi Wen"], "https://doi.org/10.21437/Interspeech.2019-2203", 5, "interspeech", 2019], ["Discriminative Learning for Monaural Speech Separation Using Deep Embedding Features", ["Cunhang Fan", "Bin Liu", "Jianhua Tao", "Jiangyan Yi", "Zhengqi Wen"], "https://doi.org/10.21437/Interspeech.2019-1940", 5, "interspeech", 2019]], "Mitchell McLaren": [0, ["Optimizing a Speaker Embedding Extractor Through Backend-Driven Regularization", ["Luciana Ferrer", "Mitchell McLaren"], "https://doi.org/10.21437/Interspeech.2019-1820", 5, "interspeech", 2019]], "Shih-Hau Fang": [0, ["Speaker-Aware Deep Denoising Autoencoder with Embedded Speaker Identity for Speech Enhancement", ["Fu-Kai Chuang", "Syu-Siang Wang", "Jeih-weih Hung", "Yu Tsao", "Shih-Hau Fang"], "https://doi.org/10.21437/Interspeech.2019-2108", 5, "interspeech", 2019]], "Clinton Fookes": [0, ["A Study of x-Vector Based Speaker Recognition on Short Utterances", ["Ahilan Kanagasundaram", "Sridha Sridharan", "Ganapathy Sriram", "S. Prachi", "Clinton Fookes"], "https://doi.org/10.21437/Interspeech.2019-1891", 5, "interspeech", 2019]], "Karen Livescu": [0, ["On the Contributions of Visual and Textual Supervision in Low-Resource Semantic Speech Retrieval", ["Ankita Pasad", "Bowen Shi", "Herman Kamper", "Karen Livescu"], "https://doi.org/10.21437/Interspeech.2019-3051", 5, "interspeech", 2019], ["Pre-Trained Text Embeddings for Enhanced Text-to-Speech Synthesis", ["Tomoki Hayashi", "Shinji Watanabe", "Tomoki Toda", "Kazuya Takeda", "Shubham Toshniwal", "Karen Livescu"], "https://doi.org/10.21437/Interspeech.2019-3177", 5, "interspeech", 2019]], "Katrin Kirchhoff": [0, ["Speech Audio Super-Resolution for Speech Recognition", ["Xinyu Li", "Venkata Chebiyyam", "Katrin Kirchhoff"], "https://doi.org/10.21437/Interspeech.2019-3043", 5, "interspeech", 2019], ["Multi-Stream Network with Temporal Attention for Environmental Sound Classification", ["Xinyu Li", "Venkata Chebiyyam", "Katrin Kirchhoff"], "https://doi.org/10.21437/Interspeech.2019-3019", 5, "interspeech", 2019]], "Pierre-Andre Vuissoz": [0, ["A Multimodal Real-Time MRI Articulatory Corpus of French for Speech Research", ["Ioannis K. Douros", "Jacques Felblinger", "Jens Frahm", "Karyna Isaieva", "Arun A. Joseph", "Yves Laprie", "Freddy Odille", "Anastasiia Tsukanova", "Dirk Voit", "Pierre-Andre Vuissoz"], "https://doi.org/10.21437/Interspeech.2019-1700", 5, "interspeech", 2019]], "Andrea Deme": [0, ["Articulatory Analysis of Transparent Vowel /i\u02d0/ in Harmonic and Antiharmonic Hungarian Stems: Is There a Difference?", ["Alexandra Marko", "Marton Bartok", "Tamas Gabor Csapo", "Tekla Etelka Graczi", "Andrea Deme"], "https://doi.org/10.21437/Interspeech.2019-2352", 5, "interspeech", 2019]], "Kareem Darwish": [0, ["FarSpeech: Arabic Natural Language Processing for Live Arabic Speech", ["Mohamed Eldesouki", "Naassih Gopee", "Ahmed Ali", "Kareem Darwish"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8030.html", 2, "interspeech", 2019]], "Eliathamby Ambikairajah": [0, ["Speech Based Emotion Prediction: Can a Linear Model Work?", ["Anda Ouyang", "Ting Dang", "Vidhyasaharan Sethu", "Eliathamby Ambikairajah"], "https://doi.org/10.21437/Interspeech.2019-3149", 5, "interspeech", 2019]], "Mark J. F. Gales": [0, ["A Deep Learning Approach to Automatic Characterisation of Rhythm in Non-Native English Speech", ["Konstantinos Kyriakopoulos", "Kate M. Knill", "Mark J. F. Gales"], "https://doi.org/10.21437/Interspeech.2019-3186", 5, "interspeech", 2019]], "Kaylah Lalonde": [0, ["Effects of Natural Variability in Cross-Modal Temporal Correlations on Audiovisual Speech Recognition Benefit", ["Kaylah Lalonde"], "https://doi.org/10.21437/Interspeech.2019-2931", 5, "interspeech", 2019]], "Anil Kumar Vuppala": [0, ["IIIT-H Spoofing Countermeasures for Automatic Speaker Verification Spoofing and Countermeasures Challenge 2019", ["K. N. R. K. Raju Alluri", "Anil Kumar Vuppala"], "https://doi.org/10.21437/Interspeech.2019-1623", 5, "interspeech", 2019], ["Sound Privacy: A Conversational Speech Corpus for Quantifying the Experience of Privacy", ["Pablo Perez Zarazaga", "Sneha Das", "Tom Backstrom", "Vishnu Vidyadhara Raju Vegesna", "Anil Kumar Vuppala"], "https://doi.org/10.21437/Interspeech.2019-1172", 5, "interspeech", 2019]], "Jae-Min Kim": [0.9150348603725433, ["Probability Density Distillation with Generative Adversarial Networks for High-Quality Parallel Waveform Generation", ["Ryuichi Yamamoto", "Eunwoo Song", "Jae-Min Kim"], "https://doi.org/10.21437/Interspeech.2019-1965", 5, "interspeech", 2019]], "Stefan Wermter": [0, ["Predictive Auxiliary Variational Autoencoder for Representation Learning of Global Speech Characteristics", ["Sebastian Springenberg", "Egor Lakomkin", "Cornelius Weber", "Stefan Wermter"], "https://doi.org/10.21437/Interspeech.2019-2845", 5, "interspeech", 2019], ["LipSound: Neural Mel-Spectrogram Reconstruction for Lip Reading", ["Leyuan Qu", "Cornelius Weber", "Stefan Wermter"], "https://doi.org/10.21437/Interspeech.2019-1393", 5, "interspeech", 2019]], "Jesper Jensen": [0, ["Keyword Spotting for Hearing Assistive Devices Robust to External Speakers", ["Ivan Lopez-Espejo", "Zheng-Hua Tan", "Jesper Jensen"], "https://doi.org/10.21437/Interspeech.2019-2010", 5, "interspeech", 2019]], "Hongxia Jin": [1.1710628397988004e-12, ["Rare Sound Event Detection Using Deep Learning and Data Augmentation", ["Yanping Chen", "Hongxia Jin"], "https://doi.org/10.21437/Interspeech.2019-1985", 5, "interspeech", 2019], ["Iterative Delexicalization for Improved Spoken Language Understanding", ["Avik Ray", "Yilin Shen", "Hongxia Jin"], "https://doi.org/10.21437/Interspeech.2019-2955", 5, "interspeech", 2019], ["Interpreting and Improving Deep Neural SLU Models via Vocabulary Importance", ["Yilin Shen", "Wenhu Chen", "Hongxia Jin"], "https://doi.org/10.21437/Interspeech.2019-3184", 5, "interspeech", 2019]], "Shakti P. Rath": [0, ["Far-Field Speech Enhancement Using Heteroscedastic Autoencoder for Improved Speech Recognition", ["Shashi Kumar", "Shakti P. Rath"], "https://doi.org/10.21437/Interspeech.2019-2032", 5, "interspeech", 2019], ["A Multi-Accent Acoustic Model Using Mixture of Experts for Speech Recognition", ["Abhinav Jain", "Vishwanath P. Singh", "Shakti P. Rath"], "https://doi.org/10.21437/Interspeech.2019-1667", 5, "interspeech", 2019]], "Bernd Mobius": [0, ["Three's a Crowd? Effects of a Second Human on Vocal Accommodation with a Voice Assistant", ["Eran Raveh", "Ingo Siegert", "Ingmar Steiner", "Iona Gessinger", "Bernd Mobius"], "https://doi.org/10.21437/Interspeech.2019-1825", 5, "interspeech", 2019]], "Laszlo Toth": [0, ["Calibrating DNN Posterior Probability Estimates of HMM/DNN Models to Improve Social Signal Detection from Audio Data", ["Gabor Gosztolya", "Laszlo Toth"], "https://doi.org/10.21437/Interspeech.2019-2552", 5, "interspeech", 2019]], "Suryakanth V. Gangashetty": [0, ["Excitation Source and Vocal Tract System Based Acoustic Features for Detection of Nasals in Continuous Speech", ["Bhanu Teja Nellore", "Sri Harsha Dumpala", "Karan Nathwani", "Suryakanth V. Gangashetty"], "https://doi.org/10.21437/Interspeech.2019-2785", 5, "interspeech", 2019]], "Sungjoo Ha": [0.9988091886043549, ["Temporal Convolution for Real-Time Keyword Spotting on Mobile Devices", ["Seungwoo Choi", "Seokjun Seo", "Beomjun Shin", "Hyeongmin Byun", "Martin Kersner", "Beomsu Kim", "Dongyoung Kim", "Sungjoo Ha"], "https://doi.org/10.21437/Interspeech.2019-1363", 5, "interspeech", 2019]], "Jan Chorowski": [0, ["Lattice Generation in Attention-Based Speech Recognition Models", ["Michal Zapotoczny", "Piotr Pietrzak", "Adrian Lancucki", "Jan Chorowski"], "https://doi.org/10.21437/Interspeech.2019-2667", 5, "interspeech", 2019]], "Laurent Besacier": [0, ["Empirical Evaluation of Sequence-to-Sequence Models for Word Discovery in Low-Resource Settings", ["Marcely Zanon Boito", "Aline Villavicencio", "Laurent Besacier"], "https://doi.org/10.21437/Interspeech.2019-2029", 5, "interspeech", 2019]], "Jens Edlund": [0, ["How to Annotate 100 Hours in 45 Minutes", ["Per Fallgren", "Zofia Malisz", "Jens Edlund"], "https://doi.org/10.21437/Interspeech.2019-1648", 5, "interspeech", 2019]], "Yonghua Lin": [0, ["Few-Shot Audio Classification with Attentional Graph Neural Networks", ["Shilei Zhang", "Yong Qin", "Kewei Sun", "Yonghua Lin"], "https://doi.org/10.21437/Interspeech.2019-1532", 5, "interspeech", 2019]], "Lenhart K. Schubert": [0, ["Investigating Linguistic and Semantic Features for Turn-Taking Prediction in Open-Domain Human-Computer Conversation", ["Seyedeh Zahra Razavi", "Benjamin Kane", "Lenhart K. Schubert"], "https://doi.org/10.21437/Interspeech.2019-3152", 5, "interspeech", 2019]], "Andreas Wendemuth": [0, ["Employing Bottleneck and Convolutional Features for Speech-Based Physical Load Detection on Limited Data Amounts", ["Olga Egorow", "Tarik Mrech", "Norman Weisskirchen", "Andreas Wendemuth"], "https://doi.org/10.21437/Interspeech.2019-2502", 5, "interspeech", 2019]], "Mickael Rouvier": [0, ["On Robustness of Unsupervised Domain Adaptation for Speaker Recognition", ["Pierre-Michel Bousquet", "Mickael Rouvier"], "https://doi.org/10.21437/Interspeech.2019-1524", 5, "interspeech", 2019]], "Gerald Penn": [0, ["Extracting Mel-Frequency and Bark-Frequency Cepstral Coefficients from Encrypted Signals", ["Patricia Thaine", "Gerald Penn"], "https://doi.org/10.21437/Interspeech.2019-1136", 5, "interspeech", 2019]], "Reiko Mazuka": [0, ["Nasal Consonant Discrimination in Infant- and Adult-Directed Speech", ["Bogdan Ludusan", "Annett Jorschick", "Reiko Mazuka"], "https://doi.org/10.21437/Interspeech.2019-1737", 5, "interspeech", 2019]], "Mei-Yuh Hwang": [0.0003176184036419727, ["A Novel Method to Correct Steering Vectors in MVDR Beamformer for Noise Robust ASR", ["Suliang Bu", "Yunxin Zhao", "Mei-Yuh Hwang"], "https://doi.org/10.21437/Interspeech.2019-2944", 5, "interspeech", 2019]], "Gyorgy Szaszak": [0, ["Assessing the Semantic Space Bias Caused by ASR Error Propagation and its Effect on Spoken Document Summarization", ["Mate Akos Tundik", "Valer Kaszas", "Gyorgy Szaszak"], "https://doi.org/10.21437/Interspeech.2019-2154", 5, "interspeech", 2019]], "Takaaki Hori": [0, ["Joint Student-Teacher Learning for Audio-Visual Scene-Aware Dialog", ["Chiori Hori", "Anoop Cherian", "Tim K. Marks", "Takaaki Hori"], "https://doi.org/10.21437/Interspeech.2019-3143", 5, "interspeech", 2019]], "Keisuke Kinoshita": [0, ["Simultaneous Denoising and Dereverberation for Low-Latency Applications Using Frame-by-Frame Online Unified Convolutional Beamformer", ["Tomohiro Nakatani", "Keisuke Kinoshita"], "https://doi.org/10.21437/Interspeech.2019-1286", 5, "interspeech", 2019]], "Mirjam Ernestus": [0, ["ERP Signal Analysis with Temporal Resolution Using a Time Window Bank", ["Annika Nijveld", "Louis ten Bosch", "Mirjam Ernestus"], "https://doi.org/10.21437/Interspeech.2019-2729", 5, "interspeech", 2019], ["Language Learning Using Speech to Image Retrieval", ["Danny Merkx", "Stefan L. Frank", "Mirjam Ernestus"], "https://doi.org/10.21437/Interspeech.2019-3067", 5, "interspeech", 2019], ["Listening with Great Expectations: An Investigation of Word Form Anticipations in Naturalistic Speech", ["M. Bentum", "Louis ten Bosch", "Antal van den Bosch", "Mirjam Ernestus"], "https://doi.org/10.21437/Interspeech.2019-2741", 5, "interspeech", 2019], ["Quantifying Expectation Modulation in Human Speech Processing", ["M. Bentum", "Louis ten Bosch", "Antal van den Bosch", "Mirjam Ernestus"], "https://doi.org/10.21437/Interspeech.2019-2685", 5, "interspeech", 2019]], "Korin Richmond": [0, ["Analysis of Pronunciation Learning in End-to-End Speech Synthesis", ["Jason Taylor", "Korin Richmond"], "https://doi.org/10.21437/Interspeech.2019-2830", 5, "interspeech", 2019]], "Noboru Miyazaki": [0, ["Evaluating Intention Communication by TTS Using Explicit Definitions of Illocutionary Act Performance", ["Nobukatsu Hojo", "Noboru Miyazaki"], "https://doi.org/10.21437/Interspeech.2019-2188", 5, "interspeech", 2019]], "Lara Keshishian": [0, ["The Voicing Contrast in Stops and Affricates in the Western Armenian of Lebanon", ["Niamh E. Kelly", "Lara Keshishian"], "https://doi.org/10.21437/Interspeech.2019-2529", 5, "interspeech", 2019]], "Shiliang Pu": [0, ["An End-to-End Audio Classification System Based on Raw Waveforms and Mix-Training Strategy", ["Jiaxu Chen", "Jing Hao", "Kai Chen", "Di Xie", "Shicai Yang", "Shiliang Pu"], "https://doi.org/10.21437/Interspeech.2019-1579", 5, "interspeech", 2019]], "Tie-Yan Liu": [0, ["Token-Level Ensemble Distillation for Grapheme-to-Phoneme Conversion", ["Hao Sun", "Xu Tan", "Jun-Wei Gan", "Hongzhi Liu", "Sheng Zhao", "Tao Qin", "Tie-Yan Liu"], "https://doi.org/10.21437/Interspeech.2019-1208", 5, "interspeech", 2019]], "Tan Lee": [0.0017472112085670233, ["Improving Unsupervised Subword Modeling via Disentangled Speech Representation Learning and Transformation", ["Siyuan Feng", "Tan Lee"], "https://doi.org/10.21437/Interspeech.2019-1338", 5, "interspeech", 2019], ["Deep Learning of Segment-Level Feature Representation with Multiple Instance Learning for Utterance-Level Speech Emotion Recognition", ["Shuiyang Mao", "P. C. Ching", "Tan Lee"], "https://doi.org/10.21437/Interspeech.2019-1968", 5, "interspeech", 2019], ["Child Speech Disorder Detection with Siamese Recurrent Network Using Speech Attribute Features", ["Jiarui Wang", "Ying Qin", "Zhiyuan Peng", "Tan Lee"], "https://doi.org/10.21437/Interspeech.2019-2320", 5, "interspeech", 2019]], "Zhiqiang Huang": [0, ["A Mandarin Prosodic Boundary Prediction Model Based on Multi-Task Learning", ["Huashan Pan", "Xiulin Li", "Zhiqiang Huang"], "https://doi.org/10.21437/Interspeech.2019-1400", 4, "interspeech", 2019]], "Ondrej Glembek": [0, ["Analysis of BUT Submission in Far-Field Scenarios of VOiCES 2019 Challenge", ["Pavel Matejka", "Oldrich Plchot", "Hossein Zeinali", "Ladislav Mosner", "Anna Silnova", "Lukas Burget", "Ondrej Novotny", "Ondrej Glembek"], "https://doi.org/10.21437/Interspeech.2019-2471", 5, "interspeech", 2019], ["Analysis of BUT Submission in Far-Field Scenarios of VOiCES 2019 Challenge", ["Pavel Matejka", "Oldrich Plchot", "Hossein Zeinali", "Ladislav Mosner", "Anna Silnova", "Lukas Burget", "Ondrej Novotny", "Ondrej Glembek"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/abs16.html", 0, "interspeech", 2019]], "Sidney S. Fels": [0, ["SPEAK YOUR MIND! Towards Imagined Speech Recognition with Hierarchical Deep Learning", ["Pramit Saha", "Muhammad Abdul-Mageed", "Sidney S. Fels"], "https://doi.org/10.21437/Interspeech.2019-3041", 5, "interspeech", 2019], ["An Extended Two-Dimensional Vocal Tract Model for Fast Acoustic Simulation of Single-Axis Symmetric Three-Dimensional Tubes", ["Debasish Ray Mohapatra", "Victor Zappi", "Sidney S. Fels"], "https://doi.org/10.21437/Interspeech.2019-1764", 5, "interspeech", 2019]], "Fang Hu": [0, ["Vowels and Diphthongs in the Xupu Xiang Chinese Dialect", ["Zhenrui Zhang", "Fang Hu"], "https://doi.org/10.21437/Interspeech.2019-1174", 5, "interspeech", 2019]], "Gianni Fenu": [0, ["Adversarial Optimization for Dictionary Attacks on Speaker Verification", ["Mirko Marras", "Pawel Korus", "Nasir D. Memon", "Gianni Fenu"], "https://doi.org/10.21437/Interspeech.2019-2430", 5, "interspeech", 2019]], "Elmar Noth": [0, ["Phonet: A Tool Based on Gated Recurrent Neural Networks to Extract Phonological Posteriors from Speech", ["Juan Camilo Vasquez-Correa", "Philipp Klumpp", "Juan Rafael Orozco-Arroyave", "Elmar Noth"], "https://doi.org/10.21437/Interspeech.2019-1405", 5, "interspeech", 2019], ["Apkinson: A Mobile Solution for Multimodal Assessment of Patients with Parkinson's Disease", ["Juan Camilo Vasquez-Correa", "Tomas Arias-Vergara", "Philipp Klumpp", "M. Strauss", "Arne Kuderle", "Nils Roth", "S. Bayerl", "Nicanor Garcia-Ospina", "Paula Andrea Perez-Toro", "L. Felipe Parra-Gallego", "Cristian David Rios-Urrego", "D. Escobar-Grisales", "Juan Rafael Orozco-Arroyave", "Bjorn Eskofier", "Elmar Noth"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8003.html", 2, "interspeech", 2019], ["Feature Representation of Pathophysiology of Parkinsonian Dysarthria", ["Alice Rueda", "Juan Camilo Vasquez-Correa", "Cristian David Rios-Urrego", "Juan Rafael Orozco-Arroyave", "Sridhar Krishnan", "Elmar Noth"], "https://doi.org/10.21437/Interspeech.2019-2490", 5, "interspeech", 2019], ["Feature Space Visualization with Spatial Similarity Maps for Pathological Speech Data", ["Philipp Klumpp", "Juan Camilo Vasquez-Correa", "Tino Haderlein", "Elmar Noth"], "https://doi.org/10.21437/Interspeech.2019-2080", 5, "interspeech", 2019], ["Phone-Attribute Posteriors to Evaluate the Speech of Cochlear Implant Users", ["Tomas Arias-Vergara", "Juan Rafael Orozco-Arroyave", "Milos Cernak", "Sandra Gollwitzer", "Maria Schuster", "Elmar Noth"], "https://doi.org/10.21437/Interspeech.2019-2144", 5, "interspeech", 2019], ["Deep Learning for Orca Call Type Identification - A Fully Unsupervised Approach", ["Christian Bergler", "Manuel Schmitt", "Rachael Xi Cheng", "Andreas K. Maier", "Volker Barth", "Elmar Noth"], "https://doi.org/10.21437/Interspeech.2019-1857", 5, "interspeech", 2019]], "Aijun Li": [0, ["CNN-BLSTM Based Question Detection from Dialogs Considering Phase and Context Information", ["Yuke Si", "Longbiao Wang", "Jianwu Dang", "Mengfei Wu", "Aijun Li"], "https://doi.org/10.21437/Interspeech.2019-1701", 5, "interspeech", 2019]], "Mounya Elhilali": [0, ["A Study of a Cross-Language Perception Based on Cortical Analysis Using Biomimetic STRFs", ["Sangwook Park", "David K. Han", "Mounya Elhilali"], "https://doi.org/10.21437/Interspeech.2019-2507", 5, "interspeech", 2019]], "Martin Jansche": [0, ["Cross-Lingual Consistency of Phonological Features: An Empirical Study", ["Cibu Johny", "Alexander Gutkin", "Martin Jansche"], "https://doi.org/10.21437/Interspeech.2019-2184", 5, "interspeech", 2019]], "Deb Roy": [0, ["RadioTalk: A Large-Scale Corpus of Talk Radio Transcripts", ["Doug Beeferman", "William Brannon", "Deb Roy"], "https://doi.org/10.21437/Interspeech.2019-2714", 5, "interspeech", 2019]], "Daniel Fogerty": [0, ["Improvement and Assessment of Spectro-Temporal Modulation Analysis for Speech Intelligibility Estimation", ["Amin Edraki", "Wai-Yip Chan", "Jesper Jensen", "Daniel Fogerty"], "https://doi.org/10.21437/Interspeech.2019-2898", 5, "interspeech", 2019]], "Raouf Hamzaoui": [0, ["Two-Dimensional Convolutional Recurrent Neural Networks for Speech Activity Detection", ["Anastasios Vafeiadis", "Eleftherios Fanioudakis", "Ilyas Potamitis", "Konstantinos Votis", "Dimitrios Giakoumis", "Dimitrios Tzovaras", "Liming Chen", "Raouf Hamzaoui"], "https://doi.org/10.21437/Interspeech.2019-1354", 5, "interspeech", 2019]], "Takao Kobayashi": [0, ["Semi-Supervised Prosody Modeling Using Deep Gaussian Process Latent Variable Model", ["Tomoki Koriyama", "Takao Kobayashi"], "https://doi.org/10.21437/Interspeech.2019-2497", 5, "interspeech", 2019]], "Khazar Khorrami": [0, ["A Computational Model of Early Language Acquisition from Audiovisual Experiences of Young Infants", ["Okko Rasanen", "Khazar Khorrami"], "https://doi.org/10.21437/Interspeech.2019-1523", 5, "interspeech", 2019]], "Joakim Gustafson": [0, ["Off the Cuff: Exploring Extemporaneous Speech Delivery with TTS", ["Eva Szekely", "Gustav Eje Henter", "Jonas Beskow", "Joakim Gustafson"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8026.html", 2, "interspeech", 2019], ["Spontaneous Conversational Speech Synthesis from Found Data", ["Eva Szekely", "Gustav Eje Henter", "Jonas Beskow", "Joakim Gustafson"], "https://doi.org/10.21437/Interspeech.2019-2836", 5, "interspeech", 2019]], "Thomas F. Quatieri": [0, ["Assessing Neuromotor Coordination in Depression Using Inverted Vocal Tract Variables", ["Carol Y. Espy-Wilson", "Adam C. Lammert", "Nadee Seneviratne", "Thomas F. Quatieri"], "https://doi.org/10.21437/Interspeech.2019-1815", 5, "interspeech", 2019], ["Vocal Biomarker Assessment Following Pediatric Traumatic Brain Injury: A Retrospective Cohort Study", ["Camille Noufi", "Adam C. Lammert", "Daryush D. Mehta", "James R. Williamson", "Gregory Ciccarelli", "Douglas E. Sturim", "Jordan R. Green", "Thomas F. Campbell", "Thomas F. Quatieri"], "https://doi.org/10.21437/Interspeech.2019-1200", 5, "interspeech", 2019]], "Mirella Lapata": [0, ["Learning Natural Language Interfaces with Neural Models", ["Mirella Lapata"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/abs23.html", 0, "interspeech", 2019]], "Alfred Mertins": [0, ["Spatio-Temporal Attention Pooling for Audio Scene Classification", ["Huy Phan", "Oliver Y. Chen", "Lam Pham", "Philipp Koch", "Maarten De Vos", "Ian Vince McLoughlin", "Alfred Mertins"], "https://doi.org/10.21437/Interspeech.2019-3040", 5, "interspeech", 2019]], "Akihiko Sugiyama": [0, ["Simultaneous Detection and Localization of a Wake-Up Word Using Multi-Task Learning of the Duration and Endpoint", ["Takashi Maekaku", "Yusuke Kida", "Akihiko Sugiyama"], "https://doi.org/10.21437/Interspeech.2019-1180", 5, "interspeech", 2019]], "Ignacio Lopez-Moreno": [0, ["VoiceFilter: Targeted Voice Separation by Speaker-Conditioned Spectrogram Masking", ["Quan Wang", "Hannah Muckenhirn", "Kevin W. Wilson", "Prashant Sridhar", "Zelin Wu", "John R. Hershey", "Rif A. Saurous", "Ron J. Weiss", "Ye Jia", "Ignacio Lopez-Moreno"], "https://doi.org/10.21437/Interspeech.2019-1101", 5, "interspeech", 2019]], "Emmanuel Dupoux": [0, ["The Zero Resource Speech Challenge 2019: TTS Without T", ["Ewan Dunbar", "Robin Algayres", "Julien Karadayi", "Mathieu Bernard", "Juan Benjumea", "Xuan-Nga Cao", "Lucie Miskic", "Charlotte Dugrain", "Lucas Ondel", "Alan W. Black", "Laurent Besacier", "Sakriani Sakti", "Emmanuel Dupoux"], "https://doi.org/10.21437/Interspeech.2019-2904", 5, "interspeech", 2019]], "Brian Mak": [0, ["Mixup Learning Strategies for Text-Independent Speaker Verification", ["Yingke Zhu", "Tom Ko", "Brian Mak"], "https://doi.org/10.21437/Interspeech.2019-2250", 5, "interspeech", 2019]], "Hisashi Kawai": [0, ["One-Pass Single-Channel Noisy Speech Recognition Using a Combination of Noisy and Enhanced Features", ["Masakiyo Fujimoto", "Hisashi Kawai"], "https://doi.org/10.21437/Interspeech.2019-1270", 5, "interspeech", 2019], ["Real-Time Neural Text-to-Speech with Sequence-to-Sequence Acoustic Model and WaveGlow or Single Gaussian WaveRNN Vocoders", ["Takuma Okamoto", "Tomoki Toda", "Yoshinori Shiga", "Hisashi Kawai"], "https://doi.org/10.21437/Interspeech.2019-1288", 5, "interspeech", 2019], ["End-to-End Articulatory Attribute Modeling for Low-Resource Multilingual Speech Recognition", ["Sheng Li", "Chenchen Ding", "Xugang Lu", "Peng Shen", "Tatsuya Kawahara", "Hisashi Kawai"], "https://doi.org/10.21437/Interspeech.2019-2092", 5, "interspeech", 2019], ["Investigating Radical-Based End-to-End Speech Recognition Systems for Chinese Dialects and Japanese", ["Sheng Li", "Xugang Lu", "Chenchen Ding", "Peng Shen", "Tatsuya Kawahara", "Hisashi Kawai"], "https://doi.org/10.21437/Interspeech.2019-2104", 5, "interspeech", 2019], ["Incorporating Symbolic Sequential Modeling for Speech Enhancement", ["Chien-Feng Liao", "Yu Tsao", "Xugang Lu", "Hisashi Kawai"], "https://doi.org/10.21437/Interspeech.2019-1777", 5, "interspeech", 2019], ["Class-Wise Centroid Distance Metric Learning for Acoustic Event Detection", ["Xugang Lu", "Peng Shen", "Sheng Li", "Yu Tsao", "Hisashi Kawai"], "https://doi.org/10.21437/Interspeech.2019-2271", 5, "interspeech", 2019], ["Improving Transformer-Based Speech Recognition Systems with Compressed Structure and Speech Attributes Augmentation", ["Sheng Li", "Dabre Raj", "Xugang Lu", "Peng Shen", "Tatsuya Kawahara", "Hisashi Kawai"], "https://doi.org/10.21437/Interspeech.2019-2112", 5, "interspeech", 2019], ["Duration Modeling with Global Phoneme-Duration Vectors", ["Jinfu Ni", "Yoshinori Shiga", "Hisashi Kawai"], "https://doi.org/10.21437/Interspeech.2019-2126", 5, "interspeech", 2019]], "Raj Karbar": [0, ["CaptionAI: A Real-Time Multilingual Captioning Application", ["Nagendra Kumar Goel", "Mousmita Sarma", "Saikiran Valluri", "Dharmeshkumar Agrawal", "Steve Braich", "Tejendra Singh Kuswah", "Zikra Iqbal", "Surbhi Chauhan", "Raj Karbar"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8039.html", 2, "interspeech", 2019]], "Yi-Wen Liu": [0, ["Acoustic Indicators of Deception in Mandarin Daily Conversations Recorded from an Interactive Game", ["Chih-Hsiang Huang", "Huang-Cheng Chou", "Yi-Tong Wu", "Chi-Chun Lee", "Yi-Wen Liu"], "https://doi.org/10.21437/Interspeech.2019-2216", 5, "interspeech", 2019]], "Koichi Shinoda": [0, ["The NEC-TT 2018 Speaker Verification System", ["Kong Aik Lee", "Hitoshi Yamamoto", "Koji Okabe", "Qiongqiong Wang", "Ling Guo", "Takafumi Koshinaka", "Jiacen Zhang", "Koichi Shinoda"], "https://doi.org/10.21437/Interspeech.2019-1517", 5, "interspeech", 2019], ["A Modified Algorithm for Multiple Input Spectrogram Inversion", ["Dongxiao Wang", "Hirokazu Kameoka", "Koichi Shinoda"], "https://doi.org/10.21437/Interspeech.2019-3242", 5, "interspeech", 2019]], "Gregor Hofer": [0, ["Analysis of Deep Learning Architectures for Cross-Corpus Speech Emotion Recognition", ["Jack Parry", "Dimitri Palaz", "Georgia Clarke", "Pauline Lecomte", "Rebecca Mead", "Michael Berger", "Gregor Hofer"], "https://doi.org/10.21437/Interspeech.2019-2753", 5, "interspeech", 2019]], "Jun Du": [0, ["Multi-Task Learning with High-Order Statistics for x-Vector Based Text-Independent Speaker Verification", ["Lanhua You", "Wu Guo", "Li-Rong Dai", "Jun Du"], "https://doi.org/10.21437/Interspeech.2019-2264", 5, "interspeech", 2019], ["Deep Neural Network Embeddings with Gating Mechanisms for Text-Independent Speaker Verification", ["Lanhua You", "Wu Guo", "Li-Rong Dai", "Jun Du"], "https://doi.org/10.21437/Interspeech.2019-1746", 5, "interspeech", 2019], ["Neural Text Clustering with Document-Level Attention Based on Dynamic Soft Labels", ["Zhi Chen", "Wu Guo", "Li-Rong Dai", "Zhen-Hua Ling", "Jun Du"], "https://doi.org/10.21437/Interspeech.2019-1417", 5, "interspeech", 2019]], "Chia-Ping Chen": [0, ["Transfer-Representation Learning for Detecting Spoofing Attacks with Converted and Synthesized Speech in Automatic Speaker Verification System", ["Su-Yu Chang", "Kai-Cheng Wu", "Chia-Ping Chen"], "https://doi.org/10.21437/Interspeech.2019-2014", 5, "interspeech", 2019]], "Mateusz Lajszczak": [0, ["Interpretable Deep Learning Model for the Detection and Reconstruction of Dysarthric Speech", ["Daniel Korzekwa", "Roberto Barra-Chicote", "Bozena Kostek", "Thomas Drugman", "Mateusz Lajszczak"], "https://doi.org/10.21437/Interspeech.2019-1206", 5, "interspeech", 2019]], "Daniel Duran": [0, ["Individual Differences in Implicit Attention to Phonetic Detail in Speech Perception", ["Natalie Lewandowski", "Daniel Duran"], "https://doi.org/10.21437/Interspeech.2019-2989", 5, "interspeech", 2019]], "Carlos Busso": [0, ["Speech Emotion Recognition with a Reject Option", ["Kusha Sridhar", "Carlos Busso"], "https://doi.org/10.21437/Interspeech.2019-1842", 5, "interspeech", 2019]], "Massimiliano Todisco": [0, ["I4U Submission to NIST SRE 2018: Leveraging from a Decade of Shared Experiences", ["Kong Aik Lee", "Ville Hautamaki", "Tomi H. Kinnunen", "Hitoshi Yamamoto", "Koji Okabe", "Ville Vestman", "Jing Huang", "Guohong Ding", "Hanwu Sun", "Anthony Larcher", "Rohan Kumar Das", "Haizhou Li", "Mickael Rouvier", "Pierre-Michel Bousquet", "Wei Rao", "Qing Wang", "Chunlei Zhang", "Fahimeh Bahmaninezhad", "Hector Delgado", "Massimiliano Todisco"], "https://doi.org/10.21437/Interspeech.2019-1533", 5, "interspeech", 2019]], "Maximilian Schmitt": [0, ["The INTERSPEECH 2019 Computational Paralinguistics Challenge: Styrian Dialects, Continuous Sleepiness, Baby Sounds & Orca Activity", ["Bjorn W. Schuller", "Anton Batliner", "Christian Bergler", "Florian B. Pokorny", "Jarek Krajewski", "Margaret Cychosz", "Ralf Vollmann", "Sonja-Dana Roelen", "Sebastian Schnieder", "Elika Bergelson", "Alejandrina Cristia", "Amanda Seidl", "Anne S. Warlaumont", "Lisa Yankowitz", "Elmar Noth", "Shahin Amiriparian", "Simone Hantke", "Maximilian Schmitt"], "https://doi.org/10.21437/Interspeech.2019-1122", 5, "interspeech", 2019]], "Petra Wagner": [0, ["Laughter Dynamics in Dyadic Conversations", ["Bogdan Ludusan", "Petra Wagner"], "https://doi.org/10.21437/Interspeech.2019-1733", 5, "interspeech", 2019], ["A User-Friendly and Adaptable Re-Implementation of an Acoustic Prominence Detection and Annotation Tool", ["Jana Vosse", "Petra Wagner"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8015.html", 2, "interspeech", 2019], ["The Greennn Tree - Lengthening Position Influences Uncertainty Perception", ["Simon Betz", "Sina Zarriess", "Eva Szekely", "Petra Wagner"], "https://doi.org/10.21437/Interspeech.2019-2572", 5, "interspeech", 2019]], "Brigitte Richardson": [0, ["Integrating Video Retrieval and Moment Detection in a Unified Corpus for Video Question Answering", ["Hongyin Luo", "Mitra Mohtarami", "James R. Glass", "Karthik Krishnamurthy", "Brigitte Richardson"], "https://doi.org/10.21437/Interspeech.2019-1736", 5, "interspeech", 2019]], "Francoise Beaufays": [0, ["An Investigation into On-Device Personalization of End-to-End Automatic Speech Recognition Models", ["Khe Chai Sim", "Petr Zadrazil", "Francoise Beaufays"], "https://doi.org/10.21437/Interspeech.2019-1752", 5, "interspeech", 2019]], "Nao Hodoshima": [0, ["Effects of Urgent Speech and Congruent/Incongruent Text on Speech Intelligibility in Noise and Reverberation", ["Nao Hodoshima"], "https://doi.org/10.21437/Interspeech.2019-1902", 5, "interspeech", 2019]], "Milos Cernak": [0, ["End-to-End Accented Speech Recognition", ["Thibault Viglino", "Petr Motlicek", "Milos Cernak"], "https://doi.org/10.21437/Interspeech.2019-2122", 5, "interspeech", 2019], ["Open-Vocabulary Keyword Spotting with Audio and Text Embeddings", ["Niccolo Sacchi", "Alexandre Nanchen", "Martin Jaggi", "Milos Cernak"], "https://doi.org/10.21437/Interspeech.2019-1846", 5, "interspeech", 2019]], "Shigeo Wada": [0, ["Individual Differences of Airflow and Sound Generation in the Vocal Tract of Sibilant /s/", ["Tsukasa Yoshinaga", "Kazunori Nozaki", "Shigeo Wada"], "https://doi.org/10.21437/Interspeech.2019-1376", 5, "interspeech", 2019]], "Sofia Cavaco": [0, ["Sustained Vowel Game: A Computer Therapy Game for Children with Dysphonia", ["Vanessa Lopes", "Joao Magalhaes", "Sofia Cavaco"], "https://doi.org/10.21437/Interspeech.2019-3017", 5, "interspeech", 2019]], "Jieping Ye": [4.120562024922947e-08, ["An Attention-Based Hybrid Network for Automatic Detection of Alzheimer's Disease from Narrative Speech", ["Jun Chen", "Ji Zhu", "Jieping Ye"], "https://doi.org/10.21437/Interspeech.2019-2872", 5, "interspeech", 2019]], "Chengqing Zong": [0, ["End-to-End Speech Translation with Knowledge Distillation", ["Yuchen Liu", "Hao Xiong", "Jiajun Zhang", "Zhongjun He", "Hua Wu", "Haifeng Wang", "Chengqing Zong"], "https://doi.org/10.21437/Interspeech.2019-2582", 5, "interspeech", 2019]], "Lei Xie": [0, ["Unsupervised Adaptation with Adversarial Dropout Regularization for Robust Speech Recognition", ["Pengcheng Guo", "Sining Sun", "Lei Xie"], "https://doi.org/10.21437/Interspeech.2019-2544", 5, "interspeech", 2019], ["A New GAN-Based End-to-End TTS Training Algorithm", ["Haohan Guo", "Frank K. Soong", "Lei He", "Lei Xie"], "https://doi.org/10.21437/Interspeech.2019-2176", 5, "interspeech", 2019], ["Towards Language-Universal Mandarin-English Speech Recognition", ["Shiliang Zhang", "Yuan Liu", "Ming Lei", "Bin Ma", "Lei Xie"], "https://doi.org/10.21437/Interspeech.2019-1365", 5, "interspeech", 2019], ["Exploiting Syntactic Features in a Parsed Tree to Improve End-to-End TTS", ["Haohan Guo", "Frank K. Soong", "Lei He", "Lei Xie"], "https://doi.org/10.21437/Interspeech.2019-2167", 5, "interspeech", 2019]], "Jennifer S. Cole": [0, ["Testing the Distinctiveness of Intonational Tunes: Evidence from Imitative Productions in American English", ["Eleanor Chodroff", "Jennifer S. Cole"], "https://doi.org/10.21437/Interspeech.2019-2684", 5, "interspeech", 2019], ["Perception of Pitch Contours in Speech and Nonspeech", ["Daniel R. Turner", "Ann R. Bradlow", "Jennifer S. Cole"], "https://doi.org/10.21437/Interspeech.2019-2619", 5, "interspeech", 2019]], "Jean-Pierre David": [0, ["Binary Speech Features for Keyword Spotting Tasks", ["Alexandre Riviello", "Jean-Pierre David"], "https://doi.org/10.21437/Interspeech.2019-1877", 5, "interspeech", 2019]], "Bettina Braun": [0, ["The Processing of Prosodic Cues to Rhetorical Question Interpretation: Psycholinguistic and Neurolinguistics Evidence", ["Mariya Kharaman", "Manluolan Xu", "Carsten Eulitz", "Bettina Braun"], "https://doi.org/10.21437/Interspeech.2019-2528", 5, "interspeech", 2019]], "Sri Garimella": [0, ["Multi-Dialect Acoustic Modeling Using Phone Mapping and Online i-Vectors", ["Harish Arsikere", "Ashtosh Sapru", "Sri Garimella"], "https://doi.org/10.21437/Interspeech.2019-2881", 5, "interspeech", 2019]], "Seungji Lee": [0.9998576194047928, ["Large-Scale Multilingual Speech Recognition with a Streaming End-to-End Model", ["Anjuli Kannan", "Arindrima Datta", "Tara N. Sainath", "Eugene Weinstein", "Bhuvana Ramabhadran", "Yonghui Wu", "Ankur Bapna", "Zhifeng Chen", "Seungji Lee"], "https://doi.org/10.21437/Interspeech.2019-2858", 5, "interspeech", 2019]], "Jianguo Wei": [0, ["Individual Difference of Relative Tongue Size and its Acoustic Effects", ["Xiaohan Zhang", "Chongke Bi", "Kiyoshi Honda", "Wenhuan Lu", "Jianguo Wei"], "https://doi.org/10.21437/Interspeech.2019-2452", 5, "interspeech", 2019]], "Alexandros Potamianos": [0, ["Unsupervised Low-Rank Representations for Speech Emotion Recognition", ["Georgios Paraskevopoulos", "Efthymios Tzinis", "Nikolaos Ellinas", "Theodoros Giannakopoulos", "Alexandros Potamianos"], "https://doi.org/10.21437/Interspeech.2019-2769", 5, "interspeech", 2019], ["Deep Hierarchical Fusion with Application in Sentiment Analysis", ["Efthymios Georgiou", "Charilaos Papaioannou", "Alexandros Potamianos"], "https://doi.org/10.21437/Interspeech.2019-3243", 5, "interspeech", 2019]], "Thomas Kisler": [0, ["BAS Web Services for Automatic Subtitle Creation and Anonymization", ["Florian Schiel", "Thomas Kisler"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8001.html", 2, "interspeech", 2019]], "Marianne Pouplier": [0, ["Zooming in on Spatiotemporal V-to-C Coarticulation with Functional PCA", ["Michele Gubian", "Manfred Pastatter", "Marianne Pouplier"], "https://doi.org/10.21437/Interspeech.2019-2143", 5, "interspeech", 2019]], "Zhizheng Wu": [1.3821066166541662e-10, ["Building a Mixed-Lingual Neural TTS System with Only Monolingual Data", ["Liumeng Xue", "Wei Song", "Guanghui Xu", "Lei Xie", "Zhizheng Wu"], "https://doi.org/10.21437/Interspeech.2019-3191", 5, "interspeech", 2019]], "Christian Poellabauer": [0, ["ReMASC: Realistic Replay Attack Corpus for Voice Controlled Systems", ["Yuan Gong", "Jian Yang", "Jacob Huber", "Mitchell MacKnight", "Christian Poellabauer"], "https://doi.org/10.21437/Interspeech.2019-1541", 5, "interspeech", 2019]], "Sandro Cumani": [0, ["Normal Variance-Mean Mixtures for Unsupervised Score Calibration", ["Sandro Cumani"], "https://doi.org/10.21437/Interspeech.2019-1609", 5, "interspeech", 2019]], "Min Liu": [0, ["Framewise Supervised Training Towards End-to-End Speech Recognition Models: First Results", ["Mohan Li", "Yuanjiang Cao", "Weicong Zhou", "Min Liu"], "https://doi.org/10.21437/Interspeech.2019-1117", 5, "interspeech", 2019]], "Jan Cernocky": [0, ["Bayesian Subspace Hidden Markov Model for Acoustic Unit Discovery", ["Lucas Ondel", "Hari Krishna Vydana", "Lukas Burget", "Jan Cernocky"], "https://doi.org/10.21437/Interspeech.2019-2224", 5, "interspeech", 2019], ["Bayesian HMM Based x-Vector Clustering for Speaker Diarization", ["Mireia Diez", "Lukas Burget", "Shuai Wang", "Johan Rohdin", "Jan Cernocky"], "https://doi.org/10.21437/Interspeech.2019-2813", 5, "interspeech", 2019], ["Detecting Spoofing Attacks Using VGG and SincNet: BUT-Omilia Submission to ASVspoof 2019 Challenge", ["Hossein Zeinali", "Themos Stafylakis", "Georgia Athanasopoulou", "Johan Rohdin", "Ioannis Gkinis", "Lukas Burget", "Jan Cernocky"], "https://doi.org/10.21437/Interspeech.2019-2892", 5, "interspeech", 2019], ["On the Usage of Phonetic Information for Text-Independent Speaker Embedding Extraction", ["Shuai Wang", "Johan Rohdin", "Lukas Burget", "Oldrich Plchot", "Yanmin Qian", "Kai Yu", "Jan Cernocky"], "https://doi.org/10.21437/Interspeech.2019-3036", 5, "interspeech", 2019], ["Analysis of Multilingual Sequence-to-Sequence Speech Recognition Systems", ["Martin Karafiat", "Murali Karthick Baskar", "Shinji Watanabe", "Takaaki Hori", "Matthew Wiesner", "Jan Cernocky"], "https://doi.org/10.21437/Interspeech.2019-2355", 5, "interspeech", 2019], ["Semi-Supervised Sequence-to-Sequence ASR Using Unpaired Speech and Text", ["Murali Karthick Baskar", "Shinji Watanabe", "Ramon Fernandez Astudillo", "Takaaki Hori", "Lukas Burget", "Jan Cernocky"], "https://doi.org/10.21437/Interspeech.2019-3167", 5, "interspeech", 2019]], "Shankar M. Venkatesan": [0, ["Real Time Online Visual End Point Detection Using Unidirectional LSTM", ["Tanay Sharma", "Rohith Chandrashekar Aralikatti", "Dilip Kumar Margam", "Abhinav Thanda", "Sharad Roy", "Pujitha Appan Kandala", "Shankar M. Venkatesan"], "https://doi.org/10.21437/Interspeech.2019-3253", 5, "interspeech", 2019], ["Speaker Adaptation for Lip-Reading Using Visual Identity Vectors", ["Pujitha Appan Kandala", "Abhinav Thanda", "Dilip Kumar Margam", "Rohith Chandrashekar Aralikatti", "Tanay Sharma", "Sharad Roy", "Shankar M. Venkatesan"], "https://doi.org/10.21437/Interspeech.2019-3237", 5, "interspeech", 2019]], "Tatsuya Komatsu": [0, ["Variational Bayesian Multi-Channel Speech Dereverberation Under Noisy Environments with Probabilistic Convolutive Transfer Function", ["Masahito Togami", "Tatsuya Komatsu"], "https://doi.org/10.21437/Interspeech.2019-1220", 5, "interspeech", 2019], ["Multichannel Loss Function for Supervised Speech Source Separation by Mask-Based Beamforming", ["Yoshiki Masuyama", "Masahito Togami", "Tatsuya Komatsu"], "https://doi.org/10.21437/Interspeech.2019-1289", 5, "interspeech", 2019]], "Emily Mower Provost": [0, ["Into the Wild: Transitioning from Recognizing Mood in Clinical Interactions to Personal Conversations for Individuals with Bipolar Disorder", ["Katie Matton", "Melvin G. McInnis", "Emily Mower Provost"], "https://doi.org/10.21437/Interspeech.2019-2698", 5, "interspeech", 2019], ["Identifying Mood Episodes Using Dialogue Features from Clinical Interviews", ["Zakaria Aldeneh", "Mimansa Jaiswal", "Michael Picheny", "Melvin G. McInnis", "Emily Mower Provost"], "https://doi.org/10.21437/Interspeech.2019-1878", 5, "interspeech", 2019], ["Emotion Recognition from Natural Phone Conversations in Individuals with and without Recent Suicidal Ideation", ["John Gideon", "Heather T. Schatten", "Melvin G. McInnis", "Emily Mower Provost"], "https://doi.org/10.21437/Interspeech.2019-1830", 5, "interspeech", 2019]], "Linda Taschenberger": [0, ["Subjective Evaluation of Communicative Effort for Younger and Older Adults in Interactive Tasks with Energetic and Informational Masking", ["Valerie Hazan", "Outi Tuomainen", "Linda Taschenberger"], "https://doi.org/10.21437/Interspeech.2019-2215", 5, "interspeech", 2019]], "Sam Tilsen": [0, ["Strength and Structure: Coupling Tones with Oral Constriction Gestures", ["Doris Mucke", "Anne Hermes", "Sam Tilsen"], "https://doi.org/10.21437/Interspeech.2019-2650", 5, "interspeech", 2019]], "David A. van Leeuwen": [0, ["Large-Scale Speaker Diarization of Radio Broadcast Archives", ["Emre Yilmaz", "Adem Derinel", "Kun Zhou", "Henk van den Heuvel", "Niko Brummer", "Haizhou Li", "David A. van Leeuwen"], "https://doi.org/10.21437/Interspeech.2019-1399", 5, "interspeech", 2019]], "Phil Hoole": [0, ["Assessing Acoustic and Articulatory Dimensions of Speech Motor Adaptation with Random Forests", ["Eugen Klein", "Jana Brunner", "Phil Hoole"], "https://doi.org/10.21437/Interspeech.2019-1812", 5, "interspeech", 2019]], "Carolin Schmid": [0, ["Sound Tools eXtended (STx) 5.0 - A Powerful Sound Analysis Tool Optimized for Speech", ["Anton Noll", "Jonathan Stuefer", "Nicola Klingler", "Hannah Leykum", "Carina Lozo", "Jan Luttenberger", "Michael Pucher", "Carolin Schmid"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8022.html", 2, "interspeech", 2019]], "Jerome R. Bellegarda": [0, ["Reverse Transfer Learning: Can Word Embeddings Trained for Different NLP Tasks Improve Neural Language Models?", ["Lyan Verwimp", "Jerome R. Bellegarda"], "https://doi.org/10.21437/Interspeech.2019-1332", 5, "interspeech", 2019]], "Michel-Pierre Jansen": [0, ["Towards an Annotation Scheme for Complex Laughter in Speech Corpora", ["Khiet P. Truong", "Jurgen Trouvain", "Michel-Pierre Jansen"], "https://doi.org/10.21437/Interspeech.2019-1557", 5, "interspeech", 2019]], "Patrick Violette": [0, ["Improving Keyword Spotting and Language Identification via Neural Architecture Search at Scale", ["Hanna Mazzawi", "Xavi Gonzalvo", "Aleks Kracun", "Prashant Sridhar", "Niranjan Subrahmanya", "Ignacio Lopez-Moreno", "Hyun-Jin Park", "Patrick Violette"], "https://doi.org/10.21437/Interspeech.2019-1916", 5, "interspeech", 2019]], "James D. Berry": [0, ["Use of Beiwe Smartphone App to Identify and Track Speech Decline in Amyotrophic Lateral Sclerosis (ALS)", ["Kathryn P. Connaghan", "Jordan R. Green", "Sabrina Paganoni", "James Chan", "Harli Weber", "Ella Collins", "Brian Richburg", "Marziye Eshghi", "Jukka-Pekka Onnela", "James D. Berry"], "https://doi.org/10.21437/Interspeech.2019-3126", 5, "interspeech", 2019]], "Jia Liu": [0, ["Large Margin Softmax Loss for Speaker Verification", ["Yi Liu", "Liang He", "Jia Liu"], "https://doi.org/10.21437/Interspeech.2019-2357", 5, "interspeech", 2019]], "Hoirin Kim": [0.12472110986709595, ["Spatial Pyramid Encoding with Convex Length Normalization for Text-Independent Speaker Verification", ["Youngmoon Jung", "Younggwan Kim", "Hyungjun Lim", "Yeunju Choi", "Hoirin Kim"], "https://doi.org/10.21437/Interspeech.2019-2177", 5, "interspeech", 2019]], "Inma Hernaez": [0, ["Parallel vs. Non-Parallel Voice Conversion for Esophageal Speech", ["Luis Serrano", "Sneha Raman", "David Tavarez", "Eva Navas", "Inma Hernaez"], "https://doi.org/10.21437/Interspeech.2019-2194", 5, "interspeech", 2019]], "Jens Frahm": [0, ["Exploring Critical Articulator Identification from 50Hz RT-MRI Data of the Vocal Tract", ["Samuel S. Silva", "Antonio J. S. Teixeira", "Conceicao Cunha", "Nuno Almeida", "Arun A. Joseph", "Jens Frahm"], "https://doi.org/10.21437/Interspeech.2019-2897", 5, "interspeech", 2019], ["On the Role of Oral Configurations in European Portuguese Nasal Vowels", ["Conceicao Cunha", "Samuel S. Silva", "Antonio J. S. Teixeira", "Catarina Oliveira", "Paula Martins", "Arun A. Joseph", "Jens Frahm"], "https://doi.org/10.21437/Interspeech.2019-2232", 5, "interspeech", 2019]], "Sriram Ganapathy": [0, ["Attention Based Hybrid i-Vector BLSTM Model for Language Recognition", ["Bharat Padi", "Anand Mohan", "Sriram Ganapathy"], "https://doi.org/10.21437/Interspeech.2019-2371", 5, "interspeech", 2019], ["Active Learning Methods for Low Resource End-to-End Speech Recognition", ["Karan Malhotra", "Shubham Bansal", "Sriram Ganapathy"], "https://doi.org/10.21437/Interspeech.2019-2316", 5, "interspeech", 2019], ["Unsupervised Raw Waveform Representation Learning for ASR", ["Purvi Agrawal", "Sriram Ganapathy"], "https://doi.org/10.21437/Interspeech.2019-2652", 5, "interspeech", 2019]], "Junjie Wang": [0.001049823418725282, ["The LeVoice Far-Field Speech Recognition System for VOiCES from a Distance Challenge 2019", ["Yulong Liang", "Lin Yang", "Xuyang Wang", "Yingjie Li", "Chen Jia", "Junjie Wang"], "https://doi.org/10.21437/Interspeech.2019-1944", 5, "interspeech", 2019]], "Mads Graesboll Christensen": [0, ["Harmonic Beamformers for Non-Intrusive Speech Intelligibility Prediction", ["Charlotte Sorensen", "Jesper Bunsow Boldt", "Mads Graesboll Christensen"], "https://doi.org/10.21437/Interspeech.2019-2929", 5, "interspeech", 2019]], "Abeer Alwan": [0, ["A Frequency Normalization Technique for Kindergarten Speech Recognition Inspired by the Role of fo in Vowel Perception", ["Gary Yeung", "Abeer Alwan"], "https://doi.org/10.21437/Interspeech.2019-1847", 5, "interspeech", 2019], ["Voice Quality and Between-Frame Entropy for Sleepiness Estimation", ["Vijay Ravi", "Soo Jin Park", "Amber Afshan", "Abeer Alwan"], "https://doi.org/10.21437/Interspeech.2019-2988", 5, "interspeech", 2019]], "Carol Y. Espy-Wilson": [0, ["Multi-Corpus Acoustic-to-Articulatory Speech Inversion", ["Nadee Seneviratne", "Ganesh Sivaraman", "Carol Y. Espy-Wilson"], "https://doi.org/10.21437/Interspeech.2019-3168", 5, "interspeech", 2019], ["Multi-Modal Learning for Speech Emotion Recognition: An Analysis and Comparison of ASR Outputs with Ground Truth Transcription", ["Saurabh Sahu", "Vikramjit Mitra", "Nadee Seneviratne", "Carol Y. Espy-Wilson"], "https://doi.org/10.21437/Interspeech.2019-1149", 5, "interspeech", 2019]], "Jindrich Zdansky": [0, ["An Approach to Online Speaker Change Point Detection Using DNNs and WFSTs", ["Lukas Mateju", "Petr Cerva", "Jindrich Zdansky"], "https://doi.org/10.21437/Interspeech.2019-1407", 5, "interspeech", 2019]], "Minhwa Chung": [0.9872890114784241, ["Self-Imitating Feedback Generation Using GAN for Computer-Assisted Pronunciation Training", ["Seung Hee Yang", "Minhwa Chung"], "https://doi.org/10.21437/Interspeech.2019-1478", 5, "interspeech", 2019]], "Gian Luca Foresti": [0, ["End-to-End Speaker Identification in Noisy and Reverberant Environments Using Raw Waveform Convolutional Neural Networks", ["Daniele Salvati", "Carlo Drioli", "Gian Luca Foresti"], "https://doi.org/10.21437/Interspeech.2019-2403", 5, "interspeech", 2019]], "Mani B. Srivastava": [0, ["Deep Residual Neural Networks for Audio Spoofing Detection", ["Moustafa Alzantot", "Ziqi Wang", "Mani B. Srivastava"], "https://doi.org/10.21437/Interspeech.2019-3174", 5, "interspeech", 2019]], "Jakub Vit": [0, ["Unified Language-Independent DNN-Based G2P Converter", ["Marketa Juzova", "Daniel Tihelka", "Jakub Vit"], "https://doi.org/10.21437/Interspeech.2019-2335", 5, "interspeech", 2019]], "Satoshi Nakamura": [0, ["VQVAE Unsupervised Unit Discovery and Multi-Scale Code2Spec Inverter for Zerospeech Challenge 2019", ["Andros Tjandra", "Berrak Sisman", "Mingyang Zhang", "Sakriani Sakti", "Haizhou Li", "Satoshi Nakamura"], "https://doi.org/10.21437/Interspeech.2019-3232", 5, "interspeech", 2019], ["Speech Quality Evaluation of Synthesized Japanese Speech Using EEG", ["Ivan Halim Parmonangan", "Hiroki Tanaka", "Sakriani Sakti", "Shinnosuke Takamichi", "Satoshi Nakamura"], "https://doi.org/10.21437/Interspeech.2019-2059", 5, "interspeech", 2019], ["Sequence-to-Sequence Learning via Attention Transfer for Incremental Speech Recognition", ["Sashi Novitasari", "Andros Tjandra", "Sakriani Sakti", "Satoshi Nakamura"], "https://doi.org/10.21437/Interspeech.2019-2985", 5, "interspeech", 2019]], "Tamsin M. McKelvey": [0, ["Using Prosody to Discover Word Order Alternations in a Novel Language", ["Anouschka Foltz", "Sarah Cooper", "Tamsin M. McKelvey"], "https://doi.org/10.21437/Interspeech.2019-1183", 5, "interspeech", 2019]], "Jiqing Han": [5.275537318993884e-06, ["Cross-Corpus Speech Emotion Recognition Using Semi-Supervised Transfer Non-Negative Matrix Factorization with Adaptation Regularization", ["Hui Luo", "Jiqing Han"], "https://doi.org/10.21437/Interspeech.2019-2041", 5, "interspeech", 2019], ["Subspace Pooling Based Temporal Features Extraction for Audio Event Recognition", ["Qiuying Shi", "Hui Luo", "Jiqing Han"], "https://doi.org/10.21437/Interspeech.2019-2047", 5, "interspeech", 2019], ["End-to-End Monaural Speech Separation with Multi-Scale Dynamic Weighted Gated Dilated Convolutional Pyramid Network", ["Ziqiang Shi", "Huibin Lin", "Liu Liu", "Rujie Liu", "Shoji Hayakawa", "Shouji Harada", "Jiqing Han"], "https://doi.org/10.21437/Interspeech.2019-1292", 5, "interspeech", 2019]], "Izhak Shafran": [0, ["Joint Speech Recognition and Speaker Diarization via Sequence Transduction", ["Laurent El Shafey", "Hagen Soltau", "Izhak Shafran"], "https://doi.org/10.21437/Interspeech.2019-1943", 5, "interspeech", 2019]], "Fei Chen": [0, ["Contributions of Consonant-Vowel Transitions to Mandarin Tone Identification in Simulated Electric-Acoustic Hearing", ["Fei Chen"], "https://doi.org/10.21437/Interspeech.2019-1124", 5, "interspeech", 2019]], "Lena Pagel": [0, ["Dimensions of Prosodic Prominence in an Attractor Model", ["Simon Roessig", "Doris Mucke", "Lena Pagel"], "https://doi.org/10.21437/Interspeech.2019-2227", 5, "interspeech", 2019]], "Yi Chang": [0.0003460402149357833, ["Follow-Up Question Generation Using Neural Tensor Network-Based Domain Ontology Population in an Interview Coaching System", ["Ming-Hsiang Su", "Chung-Hsien Wu", "Yi Chang"], "https://doi.org/10.21437/Interspeech.2019-1300", 5, "interspeech", 2019]], "Peter Birkholz": [0, ["Articulatory Copy Synthesis Based on a Genetic Algorithm", ["Yingming Gao", "Simon Stone", "Peter Birkholz"], "https://doi.org/10.21437/Interspeech.2019-1334", 5, "interspeech", 2019]], "Zelin Wu": [3.6378605727804825e-05, ["Improving Performance of End-to-End ASR on Numeric Sequences", ["Cal Peyser", "Hao Zhang", "Tara N. Sainath", "Zelin Wu"], "https://doi.org/10.21437/Interspeech.2019-1345", 5, "interspeech", 2019]], "Puming Zhan": [0, ["Deep Learning Based Mandarin Accent Identification for Accent Robust ASR", ["Felix Weninger", "Yang Sun", "Junho Park", "Daniel Willett", "Puming Zhan"], "https://doi.org/10.21437/Interspeech.2019-2737", 5, "interspeech", 2019], ["Listen, Attend, Spell and Adapt: Speaker Adapted Sequence-to-Sequence ASR", ["Felix Weninger", "Jesus Andres-Ferrer", "Xinwei Li", "Puming Zhan"], "https://doi.org/10.21437/Interspeech.2019-2719", 5, "interspeech", 2019]], "Kazuhito Koishida": [0, ["Sound Event Detection in Multichannel Audio Using Convolutional Time-Frequency-Channel Squeeze and Excitation", ["Wei Xia", "Kazuhito Koishida"], "https://doi.org/10.21437/Interspeech.2019-1860", 5, "interspeech", 2019]], "Matt Huenerfauth": [0, ["Fusion Strategy for Prosodic and Lexical Representations of Word Importance", ["Sushant Kafle", "Cecilia Ovesdotter Alm", "Matt Huenerfauth"], "https://doi.org/10.21437/Interspeech.2019-1898", 5, "interspeech", 2019]], "Torbjorn Svendsen": [0, ["A Phonetic-Level Analysis of Different Input Features for Articulatory Inversion", ["Abdolreza Sabzi Shahrebabaki", "Negar Olfati", "Ali Shariq Imran", "Sabato Marco Siniscalchi", "Torbjorn Svendsen"], "https://doi.org/10.21437/Interspeech.2019-2526", 5, "interspeech", 2019]], "Yuriko Yokoe": [0, ["Place Shift as an Autonomous Process: Evidence from Japanese Listeners", ["Yuriko Yokoe"], "https://doi.org/10.21437/Interspeech.2019-2302", 5, "interspeech", 2019]], "Reynold Bailey": [0, ["Synthesized Spoken Names: Biases Impacting Perception", ["Lucas Kessler", "Cecilia Ovesdotter Alm", "Reynold Bailey"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8031.html", 2, "interspeech", 2019]], "Patti Adank": [0, ["Talker Intelligibility and Listening Effort with Temporally Modified Speech", ["Maximillian Paulus", "Valerie Hazan", "Patti Adank"], "https://doi.org/10.21437/Interspeech.2019-1402", 5, "interspeech", 2019]], "Chanwoo Kim": [0.9085521399974823, ["Multi-Task Multi-Resolution Char-to-BPE Cross-Attention Decoder for End-to-End Speech Recognition", ["Dhananjaya Gowda", "Abhinav Garg", "Kwangyoun Kim", "Mehul Kumar", "Chanwoo Kim"], "https://doi.org/10.21437/Interspeech.2019-3216", 5, "interspeech", 2019]], "Sarmad Hussain": [0, ["Improving Large Vocabulary Urdu Speech Recognition System Using Deep Neural Networks", ["Muhammad Umar Farooq", "Farah Adeeba", "Sahar Rauf", "Sarmad Hussain"], "https://doi.org/10.21437/Interspeech.2019-2629", 5, "interspeech", 2019]], "Sebastian Moller": [0, ["Quality Degradation Diagnosis for Voice Networks - Estimating the Perceived Noisiness, Coloration, and Discontinuity of Transmitted Speech", ["Gabriel Mittag", "Sebastian Moller"], "https://doi.org/10.21437/Interspeech.2019-2636", 5, "interspeech", 2019]], "Jonathan Le Roux": [0, ["Unidirectional Neural Network Architectures for End-to-End Automatic Speech Recognition", ["Niko Moritz", "Takaaki Hori", "Jonathan Le Roux"], "https://doi.org/10.21437/Interspeech.2019-2837", 5, "interspeech", 2019], ["WHAM!: Extending Speech Separation to Noisy Environments", ["Gordon Wichern", "Joe Antognini", "Michael Flynn", "Licheng Richard Zhu", "Emmett McQuinn", "Dwight Crow", "Ethan Manilow", "Jonathan Le Roux"], "https://doi.org/10.21437/Interspeech.2019-2821", 5, "interspeech", 2019], ["Vectorized Beam Search for CTC-Attention-Based Speech Recognition", ["Hiroshi Seki", "Takaaki Hori", "Shinji Watanabe", "Niko Moritz", "Jonathan Le Roux"], "https://doi.org/10.21437/Interspeech.2019-2860", 5, "interspeech", 2019]], "Houwei Cao": [0, ["Development of Emotion Rankers Based on Intended and Perceived Emotion Labels", ["Zhenghao Jin", "Houwei Cao"], "https://doi.org/10.21437/Interspeech.2019-1831", 5, "interspeech", 2019]], "Fernando Fernandez-Martinez": [0, ["Predicting Group-Level Skin Attention to Short Movies from Audio-Based LSTM-Mixture of Experts Models", ["Ricardo Kleinlein", "Cristina Luna Jimenez", "Juan Manuel Montero", "Zoraida Callejas", "Fernando Fernandez-Martinez"], "https://doi.org/10.21437/Interspeech.2019-2799", 5, "interspeech", 2019]], "Jan Michalsky": [0, ["PASCAL and DPA: A Pilot Study on Using Prosodic Competence Scores to Predict Communicative Skills for Team Working and Public Speaking", ["Oliver Niebuhr", "Jan Michalsky"], "https://doi.org/10.21437/Interspeech.2019-3034", 5, "interspeech", 2019]], "Isabel Trancoso": [0, ["Recognition of Latin American Spanish Using Multi-Task Learning", ["Carlos Mendes", "Alberto Abad", "Joao Paulo Neto", "Isabel Trancoso"], "https://doi.org/10.21437/Interspeech.2019-2772", 5, "interspeech", 2019], ["Unbabel Talk - Human Verified Translations for Voice Instant Messaging", ["Luis Bernardo", "Mathieu Giquel", "Sebastiao Quintas", "Paulo Dimas", "Helena Moniz", "Isabel Trancoso"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8034.html", 2, "interspeech", 2019]], "Icksang Han": [0.9961989969015121, ["Who Said That?: Audio-Visual Speaker Diarisation of Real-World Meetings", ["Joon Son Chung", "Bong-Jin Lee", "Icksang Han"], "https://doi.org/10.21437/Interspeech.2019-3116", 5, "interspeech", 2019]], "Kartik Audhkhasi": [0, ["Guiding CTC Posterior Spike Timings for Improved Posterior Fusion and Knowledge Distillation", ["Gakuto Kurata", "Kartik Audhkhasi"], "https://doi.org/10.21437/Interspeech.2019-1952", 5, "interspeech", 2019], ["Multi-Task CTC Training with Auxiliary Feature Reconstruction for End-to-End Speech Recognition", ["Gakuto Kurata", "Kartik Audhkhasi"], "https://doi.org/10.21437/Interspeech.2019-1710", 5, "interspeech", 2019]], "Najim Dehak": [0, ["ASSERT: Anti-Spoofing with Squeeze-Excitation and Residual Networks", ["Cheng-I Lai", "Nanxin Chen", "Jesus Villalba", "Najim Dehak"], "https://doi.org/10.21437/Interspeech.2019-1794", 5, "interspeech", 2019], ["State-of-the-Art Speaker Recognition for Telephone and Video Speech: The JHU-MIT Submission for NIST SRE18", ["Jesus Villalba", "Nanxin Chen", "David Snyder", "Daniel Garcia-Romero", "Alan McCree", "Gregory Sell", "Jonas Borgstrom", "Fred Richardson", "Suwon Shon", "Francois Grondin", "Reda Dehak", "Leibny Paola Garcia-Perera", "Daniel Povey", "Pedro A. Torres-Carrasquillo", "Sanjeev Khudanpur", "Najim Dehak"], "https://doi.org/10.21437/Interspeech.2019-2713", 5, "interspeech", 2019], ["Unsupervised Acoustic Segmentation and Clustering Using Siamese Network Embeddings", ["Saurabhchand Bhati", "Shekhar Nayak", "K. Sri Rama Murty", "Najim Dehak"], "https://doi.org/10.21437/Interspeech.2019-2981", 5, "interspeech", 2019], ["Tied Mixture of Factor Analyzers Layer to Combine Frame Level Representations in Neural Speaker Embeddings", ["Nanxin Chen", "Jesus Villalba", "Najim Dehak"], "https://doi.org/10.21437/Interspeech.2019-1782", 5, "interspeech", 2019], ["Study of the Performance of Automatic Speech Recognition Systems in Speakers with Parkinson's Disease", ["Laureano Moro-Velazquez", "Jaejin Cho", "Shinji Watanabe", "Mark A. Hasegawa-Johnson", "Odette Scharenborg", "Heejin Kim", "Najim Dehak"], "https://doi.org/10.21437/Interspeech.2019-2993", 5, "interspeech", 2019], ["Improving Emotion Identification Using Phone Posteriors in Raw Speech Waveform Based DNN", ["Mousmita Sarma", "Pegah Ghahremani", "Daniel Povey", "Nagendra Kumar Goel", "Kandarpa Kumar Sarma", "Najim Dehak"], "https://doi.org/10.21437/Interspeech.2019-2093", 5, "interspeech", 2019]], "Felicity Cox": [0, ["Articulation of Vowel Length Contrasts in Australian English", ["Louise Ratko", "Michael I. Proctor", "Felicity Cox"], "https://doi.org/10.21437/Interspeech.2019-2995", 5, "interspeech", 2019]]}