{"Uffe Schjoedt": [0, ["God as Interlocutor - Real or Imaginary? Prosodic Markers of Dialogue Speech and Expected Efficacy in Spoken Prayer", ["Oliver Niebuhr", "Uffe Schjoedt"], "https://doi.org/10.21437/Interspeech.2019-1193", 5, "interspeech", 2019]], "Suliang Bu": [0, ["A Novel Method to Correct Steering Vectors in MVDR Beamformer for Noise Robust ASR", ["Suliang Bu", "Yunxin Zhao", "Mei-Yuh Hwang"], "https://doi.org/10.21437/Interspeech.2019-2944", 5, "interspeech", 2019]], "Ozlem Kalinli": [0, ["Bandwidth Embeddings for Mixed-Bandwidth Speech Recognition", ["Gautam Mantena", "Ozlem Kalinli", "Ossama Abdel-Hamid", "Don McAllaster"], "https://doi.org/10.21437/Interspeech.2019-2589", 5, "interspeech", 2019]], "Joakim Gusafsson": [0, ["Spot the Pleasant People! Navigating the Cocktail Party Buzz", ["Christina Tannander", "Per Fallgren", "Jens Edlund", "Joakim Gusafsson"], "https://doi.org/10.21437/Interspeech.2019-1553", 5, "interspeech", 2019]], "Sharalee Blunck": [0, ["Listeners' Ability to Identify the Gender of Preadolescent Children in Different Linguistic Contexts", ["Shawn L. Nissen", "Sharalee Blunck", "Anita Dromey", "Christopher Dromey"], "https://doi.org/10.21437/Interspeech.2019-1865", 5, "interspeech", 2019]], "Preethi Jyothi": [0, ["Exploiting Monolingual Speech Corpora for Code-Mixed Speech Recognition", ["Karan Taneja", "Satarupa Guha", "Preethi Jyothi", "Basil Abraham"], "https://doi.org/10.21437/Interspeech.2019-1959", 5, "interspeech", 2019]], "Brij Mohan Lal Srivastava": [0, ["Privacy-Preserving Adversarial Representation Learning in ASR: Reality or Illusion?", ["Brij Mohan Lal Srivastava", "Aurelien Bellet", "Marc Tommasi", "Emmanuel Vincent"], "https://doi.org/10.21437/Interspeech.2019-2415", 5, "interspeech", 2019]], "Hui Luo": [0, ["Cross-Corpus Speech Emotion Recognition Using Semi-Supervised Transfer Non-Negative Matrix Factorization with Adaptation Regularization", ["Hui Luo", "Jiqing Han"], "https://doi.org/10.21437/Interspeech.2019-2041", 5, "interspeech", 2019], ["Subspace Pooling Based Temporal Features Extraction for Audio Event Recognition", ["Qiuying Shi", "Hui Luo", "Jiqing Han"], "https://doi.org/10.21437/Interspeech.2019-2047", 5, "interspeech", 2019]], "Jeng-Lin Li": [0, ["Attentive to Individual: A Multimodal Emotion Recognition Network with Personalized Attention Profile", ["Jeng-Lin Li", "Chi-Chun Lee"], "https://doi.org/10.21437/Interspeech.2019-2044", 5, "interspeech", 2019], ["Investigating the Variability of Voice Quality and Pain Levels as a Function of Multiple Clinical Parameters", ["Hui-Ting Hong", "Jeng-Lin Li", "Yi-Ming Weng", "Chip-Jin Ng", "Chi-Chun Lee"], "https://doi.org/10.21437/Interspeech.2019-2247", 5, "interspeech", 2019]], "Wenhu Chen": [0, ["Interpreting and Improving Deep Neural SLU Models via Vocabulary Importance", ["Yilin Shen", "Wenhu Chen", "Hongxia Jin"], "https://doi.org/10.21437/Interspeech.2019-3184", 5, "interspeech", 2019]], "Hong Kook Kim": [0.9972290098667145, ["Directional Audio Rendering Using a Neural Network Based Personalized HRTF", ["Geon Woo Lee", "Jung Hyuk Lee", "Seong Ju Kim", "Hong Kook Kim"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8005.html", 2, "interspeech", 2019]], "Zhaoyi Gu": [2.6499289741688248e-11, ["Speech Separation Using Independent Vector Analysis with an Amplitude Variable Gaussian Mixture Model", ["Zhaoyi Gu", "Jing Lu", "Kai Chen"], "https://doi.org/10.21437/Interspeech.2019-2076", 5, "interspeech", 2019]], "Protima Nomo Sudro": [0, ["Modification of Devoicing Error in Cleft Lip and Palate Speech", ["Protima Nomo Sudro", "S. R. Mahadeva Prasanna"], "https://doi.org/10.21437/Interspeech.2019-2604", 5, "interspeech", 2019], ["Nasal Air Emission in Sibilant Fricatives of Cleft Lip and Palate Speech", ["Sishir Kalita", "Protima Nomo Sudro", "S. R. Mahadeva Prasanna", "Samarendra Dandapat"], "https://doi.org/10.21437/Interspeech.2019-2345", 5, "interspeech", 2019]], "Hamidou Tembine": [0, ["Nonparallel Emotional Speech Conversion", ["Jian Gao", "Deep Chakraborty", "Hamidou Tembine", "Olaitan Olaleye"], "https://doi.org/10.21437/Interspeech.2019-2878", 5, "interspeech", 2019]], "Chun-Wei Wang": [0.00011971311323577538, ["Self Attention in Variational Sequential Learning for Summarization", ["Jen-Tzung Chien", "Chun-Wei Wang"], "https://doi.org/10.21437/Interspeech.2019-1548", 5, "interspeech", 2019]], "Jingshen Pan": [0, ["Towards the Speech Features of Mild Cognitive Impairment: Universal Evidence from Structured and Unstructured Connected Speech of Chinese", ["Tianqi Wang", "Chongyuan Lian", "Jingshen Pan", "Quanlei Yan", "Feiqi Zhu", "Manwa L. Ng", "Lan Wang", "Nan Yan"], "https://doi.org/10.21437/Interspeech.2019-2414", 5, "interspeech", 2019], ["Towards the Speech Features of Early-Stage Dementia: Design and Application of the Mandarin Elderly Cognitive Speech Database", ["Tianqi Wang", "Quanlei Yan", "Jingshen Pan", "Feiqi Zhu", "Rongfeng Su", "Yi Guo", "Lan Wang", "Nan Yan"], "https://doi.org/10.21437/Interspeech.2019-2453", 5, "interspeech", 2019]], "Adele Jatteau": [0, ["\" Gra[f] e!\" Word-Final Devoicing of Obstruents in Standard French: An Acoustic Study Based on Large Corpora", ["Adele Jatteau", "Ioana Vasilescu", "Lori Lamel", "Martine Adda-Decker", "Nicolas Audibert"], "https://doi.org/10.21437/Interspeech.2019-2329", 5, "interspeech", 2019]], "Gennaro Cordasco": [0, ["The Dependability of Voice on Elders' Acceptance of Humanoid Agents", ["Anna Esposito", "Terry Amorese", "Marialucia Cuciniello", "Maria Teresa Riviello", "Antonietta Maria Esposito", "Alda Troncone", "Gennaro Cordasco"], "https://doi.org/10.21437/Interspeech.2019-1734", 5, "interspeech", 2019]], "Lanhua You": [0, ["Multi-Task Learning with High-Order Statistics for x-Vector Based Text-Independent Speaker Verification", ["Lanhua You", "Wu Guo", "Li-Rong Dai", "Jun Du"], "https://doi.org/10.21437/Interspeech.2019-2264", 5, "interspeech", 2019], ["Deep Neural Network Embeddings with Gating Mechanisms for Text-Independent Speaker Verification", ["Lanhua You", "Wu Guo", "Li-Rong Dai", "Jun Du"], "https://doi.org/10.21437/Interspeech.2019-1746", 5, "interspeech", 2019]], "Jiri Martinek": [0, ["Multi-Lingual Dialogue Act Recognition with Deep Learning Methods", ["Jiri Martinek", "Pavel Kral", "Ladislav Lenc", "Christophe Cerisara"], "https://doi.org/10.21437/Interspeech.2019-1691", 5, "interspeech", 2019]], "Hasim Sak": [0, ["Large-Scale Visual Speech Recognition", ["Brendan Shillingford", "Yannis M. Assael", "Matthew W. Hoffman", "Thomas Paine", "Cian Hughes", "Utsav Prabhu", "Hank Liao", "Hasim Sak", "Kanishka Rao", "Lorrayne Bennett", "Marie Mulville", "Misha Denil", "Ben Coppin", "Ben Laurie", "Andrew W. Senior", "Nando de Freitas"], "https://doi.org/10.21437/Interspeech.2019-1669", 5, "interspeech", 2019]], "Seyedeh Zahra Razavi": [0, ["Investigating Linguistic and Semantic Features for Turn-Taking Prediction in Open-Domain Human-Computer Conversation", ["Seyedeh Zahra Razavi", "Benjamin Kane", "Lenhart K. Schubert"], "https://doi.org/10.21437/Interspeech.2019-3152", 5, "interspeech", 2019]], "Shun-Po Chuang": [0, ["Code-Switching Sentence Generation by Generative Adversarial Networks and its Application to Data Augmentation", ["Ching-Ting Chang", "Shun-Po Chuang", "Hung-yi Lee"], "https://doi.org/10.21437/Interspeech.2019-3214", 5, "interspeech", 2019]], "Christoph Boddeker": [0, ["Guided Source Separation Meets a Strong ASR Backend: Hitachi/Paderborn University Joint Investigation for Dinner Party ASR", ["Naoyuki Kanda", "Christoph Boddeker", "Jens Heitkaemper", "Yusuke Fujita", "Shota Horiguchi", "Kenji Nagamatsu", "Reinhold Haeb-Umbach"], "https://doi.org/10.21437/Interspeech.2019-1167", 5, "interspeech", 2019]], "Trevor Strohman": [0, ["Two-Pass End-to-End Speech Recognition", ["Tara N. Sainath", "Ruoming Pang", "David Rybach", "Yanzhang He", "Rohit Prabhavalkar", "Wei Li", "Mirko Visontai", "Qiao Liang", "Trevor Strohman", "Yonghui Wu", "Ian McGraw", "Chung-Cheng Chiu"], "https://doi.org/10.21437/Interspeech.2019-1341", 5, "interspeech", 2019]], "Bistra Andreeva": [0, ["Phonetic Accommodation in a Wizard-of-Oz Experiment: Intonation and Segments", ["Iona Gessinger", "Bernd Mobius", "Bistra Andreeva", "Eran Raveh", "Ingmar Steiner"], "https://doi.org/10.21437/Interspeech.2019-2445", 5, "interspeech", 2019]], "Yiting Lu": [0, ["Impact of ASR Performance on Spoken Grammatical Error Detection", ["Yiting Lu", "Mark J. F. Gales", "Kate M. Knill", "P. P. Manakul", "Linlin Wang", "Y. Wang"], "https://doi.org/10.21437/Interspeech.2019-1706", 5, "interspeech", 2019]], "Klara Vicsi": [0, ["Depression State Assessment: Application for Detection of Depression by Speech", ["Gabor Kiss", "David Sztaho", "Klara Vicsi"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8004.html", 2, "interspeech", 2019]], "Ying Liu": [0, ["Code-Switching Sentence Generation by Bert and Generative Adversarial Networks", ["Yingying Gao", "Junlan Feng", "Ying Liu", "Leijing Hou", "Xin Pan", "Yong Ma"], "https://doi.org/10.21437/Interspeech.2019-2501", 5, "interspeech", 2019]], "Catherine Lai": [0, ["Detecting Topic-Oriented Speaker Stance in Conversational Speech", ["Catherine Lai", "Beatrice Alex", "Johanna D. Moore", "Leimin Tian", "Tatsuro Hori", "Gianpiero Francesca"], "https://doi.org/10.21437/Interspeech.2019-2632", 5, "interspeech", 2019]], "Alan Wisler": [0, ["Towards a Speaker Independent Speech-BCI Using Speaker Adaptation", ["Debadatta Dash", "Alan Wisler", "Paul Ferrari", "Jun Wang"], "https://doi.org/10.21437/Interspeech.2019-3109", 5, "interspeech", 2019]], "Arindam Jati": [0, ["Multiview Shared Subspace Learning Across Speakers and Speech Commands", ["Krishna Somandepalli", "Naveen Kumar", "Arindam Jati", "Panayiotis G. Georgiou", "Shrikanth Narayanan"], "https://doi.org/10.21437/Interspeech.2019-3130", 5, "interspeech", 2019], ["Multi-Task Discriminative Training of Hybrid DNN-TVM Model for Speaker Verification with Noisy and Far-Field Speech", ["Arindam Jati", "Raghuveer Peri", "Monisankha Pal", "Tae Jin Park", "Naveen Kumar", "Ruchir Travadi", "Panayiotis G. Georgiou", "Shrikanth Narayanan"], "https://doi.org/10.21437/Interspeech.2019-3010", 5, "interspeech", 2019]], "Anil Kumar Vuppala": [0, ["IIIT-H Spoofing Countermeasures for Automatic Speaker Verification Spoofing and Countermeasures Challenge 2019", ["K. N. R. K. Raju Alluri", "Anil Kumar Vuppala"], "https://doi.org/10.21437/Interspeech.2019-1623", 5, "interspeech", 2019], ["Sound Privacy: A Conversational Speech Corpus for Quantifying the Experience of Privacy", ["Pablo Perez Zarazaga", "Sneha Das", "Tom Backstrom", "Vishnu Vidyadhara Raju Vegesna", "Anil Kumar Vuppala"], "https://doi.org/10.21437/Interspeech.2019-1172", 5, "interspeech", 2019]], "Heike Adel": [0, ["Automatic Compression of Subtitles with Neural Networks and its Effect on User Experience", ["Katrin Angerbauer", "Heike Adel", "Ngoc Thang Vu"], "https://doi.org/10.21437/Interspeech.2019-1750", 5, "interspeech", 2019]], "Rohit Voleti": [0, ["Objective Assessment of Social Skills Using Automated Language Analysis for Identification of Schizophrenia and Bipolar Disorder", ["Rohit Voleti", "Stephanie Woolridge", "Julie M. Liss", "Melissa Milanovic", "Christopher R. Bowie", "Visar Berisha"], "https://doi.org/10.21437/Interspeech.2019-2960", 5, "interspeech", 2019]], "Tomas Arias-Vergara": [0, ["Apkinson: A Mobile Solution for Multimodal Assessment of Patients with Parkinson's Disease", ["Juan Camilo Vasquez-Correa", "Tomas Arias-Vergara", "Philipp Klumpp", "M. Strauss", "Arne Kuderle", "Nils Roth", "S. Bayerl", "Nicanor Garcia-Ospina", "Paula Andrea Perez-Toro", "L. Felipe Parra-Gallego", "Cristian David Rios-Urrego", "D. Escobar-Grisales", "Juan Rafael Orozco-Arroyave", "Bjorn Eskofier", "Elmar Noth"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8003.html", 2, "interspeech", 2019], ["Phone-Attribute Posteriors to Evaluate the Speech of Cochlear Implant Users", ["Tomas Arias-Vergara", "Juan Rafael Orozco-Arroyave", "Milos Cernak", "Sandra Gollwitzer", "Maria Schuster", "Elmar Noth"], "https://doi.org/10.21437/Interspeech.2019-2144", 5, "interspeech", 2019]], "Luciana Ferrer": [0, ["EpaDB: A Database for Development of Pronunciation Assessment Systems", ["Jazmin Vidal", "Luciana Ferrer", "Leonardo Brambilla"], "https://doi.org/10.21437/Interspeech.2019-1839", 5, "interspeech", 2019], ["Analysis of Critical Metadata Factors for the Calibration of Speaker Recognition Systems", ["Mahesh Kumar Nandwana", "Luciana Ferrer", "Mitchell McLaren", "Diego Castan", "Aaron Lawson"], "https://doi.org/10.21437/Interspeech.2019-1808", 5, "interspeech", 2019], ["Optimizing a Speaker Embedding Extractor Through Backend-Driven Regularization", ["Luciana Ferrer", "Mitchell McLaren"], "https://doi.org/10.21437/Interspeech.2019-1820", 5, "interspeech", 2019]], "Chunlei Zhang": [0, ["I4U Submission to NIST SRE 2018: Leveraging from a Decade of Shared Experiences", ["Kong Aik Lee", "Ville Hautamaki", "Tomi H. Kinnunen", "Hitoshi Yamamoto", "Koji Okabe", "Ville Vestman", "Jing Huang", "Guohong Ding", "Hanwu Sun", "Anthony Larcher", "Rohan Kumar Das", "Haizhou Li", "Mickael Rouvier", "Pierre-Michel Bousquet", "Wei Rao", "Qing Wang", "Chunlei Zhang", "Fahimeh Bahmaninezhad", "Hector Delgado", "Massimiliano Todisco"], "https://doi.org/10.21437/Interspeech.2019-1533", 5, "interspeech", 2019]], "Chaitali Chakrabarti": [0, ["Residual + Capsule Networks (ResCap) for Simultaneous Single-Channel Overlapped Keyword Recognition", ["Yan Xiong", "Visar Berisha", "Chaitali Chakrabarti"], "https://doi.org/10.21437/Interspeech.2019-2913", 5, "interspeech", 2019]], "Marzena Zyla-Hoppe": [0, ["Avaya Conversational Intelligence: A Real-Time System for Spoken Language Understanding in Human-Human Call Center Conversations", ["Jan Mizgajski", "Adrian Szymczak", "Robert Glowski", "Piotr Szymanski", "Piotr Zelasko", "Lukasz Augustyniak", "Mikolaj Morzy", "Yishay Carmiel", "Jeff Hodson", "Lukasz Wojciak", "Daniel Smoczyk", "Adam Wrobel", "Bartosz Borowik", "Adam Artajew", "Marcin Baran", "Cezary Kwiatkowski", "Marzena Zyla-Hoppe"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8002.html", 2, "interspeech", 2019]], "Yang Sun": [0.012746385298669338, ["Deep Learning Based Mandarin Accent Identification for Accent Robust ASR", ["Felix Weninger", "Yang Sun", "Junho Park", "Daniel Willett", "Puming Zhan"], "https://doi.org/10.21437/Interspeech.2019-2737", 5, "interspeech", 2019]], "Abhinav Misra": [0, ["Automated Estimation of Oral Reading Fluency During Summer Camp e-Book Reading with MyTurnToRead", ["Anastassia Loukina", "Beata Beigman Klebanov", "Patrick L. Lange", "Yao Qian", "Binod Gyawali", "Nitin Madnani", "Abhinav Misra", "Klaus Zechner", "Zuowei Wang", "John Sabatini"], "https://doi.org/10.21437/Interspeech.2019-2889", 5, "interspeech", 2019]], "Linhao Dong": [2.5628809453337453e-05, ["Boosting Character-Based Chinese Speech Synthesis via Multi-Task Learning and Dictionary Tutoring", ["Yuxiang Zou", "Linhao Dong", "Bo Xu"], "https://doi.org/10.21437/Interspeech.2019-3233", 5, "interspeech", 2019]], "Itzhak Fried": [0, ["Identifying Input Features for Development of Real-Time Translation of Neural Signals to Text", ["Janaki Sheth", "Ariel Tankus", "Michelle Tran", "Lindy Comstock", "Itzhak Fried", "William Speier"], "https://doi.org/10.21437/Interspeech.2019-3092", 5, "interspeech", 2019]], "Karan Malhotra": [0, ["Active Learning Methods for Low Resource End-to-End Speech Recognition", ["Karan Malhotra", "Shubham Bansal", "Sriram Ganapathy"], "https://doi.org/10.21437/Interspeech.2019-2316", 5, "interspeech", 2019]], "David Griol": [0, ["Discovering Dialog Rules by Means of an Evolutionary Approach", ["David Griol", "Zoraida Callejas"], "https://doi.org/10.21437/Interspeech.2019-2230", 5, "interspeech", 2019]], "H. Wood": [0, ["Splash: Speech and Language Assessment in Schools and Homes", ["A. Miwardelli", "I. Gallagher", "J. Gibson", "Napoleon Katsos", "Kate M. Knill", "H. Wood"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8027.html", 2, "interspeech", 2019]], "Kye Min Tan": [0, ["The I2R's ASR System for the VOiCES from a Distance Challenge 2019", ["Tze Yuang Chong", "Kye Min Tan", "Kah Kuan Teh", "Chang Huai You", "Hanwu Sun", "Tran Huy Dat"], "https://doi.org/10.21437/Interspeech.2019-2130", 5, "interspeech", 2019], ["The I2R's ASR System for the VOiCES from a Distance Challenge 2019", ["Tze Yuang Chong", "Kye Min Tan", "Kah Kuan Teh", "Chang Huai You", "Hanwu Sun", "Tran Huy Dat"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/abs18.html", 0, "interspeech", 2019]], "Kara D. Federmeier": [0, ["The Neural Correlates Underlying Lexically-Guided Perceptual Learning", ["Odette Scharenborg", "Jiska Koemans", "Cybelle Smith", "Mark A. Hasegawa-Johnson", "Kara D. Federmeier"], "https://doi.org/10.21437/Interspeech.2019-2328", 5, "interspeech", 2019]], "Danny Merkx": [0, ["Language Learning Using Speech to Image Retrieval", ["Danny Merkx", "Stefan L. Frank", "Mirjam Ernestus"], "https://doi.org/10.21437/Interspeech.2019-3067", 5, "interspeech", 2019]], "Rohit Prabhavalkar": [0, ["Phoneme-Based Contextualization for Cross-Lingual Speech Recognition in End-to-End Models", ["Ke Hu", "Antoine Bruguier", "Tara N. Sainath", "Rohit Prabhavalkar", "Golan Pundak"], "https://doi.org/10.21437/Interspeech.2019-1868", 5, "interspeech", 2019], ["Two-Pass End-to-End Speech Recognition", ["Tara N. Sainath", "Ruoming Pang", "David Rybach", "Yanzhang He", "Rohit Prabhavalkar", "Wei Li", "Mirko Visontai", "Qiao Liang", "Trevor Strohman", "Yonghui Wu", "Ian McGraw", "Chung-Cheng Chiu"], "https://doi.org/10.21437/Interspeech.2019-1341", 5, "interspeech", 2019], ["On the Choice of Modeling Unit for Sequence-to-Sequence Speech Recognition", ["Kazuki Irie", "Rohit Prabhavalkar", "Anjuli Kannan", "Antoine Bruguier", "David Rybach", "Patrick Nguyen"], "https://doi.org/10.21437/Interspeech.2019-2277", 5, "interspeech", 2019]], "Carolin Schmid": [0, ["Sound Tools eXtended (STx) 5.0 - A Powerful Sound Analysis Tool Optimized for Speech", ["Anton Noll", "Jonathan Stuefer", "Nicola Klingler", "Hannah Leykum", "Carina Lozo", "Jan Luttenberger", "Michael Pucher", "Carolin Schmid"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8022.html", 2, "interspeech", 2019]], "David C. Atkins": [0, ["Modeling Interpersonal Linguistic Coordination in Conversations Using Word Mover's Distance", ["Md. Nasir", "Sandeep Nallan Chakravarthula", "Brian R. W. Baucom", "David C. Atkins", "Panayiotis G. Georgiou", "Shrikanth Narayanan"], "https://doi.org/10.21437/Interspeech.2019-1900", 5, "interspeech", 2019], ["Identifying Therapist and Client Personae for Therapeutic Alliance Estimation", ["Victor R. Martinez", "Nikolaos Flemotomos", "Victor Ardulov", "Krishna Somandepalli", "Simon B. Goldberg", "Zac E. Imel", "David C. Atkins", "Shrikanth Narayanan"], "https://doi.org/10.21437/Interspeech.2019-2829", 5, "interspeech", 2019]], "Avik Ray": [0, ["Iterative Delexicalization for Improved Spoken Language Understanding", ["Avik Ray", "Yilin Shen", "Hongxia Jin"], "https://doi.org/10.21437/Interspeech.2019-2955", 5, "interspeech", 2019]], "Wei-Qiang Zhang": [0, ["Towards Discriminative Representations and Unbiased Predictions: Class-Specific Angular Softmax for Speech Emotion Recognition", ["Zhixuan Li", "Liang He", "Jingyang Li", "Li Wang", "Wei-Qiang Zhang"], "https://doi.org/10.21437/Interspeech.2019-1683", 5, "interspeech", 2019], ["Learning How to Listen: A Temporal-Frequential Attention Model for Sound Event Detection", ["Yu-Han Shen", "Ke-Xin He", "Wei-Qiang Zhang"], "https://doi.org/10.21437/Interspeech.2019-2045", 5, "interspeech", 2019], ["Music Genre Classification Using Duplicated Convolutional Layers in Neural Networks", ["Hansi Yang", "Wei-Qiang Zhang"], "https://doi.org/10.21437/Interspeech.2019-1298", 5, "interspeech", 2019], ["Hierarchical Pooling Structure for Weakly Labeled Sound Event Detection", ["Ke-Xin He", "Yu-Han Shen", "Wei-Qiang Zhang"], "https://doi.org/10.21437/Interspeech.2019-2049", 5, "interspeech", 2019]], "Emmanouil Benetos": [0, ["Ensemble Models for Spoofing Detection in Automatic Speaker Verification", ["Bhusan Chettri", "Daniel Stoller", "Veronica Morfi", "Marco A. Martinez Ramirez", "Emmanouil Benetos", "Bob L. Sturm"], "https://doi.org/10.21437/Interspeech.2019-2505", 5, "interspeech", 2019], ["Towards Joint Sound Scene and Polyphonic Sound Event Recognition", ["Helen L. Bear", "Ines Nolasco", "Emmanouil Benetos"], "https://doi.org/10.21437/Interspeech.2019-2169", 5, "interspeech", 2019]], "Yaxing Li": [0, ["A Convolutional Neural Network with Non-Local Module for Speech Enhancement", ["Xiaoqi Li", "Yaxing Li", "Meng Li", "Shan Xu", "Yuanjie Dong", "Xinrong Sun", "Shengwu Xiong"], "https://doi.org/10.21437/Interspeech.2019-2472", 5, "interspeech", 2019]], "Thomas Paine": [0, ["Large-Scale Visual Speech Recognition", ["Brendan Shillingford", "Yannis M. Assael", "Matthew W. Hoffman", "Thomas Paine", "Cian Hughes", "Utsav Prabhu", "Hank Liao", "Hasim Sak", "Kanishka Rao", "Lorrayne Bennett", "Marie Mulville", "Misha Denil", "Ben Coppin", "Ben Laurie", "Andrew W. Senior", "Nando de Freitas"], "https://doi.org/10.21437/Interspeech.2019-1669", 5, "interspeech", 2019]], "Karthik Pandia D. S": [0, ["Zero Resource Speech Synthesis Using Transcripts Derived from Perceptual Acoustic Units", ["Karthik Pandia D. S", "Hema A. Murthy"], "https://doi.org/10.21437/Interspeech.2019-2336", 5, "interspeech", 2019]], "Yannis Stylianou": [0, ["Non-Parallel Voice Conversion Using Weighted Generative Adversarial Networks", ["Dipjyoti Paul", "Yannis Pantazis", "Yannis Stylianou"], "https://doi.org/10.21437/Interspeech.2019-2869", 5, "interspeech", 2019], ["Speech Enhancement for Noise-Robust Speech Synthesis Using Wasserstein GAN", ["Nagaraj Adiga", "Yannis Pantazis", "Vassilis Tsiaras", "Yannis Stylianou"], "https://doi.org/10.21437/Interspeech.2019-2648", 5, "interspeech", 2019], ["A Non-Causal FFTNet Architecture for Speech Enhancement", ["P. V. Muhammed Shifas", "Nagaraj Adiga", "Vassilis Tsiaras", "Yannis Stylianou"], "https://doi.org/10.21437/Interspeech.2019-2622", 5, "interspeech", 2019]], "Paavo Alku": [0, ["GELP: GAN-Excited Linear Prediction for Speech Synthesis from Mel-Spectrogram", ["Lauri Juvela", "Bajibabu Bollepalli", "Junichi Yamagishi", "Paavo Alku"], "https://doi.org/10.21437/Interspeech.2019-2008", 5, "interspeech", 2019], ["Mel-Frequency Cepstral Coefficients of Voice Source Waveforms for Classification of Phonation Types in Speech", ["Sudarsana Reddy Kadiri", "Paavo Alku"], "https://doi.org/10.21437/Interspeech.2019-2863", 5, "interspeech", 2019], ["Lombard Speech Synthesis Using Transfer Learning in a Tacotron Text-to-Speech System", ["Bajibabu Bollepalli", "Lauri Juvela", "Paavo Alku"], "https://doi.org/10.21437/Interspeech.2019-1333", 5, "interspeech", 2019], ["Augmented CycleGANs for Continuous Scale Normal-to-Lombard Speaking Style Conversion", ["Shreyas Seshadri", "Lauri Juvela", "Paavo Alku", "Okko Rasanen"], "https://doi.org/10.21437/Interspeech.2019-1681", 5, "interspeech", 2019]], "Sandeep Nallan Chakravarthula": [0, ["Modeling Interpersonal Linguistic Coordination in Conversations Using Word Mover's Distance", ["Md. Nasir", "Sandeep Nallan Chakravarthula", "Brian R. W. Baucom", "David C. Atkins", "Panayiotis G. Georgiou", "Shrikanth Narayanan"], "https://doi.org/10.21437/Interspeech.2019-1900", 5, "interspeech", 2019], ["Predicting Behavior in Cancer-Afflicted Patient and Spouse Interactions Using Speech and Language", ["Sandeep Nallan Chakravarthula", "Haoqi Li", "Shao-Yen Tseng", "Maija Reblin", "Panayiotis G. Georgiou"], "https://doi.org/10.21437/Interspeech.2019-1888", 5, "interspeech", 2019]], "Jinyi Yang": [3.4071489608322736e-05, ["Exploring Methods for the Automatic Detection of Errors in Manual Transcription", ["Xiaofei Wang", "Jinyi Yang", "Ruizhi Li", "Samik Sadhu", "Hynek Hermansky"], "https://doi.org/10.21437/Interspeech.2019-1343", 5, "interspeech", 2019]], "Jian Yao": [0, ["Coarse-to-Fine Optimization for Speech Enhancement", ["Jian Yao", "Ahmad Al-Dahle"], "https://doi.org/10.21437/Interspeech.2019-2792", 5, "interspeech", 2019]], "Shreyas Seshadri": [0, ["Augmented CycleGANs for Continuous Scale Normal-to-Lombard Speaking Style Conversion", ["Shreyas Seshadri", "Lauri Juvela", "Paavo Alku", "Okko Rasanen"], "https://doi.org/10.21437/Interspeech.2019-1681", 5, "interspeech", 2019]], "Robert V. Kenyon": [0, ["The Effects of Time Expansion on English as a Second Language Individuals", ["John S. Novak III", "Daniel Bunn", "Robert V. Kenyon"], "https://doi.org/10.21437/Interspeech.2019-2763", 5, "interspeech", 2019]], "Anita E. Wagner": [0, ["Using Pupil Dilation to Measure Cognitive Load When Listening to Text-to-Speech in Quiet and in Noise", ["Avashna Govender", "Anita E. Wagner", "Simon King"], "https://doi.org/10.21437/Interspeech.2019-1783", 5, "interspeech", 2019]], "Damien Lolive": [0, ["Corpus Design Using Convolutional Auto-Encoder Embeddings for Audio-Book Synthesis", ["Meysam Shamsi", "Damien Lolive", "Nelly Barbot", "Jonathan Chevelu"], "https://doi.org/10.21437/Interspeech.2019-2190", 5, "interspeech", 2019]], "Emma ONeill": [0, ["The Effect of Phoneme Distribution on Perceptual Similarity in English", ["Emma ONeill", "Julie Carson-Berndsen"], "https://doi.org/10.21437/Interspeech.2019-3042", 5, "interspeech", 2019]], "Golan Pundak": [0, ["Phoneme-Based Contextualization for Cross-Lingual Speech Recognition in End-to-End Models", ["Ke Hu", "Antoine Bruguier", "Tara N. Sainath", "Rohit Prabhavalkar", "Golan Pundak"], "https://doi.org/10.21437/Interspeech.2019-1868", 5, "interspeech", 2019]], "Maja Pantic": [0, ["Investigating the Lombard Effect Influence on End-to-End Audio-Visual Speech Recognition", ["Pingchuan Ma", "Stavros Petridis", "Maja Pantic"], "https://doi.org/10.21437/Interspeech.2019-2726", 5, "interspeech", 2019], ["Video-Driven Speech Reconstruction Using Generative Adversarial Networks", ["Konstantinos Vougioukas", "Pingchuan Ma", "Stavros Petridis", "Maja Pantic"], "https://doi.org/10.21437/Interspeech.2019-1445", 5, "interspeech", 2019]], "Jing Lu": [0, ["Speech Separation Using Independent Vector Analysis with an Amplitude Variable Gaussian Mixture Model", ["Zhaoyi Gu", "Jing Lu", "Kai Chen"], "https://doi.org/10.21437/Interspeech.2019-2076", 5, "interspeech", 2019]], "Varun Srivastava": [0, ["Detection of Glottal Closure Instants from Raw Speech Using Convolutional Neural Networks", ["Mohit Goyal", "Varun Srivastava", "Prathosh A. P."], "https://doi.org/10.21437/Interspeech.2019-2587", 5, "interspeech", 2019]], "Ryota Nishimura": [0, ["Small-Footprint Magic Word Detection Method Using Convolutional LSTM Neural Network", ["Taiki Yamamoto", "Ryota Nishimura", "Masayuki Misaki", "Norihide Kitaoka"], "https://doi.org/10.21437/Interspeech.2019-1662", 5, "interspeech", 2019]], "Jinwoo Lee": [0.7019595056772232, ["Robust Keyword Spotting via Recycle-Pooling for Mobile Game", ["Shounan An", "Youngsoo Kim", "Hu Xu", "Jinwoo Lee", "Myungwoo Lee", "Insoo Oh"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8010.html", 2, "interspeech", 2019]], "P. C. Ching": [0, ["Deep Learning of Segment-Level Feature Representation with Multiple Instance Learning for Utterance-Level Speech Emotion Recognition", ["Shuiyang Mao", "P. C. Ching", "Tan Lee"], "https://doi.org/10.21437/Interspeech.2019-1968", 5, "interspeech", 2019]], "Gyorgy Kovacs": [0, ["Examining the Combination of Multi-Band Processing and Channel Dropout for Robust Speech Recognition", ["Gyorgy Kovacs", "Laszlo Toth", "Dirk Van Compernolle", "Marcus Liwicki"], "https://doi.org/10.21437/Interspeech.2019-3215", 5, "interspeech", 2019]], "Simon Roessig": [0, ["Dimensions of Prosodic Prominence in an Attractor Model", ["Simon Roessig", "Doris Mucke", "Lena Pagel"], "https://doi.org/10.21437/Interspeech.2019-2227", 5, "interspeech", 2019]], "Conceicao Cunha": [0, ["Exploring Critical Articulator Identification from 50Hz RT-MRI Data of the Vocal Tract", ["Samuel S. Silva", "Antonio J. S. Teixeira", "Conceicao Cunha", "Nuno Almeida", "Arun A. Joseph", "Jens Frahm"], "https://doi.org/10.21437/Interspeech.2019-2897", 5, "interspeech", 2019], ["On the Role of Oral Configurations in European Portuguese Nasal Vowels", ["Conceicao Cunha", "Samuel S. Silva", "Antonio J. S. Teixeira", "Catarina Oliveira", "Paula Martins", "Arun A. Joseph", "Jens Frahm"], "https://doi.org/10.21437/Interspeech.2019-2232", 5, "interspeech", 2019]], "Aleksandar Gjoreski": [0, ["Cross-Lingual Transfer Learning for Affective Spoken Dialogue Systems", ["Kristijan Gjoreski", "Aleksandar Gjoreski", "Ivan Kraljevski", "Diane Hirschfeld"], "https://doi.org/10.21437/Interspeech.2019-2163", 5, "interspeech", 2019]], "Jonas Borgstrom": [0, ["State-of-the-Art Speaker Recognition for Telephone and Video Speech: The JHU-MIT Submission for NIST SRE18", ["Jesus Villalba", "Nanxin Chen", "David Snyder", "Daniel Garcia-Romero", "Alan McCree", "Gregory Sell", "Jonas Borgstrom", "Fred Richardson", "Suwon Shon", "Francois Grondin", "Reda Dehak", "Leibny Paola Garcia-Perera", "Daniel Povey", "Pedro A. Torres-Carrasquillo", "Sanjeev Khudanpur", "Najim Dehak"], "https://doi.org/10.21437/Interspeech.2019-2713", 5, "interspeech", 2019]], "Patrick von Platen": [0, ["Multi-Span Acoustic Modelling Using Raw Waveform Signals", ["Patrick von Platen", "Chao Zhang", "Philip C. Woodland"], "https://doi.org/10.21437/Interspeech.2019-2454", 5, "interspeech", 2019]], "Ralf Schluter": [0, ["Survey Talk: Modeling in Automatic Speech Recognition: Beyond Hidden Markov Models", ["Ralf Schluter"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/abs4.html", 0, "interspeech", 2019], ["RWTH ASR Systems for LibriSpeech: Hybrid vs Attention", ["Christoph Luscher", "Eugen Beck", "Kazuki Irie", "Markus Kitza", "Wilfried Michel", "Albert Zeyer", "Ralf Schluter", "Hermann Ney"], "https://doi.org/10.21437/Interspeech.2019-1780", 5, "interspeech", 2019], ["Cumulative Adaptation for BLSTM Acoustic Models", ["Markus Kitza", "Pavel Golik", "Ralf Schluter", "Hermann Ney"], "https://doi.org/10.21437/Interspeech.2019-2162", 5, "interspeech", 2019], ["An Analysis of Local Monotonic Attention Variants", ["Andre Merboldt", "Albert Zeyer", "Ralf Schluter", "Hermann Ney"], "https://doi.org/10.21437/Interspeech.2019-2879", 5, "interspeech", 2019], ["Comparison of Lattice-Free and Lattice-Based Sequence Discriminative Training Criteria for LVCSR", ["Wilfried Michel", "Ralf Schluter", "Hermann Ney"], "https://doi.org/10.21437/Interspeech.2019-2254", 5, "interspeech", 2019], ["Analysis of Deep Clustering as Preprocessing for Automatic Speech Recognition of Sparsely Overlapping Speech", ["Tobias Menne", "Ilya Sklyar", "Ralf Schluter", "Hermann Ney"], "https://doi.org/10.21437/Interspeech.2019-1728", 5, "interspeech", 2019], ["Language Modeling with Deep Transformers", ["Kazuki Irie", "Albert Zeyer", "Ralf Schluter", "Hermann Ney"], "https://doi.org/10.21437/Interspeech.2019-2225", 5, "interspeech", 2019], ["Rescoring Keyword Search Confidence Estimates with Graph-Based Re-Ranking Using Acoustic Word Embeddings", ["Anna Piunova", "Eugen Beck", "Ralf Schluter", "Hermann Ney"], "https://doi.org/10.21437/Interspeech.2019-1817", 5, "interspeech", 2019]], "Sarah Cooper": [0, ["Using Prosody to Discover Word Order Alternations in a Novel Language", ["Anouschka Foltz", "Sarah Cooper", "Tamsin M. McKelvey"], "https://doi.org/10.21437/Interspeech.2019-1183", 5, "interspeech", 2019]], "Ravi Shankar": [0, ["VESUS: A Crowd-Annotated Database to Study Emotion Production and Perception in Spoken English", ["Jacob Sager", "Ravi Shankar", "Jacob Reinhold", "Archana Venkataraman"], "https://doi.org/10.21437/Interspeech.2019-1413", 5, "interspeech", 2019], ["Weakly Supervised Syllable Segmentation by Vowel-Consonant Peak Classification", ["Ravi Shankar", "Archana Venkataraman"], "https://doi.org/10.21437/Interspeech.2019-1450", 5, "interspeech", 2019], ["A Multi-Speaker Emotion Morphing Model Using Highway Networks and Maximum Likelihood Objective", ["Ravi Shankar", "Jacob Sager", "Archana Venkataraman"], "https://doi.org/10.21437/Interspeech.2019-2512", 5, "interspeech", 2019], ["Automated Emotion Morphing in Speech Based on Diffeomorphic Curve Registration and Highway Networks", ["Ravi Shankar", "Hsi-Wei Hsieh", "Nicolas Charon", "Archana Venkataraman"], "https://doi.org/10.21437/Interspeech.2019-2386", 5, "interspeech", 2019]], "Jana Vosse": [0, ["A User-Friendly and Adaptable Re-Implementation of an Acoustic Prominence Detection and Annotation Tool", ["Jana Vosse", "Petra Wagner"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8015.html", 2, "interspeech", 2019]], "Mu Yang": [0.0004269026394467801, ["Spoken Language Intent Detection Using Confusion2Vec", ["Prashanth Gurunath Shivakumar", "Mu Yang", "Panayiotis G. Georgiou"], "https://doi.org/10.21437/Interspeech.2019-2226", 5, "interspeech", 2019]], "Olga Egorow": [0, ["Employing Bottleneck and Convolutional Features for Speech-Based Physical Load Detection on Limited Data Amounts", ["Olga Egorow", "Tarik Mrech", "Norman Weisskirchen", "Andreas Wendemuth"], "https://doi.org/10.21437/Interspeech.2019-2502", 5, "interspeech", 2019]], "Ruchir Travadi": [0, ["Multi-Task Discriminative Training of Hybrid DNN-TVM Model for Speaker Verification with Noisy and Far-Field Speech", ["Arindam Jati", "Raghuveer Peri", "Monisankha Pal", "Tae Jin Park", "Naveen Kumar", "Ruchir Travadi", "Panayiotis G. Georgiou", "Shrikanth Narayanan"], "https://doi.org/10.21437/Interspeech.2019-3010", 5, "interspeech", 2019]], "Jacques Felblinger": [0, ["A Multimodal Real-Time MRI Articulatory Corpus of French for Speech Research", ["Ioannis K. Douros", "Jacques Felblinger", "Jens Frahm", "Karyna Isaieva", "Arun A. Joseph", "Yves Laprie", "Freddy Odille", "Anastasiia Tsukanova", "Dirk Voit", "Pierre-Andre Vuissoz"], "https://doi.org/10.21437/Interspeech.2019-1700", 5, "interspeech", 2019]], "Zhiqiang Lv": [0, ["Multimedia Simultaneous Translation System for Minority Language Communication with Mandarin", ["Shen Huang", "Bojie Hu", "Shan Huang", "Pengfei Hu", "Jian Kang", "Zhiqiang Lv", "Jinghao Yan", "Qi Ju", "Shiyin Kang", "Deyi Tuo", "Guangzhi Li", "Nurmemet Yolwas"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8020.html", 2, "interspeech", 2019]], "Shouye Peng": [0, ["Jointly Adversarial Enhancement Training for Robust End-to-End Speech Recognition", ["Bin Liu", "Shuai Nie", "Shan Liang", "Wenju Liu", "Meng Yu", "Lianwu Chen", "Shouye Peng", "Changliang Li"], "https://doi.org/10.21437/Interspeech.2019-1242", 5, "interspeech", 2019], ["Direction-Aware Speaker Beam for Multi-Channel Speaker Extraction", ["Guanjun Li", "Shan Liang", "Shuai Nie", "Wenju Liu", "Meng Yu", "Lianwu Chen", "Shouye Peng", "Changliang Li"], "https://doi.org/10.21437/Interspeech.2019-1474", 5, "interspeech", 2019]], "Zoltan Tuske": [0, ["Challenging the Boundaries of Speech Recognition: The MALACH Corpus", ["Michael Picheny", "Zoltan Tuske", "Brian Kingsbury", "Kartik Audhkhasi", "Xiaodong Cui", "George Saon"], "https://doi.org/10.21437/Interspeech.2019-1907", 5, "interspeech", 2019], ["Forget a Bit to Learn Better: Soft Forgetting for CTC-Based Automatic Speech Recognition", ["Kartik Audhkhasi", "George Saon", "Zoltan Tuske", "Brian Kingsbury", "Michael Picheny"], "https://doi.org/10.21437/Interspeech.2019-2841", 5, "interspeech", 2019], ["Detection and Recovery of OOVs for Improved English Broadcast News Captioning", ["Samuel Thomas", "Kartik Audhkhasi", "Zoltan Tuske", "Yinghui Huang", "Michael Picheny"], "https://doi.org/10.21437/Interspeech.2019-2793", 5, "interspeech", 2019], ["Advancing Sequence-to-Sequence Based Speech Recognition", ["Zoltan Tuske", "Kartik Audhkhasi", "George Saon"], "https://doi.org/10.21437/Interspeech.2019-3018", 5, "interspeech", 2019]], "Zhengqi Wen": [0, ["Forward-Backward Decoding for Regularizing End-to-End TTS", ["Yibin Zheng", "Xi Wang", "Lei He", "Shifeng Pan", "Frank K. Soong", "Zhengqi Wen", "Jianhua Tao"], "https://doi.org/10.21437/Interspeech.2019-2325", 5, "interspeech", 2019], ["A Time Delay Neural Network with Shared Weight Self-Attention for Small-Footprint Keyword Spotting", ["Ye Bai", "Jiangyan Yi", "Jianhua Tao", "Zhengqi Wen", "Zhengkun Tian", "Chenghao Zhao", "Cunhang Fan"], "https://doi.org/10.21437/Interspeech.2019-1676", 5, "interspeech", 2019], ["Learn Spelling from Teachers: Transferring Knowledge from Language Models to Sequence-to-Sequence Speech Recognition", ["Ye Bai", "Jiangyan Yi", "Jianhua Tao", "Zhengkun Tian", "Zhengqi Wen"], "https://doi.org/10.21437/Interspeech.2019-1554", 5, "interspeech", 2019], ["Self-Attention Transducers for End-to-End Speech Recognition", ["Zhengkun Tian", "Jiangyan Yi", "Jianhua Tao", "Ye Bai", "Zhengqi Wen"], "https://doi.org/10.21437/Interspeech.2019-2203", 5, "interspeech", 2019], ["Discriminative Learning for Monaural Speech Separation Using Deep Embedding Features", ["Cunhang Fan", "Bin Liu", "Jianhua Tao", "Jiangyan Yi", "Zhengqi Wen"], "https://doi.org/10.21437/Interspeech.2019-1940", 5, "interspeech", 2019]], "Marcin Plata": [0, ["Robust Bayesian and Light Neural Networks for Voice Spoofing Detection", ["Radoslaw Bialobrzeski", "Michal Kosmider", "Mateusz Matuszewski", "Marcin Plata", "Alexander Rakowski"], "https://doi.org/10.21437/Interspeech.2019-2676", 5, "interspeech", 2019]], "Xunying Liu": [0, ["Jointly Trained Conversion Model and WaveNet Vocoder for Non-Parallel Voice Conversion Using Mel-Spectrograms and Phonetic Posteriorgrams", ["Songxiang Liu", "Yuewen Cao", "Xixin Wu", "Lifa Sun", "Xunying Liu", "Helen Meng"], "https://doi.org/10.21437/Interspeech.2019-1316", 5, "interspeech", 2019], ["Fast DNN Acoustic Model Speaker Adaptation by Learning Hidden Unit Contribution Features", ["Xurong Xie", "Xunying Liu", "Tan Lee", "Lan Wang"], "https://doi.org/10.21437/Interspeech.2019-2050", 5, "interspeech", 2019], ["Extract, Adapt and Recognize: An End-to-End Neural Network for Corrupted Monaural Speech Recognition", ["Max W. Y. Lam", "Jun Wang", "Xunying Liu", "Helen Meng", "Dan Su", "Dong Yu"], "https://doi.org/10.21437/Interspeech.2019-1626", 5, "interspeech", 2019], ["LF-MMI Training of Bayesian and Gaussian Process Time Delay Neural Networks for Speech Recognition", ["Shoukang Hu", "Xurong Xie", "Shansong Liu", "Max W. Y. Lam", "Jianwei Yu", "Xixin Wu", "Xunying Liu", "Helen Meng"], "https://doi.org/10.21437/Interspeech.2019-2379", 5, "interspeech", 2019], ["Unsupervised Methods for Audio Classification from Lecture Discussion Recordings", ["Hang Su", "Borislav Dzodzo", "Xixin Wu", "Xunying Liu", "Helen Meng"], "https://doi.org/10.21437/Interspeech.2019-2384", 5, "interspeech", 2019], ["Comparative Study of Parametric and Representation Uncertainty Modeling for Recurrent Neural Network Language Models", ["Jianwei Yu", "Max W. Y. Lam", "Shoukang Hu", "Xixin Wu", "Xu Li", "Yuewen Cao", "Xunying Liu", "Helen Meng"], "https://doi.org/10.21437/Interspeech.2019-1927", 5, "interspeech", 2019], ["The CUHK Dysarthric Speech Recognition Systems for English and Cantonese", ["Shoukang Hu", "Shansong Liu", "Heng Fai Chang", "Mengzhe Geng", "Jiani Chen", "Lau Wing Chung", "To Ka Hei", "Jianwei Yu", "Ka Ho Wong", "Xunying Liu", "Helen Meng"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8047.html", 2, "interspeech", 2019], ["Exploiting Visual Features Using Bayesian Gated Neural Networks for Disordered Speech Recognition", ["Shansong Liu", "Shoukang Hu", "Yi Wang", "Jianwei Yu", "Rongfeng Su", "Xunying Liu", "Helen Meng"], "https://doi.org/10.21437/Interspeech.2019-1536", 5, "interspeech", 2019], ["On the Use of Pitch Features for Disordered Speech Recognition", ["Shansong Liu", "Shoukang Hu", "Xunying Liu", "Helen Meng"], "https://doi.org/10.21437/Interspeech.2019-2609", 5, "interspeech", 2019]], "Xizi Wei": [0, ["Neural Network-Based Modeling of Phonetic Durations", ["Xizi Wei", "Melvyn Hunt", "Adrian Skilling"], "https://doi.org/10.21437/Interspeech.2019-2102", 5, "interspeech", 2019]], "Hui Lu": [0, ["One-Shot Voice Conversion with Global Speaker Embeddings", ["Hui Lu", "Zhiyong Wu", "Dongyang Dai", "Runnan Li", "Shiyin Kang", "Jia Jia", "Helen Meng"], "https://doi.org/10.21437/Interspeech.2019-2365", 5, "interspeech", 2019]], "Sheng Li": [0, ["End-to-End Articulatory Attribute Modeling for Low-Resource Multilingual Speech Recognition", ["Sheng Li", "Chenchen Ding", "Xugang Lu", "Peng Shen", "Tatsuya Kawahara", "Hisashi Kawai"], "https://doi.org/10.21437/Interspeech.2019-2092", 5, "interspeech", 2019], ["Investigating Radical-Based End-to-End Speech Recognition Systems for Chinese Dialects and Japanese", ["Sheng Li", "Xugang Lu", "Chenchen Ding", "Peng Shen", "Tatsuya Kawahara", "Hisashi Kawai"], "https://doi.org/10.21437/Interspeech.2019-2104", 5, "interspeech", 2019], ["Class-Wise Centroid Distance Metric Learning for Acoustic Event Detection", ["Xugang Lu", "Peng Shen", "Sheng Li", "Yu Tsao", "Hisashi Kawai"], "https://doi.org/10.21437/Interspeech.2019-2271", 5, "interspeech", 2019], ["Improving Transformer-Based Speech Recognition Systems with Compressed Structure and Speech Attributes Augmentation", ["Sheng Li", "Dabre Raj", "Xugang Lu", "Peng Shen", "Tatsuya Kawahara", "Hisashi Kawai"], "https://doi.org/10.21437/Interspeech.2019-2112", 5, "interspeech", 2019]], "Yang Liu": [0, ["On the Role of Style in Parsing Speech with Neural Models", ["Trang Tran", "Jiahong Yuan", "Yang Liu", "Mari Ostendorf"], "https://doi.org/10.21437/Interspeech.2019-3122", 5, "interspeech", 2019]], "Giuseppe Riccardi": [0, ["Active Annotation: Bootstrapping Annotation Lexicon and Guidelines for Supervised NLU Learning", ["Federico Marinelli", "Alessandra Cervone", "Giuliano Tortoreto", "Evgeny A. Stepanov", "Giuseppe Di Fabbrizio", "Giuseppe Riccardi"], "https://doi.org/10.21437/Interspeech.2019-2537", 5, "interspeech", 2019], ["Modeling User Context for Valence Prediction from Narratives", ["Aniruddha Tammewar", "Alessandra Cervone", "Eva-Maria Messner", "Giuseppe Riccardi"], "https://doi.org/10.21437/Interspeech.2019-2489", 5, "interspeech", 2019], ["An Incremental Turn-Taking Model for Task-Oriented Dialog Systems", ["Andrei C. Coman", "Koichiro Yoshino", "Yukitoshi Murase", "Satoshi Nakamura", "Giuseppe Riccardi"], "https://doi.org/10.21437/Interspeech.2019-1826", 5, "interspeech", 2019]], "Shugong Xu": [0, ["Two-Stage Training for Chinese Dialect Recognition", ["Zongze Ren", "Guofu Yang", "Shugong Xu"], "https://doi.org/10.21437/Interspeech.2019-1522", 5, "interspeech", 2019]], "E. Felker": [0, ["Lexically Guided Perceptual Learning of a Vowel Shift in an Interactive L2 Listening Context", ["E. Felker", "Mirjam Ernestus", "Mirjam Broersma"], "https://doi.org/10.21437/Interspeech.2019-1414", 5, "interspeech", 2019]], "Like Hui": [0, ["Kernel Machines Beat Deep Neural Networks on Mask-Based Single-Channel Speech Enhancement", ["Like Hui", "Siyuan Ma", "Mikhail Belkin"], "https://doi.org/10.21437/Interspeech.2019-1344", 5, "interspeech", 2019]], "Abdullah Kayi": [0, ["A Highly Efficient Distributed Deep Learning System for Automatic Speech Recognition", ["Wei Zhang", "Xiaodong Cui", "Ulrich Finkler", "George Saon", "Abdullah Kayi", "Alper Buyuktosunoglu", "Brian Kingsbury", "David S. Kung", "Michael Picheny"], "https://doi.org/10.21437/Interspeech.2019-2700", 5, "interspeech", 2019]], "Sid-Ahmed Selouani": [0, ["Linear Discriminant Differential Evolution for Feature Selection in Emotional Speech Recognition", ["Soumaya Gharsellaoui", "Sid-Ahmed Selouani", "Mohammed Sidi Yakoub"], "https://doi.org/10.21437/Interspeech.2019-1218", 5, "interspeech", 2019]], "Barret Zoph": [0, ["SpecAugment: A Simple Data Augmentation Method for Automatic Speech Recognition", ["Daniel S. Park", "William Chan", "Yu Zhang", "Chung-Cheng Chiu", "Barret Zoph", "Ekin D. Cubuk", "Quoc V. Le"], "https://doi.org/10.21437/Interspeech.2019-2680", 5, "interspeech", 2019]], "Shashi Kumar": [0, ["Far-Field Speech Enhancement Using Heteroscedastic Autoencoder for Improved Speech Recognition", ["Shashi Kumar", "Shakti P. Rath"], "https://doi.org/10.21437/Interspeech.2019-2032", 5, "interspeech", 2019]], "Sungrack Yun": [0.9998851120471954, ["An End-to-End Text-Independent Speaker Verification Framework with a Keyword Adversarial Network", ["Sungrack Yun", "Janghoon Cho", "Jungyun Eum", "Wonil Chang", "Kyuwoong Hwang"], "https://doi.org/10.21437/Interspeech.2019-2208", 5, "interspeech", 2019]], "Thomas Pellegrini": [0, ["Char+CV-CTC: Combining Graphemes and Consonant/Vowel Units for CTC-Based ASR Using Multitask Learning", ["Abdelwahab Heba", "Thomas Pellegrini", "Jean-Pierre Lorre", "Regine Andre-Obrecht"], "https://doi.org/10.21437/Interspeech.2019-1975", 5, "interspeech", 2019], ["The Airbus Air Traffic Control Speech Recognition 2018 Challenge: Towards ATC Automatic Transcription and Call Sign Detection", ["Thomas Pellegrini", "Jerome Farinas", "Estelle Delpech", "Francois Lancelot"], "https://doi.org/10.21437/Interspeech.2019-1962", 5, "interspeech", 2019]], "Jordan R. Green": [0, ["Early Identification of Speech Changes Due to Amyotrophic Lateral Sclerosis Using Machine Classification", ["Sarah E. Gutz", "Jun Wang", "Yana Yunusova", "Jordan R. Green"], "https://doi.org/10.21437/Interspeech.2019-2967", 5, "interspeech", 2019], ["Vocal Biomarker Assessment Following Pediatric Traumatic Brain Injury: A Retrospective Cohort Study", ["Camille Noufi", "Adam C. Lammert", "Daryush D. Mehta", "James R. Williamson", "Gregory Ciccarelli", "Douglas E. Sturim", "Jordan R. Green", "Thomas F. Campbell", "Thomas F. Quatieri"], "https://doi.org/10.21437/Interspeech.2019-1200", 5, "interspeech", 2019], ["Use of Beiwe Smartphone App to Identify and Track Speech Decline in Amyotrophic Lateral Sclerosis (ALS)", ["Kathryn P. Connaghan", "Jordan R. Green", "Sabrina Paganoni", "James Chan", "Harli Weber", "Ella Collins", "Brian Richburg", "Marziye Eshghi", "Jukka-Pekka Onnela", "James D. Berry"], "https://doi.org/10.21437/Interspeech.2019-3126", 5, "interspeech", 2019], ["Profiling Speech Motor Impairments in Persons with Amyotrophic Lateral Sclerosis: An Acoustic-Based Approach", ["Hannah P. Rowe", "Jordan R. Green"], "https://doi.org/10.21437/Interspeech.2019-2911", 5, "interspeech", 2019], ["Reduced Task Adaptation in Alternating Motion Rate Tasks as an Early Marker of Bulbar Involvement in Amyotrophic Lateral Sclerosis", ["Marziye Eshghi", "Panying Rong", "Antje S. Mefferd", "Kaila L. Stipancic", "Yana Yunusova", "Jordan R. Green"], "https://doi.org/10.21437/Interspeech.2019-2546", 5, "interspeech", 2019]], "Shuzhuang Xu": [0, ["Direct F0 Estimation with Neural-Network-Based Regression", ["Shuzhuang Xu", "Hiroshi Shimodaira"], "https://doi.org/10.21437/Interspeech.2019-3267", 5, "interspeech", 2019]], "John R. Hershey": [0, ["VoiceFilter: Targeted Voice Separation by Speaker-Conditioned Spectrogram Masking", ["Quan Wang", "Hannah Muckenhirn", "Kevin W. Wilson", "Prashant Sridhar", "Zelin Wu", "John R. Hershey", "Rif A. Saurous", "Ron J. Weiss", "Ye Jia", "Ignacio Lopez-Moreno"], "https://doi.org/10.21437/Interspeech.2019-1101", 5, "interspeech", 2019], ["End-to-End Multilingual Multi-Speaker Speech Recognition", ["Hiroshi Seki", "Takaaki Hori", "Shinji Watanabe", "Jonathan Le Roux", "John R. Hershey"], "https://doi.org/10.21437/Interspeech.2019-3038", 5, "interspeech", 2019]], "Tomohiro Nagata": [0, ["Conversational and Social Laughter Synthesis with WaveNet", ["Hiroki Mori", "Tomohiro Nagata", "Yoshiko Arimoto"], "https://doi.org/10.21437/Interspeech.2019-2131", 4, "interspeech", 2019]], "Xiaoxue Gao": [0, ["NUS Speak-to-Sing: A Web Platform for Personalized Speech-to-Singing Conversion", ["Chitralekha Gupta", "Karthika Vijayan", "Bidisha Sharma", "Xiaoxue Gao", "Haizhou Li"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8041.html", 2, "interspeech", 2019]], "Anne Hermes": [0, ["Strength and Structure: Coupling Tones with Oral Constriction Gestures", ["Doris Mucke", "Anne Hermes", "Sam Tilsen"], "https://doi.org/10.21437/Interspeech.2019-2650", 5, "interspeech", 2019], ["Intragestural Variation in Natural Sentence Production: Essential Tremor Patients Treated with DBS", ["Anne Hermes", "Doris Mucke", "Tabea Thies", "Michael T. Barbe"], "https://doi.org/10.21437/Interspeech.2019-2389", 5, "interspeech", 2019]], "Van Tung Pham": [0, ["Constrained Output Embeddings for End-to-End Code-Switching Speech Recognition with Only Monolingual Data", ["Yerbolat Khassanov", "Haihua Xu", "Van Tung Pham", "Zhiping Zeng", "Eng Siong Chng", "Chongjia Ni", "Bin Ma"], "https://doi.org/10.21437/Interspeech.2019-1867", 5, "interspeech", 2019], ["On the End-to-End Solution to Mandarin-English Code-Switching Speech Recognition", ["Zhiping Zeng", "Yerbolat Khassanov", "Van Tung Pham", "Haihua Xu", "Eng Siong Chng", "Haizhou Li"], "https://doi.org/10.21437/Interspeech.2019-1429", 5, "interspeech", 2019], ["Enriching Rare Word Representations in Neural Language Models by Embedding Matrix Augmentation", ["Yerbolat Khassanov", "Zhiping Zeng", "Van Tung Pham", "Haihua Xu", "Eng Siong Chng"], "https://doi.org/10.21437/Interspeech.2019-1858", 5, "interspeech", 2019]], "Yonghong Yan": [0, ["Speaker-Invariant Feature-Mapping for Distant Speech Recognition via Adversarial Teacher-Student Learning", ["Long Wu", "Hangting Chen", "Li Wang", "Pengyuan Zhang", "Yonghong Yan"], "https://doi.org/10.21437/Interspeech.2019-2136", 5, "interspeech", 2019], ["Multi-Accent Adaptation Based on Gate Mechanism", ["Han Zhu", "Li Wang", "Pengyuan Zhang", "Yonghong Yan"], "https://doi.org/10.21437/Interspeech.2019-3155", 5, "interspeech", 2019], ["Online Hybrid CTC/Attention Architecture for End-to-End Speech Recognition", ["Haoran Miao", "Gaofeng Cheng", "Pengyuan Zhang", "Ta Li", "Yonghong Yan"], "https://doi.org/10.21437/Interspeech.2019-2018", 5, "interspeech", 2019], ["Target Speaker Recovery and Recognition Network with Average x-Vector and Global Training", ["Wenjie Li", "Pengyuan Zhang", "Yonghong Yan"], "https://doi.org/10.21437/Interspeech.2019-1692", 5, "interspeech", 2019], ["Character-Aware Sub-Word Level Language Modeling for Uyghur and Turkish ASR", ["Chang Liu", "Zhen Zhang", "Pengyuan Zhang", "Yonghong Yan"], "https://doi.org/10.21437/Interspeech.2019-1484", 5, "interspeech", 2019], ["A New Time-Frequency Attention Mechanism for TDNN and CNN-LSTM-TDNN, with Application to Language Identification", ["Xiaoxiao Miao", "Ian McLoughlin", "Yonghong Yan"], "https://doi.org/10.21437/Interspeech.2019-1256", 5, "interspeech", 2019]], "Nichola Lubold": [0, ["Do Conversational Partners Entrain on Articulatory Precision?", ["Nichola Lubold", "Stephanie A. Borrie", "Tyson S. Barrett", "Megan M. Willi", "Visar Berisha"], "https://doi.org/10.21437/Interspeech.2019-1786", 5, "interspeech", 2019]], "Stephanie Woolridge": [0, ["Objective Assessment of Social Skills Using Automated Language Analysis for Identification of Schizophrenia and Bipolar Disorder", ["Rohit Voleti", "Stephanie Woolridge", "Julie M. Liss", "Melissa Milanovic", "Christopher R. Bowie", "Visar Berisha"], "https://doi.org/10.21437/Interspeech.2019-2960", 5, "interspeech", 2019]], "Brendan Shillingford": [0, ["Large-Scale Visual Speech Recognition", ["Brendan Shillingford", "Yannis M. Assael", "Matthew W. Hoffman", "Thomas Paine", "Cian Hughes", "Utsav Prabhu", "Hank Liao", "Hasim Sak", "Kanishka Rao", "Lorrayne Bennett", "Marie Mulville", "Misha Denil", "Ben Coppin", "Ben Laurie", "Andrew W. Senior", "Nando de Freitas"], "https://doi.org/10.21437/Interspeech.2019-1669", 5, "interspeech", 2019]], "Graham Neubig": [0, ["Mitigating Noisy Inputs for Question Answering", ["Denis Peskov", "Joe Barrow", "Pedro Rodriguez", "Graham Neubig", "Jordan L. Boyd-Graber"], "https://doi.org/10.21437/Interspeech.2019-3154", 5, "interspeech", 2019]], "Franck Dernoncourt": [0, ["Exploiting Semi-Supervised Training Through a Dropout Regularization in End-to-End Speech Recognition", ["Subhadeep Dey", "Petr Motlicek", "Trung Bui", "Franck Dernoncourt"], "https://doi.org/10.21437/Interspeech.2019-3246", 5, "interspeech", 2019]], "Ryo Masumura": [0, ["Improving Conversation-Context Language Models with Multiple Spoken Language Understanding Models", ["Ryo Masumura", "Tomohiro Tanaka", "Atsushi Ando", "Hosana Kamiyama", "Takanobu Oba", "Satoshi Kobashikawa", "Yushi Aono"], "https://doi.org/10.21437/Interspeech.2019-1534", 5, "interspeech", 2019], ["End-to-End Automatic Speech Recognition with a Reconstruction Criterion Using Speech-to-Text and Text-to-Speech Encoder-Decoders", ["Ryo Masumura", "Hiroshi Sato", "Tomohiro Tanaka", "Takafumi Moriya", "Yusuke Ijima", "Takanobu Oba"], "https://doi.org/10.21437/Interspeech.2019-2111", 5, "interspeech", 2019], ["A Joint End-to-End and DNN-HMM Hybrid Automatic Speech Recognition System with Transferring Sharable Knowledge", ["Tomohiro Tanaka", "Ryo Masumura", "Takafumi Moriya", "Takanobu Oba", "Yushi Aono"], "https://doi.org/10.21437/Interspeech.2019-2263", 5, "interspeech", 2019], ["Speech Emotion Recognition Based on Multi-Label Emotion Existence Model", ["Atsushi Ando", "Ryo Masumura", "Hosana Kamiyama", "Satoshi Kobashikawa", "Yushi Aono"], "https://doi.org/10.21437/Interspeech.2019-2524", 5, "interspeech", 2019], ["Joint Maximization Decoder with Neural Converters for Fully Neural Network-Based Japanese Speech Recognition", ["Takafumi Moriya", "Jian Wang", "Tomohiro Tanaka", "Ryo Masumura", "Yusuke Shinohara", "Yoshikazu Yamaguchi", "Yushi Aono"], "https://doi.org/10.21437/Interspeech.2019-1558", 5, "interspeech", 2019]], "Stephanie Jackson": [0, ["Using Ultrasound Imaging to Create Augmented Visual Biofeedback for Articulatory Practice", ["Colin T. Annand", "Maurice Lamb", "Sarah Dugan", "Sarah R. Li", "Hannah M. Woeste", "T. Douglas Mast", "Michael A. Riley", "Jack A. Masterson", "Neeraja Mahalingam", "Kathryn J. Eary", "Caroline Spencer", "Suzanne Boyce", "Stephanie Jackson", "Anoosha Baxi", "Renee Seward"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8036.html", 2, "interspeech", 2019]], "Simon King": [0, ["Evaluating Near End Listening Enhancement Algorithms in Realistic Environments", ["Carol Chermaz", "Cassia Valentini-Botinhao", "Henning F. Schepker", "Simon King"], "https://doi.org/10.21437/Interspeech.2019-1800", 5, "interspeech", 2019], ["Investigating the Robustness of Sequence-to-Sequence Text-to-Speech Models to Imperfectly-Transcribed Training Data", ["Jason Fong", "Pilar Oplustil Gallegos", "Zack Hodari", "Simon King"], "https://doi.org/10.21437/Interspeech.2019-1824", 5, "interspeech", 2019], ["Using Pupil Dilation to Measure Cognitive Load When Listening to Text-to-Speech in Quiet and in Noise", ["Avashna Govender", "Anita E. Wagner", "Simon King"], "https://doi.org/10.21437/Interspeech.2019-1783", 5, "interspeech", 2019], ["Disentangling Style Factors from Speaker Representations", ["Jennifer Williams", "Simon King"], "https://doi.org/10.21437/Interspeech.2019-1769", 5, "interspeech", 2019], ["Improving Speech Synthesis with Discourse Relations", ["Adele Aubin", "Alessandra Cervone", "Oliver Watts", "Simon King"], "https://doi.org/10.21437/Interspeech.2019-1945", 5, "interspeech", 2019]], "Shadi Pirhosseinloo": [0, ["Monaural Speech Enhancement with Dilated Convolutions", ["Shadi Pirhosseinloo", "Jonathan S. Brumberg"], "https://doi.org/10.21437/Interspeech.2019-2782", 5, "interspeech", 2019]], "Michael T. Barbe": [0, ["Intragestural Variation in Natural Sentence Production: Essential Tremor Patients Treated with DBS", ["Anne Hermes", "Doris Mucke", "Tabea Thies", "Michael T. Barbe"], "https://doi.org/10.21437/Interspeech.2019-2389", 5, "interspeech", 2019]], "Li Wan": [0, ["Multi-Microphone Adaptive Noise Cancellation for Robust Hotword Detection", ["Yiteng Huang", "Turaj Zakizadeh Shabestary", "Alexander Gruenstein", "Li Wan"], "https://doi.org/10.21437/Interspeech.2019-3006", 5, "interspeech", 2019]], "Barry-John Theobald": [0, ["Mirroring to Build Trust in Digital Assistants", ["Katherine Metcalf", "Barry-John Theobald", "Garrett Weinberg", "Robert Lee", "Ing-Marie Jonsson", "Russ Webb", "Nicholas Apostoloff"], "https://doi.org/10.21437/Interspeech.2019-1829", 5, "interspeech", 2019]], "Anton Batliner": [0, ["The INTERSPEECH 2019 Computational Paralinguistics Challenge: Styrian Dialects, Continuous Sleepiness, Baby Sounds & Orca Activity", ["Bjorn W. Schuller", "Anton Batliner", "Christian Bergler", "Florian B. Pokorny", "Jarek Krajewski", "Margaret Cychosz", "Ralf Vollmann", "Sonja-Dana Roelen", "Sebastian Schnieder", "Elika Bergelson", "Alejandrina Cristia", "Amanda Seidl", "Anne S. Warlaumont", "Lisa Yankowitz", "Elmar Noth", "Shahin Amiriparian", "Simone Hantke", "Maximilian Schmitt"], "https://doi.org/10.21437/Interspeech.2019-1122", 5, "interspeech", 2019]], "Antoine Caubriere": [0, ["Investigating Adaptation and Transfer Learning for End-to-End Spoken Language Understanding from Speech", ["Natalia Tomashenko", "Antoine Caubriere", "Yannick Esteve"], "https://doi.org/10.21437/Interspeech.2019-2158", 5, "interspeech", 2019], ["Curriculum-Based Transfer Learning for an Effective End-to-End Spoken Language Understanding and Domain Portability", ["Antoine Caubriere", "Natalia A. Tomashenko", "Antoine Laurent", "Emmanuel Morin", "Nathalie Camelin", "Yannick Esteve"], "https://doi.org/10.21437/Interspeech.2019-1832", 5, "interspeech", 2019]], "Bojie Hu": [0, ["Multimedia Simultaneous Translation System for Minority Language Communication with Mandarin", ["Shen Huang", "Bojie Hu", "Shan Huang", "Pengfei Hu", "Jian Kang", "Zhiqiang Lv", "Jinghao Yan", "Qi Ju", "Shiyin Kang", "Deyi Tuo", "Guangzhi Li", "Nurmemet Yolwas"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8020.html", 2, "interspeech", 2019]], "Takanobu Oba": [0, ["Improving Conversation-Context Language Models with Multiple Spoken Language Understanding Models", ["Ryo Masumura", "Tomohiro Tanaka", "Atsushi Ando", "Hosana Kamiyama", "Takanobu Oba", "Satoshi Kobashikawa", "Yushi Aono"], "https://doi.org/10.21437/Interspeech.2019-1534", 5, "interspeech", 2019], ["End-to-End Automatic Speech Recognition with a Reconstruction Criterion Using Speech-to-Text and Text-to-Speech Encoder-Decoders", ["Ryo Masumura", "Hiroshi Sato", "Tomohiro Tanaka", "Takafumi Moriya", "Yusuke Ijima", "Takanobu Oba"], "https://doi.org/10.21437/Interspeech.2019-2111", 5, "interspeech", 2019], ["A Joint End-to-End and DNN-HMM Hybrid Automatic Speech Recognition System with Transferring Sharable Knowledge", ["Tomohiro Tanaka", "Ryo Masumura", "Takafumi Moriya", "Takanobu Oba", "Yushi Aono"], "https://doi.org/10.21437/Interspeech.2019-2263", 5, "interspeech", 2019]], "Kimberley Mulder": [0, ["Phase Synchronization Between EEG Signals as a Function of Differences Between Stimuli Characteristics", ["Louis ten Bosch", "Kimberley Mulder", "Louis Boves"], "https://doi.org/10.21437/Interspeech.2019-2443", 5, "interspeech", 2019], ["Analyzing Reaction Time and Error Sequences in Lexical Decision Experiments", ["Louis ten Bosch", "Lou Boves", "Kimberley Mulder"], "https://doi.org/10.21437/Interspeech.2019-2611", 5, "interspeech", 2019]], "Nuno Almeida": [0, ["Exploring Critical Articulator Identification from 50Hz RT-MRI Data of the Vocal Tract", ["Samuel S. Silva", "Antonio J. S. Teixeira", "Conceicao Cunha", "Nuno Almeida", "Arun A. Joseph", "Jens Frahm"], "https://doi.org/10.21437/Interspeech.2019-2897", 5, "interspeech", 2019]], "Brian O Raghallaigh": [0, ["All Together Now: The Living Audio Dataset", ["David A. Braude", "Matthew P. Aylett", "Caoimhin Laoide-Kemp", "Simone Ashby", "Kristen M. Scott", "Brian O Raghallaigh", "Anna Braudo", "Alex Brouwer", "Adriana Stan"], "https://doi.org/10.21437/Interspeech.2019-2448", 5, "interspeech", 2019]], "Laurent El Shafey": [0, ["Joint Speech Recognition and Speaker Diarization via Sequence Transduction", ["Laurent El Shafey", "Hagen Soltau", "Izhak Shafran"], "https://doi.org/10.21437/Interspeech.2019-1943", 5, "interspeech", 2019]], "Alfred Mertins": [0, ["Spatio-Temporal Attention Pooling for Audio Scene Classification", ["Huy Phan", "Oliver Y. Chen", "Lam Pham", "Philipp Koch", "Maarten De Vos", "Ian Vince McLoughlin", "Alfred Mertins"], "https://doi.org/10.21437/Interspeech.2019-3040", 5, "interspeech", 2019]], "Youzhi Tu": [0, ["Variational Domain Adversarial Learning for Speaker Verification", ["Youzhi Tu", "Man-Wai Mak", "Jen-Tzung Chien"], "https://doi.org/10.21437/Interspeech.2019-2168", 5, "interspeech", 2019]], "Jun Ma": [0, ["Cross-Lingual, Multi-Speaker Text-To-Speech Synthesis Using Neural Speaker Embedding", ["Mengnan Chen", "Minchuan Chen", "Shuang Liang", "Jun Ma", "Lei Chen", "Shaojun Wang", "Jing Xiao"], "https://doi.org/10.21437/Interspeech.2019-1632", 5, "interspeech", 2019]], "Shankar Ananthakrishnan": [0, ["One-vs-All Models for Asynchronous Training: An Empirical Analysis", ["Rahul Gupta", "Aman Alok", "Shankar Ananthakrishnan"], "https://doi.org/10.21437/Interspeech.2019-2760", 5, "interspeech", 2019]], "Alexei Kochetov": [0, ["Articulatory Characteristics of Secondary Palatalization in Romanian Fricatives", ["Laura Spinu", "Maida Percival", "Alexei Kochetov"], "https://doi.org/10.21437/Interspeech.2019-3039", 5, "interspeech", 2019]], "Yan Xiong": [0, ["Residual + Capsule Networks (ResCap) for Simultaneous Single-Channel Overlapped Keyword Recognition", ["Yan Xiong", "Visar Berisha", "Chaitali Chakrabarti"], "https://doi.org/10.21437/Interspeech.2019-2913", 5, "interspeech", 2019]], "Runnan Li": [0, ["One-Shot Voice Conversion with Global Speaker Embeddings", ["Hui Lu", "Zhiyong Wu", "Dongyang Dai", "Runnan Li", "Shiyin Kang", "Jia Jia", "Helen Meng"], "https://doi.org/10.21437/Interspeech.2019-2365", 5, "interspeech", 2019], ["Knowledge-Based Linguistic Encoding for End-to-End Mandarin Text-to-Speech Synthesis", ["Jingbei Li", "Zhiyong Wu", "Runnan Li", "Pengpeng Zhi", "Song Yang", "Helen Meng"], "https://doi.org/10.21437/Interspeech.2019-1118", 5, "interspeech", 2019]], "Monisankha Pal": [0, ["The Second DIHARD Challenge: System Description for USC-SAIL Team", ["Tae Jin Park", "Manoj Kumar", "Nikolaos Flemotomos", "Monisankha Pal", "Raghuveer Peri", "Rimita Lahiri", "Panayiotis G. Georgiou", "Shrikanth Narayanan"], "https://doi.org/10.21437/Interspeech.2019-1903", 5, "interspeech", 2019], ["Multi-Task Discriminative Training of Hybrid DNN-TVM Model for Speaker Verification with Noisy and Far-Field Speech", ["Arindam Jati", "Raghuveer Peri", "Monisankha Pal", "Tae Jin Park", "Naveen Kumar", "Ruchir Travadi", "Panayiotis G. Georgiou", "Shrikanth Narayanan"], "https://doi.org/10.21437/Interspeech.2019-3010", 5, "interspeech", 2019]], "Yuanjiang Cao": [0, ["Framewise Supervised Training Towards End-to-End Speech Recognition Models: First Results", ["Mohan Li", "Yuanjiang Cao", "Weicong Zhou", "Min Liu"], "https://doi.org/10.21437/Interspeech.2019-1117", 5, "interspeech", 2019]], "Rashmi Prasad": [0, ["Neural Transition Systems for Modeling Hierarchical Semantic Representations", ["Riyaz Ahmad Bhat", "John Chen", "Rashmi Prasad", "Srinivas Bangalore"], "https://doi.org/10.21437/Interspeech.2019-3075", 5, "interspeech", 2019]], "Marco A. Martinez Ramirez": [0, ["Ensemble Models for Spoofing Detection in Automatic Speaker Verification", ["Bhusan Chettri", "Daniel Stoller", "Veronica Morfi", "Marco A. Martinez Ramirez", "Emmanouil Benetos", "Bob L. Sturm"], "https://doi.org/10.21437/Interspeech.2019-2505", 5, "interspeech", 2019]], "Gang Liu": [0, ["Towards a Fault-Tolerant Speaker Verification System: A Regularization Approach to Reduce the Condition Number", ["Siqi Zheng", "Gang Liu", "Hongbin Suo", "Yun Lei"], "https://doi.org/10.21437/Interspeech.2019-1442", 5, "interspeech", 2019], ["Autoencoder-Based Semi-Supervised Curriculum Learning for Out-of-Domain Speaker Verification", ["Siqi Zheng", "Gang Liu", "Hongbin Suo", "Yun Lei"], "https://doi.org/10.21437/Interspeech.2019-1440", 5, "interspeech", 2019], ["An Online Attention-Based Model for Speech Recognition", ["Ruchao Fan", "Pan Zhou", "Wei Chen", "Jia Jia", "Gang Liu"], "https://doi.org/10.21437/Interspeech.2019-2218", 5, "interspeech", 2019]], "Janina Molczanow": [0, ["An Acoustic Study of Vowel Undershoot in a System with Several Degrees of Prominence", ["Janina Molczanow", "Beata Lukaszewicz", "Anna Lukaszewicz"], "https://doi.org/10.21437/Interspeech.2019-1806", 5, "interspeech", 2019]], "Mu-Yeol Choi": [0.9999386668205261, ["Extending an Acoustic Data-Driven Phone Set for Spontaneous Speech Recognition", ["Jeong-Uk Bang", "Mu-Yeol Choi", "Sang-Hun Kim", "Oh-Wook Kwon"], "https://doi.org/10.21437/Interspeech.2019-1979", 5, "interspeech", 2019]], "Panying Rong": [0, ["Reduced Task Adaptation in Alternating Motion Rate Tasks as an Early Marker of Bulbar Involvement in Amyotrophic Lateral Sclerosis", ["Marziye Eshghi", "Panying Rong", "Antje S. Mefferd", "Kaila L. Stipancic", "Yana Yunusova", "Jordan R. Green"], "https://doi.org/10.21437/Interspeech.2019-2546", 5, "interspeech", 2019]], "Kiyoshi Honda": [0, ["Individual Difference of Relative Tongue Size and its Acoustic Effects", ["Xiaohan Zhang", "Chongke Bi", "Kiyoshi Honda", "Wenhuan Lu", "Jianguo Wei"], "https://doi.org/10.21437/Interspeech.2019-2452", 5, "interspeech", 2019], ["Acoustic and Articulatory Study of Ewe Vowels: A Comparative Study of Male and Female", ["Kowovi Comivi Alowonou", "Jianguo Wei", "Wenhuan Lu", "Zhicheng Liu", "Kiyoshi Honda", "Jianwu Dang"], "https://doi.org/10.21437/Interspeech.2019-2196", 5, "interspeech", 2019]], "Robert Kjaran": [0, ["The Althingi ASR System", ["Inga Run Helgadottir", "Anna Bjork Nikulasdottir", "Michal Borsky", "Judy Y. Fong", "Robert Kjaran", "Jon Gudnason"], "https://doi.org/10.21437/Interspeech.2019-1248", 5, "interspeech", 2019]], "Sharon Peperkamp": [0, ["Compensation for French Liquid Deletion During Auditory Sentence Processing", ["Sharon Peperkamp", "Alvaro Martin Iturralde Zurita"], "https://doi.org/10.21437/Interspeech.2019-2950", 5, "interspeech", 2019], ["The Different Roles of Expectations in Phonetic and Lexical Processing", ["Shiri Lev-Ari", "Robin Dodsworth", "Jeff Mielke", "Sharon Peperkamp"], "https://doi.org/10.21437/Interspeech.2019-1795", 5, "interspeech", 2019], ["Liquid Deletion in French Child-Directed Speech", ["Sharon Peperkamp", "Monica Hegde", "Maria Julia Carbajal"], "https://doi.org/10.21437/Interspeech.2019-2838", 5, "interspeech", 2019]], "Alan McCree": [0, ["Speaker Diarization Using Leave-One-Out Gaussian PLDA Clustering of DNN Embeddings", ["Alan McCree", "Gregory Sell", "Daniel Garcia-Romero"], "https://doi.org/10.21437/Interspeech.2019-2912", 5, "interspeech", 2019], ["State-of-the-Art Speaker Recognition for Telephone and Video Speech: The JHU-MIT Submission for NIST SRE18", ["Jesus Villalba", "Nanxin Chen", "David Snyder", "Daniel Garcia-Romero", "Alan McCree", "Gregory Sell", "Jonas Borgstrom", "Fred Richardson", "Suwon Shon", "Francois Grondin", "Reda Dehak", "Leibny Paola Garcia-Perera", "Daniel Povey", "Pedro A. Torres-Carrasquillo", "Sanjeev Khudanpur", "Najim Dehak"], "https://doi.org/10.21437/Interspeech.2019-2713", 5, "interspeech", 2019], ["x-Vector DNN Refinement with Full-Length Recordings for Speaker Recognition", ["Daniel Garcia-Romero", "David Snyder", "Gregory Sell", "Alan McCree", "Daniel Povey", "Sanjeev Khudanpur"], "https://doi.org/10.21437/Interspeech.2019-2205", 4, "interspeech", 2019], ["Speaker Recognition Benchmark Using the CHiME-5 Corpus", ["Daniel Garcia-Romero", "David Snyder", "Shinji Watanabe", "Gregory Sell", "Alan McCree", "Daniel Povey", "Sanjeev Khudanpur"], "https://doi.org/10.21437/Interspeech.2019-2174", 5, "interspeech", 2019]], "Radhika Arava": [0, ["Two Tiered Distributed Training Algorithm for Acoustic Modeling", ["Pranav Ladkat", "Oleg Rybakov", "Radhika Arava", "Sree Hari Krishnan Parthasarathi", "I-Fan Chen", "Nikko Strom"], "https://doi.org/10.21437/Interspeech.2019-1859", 5, "interspeech", 2019]], "Bowen Shi": [0, ["Compression of Acoustic Event Detection Models with Quantized Distillation", ["Bowen Shi", "Ming Sun", "Chieh-Chi Kao", "Viktor Rozgic", "Spyros Matsoukas", "Chao Wang"], "https://doi.org/10.21437/Interspeech.2019-1747", 5, "interspeech", 2019], ["On the Contributions of Visual and Textual Supervision in Low-Resource Semantic Speech Retrieval", ["Ankita Pasad", "Bowen Shi", "Herman Kamper", "Karen Livescu"], "https://doi.org/10.21437/Interspeech.2019-3051", 5, "interspeech", 2019]], "Devang Naik": [0, ["Leveraging Acoustic Cues and Paralinguistic Embeddings to Detect Expression from Voice", ["Vikramjit Mitra", "Sue Booker", "Erik Marchi", "David Scott Farrar", "Ute Dorothea Peitz", "Bridget Cheng", "Ermine Teves", "Anuj Mehta", "Devang Naik"], "https://doi.org/10.21437/Interspeech.2019-2998", 5, "interspeech", 2019]], "Xihong Wu": [0.0003008982093888335, ["Effects of Spectral and Temporal Cues to Mandarin Concurrent-Vowels Identification for Normal-Hearing and Hearing-Impaired Listeners", ["Zhen Fu", "Xihong Wu", "Jing Chen"], "https://doi.org/10.21437/Interspeech.2019-3209", 5, "interspeech", 2019]], "Sunil Kumar Kopparapu": [0, ["End-to-End Spoken Language Understanding: Bootstrapping in Low Resource Scenarios", ["Swapnil Bhosale", "Imran Sheikh", "Sri Harsha Dumpala", "Sunil Kumar Kopparapu"], "https://doi.org/10.21437/Interspeech.2019-2366", 5, "interspeech", 2019], ["Front-End Feature Compensation and Denoising for Noise Robust Speech Emotion Recognition", ["Rupayan Chakraborty", "Ashish Panda", "Meghna Pandharipande", "Sonal Joshi", "Sunil Kumar Kopparapu"], "https://doi.org/10.21437/Interspeech.2019-2243", 5, "interspeech", 2019]], "Viktor Rozgic": [0, ["Compression of Acoustic Event Detection Models with Quantized Distillation", ["Bowen Shi", "Ming Sun", "Chieh-Chi Kao", "Viktor Rozgic", "Spyros Matsoukas", "Chao Wang"], "https://doi.org/10.21437/Interspeech.2019-1747", 5, "interspeech", 2019]], "Julie M. Liss": [0, ["Objective Assessment of Social Skills Using Automated Language Analysis for Identification of Schizophrenia and Bipolar Disorder", ["Rohit Voleti", "Stephanie Woolridge", "Julie M. Liss", "Melissa Milanovic", "Christopher R. Bowie", "Visar Berisha"], "https://doi.org/10.21437/Interspeech.2019-2960", 5, "interspeech", 2019]], "Hongwei Song": [9.227629860220077e-08, ["Acoustic Scene Classification by Implicitly Identifying Distinct Sound Events", ["Hongwei Song", "Jiqing Han", "Shiwen Deng", "Zhihao Du"], "https://doi.org/10.21437/Interspeech.2019-2231", 5, "interspeech", 2019]], "Jack Serrino": [0, ["Contextual Recovery of Out-of-Lattice Named Entities in Automatic Speech Recognition", ["Jack Serrino", "Leonid Velikovich", "Petar S. Aleksic", "Cyril Allauzen"], "https://doi.org/10.21437/Interspeech.2019-2962", 5, "interspeech", 2019]], "Batushiren": [0, ["UNetGAN: A Robust Speech Enhancement Approach in Time Domain for Extremely Low Signal-to-Noise Ratio Condition", ["Xiang Hao", "Xiangdong Su", "Zhiyu Wang", "Hui Zhang", "Batushiren"], "https://doi.org/10.21437/Interspeech.2019-1567", 5, "interspeech", 2019]], "Steve Renals": [0, ["Ultrasound Tongue Imaging for Diarization and Alignment of Child Speech Therapy Sessions", ["Manuel Sam Ribeiro", "Aciel Eshky", "Korin Richmond", "Steve Renals"], "https://doi.org/10.21437/Interspeech.2019-2612", 5, "interspeech", 2019], ["Untranscribed Web Audio for Low Resource Speech Recognition", ["Andrea Carmantini", "Peter Bell", "Steve Renals"], "https://doi.org/10.21437/Interspeech.2019-2623", 5, "interspeech", 2019], ["Trainable Dynamic Subsampling for End-to-End Speech Recognition", ["Shucong Zhang", "Erfan Loweimi", "Yumo Xu", "Peter Bell", "Steve Renals"], "https://doi.org/10.21437/Interspeech.2019-2778", 5, "interspeech", 2019], ["Lattice-Based Lightly-Supervised Acoustic Model Training", ["Joachim Fainberg", "Ondrej Klejch", "Steve Renals", "Peter Bell"], "https://doi.org/10.21437/Interspeech.2019-2533", 5, "interspeech", 2019], ["On Learning Interpretable CNNs with Parametric Modulated Kernel-Based Filters", ["Erfan Loweimi", "Peter Bell", "Steve Renals"], "https://doi.org/10.21437/Interspeech.2019-1257", 5, "interspeech", 2019], ["Synchronising Audio and Ultrasound by Learning Cross-Modal Embeddings", ["Aciel Eshky", "Manuel Sam Ribeiro", "Korin Richmond", "Steve Renals"], "https://doi.org/10.21437/Interspeech.2019-1804", 5, "interspeech", 2019]], "Andrew Zisserman": [0, ["My Lips Are Concealed: Audio-Visual Speech Enhancement Through Obstructions", ["Triantafyllos Afouras", "Joon Son Chung", "Andrew Zisserman"], "https://doi.org/10.21437/Interspeech.2019-3114", 5, "interspeech", 2019]], "Ivan Medennikov": [0, ["R-Vectors: New Technique for Adaptation to Room Acoustics", ["Yuri Y. Khokhlov", "Alexander Zatvornitskiy", "Ivan Medennikov", "Ivan Sorokin", "Tatiana Prisyach", "Aleksei Romanenko", "Anton Mitrofanov", "Vladimir Bataev", "Andrei Andrusenko", "Mariya Korenevskaya", "Oleg Petrov"], "https://doi.org/10.21437/Interspeech.2019-2645", 5, "interspeech", 2019], ["The STC ASR System for the VOiCES from a Distance Challenge 2019", ["Ivan Medennikov", "Yuri Y. Khokhlov", "Aleksei Romanenko", "Ivan Sorokin", "Anton Mitrofanov", "Vladimir Bataev", "Andrei Andrusenko", "Tatiana Prisyach", "Mariya Korenevskaya", "Oleg Petrov", "Alexander Zatvornitskiy"], "https://doi.org/10.21437/Interspeech.2019-1574", 5, "interspeech", 2019], ["The STC ASR System for the VOiCES from a Distance Challenge 2019", ["Ivan Medennikov", "Yuri Y. Khokhlov", "Aleksei Romanenko", "Ivan Sorokin", "Anton Mitrofanov", "Vladimir Bataev", "Andrei Andrusenko", "Tatiana Prisyach", "Mariya Korenevskaya", "Oleg Petrov", "Alexander Zatvornitskiy"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/abs17.html", 0, "interspeech", 2019]], "Raquel Sitman": [0, ["GECKO - A Tool for Effective Annotation of Human Conversations", ["Golan Levy", "Raquel Sitman", "Ido Amir", "Eduard Golshtein", "Ran Mochary", "Eilon Reshef", "Roi Reichart", "Omri Allouche"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8025.html", 2, "interspeech", 2019]], "Sibo Tong": [0, ["Unbiased Semi-Supervised LF-MMI Training Using Dropout", ["Sibo Tong", "Apoorv Vyas", "Philip N. Garner", "Herve Bourlard"], "https://doi.org/10.21437/Interspeech.2019-2678", 5, "interspeech", 2019]], "Joao Magalhaes": [0, ["Sustained Vowel Game: A Computer Therapy Game for Children with Dysphonia", ["Vanessa Lopes", "Joao Magalhaes", "Sofia Cavaco"], "https://doi.org/10.21437/Interspeech.2019-3017", 5, "interspeech", 2019]], "Katsuya Yokoyama": [0, ["Recognition of Intentions of Users' Short Responses for Conversational News Delivery System", ["Hiroaki Takatsu", "Katsuya Yokoyama", "Yoichi Matsuyama", "Hiroshi Honda", "Shinya Fujie", "Tetsunori Kobayashi"], "https://doi.org/10.21437/Interspeech.2019-2121", 5, "interspeech", 2019]], "Jianze Li": [0, ["Automatic Detection of the Temporal Segmentation of Hand Movements in British English Cued Speech", ["Li Liu", "Jianze Li", "Gang Feng", "Xiao-Ping Steven Zhang"], "https://doi.org/10.21437/Interspeech.2019-2353", 5, "interspeech", 2019]], "Yoshua Bengio": [0, ["Learning Problem-Agnostic Speech Representations from Multiple Self-Supervised Tasks", ["Santiago Pascual", "Mirco Ravanelli", "Joan Serra", "Antonio Bonafonte", "Yoshua Bengio"], "https://doi.org/10.21437/Interspeech.2019-2605", 5, "interspeech", 2019], ["Speech Model Pre-Training for End-to-End Spoken Language Understanding", ["Loren Lugosch", "Mirco Ravanelli", "Patrick Ignoto", "Vikrant Singh Tomar", "Yoshua Bengio"], "https://doi.org/10.21437/Interspeech.2019-2396", 5, "interspeech", 2019], ["Learning Speaker Representations with Mutual Information", ["Mirco Ravanelli", "Yoshua Bengio"], "https://doi.org/10.21437/Interspeech.2019-2380", 5, "interspeech", 2019]], "Jurgen Trouvain": [0, ["Towards an Annotation Scheme for Complex Laughter in Speech Corpora", ["Khiet P. Truong", "Jurgen Trouvain", "Michel-Pierre Jansen"], "https://doi.org/10.21437/Interspeech.2019-1557", 5, "interspeech", 2019]], "Tokihiko Kaburagi": [0, ["A Study of Soprano Singing in Light of the Source-Filter Interaction", ["Tokihiko Kaburagi"], "https://doi.org/10.21437/Interspeech.2019-1153", 5, "interspeech", 2019]], "Ken-Ichi Sakakibara": [0, ["Investigating the Physiological and Acoustic Contrasts Between Choral and Operatic Singing", ["Hiroko Terasawa", "Kenta Wakasa", "Hideki Kawahara", "Ken-Ichi Sakakibara"], "https://doi.org/10.21437/Interspeech.2019-1864", 5, "interspeech", 2019]], "Simone Hantke": [0, ["The INTERSPEECH 2019 Computational Paralinguistics Challenge: Styrian Dialects, Continuous Sleepiness, Baby Sounds & Orca Activity", ["Bjorn W. Schuller", "Anton Batliner", "Christian Bergler", "Florian B. Pokorny", "Jarek Krajewski", "Margaret Cychosz", "Ralf Vollmann", "Sonja-Dana Roelen", "Sebastian Schnieder", "Elika Bergelson", "Alejandrina Cristia", "Amanda Seidl", "Anne S. Warlaumont", "Lisa Yankowitz", "Elmar Noth", "Shahin Amiriparian", "Simone Hantke", "Maximilian Schmitt"], "https://doi.org/10.21437/Interspeech.2019-1122", 5, "interspeech", 2019]], "Ye Jia": [0, ["Direct Speech-to-Speech Translation with a Sequence-to-Sequence Model", ["Ye Jia", "Ron J. Weiss", "Fadi Biadsy", "Wolfgang Macherey", "Melvin Johnson", "Zhifeng Chen", "Yonghui Wu"], "https://doi.org/10.21437/Interspeech.2019-1951", 5, "interspeech", 2019], ["LibriTTS: A Corpus Derived from LibriSpeech for Text-to-Speech", ["Heiga Zen", "Viet Dang", "Rob Clark", "Yu Zhang", "Ron J. Weiss", "Ye Jia", "Zhifeng Chen", "Yonghui Wu"], "https://doi.org/10.21437/Interspeech.2019-2441", 5, "interspeech", 2019], ["Learning to Speak Fluently in a Foreign Language: Multilingual Speech Synthesis and Cross-Language Voice Cloning", ["Yu Zhang", "Ron J. Weiss", "Heiga Zen", "Yonghui Wu", "Zhifeng Chen", "R. J. Skerry-Ryan", "Ye Jia", "Andrew Rosenberg", "Bhuvana Ramabhadran"], "https://doi.org/10.21437/Interspeech.2019-2668", 5, "interspeech", 2019], ["VoiceFilter: Targeted Voice Separation by Speaker-Conditioned Spectrogram Masking", ["Quan Wang", "Hannah Muckenhirn", "Kevin W. Wilson", "Prashant Sridhar", "Zelin Wu", "John R. Hershey", "Rif A. Saurous", "Ron J. Weiss", "Ye Jia", "Ignacio Lopez-Moreno"], "https://doi.org/10.21437/Interspeech.2019-1101", 5, "interspeech", 2019], ["Parrotron: An End-to-End Speech-to-Speech Conversion Model and its Applications to Hearing-Impaired Speech and Speech Separation", ["Fadi Biadsy", "Ron J. Weiss", "Pedro J. Moreno", "Dimitri Kanvesky", "Ye Jia"], "https://doi.org/10.21437/Interspeech.2019-1789", 5, "interspeech", 2019]], "Han Zhu": [0, ["Multi-Accent Adaptation Based on Gate Mechanism", ["Han Zhu", "Li Wang", "Pengyuan Zhang", "Yonghong Yan"], "https://doi.org/10.21437/Interspeech.2019-3155", 5, "interspeech", 2019]], "Cecilia Ovesdotter Alm": [0, ["Fusion Strategy for Prosodic and Lexical Representations of Word Importance", ["Sushant Kafle", "Cecilia Ovesdotter Alm", "Matt Huenerfauth"], "https://doi.org/10.21437/Interspeech.2019-1898", 5, "interspeech", 2019], ["Synthesized Spoken Names: Biases Impacting Perception", ["Lucas Kessler", "Cecilia Ovesdotter Alm", "Reynold Bailey"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8031.html", 2, "interspeech", 2019]], "Vijay Ramaseshan Chandrasekhar": [0, ["Semi-Supervised Audio Classification with Consistency-Based Regularization", ["Kangkang Lu", "Chuan-Sheng Foo", "Kah Kuan Teh", "Huy Dat Tran", "Vijay Ramaseshan Chandrasekhar"], "https://doi.org/10.21437/Interspeech.2019-1231", 5, "interspeech", 2019]], "Yuan-Hao Yi": [1.506132818462902e-07, ["Singing Voice Synthesis Using Deep Autoregressive Neural Networks for Acoustic Modeling", ["Yuan-Hao Yi", "Yang Ai", "Zhen-Hua Ling", "Li-Rong Dai"], "https://doi.org/10.21437/Interspeech.2019-1563", 5, "interspeech", 2019]], "Irit Opher": [0, ["Identifying Distinctive Acoustic and Spectral Features in Parkinson's Disease", ["Yermiyahu Hauptman", "Ruth Aloni-Lavi", "Itshak Lapidot", "Tanya Gurevich", "Yael Manor", "Stav Naor", "Noa Diamant", "Irit Opher"], "https://doi.org/10.21437/Interspeech.2019-2465", 5, "interspeech", 2019]], "Triantafyllos Afouras": [0, ["My Lips Are Concealed: Audio-Visual Speech Enhancement Through Obstructions", ["Triantafyllos Afouras", "Joon Son Chung", "Andrew Zisserman"], "https://doi.org/10.21437/Interspeech.2019-3114", 5, "interspeech", 2019]], "Matthew Paradis": [0, ["R2SPIN: Re-Recording the Revised Speech Perception in Noise Test", ["Lauren Ward", "Catherine Robinson", "Matthew Paradis", "Katherine M. Tucker", "Ben G. Shirley"], "https://doi.org/10.21437/Interspeech.2019-1281", 5, "interspeech", 2019]], "Meena Chandra Shekhar": [0, ["The 2019 Inaugural Fearless Steps Challenge: A Giant Leap for Naturalistic Audio", ["John H. L. Hansen", "Aditya Joglekar", "Meena Chandra Shekhar", "Vinay Kothapally", "Chengzhu Yu", "Lakshmish Kaushik", "Abhijeet Sangwan"], "https://doi.org/10.21437/Interspeech.2019-2301", 5, "interspeech", 2019]], "Chenghao Zhao": [0, ["A Time Delay Neural Network with Shared Weight Self-Attention for Small-Footprint Keyword Spotting", ["Ye Bai", "Jiangyan Yi", "Jianhua Tao", "Zhengqi Wen", "Zhengkun Tian", "Chenghao Zhao", "Cunhang Fan"], "https://doi.org/10.21437/Interspeech.2019-1676", 5, "interspeech", 2019]], "Zhifeng Chen": [0, ["Direct Speech-to-Speech Translation with a Sequence-to-Sequence Model", ["Ye Jia", "Ron J. Weiss", "Fadi Biadsy", "Wolfgang Macherey", "Melvin Johnson", "Zhifeng Chen", "Yonghui Wu"], "https://doi.org/10.21437/Interspeech.2019-1951", 5, "interspeech", 2019], ["LibriTTS: A Corpus Derived from LibriSpeech for Text-to-Speech", ["Heiga Zen", "Viet Dang", "Rob Clark", "Yu Zhang", "Ron J. Weiss", "Ye Jia", "Zhifeng Chen", "Yonghui Wu"], "https://doi.org/10.21437/Interspeech.2019-2441", 5, "interspeech", 2019], ["Learning to Speak Fluently in a Foreign Language: Multilingual Speech Synthesis and Cross-Language Voice Cloning", ["Yu Zhang", "Ron J. Weiss", "Heiga Zen", "Yonghui Wu", "Zhifeng Chen", "R. J. Skerry-Ryan", "Ye Jia", "Andrew Rosenberg", "Bhuvana Ramabhadran"], "https://doi.org/10.21437/Interspeech.2019-2668", 5, "interspeech", 2019], ["Large-Scale Multilingual Speech Recognition with a Streaming End-to-End Model", ["Anjuli Kannan", "Arindrima Datta", "Tara N. Sainath", "Eugene Weinstein", "Bhuvana Ramabhadran", "Yonghui Wu", "Ankur Bapna", "Zhifeng Chen", "Seungji Lee"], "https://doi.org/10.21437/Interspeech.2019-2858", 5, "interspeech", 2019]], "Fei Wu": [0.000492751831188798, ["Advances in Automatic Speech Recognition for Child Speech Using Factored Time Delay Neural Network", ["Fei Wu", "Leibny Paola Garcia-Perera", "Daniel Povey", "Sanjeev Khudanpur"], "https://doi.org/10.21437/Interspeech.2019-2980", 5, "interspeech", 2019]], "Karthik Krishnamurthy": [0, ["Integrating Video Retrieval and Moment Detection in a Unified Corpus for Video Question Answering", ["Hongyin Luo", "Mitra Mohtarami", "James R. Glass", "Karthik Krishnamurthy", "Brigitte Richardson"], "https://doi.org/10.21437/Interspeech.2019-1736", 5, "interspeech", 2019]], "Tom Backstrom": [0, ["End-to-End Optimization of Source Models for Speech and Audio Coding Using a Machine Learning Framework", ["Tom Backstrom"], "https://doi.org/10.21437/Interspeech.2019-1284", 5, "interspeech", 2019], ["Super-Wideband Spectral Envelope Modeling for Speech Coding", ["Guillaume Fuchs", "Chamran Ashour", "Tom Backstrom"], "https://doi.org/10.21437/Interspeech.2019-1620", 5, "interspeech", 2019], ["Sound Privacy: A Conversational Speech Corpus for Quantifying the Experience of Privacy", ["Pablo Perez Zarazaga", "Sneha Das", "Tom Backstrom", "Vishnu Vidyadhara Raju Vegesna", "Anil Kumar Vuppala"], "https://doi.org/10.21437/Interspeech.2019-1172", 5, "interspeech", 2019]], "Ankur T. Patil": [0, ["Energy Separation-Based Instantaneous Frequency Estimation for Cochlear Cepstral Feature for Replay Spoof Detection", ["Ankur T. Patil", "Rajul Acharya", "Pulikonda Krishna Aditya Sai", "Hemant A. Patil"], "https://doi.org/10.21437/Interspeech.2019-2742", 5, "interspeech", 2019]], "Eran Raveh": [0, ["Phonetic Accommodation in a Wizard-of-Oz Experiment: Intonation and Segments", ["Iona Gessinger", "Bernd Mobius", "Bistra Andreeva", "Eran Raveh", "Ingmar Steiner"], "https://doi.org/10.21437/Interspeech.2019-2445", 5, "interspeech", 2019], ["Three's a Crowd? Effects of a Second Human on Vocal Accommodation with a Voice Assistant", ["Eran Raveh", "Ingo Siegert", "Ingmar Steiner", "Iona Gessinger", "Bernd Mobius"], "https://doi.org/10.21437/Interspeech.2019-1825", 5, "interspeech", 2019]], "Adib Mehrabi": [0, ["An Articulatory-Acoustic Investigation into GOOSE-Fronting in German-English Bilinguals Residing in London, UK", ["Scott Lewis", "Adib Mehrabi", "Esther de Leeuw"], "https://doi.org/10.21437/Interspeech.2019-2637", 5, "interspeech", 2019]], "Motoyuki Suzuki": [0, ["Lyrics Recognition from Singing Voice Focused on Correspondence Between Voice and Notes", ["Motoyuki Suzuki", "Sho Tomita", "Tomoki Morita"], "https://doi.org/10.21437/Interspeech.2019-1318", 4, "interspeech", 2019]], "Chieh-Yu Chen": [0, ["Using Attention Networks and Adversarial Augmentation for Styrian Dialect Continuous Sleepiness and Baby Sound Recognition", ["Sung-Lin Yeh", "Gao-Yi Chao", "Bo-Hao Su", "Yu-Lin Huang", "Meng-Han Lin", "Yin-Chun Tsai", "Yu-Wen Tai", "Zheng-Chi Lu", "Chieh-Yu Chen", "Tsung-Ming Tai", "Chiu-Wang Tseng", "Cheng-Kuang Lee", "Chi-Chun Lee"], "https://doi.org/10.21437/Interspeech.2019-2110", 5, "interspeech", 2019]], "Negar Olfati": [0, ["A Phonetic-Level Analysis of Different Input Features for Articulatory Inversion", ["Abdolreza Sabzi Shahrebabaki", "Negar Olfati", "Ali Shariq Imran", "Sabato Marco Siniscalchi", "Torbjorn Svendsen"], "https://doi.org/10.21437/Interspeech.2019-2526", 5, "interspeech", 2019]], "Kris Tjaden": [0, ["Using a Manifold Vocoder for Spectral Voice and Style Conversion", ["Tuan Dinh", "Alexander Kain", "Kris Tjaden"], "https://doi.org/10.21437/Interspeech.2019-1176", 5, "interspeech", 2019]], "John Kane": [0, ["Gender De-Biasing in Speech Emotion Recognition", ["Cristina Gorrostieta", "Reza Lotfian", "Kye Taylor", "Richard Brutti", "John Kane"], "https://doi.org/10.21437/Interspeech.2019-1708", 5, "interspeech", 2019]], "Yibin Zheng": [0, ["Forward-Backward Decoding for Regularizing End-to-End TTS", ["Yibin Zheng", "Xi Wang", "Lei He", "Shifeng Pan", "Frank K. Soong", "Zhengqi Wen", "Jianhua Tao"], "https://doi.org/10.21437/Interspeech.2019-2325", 5, "interspeech", 2019]], "Guangzhi Li": [0, ["Multimedia Simultaneous Translation System for Minority Language Communication with Mandarin", ["Shen Huang", "Bojie Hu", "Shan Huang", "Pengfei Hu", "Jian Kang", "Zhiqiang Lv", "Jinghao Yan", "Qi Ju", "Shiyin Kang", "Deyi Tuo", "Guangzhi Li", "Nurmemet Yolwas"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8020.html", 2, "interspeech", 2019]], "Florian Lingenfelser": [0, ["Relevance-Based Feature Masking: Improving Neural Network Based Whale Classification Through Explainable Artificial Intelligence", ["Dominik Schiller", "Tobias Huber", "Florian Lingenfelser", "Michael Dietz", "Andreas Seiderer", "Elisabeth Andre"], "https://doi.org/10.21437/Interspeech.2019-2707", 5, "interspeech", 2019]], "Che-Ping Tsai": [0, ["Completely Unsupervised Phoneme Recognition by a Generative Adversarial Network Harmonized with Iteratively Refined Hidden Markov Models", ["Kuan-Yu Chen", "Che-Ping Tsai", "Da-Rong Liu", "Hung-yi Lee", "Lin-Shan Lee"], "https://doi.org/10.21437/Interspeech.2019-2068", 5, "interspeech", 2019]], "Matthew Sharifi": [0, ["Fr\u00e9chet Audio Distance: A Reference-Free Metric for Evaluating Music Enhancement Algorithms", ["Kevin Kilgour", "Mauricio Zuluaga", "Dominik Roblek", "Matthew Sharifi"], "https://doi.org/10.21437/Interspeech.2019-2219", 5, "interspeech", 2019], ["Low-Dimensional Bottleneck Features for On-Device Continuous Speech Recognition", ["David B. Ramsay", "Kevin Kilgour", "Dominik Roblek", "Matthew Sharifi"], "https://doi.org/10.21437/Interspeech.2019-2193", 4, "interspeech", 2019]], "Maximillian Paulus": [0, ["Talker Intelligibility and Listening Effort with Temporally Modified Speech", ["Maximillian Paulus", "Valerie Hazan", "Patti Adank"], "https://doi.org/10.21437/Interspeech.2019-1402", 5, "interspeech", 2019]], "Jonas Fromseier Mortensen": [0, ["Building Large-Vocabulary ASR Systems for Languages Without Any Audio Training Data", ["Manasa Prasad", "Daan van Esch", "Sandy Ritchie", "Jonas Fromseier Mortensen"], "https://doi.org/10.21437/Interspeech.2019-1775", 5, "interspeech", 2019], ["Developing Pronunciation Models in New Languages Faster by Exploiting Common Grapheme-to-Phoneme Correspondences Across Languages", ["Harry Bleyan", "Sandy Ritchie", "Jonas Fromseier Mortensen", "Daan van Esch"], "https://doi.org/10.21437/Interspeech.2019-1781", 5, "interspeech", 2019], ["Unified Verbalization for Speech Recognition & Synthesis Across Languages", ["Sandy Ritchie", "Richard Sproat", "Kyle Gorman", "Daan van Esch", "Christian Schallhart", "Nikos Bampounis", "Benoit Brard", "Jonas Fromseier Mortensen", "Millie Holt", "Eoin Mahon"], "https://doi.org/10.21437/Interspeech.2019-2807", 5, "interspeech", 2019]], "Tomi H. Kinnunen": [0, ["Unleashing the Unused Potential of i-Vectors Enabled by GPU Acceleration", ["Ville Vestman", "Kong Aik Lee", "Tomi H. Kinnunen", "Takafumi Koshinaka"], "https://doi.org/10.21437/Interspeech.2019-1955", 5, "interspeech", 2019], ["ASVspoof 2019: Future Horizons in Spoofed and Fake Audio Detection", ["Massimiliano Todisco", "Xin Wang", "Ville Vestman", "Md. Sahidullah", "Hector Delgado", "Andreas Nautsch", "Junichi Yamagishi", "Nicholas W. D. Evans", "Tomi H. Kinnunen", "Kong Aik Lee"], "https://doi.org/10.21437/Interspeech.2019-2249", 5, "interspeech", 2019], ["I4U Submission to NIST SRE 2018: Leveraging from a Decade of Shared Experiences", ["Kong Aik Lee", "Ville Hautamaki", "Tomi H. Kinnunen", "Hitoshi Yamamoto", "Koji Okabe", "Ville Vestman", "Jing Huang", "Guohong Ding", "Hanwu Sun", "Anthony Larcher", "Rohan Kumar Das", "Haizhou Li", "Mickael Rouvier", "Pierre-Michel Bousquet", "Wei Rao", "Qing Wang", "Chunlei Zhang", "Fahimeh Bahmaninezhad", "Hector Delgado", "Massimiliano Todisco"], "https://doi.org/10.21437/Interspeech.2019-1533", 5, "interspeech", 2019]], "Patrick Violette": [0, ["Improving Keyword Spotting and Language Identification via Neural Architecture Search at Scale", ["Hanna Mazzawi", "Xavi Gonzalvo", "Aleks Kracun", "Prashant Sridhar", "Niranjan Subrahmanya", "Ignacio Lopez-Moreno", "Hyun-Jin Park", "Patrick Violette"], "https://doi.org/10.21437/Interspeech.2019-1916", 5, "interspeech", 2019]], "Yonghui Wu": [0.6403691470623016, ["Direct Speech-to-Speech Translation with a Sequence-to-Sequence Model", ["Ye Jia", "Ron J. Weiss", "Fadi Biadsy", "Wolfgang Macherey", "Melvin Johnson", "Zhifeng Chen", "Yonghui Wu"], "https://doi.org/10.21437/Interspeech.2019-1951", 5, "interspeech", 2019], ["LibriTTS: A Corpus Derived from LibriSpeech for Text-to-Speech", ["Heiga Zen", "Viet Dang", "Rob Clark", "Yu Zhang", "Ron J. Weiss", "Ye Jia", "Zhifeng Chen", "Yonghui Wu"], "https://doi.org/10.21437/Interspeech.2019-2441", 5, "interspeech", 2019], ["Learning to Speak Fluently in a Foreign Language: Multilingual Speech Synthesis and Cross-Language Voice Cloning", ["Yu Zhang", "Ron J. Weiss", "Heiga Zen", "Yonghui Wu", "Zhifeng Chen", "R. J. Skerry-Ryan", "Ye Jia", "Andrew Rosenberg", "Bhuvana Ramabhadran"], "https://doi.org/10.21437/Interspeech.2019-2668", 5, "interspeech", 2019], ["Large-Scale Multilingual Speech Recognition with a Streaming End-to-End Model", ["Anjuli Kannan", "Arindrima Datta", "Tara N. Sainath", "Eugene Weinstein", "Bhuvana Ramabhadran", "Yonghui Wu", "Ankur Bapna", "Zhifeng Chen", "Seungji Lee"], "https://doi.org/10.21437/Interspeech.2019-2858", 5, "interspeech", 2019], ["Two-Pass End-to-End Speech Recognition", ["Tara N. Sainath", "Ruoming Pang", "David Rybach", "Yanzhang He", "Rohit Prabhavalkar", "Wei Li", "Mirko Visontai", "Qiao Liang", "Trevor Strohman", "Yonghui Wu", "Ian McGraw", "Chung-Cheng Chiu"], "https://doi.org/10.21437/Interspeech.2019-1341", 5, "interspeech", 2019]], "Purvi Agrawal": [0, ["Unsupervised Raw Waveform Representation Learning for ASR", ["Purvi Agrawal", "Sriram Ganapathy"], "https://doi.org/10.21437/Interspeech.2019-2652", 5, "interspeech", 2019]], "Qin Jin": [8.872806574800052e-05, ["Speech Emotion Recognition in Dyadic Dialogues with Attentive Interaction Modeling", ["Jinming Zhao", "Shizhe Chen", "Jingjun Liang", "Qin Jin"], "https://doi.org/10.21437/Interspeech.2019-2103", 5, "interspeech", 2019]], "Judy Y. Fong": [0, ["The Althingi ASR System", ["Inga Run Helgadottir", "Anna Bjork Nikulasdottir", "Michal Borsky", "Judy Y. Fong", "Robert Kjaran", "Jon Gudnason"], "https://doi.org/10.21437/Interspeech.2019-1248", 5, "interspeech", 2019]], "Nikolaos Flemotomos": [0, ["The Second DIHARD Challenge: System Description for USC-SAIL Team", ["Tae Jin Park", "Manoj Kumar", "Nikolaos Flemotomos", "Monisankha Pal", "Raghuveer Peri", "Rimita Lahiri", "Panayiotis G. Georgiou", "Shrikanth Narayanan"], "https://doi.org/10.21437/Interspeech.2019-1903", 5, "interspeech", 2019], ["Identifying Therapist and Client Personae for Therapeutic Alliance Estimation", ["Victor R. Martinez", "Nikolaos Flemotomos", "Victor Ardulov", "Krishna Somandepalli", "Simon B. Goldberg", "Zac E. Imel", "David C. Atkins", "Shrikanth Narayanan"], "https://doi.org/10.21437/Interspeech.2019-2829", 5, "interspeech", 2019]], "Dimitrios Tzovaras": [0, ["Two-Dimensional Convolutional Recurrent Neural Networks for Speech Activity Detection", ["Anastasios Vafeiadis", "Eleftherios Fanioudakis", "Ilyas Potamitis", "Konstantinos Votis", "Dimitrios Giakoumis", "Dimitrios Tzovaras", "Liming Chen", "Raouf Hamzaoui"], "https://doi.org/10.21437/Interspeech.2019-1354", 5, "interspeech", 2019]], "Lisa van Staden": [0, ["Unsupervised Acoustic Unit Discovery for Speech Synthesis Using Discrete Latent-Variable Neural Networks", ["Ryan Eloff", "Andre Nortje", "Benjamin van Niekerk", "Avashna Govender", "Leanne Nortje", "Arnu Pretorius", "Elan Van Biljon", "Ewald van der Westhuizen", "Lisa van Staden", "Herman Kamper"], "https://doi.org/10.21437/Interspeech.2019-1518", 5, "interspeech", 2019]], "Marc Delcroix": [0, ["End-to-End SpeakerBeam for Single Channel Target Speech Recognition", ["Marc Delcroix", "Shinji Watanabe", "Tsubasa Ochiai", "Keisuke Kinoshita", "Shigeki Karita", "Atsunori Ogawa", "Tomohiro Nakatani"], "https://doi.org/10.21437/Interspeech.2019-1856", 5, "interspeech", 2019], ["Improving Transformer-Based End-to-End Speech Recognition with Connectionist Temporal Classification and Language Model Integration", ["Shigeki Karita", "Nelson Enrique Yalta Soplin", "Shinji Watanabe", "Marc Delcroix", "Atsunori Ogawa", "Tomohiro Nakatani"], "https://doi.org/10.21437/Interspeech.2019-1938", 5, "interspeech", 2019], ["Multimodal SpeakerBeam: Single Channel Target Speech Extraction with Audio-Visual Speaker Clues", ["Tsubasa Ochiai", "Marc Delcroix", "Keisuke Kinoshita", "Atsunori Ogawa", "Tomohiro Nakatani"], "https://doi.org/10.21437/Interspeech.2019-1513", 5, "interspeech", 2019], ["Improved Deep Duel Model for Rescoring N-Best Speech Recognition List Using Backward LSTMLM and Ensemble Encoders", ["Atsunori Ogawa", "Marc Delcroix", "Shigeki Karita", "Tomohiro Nakatani"], "https://doi.org/10.21437/Interspeech.2019-1949", 5, "interspeech", 2019]], "Yuan Jia": [0, ["Influence of Contextuality on Prosodic Realization of Information Structure in Chinese Dialogues", ["Bin Li", "Yuan Jia"], "https://doi.org/10.21437/Interspeech.2019-2291", 5, "interspeech", 2019]], "Sara Dahmani": [0, ["Conditional Variational Auto-Encoder for Text-Driven Expressive AudioVisual Speech Synthesis", ["Sara Dahmani", "Vincent Colotte", "Valerian Girard", "Slim Ouni"], "https://doi.org/10.21437/Interspeech.2019-2848", 5, "interspeech", 2019], ["Modeling Labial Coarticulation with Bidirectional Gated Recurrent Networks and Transfer Learning", ["Theo Biasutto-Lervat", "Sara Dahmani", "Slim Ouni"], "https://doi.org/10.21437/Interspeech.2019-2097", 5, "interspeech", 2019]], "Zi-Rui Wang": [3.851351152661664e-06, ["A Hybrid Approach to Acoustic Scene Classification Based on Universal Acoustic Models", ["Xue Bai", "Jun Du", "Zi-Rui Wang", "Chin-Hui Lee"], "https://doi.org/10.21437/Interspeech.2019-2171", 5, "interspeech", 2019]], "Kyogu Lee": [0.942917138338089, ["Adversarially Trained End-to-End Korean Singing Voice Synthesis System", ["Juheon Lee", "Hyeong-Seok Choi", "Chang-Bin Jeon", "Junghyun Koo", "Kyogu Lee"], "https://doi.org/10.21437/Interspeech.2019-1722", 5, "interspeech", 2019]], "Srikanth Ronanki": [0, ["Fine-Grained Robust Prosody Transfer for Single-Speaker Neural Text-To-Speech", ["Viacheslav Klimkov", "Srikanth Ronanki", "Jonas Rohnke", "Thomas Drugman"], "https://doi.org/10.21437/Interspeech.2019-2571", 5, "interspeech", 2019]], "I-Fan Chen": [0, ["Two Tiered Distributed Training Algorithm for Acoustic Modeling", ["Pranav Ladkat", "Oleg Rybakov", "Radhika Arava", "Sree Hari Krishnan Parthasarathi", "I-Fan Chen", "Nikko Strom"], "https://doi.org/10.21437/Interspeech.2019-1859", 5, "interspeech", 2019]], "Jesus Andres-Ferrer": [0, ["Listen, Attend, Spell and Adapt: Speaker Adapted Sequence-to-Sequence ASR", ["Felix Weninger", "Jesus Andres-Ferrer", "Xinwei Li", "Puming Zhan"], "https://doi.org/10.21437/Interspeech.2019-2719", 5, "interspeech", 2019]], "Nicola Klingler": [0, ["Sound Tools eXtended (STx) 5.0 - A Powerful Sound Analysis Tool Optimized for Speech", ["Anton Noll", "Jonathan Stuefer", "Nicola Klingler", "Hannah Leykum", "Carina Lozo", "Jan Luttenberger", "Michael Pucher", "Carolin Schmid"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8022.html", 2, "interspeech", 2019]], "Rainer Martin": [0, ["Privacy-Preserving Siamese Feature Extraction for Gender Recognition versus Speaker Identification", ["Alexandru Nelus", "Silas Rech", "Timm Koppelmann", "Henrik Biermann", "Rainer Martin"], "https://doi.org/10.21437/Interspeech.2019-1148", 5, "interspeech", 2019], ["Privacy-Preserving Variational Information Feature Extraction for Domestic Activity Monitoring versus Speaker Identification", ["Alexandru Nelus", "Janek Ebbers", "Reinhold Haeb-Umbach", "Rainer Martin"], "https://doi.org/10.21437/Interspeech.2019-1703", 5, "interspeech", 2019]], "Takami Yoshida": [0, ["Slot Filling with Weighted Multi-Encoders for Out-of-Domain Values", ["Yuka Kobayashi", "Takami Yoshida", "Kenji Iwata", "Hiroshi Fujimura"], "https://doi.org/10.21437/Interspeech.2019-1226", 5, "interspeech", 2019]], "Wendy Lalhminghlui": [0, ["Vowel-Tone Interaction in Two Tibeto-Burman Languages", ["Wendy Lalhminghlui", "Viyazonuo Terhiija", "Priyankoo Sarmah"], "https://doi.org/10.21437/Interspeech.2019-2808", 5, "interspeech", 2019]], "Jiaxu Chen": [0, ["An End-to-End Audio Classification System Based on Raw Waveforms and Mix-Training Strategy", ["Jiaxu Chen", "Jing Hao", "Kai Chen", "Di Xie", "Shicai Yang", "Shiliang Pu"], "https://doi.org/10.21437/Interspeech.2019-1579", 5, "interspeech", 2019]], "Takuya Saito": [0, ["Audio Classification of Bit-Representation Waveform", ["Masaki Okawa", "Takuya Saito", "Naoki Sawada", "Hiromitsu Nishizaki"], "https://doi.org/10.21437/Interspeech.2019-1855", 5, "interspeech", 2019]], "Yana Yunusova": [0, ["Early Identification of Speech Changes Due to Amyotrophic Lateral Sclerosis Using Machine Classification", ["Sarah E. Gutz", "Jun Wang", "Yana Yunusova", "Jordan R. Green"], "https://doi.org/10.21437/Interspeech.2019-2967", 5, "interspeech", 2019], ["Reduced Task Adaptation in Alternating Motion Rate Tasks as an Early Marker of Bulbar Involvement in Amyotrophic Lateral Sclerosis", ["Marziye Eshghi", "Panying Rong", "Antje S. Mefferd", "Kaila L. Stipancic", "Yana Yunusova", "Jordan R. Green"], "https://doi.org/10.21437/Interspeech.2019-2546", 5, "interspeech", 2019]], "Ignacio Vinals": [0, ["ViVoLAB Speaker Diarization System for the DIHARD 2019 Challenge", ["Ignacio Vinals", "Pablo Gimeno", "Alfonso Ortega Gimenez", "Antonio Miguel", "Eduardo Lleida"], "https://doi.org/10.21437/Interspeech.2019-2462", 5, "interspeech", 2019], ["Phonetically-Aware Embeddings, Wide Residual Networks with Time-Delay Neural Networks and Self Attention Models for the 2018 NIST Speaker Recognition Evaluation", ["Ignacio Vinals", "Dayana Ribas", "Victoria Mingote", "Jorge Llombart", "Pablo Gimeno", "Antonio Miguel", "Alfonso Ortega Gimenez", "Eduardo Lleida"], "https://doi.org/10.21437/Interspeech.2019-2417", 5, "interspeech", 2019]], "Hank Liao": [0, ["Large-Scale Visual Speech Recognition", ["Brendan Shillingford", "Yannis M. Assael", "Matthew W. Hoffman", "Thomas Paine", "Cian Hughes", "Utsav Prabhu", "Hank Liao", "Hasim Sak", "Kanishka Rao", "Lorrayne Bennett", "Marie Mulville", "Misha Denil", "Ben Coppin", "Ben Laurie", "Andrew W. Senior", "Nando de Freitas"], "https://doi.org/10.21437/Interspeech.2019-1669", 5, "interspeech", 2019]], "Leda Sari": [0, ["Learning Speaker Aware Offsets for Speaker Adaptation of Neural Networks", ["Leda Sari", "Samuel Thomas", "Mark A. Hasegawa-Johnson"], "https://doi.org/10.21437/Interspeech.2019-1788", 5, "interspeech", 2019]], "Wei Zhang": [0, ["Large-Scale Mixed-Bandwidth Deep Neural Network Acoustic Modeling for Automatic Speech Recognition", ["Khoi-Nguyen C. Mac", "Xiaodong Cui", "Wei Zhang", "Michael Picheny"], "https://doi.org/10.21437/Interspeech.2019-2641", 5, "interspeech", 2019], ["A Highly Efficient Distributed Deep Learning System for Automatic Speech Recognition", ["Wei Zhang", "Xiaodong Cui", "Ulrich Finkler", "George Saon", "Abdullah Kayi", "Alper Buyuktosunoglu", "Brian Kingsbury", "David S. Kung", "Michael Picheny"], "https://doi.org/10.21437/Interspeech.2019-2700", 5, "interspeech", 2019]], "Takahito Suzuki": [0, ["Knowledge Distillation for Throat Microphone Speech Recognition", ["Takahito Suzuki", "Jun Ogata", "Takashi Tsunakawa", "Masafumi Nishida", "Masafumi Nishimura"], "https://doi.org/10.21437/Interspeech.2019-1597", 5, "interspeech", 2019]], "Shreya Khare": [0, ["Adversarial Black-Box Attacks on Automatic Speech Recognition Systems Using Multi-Objective Evolutionary Optimization", ["Shreya Khare", "Rahul Aralikatte", "Senthil Mani"], "https://doi.org/10.21437/Interspeech.2019-2420", 5, "interspeech", 2019]], "Aman Alok": [0, ["One-vs-All Models for Asynchronous Training: An Empirical Analysis", ["Rahul Gupta", "Aman Alok", "Shankar Ananthakrishnan"], "https://doi.org/10.21437/Interspeech.2019-2760", 5, "interspeech", 2019]], "Diego Castan": [0, ["Language Recognition Using Triplet Neural Networks", ["Victoria Mingote", "Diego Castan", "Mitchell McLaren", "Mahesh Kumar Nandwana", "Alfonso Ortega Gimenez", "Eduardo Lleida", "Antonio Miguel"], "https://doi.org/10.21437/Interspeech.2019-2437", 5, "interspeech", 2019], ["Analysis of Critical Metadata Factors for the Calibration of Speaker Recognition Systems", ["Mahesh Kumar Nandwana", "Luciana Ferrer", "Mitchell McLaren", "Diego Castan", "Aaron Lawson"], "https://doi.org/10.21437/Interspeech.2019-1808", 5, "interspeech", 2019]], "Pat Rondon": [0, ["Shallow-Fusion End-to-End Contextual Biasing", ["Ding Zhao", "Tara N. Sainath", "David Rybach", "Pat Rondon", "Deepti Bhatia", "Bo Li", "Ruoming Pang"], "https://doi.org/10.21437/Interspeech.2019-1209", 5, "interspeech", 2019]], "Shifeng Pan": [0, ["Forward-Backward Decoding for Regularizing End-to-End TTS", ["Yibin Zheng", "Xi Wang", "Lei He", "Shifeng Pan", "Frank K. Soong", "Zhengqi Wen", "Jianhua Tao"], "https://doi.org/10.21437/Interspeech.2019-2325", 5, "interspeech", 2019]], "Stav Naor": [0, ["Identifying Distinctive Acoustic and Spectral Features in Parkinson's Disease", ["Yermiyahu Hauptman", "Ruth Aloni-Lavi", "Itshak Lapidot", "Tanya Gurevich", "Yael Manor", "Stav Naor", "Noa Diamant", "Irit Opher"], "https://doi.org/10.21437/Interspeech.2019-2465", 5, "interspeech", 2019]], "Adriaan J. van Wijngaarden": [0, ["Speech Enhancement Using Forked Generative Adversarial Networks with Spectral Subtraction", ["Ju Lin", "Sufeng Niu", "Zice Wei", "Xiang Lan", "Adriaan J. van Wijngaarden", "Melissa C. Smith", "Kuang-Ching Wang"], "https://doi.org/10.21437/Interspeech.2019-2954", 5, "interspeech", 2019]], "Zhongjun He": [0, ["End-to-End Speech Translation with Knowledge Distillation", ["Yuchen Liu", "Hao Xiong", "Jiajun Zhang", "Zhongjun He", "Hua Wu", "Haifeng Wang", "Chengqing Zong"], "https://doi.org/10.21437/Interspeech.2019-2582", 5, "interspeech", 2019]], "Sarah Leimkotter": [0, ["An Acoustic and Lexical Analysis of Emotional Valence in Spontaneous Speech: Autobiographical Memory Recall in Older Adults", ["Deniece S. Nazareth", "Ellen Tournier", "Sarah Leimkotter", "Esther Janse", "Dirk Heylen", "Gerben J. Westerhof", "Khiet P. Truong"], "https://doi.org/10.21437/Interspeech.2019-1823", 5, "interspeech", 2019]], "Dominik Roblek": [0, ["Fr\u00e9chet Audio Distance: A Reference-Free Metric for Evaluating Music Enhancement Algorithms", ["Kevin Kilgour", "Mauricio Zuluaga", "Dominik Roblek", "Matthew Sharifi"], "https://doi.org/10.21437/Interspeech.2019-2219", 5, "interspeech", 2019], ["Low-Dimensional Bottleneck Features for On-Device Continuous Speech Recognition", ["David B. Ramsay", "Kevin Kilgour", "Dominik Roblek", "Matthew Sharifi"], "https://doi.org/10.21437/Interspeech.2019-2193", 4, "interspeech", 2019]], "Satoshi Asakawa": [0, ["End-to-End Adaptation with Backpropagation Through WFST for On-Device Speech Recognition System", ["Emiru Tsunoo", "Yosuke Kashiwagi", "Satoshi Asakawa", "Toshiyuki Kumakura"], "https://doi.org/10.21437/Interspeech.2019-1880", 5, "interspeech", 2019]], "Shinji Takaki": [0, ["Does the Lombard Effect Improve Emotional Communication in Noise? - Analysis of Emotional Speech Acted in Noise", ["Yi Zhao", "Atsushi Ando", "Shinji Takaki", "Junichi Yamagishi", "Satoshi Kobashikawa"], "https://doi.org/10.21437/Interspeech.2019-1605", 5, "interspeech", 2019]], "Mahesh Kumar Nandwana": [0, ["The VOiCES from a Distance Challenge 2019", ["Mahesh Kumar Nandwana", "Julien van Hout", "Colleen Richey", "Mitchell McLaren", "Maria Auxiliadora Barrios", "Aaron Lawson"], "https://doi.org/10.21437/Interspeech.2019-1837", 5, "interspeech", 2019], ["The VOiCES from a Distance Challenge 2019", ["Mahesh Kumar Nandwana", "Julien van Hout", "Colleen Richey", "Mitchell McLaren", "Maria Alejandra Barrios", "Aaron Lawson"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/abs14.html", 0, "interspeech", 2019], ["Language Recognition Using Triplet Neural Networks", ["Victoria Mingote", "Diego Castan", "Mitchell McLaren", "Mahesh Kumar Nandwana", "Alfonso Ortega Gimenez", "Eduardo Lleida", "Antonio Miguel"], "https://doi.org/10.21437/Interspeech.2019-2437", 5, "interspeech", 2019], ["Analysis of Critical Metadata Factors for the Calibration of Speaker Recognition Systems", ["Mahesh Kumar Nandwana", "Luciana Ferrer", "Mitchell McLaren", "Diego Castan", "Aaron Lawson"], "https://doi.org/10.21437/Interspeech.2019-1808", 5, "interspeech", 2019]], "Shan Liang": [0, ["Jointly Adversarial Enhancement Training for Robust End-to-End Speech Recognition", ["Bin Liu", "Shuai Nie", "Shan Liang", "Wenju Liu", "Meng Yu", "Lianwu Chen", "Shouye Peng", "Changliang Li"], "https://doi.org/10.21437/Interspeech.2019-1242", 5, "interspeech", 2019], ["Direction-Aware Speaker Beam for Multi-Channel Speaker Extraction", ["Guanjun Li", "Shan Liang", "Shuai Nie", "Wenju Liu", "Meng Yu", "Lianwu Chen", "Shouye Peng", "Changliang Li"], "https://doi.org/10.21437/Interspeech.2019-1474", 5, "interspeech", 2019]], "Satarupa Guha": [0, ["Exploiting Monolingual Speech Corpora for Code-Mixed Speech Recognition", ["Karan Taneja", "Satarupa Guha", "Preethi Jyothi", "Basil Abraham"], "https://doi.org/10.21437/Interspeech.2019-1959", 5, "interspeech", 2019]], "Woo Hyun Kang": [0.9989664554595947, ["End-to-End Multi-Channel Speech Enhancement Using Inter-Channel Time-Restricted Attention on Raw Waveform", ["Hyeon Seung Lee", "Hyung Yong Kim", "Woo Hyun Kang", "Jeunghun Kim", "Nam Soo Kim"], "https://doi.org/10.21437/Interspeech.2019-2397", 5, "interspeech", 2019]], "Andrea Deme": [0, ["V-to-V Coarticulation Induced Acoustic and Articulatory Variability of Vowels: The Effect of Pitch-Accent", ["Andrea Deme", "Marton Bartok", "Tekla Etelka Graczi", "Tamas Gabor Csapo", "Alexandra Marko"], "https://doi.org/10.21437/Interspeech.2019-2890", 5, "interspeech", 2019], ["Articulatory Analysis of Transparent Vowel /i\u02d0/ in Harmonic and Antiharmonic Hungarian Stems: Is There a Difference?", ["Alexandra Marko", "Marton Bartok", "Tamas Gabor Csapo", "Tekla Etelka Graczi", "Andrea Deme"], "https://doi.org/10.21437/Interspeech.2019-2352", 5, "interspeech", 2019]], "Nicholas Apostoloff": [0, ["Mirroring to Build Trust in Digital Assistants", ["Katherine Metcalf", "Barry-John Theobald", "Garrett Weinberg", "Robert Lee", "Ing-Marie Jonsson", "Russ Webb", "Nicholas Apostoloff"], "https://doi.org/10.21437/Interspeech.2019-1829", 5, "interspeech", 2019]], "K. G. van Leeuwen": [0, ["CNN-Based Phoneme Classifier from Vocal Tract MRI Learns Embedding Consistent with Articulatory Topology", ["K. G. van Leeuwen", "P. Bos", "Stefano Trebeschi", "Maarten J. A. van Alphen", "Luuk Voskuilen", "Ludi E. Smeele", "Ferdi van der Heijden", "R. J. J. H. van Son"], "https://doi.org/10.21437/Interspeech.2019-1173", 5, "interspeech", 2019]], "Guan-Lin Chao": [0, ["BERT-DST: Scalable End-to-End Dialogue State Tracking with Bidirectional Encoder Representations from Transformer", ["Guan-Lin Chao", "Ian Lane"], "https://doi.org/10.21437/Interspeech.2019-1355", 5, "interspeech", 2019]], "Chip-Jin Ng": [0, ["Investigating the Variability of Voice Quality and Pain Levels as a Function of Multiple Clinical Parameters", ["Hui-Ting Hong", "Jeng-Lin Li", "Yi-Ming Weng", "Chip-Jin Ng", "Chi-Chun Lee"], "https://doi.org/10.21437/Interspeech.2019-2247", 5, "interspeech", 2019]], "Jan Chorowski": [0, ["Lattice Generation in Attention-Based Speech Recognition Models", ["Michal Zapotoczny", "Piotr Pietrzak", "Adrian Lancucki", "Jan Chorowski"], "https://doi.org/10.21437/Interspeech.2019-2667", 5, "interspeech", 2019], ["Towards Using Context-Dependent Symbols in CTC Without State-Tying Decision Trees", ["Jan Chorowski", "Adrian Lancucki", "Bartosz Kostka", "Michal Zapotoczny"], "https://doi.org/10.21437/Interspeech.2019-2720", 5, "interspeech", 2019]], "Jacob Reinhold": [0, ["VESUS: A Crowd-Annotated Database to Study Emotion Production and Perception in Spoken English", ["Jacob Sager", "Ravi Shankar", "Jacob Reinhold", "Archana Venkataraman"], "https://doi.org/10.21437/Interspeech.2019-1413", 5, "interspeech", 2019]], "K. N. R. K. Raju Alluri": [0, ["IIIT-H Spoofing Countermeasures for Automatic Speaker Verification Spoofing and Countermeasures Challenge 2019", ["K. N. R. K. Raju Alluri", "Anil Kumar Vuppala"], "https://doi.org/10.21437/Interspeech.2019-1623", 5, "interspeech", 2019]], "Javier Iranzo-Sanchez": [0, ["Real-Time One-Pass Decoder for Speech Recognition Using LSTM Language Models", ["Javier Jorge", "Adria Gimenez", "Javier Iranzo-Sanchez", "Jorge Civera", "Albert Sanchis", "Alfons Juan"], "https://doi.org/10.21437/Interspeech.2019-2798", 5, "interspeech", 2019]], "Hao Zhang": [0, ["Improving Performance of End-to-End ASR on Numeric Sequences", ["Cal Peyser", "Hao Zhang", "Tara N. Sainath", "Zelin Wu"], "https://doi.org/10.21437/Interspeech.2019-1345", 5, "interspeech", 2019], ["Deep Learning for Joint Acoustic Echo and Noise Cancellation with Nonlinear Distortions", ["Hao Zhang", "Ke Tan", "DeLiang Wang"], "https://doi.org/10.21437/Interspeech.2019-2651", 5, "interspeech", 2019], ["Dual Encoder Classifier Models as Constraints in Neural Text Normalization", ["Ajda Gokcen", "Hao Zhang", "Richard Sproat"], "https://doi.org/10.21437/Interspeech.2019-1135", 5, "interspeech", 2019]], "Jilong Kuang": [0, ["DeepLung: Smartphone Convolutional Neural Network-Based Inference of Lung Anomalies for Pulmonary Patients", ["Mohsin Y. Ahmed", "Md. Mahbubur Rahman", "Jilong Kuang"], "https://doi.org/10.21437/Interspeech.2019-2953", 5, "interspeech", 2019]], "Douglas D. OShaughnessy": [0, ["Blind Channel Response Estimation for Replay Attack Detection", ["Anderson R. Avila", "Md. Jahangir Alam", "Douglas D. OShaughnessy", "Tiago H. Falk"], "https://doi.org/10.21437/Interspeech.2019-2956", 5, "interspeech", 2019]], "Victor Soto": [0, ["Improving Code-Switched Language Modeling Performance Using Cognate Features", ["Victor Soto", "Julia Hirschberg"], "https://doi.org/10.21437/Interspeech.2019-2681", 5, "interspeech", 2019]], "Koichiro Yoshino": [0, ["An Incremental Turn-Taking Model for Task-Oriented Dialog Systems", ["Andrei C. Coman", "Koichiro Yoshino", "Yukitoshi Murase", "Satoshi Nakamura", "Giuseppe Riccardi"], "https://doi.org/10.21437/Interspeech.2019-1826", 5, "interspeech", 2019]], "Eva Navas": [0, ["Parallel vs. Non-Parallel Voice Conversion for Esophageal Speech", ["Luis Serrano", "Sneha Raman", "David Tavarez", "Eva Navas", "Inma Hernaez"], "https://doi.org/10.21437/Interspeech.2019-2194", 5, "interspeech", 2019]], "Mohsin Y. Ahmed": [0, ["DeepLung: Smartphone Convolutional Neural Network-Based Inference of Lung Anomalies for Pulmonary Patients", ["Mohsin Y. Ahmed", "Md. Mahbubur Rahman", "Jilong Kuang"], "https://doi.org/10.21437/Interspeech.2019-2953", 5, "interspeech", 2019]], "Seyed Hamidreza Mohammadi": [0, ["One-Shot Voice Conversion with Disentangled Representations by Leveraging Phonetic Posteriorgrams", ["Seyed Hamidreza Mohammadi", "Taehwan Kim"], "https://doi.org/10.21437/Interspeech.2019-1798", 5, "interspeech", 2019]], "Fengna Wang": [1.1101697054982651e-05, ["Visualization and Interpretation of Latent Spaces for Controlling Expressive Speech Synthesis Through Audio Analysis", ["Noe Tits", "Fengna Wang", "Kevin El Haddad", "Vincent Pagel", "Thierry Dutoit"], "https://doi.org/10.21437/Interspeech.2019-1426", 5, "interspeech", 2019]], "Gianni Fenu": [0, ["Adversarial Optimization for Dictionary Attacks on Speaker Verification", ["Mirko Marras", "Pawel Korus", "Nasir D. Memon", "Gianni Fenu"], "https://doi.org/10.21437/Interspeech.2019-2430", 5, "interspeech", 2019]], "Marketa Juzova": [0, ["Unified Language-Independent DNN-Based G2P Converter", ["Marketa Juzova", "Daniel Tihelka", "Jakub Vit"], "https://doi.org/10.21437/Interspeech.2019-2335", 5, "interspeech", 2019]], "Deb Roy": [0, ["RadioTalk: A Large-Scale Corpus of Talk Radio Transcripts", ["Doug Beeferman", "William Brannon", "Deb Roy"], "https://doi.org/10.21437/Interspeech.2019-2714", 5, "interspeech", 2019]], "Daniel Fogerty": [0, ["Improvement and Assessment of Spectro-Temporal Modulation Analysis for Speech Intelligibility Estimation", ["Amin Edraki", "Wai-Yip Chan", "Jesper Jensen", "Daniel Fogerty"], "https://doi.org/10.21437/Interspeech.2019-2898", 5, "interspeech", 2019]], "Antonietta Maria Esposito": [0, ["The Dependability of Voice on Elders' Acceptance of Humanoid Agents", ["Anna Esposito", "Terry Amorese", "Marialucia Cuciniello", "Maria Teresa Riviello", "Antonietta Maria Esposito", "Alda Troncone", "Gennaro Cordasco"], "https://doi.org/10.21437/Interspeech.2019-1734", 5, "interspeech", 2019]], "Sarah E. Gutz": [0, ["Early Identification of Speech Changes Due to Amyotrophic Lateral Sclerosis Using Machine Classification", ["Sarah E. Gutz", "Jun Wang", "Yana Yunusova", "Jordan R. Green"], "https://doi.org/10.21437/Interspeech.2019-2967", 5, "interspeech", 2019]], "Dipjyoti Paul": [0, ["Non-Parallel Voice Conversion Using Weighted Generative Adversarial Networks", ["Dipjyoti Paul", "Yannis Pantazis", "Yannis Stylianou"], "https://doi.org/10.21437/Interspeech.2019-2869", 5, "interspeech", 2019]], "Mary Stevens": [0, ["Tracking the New Zealand English NEAR/SQUARE Merger Using Functional Principal Components Analysis", ["Michele Gubian", "Jonathan Harrington", "Mary Stevens", "Florian Schiel", "Paul Warren"], "https://doi.org/10.21437/Interspeech.2019-2115", 5, "interspeech", 2019]], "Juheon Lee": [0.9739110469818115, ["Adversarially Trained End-to-End Korean Singing Voice Synthesis System", ["Juheon Lee", "Hyeong-Seok Choi", "Chang-Bin Jeon", "Junghyun Koo", "Kyogu Lee"], "https://doi.org/10.21437/Interspeech.2019-1722", 5, "interspeech", 2019]], "Bharat Padi": [0, ["Attention Based Hybrid i-Vector BLSTM Model for Language Recognition", ["Bharat Padi", "Anand Mohan", "Sriram Ganapathy"], "https://doi.org/10.21437/Interspeech.2019-2371", 5, "interspeech", 2019]], "Eleftherios Fanioudakis": [0, ["Two-Dimensional Convolutional Recurrent Neural Networks for Speech Activity Detection", ["Anastasios Vafeiadis", "Eleftherios Fanioudakis", "Ilyas Potamitis", "Konstantinos Votis", "Dimitrios Giakoumis", "Dimitrios Tzovaras", "Liming Chen", "Raouf Hamzaoui"], "https://doi.org/10.21437/Interspeech.2019-1354", 5, "interspeech", 2019]], "Kyle Gorman": [0, ["Unified Verbalization for Speech Recognition & Synthesis Across Languages", ["Sandy Ritchie", "Richard Sproat", "Kyle Gorman", "Daan van Esch", "Christian Schallhart", "Nikos Bampounis", "Benoit Brard", "Jonas Fromseier Mortensen", "Millie Holt", "Eoin Mahon"], "https://doi.org/10.21437/Interspeech.2019-2807", 5, "interspeech", 2019]], "Ron J. Weiss": [0, ["Direct Speech-to-Speech Translation with a Sequence-to-Sequence Model", ["Ye Jia", "Ron J. Weiss", "Fadi Biadsy", "Wolfgang Macherey", "Melvin Johnson", "Zhifeng Chen", "Yonghui Wu"], "https://doi.org/10.21437/Interspeech.2019-1951", 5, "interspeech", 2019], ["LibriTTS: A Corpus Derived from LibriSpeech for Text-to-Speech", ["Heiga Zen", "Viet Dang", "Rob Clark", "Yu Zhang", "Ron J. Weiss", "Ye Jia", "Zhifeng Chen", "Yonghui Wu"], "https://doi.org/10.21437/Interspeech.2019-2441", 5, "interspeech", 2019], ["Learning to Speak Fluently in a Foreign Language: Multilingual Speech Synthesis and Cross-Language Voice Cloning", ["Yu Zhang", "Ron J. Weiss", "Heiga Zen", "Yonghui Wu", "Zhifeng Chen", "R. J. Skerry-Ryan", "Ye Jia", "Andrew Rosenberg", "Bhuvana Ramabhadran"], "https://doi.org/10.21437/Interspeech.2019-2668", 5, "interspeech", 2019], ["VoiceFilter: Targeted Voice Separation by Speaker-Conditioned Spectrogram Masking", ["Quan Wang", "Hannah Muckenhirn", "Kevin W. Wilson", "Prashant Sridhar", "Zelin Wu", "John R. Hershey", "Rif A. Saurous", "Ron J. Weiss", "Ye Jia", "Ignacio Lopez-Moreno"], "https://doi.org/10.21437/Interspeech.2019-1101", 5, "interspeech", 2019], ["Parrotron: An End-to-End Speech-to-Speech Conversion Model and its Applications to Hearing-Impaired Speech and Speech Separation", ["Fadi Biadsy", "Ron J. Weiss", "Pedro J. Moreno", "Dimitri Kanvesky", "Ye Jia"], "https://doi.org/10.21437/Interspeech.2019-1789", 5, "interspeech", 2019]], "Mengnan Chen": [0, ["Cross-Lingual, Multi-Speaker Text-To-Speech Synthesis Using Neural Speaker Embedding", ["Mengnan Chen", "Minchuan Chen", "Shuang Liang", "Jun Ma", "Lei Chen", "Shaojun Wang", "Jing Xiao"], "https://doi.org/10.21437/Interspeech.2019-1632", 5, "interspeech", 2019]], "Tasavat Trisitichoke": [0, ["Analysis of Native Listeners' Facial Microexpressions While Shadowing Non-Native Speech - Potential of Shadowers' Facial Expressions for Comprehensibility Prediction", ["Tasavat Trisitichoke", "Shintaro Ando", "Daisuke Saito", "Nobuaki Minematsu"], "https://doi.org/10.21437/Interspeech.2019-1953", 5, "interspeech", 2019]], "Harald Baumeister": [0, ["Using Speech to Predict Sequentially Measured Cortisol Levels During a Trier Social Stress Test", ["Alice Baird", "Shahin Amiriparian", "Nicholas Cummins", "Sarah Sturmbauer", "Johanna Janson", "Eva-Maria Messner", "Harald Baumeister", "Nicolas Rohleder", "Bjorn W. Schuller"], "https://doi.org/10.21437/Interspeech.2019-1352", 5, "interspeech", 2019]], "Felix Weninger": [0, ["Deep Learning Based Mandarin Accent Identification for Accent Robust ASR", ["Felix Weninger", "Yang Sun", "Junho Park", "Daniel Willett", "Puming Zhan"], "https://doi.org/10.21437/Interspeech.2019-2737", 5, "interspeech", 2019], ["Listen, Attend, Spell and Adapt: Speaker Adapted Sequence-to-Sequence ASR", ["Felix Weninger", "Jesus Andres-Ferrer", "Xinwei Li", "Puming Zhan"], "https://doi.org/10.21437/Interspeech.2019-2719", 5, "interspeech", 2019]], "Sara Khalifa": [0, ["Direct Modelling of Speech Emotion from Raw Speech", ["Siddique Latif", "Rajib Rana", "Sara Khalifa", "Raja Jurdak", "Julien Epps"], "https://doi.org/10.21437/Interspeech.2019-3252", 5, "interspeech", 2019]], "Shilei Zhang": [0, ["Few-Shot Audio Classification with Attentional Graph Neural Networks", ["Shilei Zhang", "Yong Qin", "Kewei Sun", "Yonghua Lin"], "https://doi.org/10.21437/Interspeech.2019-1532", 5, "interspeech", 2019]], "Jeffrey F. Cohn": [0, ["Bag-of-Acoustic-Words for Mental Health Assessment: A Deep Autoencoding Approach", ["Wenchao Du", "Louis-Philippe Morency", "Jeffrey F. Cohn", "Alan W. Black"], "https://doi.org/10.21437/Interspeech.2019-3059", 5, "interspeech", 2019]], "Brigitte Richardson": [0, ["Integrating Video Retrieval and Moment Detection in a Unified Corpus for Video Question Answering", ["Hongyin Luo", "Mitra Mohtarami", "James R. Glass", "Karthik Krishnamurthy", "Brigitte Richardson"], "https://doi.org/10.21437/Interspeech.2019-1736", 5, "interspeech", 2019]], "Kazuya Takeda": [0, ["Robustness of Statistical Voice Conversion Based on Direct Waveform Modification Against Background Sounds", ["Yusuke Kurita", "Kazuhiro Kobayashi", "Kazuya Takeda", "Tomoki Toda"], "https://doi.org/10.21437/Interspeech.2019-2206", 5, "interspeech", 2019], ["Pre-Trained Text Embeddings for Enhanced Text-to-Speech Synthesis", ["Tomoki Hayashi", "Shinji Watanabe", "Tomoki Toda", "Kazuya Takeda", "Shubham Toshniwal", "Karen Livescu"], "https://doi.org/10.21437/Interspeech.2019-3177", 5, "interspeech", 2019]], "David Scott Farrar": [0, ["Leveraging Acoustic Cues and Paralinguistic Embeddings to Detect Expression from Voice", ["Vikramjit Mitra", "Sue Booker", "Erik Marchi", "David Scott Farrar", "Ute Dorothea Peitz", "Bridget Cheng", "Ermine Teves", "Anuj Mehta", "Devang Naik"], "https://doi.org/10.21437/Interspeech.2019-2998", 5, "interspeech", 2019]], "Yusuke Kurita": [0, ["Robustness of Statistical Voice Conversion Based on Direct Waveform Modification Against Background Sounds", ["Yusuke Kurita", "Kazuhiro Kobayashi", "Kazuya Takeda", "Tomoki Toda"], "https://doi.org/10.21437/Interspeech.2019-2206", 5, "interspeech", 2019]], "Feng Wang": [0.00021905750327277929, ["Ectc-Docd: An End-to-End Structure with CTC Encoder and OCD Decoder for Speech Recognition", ["Cheng Yi", "Feng Wang", "Bo Xu"], "https://doi.org/10.21437/Interspeech.2019-1212", 5, "interspeech", 2019]], "John D. Kanu": [0, ["Regression and Classification for Direction-of-Arrival Estimation with Convolutional Recurrent Neural Networks", ["Zhenyu Tang", "John D. Kanu", "Kevin Hogan", "Dinesh Manocha"], "https://doi.org/10.21437/Interspeech.2019-1111", 5, "interspeech", 2019]], "Lucas Ondel": [0, ["Bayesian Subspace Hidden Markov Model for Acoustic Unit Discovery", ["Lucas Ondel", "Hari Krishna Vydana", "Lukas Burget", "Jan Cernocky"], "https://doi.org/10.21437/Interspeech.2019-2224", 5, "interspeech", 2019], ["The Zero Resource Speech Challenge 2019: TTS Without T", ["Ewan Dunbar", "Robin Algayres", "Julien Karadayi", "Mathieu Bernard", "Juan Benjumea", "Xuan-Nga Cao", "Lucie Miskic", "Charlotte Dugrain", "Lucas Ondel", "Alan W. Black", "Laurent Besacier", "Sakriani Sakti", "Emmanuel Dupoux"], "https://doi.org/10.21437/Interspeech.2019-2904", 5, "interspeech", 2019]], "Jason Li": [0, ["Jasper: An End-to-End Convolutional Neural Acoustic Model", ["Jason Li", "Vitaly Lavrukhin", "Boris Ginsburg", "Ryan Leary", "Oleksii Kuchaiev", "Jonathan M. Cohen", "Huyen Nguyen", "Ravi Teja Gadde"], "https://doi.org/10.21437/Interspeech.2019-1819", 5, "interspeech", 2019]], "Tanay Sharma": [0, ["Real Time Online Visual End Point Detection Using Unidirectional LSTM", ["Tanay Sharma", "Rohith Chandrashekar Aralikatti", "Dilip Kumar Margam", "Abhinav Thanda", "Sharad Roy", "Pujitha Appan Kandala", "Shankar M. Venkatesan"], "https://doi.org/10.21437/Interspeech.2019-3253", 5, "interspeech", 2019], ["Speaker Adaptation for Lip-Reading Using Visual Identity Vectors", ["Pujitha Appan Kandala", "Abhinav Thanda", "Dilip Kumar Margam", "Rohith Chandrashekar Aralikatti", "Tanay Sharma", "Sharad Roy", "Shankar M. Venkatesan"], "https://doi.org/10.21437/Interspeech.2019-3237", 5, "interspeech", 2019]], "Bo-Hao Su": [0, ["Using Attention Networks and Adversarial Augmentation for Styrian Dialect Continuous Sleepiness and Baby Sound Recognition", ["Sung-Lin Yeh", "Gao-Yi Chao", "Bo-Hao Su", "Yu-Lin Huang", "Meng-Han Lin", "Yin-Chun Tsai", "Yu-Wen Tai", "Zheng-Chi Lu", "Chieh-Yu Chen", "Tsung-Ming Tai", "Chiu-Wang Tseng", "Cheng-Kuang Lee", "Chi-Chun Lee"], "https://doi.org/10.21437/Interspeech.2019-2110", 5, "interspeech", 2019]], "Cybelle Smith": [0, ["The Neural Correlates Underlying Lexically-Guided Perceptual Learning", ["Odette Scharenborg", "Jiska Koemans", "Cybelle Smith", "Mark A. Hasegawa-Johnson", "Kara D. Federmeier"], "https://doi.org/10.21437/Interspeech.2019-2328", 5, "interspeech", 2019]], "Sandro Cumani": [0, ["Normal Variance-Mean Mixtures for Unsupervised Score Calibration", ["Sandro Cumani"], "https://doi.org/10.21437/Interspeech.2019-1609", 5, "interspeech", 2019]], "Anke Sennema": [0, ["Vietnamese Learners Tackling the German /\u0283t/ in Perception", ["Anke Sennema", "Silke Hamann"], "https://doi.org/10.21437/Interspeech.2019-2832", 4, "interspeech", 2019]], "Kewei Sun": [2.2388825982488925e-05, ["Few-Shot Audio Classification with Attentional Graph Neural Networks", ["Shilei Zhang", "Yong Qin", "Kewei Sun", "Yonghua Lin"], "https://doi.org/10.21437/Interspeech.2019-1532", 5, "interspeech", 2019]], "Carolina De Pasquale": [0, ["An Investigation of Therapeutic Rapport Through Prosody in Brief Psychodynamic Psychotherapy", ["Carolina De Pasquale", "Charlie Cullen", "Brian Vaughan"], "https://doi.org/10.21437/Interspeech.2019-2551", 5, "interspeech", 2019]], "Emily Mower Provost": [0, ["Into the Wild: Transitioning from Recognizing Mood in Clinical Interactions to Personal Conversations for Individuals with Bipolar Disorder", ["Katie Matton", "Melvin G. McInnis", "Emily Mower Provost"], "https://doi.org/10.21437/Interspeech.2019-2698", 5, "interspeech", 2019], ["Identifying Mood Episodes Using Dialogue Features from Clinical Interviews", ["Zakaria Aldeneh", "Mimansa Jaiswal", "Michael Picheny", "Melvin G. McInnis", "Emily Mower Provost"], "https://doi.org/10.21437/Interspeech.2019-1878", 5, "interspeech", 2019], ["Emotion Recognition from Natural Phone Conversations in Individuals with and without Recent Suicidal Ideation", ["John Gideon", "Heather T. Schatten", "Melvin G. McInnis", "Emily Mower Provost"], "https://doi.org/10.21437/Interspeech.2019-1830", 5, "interspeech", 2019]], "Masafumi Nishida": [0, ["Knowledge Distillation for Throat Microphone Speech Recognition", ["Takahito Suzuki", "Jun Ogata", "Takashi Tsunakawa", "Masafumi Nishida", "Masafumi Nishimura"], "https://doi.org/10.21437/Interspeech.2019-1597", 5, "interspeech", 2019]], "Herve Bourlard": [0, ["Unbiased Semi-Supervised LF-MMI Training Using Dropout", ["Sibo Tong", "Apoorv Vyas", "Philip N. Garner", "Herve Bourlard"], "https://doi.org/10.21437/Interspeech.2019-2678", 5, "interspeech", 2019], ["Spectral Subspace Analysis for Automatic Assessment of Pathological Speech Intelligibility", ["Parvaneh Janbakhshi", "Ina Kodrasi", "Herve Bourlard"], "https://doi.org/10.21437/Interspeech.2019-2791", 5, "interspeech", 2019]], "Jerome R. Bellegarda": [0, ["Reverse Transfer Learning: Can Word Embeddings Trained for Different NLP Tasks Improve Neural Language Models?", ["Lyan Verwimp", "Jerome R. Bellegarda"], "https://doi.org/10.21437/Interspeech.2019-1332", 5, "interspeech", 2019]], "Konstantinos Votis": [0, ["Two-Dimensional Convolutional Recurrent Neural Networks for Speech Activity Detection", ["Anastasios Vafeiadis", "Eleftherios Fanioudakis", "Ilyas Potamitis", "Konstantinos Votis", "Dimitrios Giakoumis", "Dimitrios Tzovaras", "Liming Chen", "Raouf Hamzaoui"], "https://doi.org/10.21437/Interspeech.2019-1354", 5, "interspeech", 2019]], "Masato Akagi": [0, ["The Contribution of Acoustic Features Analysis to Model Emotion Perceptual Process for Language Diversity", ["Xingfeng Li", "Masato Akagi"], "https://doi.org/10.21437/Interspeech.2019-2229", 5, "interspeech", 2019]], "Nikolaos Ellinas": [0, ["Unsupervised Low-Rank Representations for Speech Emotion Recognition", ["Georgios Paraskevopoulos", "Efthymios Tzinis", "Nikolaos Ellinas", "Theodoros Giannakopoulos", "Alexandros Potamianos"], "https://doi.org/10.21437/Interspeech.2019-2769", 5, "interspeech", 2019]], "Petr Cerva": [0, ["An Approach to Online Speaker Change Point Detection Using DNNs and WFSTs", ["Lukas Mateju", "Petr Cerva", "Jindrich Zdansky"], "https://doi.org/10.21437/Interspeech.2019-1407", 5, "interspeech", 2019]], "Abeer Alwan": [0, ["A Frequency Normalization Technique for Kindergarten Speech Recognition Inspired by the Role of fo in Vowel Perception", ["Gary Yeung", "Abeer Alwan"], "https://doi.org/10.21437/Interspeech.2019-1847", 5, "interspeech", 2019], ["Voice Quality and Between-Frame Entropy for Sleepiness Estimation", ["Vijay Ravi", "Soo Jin Park", "Amber Afshan", "Abeer Alwan"], "https://doi.org/10.21437/Interspeech.2019-2988", 5, "interspeech", 2019]], "Rongfeng Su": [0, ["Exploiting Visual Features Using Bayesian Gated Neural Networks for Disordered Speech Recognition", ["Shansong Liu", "Shoukang Hu", "Yi Wang", "Jianwei Yu", "Rongfeng Su", "Xunying Liu", "Helen Meng"], "https://doi.org/10.21437/Interspeech.2019-1536", 5, "interspeech", 2019], ["Towards the Speech Features of Early-Stage Dementia: Design and Application of the Mandarin Elderly Cognitive Speech Database", ["Tianqi Wang", "Quanlei Yan", "Jingshen Pan", "Feiqi Zhu", "Rongfeng Su", "Yi Guo", "Lan Wang", "Nan Yan"], "https://doi.org/10.21437/Interspeech.2019-2453", 5, "interspeech", 2019]], "Mani B. Srivastava": [0, ["Deep Residual Neural Networks for Audio Spoofing Detection", ["Moustafa Alzantot", "Ziqi Wang", "Mani B. Srivastava"], "https://doi.org/10.21437/Interspeech.2019-3174", 5, "interspeech", 2019]], "Artem Gorlanov": [0, ["Speaker Diarization with Deep Speaker Embeddings for DIHARD Challenge II", ["Sergey Novoselov", "Aleksei Gusev", "Artem Ivanov", "Timur Pekhovsky", "Andrey Shulipa", "Anastasia Avdeeva", "Artem Gorlanov", "Alexandr Kozlov"], "https://doi.org/10.21437/Interspeech.2019-2757", 5, "interspeech", 2019], ["STC Antispoofing Systems for the ASVspoof2019 Challenge", ["Galina Lavrentyeva", "Sergey Novoselov", "Andzhukaev Tseren", "Marina Volkova", "Artem Gorlanov", "Alexandr Kozlov"], "https://doi.org/10.21437/Interspeech.2019-1768", 5, "interspeech", 2019]], "Qinglang Chen": [0, ["Topical-Chat: Towards Knowledge-Grounded Open-Domain Conversations", ["Karthik Gopalakrishnan", "Behnam Hedayatnia", "Qinglang Chen", "Anna Gottardi", "Sanjeev Kwatra", "Anu Venkatesh", "Raefer Gabriel", "Dilek Hakkani-Tur"], "https://doi.org/10.21437/Interspeech.2019-3079", 5, "interspeech", 2019]], "Tamas Gabor Csapo": [0, ["Ultrasound-Based Silent Speech Interface Built on a Continuous Vocoder", ["Tamas Gabor Csapo", "Mohammed Salah Al-Radhi", "Geza Nemeth", "Gabor Gosztolya", "Tamas Grosz", "Laszlo Toth", "Alexandra Marko"], "https://doi.org/10.21437/Interspeech.2019-2046", 5, "interspeech", 2019], ["V-to-V Coarticulation Induced Acoustic and Articulatory Variability of Vowels: The Effect of Pitch-Accent", ["Andrea Deme", "Marton Bartok", "Tekla Etelka Graczi", "Tamas Gabor Csapo", "Alexandra Marko"], "https://doi.org/10.21437/Interspeech.2019-2890", 5, "interspeech", 2019], ["Articulatory Analysis of Transparent Vowel /i\u02d0/ in Harmonic and Antiharmonic Hungarian Stems: Is There a Difference?", ["Alexandra Marko", "Marton Bartok", "Tamas Gabor Csapo", "Tekla Etelka Graczi", "Andrea Deme"], "https://doi.org/10.21437/Interspeech.2019-2352", 5, "interspeech", 2019]], "Leonardo Brambilla": [0, ["EpaDB: A Database for Development of Pronunciation Assessment Systems", ["Jazmin Vidal", "Luciana Ferrer", "Leonardo Brambilla"], "https://doi.org/10.21437/Interspeech.2019-1839", 5, "interspeech", 2019]], "Nan Li": [0, ["Environment-Dependent Attention-Driven Recurrent Convolutional Neural Network for Robust Speech Enhancement", ["Meng Ge", "Longbiao Wang", "Nan Li", "Hao Shi", "Jianwu Dang", "Xiangang Li"], "https://doi.org/10.21437/Interspeech.2019-1477", 5, "interspeech", 2019]], "Nilay Shrivastava": [0, ["MobiVSR : Efficient and Light-Weight Neural Network for Visual Speech Recognition on Mobile Devices", ["Nilay Shrivastava", "Astitwa Saxena", "Yaman Kumar", "Rajiv Ratn Shah", "Amanda Stent", "Debanjan Mahata", "Preeti Kaur", "Roger Zimmermann"], "https://doi.org/10.21437/Interspeech.2019-3273", 5, "interspeech", 2019]], "Erfan Loweimi": [0, ["Trainable Dynamic Subsampling for End-to-End Speech Recognition", ["Shucong Zhang", "Erfan Loweimi", "Yumo Xu", "Peter Bell", "Steve Renals"], "https://doi.org/10.21437/Interspeech.2019-2778", 5, "interspeech", 2019], ["Learning Temporal Clusters Using Capsule Routing for Speech Emotion Recognition", ["Md Asif Jalal", "Erfan Loweimi", "Roger K. Moore", "Thomas Hain"], "https://doi.org/10.21437/Interspeech.2019-3068", 5, "interspeech", 2019], ["On Learning Interpretable CNNs with Parametric Modulated Kernel-Based Filters", ["Erfan Loweimi", "Peter Bell", "Steve Renals"], "https://doi.org/10.21437/Interspeech.2019-1257", 5, "interspeech", 2019]], "Ben Foley": [0, ["Elpis, an Accessible Speech-to-Text Tool", ["Ben Foley", "Alina Rakhi", "Nicholas Lambourne", "Nicholas Buckeridge", "Janet Wiles"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8006.html", 2, "interspeech", 2019]], "Andrea Carmantini": [0, ["Untranscribed Web Audio for Low Resource Speech Recognition", ["Andrea Carmantini", "Peter Bell", "Steve Renals"], "https://doi.org/10.21437/Interspeech.2019-2623", 5, "interspeech", 2019]], "Lyan Verwimp": [0, ["Reverse Transfer Learning: Can Word Embeddings Trained for Different NLP Tasks Improve Neural Language Models?", ["Lyan Verwimp", "Jerome R. Bellegarda"], "https://doi.org/10.21437/Interspeech.2019-1332", 5, "interspeech", 2019]], "Katrin Angerbauer": [0, ["Automatic Compression of Subtitles with Neural Networks and its Effect on User Experience", ["Katrin Angerbauer", "Heike Adel", "Ngoc Thang Vu"], "https://doi.org/10.21437/Interspeech.2019-1750", 5, "interspeech", 2019]], "S. Bayerl": [0, ["Apkinson: A Mobile Solution for Multimodal Assessment of Patients with Parkinson's Disease", ["Juan Camilo Vasquez-Correa", "Tomas Arias-Vergara", "Philipp Klumpp", "M. Strauss", "Arne Kuderle", "Nils Roth", "S. Bayerl", "Nicanor Garcia-Ospina", "Paula Andrea Perez-Toro", "L. Felipe Parra-Gallego", "Cristian David Rios-Urrego", "D. Escobar-Grisales", "Juan Rafael Orozco-Arroyave", "Bjorn Eskofier", "Elmar Noth"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8003.html", 2, "interspeech", 2019]], "Yuriko Yokoe": [0, ["Place Shift as an Autonomous Process: Evidence from Japanese Listeners", ["Yuriko Yokoe"], "https://doi.org/10.21437/Interspeech.2019-2302", 5, "interspeech", 2019]], "Kiyoaki Matsui": [0, ["Neural Whispered Speech Detection with Imbalanced Learning", ["Takanori Ashihara", "Yusuke Shinohara", "Hiroshi Sato", "Takafumi Moriya", "Kiyoaki Matsui", "Takaaki Fukutomi", "Yoshikazu Yamaguchi", "Yushi Aono"], "https://doi.org/10.21437/Interspeech.2019-2161", 5, "interspeech", 2019]], "Vikrant Singh Tomar": [0, ["Speech Model Pre-Training for End-to-End Spoken Language Understanding", ["Loren Lugosch", "Mirco Ravanelli", "Patrick Ignoto", "Vikrant Singh Tomar", "Yoshua Bengio"], "https://doi.org/10.21437/Interspeech.2019-2396", 5, "interspeech", 2019]], "Kenichi Arai": [0, ["Predicting Speech Intelligibility of Enhanced Speech Using Phone Accuracy of DNN-Based ASR System", ["Kenichi Arai", "Shoko Araki", "Atsunori Ogawa", "Keisuke Kinoshita", "Tomohiro Nakatani", "Katsuhiko Yamamoto", "Toshio Irino"], "https://doi.org/10.21437/Interspeech.2019-1381", 5, "interspeech", 2019]], "Jan Michalsky": [0, ["PASCAL and DPA: A Pilot Study on Using Prosodic Competence Scores to Predict Communicative Skills for Team Working and Public Speaking", ["Oliver Niebuhr", "Jan Michalsky"], "https://doi.org/10.21437/Interspeech.2019-3034", 5, "interspeech", 2019], ["Towards the Prosody of Persuasion in Competitive Negotiation. The Relationship Between f0 and Negotiation Success in Same Sex Sales Tasks", ["Jan Michalsky", "Heike Schoormann", "Thomas Schultze"], "https://doi.org/10.21437/Interspeech.2019-3031", 5, "interspeech", 2019]], "Esther de Leeuw": [0, ["An Articulatory-Acoustic Investigation into GOOSE-Fronting in German-English Bilinguals Residing in London, UK", ["Scott Lewis", "Adib Mehrabi", "Esther de Leeuw"], "https://doi.org/10.21437/Interspeech.2019-2637", 5, "interspeech", 2019]], "Chiori Hori": [0, ["Joint Student-Teacher Learning for Audio-Visual Scene-Aware Dialog", ["Chiori Hori", "Anoop Cherian", "Tim K. Marks", "Takaaki Hori"], "https://doi.org/10.21437/Interspeech.2019-3143", 5, "interspeech", 2019]], "Tianchi Liu": [0, ["A Unified Framework for Speaker and Utterance Verification", ["Tianchi Liu", "Maulik C. Madhavi", "Rohan Kumar Das", "Haizhou Li"], "https://doi.org/10.21437/Interspeech.2019-1994", 5, "interspeech", 2019]], "Li-Wei Chen": [0, ["Generative Adversarial Networks for Unpaired Voice Transformation on Impaired Speech", ["Li-Wei Chen", "Hung-yi Lee", "Yu Tsao"], "https://doi.org/10.21437/Interspeech.2019-1265", 5, "interspeech", 2019]], "Zhen Zhang": [0, ["Character-Aware Sub-Word Level Language Modeling for Uyghur and Turkish ASR", ["Chang Liu", "Zhen Zhang", "Pengyuan Zhang", "Yonghong Yan"], "https://doi.org/10.21437/Interspeech.2019-1484", 5, "interspeech", 2019]], "Jean-Pierre Lorre": [0, ["Char+CV-CTC: Combining Graphemes and Consonant/Vowel Units for CTC-Based ASR Using Multitask Learning", ["Abdelwahab Heba", "Thomas Pellegrini", "Jean-Pierre Lorre", "Regine Andre-Obrecht"], "https://doi.org/10.21437/Interspeech.2019-1975", 5, "interspeech", 2019]], "Gabriel Marzinotto": [0, ["Adapting a FrameNet Semantic Parser for Spoken Language Understanding Using Adversarial Learning", ["Gabriel Marzinotto", "Geraldine Damnati", "Frederic Bechet"], "https://doi.org/10.21437/Interspeech.2019-2732", 5, "interspeech", 2019]], "Po-chun Hsu": [0, ["Unsupervised End-to-End Learning of Discrete Linguistic Units for Voice Conversion", ["Andy T. Liu", "Po-chun Hsu", "Hung-yi Lee"], "https://doi.org/10.21437/Interspeech.2019-2048", 5, "interspeech", 2019]], "Vijay Ravi": [0, ["Voice Quality and Between-Frame Entropy for Sleepiness Estimation", ["Vijay Ravi", "Soo Jin Park", "Amber Afshan", "Abeer Alwan"], "https://doi.org/10.21437/Interspeech.2019-2988", 5, "interspeech", 2019]], "Francis Nolan": [0, ["Articulation Rate as a Metric in Spoken Language Assessment", ["Calbert Graham", "Francis Nolan"], "https://doi.org/10.21437/Interspeech.2019-2098", 5, "interspeech", 2019]], "Jun Wang": [0.07243982143700123, ["Early Identification of Speech Changes Due to Amyotrophic Lateral Sclerosis Using Machine Classification", ["Sarah E. Gutz", "Jun Wang", "Yana Yunusova", "Jordan R. Green"], "https://doi.org/10.21437/Interspeech.2019-2967", 5, "interspeech", 2019], ["Towards a Speaker Independent Speech-BCI Using Speaker Adaptation", ["Debadatta Dash", "Alan Wisler", "Paul Ferrari", "Jun Wang"], "https://doi.org/10.21437/Interspeech.2019-3109", 5, "interspeech", 2019], ["Spatial and Spectral Fingerprint in the Brain: Speaker Identification from Single Trial MEG Signals", ["Debadatta Dash", "Paul Ferrari", "Jun Wang"], "https://doi.org/10.21437/Interspeech.2019-3105", 5, "interspeech", 2019], ["Extract, Adapt and Recognize: An End-to-End Neural Network for Corrupted Monaural Speech Recognition", ["Max W. Y. Lam", "Jun Wang", "Xunying Liu", "Helen Meng", "Dan Su", "Dong Yu"], "https://doi.org/10.21437/Interspeech.2019-1626", 5, "interspeech", 2019]], "Zoraida Callejas": [0, ["Predicting Group-Level Skin Attention to Short Movies from Audio-Based LSTM-Mixture of Experts Models", ["Ricardo Kleinlein", "Cristina Luna Jimenez", "Juan Manuel Montero", "Zoraida Callejas", "Fernando Fernandez-Martinez"], "https://doi.org/10.21437/Interspeech.2019-2799", 5, "interspeech", 2019], ["Discovering Dialog Rules by Means of an Evolutionary Approach", ["David Griol", "Zoraida Callejas"], "https://doi.org/10.21437/Interspeech.2019-2230", 5, "interspeech", 2019]], "Christian Bergler": [0, ["Analysis by Adversarial Synthesis - A Novel Approach for Speech Vocoding", ["Ahmed Mustafa", "Arijit Biswas", "Christian Bergler", "Julia Schottenhamml", "Andreas K. Maier"], "https://doi.org/10.21437/Interspeech.2019-1195", 5, "interspeech", 2019], ["The INTERSPEECH 2019 Computational Paralinguistics Challenge: Styrian Dialects, Continuous Sleepiness, Baby Sounds & Orca Activity", ["Bjorn W. Schuller", "Anton Batliner", "Christian Bergler", "Florian B. Pokorny", "Jarek Krajewski", "Margaret Cychosz", "Ralf Vollmann", "Sonja-Dana Roelen", "Sebastian Schnieder", "Elika Bergelson", "Alejandrina Cristia", "Amanda Seidl", "Anne S. Warlaumont", "Lisa Yankowitz", "Elmar Noth", "Shahin Amiriparian", "Simone Hantke", "Maximilian Schmitt"], "https://doi.org/10.21437/Interspeech.2019-1122", 5, "interspeech", 2019], ["Deep Learning for Orca Call Type Identification - A Fully Unsupervised Approach", ["Christian Bergler", "Manuel Schmitt", "Rachael Xi Cheng", "Andreas K. Maier", "Volker Barth", "Elmar Noth"], "https://doi.org/10.21437/Interspeech.2019-1857", 5, "interspeech", 2019]], "Elisabet Eir Cortes": [0, ["No Distributional Learning in Adults from Attended Listening to Non-Speech", ["Ellen Marklund", "Johan Sjons", "Lisa Gustavsson", "Elisabet Eir Cortes"], "https://doi.org/10.21437/Interspeech.2019-1674", 5, "interspeech", 2019]], "Maija Reblin": [0, ["Predicting Behavior in Cancer-Afflicted Patient and Spouse Interactions Using Speech and Language", ["Sandeep Nallan Chakravarthula", "Haoqi Li", "Shao-Yen Tseng", "Maija Reblin", "Panayiotis G. Georgiou"], "https://doi.org/10.21437/Interspeech.2019-1888", 5, "interspeech", 2019]], "Chun Yang": [0.5, ["Pyramid Memory Block and Timestep Attention for Speech Emotion Recognition", ["Miao Cao", "Chun Yang", "Fang Zhou", "Xu-Cheng Yin"], "https://doi.org/10.21437/Interspeech.2019-3140", 5, "interspeech", 2019]], "Andre Nortje": [0, ["Unsupervised Acoustic Unit Discovery for Speech Synthesis Using Discrete Latent-Variable Neural Networks", ["Ryan Eloff", "Andre Nortje", "Benjamin van Niekerk", "Avashna Govender", "Leanne Nortje", "Arnu Pretorius", "Elan Van Biljon", "Ewald van der Westhuizen", "Lisa van Staden", "Herman Kamper"], "https://doi.org/10.21437/Interspeech.2019-1518", 5, "interspeech", 2019]], "Robert Gale": [0, ["Improving ASR Systems for Children with Autism and Language Impairment Using Domain-Focused DNN Transfer Techniques", ["Robert Gale", "Liu Chen", "Jill Dolata", "Jan P. H. van Santen", "Meysam Asgari"], "https://doi.org/10.21437/Interspeech.2019-3161", 5, "interspeech", 2019]], "Ivan Kukanov": [0, ["The I2R's Submission to VOiCES Distance Speaker Recognition Challenge 2019", ["Hanwu Sun", "Kah Kuan Teh", "Ivan Kukanov", "Tran Huy Dat"], "https://doi.org/10.21437/Interspeech.2019-1997", 5, "interspeech", 2019]], "Ville Hautamaki": [0, ["I4U Submission to NIST SRE 2018: Leveraging from a Decade of Shared Experiences", ["Kong Aik Lee", "Ville Hautamaki", "Tomi H. Kinnunen", "Hitoshi Yamamoto", "Koji Okabe", "Ville Vestman", "Jing Huang", "Guohong Ding", "Hanwu Sun", "Anthony Larcher", "Rohan Kumar Das", "Haizhou Li", "Mickael Rouvier", "Pierre-Michel Bousquet", "Wei Rao", "Qing Wang", "Chunlei Zhang", "Fahimeh Bahmaninezhad", "Hector Delgado", "Massimiliano Todisco"], "https://doi.org/10.21437/Interspeech.2019-1533", 5, "interspeech", 2019], ["Towards Debugging Deep Neural Networks by Generating Speech Utterances", ["Bilal Soomro", "Anssi Kanervisto", "Trung Ngo Trong", "Ville Hautamaki"], "https://doi.org/10.21437/Interspeech.2019-2339", 5, "interspeech", 2019]], "Yanan Guo": [0, ["Speech Augmentation via Speaker-Specific Noise in Unseen Environment", ["Yanan Guo", "Ziping Zhao", "Yide Ma", "Bjorn W. Schuller"], "https://doi.org/10.21437/Interspeech.2019-2712", 5, "interspeech", 2019]], "Napoleon Katsos": [0, ["Splash: Speech and Language Assessment in Schools and Homes", ["A. Miwardelli", "I. Gallagher", "J. Gibson", "Napoleon Katsos", "Kate M. Knill", "H. Wood"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8027.html", 2, "interspeech", 2019]], "Meghna Pandharipande": [0, ["Front-End Feature Compensation and Denoising for Noise Robust Speech Emotion Recognition", ["Rupayan Chakraborty", "Ashish Panda", "Meghna Pandharipande", "Sonal Joshi", "Sunil Kumar Kopparapu"], "https://doi.org/10.21437/Interspeech.2019-2243", 5, "interspeech", 2019]], "Marcin Wlodarczak": [0, ["Comparative Analysis of Prosodic Characteristics Using WaveNet Embeddings", ["Antti Suni", "Marcin Wlodarczak", "Martti Vainio", "Juraj Simko"], "https://doi.org/10.21437/Interspeech.2019-2373", 5, "interspeech", 2019], ["Voice Quality as a Turn-Taking Cue", ["Mattias Heldner", "Marcin Wlodarczak", "Stefan Benus", "Agustin Gravano"], "https://doi.org/10.21437/Interspeech.2019-1592", 5, "interspeech", 2019]], "Chongjia Ni": [0, ["Multi-Task Multi-Network Joint-Learning of Deep Residual Networks and Cycle-Consistency Generative Adversarial Networks for Robust Speech Recognition", ["Shengkui Zhao", "Chongjia Ni", "Rong Tong", "Bin Ma"], "https://doi.org/10.21437/Interspeech.2019-2078", 5, "interspeech", 2019], ["Constrained Output Embeddings for End-to-End Code-Switching Speech Recognition with Only Monolingual Data", ["Yerbolat Khassanov", "Haihua Xu", "Van Tung Pham", "Zhiping Zeng", "Eng Siong Chng", "Chongjia Ni", "Bin Ma"], "https://doi.org/10.21437/Interspeech.2019-1867", 5, "interspeech", 2019]], "Shubham Bansal": [0, ["Active Learning Methods for Low Resource End-to-End Speech Recognition", ["Karan Malhotra", "Shubham Bansal", "Sriram Ganapathy"], "https://doi.org/10.21437/Interspeech.2019-2316", 5, "interspeech", 2019]], "Charles Jankowski": [0, ["Optimizing Voice Activity Detection for Noisy Conditions", ["Ruixi Lin", "Charles Costello", "Charles Jankowski", "Vishwas Mruthyunjaya"], "https://doi.org/10.21437/Interspeech.2019-1776", 5, "interspeech", 2019]], "Rajul Acharya": [0, ["Energy Separation-Based Instantaneous Frequency Estimation for Cochlear Cepstral Feature for Replay Spoof Detection", ["Ankur T. Patil", "Rajul Acharya", "Pulikonda Krishna Aditya Sai", "Hemant A. Patil"], "https://doi.org/10.21437/Interspeech.2019-2742", 5, "interspeech", 2019]], "Eric Nyberg": [0, ["Ordinal Triplet Loss: Investigating Sleepiness Detection from Speech", ["Peter Wu", "Sai Krishna Rallabandi", "Alan W. Black", "Eric Nyberg"], "https://doi.org/10.21437/Interspeech.2019-2278", 5, "interspeech", 2019]], "Stefan Benus": [0, ["Voice Quality as a Turn-Taking Cue", ["Mattias Heldner", "Marcin Wlodarczak", "Stefan Benus", "Agustin Gravano"], "https://doi.org/10.21437/Interspeech.2019-1592", 5, "interspeech", 2019]], "Dilek Hakkani-Tur": [0, ["Towards Universal Dialogue Act Tagging for Task-Oriented Dialogues", ["Shachi Paul", "Rahul Goel", "Dilek Hakkani-Tur"], "https://doi.org/10.21437/Interspeech.2019-1866", 5, "interspeech", 2019], ["HyST: A Hybrid Approach for Flexible and Accurate Dialogue State Tracking", ["Rahul Goel", "Shachi Paul", "Dilek Hakkani-Tur"], "https://doi.org/10.21437/Interspeech.2019-1863", 5, "interspeech", 2019], ["Topical-Chat: Towards Knowledge-Grounded Open-Domain Conversations", ["Karthik Gopalakrishnan", "Behnam Hedayatnia", "Qinglang Chen", "Anna Gottardi", "Sanjeev Kwatra", "Anu Venkatesh", "Raefer Gabriel", "Dilek Hakkani-Tur"], "https://doi.org/10.21437/Interspeech.2019-3079", 5, "interspeech", 2019]], "Zhijie Yan": [0, ["Investigation of Transformer Based Spelling Correction Model for CTC-Based End-to-End Mandarin Speech Recognition", ["Shiliang Zhang", "Ming Lei", "Zhijie Yan"], "https://doi.org/10.21437/Interspeech.2019-1290", 5, "interspeech", 2019]], "Ailbhe Ni Chasaide": [0, ["Time to Frequency Domain Mapping of the Voice Source: The Influence of Open Quotient and Glottal Skew on the Low End of the Source Spectrum", ["Christer Gobl", "Ailbhe Ni Chasaide"], "https://doi.org/10.21437/Interspeech.2019-2888", 5, "interspeech", 2019], ["The Role of Voice Quality in the Perception of Prominence in Synthetic Speech", ["Andy Murphy", "Irena Yanushevskaya", "Ailbhe Ni Chasaide", "Christer Gobl"], "https://doi.org/10.21437/Interspeech.2019-2761", 5, "interspeech", 2019]], "Alda Troncone": [0, ["The Dependability of Voice on Elders' Acceptance of Humanoid Agents", ["Anna Esposito", "Terry Amorese", "Marialucia Cuciniello", "Maria Teresa Riviello", "Antonietta Maria Esposito", "Alda Troncone", "Gennaro Cordasco"], "https://doi.org/10.21437/Interspeech.2019-1734", 5, "interspeech", 2019]], "Yuhang Cao": [0, ["Investigation of Cost Function for Supervised Monaural Speech Separation", ["Yun Liu", "Hui Zhang", "Xueliang Zhang", "Yuhang Cao"], "https://doi.org/10.21437/Interspeech.2019-1897", 5, "interspeech", 2019]], "Jorge Llombart": [0, ["Speech Enhancement with Wide Residual Networks in Reverberant Environments", ["Jorge Llombart", "Dayana Ribas", "Antonio Miguel", "Luis Vicente", "Alfonso Ortega Gimenez", "Eduardo Lleida"], "https://doi.org/10.21437/Interspeech.2019-1745", 5, "interspeech", 2019], ["Progressive Speech Enhancement with Residual Connections", ["Jorge Llombart", "Dayana Ribas", "Antonio Miguel", "Luis Vicente", "Alfonso Ortega Gimenez", "Eduardo Lleida"], "https://doi.org/10.21437/Interspeech.2019-1748", 5, "interspeech", 2019], ["Phonetically-Aware Embeddings, Wide Residual Networks with Time-Delay Neural Networks and Self Attention Models for the 2018 NIST Speaker Recognition Evaluation", ["Ignacio Vinals", "Dayana Ribas", "Victoria Mingote", "Jorge Llombart", "Pablo Gimeno", "Antonio Miguel", "Alfonso Ortega Gimenez", "Eduardo Lleida"], "https://doi.org/10.21437/Interspeech.2019-2417", 5, "interspeech", 2019]], "Hannah M. Woeste": [0, ["Using Ultrasound Imaging to Create Augmented Visual Biofeedback for Articulatory Practice", ["Colin T. Annand", "Maurice Lamb", "Sarah Dugan", "Sarah R. Li", "Hannah M. Woeste", "T. Douglas Mast", "Michael A. Riley", "Jack A. Masterson", "Neeraja Mahalingam", "Kathryn J. Eary", "Caroline Spencer", "Suzanne Boyce", "Stephanie Jackson", "Anoosha Baxi", "Renee Seward"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8036.html", 2, "interspeech", 2019]], "Deep Patel": [0, ["Comparison of Speech Tasks and Recording Devices for Voice Based Automatic Classification of Healthy Subjects and Patients with Amyotrophic Lateral Sclerosis", ["Suhas B. N.", "Deep Patel", "Nithin Rao Koluguri", "Yamini Belur", "Pradeep Reddy", "Atchayaram Nalini", "Ravi Yadav", "Dipanjan Gope", "Prasanta Kumar Ghosh"], "https://doi.org/10.21437/Interspeech.2019-1285", 5, "interspeech", 2019]], "Zhiying Huang": [0, ["Audio Tagging with Compact Feedforward Sequential Memory Network and Audio-to-Audio Ratio Based Data Augmentation", ["Zhiying Huang", "Shiliang Zhang", "Ming Lei"], "https://doi.org/10.21437/Interspeech.2019-1302", 5, "interspeech", 2019]], "Shengwu Xiong": [0, ["A Convolutional Neural Network with Non-Local Module for Speech Enhancement", ["Xiaoqi Li", "Yaxing Li", "Meng Li", "Shan Xu", "Yuanjie Dong", "Xinrong Sun", "Shengwu Xiong"], "https://doi.org/10.21437/Interspeech.2019-2472", 5, "interspeech", 2019]], "Kristina Tesch": [0, ["On Nonlinear Spatial Filtering in Multichannel Speech Enhancement", ["Kristina Tesch", "Robert Rehr", "Timo Gerkmann"], "https://doi.org/10.21437/Interspeech.2019-2751", 5, "interspeech", 2019]], "Jamie Pool": [0, ["A Scalable Noisy Speech Dataset and Online Subjective Test Framework", ["Chandan K. A. Reddy", "Ebrahim Beyrami", "Jamie Pool", "Ross Cutler", "Sriram Srinivasan", "Johannes Gehrke"], "https://doi.org/10.21437/Interspeech.2019-3087", 5, "interspeech", 2019]], "Luc Ardaillon": [0, ["Fully-Convolutional Network for Pitch Estimation of Speech Signals", ["Luc Ardaillon", "Axel Roebel"], "https://doi.org/10.21437/Interspeech.2019-2815", 5, "interspeech", 2019]], "Dimitrios Giakoumis": [0, ["Two-Dimensional Convolutional Recurrent Neural Networks for Speech Activity Detection", ["Anastasios Vafeiadis", "Eleftherios Fanioudakis", "Ilyas Potamitis", "Konstantinos Votis", "Dimitrios Giakoumis", "Dimitrios Tzovaras", "Liming Chen", "Raouf Hamzaoui"], "https://doi.org/10.21437/Interspeech.2019-1354", 5, "interspeech", 2019]], "Yusuke Ijima": [0, ["End-to-End Automatic Speech Recognition with a Reconstruction Criterion Using Speech-to-Text and Text-to-Speech Encoder-Decoders", ["Ryo Masumura", "Hiroshi Sato", "Tomohiro Tanaka", "Takafumi Moriya", "Yusuke Ijima", "Takanobu Oba"], "https://doi.org/10.21437/Interspeech.2019-2111", 5, "interspeech", 2019]], "Antti Suni": [0, ["Prosodic Representations of Prominence Classification Neural Networks and Autoencoders Using Bottleneck Features", ["Sofoklis Kakouros", "Antti Suni", "Juraj Simko", "Martti Vainio"], "https://doi.org/10.21437/Interspeech.2019-2984", 5, "interspeech", 2019], ["Comparative Analysis of Prosodic Characteristics Using WaveNet Embeddings", ["Antti Suni", "Marcin Wlodarczak", "Martti Vainio", "Juraj Simko"], "https://doi.org/10.21437/Interspeech.2019-2373", 5, "interspeech", 2019]], "Lukas Mateju": [0, ["An Approach to Online Speaker Change Point Detection Using DNNs and WFSTs", ["Lukas Mateju", "Petr Cerva", "Jindrich Zdansky"], "https://doi.org/10.21437/Interspeech.2019-1407", 5, "interspeech", 2019]], "Pauline Lecomte": [0, ["Analysis of Deep Learning Architectures for Cross-Corpus Speech Emotion Recognition", ["Jack Parry", "Dimitri Palaz", "Georgia Clarke", "Pauline Lecomte", "Rebecca Mead", "Michael Berger", "Gregor Hofer"], "https://doi.org/10.21437/Interspeech.2019-2753", 5, "interspeech", 2019]], "Jian Wu": [0.40413545072078705, ["Improved Speaker-Dependent Separation for CHiME-5 Challenge", ["Jian Wu", "Yong Xu", "Shi-Xiong Zhang", "Lianwu Chen", "Meng Yu", "Lei Xie", "Dong Yu"], "https://doi.org/10.21437/Interspeech.2019-1569", 5, "interspeech", 2019], ["A Comprehensive Study of Speech Separation: Spectrogram vs Waveform Separation", ["Fahimeh Bahmaninezhad", "Jian Wu", "Rongzhi Gu", "Shi-Xiong Zhang", "Yong Xu", "Meng Yu", "Dong Yu"], "https://doi.org/10.21437/Interspeech.2019-3181", 5, "interspeech", 2019]], "Jakub Vit": [0, ["Unified Language-Independent DNN-Based G2P Converter", ["Marketa Juzova", "Daniel Tihelka", "Jakub Vit"], "https://doi.org/10.21437/Interspeech.2019-2335", 5, "interspeech", 2019], ["Web-Based Speech Synthesis Editor", ["Martin Gruber", "Jakub Vit", "Jindrich Matousek"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8013.html", 2, "interspeech", 2019]], "Dijana Petrovska-Delacretaz": [0, ["Comparison of Telephone Recordings and Professional Microphone Recordings for Early Detection of Parkinson's Disease, Using Mel-Frequency Cepstral Coefficients with Gaussian Mixture Models", ["Laetitia Jeancolas", "Graziella Mangone", "Jean-Christophe Corvol", "Marie Vidailhet", "Stephane Lehericy", "Badr-Eddine Benkelfat", "Habib Benali", "Dijana Petrovska-Delacretaz"], "https://doi.org/10.21437/Interspeech.2019-2825", 5, "interspeech", 2019]], "Chang Huai You": [0, ["The I2R's ASR System for the VOiCES from a Distance Challenge 2019", ["Tze Yuang Chong", "Kye Min Tan", "Kah Kuan Teh", "Chang Huai You", "Hanwu Sun", "Tran Huy Dat"], "https://doi.org/10.21437/Interspeech.2019-2130", 5, "interspeech", 2019], ["The I2R's ASR System for the VOiCES from a Distance Challenge 2019", ["Tze Yuang Chong", "Kye Min Tan", "Kah Kuan Teh", "Chang Huai You", "Hanwu Sun", "Tran Huy Dat"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/abs18.html", 0, "interspeech", 2019], ["Device Feature Extractor for Replay Spoofing Detection", ["Chang Huai You", "Jichen Yang", "Huy Dat Tran"], "https://doi.org/10.21437/Interspeech.2019-2137", 5, "interspeech", 2019]], "Seong Ju Kim": [0.9988640397787094, ["Directional Audio Rendering Using a Neural Network Based Personalized HRTF", ["Geon Woo Lee", "Jung Hyuk Lee", "Seong Ju Kim", "Hong Kook Kim"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8005.html", 2, "interspeech", 2019]], "Vicky Zayats": [0, ["Disfluencies and Human Speech Transcription Errors", ["Vicky Zayats", "Trang Tran", "Richard A. Wright", "Courtney Mansfield", "Mari Ostendorf"], "https://doi.org/10.21437/Interspeech.2019-3134", 5, "interspeech", 2019]], "Daniil Kocharov": [0, ["Prosodic Factors Influencing Vowel Reduction in Russian", ["Daniil Kocharov", "Tatiana Kachkovskaia", "Pavel A. Skrelin"], "https://doi.org/10.21437/Interspeech.2019-2918", 5, "interspeech", 2019]], "Logan Ford": [0, ["A Deep Residual Network for Large-Scale Acoustic Scene Analysis", ["Logan Ford", "Hao Tang", "Francois Grondin", "James R. Glass"], "https://doi.org/10.21437/Interspeech.2019-2731", 5, "interspeech", 2019]], "Hyun-Jin Park": [0.980937585234642, ["Improving Keyword Spotting and Language Identification via Neural Architecture Search at Scale", ["Hanna Mazzawi", "Xavi Gonzalvo", "Aleks Kracun", "Prashant Sridhar", "Niranjan Subrahmanya", "Ignacio Lopez-Moreno", "Hyun-Jin Park", "Patrick Violette"], "https://doi.org/10.21437/Interspeech.2019-1916", 5, "interspeech", 2019]], "Noboru Miyazaki": [0, ["Evaluating Intention Communication by TTS Using Explicit Definitions of Illocutionary Act Performance", ["Nobukatsu Hojo", "Noboru Miyazaki"], "https://doi.org/10.21437/Interspeech.2019-2188", 5, "interspeech", 2019]], "Matteo Negri": [0, ["Adapting Transformer to End-to-End Spoken Language Translation", ["Mattia Antonino Di Gangi", "Matteo Negri", "Marco Turchi"], "https://doi.org/10.21437/Interspeech.2019-3045", 5, "interspeech", 2019]], "Antje S. Mefferd": [0, ["Reduced Task Adaptation in Alternating Motion Rate Tasks as an Early Marker of Bulbar Involvement in Amyotrophic Lateral Sclerosis", ["Marziye Eshghi", "Panying Rong", "Antje S. Mefferd", "Kaila L. Stipancic", "Yana Yunusova", "Jordan R. Green"], "https://doi.org/10.21437/Interspeech.2019-2546", 5, "interspeech", 2019]], "Yiping Peng": [0, ["Learning Alignment for Multimodal Emotion Recognition from Speech", ["Haiyang Xu", "Hui Zhang", "Kun Han", "Yun Wang", "Yiping Peng", "Xiangang Li"], "https://doi.org/10.21437/Interspeech.2019-3247", 5, "interspeech", 2019]], "Wonil Chang": [0.8482328802347183, ["An End-to-End Text-Independent Speaker Verification Framework with a Keyword Adversarial Network", ["Sungrack Yun", "Janghoon Cho", "Jungyun Eum", "Wonil Chang", "Kyuwoong Hwang"], "https://doi.org/10.21437/Interspeech.2019-2208", 5, "interspeech", 2019]], "Youssef Oualil": [0, ["Connecting and Comparing Language Model Interpolation Techniques", ["Ernest Pusateri", "Christophe Van Gysel", "Rami Botros", "Sameer Badaskar", "Mirko Hannemann", "Youssef Oualil", "Ilya Oparin"], "https://doi.org/10.21437/Interspeech.2019-1822", 5, "interspeech", 2019]], "Mauricio Zuluaga": [0, ["Fr\u00e9chet Audio Distance: A Reference-Free Metric for Evaluating Music Enhancement Algorithms", ["Kevin Kilgour", "Mauricio Zuluaga", "Dominik Roblek", "Matthew Sharifi"], "https://doi.org/10.21437/Interspeech.2019-2219", 5, "interspeech", 2019]], "Zuowei Wang": [2.6421319559294387e-12, ["Automated Estimation of Oral Reading Fluency During Summer Camp e-Book Reading with MyTurnToRead", ["Anastassia Loukina", "Beata Beigman Klebanov", "Patrick L. Lange", "Yao Qian", "Binod Gyawali", "Nitin Madnani", "Abhinav Misra", "Klaus Zechner", "Zuowei Wang", "John Sabatini"], "https://doi.org/10.21437/Interspeech.2019-2889", 5, "interspeech", 2019]], "Miao Zhao": [0, ["Anti-Spoofing Speaker Verification System with Multi-Feature Integration and Multi-Task Learning", ["Rongjin Li", "Miao Zhao", "Zheng Li", "Lin Li", "Qingyang Hong"], "https://doi.org/10.21437/Interspeech.2019-1698", 5, "interspeech", 2019]], "Shintaro Ando": [0, ["Analysis of Native Listeners' Facial Microexpressions While Shadowing Non-Native Speech - Potential of Shadowers' Facial Expressions for Comprehensibility Prediction", ["Tasavat Trisitichoke", "Shintaro Ando", "Daisuke Saito", "Nobuaki Minematsu"], "https://doi.org/10.21437/Interspeech.2019-1953", 5, "interspeech", 2019]], "Yannis M. Assael": [0, ["Large-Scale Visual Speech Recognition", ["Brendan Shillingford", "Yannis M. Assael", "Matthew W. Hoffman", "Thomas Paine", "Cian Hughes", "Utsav Prabhu", "Hank Liao", "Hasim Sak", "Kanishka Rao", "Lorrayne Bennett", "Marie Mulville", "Misha Denil", "Ben Coppin", "Ben Laurie", "Andrew W. Senior", "Nando de Freitas"], "https://doi.org/10.21437/Interspeech.2019-1669", 5, "interspeech", 2019]], "Li Liu": [0, ["Automatic Detection of the Temporal Segmentation of Hand Movements in British English Cued Speech", ["Li Liu", "Jianze Li", "Gang Feng", "Xiao-Ping Steven Zhang"], "https://doi.org/10.21437/Interspeech.2019-2353", 5, "interspeech", 2019]], "Georgia Zellou": [0, ["Expressiveness Influences Human Vocal Alignment Toward voice-AI", ["Michelle Cohn", "Georgia Zellou"], "https://doi.org/10.21437/Interspeech.2019-1368", 5, "interspeech", 2019], ["Individual Variation in Cognitive Processing Style Predicts Differences in Phonetic Imitation of Device and Human Voices", ["Cathryn Snyder", "Michelle Cohn", "Georgia Zellou"], "https://doi.org/10.21437/Interspeech.2019-2669", 5, "interspeech", 2019], ["The Role of Musical Experience in the Perceptual Weighting of Acoustic Cues for the Obstruent Coda Voicing Contrast in American English", ["Michelle Cohn", "Georgia Zellou", "Santiago Barreda"], "https://doi.org/10.21437/Interspeech.2019-3103", 5, "interspeech", 2019], ["Perceptual Adaptation to Device and Human Voices: Learning and Generalization of a Phonetic Shift Across Real and Voice-AI Talkers", ["Bruno Ferenc Segedin", "Michelle Cohn", "Georgia Zellou"], "https://doi.org/10.21437/Interspeech.2019-1433", 5, "interspeech", 2019]], "Amanda Seidl": [0, ["The INTERSPEECH 2019 Computational Paralinguistics Challenge: Styrian Dialects, Continuous Sleepiness, Baby Sounds & Orca Activity", ["Bjorn W. Schuller", "Anton Batliner", "Christian Bergler", "Florian B. Pokorny", "Jarek Krajewski", "Margaret Cychosz", "Ralf Vollmann", "Sonja-Dana Roelen", "Sebastian Schnieder", "Elika Bergelson", "Alejandrina Cristia", "Amanda Seidl", "Anne S. Warlaumont", "Lisa Yankowitz", "Elmar Noth", "Shahin Amiriparian", "Simone Hantke", "Maximilian Schmitt"], "https://doi.org/10.21437/Interspeech.2019-1122", 5, "interspeech", 2019], ["Towards Detection of Canonical Babbling by Citizen Scientists: Performance as a Function of Clip Length", ["Amanda Seidl", "Anne S. Warlaumont", "Alejandrina Cristia"], "https://doi.org/10.21437/Interspeech.2019-1773", 5, "interspeech", 2019]], "Chelzy Belitz": [0, ["A Machine Learning Based Clustering Protocol for Determining Hearing Aid Initial Configurations from Pure-Tone Audiograms", ["Chelzy Belitz", "Hussnain Ali", "John H. L. Hansen"], "https://doi.org/10.21437/Interspeech.2019-3091", 5, "interspeech", 2019]], "Daniel Tihelka": [0, ["Unified Language-Independent DNN-Based G2P Converter", ["Marketa Juzova", "Daniel Tihelka", "Jakub Vit"], "https://doi.org/10.21437/Interspeech.2019-2335", 5, "interspeech", 2019]], "Sridha Sridharan": [0, ["A Study of x-Vector Based Speaker Recognition on Short Utterances", ["Ahilan Kanagasundaram", "Sridha Sridharan", "Ganapathy Sriram", "S. Prachi", "Clinton Fookes"], "https://doi.org/10.21437/Interspeech.2019-1891", 5, "interspeech", 2019]], "Henk van den Heuvel": [0, ["Large-Scale Speaker Diarization of Radio Broadcast Archives", ["Emre Yilmaz", "Adem Derinel", "Kun Zhou", "Henk van den Heuvel", "Niko Brummer", "Haizhou Li", "David A. van Leeuwen"], "https://doi.org/10.21437/Interspeech.2019-1399", 5, "interspeech", 2019]], "Sufeng Niu": [0, ["Speech Enhancement Using Forked Generative Adversarial Networks with Spectral Subtraction", ["Ju Lin", "Sufeng Niu", "Zice Wei", "Xiang Lan", "Adriaan J. van Wijngaarden", "Melissa C. Smith", "Kuang-Ching Wang"], "https://doi.org/10.21437/Interspeech.2019-2954", 5, "interspeech", 2019]], "Shehzeen Hussain": [0, ["Universal Adversarial Perturbations for Speech Recognition Systems", ["Paarth Neekhara", "Shehzeen Hussain", "Prakhar Pandey", "Shlomo Dubnov", "Julian J. McAuley", "Farinaz Koushanfar"], "https://doi.org/10.21437/Interspeech.2019-1353", 5, "interspeech", 2019]], "Andrew Rosenberg": [0, ["Learning to Speak Fluently in a Foreign Language: Multilingual Speech Synthesis and Cross-Language Voice Cloning", ["Yu Zhang", "Ron J. Weiss", "Heiga Zen", "Yonghui Wu", "Zhifeng Chen", "R. J. Skerry-Ryan", "Ye Jia", "Andrew Rosenberg", "Bhuvana Ramabhadran"], "https://doi.org/10.21437/Interspeech.2019-2668", 5, "interspeech", 2019]], "Ju-ho Kim": [0.6127787604928017, ["RawNet: Advanced End-to-End Deep Neural Network Using Raw Waveforms for Text-Independent Speaker Verification", ["Jee-weon Jung", "Hee-Soo Heo", "Ju-ho Kim", "Hye-jin Shim", "Ha-Jin Yu"], "https://doi.org/10.21437/Interspeech.2019-1982", 5, "interspeech", 2019]], "Jinyu Li": [0, ["Speaker Adaptation for Attention-Based End-to-End Speech Recognition", ["Zhong Meng", "Yashesh Gaur", "Jinyu Li", "Yifan Gong"], "https://doi.org/10.21437/Interspeech.2019-3135", 5, "interspeech", 2019], ["Layer Trajectory BLSTM", ["Eric Sun", "Jinyu Li", "Yifan Gong"], "https://doi.org/10.21437/Interspeech.2019-2971", 5, "interspeech", 2019], ["Acoustic-to-Phrase Models for Speech Recognition", ["Yashesh Gaur", "Jinyu Li", "Zhong Meng", "Yifan Gong"], "https://doi.org/10.21437/Interspeech.2019-3056", 5, "interspeech", 2019]], "Yuanjie Dong": [2.492428663458668e-08, ["A Convolutional Neural Network with Non-Local Module for Speech Enhancement", ["Xiaoqi Li", "Yaxing Li", "Meng Li", "Shan Xu", "Yuanjie Dong", "Xinrong Sun", "Shengwu Xiong"], "https://doi.org/10.21437/Interspeech.2019-2472", 5, "interspeech", 2019]], "Masahito Togami": [0, ["Variational Bayesian Multi-Channel Speech Dereverberation Under Noisy Environments with Probabilistic Convolutive Transfer Function", ["Masahito Togami", "Tatsuya Komatsu"], "https://doi.org/10.21437/Interspeech.2019-1220", 5, "interspeech", 2019], ["Multichannel Loss Function for Supervised Speech Source Separation by Mask-Based Beamforming", ["Yoshiki Masuyama", "Masahito Togami", "Tatsuya Komatsu"], "https://doi.org/10.21437/Interspeech.2019-1289", 5, "interspeech", 2019]], "Prakhar Pandey": [0, ["Universal Adversarial Perturbations for Speech Recognition Systems", ["Paarth Neekhara", "Shehzeen Hussain", "Prakhar Pandey", "Shlomo Dubnov", "Julian J. McAuley", "Farinaz Koushanfar"], "https://doi.org/10.21437/Interspeech.2019-1353", 5, "interspeech", 2019]], "Michael Dietz": [0, ["Relevance-Based Feature Masking: Improving Neural Network Based Whale Classification Through Explainable Artificial Intelligence", ["Dominik Schiller", "Tobias Huber", "Florian Lingenfelser", "Michael Dietz", "Andreas Seiderer", "Elisabeth Andre"], "https://doi.org/10.21437/Interspeech.2019-2707", 5, "interspeech", 2019]], "Chi-Chun Lee": [0.2932860553264618, ["Attentive to Individual: A Multimodal Emotion Recognition Network with Personalized Attention Profile", ["Jeng-Lin Li", "Chi-Chun Lee"], "https://doi.org/10.21437/Interspeech.2019-2044", 5, "interspeech", 2019], ["Predicting Group Performances Using a Personality Composite-Network Architecture During Collaborative Task", ["Shun-Chang Zhong", "Yun-Shao Lin", "Chun-Min Chang", "Yi-Ching Liu", "Chi-Chun Lee"], "https://doi.org/10.21437/Interspeech.2019-2087", 5, "interspeech", 2019], ["Enforcing Semantic Consistency for Cross Corpus Valence Regression from Speech Using Adversarial Discrepancy Learning", ["Gao-Yi Chao", "Yun-Shao Lin", "Chun-Min Chang", "Chi-Chun Lee"], "https://doi.org/10.21437/Interspeech.2019-2037", 5, "interspeech", 2019], ["Acoustic Indicators of Deception in Mandarin Daily Conversations Recorded from an Interactive Game", ["Chih-Hsiang Huang", "Huang-Cheng Chou", "Yi-Tong Wu", "Chi-Chun Lee", "Yi-Wen Liu"], "https://doi.org/10.21437/Interspeech.2019-2216", 5, "interspeech", 2019], ["Using Attention Networks and Adversarial Augmentation for Styrian Dialect Continuous Sleepiness and Baby Sound Recognition", ["Sung-Lin Yeh", "Gao-Yi Chao", "Bo-Hao Su", "Yu-Lin Huang", "Meng-Han Lin", "Yin-Chun Tsai", "Yu-Wen Tai", "Zheng-Chi Lu", "Chieh-Yu Chen", "Tsung-Ming Tai", "Chiu-Wang Tseng", "Cheng-Kuang Lee", "Chi-Chun Lee"], "https://doi.org/10.21437/Interspeech.2019-2110", 5, "interspeech", 2019], ["Investigating the Variability of Voice Quality and Pain Levels as a Function of Multiple Clinical Parameters", ["Hui-Ting Hong", "Jeng-Lin Li", "Yi-Ming Weng", "Chip-Jin Ng", "Chi-Chun Lee"], "https://doi.org/10.21437/Interspeech.2019-2247", 5, "interspeech", 2019]], "Tianyu Zhao": [0, ["Improved End-to-End Speech Emotion Recognition Using Self Attention Mechanism and Multitask Learning", ["Yuanchao Li", "Tianyu Zhao", "Tatsuya Kawahara"], "https://doi.org/10.21437/Interspeech.2019-2594", 5, "interspeech", 2019]], "Ming Li": [0, ["LSTM Based Similarity Measurement with Spectral Clustering for Speaker Diarization", ["Qingjian Lin", "Ruiqing Yin", "Ming Li", "Herve Bredin", "Claude Barras"], "https://doi.org/10.21437/Interspeech.2019-1388", 5, "interspeech", 2019], ["The DKU Replay Detection System for the ASVspoof 2019 Challenge: On Data Augmentation, Feature Representation, Classification, and Fusion", ["Weicheng Cai", "Haiwei Wu", "Danwei Cai", "Ming Li"], "https://doi.org/10.21437/Interspeech.2019-1230", 5, "interspeech", 2019], ["Survey Talk: End-to-End Deep Neural Network Based Speaker and Language Recognition", ["Ming Li", "Weicheng Cai", "Danwei Cai"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/abs10.html", 0, "interspeech", 2019], ["Polyphone Disambiguation for Mandarin Chinese Using Conditional Neural Network with Multi-Level Embedding Features", ["Zexin Cai", "Yaogen Yang", "Chuxiong Zhang", "Xiaoyi Qin", "Ming Li"], "https://doi.org/10.21437/Interspeech.2019-1235", 5, "interspeech", 2019], ["The DKU-LENOVO Systems for the INTERSPEECH 2019 Computational Paralinguistic Challenge", ["Haiwei Wu", "Weiqing Wang", "Ming Li"], "https://doi.org/10.21437/Interspeech.2019-1386", 5, "interspeech", 2019], ["The DKU System for the Speaker Recognition Task of the 2019 VOiCES from a Distance Challenge", ["Danwei Cai", "Xiaoyi Qin", "Weicheng Cai", "Ming Li"], "https://doi.org/10.21437/Interspeech.2019-1435", 5, "interspeech", 2019], ["Far-Field End-to-End Text-Dependent Speaker Verification Based on Mixed Training Data with Transfer Learning and Enrollment Data Augmentation", ["Xiaoyi Qin", "Danwei Cai", "Ming Li"], "https://doi.org/10.21437/Interspeech.2019-1542", 5, "interspeech", 2019], ["Multi-Channel Training for End-to-End Speaker Recognition Under Reverberant and Noisy Environment", ["Danwei Cai", "Xiaoyi Qin", "Ming Li"], "https://doi.org/10.21437/Interspeech.2019-1437", 5, "interspeech", 2019], ["The DKU-SMIIP System for NIST 2018 Speaker Recognition Evaluation", ["Danwei Cai", "Weicheng Cai", "Ming Li"], "https://doi.org/10.21437/Interspeech.2019-1436", 5, "interspeech", 2019]], "Christoph Luscher": [0, ["RWTH ASR Systems for LibriSpeech: Hybrid vs Attention", ["Christoph Luscher", "Eugen Beck", "Kazuki Irie", "Markus Kitza", "Wilfried Michel", "Albert Zeyer", "Ralf Schluter", "Hermann Ney"], "https://doi.org/10.21437/Interspeech.2019-1780", 5, "interspeech", 2019]], "Tomasz Rutowski": [0, ["Optimizing Speech-Input Length for Speaker-Independent Depression Classification", ["Tomasz Rutowski", "Amir Harati", "Yang Lu", "Elizabeth Shriberg"], "https://doi.org/10.21437/Interspeech.2019-3095", 5, "interspeech", 2019]], "DeLiang Wang": [0.0001271415312658064, ["Bridging the Gap Between Monaural Speech Enhancement and Recognition with Distortion-Independent Acoustic Modeling", ["Peidong Wang", "Ke Tan", "DeLiang Wang"], "https://doi.org/10.21437/Interspeech.2019-1495", 5, "interspeech", 2019], ["Enhanced Spectral Features for Distortion-Independent Acoustic Modeling", ["Peidong Wang", "DeLiang Wang"], "https://doi.org/10.21437/Interspeech.2019-1493", 5, "interspeech", 2019], ["Deep Learning Based Multi-Channel Speaker Recognition in Noisy and Reverberant Environments", ["Hassan Taherian", "Zhong-Qiu Wang", "DeLiang Wang"], "https://doi.org/10.21437/Interspeech.2019-1428", 5, "interspeech", 2019], ["Deep Learning for Joint Acoustic Echo and Noise Cancellation with Nonlinear Distortions", ["Hao Zhang", "Ke Tan", "DeLiang Wang"], "https://doi.org/10.21437/Interspeech.2019-2651", 5, "interspeech", 2019]], "Lei He": [0, ["Forward-Backward Decoding for Regularizing End-to-End TTS", ["Yibin Zheng", "Xi Wang", "Lei He", "Shifeng Pan", "Frank K. Soong", "Zhengqi Wen", "Jianhua Tao"], "https://doi.org/10.21437/Interspeech.2019-2325", 5, "interspeech", 2019], ["A New GAN-Based End-to-End TTS Training Algorithm", ["Haohan Guo", "Frank K. Soong", "Lei He", "Lei Xie"], "https://doi.org/10.21437/Interspeech.2019-2176", 5, "interspeech", 2019], ["Robust Sequence-to-Sequence Acoustic Modeling with Stepwise Monotonic Attention for Neural TTS", ["Mutian He", "Yan Deng", "Lei He"], "https://doi.org/10.21437/Interspeech.2019-1972", 5, "interspeech", 2019], ["Exploiting Syntactic Features in a Parsed Tree to Improve End-to-End TTS", ["Haohan Guo", "Frank K. Soong", "Lei He", "Lei Xie"], "https://doi.org/10.21437/Interspeech.2019-2167", 5, "interspeech", 2019]], "Oh-Wook Kwon": [0.9998743832111359, ["Extending an Acoustic Data-Driven Phone Set for Spontaneous Speech Recognition", ["Jeong-Uk Bang", "Mu-Yeol Choi", "Sang-Hun Kim", "Oh-Wook Kwon"], "https://doi.org/10.21437/Interspeech.2019-1979", 5, "interspeech", 2019]], "Kun Han": [0.008101410465314984, ["Learning Alignment for Multimodal Emotion Recognition from Speech", ["Haiyang Xu", "Hui Zhang", "Kun Han", "Yun Wang", "Yiping Peng", "Xiangang Li"], "https://doi.org/10.21437/Interspeech.2019-3247", 5, "interspeech", 2019]], "Annett Jorschick": [0, ["Nasal Consonant Discrimination in Infant- and Adult-Directed Speech", ["Bogdan Ludusan", "Annett Jorschick", "Reiko Mazuka"], "https://doi.org/10.21437/Interspeech.2019-1737", 5, "interspeech", 2019]], "Mohan Li": [0, ["Framewise Supervised Training Towards End-to-End Speech Recognition Models: First Results", ["Mohan Li", "Yuanjiang Cao", "Weicong Zhou", "Min Liu"], "https://doi.org/10.21437/Interspeech.2019-1117", 5, "interspeech", 2019]], "Scott Lewis": [0, ["An Articulatory-Acoustic Investigation into GOOSE-Fronting in German-English Bilinguals Residing in London, UK", ["Scott Lewis", "Adib Mehrabi", "Esther de Leeuw"], "https://doi.org/10.21437/Interspeech.2019-2637", 5, "interspeech", 2019]], "Rebecca Nissen": [0, ["Using Real-Time Visual Biofeedback for Second Language Instruction", ["Shawn L. Nissen", "Rebecca Nissen"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8016.html", 2, "interspeech", 2019]], "Thomas Mulc": [0, ["CSS10: A Collection of Single Speaker Speech Datasets for 10 Languages", ["Kyubyong Park", "Thomas Mulc"], "https://doi.org/10.21437/Interspeech.2019-1500", 5, "interspeech", 2019]], "Shan Luo": [0, ["Phonetic Detail Encoding in Explaining the Size of Speech Planning Window", ["Shan Luo"], "https://doi.org/10.21437/Interspeech.2019-1412", 5, "interspeech", 2019]], "Kong Aik Lee": [2.7774383966061578e-06, ["Unleashing the Unused Potential of i-Vectors Enabled by GPU Acceleration", ["Ville Vestman", "Kong Aik Lee", "Tomi H. Kinnunen", "Takafumi Koshinaka"], "https://doi.org/10.21437/Interspeech.2019-1955", 5, "interspeech", 2019], ["Speaker Augmentation and Bandwidth Extension for Deep Speaker Embedding", ["Hitoshi Yamamoto", "Kong Aik Lee", "Koji Okabe", "Takafumi Koshinaka"], "https://doi.org/10.21437/Interspeech.2019-1508", 5, "interspeech", 2019], ["ASVspoof 2019: Future Horizons in Spoofed and Fake Audio Detection", ["Massimiliano Todisco", "Xin Wang", "Ville Vestman", "Md. Sahidullah", "Hector Delgado", "Andreas Nautsch", "Junichi Yamagishi", "Nicholas W. D. Evans", "Tomi H. Kinnunen", "Kong Aik Lee"], "https://doi.org/10.21437/Interspeech.2019-2249", 5, "interspeech", 2019], ["I4U Submission to NIST SRE 2018: Leveraging from a Decade of Shared Experiences", ["Kong Aik Lee", "Ville Hautamaki", "Tomi H. Kinnunen", "Hitoshi Yamamoto", "Koji Okabe", "Ville Vestman", "Jing Huang", "Guohong Ding", "Hanwu Sun", "Anthony Larcher", "Rohan Kumar Das", "Haizhou Li", "Mickael Rouvier", "Pierre-Michel Bousquet", "Wei Rao", "Qing Wang", "Chunlei Zhang", "Fahimeh Bahmaninezhad", "Hector Delgado", "Massimiliano Todisco"], "https://doi.org/10.21437/Interspeech.2019-1533", 5, "interspeech", 2019], ["The NEC-TT 2018 Speaker Verification System", ["Kong Aik Lee", "Hitoshi Yamamoto", "Koji Okabe", "Qiongqiong Wang", "Ling Guo", "Takafumi Koshinaka", "Jiacen Zhang", "Koichi Shinoda"], "https://doi.org/10.21437/Interspeech.2019-1517", 5, "interspeech", 2019]], "Pedro Rodriguez": [0, ["Mitigating Noisy Inputs for Question Answering", ["Denis Peskov", "Joe Barrow", "Pedro Rodriguez", "Graham Neubig", "Jordan L. Boyd-Graber"], "https://doi.org/10.21437/Interspeech.2019-3154", 5, "interspeech", 2019]], "Mark Liberman": [0, ["The Second DIHARD Diarization Challenge: Dataset, Task, and Baselines", ["Neville Ryant", "Kenneth Church", "Christopher Cieri", "Alejandrina Cristia", "Jun Du", "Sriram Ganapathy", "Mark Liberman"], "https://doi.org/10.21437/Interspeech.2019-1268", 5, "interspeech", 2019], ["Automatic Detection of Autism Spectrum Disorder in Children Using Acoustic and Text Features from Brief Natural Conversations", ["Sunghye Cho", "Mark Liberman", "Neville Ryant", "Meredith Cola", "Robert T. Schultz", "Julia Parish-Morris"], "https://doi.org/10.21437/Interspeech.2019-1452", 5, "interspeech", 2019], ["Automatic Detection of Prosodic Focus in American English", ["Sunghye Cho", "Mark Liberman", "Yong-cheol Lee"], "https://doi.org/10.21437/Interspeech.2019-1668", 5, "interspeech", 2019]], "Abdolreza Sabzi Shahrebabaki": [0, ["A Phonetic-Level Analysis of Different Input Features for Articulatory Inversion", ["Abdolreza Sabzi Shahrebabaki", "Negar Olfati", "Ali Shariq Imran", "Sabato Marco Siniscalchi", "Torbjorn Svendsen"], "https://doi.org/10.21437/Interspeech.2019-2526", 5, "interspeech", 2019]], "Ming-Hsiang Su": [0, ["Follow-Up Question Generation Using Neural Tensor Network-Based Domain Ontology Population in an Interview Coaching System", ["Ming-Hsiang Su", "Chung-Hsien Wu", "Yi Chang"], "https://doi.org/10.21437/Interspeech.2019-1300", 5, "interspeech", 2019]], "Zofia Malisz": [0, ["How to Annotate 100 Hours in 45 Minutes", ["Per Fallgren", "Zofia Malisz", "Jens Edlund"], "https://doi.org/10.21437/Interspeech.2019-1648", 5, "interspeech", 2019]], "Yiteng Huang": [0, ["Multi-Microphone Adaptive Noise Cancellation for Robust Hotword Detection", ["Yiteng Huang", "Turaj Zakizadeh Shabestary", "Alexander Gruenstein", "Li Wan"], "https://doi.org/10.21437/Interspeech.2019-3006", 5, "interspeech", 2019]], "Takanori Ashihara": [0, ["Neural Whispered Speech Detection with Imbalanced Learning", ["Takanori Ashihara", "Yusuke Shinohara", "Hiroshi Sato", "Takafumi Moriya", "Kiyoaki Matsui", "Takaaki Fukutomi", "Yoshikazu Yamaguchi", "Yushi Aono"], "https://doi.org/10.21437/Interspeech.2019-2161", 5, "interspeech", 2019]], "Xiaofei Wang": [3.716871946231055e-15, ["Exploring Methods for the Automatic Detection of Errors in Manual Transcription", ["Xiaofei Wang", "Jinyi Yang", "Ruizhi Li", "Samik Sadhu", "Hynek Hermansky"], "https://doi.org/10.21437/Interspeech.2019-1343", 5, "interspeech", 2019]], "Thomas Schneider": [0, ["Privacy-Preserving Speaker Recognition with Cohort Score Normalisation", ["Andreas Nautsch", "Jose Patino", "Amos Treiber", "Themos Stafylakis", "Petr Mizera", "Massimiliano Todisco", "Thomas Schneider", "Nicholas W. D. Evans"], "https://doi.org/10.21437/Interspeech.2019-2638", 5, "interspeech", 2019]], "Chien-Feng Liao": [0, ["Incorporating Symbolic Sequential Modeling for Speech Enhancement", ["Chien-Feng Liao", "Yu Tsao", "Xugang Lu", "Hisashi Kawai"], "https://doi.org/10.21437/Interspeech.2019-1777", 5, "interspeech", 2019], ["Noise Adaptive Speech Enhancement Using Domain Adversarial Training", ["Chien-Feng Liao", "Yu Tsao", "Hung-yi Lee", "Hsin-Min Wang"], "https://doi.org/10.21437/Interspeech.2019-1519", 5, "interspeech", 2019]], "Tatsuya Kitamura": [0, ["Speech Organ Contour Extraction Using Real-Time MRI and Machine Learning Method", ["Hironori Takemoto", "Tsubasa Goto", "Yuya Hagihara", "Sayaka Hamanaka", "Tatsuya Kitamura", "Yukiko Nota", "Kikuo Maekawa"], "https://doi.org/10.21437/Interspeech.2019-1593", 5, "interspeech", 2019]], "Ilyas Potamitis": [0, ["Two-Dimensional Convolutional Recurrent Neural Networks for Speech Activity Detection", ["Anastasios Vafeiadis", "Eleftherios Fanioudakis", "Ilyas Potamitis", "Konstantinos Votis", "Dimitrios Giakoumis", "Dimitrios Tzovaras", "Liming Chen", "Raouf Hamzaoui"], "https://doi.org/10.21437/Interspeech.2019-1354", 5, "interspeech", 2019]], "Diyuan Liu": [0, ["Acoustic Model Ensembling Using Effective Data Augmentation for CHiME-5 Challenge", ["Feng Ma", "Li Chai", "Jun Du", "Diyuan Liu", "Zhongfu Ye", "Chin-Hui Lee"], "https://doi.org/10.21437/Interspeech.2019-2601", 5, "interspeech", 2019]], "Yi Zhao": [0, ["Does the Lombard Effect Improve Emotional Communication in Noise? - Analysis of Emotional Speech Acted in Noise", ["Yi Zhao", "Atsushi Ando", "Shinji Takaki", "Junichi Yamagishi", "Satoshi Kobashikawa"], "https://doi.org/10.21437/Interspeech.2019-1605", 5, "interspeech", 2019]], "Masayuki Misaki": [0, ["Small-Footprint Magic Word Detection Method Using Convolutional LSTM Neural Network", ["Taiki Yamamoto", "Ryota Nishimura", "Masayuki Misaki", "Norihide Kitaoka"], "https://doi.org/10.21437/Interspeech.2019-1662", 5, "interspeech", 2019]], "Jonathan Stuefer": [0, ["Sound Tools eXtended (STx) 5.0 - A Powerful Sound Analysis Tool Optimized for Speech", ["Anton Noll", "Jonathan Stuefer", "Nicola Klingler", "Hannah Leykum", "Carina Lozo", "Jan Luttenberger", "Michael Pucher", "Carolin Schmid"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8022.html", 2, "interspeech", 2019]], "Mark A. Hasegawa-Johnson": [0, ["Learning Speaker Aware Offsets for Speaker Adaptation of Neural Networks", ["Leda Sari", "Samuel Thomas", "Mark A. Hasegawa-Johnson"], "https://doi.org/10.21437/Interspeech.2019-1788", 5, "interspeech", 2019], ["The Neural Correlates Underlying Lexically-Guided Perceptual Learning", ["Odette Scharenborg", "Jiska Koemans", "Cybelle Smith", "Mark A. Hasegawa-Johnson", "Kara D. Federmeier"], "https://doi.org/10.21437/Interspeech.2019-2328", 5, "interspeech", 2019], ["Multimodal Word Discovery and Retrieval with Phone Sequence and Image Concepts", ["Liming Wang", "Mark A. Hasegawa-Johnson"], "https://doi.org/10.21437/Interspeech.2019-1487", 5, "interspeech", 2019], ["Study of the Performance of Automatic Speech Recognition Systems in Speakers with Parkinson's Disease", ["Laureano Moro-Velazquez", "Jaejin Cho", "Shinji Watanabe", "Mark A. Hasegawa-Johnson", "Odette Scharenborg", "Heejin Kim", "Najim Dehak"], "https://doi.org/10.21437/Interspeech.2019-2993", 5, "interspeech", 2019]], "Catherine T. Best": [0, ["Cognitive Factors in Thai-Na\u00efve Mandarin Speakers' Imitation of Thai Lexical Tones", ["Juqiang Chen", "Catherine T. Best", "Mark Antoniou"], "https://doi.org/10.21437/Interspeech.2019-1403", 5, "interspeech", 2019]], "Chris Davis": [0, ["Perceiving Older Adults Producing Clear and Lombard Speech", ["Chris Davis", "Jeesun Kim"], "https://doi.org/10.21437/Interspeech.2019-2210", 5, "interspeech", 2019]], "Hassan Taherian": [0, ["Deep Learning Based Multi-Channel Speaker Recognition in Noisy and Reverberant Environments", ["Hassan Taherian", "Zhong-Qiu Wang", "DeLiang Wang"], "https://doi.org/10.21437/Interspeech.2019-1428", 5, "interspeech", 2019]], "Marek Hruz": [0, ["UWB-NTIS Speaker Diarization System for the DIHARD II 2019 Challenge", ["Zbynek Zajic", "Marie Kunesova", "Marek Hruz", "Jan Vanek"], "https://doi.org/10.21437/Interspeech.2019-1385", 5, "interspeech", 2019]], "Carla Agurto": [0, ["A New Approach for Automating Analysis of Responses on Verbal Fluency Tests from Subjects At-Risk for Schizophrenia", ["Mary Pietrowicz", "Carla Agurto", "Raquel Norel", "Elif Eyigoz", "Guillermo A. Cecchi", "Zarina R. Bilgrami", "Cheryl Corcoran"], "https://doi.org/10.21437/Interspeech.2019-2987", 5, "interspeech", 2019]], "Kaylah Lalonde": [0, ["Effects of Natural Variability in Cross-Modal Temporal Correlations on Audiovisual Speech Recognition Benefit", ["Kaylah Lalonde"], "https://doi.org/10.21437/Interspeech.2019-2931", 5, "interspeech", 2019]], "Arnu Pretorius": [0, ["Unsupervised Acoustic Unit Discovery for Speech Synthesis Using Discrete Latent-Variable Neural Networks", ["Ryan Eloff", "Andre Nortje", "Benjamin van Niekerk", "Avashna Govender", "Leanne Nortje", "Arnu Pretorius", "Elan Van Biljon", "Ewald van der Westhuizen", "Lisa van Staden", "Herman Kamper"], "https://doi.org/10.21437/Interspeech.2019-1518", 5, "interspeech", 2019]], "Lau Wing Chung": [3.3131886567616675e-08, ["The CUHK Dysarthric Speech Recognition Systems for English and Cantonese", ["Shoukang Hu", "Shansong Liu", "Heng Fai Chang", "Mengzhe Geng", "Jiani Chen", "Lau Wing Chung", "To Ka Hei", "Jianwei Yu", "Ka Ho Wong", "Xunying Liu", "Helen Meng"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8047.html", 2, "interspeech", 2019]], "Shicai Yang": [5.108859002511679e-09, ["An End-to-End Audio Classification System Based on Raw Waveforms and Mix-Training Strategy", ["Jiaxu Chen", "Jing Hao", "Kai Chen", "Di Xie", "Shicai Yang", "Shiliang Pu"], "https://doi.org/10.21437/Interspeech.2019-1579", 5, "interspeech", 2019]], "Meysam Shamsi": [0, ["Corpus Design Using Convolutional Auto-Encoder Embeddings for Audio-Book Synthesis", ["Meysam Shamsi", "Damien Lolive", "Nelly Barbot", "Jonathan Chevelu"], "https://doi.org/10.21437/Interspeech.2019-2190", 5, "interspeech", 2019]], "Yosi Shrem": [0, ["Dr.VOT: Measuring Positive and Negative Voice Onset Time in the Wild", ["Yosi Shrem", "Matthew Goldrick", "Joseph Keshet"], "https://doi.org/10.21437/Interspeech.2019-1735", 5, "interspeech", 2019]], "Shuangshuang Zhu": [0, ["Acoustic Characteristics of Lexical Tone Disruption in Mandarin Speakers After Brain Damage", ["Wenjun Chen", "Jeroen van de Weijer", "Shuangshuang Zhu", "Qian Qian", "Manna Wang"], "https://doi.org/10.21437/Interspeech.2019-2432", 5, "interspeech", 2019]], "William L. Hamilton": [0, ["Neural Transfer Learning for Cry-Based Diagnosis of Perinatal Asphyxia", ["Charles C. Onu", "Jonathan Lebensold", "William L. Hamilton", "Doina Precup"], "https://doi.org/10.21437/Interspeech.2019-2340", 5, "interspeech", 2019]], "Yi-Ching Liu": [0, ["Predicting Group Performances Using a Personality Composite-Network Architecture During Collaborative Task", ["Shun-Chang Zhong", "Yun-Shao Lin", "Chun-Min Chang", "Yi-Ching Liu", "Chi-Chun Lee"], "https://doi.org/10.21437/Interspeech.2019-2087", 5, "interspeech", 2019]], "Prathosh A. P.": [0, ["Detection of Glottal Closure Instants from Raw Speech Using Convolutional Neural Networks", ["Mohit Goyal", "Varun Srivastava", "Prathosh A. P."], "https://doi.org/10.21437/Interspeech.2019-2587", 5, "interspeech", 2019]], "Ding Zhao": [0, ["Shallow-Fusion End-to-End Contextual Biasing", ["Ding Zhao", "Tara N. Sainath", "David Rybach", "Pat Rondon", "Deepti Bhatia", "Bo Li", "Ruoming Pang"], "https://doi.org/10.21437/Interspeech.2019-1209", 5, "interspeech", 2019]], "Gabriel Mittag": [0, ["Quality Degradation Diagnosis for Voice Networks - Estimating the Perceived Noisiness, Coloration, and Discontinuity of Transmitted Speech", ["Gabriel Mittag", "Sebastian Moller"], "https://doi.org/10.21437/Interspeech.2019-2636", 5, "interspeech", 2019], ["Extending the E-Model Towards Super-Wideband and Fullband Speech Communication Scenarios", ["Sebastian Moller", "Gabriel Mittag", "Thilo Michael", "Vincent Barriac", "Hitoshi Aoki"], "https://doi.org/10.21437/Interspeech.2019-1340", 5, "interspeech", 2019]], "Nasir D. Memon": [0, ["Adversarial Optimization for Dictionary Attacks on Speaker Verification", ["Mirko Marras", "Pawel Korus", "Nasir D. Memon", "Gianni Fenu"], "https://doi.org/10.21437/Interspeech.2019-2430", 5, "interspeech", 2019]], "Ioannis K. Douros": [0, ["Towards a Method of Dynamic Vocal Tract Shapes Generation by Combining Static 3D and Dynamic 2D MRI Speech Data", ["Ioannis K. Douros", "Anastasiia Tsukanova", "Karyna Isaieva", "Pierre-Andre Vuissoz", "Yves Laprie"], "https://doi.org/10.21437/Interspeech.2019-2880", 5, "interspeech", 2019], ["A Multimodal Real-Time MRI Articulatory Corpus of French for Speech Research", ["Ioannis K. Douros", "Jacques Felblinger", "Jens Frahm", "Karyna Isaieva", "Arun A. Joseph", "Yves Laprie", "Freddy Odille", "Anastasiia Tsukanova", "Dirk Voit", "Pierre-Andre Vuissoz"], "https://doi.org/10.21437/Interspeech.2019-1700", 5, "interspeech", 2019]], "Raymond Chi-Wing Wong": [0, ["Topic-Aware Dialogue Speech Recognition with Transfer Learning", ["Yuanfeng Song", "Di Jiang", "Xueyang Wu", "Qian Xu", "Raymond Chi-Wing Wong", "Qiang Yang"], "https://doi.org/10.21437/Interspeech.2019-1694", 5, "interspeech", 2019]], "Petr Motlicek": [0, ["Exploiting Semi-Supervised Training Through a Dropout Regularization in End-to-End Speech Recognition", ["Subhadeep Dey", "Petr Motlicek", "Trung Bui", "Franck Dernoncourt"], "https://doi.org/10.21437/Interspeech.2019-3246", 5, "interspeech", 2019], ["End-to-End Accented Speech Recognition", ["Thibault Viglino", "Petr Motlicek", "Milos Cernak"], "https://doi.org/10.21437/Interspeech.2019-2122", 5, "interspeech", 2019]], "Binod Gyawali": [0, ["Automated Estimation of Oral Reading Fluency During Summer Camp e-Book Reading with MyTurnToRead", ["Anastassia Loukina", "Beata Beigman Klebanov", "Patrick L. Lange", "Yao Qian", "Binod Gyawali", "Nitin Madnani", "Abhinav Misra", "Klaus Zechner", "Zuowei Wang", "John Sabatini"], "https://doi.org/10.21437/Interspeech.2019-2889", 5, "interspeech", 2019]], "Ute Dorothea Peitz": [0, ["Leveraging Acoustic Cues and Paralinguistic Embeddings to Detect Expression from Voice", ["Vikramjit Mitra", "Sue Booker", "Erik Marchi", "David Scott Farrar", "Ute Dorothea Peitz", "Bridget Cheng", "Ermine Teves", "Anuj Mehta", "Devang Naik"], "https://doi.org/10.21437/Interspeech.2019-2998", 5, "interspeech", 2019]], "Naassih Gopee": [0, ["FarSpeech: Arabic Natural Language Processing for Live Arabic Speech", ["Mohamed Eldesouki", "Naassih Gopee", "Ahmed Ali", "Kareem Darwish"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8030.html", 2, "interspeech", 2019]], "Freddy Odille": [0, ["A Multimodal Real-Time MRI Articulatory Corpus of French for Speech Research", ["Ioannis K. Douros", "Jacques Felblinger", "Jens Frahm", "Karyna Isaieva", "Arun A. Joseph", "Yves Laprie", "Freddy Odille", "Anastasiia Tsukanova", "Dirk Voit", "Pierre-Andre Vuissoz"], "https://doi.org/10.21437/Interspeech.2019-1700", 5, "interspeech", 2019]], "Alexandros Potamianos": [0, ["Data Augmentation Using GANs for Speech Emotion Recognition", ["Aggelina Chatziagapi", "Georgios Paraskevopoulos", "Dimitris Sgouropoulos", "Georgios Pantazopoulos", "Malvina Nikandrou", "Theodoros Giannakopoulos", "Athanasios Katsamanis", "Alexandros Potamianos", "Shrikanth Narayanan"], "https://doi.org/10.21437/Interspeech.2019-2561", 5, "interspeech", 2019], ["Unsupervised Low-Rank Representations for Speech Emotion Recognition", ["Georgios Paraskevopoulos", "Efthymios Tzinis", "Nikolaos Ellinas", "Theodoros Giannakopoulos", "Alexandros Potamianos"], "https://doi.org/10.21437/Interspeech.2019-2769", 5, "interspeech", 2019], ["Deep Hierarchical Fusion with Application in Sentiment Analysis", ["Efthymios Georgiou", "Charilaos Papaioannou", "Alexandros Potamianos"], "https://doi.org/10.21437/Interspeech.2019-3243", 5, "interspeech", 2019]], "Xavi Gonzalvo": [0, ["Improving Keyword Spotting and Language Identification via Neural Architecture Search at Scale", ["Hanna Mazzawi", "Xavi Gonzalvo", "Aleks Kracun", "Prashant Sridhar", "Niranjan Subrahmanya", "Ignacio Lopez-Moreno", "Hyun-Jin Park", "Patrick Violette"], "https://doi.org/10.21437/Interspeech.2019-1916", 5, "interspeech", 2019]], "Sina Zarriess": [0, ["Do Hesitations Facilitate Processing of Partially Defective System Utterances? An Exploratory Eye Tracking Study", ["Kristin Haake", "Sarah Schimke", "Simon Betz", "Sina Zarriess"], "https://doi.org/10.21437/Interspeech.2019-2820", 5, "interspeech", 2019], ["The Greennn Tree - Lengthening Position Influences Uncertainty Perception", ["Simon Betz", "Sina Zarriess", "Eva Szekely", "Petra Wagner"], "https://doi.org/10.21437/Interspeech.2019-2572", 5, "interspeech", 2019]], "Erik P. Bucy": [0, ["Multi-Modal Sentiment Analysis Using Deep Canonical Correlation Analysis", ["Zhongkai Sun", "Prathusha Kameswara Sarma", "William A. Sethares", "Erik P. Bucy"], "https://doi.org/10.21437/Interspeech.2019-2482", 5, "interspeech", 2019]], "Pengyuan Zhang": [0, ["Speaker-Invariant Feature-Mapping for Distant Speech Recognition via Adversarial Teacher-Student Learning", ["Long Wu", "Hangting Chen", "Li Wang", "Pengyuan Zhang", "Yonghong Yan"], "https://doi.org/10.21437/Interspeech.2019-2136", 5, "interspeech", 2019], ["Multi-Accent Adaptation Based on Gate Mechanism", ["Han Zhu", "Li Wang", "Pengyuan Zhang", "Yonghong Yan"], "https://doi.org/10.21437/Interspeech.2019-3155", 5, "interspeech", 2019], ["Online Hybrid CTC/Attention Architecture for End-to-End Speech Recognition", ["Haoran Miao", "Gaofeng Cheng", "Pengyuan Zhang", "Ta Li", "Yonghong Yan"], "https://doi.org/10.21437/Interspeech.2019-2018", 5, "interspeech", 2019], ["Target Speaker Recovery and Recognition Network with Average x-Vector and Global Training", ["Wenjie Li", "Pengyuan Zhang", "Yonghong Yan"], "https://doi.org/10.21437/Interspeech.2019-1692", 5, "interspeech", 2019], ["Character-Aware Sub-Word Level Language Modeling for Uyghur and Turkish ASR", ["Chang Liu", "Zhen Zhang", "Pengyuan Zhang", "Yonghong Yan"], "https://doi.org/10.21437/Interspeech.2019-1484", 5, "interspeech", 2019]], "Millie Holt": [0, ["Unified Verbalization for Speech Recognition & Synthesis Across Languages", ["Sandy Ritchie", "Richard Sproat", "Kyle Gorman", "Daan van Esch", "Christian Schallhart", "Nikos Bampounis", "Benoit Brard", "Jonas Fromseier Mortensen", "Millie Holt", "Eoin Mahon"], "https://doi.org/10.21437/Interspeech.2019-2807", 5, "interspeech", 2019]], "Miller S. Puckette": [0, ["Expediting TTS Synthesis with Adversarial Vocoding", ["Paarth Neekhara", "Chris Donahue", "Miller S. Puckette", "Shlomo Dubnov", "Julian J. McAuley"], "https://doi.org/10.21437/Interspeech.2019-3099", 5, "interspeech", 2019]], "Chengzhu Yu": [1.484971062382101e-05, ["The 2019 Inaugural Fearless Steps Challenge: A Giant Leap for Naturalistic Audio", ["John H. L. Hansen", "Aditya Joglekar", "Meena Chandra Shekhar", "Vinay Kothapally", "Chengzhu Yu", "Lakshmish Kaushik", "Abhijeet Sangwan"], "https://doi.org/10.21437/Interspeech.2019-2301", 5, "interspeech", 2019]], "Jonathan Chevelu": [0, ["Corpus Design Using Convolutional Auto-Encoder Embeddings for Audio-Book Synthesis", ["Meysam Shamsi", "Damien Lolive", "Nelly Barbot", "Jonathan Chevelu"], "https://doi.org/10.21437/Interspeech.2019-2190", 5, "interspeech", 2019]], "Min Liu": [0, ["Framewise Supervised Training Towards End-to-End Speech Recognition Models: First Results", ["Mohan Li", "Yuanjiang Cao", "Weicong Zhou", "Min Liu"], "https://doi.org/10.21437/Interspeech.2019-1117", 5, "interspeech", 2019]], "Ulrich Finkler": [0, ["A Highly Efficient Distributed Deep Learning System for Automatic Speech Recognition", ["Wei Zhang", "Xiaodong Cui", "Ulrich Finkler", "George Saon", "Abdullah Kayi", "Alper Buyuktosunoglu", "Brian Kingsbury", "David S. Kung", "Michael Picheny"], "https://doi.org/10.21437/Interspeech.2019-2700", 5, "interspeech", 2019]], "Bhusan Chettri": [0, ["Ensemble Models for Spoofing Detection in Automatic Speaker Verification", ["Bhusan Chettri", "Daniel Stoller", "Veronica Morfi", "Marco A. Martinez Ramirez", "Emmanouil Benetos", "Bob L. Sturm"], "https://doi.org/10.21437/Interspeech.2019-2505", 5, "interspeech", 2019]], "Kuan-Yu Chen": [0, ["Exploring the Encoder Layers of Discriminative Autoencoders for LVCSR", ["Pin-Tuan Huang", "Hung-Shin Lee", "Syu-Siang Wang", "Kuan-Yu Chen", "Yu Tsao", "Hsin-Min Wang"], "https://doi.org/10.21437/Interspeech.2019-1717", 5, "interspeech", 2019], ["Completely Unsupervised Phoneme Recognition by a Generative Adversarial Network Harmonized with Iteratively Refined Hidden Markov Models", ["Kuan-Yu Chen", "Che-Ping Tsai", "Da-Rong Liu", "Hung-yi Lee", "Lin-Shan Lee"], "https://doi.org/10.21437/Interspeech.2019-2068", 5, "interspeech", 2019]], "Brian Mak": [0, ["Mixup Learning Strategies for Text-Independent Speaker Verification", ["Yingke Zhu", "Tom Ko", "Brian Mak"], "https://doi.org/10.21437/Interspeech.2019-2250", 5, "interspeech", 2019]], "Ahilan Kanagasundaram": [0, ["A Study of x-Vector Based Speaker Recognition on Short Utterances", ["Ahilan Kanagasundaram", "Sridha Sridharan", "Ganapathy Sriram", "S. Prachi", "Clinton Fookes"], "https://doi.org/10.21437/Interspeech.2019-1891", 5, "interspeech", 2019]], "Zarina R. Bilgrami": [0, ["A New Approach for Automating Analysis of Responses on Verbal Fluency Tests from Subjects At-Risk for Schizophrenia", ["Mary Pietrowicz", "Carla Agurto", "Raquel Norel", "Elif Eyigoz", "Guillermo A. Cecchi", "Zarina R. Bilgrami", "Cheryl Corcoran"], "https://doi.org/10.21437/Interspeech.2019-2987", 5, "interspeech", 2019]], "Karthika Vijayan": [0, ["NUS Speak-to-Sing: A Web Platform for Personalized Speech-to-Singing Conversion", ["Chitralekha Gupta", "Karthika Vijayan", "Bidisha Sharma", "Xiaoxue Gao", "Haizhou Li"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8041.html", 2, "interspeech", 2019]], "Marco Turchi": [0, ["Adapting Transformer to End-to-End Spoken Language Translation", ["Mattia Antonino Di Gangi", "Matteo Negri", "Marco Turchi"], "https://doi.org/10.21437/Interspeech.2019-3045", 5, "interspeech", 2019]], "Doug Beeferman": [0, ["RadioTalk: A Large-Scale Corpus of Talk Radio Transcripts", ["Doug Beeferman", "William Brannon", "Deb Roy"], "https://doi.org/10.21437/Interspeech.2019-2714", 5, "interspeech", 2019]], "Jinsong Zhang": [0, ["Capturing L1 Influence on L2 Pronunciation by Simulating Perceptual Space Using Acoustic Features", ["Shuju Shi", "Chilin Shih", "Jinsong Zhang"], "https://doi.org/10.21437/Interspeech.2019-3183", 5, "interspeech", 2019], ["The Production of Chinese Affricates /ts/ and /tsh/ by Native Urdu Speakers", ["Dan Du", "Jinsong Zhang"], "https://doi.org/10.21437/Interspeech.2019-1638", 5, "interspeech", 2019]], "Lorenzo Tarantino": [0, ["Self-Attention for Speech Emotion Recognition", ["Lorenzo Tarantino", "Philip N. Garner", "Alexandros Lazaridis"], "https://doi.org/10.21437/Interspeech.2019-2822", 5, "interspeech", 2019]], "Alexandra Marko": [0, ["Ultrasound-Based Silent Speech Interface Built on a Continuous Vocoder", ["Tamas Gabor Csapo", "Mohammed Salah Al-Radhi", "Geza Nemeth", "Gabor Gosztolya", "Tamas Grosz", "Laszlo Toth", "Alexandra Marko"], "https://doi.org/10.21437/Interspeech.2019-2046", 5, "interspeech", 2019], ["V-to-V Coarticulation Induced Acoustic and Articulatory Variability of Vowels: The Effect of Pitch-Accent", ["Andrea Deme", "Marton Bartok", "Tekla Etelka Graczi", "Tamas Gabor Csapo", "Alexandra Marko"], "https://doi.org/10.21437/Interspeech.2019-2890", 5, "interspeech", 2019], ["Articulatory Analysis of Transparent Vowel /i\u02d0/ in Harmonic and Antiharmonic Hungarian Stems: Is There a Difference?", ["Alexandra Marko", "Marton Bartok", "Tamas Gabor Csapo", "Tekla Etelka Graczi", "Andrea Deme"], "https://doi.org/10.21437/Interspeech.2019-2352", 5, "interspeech", 2019]], "Zhengkun Tian": [0, ["A Time Delay Neural Network with Shared Weight Self-Attention for Small-Footprint Keyword Spotting", ["Ye Bai", "Jiangyan Yi", "Jianhua Tao", "Zhengqi Wen", "Zhengkun Tian", "Chenghao Zhao", "Cunhang Fan"], "https://doi.org/10.21437/Interspeech.2019-1676", 5, "interspeech", 2019], ["Learn Spelling from Teachers: Transferring Knowledge from Language Models to Sequence-to-Sequence Speech Recognition", ["Ye Bai", "Jiangyan Yi", "Jianhua Tao", "Zhengkun Tian", "Zhengqi Wen"], "https://doi.org/10.21437/Interspeech.2019-1554", 5, "interspeech", 2019], ["Self-Attention Transducers for End-to-End Speech Recognition", ["Zhengkun Tian", "Jiangyan Yi", "Jianhua Tao", "Ye Bai", "Zhengqi Wen"], "https://doi.org/10.21437/Interspeech.2019-2203", 5, "interspeech", 2019]], "Yong Xu": [0, ["Improved Speaker-Dependent Separation for CHiME-5 Challenge", ["Jian Wu", "Yong Xu", "Shi-Xiong Zhang", "Lianwu Chen", "Meng Yu", "Lei Xie", "Dong Yu"], "https://doi.org/10.21437/Interspeech.2019-1569", 5, "interspeech", 2019], ["Neural Spatial Filter: Target Speaker Speech Separation Assisted with Directional Information", ["Rongzhi Gu", "Lianwu Chen", "Shi-Xiong Zhang", "Jimeng Zheng", "Yong Xu", "Meng Yu", "Dan Su", "Yuexian Zou", "Dong Yu"], "https://doi.org/10.21437/Interspeech.2019-2266", 5, "interspeech", 2019], ["A Comprehensive Study of Speech Separation: Spectrogram vs Waveform Separation", ["Fahimeh Bahmaninezhad", "Jian Wu", "Rongzhi Gu", "Shi-Xiong Zhang", "Yong Xu", "Meng Yu", "Dong Yu"], "https://doi.org/10.21437/Interspeech.2019-3181", 5, "interspeech", 2019]], "Haifeng Wang": [1.047162463407858e-07, ["End-to-End Speech Translation with Knowledge Distillation", ["Yuchen Liu", "Hao Xiong", "Jiajun Zhang", "Zhongjun He", "Hua Wu", "Haifeng Wang", "Chengqing Zong"], "https://doi.org/10.21437/Interspeech.2019-2582", 5, "interspeech", 2019]], "Sebastian Moller": [0, ["Quality Degradation Diagnosis for Voice Networks - Estimating the Perceived Noisiness, Coloration, and Discontinuity of Transmitted Speech", ["Gabriel Mittag", "Sebastian Moller"], "https://doi.org/10.21437/Interspeech.2019-2636", 5, "interspeech", 2019], ["Extending the E-Model Towards Super-Wideband and Fullband Speech Communication Scenarios", ["Sebastian Moller", "Gabriel Mittag", "Thilo Michael", "Vincent Barriac", "Hitoshi Aoki"], "https://doi.org/10.21437/Interspeech.2019-1340", 5, "interspeech", 2019]], "Icksang Han": [0.9961989969015121, ["Who Said That?: Audio-Visual Speaker Diarisation of Real-World Meetings", ["Joon Son Chung", "Bong-Jin Lee", "Icksang Han"], "https://doi.org/10.21437/Interspeech.2019-3116", 5, "interspeech", 2019]], "Michael Brenner": [0, ["Personalizing ASR for Dysarthric and Accented Speech with Limited Data", ["Joel Shor", "Dotan Emanuel", "Oran Lang", "Omry Tuval", "Michael Brenner", "Julie Cattiau", "Fernando Vieira", "Maeve McNally", "Taylor Charbonneau", "Melissa Nollstadt", "Avinatan Hassidim", "Yossi Matias"], "https://doi.org/10.21437/Interspeech.2019-1427", 5, "interspeech", 2019]], "Jahn Heymann": [0, ["Unsupervised Training of Neural Mask-Based Beamforming", ["Lukas Drude", "Jahn Heymann", "Reinhold Haeb-Umbach"], "https://doi.org/10.21437/Interspeech.2019-2549", 5, "interspeech", 2019]], "Francois Grondin": [0, ["State-of-the-Art Speaker Recognition for Telephone and Video Speech: The JHU-MIT Submission for NIST SRE18", ["Jesus Villalba", "Nanxin Chen", "David Snyder", "Daniel Garcia-Romero", "Alan McCree", "Gregory Sell", "Jonas Borgstrom", "Fred Richardson", "Suwon Shon", "Francois Grondin", "Reda Dehak", "Leibny Paola Garcia-Perera", "Daniel Povey", "Pedro A. Torres-Carrasquillo", "Sanjeev Khudanpur", "Najim Dehak"], "https://doi.org/10.21437/Interspeech.2019-2713", 5, "interspeech", 2019], ["A Deep Residual Network for Large-Scale Acoustic Scene Analysis", ["Logan Ford", "Hao Tang", "Francois Grondin", "James R. Glass"], "https://doi.org/10.21437/Interspeech.2019-2731", 5, "interspeech", 2019], ["Multiple Sound Source Localization with SVD-PHAT", ["Francois Grondin", "James R. Glass"], "https://doi.org/10.21437/Interspeech.2019-2653", 5, "interspeech", 2019]], "Marina Volkova": [0, ["STC Antispoofing Systems for the ASVspoof2019 Challenge", ["Galina Lavrentyeva", "Sergey Novoselov", "Andzhukaev Tseren", "Marina Volkova", "Artem Gorlanov", "Alexandr Kozlov"], "https://doi.org/10.21437/Interspeech.2019-1768", 5, "interspeech", 2019]], "Ji Zhu": [0, ["An Attention-Based Hybrid Network for Automatic Detection of Alzheimer's Disease from Narrative Speech", ["Jun Chen", "Ji Zhu", "Jieping Ye"], "https://doi.org/10.21437/Interspeech.2019-2872", 5, "interspeech", 2019]], "Eliya Nachmani": [0, ["Unsupervised Singing Voice Conversion", ["Eliya Nachmani", "Lior Wolf"], "https://doi.org/10.21437/Interspeech.2019-1761", 5, "interspeech", 2019]], "Lin Li": [0, ["Anti-Spoofing Speaker Verification System with Multi-Feature Integration and Multi-Task Learning", ["Rongjin Li", "Miao Zhao", "Zheng Li", "Lin Li", "Qingyang Hong"], "https://doi.org/10.21437/Interspeech.2019-1698", 5, "interspeech", 2019], ["Deep Speaker Embedding Extraction with Channel-Wise Feature Responses and Additive Supervision Softmax Loss Function", ["Jianfeng Zhou", "Tao Jiang", "Zheng Li", "Lin Li", "Qingyang Hong"], "https://doi.org/10.21437/Interspeech.2019-1704", 5, "interspeech", 2019]], "Jon Gudnason": [0, ["F0 Variability Measures Based on Glottal Closure Instants", ["Yu-Ren Chien", "Michal Borsky", "Jon Gudnason"], "https://doi.org/10.21437/Interspeech.2019-1326", 4, "interspeech", 2019], ["The Althingi ASR System", ["Inga Run Helgadottir", "Anna Bjork Nikulasdottir", "Michal Borsky", "Judy Y. Fong", "Robert Kjaran", "Jon Gudnason"], "https://doi.org/10.21437/Interspeech.2019-1248", 5, "interspeech", 2019], ["Lattice Re-Scoring During Manual Editing for Automatic Error Correction of ASR Transcripts", ["Anna V. Runarsdottir", "Inga Run Helgadottir", "Jon Gudnason"], "https://doi.org/10.21437/Interspeech.2019-1790", 5, "interspeech", 2019], ["Bootstrapping a Text Normalization System for an Inflected Language. Numbers as a Test Case", ["Anna Bjork Nikulasdottir", "Jon Gudnason"], "https://doi.org/10.21437/Interspeech.2019-2367", 5, "interspeech", 2019]], "Wilson Ang": [0, ["Building the Singapore English National Speech Corpus", ["Jia Xin Koh", "Aqilah Mislan", "Kevin Khoo", "Brian Ang", "Wilson Ang", "Charmaine Ng", "Ying-Ying Tan"], "https://doi.org/10.21437/Interspeech.2019-1525", 5, "interspeech", 2019]], "Jee-weon Jung": [0.9995425939559937, ["Acoustic Scene Classification Using Teacher-Student Learning with Soft-Labels", ["Hee-Soo Heo", "Jee-weon Jung", "Hye-jin Shim", "Ha-Jin Yu"], "https://doi.org/10.21437/Interspeech.2019-1989", 5, "interspeech", 2019], ["Replay Attack Detection with Complementary High-Resolution Information Using End-to-End DNN for the ASVspoof 2019 Challenge", ["Jee-weon Jung", "Hye-jin Shim", "Hee-Soo Heo", "Ha-Jin Yu"], "https://doi.org/10.21437/Interspeech.2019-1991", 5, "interspeech", 2019], ["RawNet: Advanced End-to-End Deep Neural Network Using Raw Waveforms for Text-Independent Speaker Verification", ["Jee-weon Jung", "Hee-Soo Heo", "Ju-ho Kim", "Hye-jin Shim", "Ha-Jin Yu"], "https://doi.org/10.21437/Interspeech.2019-1982", 5, "interspeech", 2019], ["End-to-End Losses Based on Speaker Basis Vectors and All-Speaker Hard Negative Mining for Speaker Verification", ["Hee-Soo Heo", "Jee-weon Jung", "Il-Ho Yang", "Sung-Hyun Yoon", "Hye-jin Shim", "Ha-Jin Yu"], "https://doi.org/10.21437/Interspeech.2019-1986", 5, "interspeech", 2019]], "Stephanie Berger": [0, ["A Preliminary Study of Charismatic Speech on YouTube: Correlating Prosodic Variation with Counts of Subscribers, Views and Likes", ["Stephanie Berger", "Oliver Niebuhr", "Margaret Zellers"], "https://doi.org/10.21437/Interspeech.2019-1664", 5, "interspeech", 2019]], "Jonathan Huang": [0, ["Intel Far-Field Speaker Recognition System for VOiCES Challenge 2019", ["Jonathan Huang", "Tobias Bocklet"], "https://doi.org/10.21437/Interspeech.2019-2894", 5, "interspeech", 2019]], "Tei-Wei Kuo": [0, ["IA-NET: Acceleration and Compression of Speech Enhancement Using Integer-Adder Deep Neural Network", ["Yu-Chen Lin", "Yi-Te Hsu", "Szu-Wei Fu", "Yu Tsao", "Tei-Wei Kuo"], "https://doi.org/10.21437/Interspeech.2019-1207", 5, "interspeech", 2019]], "Nehory Carmi": [0, ["A Storyteller's Tale: Literature Audiobooks Genre Classification Using CNN and RNN Architectures", ["Nehory Carmi", "Azaria Cohen", "Mireille Avigal", "Anat Lerner"], "https://doi.org/10.21437/Interspeech.2019-1154", 4, "interspeech", 2019]], "Y. Wang": [0.5, ["Impact of ASR Performance on Spoken Grammatical Error Detection", ["Yiting Lu", "Mark J. F. Gales", "Kate M. Knill", "P. P. Manakul", "Linlin Wang", "Y. Wang"], "https://doi.org/10.21437/Interspeech.2019-1706", 5, "interspeech", 2019]], "Meredith Cola": [0, ["Automatic Detection of Autism Spectrum Disorder in Children Using Acoustic and Text Features from Brief Natural Conversations", ["Sunghye Cho", "Mark Liberman", "Neville Ryant", "Meredith Cola", "Robert T. Schultz", "Julia Parish-Morris"], "https://doi.org/10.21437/Interspeech.2019-1452", 5, "interspeech", 2019]], "Andy Murphy": [0, ["The Role of Voice Quality in the Perception of Prominence in Synthetic Speech", ["Andy Murphy", "Irena Yanushevskaya", "Ailbhe Ni Chasaide", "Christer Gobl"], "https://doi.org/10.21437/Interspeech.2019-2761", 5, "interspeech", 2019]], "Ronan Collobert": [0, ["wav2vec: Unsupervised Pre-Training for Speech Recognition", ["Steffen Schneider", "Alexei Baevski", "Ronan Collobert", "Michael Auli"], "https://doi.org/10.21437/Interspeech.2019-1873", 5, "interspeech", 2019], ["Sequence-to-Sequence Speech Recognition with Time-Depth Separable Convolutions", ["Awni Hannun", "Ann Lee", "Qiantong Xu", "Ronan Collobert"], "https://doi.org/10.21437/Interspeech.2019-2460", 5, "interspeech", 2019], ["Who Needs Words? Lexicon-Free Speech Recognition", ["Tatiana Likhomanenko", "Gabriel Synnaeve", "Ronan Collobert"], "https://doi.org/10.21437/Interspeech.2019-3107", 5, "interspeech", 2019]], "Hitoshi Yamamoto": [0, ["Speaker Augmentation and Bandwidth Extension for Deep Speaker Embedding", ["Hitoshi Yamamoto", "Kong Aik Lee", "Koji Okabe", "Takafumi Koshinaka"], "https://doi.org/10.21437/Interspeech.2019-1508", 5, "interspeech", 2019], ["I4U Submission to NIST SRE 2018: Leveraging from a Decade of Shared Experiences", ["Kong Aik Lee", "Ville Hautamaki", "Tomi H. Kinnunen", "Hitoshi Yamamoto", "Koji Okabe", "Ville Vestman", "Jing Huang", "Guohong Ding", "Hanwu Sun", "Anthony Larcher", "Rohan Kumar Das", "Haizhou Li", "Mickael Rouvier", "Pierre-Michel Bousquet", "Wei Rao", "Qing Wang", "Chunlei Zhang", "Fahimeh Bahmaninezhad", "Hector Delgado", "Massimiliano Todisco"], "https://doi.org/10.21437/Interspeech.2019-1533", 5, "interspeech", 2019], ["The NEC-TT 2018 Speaker Verification System", ["Kong Aik Lee", "Hitoshi Yamamoto", "Koji Okabe", "Qiongqiong Wang", "Ling Guo", "Takafumi Koshinaka", "Jiacen Zhang", "Koichi Shinoda"], "https://doi.org/10.21437/Interspeech.2019-1517", 5, "interspeech", 2019]], "Mandy Korpusik": [0, ["A Comparison of Deep Learning Methods for Language Understanding", ["Mandy Korpusik", "Zoe Liu", "James R. Glass"], "https://doi.org/10.21437/Interspeech.2019-1262", 5, "interspeech", 2019]], "Norman Weisskirchen": [0, ["Employing Bottleneck and Convolutional Features for Speech-Based Physical Load Detection on Limited Data Amounts", ["Olga Egorow", "Tarik Mrech", "Norman Weisskirchen", "Andreas Wendemuth"], "https://doi.org/10.21437/Interspeech.2019-2502", 5, "interspeech", 2019]], "Midia Yousefi": [0, ["Probabilistic Permutation Invariant Training for Speech Separation", ["Midia Yousefi", "Soheil Khorram", "John H. L. Hansen"], "https://doi.org/10.21437/Interspeech.2019-1827", 5, "interspeech", 2019]], "Ondrej Novotny": [0, ["Analysis of BUT Submission in Far-Field Scenarios of VOiCES 2019 Challenge", ["Pavel Matejka", "Oldrich Plchot", "Hossein Zeinali", "Ladislav Mosner", "Anna Silnova", "Lukas Burget", "Ondrej Novotny", "Ondrej Glembek"], "https://doi.org/10.21437/Interspeech.2019-2471", 5, "interspeech", 2019], ["Analysis of BUT Submission in Far-Field Scenarios of VOiCES 2019 Challenge", ["Pavel Matejka", "Oldrich Plchot", "Hossein Zeinali", "Ladislav Mosner", "Anna Silnova", "Lukas Burget", "Ondrej Novotny", "Ondrej Glembek"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/abs16.html", 0, "interspeech", 2019], ["Factorization of Discriminatively Trained i-Vector Extractor for Speaker Recognition", ["Ondrej Novotny", "Oldrich Plchot", "Ondrej Glembek", "Lukas Burget"], "https://doi.org/10.21437/Interspeech.2019-1757", 5, "interspeech", 2019]], "Martin Gruber": [0, ["Web-Based Speech Synthesis Editor", ["Martin Gruber", "Jakub Vit", "Jindrich Matousek"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8013.html", 2, "interspeech", 2019], ["Framework for Conducting Tasks Requiring Human Assessment", ["Martin Gruber", "Adam Chylek", "Jindrich Matousek"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8009.html", 2, "interspeech", 2019]], "Carol Figueroa": [0, ["Investigating the Effects of Noisy and Reverberant Speech in Text-to-Speech Systems", ["David Ayllon", "Hector A. Sanchez-Hevia", "Carol Figueroa", "Pierre Lanchantin"], "https://doi.org/10.21437/Interspeech.2019-3104", 5, "interspeech", 2019]], "Shuju Shi": [0, ["Capturing L1 Influence on L2 Pronunciation by Simulating Perceptual Space Using Acoustic Features", ["Shuju Shi", "Chilin Shih", "Jinsong Zhang"], "https://doi.org/10.21437/Interspeech.2019-3183", 5, "interspeech", 2019]], "Batuhan Gundogdu": [0, ["Temporally-Aware Acoustic Unit Discovery for Zerospeech 2019 Challenge", ["Bolaji Yusuf", "Alican Gok", "Batuhan Gundogdu", "Oyku Deniz Kose", "Murat Saraclar"], "https://doi.org/10.21437/Interspeech.2019-1430", 5, "interspeech", 2019]], "Hiroshi Ishiguro": [0, ["A Neural Turn-Taking Model without RNN", ["Chaoran Liu", "Carlos Toshinori Ishi", "Hiroshi Ishiguro"], "https://doi.org/10.21437/Interspeech.2019-2270", 5, "interspeech", 2019]], "Peisong Huang": [0, ["Latent Topic Attention for Domain Classification", ["Peisong Huang", "Peijie Huang", "Wencheng Ai", "Jiande Ding", "Jinchuan Zhang"], "https://doi.org/10.21437/Interspeech.2019-2228", 5, "interspeech", 2019]], "Michelle Cohn": [0, ["Expressiveness Influences Human Vocal Alignment Toward voice-AI", ["Michelle Cohn", "Georgia Zellou"], "https://doi.org/10.21437/Interspeech.2019-1368", 5, "interspeech", 2019], ["Individual Variation in Cognitive Processing Style Predicts Differences in Phonetic Imitation of Device and Human Voices", ["Cathryn Snyder", "Michelle Cohn", "Georgia Zellou"], "https://doi.org/10.21437/Interspeech.2019-2669", 5, "interspeech", 2019], ["The Role of Musical Experience in the Perceptual Weighting of Acoustic Cues for the Obstruent Coda Voicing Contrast in American English", ["Michelle Cohn", "Georgia Zellou", "Santiago Barreda"], "https://doi.org/10.21437/Interspeech.2019-3103", 5, "interspeech", 2019], ["Perceptual Adaptation to Device and Human Voices: Learning and Generalization of a Phonetic Shift Across Real and Voice-AI Talkers", ["Bruno Ferenc Segedin", "Michelle Cohn", "Georgia Zellou"], "https://doi.org/10.21437/Interspeech.2019-1433", 5, "interspeech", 2019]], "Caroline Spencer": [0, ["Using Ultrasound Imaging to Create Augmented Visual Biofeedback for Articulatory Practice", ["Colin T. Annand", "Maurice Lamb", "Sarah Dugan", "Sarah R. Li", "Hannah M. Woeste", "T. Douglas Mast", "Michael A. Riley", "Jack A. Masterson", "Neeraja Mahalingam", "Kathryn J. Eary", "Caroline Spencer", "Suzanne Boyce", "Stephanie Jackson", "Anoosha Baxi", "Renee Seward"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8036.html", 2, "interspeech", 2019]], "Thomas Merritt": [0, ["Towards Achieving Robust Universal Neural Vocoding", ["Jaime Lorenzo-Trueba", "Thomas Drugman", "Javier Latorre", "Thomas Merritt", "Bartosz Putrycz", "Roberto Barra-Chicote", "Alexis Moinet", "Vatsal Aggarwal"], "https://doi.org/10.21437/Interspeech.2019-1424", 5, "interspeech", 2019]], "Yuri Y. Khokhlov": [0, ["R-Vectors: New Technique for Adaptation to Room Acoustics", ["Yuri Y. Khokhlov", "Alexander Zatvornitskiy", "Ivan Medennikov", "Ivan Sorokin", "Tatiana Prisyach", "Aleksei Romanenko", "Anton Mitrofanov", "Vladimir Bataev", "Andrei Andrusenko", "Mariya Korenevskaya", "Oleg Petrov"], "https://doi.org/10.21437/Interspeech.2019-2645", 5, "interspeech", 2019], ["The STC ASR System for the VOiCES from a Distance Challenge 2019", ["Ivan Medennikov", "Yuri Y. Khokhlov", "Aleksei Romanenko", "Ivan Sorokin", "Anton Mitrofanov", "Vladimir Bataev", "Andrei Andrusenko", "Tatiana Prisyach", "Mariya Korenevskaya", "Oleg Petrov", "Alexander Zatvornitskiy"], "https://doi.org/10.21437/Interspeech.2019-1574", 5, "interspeech", 2019], ["The STC ASR System for the VOiCES from a Distance Challenge 2019", ["Ivan Medennikov", "Yuri Y. Khokhlov", "Aleksei Romanenko", "Ivan Sorokin", "Anton Mitrofanov", "Vladimir Bataev", "Andrei Andrusenko", "Tatiana Prisyach", "Mariya Korenevskaya", "Oleg Petrov", "Alexander Zatvornitskiy"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/abs17.html", 0, "interspeech", 2019]], "Vidhyasaharan Sethu": [0, ["Speech Based Emotion Prediction: Can a Linear Model Work?", ["Anda Ouyang", "Ting Dang", "Vidhyasaharan Sethu", "Eliathamby Ambikairajah"], "https://doi.org/10.21437/Interspeech.2019-3149", 5, "interspeech", 2019]], "Sridhar Krishnan": [0, ["Feature Representation of Pathophysiology of Parkinsonian Dysarthria", ["Alice Rueda", "Juan Camilo Vasquez-Correa", "Cristian David Rios-Urrego", "Juan Rafael Orozco-Arroyave", "Sridhar Krishnan", "Elmar Noth"], "https://doi.org/10.21437/Interspeech.2019-2490", 5, "interspeech", 2019]], "Hossein Zeinali": [0, ["Detecting Spoofing Attacks Using VGG and SincNet: BUT-Omilia Submission to ASVspoof 2019 Challenge", ["Hossein Zeinali", "Themos Stafylakis", "Georgia Athanasopoulou", "Johan Rohdin", "Ioannis Gkinis", "Lukas Burget", "Jan Cernocky"], "https://doi.org/10.21437/Interspeech.2019-2892", 5, "interspeech", 2019], ["Analysis of BUT Submission in Far-Field Scenarios of VOiCES 2019 Challenge", ["Pavel Matejka", "Oldrich Plchot", "Hossein Zeinali", "Ladislav Mosner", "Anna Silnova", "Lukas Burget", "Ondrej Novotny", "Ondrej Glembek"], "https://doi.org/10.21437/Interspeech.2019-2471", 5, "interspeech", 2019], ["Analysis of BUT Submission in Far-Field Scenarios of VOiCES 2019 Challenge", ["Pavel Matejka", "Oldrich Plchot", "Hossein Zeinali", "Ladislav Mosner", "Anna Silnova", "Lukas Burget", "Ondrej Novotny", "Ondrej Glembek"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/abs16.html", 0, "interspeech", 2019]], "Hong-Goo Kang": [1, ["Parameter Enhancement for MELP Speech Codec in Noisy Communication Environment", ["Min-Jae Hwang", "Hong-Goo Kang"], "https://doi.org/10.21437/Interspeech.2019-3249", 5, "interspeech", 2019]], "Chunxi Liu": [0, ["Pretraining by Backtranslation for End-to-End ASR in Low-Resource Settings", ["Matthew Wiesner", "Adithya Renduchintala", "Shinji Watanabe", "Chunxi Liu", "Najim Dehak", "Sanjeev Khudanpur"], "https://doi.org/10.21437/Interspeech.2019-3254", 5, "interspeech", 2019]], "Jens Frahm": [0, ["Exploring Critical Articulator Identification from 50Hz RT-MRI Data of the Vocal Tract", ["Samuel S. Silva", "Antonio J. S. Teixeira", "Conceicao Cunha", "Nuno Almeida", "Arun A. Joseph", "Jens Frahm"], "https://doi.org/10.21437/Interspeech.2019-2897", 5, "interspeech", 2019], ["A Multimodal Real-Time MRI Articulatory Corpus of French for Speech Research", ["Ioannis K. Douros", "Jacques Felblinger", "Jens Frahm", "Karyna Isaieva", "Arun A. Joseph", "Yves Laprie", "Freddy Odille", "Anastasiia Tsukanova", "Dirk Voit", "Pierre-Andre Vuissoz"], "https://doi.org/10.21437/Interspeech.2019-1700", 5, "interspeech", 2019], ["On the Role of Oral Configurations in European Portuguese Nasal Vowels", ["Conceicao Cunha", "Samuel S. Silva", "Antonio J. S. Teixeira", "Catarina Oliveira", "Paula Martins", "Arun A. Joseph", "Jens Frahm"], "https://doi.org/10.21437/Interspeech.2019-2232", 5, "interspeech", 2019]], "Tuan Dinh": [0, ["Using a Manifold Vocoder for Spectral Voice and Style Conversion", ["Tuan Dinh", "Alexander Kain", "Kris Tjaden"], "https://doi.org/10.21437/Interspeech.2019-1176", 5, "interspeech", 2019]], "Niamh E. Kelly": [0, ["The Voicing Contrast in Stops and Affricates in the Western Armenian of Lebanon", ["Niamh E. Kelly", "Lara Keshishian"], "https://doi.org/10.21437/Interspeech.2019-2529", 5, "interspeech", 2019]], "Lukas Burget": [0, ["Bayesian Subspace Hidden Markov Model for Acoustic Unit Discovery", ["Lucas Ondel", "Hari Krishna Vydana", "Lukas Burget", "Jan Cernocky"], "https://doi.org/10.21437/Interspeech.2019-2224", 5, "interspeech", 2019], ["Bayesian HMM Based x-Vector Clustering for Speaker Diarization", ["Mireia Diez", "Lukas Burget", "Shuai Wang", "Johan Rohdin", "Jan Cernocky"], "https://doi.org/10.21437/Interspeech.2019-2813", 5, "interspeech", 2019], ["Detecting Spoofing Attacks Using VGG and SincNet: BUT-Omilia Submission to ASVspoof 2019 Challenge", ["Hossein Zeinali", "Themos Stafylakis", "Georgia Athanasopoulou", "Johan Rohdin", "Ioannis Gkinis", "Lukas Burget", "Jan Cernocky"], "https://doi.org/10.21437/Interspeech.2019-2892", 5, "interspeech", 2019], ["On the Usage of Phonetic Information for Text-Independent Speaker Embedding Extraction", ["Shuai Wang", "Johan Rohdin", "Lukas Burget", "Oldrich Plchot", "Yanmin Qian", "Kai Yu", "Jan Cernocky"], "https://doi.org/10.21437/Interspeech.2019-3036", 5, "interspeech", 2019], ["Analysis of BUT Submission in Far-Field Scenarios of VOiCES 2019 Challenge", ["Pavel Matejka", "Oldrich Plchot", "Hossein Zeinali", "Ladislav Mosner", "Anna Silnova", "Lukas Burget", "Ondrej Novotny", "Ondrej Glembek"], "https://doi.org/10.21437/Interspeech.2019-2471", 5, "interspeech", 2019], ["Analysis of BUT Submission in Far-Field Scenarios of VOiCES 2019 Challenge", ["Pavel Matejka", "Oldrich Plchot", "Hossein Zeinali", "Ladislav Mosner", "Anna Silnova", "Lukas Burget", "Ondrej Novotny", "Ondrej Glembek"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/abs16.html", 0, "interspeech", 2019], ["Self-Supervised Speaker Embeddings", ["Themos Stafylakis", "Johan Rohdin", "Oldrich Plchot", "Petr Mizera", "Lukas Burget"], "https://doi.org/10.21437/Interspeech.2019-2842", 5, "interspeech", 2019], ["Semi-Supervised Sequence-to-Sequence ASR Using Unpaired Speech and Text", ["Murali Karthick Baskar", "Shinji Watanabe", "Ramon Fernandez Astudillo", "Takaaki Hori", "Lukas Burget", "Jan Cernocky"], "https://doi.org/10.21437/Interspeech.2019-3167", 5, "interspeech", 2019], ["Factorization of Discriminatively Trained i-Vector Extractor for Speaker Recognition", ["Ondrej Novotny", "Oldrich Plchot", "Ondrej Glembek", "Lukas Burget"], "https://doi.org/10.21437/Interspeech.2019-1757", 5, "interspeech", 2019]], "Roberto Barra-Chicote": [0, ["Towards Achieving Robust Universal Neural Vocoding", ["Jaime Lorenzo-Trueba", "Thomas Drugman", "Javier Latorre", "Thomas Merritt", "Bartosz Putrycz", "Roberto Barra-Chicote", "Alexis Moinet", "Vatsal Aggarwal"], "https://doi.org/10.21437/Interspeech.2019-1424", 5, "interspeech", 2019], ["Interpretable Deep Learning Model for the Detection and Reconstruction of Dysarthric Speech", ["Daniel Korzekwa", "Roberto Barra-Chicote", "Bozena Kostek", "Thomas Drugman", "Mateusz Lajszczak"], "https://doi.org/10.21437/Interspeech.2019-1206", 5, "interspeech", 2019]], "Nicholas W. D. Evans": [0, ["ASVspoof 2019: Future Horizons in Spoofed and Fake Audio Detection", ["Massimiliano Todisco", "Xin Wang", "Ville Vestman", "Md. Sahidullah", "Hector Delgado", "Andreas Nautsch", "Junichi Yamagishi", "Nicholas W. D. Evans", "Tomi H. Kinnunen", "Kong Aik Lee"], "https://doi.org/10.21437/Interspeech.2019-2249", 5, "interspeech", 2019], ["Privacy-Preserving Speaker Recognition with Cohort Score Normalisation", ["Andreas Nautsch", "Jose Patino", "Amos Treiber", "Themos Stafylakis", "Petr Mizera", "Massimiliano Todisco", "Thomas Schneider", "Nicholas W. D. Evans"], "https://doi.org/10.21437/Interspeech.2019-2638", 5, "interspeech", 2019], ["The GDPR & Speech Data: Reflections of Legal and Technology Communities, First Steps Towards a Common Understanding", ["Andreas Nautsch", "Catherine Jasserand", "Els Kindt", "Massimiliano Todisco", "Isabel Trancoso", "Nicholas W. D. Evans"], "https://doi.org/10.21437/Interspeech.2019-2647", 5, "interspeech", 2019]], "David K. Han": [2.5525283969818346e-10, ["A Study of a Cross-Language Perception Based on Cortical Analysis Using Biomimetic STRFs", ["Sangwook Park", "David K. Han", "Mounya Elhilali"], "https://doi.org/10.21437/Interspeech.2019-2507", 5, "interspeech", 2019]], "Adam C. Lammert": [0, ["Assessing Neuromotor Coordination in Depression Using Inverted Vocal Tract Variables", ["Carol Y. Espy-Wilson", "Adam C. Lammert", "Nadee Seneviratne", "Thomas F. Quatieri"], "https://doi.org/10.21437/Interspeech.2019-1815", 5, "interspeech", 2019], ["Vocal Biomarker Assessment Following Pediatric Traumatic Brain Injury: A Retrospective Cohort Study", ["Camille Noufi", "Adam C. Lammert", "Daryush D. Mehta", "James R. Williamson", "Gregory Ciccarelli", "Douglas E. Sturim", "Jordan R. Green", "Thomas F. Campbell", "Thomas F. Quatieri"], "https://doi.org/10.21437/Interspeech.2019-1200", 5, "interspeech", 2019]], "Timur Pekhovsky": [0, ["Speaker Diarization with Deep Speaker Embeddings for DIHARD Challenge II", ["Sergey Novoselov", "Aleksei Gusev", "Artem Ivanov", "Timur Pekhovsky", "Andrey Shulipa", "Anastasia Avdeeva", "Artem Gorlanov", "Alexandr Kozlov"], "https://doi.org/10.21437/Interspeech.2019-2757", 5, "interspeech", 2019], ["STC Speaker Recognition Systems for the VOiCES from a Distance Challenge", ["Sergey Novoselov", "Aleksei Gusev", "Artem Ivanov", "Timur Pekhovsky", "Andrey Shulipa", "Galina Lavrentyeva", "Vladimir Volokhov", "Alexandr Kozlov"], "https://doi.org/10.21437/Interspeech.2019-2783", 5, "interspeech", 2019], ["STC Speaker Recognition Systems for the VOiCES from a Distance Challenge", ["Sergey Novoselov", "Aleksei Gusev", "Artem Ivanov", "Timur Pekhovsky", "Andrey Shulipa", "Galina Lavrentyeva", "Vladimir Volokhov", "Alexandr Kozlov"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/abs15.html", 0, "interspeech", 2019]], "Lakshmish Kaushik": [0, ["The 2019 Inaugural Fearless Steps Challenge: A Giant Leap for Naturalistic Audio", ["John H. L. Hansen", "Aditya Joglekar", "Meena Chandra Shekhar", "Vinay Kothapally", "Chengzhu Yu", "Lakshmish Kaushik", "Abhijeet Sangwan"], "https://doi.org/10.21437/Interspeech.2019-2301", 5, "interspeech", 2019]], "Yuan Gong": [0.18233120441436768, ["ReMASC: Realistic Replay Attack Corpus for Voice Controlled Systems", ["Yuan Gong", "Jian Yang", "Jacob Huber", "Mitchell MacKnight", "Christian Poellabauer"], "https://doi.org/10.21437/Interspeech.2019-1541", 5, "interspeech", 2019]], "Takuhiro Kaneko": [0, ["StarGAN-VC2: Rethinking Conditional Methods for StarGAN-Based Voice Conversion", ["Takuhiro Kaneko", "Hirokazu Kameoka", "Kou Tanaka", "Nobukatsu Hojo"], "https://doi.org/10.21437/Interspeech.2019-2236", 5, "interspeech", 2019]], "Shaojin Ding": [0, ["Group Latent Embedding for Vector Quantized Variational Autoencoder in Non-Parallel Voice Conversion", ["Shaojin Ding", "Ricardo Gutierrez-Osuna"], "https://doi.org/10.21437/Interspeech.2019-1198", 5, "interspeech", 2019], ["Foreign Accent Conversion by Synthesizing Speech from Phonetic Posteriorgrams", ["Guanlong Zhao", "Shaojin Ding", "Ricardo Gutierrez-Osuna"], "https://doi.org/10.21437/Interspeech.2019-1778", 5, "interspeech", 2019]], "Adrian Lancucki": [0, ["Lattice Generation in Attention-Based Speech Recognition Models", ["Michal Zapotoczny", "Piotr Pietrzak", "Adrian Lancucki", "Jan Chorowski"], "https://doi.org/10.21437/Interspeech.2019-2667", 5, "interspeech", 2019], ["Towards Using Context-Dependent Symbols in CTC Without State-Tying Decision Trees", ["Jan Chorowski", "Adrian Lancucki", "Bartosz Kostka", "Michal Zapotoczny"], "https://doi.org/10.21437/Interspeech.2019-2720", 5, "interspeech", 2019]], "Yuexian Zou": [0, ["Neural Spatial Filter: Target Speaker Speech Separation Assisted with Directional Information", ["Rongzhi Gu", "Lianwu Chen", "Shi-Xiong Zhang", "Jimeng Zheng", "Yong Xu", "Meng Yu", "Dan Su", "Yuexian Zou", "Dong Yu"], "https://doi.org/10.21437/Interspeech.2019-2266", 5, "interspeech", 2019]], "Vatsal Aggarwal": [0, ["Towards Achieving Robust Universal Neural Vocoding", ["Jaime Lorenzo-Trueba", "Thomas Drugman", "Javier Latorre", "Thomas Merritt", "Bartosz Putrycz", "Roberto Barra-Chicote", "Alexis Moinet", "Vatsal Aggarwal"], "https://doi.org/10.21437/Interspeech.2019-1424", 5, "interspeech", 2019]], "Debasish Ray Mohapatra": [0, ["An Extended Two-Dimensional Vocal Tract Model for Fast Acoustic Simulation of Single-Axis Symmetric Three-Dimensional Tubes", ["Debasish Ray Mohapatra", "Victor Zappi", "Sidney S. Fels"], "https://doi.org/10.21437/Interspeech.2019-1764", 5, "interspeech", 2019]], "Simon Betz": [0, ["Do Hesitations Facilitate Processing of Partially Defective System Utterances? An Exploratory Eye Tracking Study", ["Kristin Haake", "Sarah Schimke", "Simon Betz", "Sina Zarriess"], "https://doi.org/10.21437/Interspeech.2019-2820", 5, "interspeech", 2019], ["The Greennn Tree - Lengthening Position Influences Uncertainty Perception", ["Simon Betz", "Sina Zarriess", "Eva Szekely", "Petra Wagner"], "https://doi.org/10.21437/Interspeech.2019-2572", 5, "interspeech", 2019]], "Ashish Panda": [0, ["Label Driven Time-Frequency Masking for Robust Continuous Speech Recognition", ["Meet H. Soni", "Ashish Panda"], "https://doi.org/10.21437/Interspeech.2019-2172", 5, "interspeech", 2019], ["Generative Noise Modeling and Channel Simulation for Robust Speech Recognition in Unseen Conditions", ["Meet H. Soni", "Sonal Joshi", "Ashish Panda"], "https://doi.org/10.21437/Interspeech.2019-2090", 5, "interspeech", 2019], ["Front-End Feature Compensation and Denoising for Noise Robust Speech Emotion Recognition", ["Rupayan Chakraborty", "Ashish Panda", "Meghna Pandharipande", "Sonal Joshi", "Sunil Kumar Kopparapu"], "https://doi.org/10.21437/Interspeech.2019-2243", 5, "interspeech", 2019]], "Sebastiao Quintas": [0, ["Unbabel Talk - Human Verified Translations for Voice Instant Messaging", ["Luis Bernardo", "Mathieu Giquel", "Sebastiao Quintas", "Paulo Dimas", "Helena Moniz", "Isabel Trancoso"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8034.html", 2, "interspeech", 2019]], "Zixing Zhang": [0, ["Attention-Enhanced Connectionist Temporal Classification for Discrete Speech Emotion Recognition", ["Ziping Zhao", "Zhongtian Bao", "Zixing Zhang", "Nicholas Cummins", "Haishuai Wang", "Bjorn W. Schuller"], "https://doi.org/10.21437/Interspeech.2019-1649", 5, "interspeech", 2019], ["Autonomous Emotion Learning in Speech: A View of Zero-Shot Speech Emotion Recognition", ["Xinzhou Xu", "Jun Deng", "Nicholas Cummins", "Zixing Zhang", "Li Zhao", "Bjorn W. Schuller"], "https://doi.org/10.21437/Interspeech.2019-2406", 5, "interspeech", 2019]], "Vladlen Koltun": [0, ["Speech Denoising with Deep Feature Losses", ["Francois G. Germain", "Qifeng Chen", "Vladlen Koltun"], "https://doi.org/10.21437/Interspeech.2019-1924", 5, "interspeech", 2019]], "Cristina Gorrostieta": [0, ["Gender De-Biasing in Speech Emotion Recognition", ["Cristina Gorrostieta", "Reza Lotfian", "Kye Taylor", "Richard Brutti", "John Kane"], "https://doi.org/10.21437/Interspeech.2019-1708", 5, "interspeech", 2019]], "Graziella Mangone": [0, ["Comparison of Telephone Recordings and Professional Microphone Recordings for Early Detection of Parkinson's Disease, Using Mel-Frequency Cepstral Coefficients with Gaussian Mixture Models", ["Laetitia Jeancolas", "Graziella Mangone", "Jean-Christophe Corvol", "Marie Vidailhet", "Stephane Lehericy", "Badr-Eddine Benkelfat", "Habib Benali", "Dijana Petrovska-Delacretaz"], "https://doi.org/10.21437/Interspeech.2019-2825", 5, "interspeech", 2019]], "George Saon": [0, ["Challenging the Boundaries of Speech Recognition: The MALACH Corpus", ["Michael Picheny", "Zoltan Tuske", "Brian Kingsbury", "Kartik Audhkhasi", "Xiaodong Cui", "George Saon"], "https://doi.org/10.21437/Interspeech.2019-1907", 5, "interspeech", 2019], ["Forget a Bit to Learn Better: Soft Forgetting for CTC-Based Automatic Speech Recognition", ["Kartik Audhkhasi", "George Saon", "Zoltan Tuske", "Brian Kingsbury", "Michael Picheny"], "https://doi.org/10.21437/Interspeech.2019-2841", 5, "interspeech", 2019], ["A Highly Efficient Distributed Deep Learning System for Automatic Speech Recognition", ["Wei Zhang", "Xiaodong Cui", "Ulrich Finkler", "George Saon", "Abdullah Kayi", "Alper Buyuktosunoglu", "Brian Kingsbury", "David S. Kung", "Michael Picheny"], "https://doi.org/10.21437/Interspeech.2019-2700", 5, "interspeech", 2019], ["Advancing Sequence-to-Sequence Based Speech Recognition", ["Zoltan Tuske", "Kartik Audhkhasi", "George Saon"], "https://doi.org/10.21437/Interspeech.2019-3018", 5, "interspeech", 2019]], "Qian Xu": [0, ["Topic-Aware Dialogue Speech Recognition with Transfer Learning", ["Yuanfeng Song", "Di Jiang", "Xueyang Wu", "Qian Xu", "Raymond Chi-Wing Wong", "Qiang Yang"], "https://doi.org/10.21437/Interspeech.2019-1694", 5, "interspeech", 2019]], "Katie Matton": [0, ["Into the Wild: Transitioning from Recognizing Mood in Clinical Interactions to Personal Conversations for Individuals with Bipolar Disorder", ["Katie Matton", "Melvin G. McInnis", "Emily Mower Provost"], "https://doi.org/10.21437/Interspeech.2019-2698", 5, "interspeech", 2019]], "Ricardo Gutierrez-Osuna": [0, ["Group Latent Embedding for Vector Quantized Variational Autoencoder in Non-Parallel Voice Conversion", ["Shaojin Ding", "Ricardo Gutierrez-Osuna"], "https://doi.org/10.21437/Interspeech.2019-1198", 5, "interspeech", 2019], ["Foreign Accent Conversion by Synthesizing Speech from Phonetic Posteriorgrams", ["Guanlong Zhao", "Shaojin Ding", "Ricardo Gutierrez-Osuna"], "https://doi.org/10.21437/Interspeech.2019-1778", 5, "interspeech", 2019]], "Yuichi Kageyama": [0, ["GPU-Based WFST Decoding with Extra Large Language Model", ["Daisuke Fukunaga", "Yoshiki Tanaka", "Yuichi Kageyama"], "https://doi.org/10.21437/Interspeech.2019-2101", 5, "interspeech", 2019]], "Philip C. Woodland": [0, ["Multi-Span Acoustic Modelling Using Raw Waveform Signals", ["Patrick von Platen", "Chao Zhang", "Philip C. Woodland"], "https://doi.org/10.21437/Interspeech.2019-2454", 5, "interspeech", 2019]], "Ying-Hui Lai": [0, ["Consonant Classification in Mandarin Based on the Depth Image Feature: A Pilot Study", ["Han-Chi Hsieh", "Wei-Zhong Zheng", "Ko-Chiang Chen", "Ying-Hui Lai"], "https://doi.org/10.21437/Interspeech.2019-1893", 5, "interspeech", 2019]], "Yael Manor": [0, ["Identifying Distinctive Acoustic and Spectral Features in Parkinson's Disease", ["Yermiyahu Hauptman", "Ruth Aloni-Lavi", "Itshak Lapidot", "Tanya Gurevich", "Yael Manor", "Stav Naor", "Noa Diamant", "Irit Opher"], "https://doi.org/10.21437/Interspeech.2019-2465", 5, "interspeech", 2019]], "Ellen Tournier": [0, ["An Acoustic and Lexical Analysis of Emotional Valence in Spontaneous Speech: Autobiographical Memory Recall in Older Adults", ["Deniece S. Nazareth", "Ellen Tournier", "Sarah Leimkotter", "Esther Janse", "Dirk Heylen", "Gerben J. Westerhof", "Khiet P. Truong"], "https://doi.org/10.21437/Interspeech.2019-1823", 5, "interspeech", 2019]], "Xiaohai Tian": [0, ["A Speaker-Dependent WaveNet for Voice Conversion with Non-Parallel Data", ["Xiaohai Tian", "Eng Siong Chng", "Haizhou Li"], "https://doi.org/10.21437/Interspeech.2019-1514", 5, "interspeech", 2019]], "Xuan-Nga Cao": [0, ["The Zero Resource Speech Challenge 2019: TTS Without T", ["Ewan Dunbar", "Robin Algayres", "Julien Karadayi", "Mathieu Bernard", "Juan Benjumea", "Xuan-Nga Cao", "Lucie Miskic", "Charlotte Dugrain", "Lucas Ondel", "Alan W. Black", "Laurent Besacier", "Sakriani Sakti", "Emmanuel Dupoux"], "https://doi.org/10.21437/Interspeech.2019-2904", 5, "interspeech", 2019]], "Xiaodong Cui": [0, ["Large-Scale Mixed-Bandwidth Deep Neural Network Acoustic Modeling for Automatic Speech Recognition", ["Khoi-Nguyen C. Mac", "Xiaodong Cui", "Wei Zhang", "Michael Picheny"], "https://doi.org/10.21437/Interspeech.2019-2641", 5, "interspeech", 2019], ["Challenging the Boundaries of Speech Recognition: The MALACH Corpus", ["Michael Picheny", "Zoltan Tuske", "Brian Kingsbury", "Kartik Audhkhasi", "Xiaodong Cui", "George Saon"], "https://doi.org/10.21437/Interspeech.2019-1907", 5, "interspeech", 2019], ["Acoustic Model Optimization Based on Evolutionary Stochastic Gradient Descent with Anchors for Automatic Speech Recognition", ["Xiaodong Cui", "Michael Picheny"], "https://doi.org/10.21437/Interspeech.2019-2620", 5, "interspeech", 2019], ["A Highly Efficient Distributed Deep Learning System for Automatic Speech Recognition", ["Wei Zhang", "Xiaodong Cui", "Ulrich Finkler", "George Saon", "Abdullah Kayi", "Alper Buyuktosunoglu", "Brian Kingsbury", "David S. Kung", "Michael Picheny"], "https://doi.org/10.21437/Interspeech.2019-2700", 5, "interspeech", 2019]], "Hua Wu": [0.005701346439309418, ["End-to-End Speech Translation with Knowledge Distillation", ["Yuchen Liu", "Hao Xiong", "Jiajun Zhang", "Zhongjun He", "Hua Wu", "Haifeng Wang", "Chengqing Zong"], "https://doi.org/10.21437/Interspeech.2019-2582", 5, "interspeech", 2019]], "Ewald van der Westhuizen": [0, ["Unsupervised Acoustic Unit Discovery for Speech Synthesis Using Discrete Latent-Variable Neural Networks", ["Ryan Eloff", "Andre Nortje", "Benjamin van Niekerk", "Avashna Govender", "Leanne Nortje", "Arnu Pretorius", "Elan Van Biljon", "Ewald van der Westhuizen", "Lisa van Staden", "Herman Kamper"], "https://doi.org/10.21437/Interspeech.2019-1518", 5, "interspeech", 2019], ["Improved Low-Resource Somali Speech Recognition by Semi-Supervised Acoustic and Language Model Training", ["Astik Biswas", "Raghav Menon", "Ewald van der Westhuizen", "Thomas Niesler"], "https://doi.org/10.21437/Interspeech.2019-1328", 5, "interspeech", 2019], ["Feature Exploration for Almost Zero-Resource ASR-Free Keyword Spotting Using a Multilingual Bottleneck Extractor and Correspondence Autoencoders", ["Raghav Menon", "Herman Kamper", "Ewald van der Westhuizen", "John Quinn", "Thomas Niesler"], "https://doi.org/10.21437/Interspeech.2019-1665", 5, "interspeech", 2019], ["Semi-Supervised Acoustic Model Training for Five-Lingual Code-Switched ASR", ["Astik Biswas", "Emre Yilmaz", "Febe de Wet", "Ewald van der Westhuizen", "Thomas Niesler"], "https://doi.org/10.21437/Interspeech.2019-1325", 5, "interspeech", 2019]], "Kenji Iwata": [0, ["Slot Filling with Weighted Multi-Encoders for Out-of-Domain Values", ["Yuka Kobayashi", "Takami Yoshida", "Kenji Iwata", "Hiroshi Fujimura"], "https://doi.org/10.21437/Interspeech.2019-1226", 5, "interspeech", 2019]], "Johanna D. Moore": [0, ["Detecting Topic-Oriented Speaker Stance in Conversational Speech", ["Catherine Lai", "Beatrice Alex", "Johanna D. Moore", "Leimin Tian", "Tatsuro Hori", "Gianpiero Francesca"], "https://doi.org/10.21437/Interspeech.2019-2632", 5, "interspeech", 2019]], "Alejandro Coucheiro-Limeres": [0, ["Attention-Based Word Vector Prediction with LSTMs and its Application to the OOV Problem in ASR", ["Alejandro Coucheiro-Limeres", "Fernando Fernandez-Martinez", "Ruben San Segundo", "Javier Ferreiros Lopez"], "https://doi.org/10.21437/Interspeech.2019-2347", 5, "interspeech", 2019]], "Samik Sadhu": [0, ["Exploring Methods for the Automatic Detection of Errors in Manual Transcription", ["Xiaofei Wang", "Jinyi Yang", "Ruizhi Li", "Samik Sadhu", "Hynek Hermansky"], "https://doi.org/10.21437/Interspeech.2019-1343", 5, "interspeech", 2019], ["Modulation Vectors as Robust Feature Representation for ASR in Domain Mismatched Conditions", ["Samik Sadhu", "Hynek Hermansky"], "https://doi.org/10.21437/Interspeech.2019-2723", 5, "interspeech", 2019]], "Mireille Avigal": [0, ["A Storyteller's Tale: Literature Audiobooks Genre Classification Using CNN and RNN Architectures", ["Nehory Carmi", "Azaria Cohen", "Mireille Avigal", "Anat Lerner"], "https://doi.org/10.21437/Interspeech.2019-1154", 4, "interspeech", 2019]], "Prachi Singh": [0, ["LEAP Diarization System for the Second DIHARD Challenge", ["Prachi Singh", "Harsha Vardhan", "Sriram Ganapathy", "A. Kanagasundaram"], "https://doi.org/10.21437/Interspeech.2019-2716", 5, "interspeech", 2019]], "Alexandros Lazaridis": [0, ["Self-Attention for Speech Emotion Recognition", ["Lorenzo Tarantino", "Philip N. Garner", "Alexandros Lazaridis"], "https://doi.org/10.21437/Interspeech.2019-2822", 5, "interspeech", 2019]], "Joe Barrow": [0, ["Mitigating Noisy Inputs for Question Answering", ["Denis Peskov", "Joe Barrow", "Pedro Rodriguez", "Graham Neubig", "Jordan L. Boyd-Graber"], "https://doi.org/10.21437/Interspeech.2019-3154", 5, "interspeech", 2019]], "Sweekar Sudhakara": [0, ["An Improved Goodness of Pronunciation (GoP) Measure for Pronunciation Evaluation with DNN-HMM System Considering HMM Transition Probabilities", ["Sweekar Sudhakara", "Manoj Kumar Ramanathi", "Chiranjeevi Yarra", "Prasanta Kumar Ghosh"], "https://doi.org/10.21437/Interspeech.2019-2363", 5, "interspeech", 2019]], "Marie Mulville": [0, ["Large-Scale Visual Speech Recognition", ["Brendan Shillingford", "Yannis M. Assael", "Matthew W. Hoffman", "Thomas Paine", "Cian Hughes", "Utsav Prabhu", "Hank Liao", "Hasim Sak", "Kanishka Rao", "Lorrayne Bennett", "Marie Mulville", "Misha Denil", "Ben Coppin", "Ben Laurie", "Andrew W. Senior", "Nando de Freitas"], "https://doi.org/10.21437/Interspeech.2019-1669", 5, "interspeech", 2019]], "Sneha Das": [0, ["Sound Privacy: A Conversational Speech Corpus for Quantifying the Experience of Privacy", ["Pablo Perez Zarazaga", "Sneha Das", "Tom Backstrom", "Vishnu Vidyadhara Raju Vegesna", "Anil Kumar Vuppala"], "https://doi.org/10.21437/Interspeech.2019-1172", 5, "interspeech", 2019]], "Zhong-Qiu Wang": [1.0870333767235701e-12, ["Deep Learning Based Multi-Channel Speaker Recognition in Noisy and Reverberant Environments", ["Hassan Taherian", "Zhong-Qiu Wang", "DeLiang Wang"], "https://doi.org/10.21437/Interspeech.2019-1428", 5, "interspeech", 2019]], "Abdalghani Abujabal": [0, ["Neural Named Entity Recognition from Subword Units", ["Abdalghani Abujabal", "Judith Gaspers"], "https://doi.org/10.21437/Interspeech.2019-1305", 5, "interspeech", 2019]], "Kareem Darwish": [0, ["FarSpeech: Arabic Natural Language Processing for Live Arabic Speech", ["Mohamed Eldesouki", "Naassih Gopee", "Ahmed Ali", "Kareem Darwish"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8030.html", 2, "interspeech", 2019]], "Aleks Kracun": [0, ["Improving Keyword Spotting and Language Identification via Neural Architecture Search at Scale", ["Hanna Mazzawi", "Xavi Gonzalvo", "Aleks Kracun", "Prashant Sridhar", "Niranjan Subrahmanya", "Ignacio Lopez-Moreno", "Hyun-Jin Park", "Patrick Violette"], "https://doi.org/10.21437/Interspeech.2019-1916", 5, "interspeech", 2019]], "Jae-Min Kim": [0.9150348603725433, ["Probability Density Distillation with Generative Adversarial Networks for High-Quality Parallel Waveform Generation", ["Ryuichi Yamamoto", "Eunwoo Song", "Jae-Min Kim"], "https://doi.org/10.21437/Interspeech.2019-1965", 5, "interspeech", 2019]], "David Ditter": [0, ["Influence of Speaker-Specific Parameters on Speech Separation Systems", ["David Ditter", "Timo Gerkmann"], "https://doi.org/10.21437/Interspeech.2019-2459", 5, "interspeech", 2019]], "Hanwu Sun": [0.7757290154695511, ["I4U Submission to NIST SRE 2018: Leveraging from a Decade of Shared Experiences", ["Kong Aik Lee", "Ville Hautamaki", "Tomi H. Kinnunen", "Hitoshi Yamamoto", "Koji Okabe", "Ville Vestman", "Jing Huang", "Guohong Ding", "Hanwu Sun", "Anthony Larcher", "Rohan Kumar Das", "Haizhou Li", "Mickael Rouvier", "Pierre-Michel Bousquet", "Wei Rao", "Qing Wang", "Chunlei Zhang", "Fahimeh Bahmaninezhad", "Hector Delgado", "Massimiliano Todisco"], "https://doi.org/10.21437/Interspeech.2019-1533", 5, "interspeech", 2019], ["The I2R's ASR System for the VOiCES from a Distance Challenge 2019", ["Tze Yuang Chong", "Kye Min Tan", "Kah Kuan Teh", "Chang Huai You", "Hanwu Sun", "Tran Huy Dat"], "https://doi.org/10.21437/Interspeech.2019-2130", 5, "interspeech", 2019], ["The I2R's ASR System for the VOiCES from a Distance Challenge 2019", ["Tze Yuang Chong", "Kye Min Tan", "Kah Kuan Teh", "Chang Huai You", "Hanwu Sun", "Tran Huy Dat"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/abs18.html", 0, "interspeech", 2019], ["The I2R's Submission to VOiCES Distance Speaker Recognition Challenge 2019", ["Hanwu Sun", "Kah Kuan Teh", "Ivan Kukanov", "Tran Huy Dat"], "https://doi.org/10.21437/Interspeech.2019-1997", 5, "interspeech", 2019]], "Jasper Ooster": [0, ["\"Computer, Test My Hearing\": Accurate Speech Audiometry with Smart Speakers", ["Jasper Ooster", "Pia Nancy Porysek Moreta", "Jorg-Hendrik Bach", "Inga Holube", "Bernd T. Meyer"], "https://doi.org/10.21437/Interspeech.2019-2118", 5, "interspeech", 2019]], "Xiaodong He": [0, ["Speaker Diarization with Lexical Information", ["Tae Jin Park", "Kyu J. Han", "Jing Huang", "Xiaodong He", "Bowen Zhou", "Panayiotis G. Georgiou", "Shrikanth Narayanan"], "https://doi.org/10.21437/Interspeech.2019-1947", 5, "interspeech", 2019], ["Direct-Path Signal Cross-Correlation Estimation for Sound Source Localization in Reverberation", ["Wei Xue", "Ying Tong", "Guohong Ding", "Chao Zhang", "Tao Ma", "Xiaodong He", "Bowen Zhou"], "https://doi.org/10.21437/Interspeech.2019-1488", 5, "interspeech", 2019], ["Multi-Stride Self-Attention for Speech Recognition", ["Kyu J. Han", "Jing Huang", "Yun Tang", "Xiaodong He", "Bowen Zhou"], "https://doi.org/10.21437/Interspeech.2019-1973", 5, "interspeech", 2019]], "Juqiang Chen": [0, ["Cognitive Factors in Thai-Na\u00efve Mandarin Speakers' Imitation of Thai Lexical Tones", ["Juqiang Chen", "Catherine T. Best", "Mark Antoniou"], "https://doi.org/10.21437/Interspeech.2019-1403", 5, "interspeech", 2019]], "Zhen Fu": [0, ["Effects of Spectral and Temporal Cues to Mandarin Concurrent-Vowels Identification for Normal-Hearing and Hearing-Impaired Listeners", ["Zhen Fu", "Xihong Wu", "Jing Chen"], "https://doi.org/10.21437/Interspeech.2019-3209", 5, "interspeech", 2019]], "Patrick Lumban Tobing": [0, ["Quasi-Periodic WaveNet Vocoder: A Pitch Dependent Dilated Convolution Model for Parametric Speech Generation", ["Yi-Chiao Wu", "Tomoki Hayashi", "Patrick Lumban Tobing", "Kazuhiro Kobayashi", "Tomoki Toda"], "https://doi.org/10.21437/Interspeech.2019-1232", 5, "interspeech", 2019], ["Non-Parallel Voice Conversion with Cyclic Variational Autoencoder", ["Patrick Lumban Tobing", "Yi-Chiao Wu", "Tomoki Hayashi", "Kazuhiro Kobayashi", "Tomoki Toda"], "https://doi.org/10.21437/Interspeech.2019-2307", 5, "interspeech", 2019], ["Investigation of F0 Conditioning and Fully Convolutional Networks in Variational Autoencoder Based Voice Conversion", ["Wen-Chin Huang", "Yi-Chiao Wu", "Chen-Chou Lo", "Patrick Lumban Tobing", "Tomoki Hayashi", "Kazuhiro Kobayashi", "Tomoki Toda", "Yu Tsao", "Hsin-Min Wang"], "https://doi.org/10.21437/Interspeech.2019-1774", 5, "interspeech", 2019]], "Naoyuki Kanda": [0, ["Auxiliary Interference Speaker Loss for Target-Speaker Speech Recognition", ["Naoyuki Kanda", "Shota Horiguchi", "Ryoichi Takashima", "Yusuke Fujita", "Kenji Nagamatsu", "Shinji Watanabe"], "https://doi.org/10.21437/Interspeech.2019-1126", 5, "interspeech", 2019], ["Guided Source Separation Meets a Strong ASR Backend: Hitachi/Paderborn University Joint Investigation for Dinner Party ASR", ["Naoyuki Kanda", "Christoph Boddeker", "Jens Heitkaemper", "Yusuke Fujita", "Shota Horiguchi", "Kenji Nagamatsu", "Reinhold Haeb-Umbach"], "https://doi.org/10.21437/Interspeech.2019-1167", 5, "interspeech", 2019], ["Multimodal Response Obligation Detection with Unsupervised Online Domain Adaptation", ["Shota Horiguchi", "Naoyuki Kanda", "Kenji Nagamatsu"], "https://doi.org/10.21437/Interspeech.2019-1313", 5, "interspeech", 2019], ["End-to-End Neural Speaker Diarization with Permutation-Free Objectives", ["Yusuke Fujita", "Naoyuki Kanda", "Shota Horiguchi", "Kenji Nagamatsu", "Shinji Watanabe"], "https://doi.org/10.21437/Interspeech.2019-2899", 5, "interspeech", 2019]], "Li Zhao": [0, ["Autonomous Emotion Learning in Speech: A View of Zero-Shot Speech Emotion Recognition", ["Xinzhou Xu", "Jun Deng", "Nicholas Cummins", "Zixing Zhang", "Li Zhao", "Bjorn W. Schuller"], "https://doi.org/10.21437/Interspeech.2019-2406", 5, "interspeech", 2019]], "Sergey Novoselov": [0, ["Speaker Diarization with Deep Speaker Embeddings for DIHARD Challenge II", ["Sergey Novoselov", "Aleksei Gusev", "Artem Ivanov", "Timur Pekhovsky", "Andrey Shulipa", "Anastasia Avdeeva", "Artem Gorlanov", "Alexandr Kozlov"], "https://doi.org/10.21437/Interspeech.2019-2757", 5, "interspeech", 2019], ["STC Antispoofing Systems for the ASVspoof2019 Challenge", ["Galina Lavrentyeva", "Sergey Novoselov", "Andzhukaev Tseren", "Marina Volkova", "Artem Gorlanov", "Alexandr Kozlov"], "https://doi.org/10.21437/Interspeech.2019-1768", 5, "interspeech", 2019], ["STC Speaker Recognition Systems for the VOiCES from a Distance Challenge", ["Sergey Novoselov", "Aleksei Gusev", "Artem Ivanov", "Timur Pekhovsky", "Andrey Shulipa", "Galina Lavrentyeva", "Vladimir Volokhov", "Alexandr Kozlov"], "https://doi.org/10.21437/Interspeech.2019-2783", 5, "interspeech", 2019], ["STC Speaker Recognition Systems for the VOiCES from a Distance Challenge", ["Sergey Novoselov", "Aleksei Gusev", "Artem Ivanov", "Timur Pekhovsky", "Andrey Shulipa", "Galina Lavrentyeva", "Vladimir Volokhov", "Alexandr Kozlov"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/abs15.html", 0, "interspeech", 2019]], "Gyorgy Szaszak": [0, ["Assessing the Semantic Space Bias Caused by ASR Error Propagation and its Effect on Spoken Document Summarization", ["Mate Akos Tundik", "Valer Kaszas", "Gyorgy Szaszak"], "https://doi.org/10.21437/Interspeech.2019-2154", 5, "interspeech", 2019], ["Leveraging a Character, Word and Prosody Triplet for an ASR Error Robust and Agglutination Friendly Punctuation Approach", ["Gyorgy Szaszak", "Mate Akos Tundik"], "https://doi.org/10.21437/Interspeech.2019-2132", 5, "interspeech", 2019]], "Takaaki Hori": [0, ["Unidirectional Neural Network Architectures for End-to-End Automatic Speech Recognition", ["Niko Moritz", "Takaaki Hori", "Jonathan Le Roux"], "https://doi.org/10.21437/Interspeech.2019-2837", 5, "interspeech", 2019], ["Joint Student-Teacher Learning for Audio-Visual Scene-Aware Dialog", ["Chiori Hori", "Anoop Cherian", "Tim K. Marks", "Takaaki Hori"], "https://doi.org/10.21437/Interspeech.2019-3143", 5, "interspeech", 2019], ["Analysis of Multilingual Sequence-to-Sequence Speech Recognition Systems", ["Martin Karafiat", "Murali Karthick Baskar", "Shinji Watanabe", "Takaaki Hori", "Matthew Wiesner", "Jan Cernocky"], "https://doi.org/10.21437/Interspeech.2019-2355", 5, "interspeech", 2019], ["End-to-End Multilingual Multi-Speaker Speech Recognition", ["Hiroshi Seki", "Takaaki Hori", "Shinji Watanabe", "Jonathan Le Roux", "John R. Hershey"], "https://doi.org/10.21437/Interspeech.2019-3038", 5, "interspeech", 2019], ["Semi-Supervised Sequence-to-Sequence ASR Using Unpaired Speech and Text", ["Murali Karthick Baskar", "Shinji Watanabe", "Ramon Fernandez Astudillo", "Takaaki Hori", "Lukas Burget", "Jan Cernocky"], "https://doi.org/10.21437/Interspeech.2019-3167", 5, "interspeech", 2019], ["Vectorized Beam Search for CTC-Attention-Based Speech Recognition", ["Hiroshi Seki", "Takaaki Hori", "Shinji Watanabe", "Niko Moritz", "Jonathan Le Roux"], "https://doi.org/10.21437/Interspeech.2019-2860", 5, "interspeech", 2019]], "Joel Shor": [0, ["Personalizing ASR for Dysarthric and Accented Speech with Limited Data", ["Joel Shor", "Dotan Emanuel", "Oran Lang", "Omry Tuval", "Michael Brenner", "Julie Cattiau", "Fernando Vieira", "Maeve McNally", "Taylor Charbonneau", "Melissa Nollstadt", "Avinatan Hassidim", "Yossi Matias"], "https://doi.org/10.21437/Interspeech.2019-1427", 5, "interspeech", 2019]], "Korin Richmond": [0, ["Ultrasound Tongue Imaging for Diarization and Alignment of Child Speech Therapy Sessions", ["Manuel Sam Ribeiro", "Aciel Eshky", "Korin Richmond", "Steve Renals"], "https://doi.org/10.21437/Interspeech.2019-2612", 5, "interspeech", 2019], ["Analysis of Pronunciation Learning in End-to-End Speech Synthesis", ["Jason Taylor", "Korin Richmond"], "https://doi.org/10.21437/Interspeech.2019-2830", 5, "interspeech", 2019], ["Synchronising Audio and Ultrasound by Learning Cross-Modal Embeddings", ["Aciel Eshky", "Manuel Sam Ribeiro", "Korin Richmond", "Steve Renals"], "https://doi.org/10.21437/Interspeech.2019-1804", 5, "interspeech", 2019]], "Henning F. Schepker": [0, ["Evaluating Near End Listening Enhancement Algorithms in Realistic Environments", ["Carol Chermaz", "Cassia Valentini-Botinhao", "Henning F. Schepker", "Simon King"], "https://doi.org/10.21437/Interspeech.2019-1800", 5, "interspeech", 2019]], "Rajiv Ratn Shah": [0, ["Hush-Hush Speak: Speech Reconstruction Using Silent Videos", ["Shashwat Uttam", "Yaman Kumar", "Dhruva Sahrawat", "Mansi Aggarwal", "Rajiv Ratn Shah", "Debanjan Mahata", "Amanda Stent"], "https://doi.org/10.21437/Interspeech.2019-3269", 5, "interspeech", 2019], ["MobiVSR : Efficient and Light-Weight Neural Network for Visual Speech Recognition on Mobile Devices", ["Nilay Shrivastava", "Astitwa Saxena", "Yaman Kumar", "Rajiv Ratn Shah", "Amanda Stent", "Debanjan Mahata", "Preeti Kaur", "Roger Zimmermann"], "https://doi.org/10.21437/Interspeech.2019-3273", 5, "interspeech", 2019]], "Gautam Tiwari": [0, ["Scalable Multi Corpora Neural Language Models for ASR", ["Anirudh Raju", "Denis Filimonov", "Gautam Tiwari", "Guitang Lan", "Ariya Rastrow"], "https://doi.org/10.21437/Interspeech.2019-3060", 5, "interspeech", 2019]], "Tie-Yan Liu": [0, ["Token-Level Ensemble Distillation for Grapheme-to-Phoneme Conversion", ["Hao Sun", "Xu Tan", "Jun-Wei Gan", "Hongzhi Liu", "Sheng Zhao", "Tao Qin", "Tie-Yan Liu"], "https://doi.org/10.21437/Interspeech.2019-1208", 5, "interspeech", 2019]], "Chilin Shih": [0, ["Capturing L1 Influence on L2 Pronunciation by Simulating Perceptual Space Using Acoustic Features", ["Shuju Shi", "Chilin Shih", "Jinsong Zhang"], "https://doi.org/10.21437/Interspeech.2019-3183", 5, "interspeech", 2019]], "Marie-Jose Caraty": [0, ["Spatial, Temporal and Spectral Multiresolution Analysis for the INTERSPEECH 2019 ComParE Challenge", ["Marie-Jose Caraty", "Claude Montacie"], "https://doi.org/10.21437/Interspeech.2019-1693", 5, "interspeech", 2019]], "Wenchao Du": [0, ["Bag-of-Acoustic-Words for Mental Health Assessment: A Deep Autoencoding Approach", ["Wenchao Du", "Louis-Philippe Morency", "Jeffrey F. Cohn", "Alan W. Black"], "https://doi.org/10.21437/Interspeech.2019-3059", 5, "interspeech", 2019]], "Juan Soler Company": [0, ["PyToBI: A Toolkit for ToBI Labeling Under Python", ["Monica Dominguez", "Patrick Louis Rohrer", "Juan Soler Company"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8021.html", 2, "interspeech", 2019]], "Nicanor Garcia-Ospina": [0, ["Apkinson: A Mobile Solution for Multimodal Assessment of Patients with Parkinson's Disease", ["Juan Camilo Vasquez-Correa", "Tomas Arias-Vergara", "Philipp Klumpp", "M. Strauss", "Arne Kuderle", "Nils Roth", "S. Bayerl", "Nicanor Garcia-Ospina", "Paula Andrea Perez-Toro", "L. Felipe Parra-Gallego", "Cristian David Rios-Urrego", "D. Escobar-Grisales", "Juan Rafael Orozco-Arroyave", "Bjorn Eskofier", "Elmar Noth"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8003.html", 2, "interspeech", 2019]], "Martin Jansche": [0, ["Cross-Lingual Consistency of Phonological Features: An Empirical Study", ["Cibu Johny", "Alexander Gutkin", "Martin Jansche"], "https://doi.org/10.21437/Interspeech.2019-2184", 5, "interspeech", 2019], ["Sampling from Stochastic Finite Automata with Applications to CTC Decoding", ["Martin Jansche", "Alexander Gutkin"], "https://doi.org/10.21437/Interspeech.2019-2740", 5, "interspeech", 2019]], "Yinghui Huang": [0, ["Detection and Recovery of OOVs for Improved English Broadcast News Captioning", ["Samuel Thomas", "Kartik Audhkhasi", "Zoltan Tuske", "Yinghui Huang", "Michael Picheny"], "https://doi.org/10.21437/Interspeech.2019-2793", 5, "interspeech", 2019]], "Monica Hegde": [0, ["Liquid Deletion in French Child-Directed Speech", ["Sharon Peperkamp", "Monica Hegde", "Maria Julia Carbajal"], "https://doi.org/10.21437/Interspeech.2019-2838", 5, "interspeech", 2019]], "Hisashi Kawai": [0, ["One-Pass Single-Channel Noisy Speech Recognition Using a Combination of Noisy and Enhanced Features", ["Masakiyo Fujimoto", "Hisashi Kawai"], "https://doi.org/10.21437/Interspeech.2019-1270", 5, "interspeech", 2019], ["Real-Time Neural Text-to-Speech with Sequence-to-Sequence Acoustic Model and WaveGlow or Single Gaussian WaveRNN Vocoders", ["Takuma Okamoto", "Tomoki Toda", "Yoshinori Shiga", "Hisashi Kawai"], "https://doi.org/10.21437/Interspeech.2019-1288", 5, "interspeech", 2019], ["End-to-End Articulatory Attribute Modeling for Low-Resource Multilingual Speech Recognition", ["Sheng Li", "Chenchen Ding", "Xugang Lu", "Peng Shen", "Tatsuya Kawahara", "Hisashi Kawai"], "https://doi.org/10.21437/Interspeech.2019-2092", 5, "interspeech", 2019], ["Investigating Radical-Based End-to-End Speech Recognition Systems for Chinese Dialects and Japanese", ["Sheng Li", "Xugang Lu", "Chenchen Ding", "Peng Shen", "Tatsuya Kawahara", "Hisashi Kawai"], "https://doi.org/10.21437/Interspeech.2019-2104", 5, "interspeech", 2019], ["Incorporating Symbolic Sequential Modeling for Speech Enhancement", ["Chien-Feng Liao", "Yu Tsao", "Xugang Lu", "Hisashi Kawai"], "https://doi.org/10.21437/Interspeech.2019-1777", 5, "interspeech", 2019], ["Class-Wise Centroid Distance Metric Learning for Acoustic Event Detection", ["Xugang Lu", "Peng Shen", "Sheng Li", "Yu Tsao", "Hisashi Kawai"], "https://doi.org/10.21437/Interspeech.2019-2271", 5, "interspeech", 2019], ["Improving Transformer-Based Speech Recognition Systems with Compressed Structure and Speech Attributes Augmentation", ["Sheng Li", "Dabre Raj", "Xugang Lu", "Peng Shen", "Tatsuya Kawahara", "Hisashi Kawai"], "https://doi.org/10.21437/Interspeech.2019-2112", 5, "interspeech", 2019], ["Duration Modeling with Global Phoneme-Duration Vectors", ["Jinfu Ni", "Yoshinori Shiga", "Hisashi Kawai"], "https://doi.org/10.21437/Interspeech.2019-2126", 5, "interspeech", 2019]], "Helen L. Bear": [0, ["Towards Joint Sound Scene and Polyphonic Sound Event Recognition", ["Helen L. Bear", "Ines Nolasco", "Emmanouil Benetos"], "https://doi.org/10.21437/Interspeech.2019-2169", 5, "interspeech", 2019]], "Yi-Wen Liu": [0, ["Acoustic Indicators of Deception in Mandarin Daily Conversations Recorded from an Interactive Game", ["Chih-Hsiang Huang", "Huang-Cheng Chou", "Yi-Tong Wu", "Chi-Chun Lee", "Yi-Wen Liu"], "https://doi.org/10.21437/Interspeech.2019-2216", 5, "interspeech", 2019]], "Ko-Chiang Chen": [0, ["Consonant Classification in Mandarin Based on the Depth Image Feature: A Pilot Study", ["Han-Chi Hsieh", "Wei-Zhong Zheng", "Ko-Chiang Chen", "Ying-Hui Lai"], "https://doi.org/10.21437/Interspeech.2019-1893", 5, "interspeech", 2019]], "Ingo Siegert": [0, ["Three's a Crowd? Effects of a Second Human on Vocal Accommodation with a Voice Assistant", ["Eran Raveh", "Ingo Siegert", "Ingmar Steiner", "Iona Gessinger", "Bernd Mobius"], "https://doi.org/10.21437/Interspeech.2019-1825", 5, "interspeech", 2019]], "Zack Hodari": [0, ["Investigating the Robustness of Sequence-to-Sequence Text-to-Speech Models to Imperfectly-Transcribed Training Data", ["Jason Fong", "Pilar Oplustil Gallegos", "Zack Hodari", "Simon King"], "https://doi.org/10.21437/Interspeech.2019-1824", 5, "interspeech", 2019]], "Yael Segal": [0, ["SpeechYOLO: Detection and Localization of Speech Objects", ["Yael Segal", "Tzeviya Sylvia Fuchs", "Joseph Keshet"], "https://doi.org/10.21437/Interspeech.2019-1749", 5, "interspeech", 2019]], "Laure Dentel": [0, ["A Perceptual Study of CV Syllables in Both Spoken and Whistled Speech: A Tashlhiyt Berber Perspective", ["Julien Meyer", "Laure Dentel", "Silvain Gerber", "Rachid Ridouane"], "https://doi.org/10.21437/Interspeech.2019-2251", 5, "interspeech", 2019]], "Fasih Haider": [0, ["A System for Real-Time Privacy Preserving Data Collection for Ambient Assisted Living", ["Fasih Haider", "Saturnino Luz"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8037.html", 2, "interspeech", 2019]], "Fredric J. Harris": [0, ["On Mitigating Acoustic Feedback in Hearing Aids with Frequency Warping by All-Pass Networks", ["Ching Hua Lee", "Kuan-Lin Chen", "Fredric J. Harris", "Bhaskar D. Rao", "Harinath Garudadri"], "https://doi.org/10.21437/Interspeech.2019-3195", 5, "interspeech", 2019]], "Jinfu Ni": [0, ["Duration Modeling with Global Phoneme-Duration Vectors", ["Jinfu Ni", "Yoshinori Shiga", "Hisashi Kawai"], "https://doi.org/10.21437/Interspeech.2019-2126", 5, "interspeech", 2019]], "Kuan-Lin Chen": [0, ["On Mitigating Acoustic Feedback in Hearing Aids with Frequency Warping by All-Pass Networks", ["Ching Hua Lee", "Kuan-Lin Chen", "Fredric J. Harris", "Bhaskar D. Rao", "Harinath Garudadri"], "https://doi.org/10.21437/Interspeech.2019-3195", 5, "interspeech", 2019]], "Yonghua Lin": [0, ["Few-Shot Audio Classification with Attentional Graph Neural Networks", ["Shilei Zhang", "Yong Qin", "Kewei Sun", "Yonghua Lin"], "https://doi.org/10.21437/Interspeech.2019-1532", 5, "interspeech", 2019]], "Ekin D. Cubuk": [0, ["SpecAugment: A Simple Data Augmentation Method for Automatic Speech Recognition", ["Daniel S. Park", "William Chan", "Yu Zhang", "Chung-Cheng Chiu", "Barret Zoph", "Ekin D. Cubuk", "Quoc V. Le"], "https://doi.org/10.21437/Interspeech.2019-2680", 5, "interspeech", 2019]], "Jiacen Zhang": [0, ["The NEC-TT 2018 Speaker Verification System", ["Kong Aik Lee", "Hitoshi Yamamoto", "Koji Okabe", "Qiongqiong Wang", "Ling Guo", "Takafumi Koshinaka", "Jiacen Zhang", "Koichi Shinoda"], "https://doi.org/10.21437/Interspeech.2019-1517", 5, "interspeech", 2019]], "Bong-Jin Lee": [0.835849791765213, ["Who Said That?: Audio-Visual Speaker Diarisation of Real-World Meetings", ["Joon Son Chung", "Bong-Jin Lee", "Icksang Han"], "https://doi.org/10.21437/Interspeech.2019-3116", 5, "interspeech", 2019]], "Kun Zhou": [0, ["Large-Scale Speaker Diarization of Radio Broadcast Archives", ["Emre Yilmaz", "Adem Derinel", "Kun Zhou", "Henk van den Heuvel", "Niko Brummer", "Haizhou Li", "David A. van Leeuwen"], "https://doi.org/10.21437/Interspeech.2019-1399", 5, "interspeech", 2019]], "Jennifer S. Cole": [0, ["Testing the Distinctiveness of Intonational Tunes: Evidence from Imitative Productions in American English", ["Eleanor Chodroff", "Jennifer S. Cole"], "https://doi.org/10.21437/Interspeech.2019-2684", 5, "interspeech", 2019], ["Perception of Pitch Contours in Speech and Nonspeech", ["Daniel R. Turner", "Ann R. Bradlow", "Jennifer S. Cole"], "https://doi.org/10.21437/Interspeech.2019-2619", 5, "interspeech", 2019]], "Ke Hu": [0, ["Phoneme-Based Contextualization for Cross-Lingual Speech Recognition in End-to-End Models", ["Ke Hu", "Antoine Bruguier", "Tara N. Sainath", "Rohit Prabhavalkar", "Golan Pundak"], "https://doi.org/10.21437/Interspeech.2019-1868", 5, "interspeech", 2019]], "Jason Taylor": [0, ["Analysis of Pronunciation Learning in End-to-End Speech Synthesis", ["Jason Taylor", "Korin Richmond"], "https://doi.org/10.21437/Interspeech.2019-2830", 5, "interspeech", 2019]], "Hiroshi Fujimura": [0, ["Slot Filling with Weighted Multi-Encoders for Out-of-Domain Values", ["Yuka Kobayashi", "Takami Yoshida", "Kenji Iwata", "Hiroshi Fujimura"], "https://doi.org/10.21437/Interspeech.2019-1226", 5, "interspeech", 2019]], "Steven Hillis": [0, ["Unsupervised Phonetic and Word Level Discovery for Speech to Speech Translation for Unwritten Languages", ["Steven Hillis", "Anushree Prasanna Kumar", "Alan W. Black"], "https://doi.org/10.21437/Interspeech.2019-3026", 5, "interspeech", 2019]], "Siddharth Dalmia": [0, ["Multilingual Speech Recognition with Corpus Relatedness Sampling", ["Xinjian Li", "Siddharth Dalmia", "Alan W. Black", "Florian Metze"], "https://doi.org/10.21437/Interspeech.2019-3052", 5, "interspeech", 2019], ["SANTLR: Speech Annotation Toolkit for Low Resource Languages", ["Xinjian Li", "Zhong Zhou", "Siddharth Dalmia", "Alan W. Black", "Florian Metze"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8040.html", 2, "interspeech", 2019], ["Cross-Attention End-to-End ASR for Two-Party Conversations", ["Suyoun Kim", "Siddharth Dalmia", "Florian Metze"], "https://doi.org/10.21437/Interspeech.2019-3173", 5, "interspeech", 2019]], "Ganesh Sivaraman": [0, ["Multi-Corpus Acoustic-to-Articulatory Speech Inversion", ["Nadee Seneviratne", "Ganesh Sivaraman", "Carol Y. Espy-Wilson"], "https://doi.org/10.21437/Interspeech.2019-3168", 5, "interspeech", 2019], ["Pindrop Labs' Submission to the First Multi-Target Speaker Detection and Identification Challenge", ["Elie Khoury", "Khaled Lakhdhar", "Andrew Vaughan", "Ganesh Sivaraman", "Parav Nagarsheth"], "https://doi.org/10.21437/Interspeech.2019-3179", 4, "interspeech", 2019]], "Tomohiro Tanaka": [0, ["Improving Conversation-Context Language Models with Multiple Spoken Language Understanding Models", ["Ryo Masumura", "Tomohiro Tanaka", "Atsushi Ando", "Hosana Kamiyama", "Takanobu Oba", "Satoshi Kobashikawa", "Yushi Aono"], "https://doi.org/10.21437/Interspeech.2019-1534", 5, "interspeech", 2019], ["End-to-End Automatic Speech Recognition with a Reconstruction Criterion Using Speech-to-Text and Text-to-Speech Encoder-Decoders", ["Ryo Masumura", "Hiroshi Sato", "Tomohiro Tanaka", "Takafumi Moriya", "Yusuke Ijima", "Takanobu Oba"], "https://doi.org/10.21437/Interspeech.2019-2111", 5, "interspeech", 2019], ["A Joint End-to-End and DNN-HMM Hybrid Automatic Speech Recognition System with Transferring Sharable Knowledge", ["Tomohiro Tanaka", "Ryo Masumura", "Takafumi Moriya", "Takanobu Oba", "Yushi Aono"], "https://doi.org/10.21437/Interspeech.2019-2263", 5, "interspeech", 2019], ["Joint Maximization Decoder with Neural Converters for Fully Neural Network-Based Japanese Speech Recognition", ["Takafumi Moriya", "Jian Wang", "Tomohiro Tanaka", "Ryo Masumura", "Yusuke Shinohara", "Yoshikazu Yamaguchi", "Yushi Aono"], "https://doi.org/10.21437/Interspeech.2019-1558", 5, "interspeech", 2019]], "Roger Yu-Hsiang Lo": [0, ["SLP-AA: Tools for Sign Language Phonetic and Phonological Research", ["Roger Yu-Hsiang Lo", "Kathleen Currie Hall"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8028.html", 2, "interspeech", 2019]], "Jonathan Le Roux": [0, ["Unidirectional Neural Network Architectures for End-to-End Automatic Speech Recognition", ["Niko Moritz", "Takaaki Hori", "Jonathan Le Roux"], "https://doi.org/10.21437/Interspeech.2019-2837", 5, "interspeech", 2019], ["WHAM!: Extending Speech Separation to Noisy Environments", ["Gordon Wichern", "Joe Antognini", "Michael Flynn", "Licheng Richard Zhu", "Emmett McQuinn", "Dwight Crow", "Ethan Manilow", "Jonathan Le Roux"], "https://doi.org/10.21437/Interspeech.2019-2821", 5, "interspeech", 2019], ["End-to-End Multilingual Multi-Speaker Speech Recognition", ["Hiroshi Seki", "Takaaki Hori", "Shinji Watanabe", "Jonathan Le Roux", "John R. Hershey"], "https://doi.org/10.21437/Interspeech.2019-3038", 5, "interspeech", 2019], ["Vectorized Beam Search for CTC-Attention-Based Speech Recognition", ["Hiroshi Seki", "Takaaki Hori", "Shinji Watanabe", "Niko Moritz", "Jonathan Le Roux"], "https://doi.org/10.21437/Interspeech.2019-2860", 5, "interspeech", 2019]], "Tanya Gurevich": [0, ["Identifying Distinctive Acoustic and Spectral Features in Parkinson's Disease", ["Yermiyahu Hauptman", "Ruth Aloni-Lavi", "Itshak Lapidot", "Tanya Gurevich", "Yael Manor", "Stav Naor", "Noa Diamant", "Irit Opher"], "https://doi.org/10.21437/Interspeech.2019-2465", 5, "interspeech", 2019]], "Lou Boves": [0, ["Analyzing Reaction Time and Error Sequences in Lexical Decision Experiments", ["Louis ten Bosch", "Lou Boves", "Kimberley Mulder"], "https://doi.org/10.21437/Interspeech.2019-2611", 5, "interspeech", 2019]], "Lauren Ward": [0, ["R2SPIN: Re-Recording the Revised Speech Perception in Noise Test", ["Lauren Ward", "Catherine Robinson", "Matthew Paradis", "Katherine M. Tucker", "Ben G. Shirley"], "https://doi.org/10.21437/Interspeech.2019-1281", 5, "interspeech", 2019]], "Artem Ivanov": [0, ["Speaker Diarization with Deep Speaker Embeddings for DIHARD Challenge II", ["Sergey Novoselov", "Aleksei Gusev", "Artem Ivanov", "Timur Pekhovsky", "Andrey Shulipa", "Anastasia Avdeeva", "Artem Gorlanov", "Alexandr Kozlov"], "https://doi.org/10.21437/Interspeech.2019-2757", 5, "interspeech", 2019], ["STC Speaker Recognition Systems for the VOiCES from a Distance Challenge", ["Sergey Novoselov", "Aleksei Gusev", "Artem Ivanov", "Timur Pekhovsky", "Andrey Shulipa", "Galina Lavrentyeva", "Vladimir Volokhov", "Alexandr Kozlov"], "https://doi.org/10.21437/Interspeech.2019-2783", 5, "interspeech", 2019], ["STC Speaker Recognition Systems for the VOiCES from a Distance Challenge", ["Sergey Novoselov", "Aleksei Gusev", "Artem Ivanov", "Timur Pekhovsky", "Andrey Shulipa", "Galina Lavrentyeva", "Vladimir Volokhov", "Alexandr Kozlov"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/abs15.html", 0, "interspeech", 2019]], "Soonshin Seo": [0.10910973697900772, ["Shortcut Connections Based Deep Speaker Embeddings for End-to-End Speaker Verification System", ["Soonshin Seo", "Daniel Jun Rim", "Minkyu Lim", "Donghyun Lee", "Hosung Park", "Junseok Oh", "Changmin Kim", "Ji-Hwan Kim"], "https://doi.org/10.21437/Interspeech.2019-2195", 5, "interspeech", 2019]], "Sneha Raman": [0, ["Parallel vs. Non-Parallel Voice Conversion for Esophageal Speech", ["Luis Serrano", "Sneha Raman", "David Tavarez", "Eva Navas", "Inma Hernaez"], "https://doi.org/10.21437/Interspeech.2019-2194", 5, "interspeech", 2019]], "Bruno Ferenc Segedin": [0, ["Perceptual Adaptation to Device and Human Voices: Learning and Generalization of a Phonetic Shift Across Real and Voice-AI Talkers", ["Bruno Ferenc Segedin", "Michelle Cohn", "Georgia Zellou"], "https://doi.org/10.21437/Interspeech.2019-1433", 5, "interspeech", 2019]], "Sree Hari Krishnan Parthasarathi": [0, ["Two Tiered Distributed Training Algorithm for Acoustic Modeling", ["Pranav Ladkat", "Oleg Rybakov", "Radhika Arava", "Sree Hari Krishnan Parthasarathi", "I-Fan Chen", "Nikko Strom"], "https://doi.org/10.21437/Interspeech.2019-1859", 5, "interspeech", 2019]], "Iona Gessinger": [0, ["Phonetic Accommodation in a Wizard-of-Oz Experiment: Intonation and Segments", ["Iona Gessinger", "Bernd Mobius", "Bistra Andreeva", "Eran Raveh", "Ingmar Steiner"], "https://doi.org/10.21437/Interspeech.2019-2445", 5, "interspeech", 2019], ["Three's a Crowd? Effects of a Second Human on Vocal Accommodation with a Voice Assistant", ["Eran Raveh", "Ingo Siegert", "Ingmar Steiner", "Iona Gessinger", "Bernd Mobius"], "https://doi.org/10.21437/Interspeech.2019-1825", 5, "interspeech", 2019]], "Maria Liakata": [0, ["A Path Signature Approach for Speech Emotion Recognition", ["Bo Wang", "Maria Liakata", "Hao Ni", "Terry Lyons", "Alejo J. Nevado-Holgado", "Kate Saunders"], "https://doi.org/10.21437/Interspeech.2019-2624", 5, "interspeech", 2019]], "Silas Rech": [0, ["Privacy-Preserving Siamese Feature Extraction for Gender Recognition versus Speaker Identification", ["Alexandru Nelus", "Silas Rech", "Timm Koppelmann", "Henrik Biermann", "Rainer Martin"], "https://doi.org/10.21437/Interspeech.2019-1148", 5, "interspeech", 2019]], "Henrik Biermann": [0, ["Privacy-Preserving Siamese Feature Extraction for Gender Recognition versus Speaker Identification", ["Alexandru Nelus", "Silas Rech", "Timm Koppelmann", "Henrik Biermann", "Rainer Martin"], "https://doi.org/10.21437/Interspeech.2019-1148", 5, "interspeech", 2019]], "Paula Martins": [0, ["On the Role of Oral Configurations in European Portuguese Nasal Vowels", ["Conceicao Cunha", "Samuel S. Silva", "Antonio J. S. Teixeira", "Catarina Oliveira", "Paula Martins", "Arun A. Joseph", "Jens Frahm"], "https://doi.org/10.21437/Interspeech.2019-2232", 5, "interspeech", 2019]], "Masakiyo Fujimoto": [0, ["One-Pass Single-Channel Noisy Speech Recognition Using a Combination of Noisy and Enhanced Features", ["Masakiyo Fujimoto", "Hisashi Kawai"], "https://doi.org/10.21437/Interspeech.2019-1270", 5, "interspeech", 2019]], "Puming Zhan": [0, ["Deep Learning Based Mandarin Accent Identification for Accent Robust ASR", ["Felix Weninger", "Yang Sun", "Junho Park", "Daniel Willett", "Puming Zhan"], "https://doi.org/10.21437/Interspeech.2019-2737", 5, "interspeech", 2019], ["Listen, Attend, Spell and Adapt: Speaker Adapted Sequence-to-Sequence ASR", ["Felix Weninger", "Jesus Andres-Ferrer", "Xinwei Li", "Puming Zhan"], "https://doi.org/10.21437/Interspeech.2019-2719", 5, "interspeech", 2019]], "Alex Sokolov": [0, ["Neural Machine Translation for Multilingual Grapheme-to-Phoneme Conversion", ["Alex Sokolov", "Tracy Rohlin", "Ariya Rastrow"], "https://doi.org/10.21437/Interspeech.2019-3176", 5, "interspeech", 2019]], "Chanwoo Kim": [0.9085521399974823, ["Improved Vocal Tract Length Perturbation for a State-of-the-Art End-to-End Speech Recognition System", ["Chanwoo Kim", "Minkyu Shin", "Abhinav Garg", "Dhananjaya Gowda"], "https://doi.org/10.21437/Interspeech.2019-3227", 5, "interspeech", 2019], ["Multi-Task Multi-Resolution Char-to-BPE Cross-Attention Decoder for End-to-End Speech Recognition", ["Dhananjaya Gowda", "Abhinav Garg", "Kwangyoun Kim", "Mehul Kumar", "Chanwoo Kim"], "https://doi.org/10.21437/Interspeech.2019-3216", 5, "interspeech", 2019]], "Hiroshi Honda": [0, ["Recognition of Intentions of Users' Short Responses for Conversational News Delivery System", ["Hiroaki Takatsu", "Katsuya Yokoyama", "Yoichi Matsuyama", "Hiroshi Honda", "Shinya Fujie", "Tetsunori Kobayashi"], "https://doi.org/10.21437/Interspeech.2019-2121", 5, "interspeech", 2019]], "Louis ten Bosch": [0, ["ERP Signal Analysis with Temporal Resolution Using a Time Window Bank", ["Annika Nijveld", "Louis ten Bosch", "Mirjam Ernestus"], "https://doi.org/10.21437/Interspeech.2019-2729", 5, "interspeech", 2019], ["Phase Synchronization Between EEG Signals as a Function of Differences Between Stimuli Characteristics", ["Louis ten Bosch", "Kimberley Mulder", "Louis Boves"], "https://doi.org/10.21437/Interspeech.2019-2443", 5, "interspeech", 2019], ["Listening with Great Expectations: An Investigation of Word Form Anticipations in Naturalistic Speech", ["M. Bentum", "Louis ten Bosch", "Antal van den Bosch", "Mirjam Ernestus"], "https://doi.org/10.21437/Interspeech.2019-2741", 5, "interspeech", 2019], ["Quantifying Expectation Modulation in Human Speech Processing", ["M. Bentum", "Louis ten Bosch", "Antal van den Bosch", "Mirjam Ernestus"], "https://doi.org/10.21437/Interspeech.2019-2685", 5, "interspeech", 2019], ["Analyzing Reaction Time and Error Sequences in Lexical Decision Experiments", ["Louis ten Bosch", "Lou Boves", "Kimberley Mulder"], "https://doi.org/10.21437/Interspeech.2019-2611", 5, "interspeech", 2019]], "Lena Pagel": [0, ["Dimensions of Prosodic Prominence in an Attractor Model", ["Simon Roessig", "Doris Mucke", "Lena Pagel"], "https://doi.org/10.21437/Interspeech.2019-2227", 5, "interspeech", 2019]], "Naohiro Tawara": [0, ["Multi-Channel Speech Enhancement Using Time-Domain Convolutional Denoising Autoencoder", ["Naohiro Tawara", "Tetsunori Kobayashi", "Tetsuji Ogawa"], "https://doi.org/10.21437/Interspeech.2019-3197", 5, "interspeech", 2019], ["Speaker Adversarial Training of DPGMM-Based Feature Extractor for Zero-Resource Languages", ["Yosuke Higuchi", "Naohiro Tawara", "Tetsunori Kobayashi", "Tetsuji Ogawa"], "https://doi.org/10.21437/Interspeech.2019-2052", 5, "interspeech", 2019]], "Ha-Jin Yu": [0.7287916094064713, ["Acoustic Scene Classification Using Teacher-Student Learning with Soft-Labels", ["Hee-Soo Heo", "Jee-weon Jung", "Hye-jin Shim", "Ha-Jin Yu"], "https://doi.org/10.21437/Interspeech.2019-1989", 5, "interspeech", 2019], ["Replay Attack Detection with Complementary High-Resolution Information Using End-to-End DNN for the ASVspoof 2019 Challenge", ["Jee-weon Jung", "Hye-jin Shim", "Hee-Soo Heo", "Ha-Jin Yu"], "https://doi.org/10.21437/Interspeech.2019-1991", 5, "interspeech", 2019], ["RawNet: Advanced End-to-End Deep Neural Network Using Raw Waveforms for Text-Independent Speaker Verification", ["Jee-weon Jung", "Hee-Soo Heo", "Ju-ho Kim", "Hye-jin Shim", "Ha-Jin Yu"], "https://doi.org/10.21437/Interspeech.2019-1982", 5, "interspeech", 2019], ["End-to-End Losses Based on Speaker Basis Vectors and All-Speaker Hard Negative Mining for Speaker Verification", ["Hee-Soo Heo", "Jee-weon Jung", "Il-Ho Yang", "Sung-Hyun Yoon", "Hye-jin Shim", "Ha-Jin Yu"], "https://doi.org/10.21437/Interspeech.2019-1986", 5, "interspeech", 2019]], "William Brannon": [0, ["RadioTalk: A Large-Scale Corpus of Talk Radio Transcripts", ["Doug Beeferman", "William Brannon", "Deb Roy"], "https://doi.org/10.21437/Interspeech.2019-2714", 5, "interspeech", 2019]], "Anna Lukaszewicz": [0, ["An Acoustic Study of Vowel Undershoot in a System with Several Degrees of Prominence", ["Janina Molczanow", "Beata Lukaszewicz", "Anna Lukaszewicz"], "https://doi.org/10.21437/Interspeech.2019-1806", 5, "interspeech", 2019]], "Phani Sankar Nidadavolu": [0, ["The JHU ASR System for VOiCES from a Distance Challenge 2019", ["Yiming Wang", "David Snyder", "Hainan Xu", "Vimal Manohar", "Phani Sankar Nidadavolu", "Daniel Povey", "Sanjeev Khudanpur"], "https://doi.org/10.21437/Interspeech.2019-1948", 5, "interspeech", 2019]], "Yexin Yang": [1.4208983429853106e-05, ["The SJTU Robust Anti-Spoofing System for the ASVspoof 2019 Challenge", ["Yexin Yang", "Hongji Wang", "Heinrich Dinkel", "Zhengyang Chen", "Shuai Wang", "Yanmin Qian", "Kai Yu"], "https://doi.org/10.21437/Interspeech.2019-2170", 5, "interspeech", 2019]], "Fahimeh Bahmaninezhad": [0, ["I4U Submission to NIST SRE 2018: Leveraging from a Decade of Shared Experiences", ["Kong Aik Lee", "Ville Hautamaki", "Tomi H. Kinnunen", "Hitoshi Yamamoto", "Koji Okabe", "Ville Vestman", "Jing Huang", "Guohong Ding", "Hanwu Sun", "Anthony Larcher", "Rohan Kumar Das", "Haizhou Li", "Mickael Rouvier", "Pierre-Michel Bousquet", "Wei Rao", "Qing Wang", "Chunlei Zhang", "Fahimeh Bahmaninezhad", "Hector Delgado", "Massimiliano Todisco"], "https://doi.org/10.21437/Interspeech.2019-1533", 5, "interspeech", 2019], ["A Comprehensive Study of Speech Separation: Spectrogram vs Waveform Separation", ["Fahimeh Bahmaninezhad", "Jian Wu", "Rongzhi Gu", "Shi-Xiong Zhang", "Yong Xu", "Meng Yu", "Dong Yu"], "https://doi.org/10.21437/Interspeech.2019-3181", 5, "interspeech", 2019]], "Michelle Tran": [0, ["Identifying Input Features for Development of Real-Time Translation of Neural Signals to Text", ["Janaki Sheth", "Ariel Tankus", "Michelle Tran", "Lindy Comstock", "Itzhak Fried", "William Speier"], "https://doi.org/10.21437/Interspeech.2019-3092", 5, "interspeech", 2019]], "Shucong Zhang": [0, ["Trainable Dynamic Subsampling for End-to-End Speech Recognition", ["Shucong Zhang", "Erfan Loweimi", "Yumo Xu", "Peter Bell", "Steve Renals"], "https://doi.org/10.21437/Interspeech.2019-2778", 5, "interspeech", 2019]], "Shi-Xiong Zhang": [0, ["Improved Speaker-Dependent Separation for CHiME-5 Challenge", ["Jian Wu", "Yong Xu", "Shi-Xiong Zhang", "Lianwu Chen", "Meng Yu", "Lei Xie", "Dong Yu"], "https://doi.org/10.21437/Interspeech.2019-1569", 5, "interspeech", 2019], ["Neural Spatial Filter: Target Speaker Speech Separation Assisted with Directional Information", ["Rongzhi Gu", "Lianwu Chen", "Shi-Xiong Zhang", "Jimeng Zheng", "Yong Xu", "Meng Yu", "Dan Su", "Yuexian Zou", "Dong Yu"], "https://doi.org/10.21437/Interspeech.2019-2266", 5, "interspeech", 2019], ["A Comprehensive Study of Speech Separation: Spectrogram vs Waveform Separation", ["Fahimeh Bahmaninezhad", "Jian Wu", "Rongzhi Gu", "Shi-Xiong Zhang", "Yong Xu", "Meng Yu", "Dong Yu"], "https://doi.org/10.21437/Interspeech.2019-3181", 5, "interspeech", 2019]], "Titouan Parcollet": [0, ["M2H-GAN: A GAN-Based Mapping from Machine to Human Transcripts for Speech Understanding", ["Titouan Parcollet", "Mohamed Morchid", "Xavier Bost", "Georges Linares"], "https://doi.org/10.21437/Interspeech.2019-2662", 5, "interspeech", 2019], ["Real to H-Space Encoder for Speech Recognition", ["Titouan Parcollet", "Mohamed Morchid", "Georges Linares", "Renato De Mori"], "https://doi.org/10.21437/Interspeech.2019-1539", 5, "interspeech", 2019]], "Chenda Li": [0, ["Prosody Usage Optimization for Children Speech Recognition with Zero Resource Children Speech", ["Chenda Li", "Yanmin Qian"], "https://doi.org/10.21437/Interspeech.2019-2659", 5, "interspeech", 2019]], "Joao Monteiro": [0, ["Combining Speaker Recognition and Metric Learning for Speaker-Dependent Representation Learning", ["Joao Monteiro", "Md. Jahangir Alam", "Tiago H. Falk"], "https://doi.org/10.21437/Interspeech.2019-2974", 5, "interspeech", 2019]], "Ruiqing Yin": [0, ["LSTM Based Similarity Measurement with Spectral Clustering for Speaker Diarization", ["Qingjian Lin", "Ruiqing Yin", "Ming Li", "Herve Bredin", "Claude Barras"], "https://doi.org/10.21437/Interspeech.2019-1388", 5, "interspeech", 2019]], "Patrick Louis Rohrer": [0, ["PyToBI: A Toolkit for ToBI Labeling Under Python", ["Monica Dominguez", "Patrick Louis Rohrer", "Juan Soler Company"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8021.html", 2, "interspeech", 2019]], "Mariya Kharaman": [0, ["The Processing of Prosodic Cues to Rhetorical Question Interpretation: Psycholinguistic and Neurolinguistics Evidence", ["Mariya Kharaman", "Manluolan Xu", "Carsten Eulitz", "Bettina Braun"], "https://doi.org/10.21437/Interspeech.2019-2528", 5, "interspeech", 2019]], "Deep Chakraborty": [0, ["Nonparallel Emotional Speech Conversion", ["Jian Gao", "Deep Chakraborty", "Hamidou Tembine", "Olaitan Olaleye"], "https://doi.org/10.21437/Interspeech.2019-2878", 5, "interspeech", 2019]], "Raefer Gabriel": [0, ["Topical-Chat: Towards Knowledge-Grounded Open-Domain Conversations", ["Karthik Gopalakrishnan", "Behnam Hedayatnia", "Qinglang Chen", "Anna Gottardi", "Sanjeev Kwatra", "Anu Venkatesh", "Raefer Gabriel", "Dilek Hakkani-Tur"], "https://doi.org/10.21437/Interspeech.2019-3079", 5, "interspeech", 2019]], "Zakaria Aldeneh": [0, ["Identifying Mood Episodes Using Dialogue Features from Clinical Interviews", ["Zakaria Aldeneh", "Mimansa Jaiswal", "Michael Picheny", "Melvin G. McInnis", "Emily Mower Provost"], "https://doi.org/10.21437/Interspeech.2019-1878", 5, "interspeech", 2019]], "Katherine Metcalf": [0, ["Mirroring to Build Trust in Digital Assistants", ["Katherine Metcalf", "Barry-John Theobald", "Garrett Weinberg", "Robert Lee", "Ing-Marie Jonsson", "Russ Webb", "Nicholas Apostoloff"], "https://doi.org/10.21437/Interspeech.2019-1829", 5, "interspeech", 2019]], "Alexandru Nelus": [0, ["Privacy-Preserving Siamese Feature Extraction for Gender Recognition versus Speaker Identification", ["Alexandru Nelus", "Silas Rech", "Timm Koppelmann", "Henrik Biermann", "Rainer Martin"], "https://doi.org/10.21437/Interspeech.2019-1148", 5, "interspeech", 2019], ["Privacy-Preserving Variational Information Feature Extraction for Domestic Activity Monitoring versus Speaker Identification", ["Alexandru Nelus", "Janek Ebbers", "Reinhold Haeb-Umbach", "Rainer Martin"], "https://doi.org/10.21437/Interspeech.2019-1703", 5, "interspeech", 2019]], "Mirko Marras": [0, ["Adversarial Optimization for Dictionary Attacks on Speaker Verification", ["Mirko Marras", "Pawel Korus", "Nasir D. Memon", "Gianni Fenu"], "https://doi.org/10.21437/Interspeech.2019-2430", 5, "interspeech", 2019]], "Ben G. Shirley": [0, ["R2SPIN: Re-Recording the Revised Speech Perception in Noise Test", ["Lauren Ward", "Catherine Robinson", "Matthew Paradis", "Katherine M. Tucker", "Ben G. Shirley"], "https://doi.org/10.21437/Interspeech.2019-1281", 5, "interspeech", 2019]], "Jia-Xiang Chen": [0, ["A Chinese Dataset for Identifying Speakers in Novels", ["Jia-Xiang Chen", "Zhen-Hua Ling", "Li-Rong Dai"], "https://doi.org/10.21437/Interspeech.2019-1614", 5, "interspeech", 2019]], "Benjamin Milde": [0, ["SparseSpeech: Unsupervised Acoustic Unit Discovery with Memory-Augmented Sequence Autoencoders", ["Benjamin Milde", "Chris Biemann"], "https://doi.org/10.21437/Interspeech.2019-2938", 5, "interspeech", 2019]], "Cathryn Snyder": [0, ["Individual Variation in Cognitive Processing Style Predicts Differences in Phonetic Imitation of Device and Human Voices", ["Cathryn Snyder", "Michelle Cohn", "Georgia Zellou"], "https://doi.org/10.21437/Interspeech.2019-2669", 5, "interspeech", 2019]], "David Ayllon": [0, ["Investigating the Effects of Noisy and Reverberant Speech in Text-to-Speech Systems", ["David Ayllon", "Hector A. Sanchez-Hevia", "Carol Figueroa", "Pierre Lanchantin"], "https://doi.org/10.21437/Interspeech.2019-3104", 5, "interspeech", 2019], ["A Strategy for Improved Phone-Level Lyrics-to-Audio Alignment for Speech-to-Singing Synthesis", ["David Ayllon", "Fernando Villavicencio", "Pierre Lanchantin"], "https://doi.org/10.21437/Interspeech.2019-3049", 5, "interspeech", 2019]], "Ravi Yadav": [0, ["Comparison of Speech Tasks and Recording Devices for Voice Based Automatic Classification of Healthy Subjects and Patients with Amyotrophic Lateral Sclerosis", ["Suhas B. N.", "Deep Patel", "Nithin Rao Koluguri", "Yamini Belur", "Pradeep Reddy", "Atchayaram Nalini", "Ravi Yadav", "Dipanjan Gope", "Prasanta Kumar Ghosh"], "https://doi.org/10.21437/Interspeech.2019-1285", 5, "interspeech", 2019]], "Sudarsana Reddy Kadiri": [0, ["Mel-Frequency Cepstral Coefficients of Voice Source Waveforms for Classification of Phonation Types in Speech", ["Sudarsana Reddy Kadiri", "Paavo Alku"], "https://doi.org/10.21437/Interspeech.2019-2863", 5, "interspeech", 2019]], "Mohamed Ismail Yasar Arafath K": [0, ["Automatic Detection of Breath Using Voice Activity Detection and SVM Classifier with Application on News Reports", ["Mohamed Ismail Yasar Arafath K", "Aurobinda Routray"], "https://doi.org/10.21437/Interspeech.2019-2434", 5, "interspeech", 2019]], "Dhruva Sahrawat": [0, ["Hush-Hush Speak: Speech Reconstruction Using Silent Videos", ["Shashwat Uttam", "Yaman Kumar", "Dhruva Sahrawat", "Mansi Aggarwal", "Rajiv Ratn Shah", "Debanjan Mahata", "Amanda Stent"], "https://doi.org/10.21437/Interspeech.2019-3269", 5, "interspeech", 2019]], "Peter Balazs": [0, ["Harmonic-Aligned Frame Mask Based on Non-Stationary Gabor Transform with Application to Content-Dependent Speaker Comparison", ["Feng Huang", "Peter Balazs"], "https://doi.org/10.21437/Interspeech.2019-1327", 5, "interspeech", 2019]], "Qing Wang": [0.00010747280612122267, ["I4U Submission to NIST SRE 2018: Leveraging from a Decade of Shared Experiences", ["Kong Aik Lee", "Ville Hautamaki", "Tomi H. Kinnunen", "Hitoshi Yamamoto", "Koji Okabe", "Ville Vestman", "Jing Huang", "Guohong Ding", "Hanwu Sun", "Anthony Larcher", "Rohan Kumar Das", "Haizhou Li", "Mickael Rouvier", "Pierre-Michel Bousquet", "Wei Rao", "Qing Wang", "Chunlei Zhang", "Fahimeh Bahmaninezhad", "Hector Delgado", "Massimiliano Todisco"], "https://doi.org/10.21437/Interspeech.2019-1533", 5, "interspeech", 2019], ["Adversarial Regularization for End-to-End Robust Speaker Verification", ["Qing Wang", "Pengcheng Guo", "Sining Sun", "Lei Xie", "John H. L. Hansen"], "https://doi.org/10.21437/Interspeech.2019-2983", 5, "interspeech", 2019]], "Eng Siong Chng": [0, ["A Speaker-Dependent WaveNet for Voice Conversion with Non-Parallel Data", ["Xiaohai Tian", "Eng Siong Chng", "Haizhou Li"], "https://doi.org/10.21437/Interspeech.2019-1514", 5, "interspeech", 2019], ["Target Speaker Extraction for Multi-Talker Speaker Verification", ["Wei Rao", "Chenglin Xu", "Eng Siong Chng", "Haizhou Li"], "https://doi.org/10.21437/Interspeech.2019-1410", 5, "interspeech", 2019], ["Constrained Output Embeddings for End-to-End Code-Switching Speech Recognition with Only Monolingual Data", ["Yerbolat Khassanov", "Haihua Xu", "Van Tung Pham", "Zhiping Zeng", "Eng Siong Chng", "Chongjia Ni", "Bin Ma"], "https://doi.org/10.21437/Interspeech.2019-1867", 5, "interspeech", 2019], ["On the End-to-End Solution to Mandarin-English Code-Switching Speech Recognition", ["Zhiping Zeng", "Yerbolat Khassanov", "Van Tung Pham", "Haihua Xu", "Eng Siong Chng", "Haizhou Li"], "https://doi.org/10.21437/Interspeech.2019-1429", 5, "interspeech", 2019], ["Enriching Rare Word Representations in Neural Language Models by Embedding Matrix Augmentation", ["Yerbolat Khassanov", "Zhiping Zeng", "Van Tung Pham", "Haihua Xu", "Eng Siong Chng"], "https://doi.org/10.21437/Interspeech.2019-1858", 5, "interspeech", 2019]], "Inga Run Helgadottir": [0, ["The Althingi ASR System", ["Inga Run Helgadottir", "Anna Bjork Nikulasdottir", "Michal Borsky", "Judy Y. Fong", "Robert Kjaran", "Jon Gudnason"], "https://doi.org/10.21437/Interspeech.2019-1248", 5, "interspeech", 2019], ["Lattice Re-Scoring During Manual Editing for Automatic Error Correction of ASR Transcripts", ["Anna V. Runarsdottir", "Inga Run Helgadottir", "Jon Gudnason"], "https://doi.org/10.21437/Interspeech.2019-1790", 5, "interspeech", 2019]], "Chongke Bi": [0, ["Individual Difference of Relative Tongue Size and its Acoustic Effects", ["Xiaohan Zhang", "Chongke Bi", "Kiyoshi Honda", "Wenhuan Lu", "Jianguo Wei"], "https://doi.org/10.21437/Interspeech.2019-2452", 5, "interspeech", 2019]], "Pavel Denisov": [0, ["End-to-End Multi-Speaker Speech Recognition Using Speaker Embeddings and Transfer Learning", ["Pavel Denisov", "Ngoc Thang Vu"], "https://doi.org/10.21437/Interspeech.2019-1130", 5, "interspeech", 2019]], "Rachel Albar": [0, ["Phonological Awareness of French Rising Contours in Japanese Learners", ["Rachel Albar", "Hiyon Yoo"], "https://doi.org/10.21437/Interspeech.2019-2856", 5, "interspeech", 2019]], "Shoukang Hu": [0, ["LF-MMI Training of Bayesian and Gaussian Process Time Delay Neural Networks for Speech Recognition", ["Shoukang Hu", "Xurong Xie", "Shansong Liu", "Max W. Y. Lam", "Jianwei Yu", "Xixin Wu", "Xunying Liu", "Helen Meng"], "https://doi.org/10.21437/Interspeech.2019-2379", 5, "interspeech", 2019], ["Comparative Study of Parametric and Representation Uncertainty Modeling for Recurrent Neural Network Language Models", ["Jianwei Yu", "Max W. Y. Lam", "Shoukang Hu", "Xixin Wu", "Xu Li", "Yuewen Cao", "Xunying Liu", "Helen Meng"], "https://doi.org/10.21437/Interspeech.2019-1927", 5, "interspeech", 2019], ["The CUHK Dysarthric Speech Recognition Systems for English and Cantonese", ["Shoukang Hu", "Shansong Liu", "Heng Fai Chang", "Mengzhe Geng", "Jiani Chen", "Lau Wing Chung", "To Ka Hei", "Jianwei Yu", "Ka Ho Wong", "Xunying Liu", "Helen Meng"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8047.html", 2, "interspeech", 2019], ["Exploiting Visual Features Using Bayesian Gated Neural Networks for Disordered Speech Recognition", ["Shansong Liu", "Shoukang Hu", "Yi Wang", "Jianwei Yu", "Rongfeng Su", "Xunying Liu", "Helen Meng"], "https://doi.org/10.21437/Interspeech.2019-1536", 5, "interspeech", 2019], ["On the Use of Pitch Features for Disordered Speech Recognition", ["Shansong Liu", "Shoukang Hu", "Xunying Liu", "Helen Meng"], "https://doi.org/10.21437/Interspeech.2019-2609", 5, "interspeech", 2019]], "Mitchell MacKnight": [0, ["ReMASC: Realistic Replay Attack Corpus for Voice Controlled Systems", ["Yuan Gong", "Jian Yang", "Jacob Huber", "Mitchell MacKnight", "Christian Poellabauer"], "https://doi.org/10.21437/Interspeech.2019-1541", 5, "interspeech", 2019]], "Siqi Zheng": [0, ["Towards a Fault-Tolerant Speaker Verification System: A Regularization Approach to Reduce the Condition Number", ["Siqi Zheng", "Gang Liu", "Hongbin Suo", "Yun Lei"], "https://doi.org/10.21437/Interspeech.2019-1442", 5, "interspeech", 2019], ["Autoencoder-Based Semi-Supervised Curriculum Learning for Out-of-Domain Speaker Verification", ["Siqi Zheng", "Gang Liu", "Hongbin Suo", "Yun Lei"], "https://doi.org/10.21437/Interspeech.2019-1440", 5, "interspeech", 2019]], "Daniel Bunn": [0, ["The Effects of Time Expansion on English as a Second Language Individuals", ["John S. Novak III", "Daniel Bunn", "Robert V. Kenyon"], "https://doi.org/10.21437/Interspeech.2019-2763", 5, "interspeech", 2019]], "Loren Lugosch": [0, ["Speech Model Pre-Training for End-to-End Spoken Language Understanding", ["Loren Lugosch", "Mirco Ravanelli", "Patrick Ignoto", "Vikrant Singh Tomar", "Yoshua Bengio"], "https://doi.org/10.21437/Interspeech.2019-2396", 5, "interspeech", 2019]], "Karan Nathwani": [0, ["Excitation Source and Vocal Tract System Based Acoustic Features for Detection of Nasals in Continuous Speech", ["Bhanu Teja Nellore", "Sri Harsha Dumpala", "Karan Nathwani", "Suryakanth V. Gangashetty"], "https://doi.org/10.21437/Interspeech.2019-2785", 5, "interspeech", 2019]], "Michael Flynn": [0, ["WHAM!: Extending Speech Separation to Noisy Environments", ["Gordon Wichern", "Joe Antognini", "Michael Flynn", "Licheng Richard Zhu", "Emmett McQuinn", "Dwight Crow", "Ethan Manilow", "Jonathan Le Roux"], "https://doi.org/10.21437/Interspeech.2019-2821", 5, "interspeech", 2019]], "Hang Su": [0, ["Unsupervised Methods for Audio Classification from Lecture Discussion Recordings", ["Hang Su", "Borislav Dzodzo", "Xixin Wu", "Xunying Liu", "Helen Meng"], "https://doi.org/10.21437/Interspeech.2019-2384", 5, "interspeech", 2019]], "Philip N. Garner": [0, ["Unbiased Semi-Supervised LF-MMI Training Using Dropout", ["Sibo Tong", "Apoorv Vyas", "Philip N. Garner", "Herve Bourlard"], "https://doi.org/10.21437/Interspeech.2019-2678", 5, "interspeech", 2019], ["Self-Attention for Speech Emotion Recognition", ["Lorenzo Tarantino", "Philip N. Garner", "Alexandros Lazaridis"], "https://doi.org/10.21437/Interspeech.2019-2822", 5, "interspeech", 2019]], "Heiga Zen": [0, ["LibriTTS: A Corpus Derived from LibriSpeech for Text-to-Speech", ["Heiga Zen", "Viet Dang", "Rob Clark", "Yu Zhang", "Ron J. Weiss", "Ye Jia", "Zhifeng Chen", "Yonghui Wu"], "https://doi.org/10.21437/Interspeech.2019-2441", 5, "interspeech", 2019], ["Learning to Speak Fluently in a Foreign Language: Multilingual Speech Synthesis and Cross-Language Voice Cloning", ["Yu Zhang", "Ron J. Weiss", "Heiga Zen", "Yonghui Wu", "Zhifeng Chen", "R. J. Skerry-Ryan", "Ye Jia", "Andrew Rosenberg", "Bhuvana Ramabhadran"], "https://doi.org/10.21437/Interspeech.2019-2668", 5, "interspeech", 2019]], "A. Miwardelli": [0, ["Splash: Speech and Language Assessment in Schools and Homes", ["A. Miwardelli", "I. Gallagher", "J. Gibson", "Napoleon Katsos", "Kate M. Knill", "H. Wood"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8027.html", 2, "interspeech", 2019]], "Gabriel Skantze": [0, ["Fundamental Frequency Accommodation in Multi-Party Human-Robot Game Interactions: The Effect of Winning or Losing", ["Omnia Ibrahim", "Gabriel Skantze", "Sabine Stoll", "Volker Dellwo"], "https://doi.org/10.21437/Interspeech.2019-2496", 5, "interspeech", 2019]], "Anna Piunova": [0, ["Rescoring Keyword Search Confidence Estimates with Graph-Based Re-Ranking Using Acoustic Word Embeddings", ["Anna Piunova", "Eugen Beck", "Ralf Schluter", "Hermann Ney"], "https://doi.org/10.21437/Interspeech.2019-1817", 5, "interspeech", 2019]], "Emmanuel Dupoux": [0, ["The Zero Resource Speech Challenge 2019: TTS Without T", ["Ewan Dunbar", "Robin Algayres", "Julien Karadayi", "Mathieu Bernard", "Juan Benjumea", "Xuan-Nga Cao", "Lucie Miskic", "Charlotte Dugrain", "Lucas Ondel", "Alan W. Black", "Laurent Besacier", "Sakriani Sakti", "Emmanuel Dupoux"], "https://doi.org/10.21437/Interspeech.2019-2904", 5, "interspeech", 2019]], "Felicity Cox": [0, ["Articulation of Vowel Length Contrasts in Australian English", ["Louise Ratko", "Michael I. Proctor", "Felicity Cox"], "https://doi.org/10.21437/Interspeech.2019-2995", 5, "interspeech", 2019]], "Quanlei Yan": [0, ["Towards the Speech Features of Mild Cognitive Impairment: Universal Evidence from Structured and Unstructured Connected Speech of Chinese", ["Tianqi Wang", "Chongyuan Lian", "Jingshen Pan", "Quanlei Yan", "Feiqi Zhu", "Manwa L. Ng", "Lan Wang", "Nan Yan"], "https://doi.org/10.21437/Interspeech.2019-2414", 5, "interspeech", 2019], ["Towards the Speech Features of Early-Stage Dementia: Design and Application of the Mandarin Elderly Cognitive Speech Database", ["Tianqi Wang", "Quanlei Yan", "Jingshen Pan", "Feiqi Zhu", "Rongfeng Su", "Yi Guo", "Lan Wang", "Nan Yan"], "https://doi.org/10.21437/Interspeech.2019-2453", 5, "interspeech", 2019]], "Bartosz Borowik": [0, ["Avaya Conversational Intelligence: A Real-Time System for Spoken Language Understanding in Human-Human Call Center Conversations", ["Jan Mizgajski", "Adrian Szymczak", "Robert Glowski", "Piotr Szymanski", "Piotr Zelasko", "Lukasz Augustyniak", "Mikolaj Morzy", "Yishay Carmiel", "Jeff Hodson", "Lukasz Wojciak", "Daniel Smoczyk", "Adam Wrobel", "Bartosz Borowik", "Adam Artajew", "Marcin Baran", "Cezary Kwiatkowski", "Marzena Zyla-Hoppe"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8002.html", 2, "interspeech", 2019]], "Huy Phan": [0, ["A Robust Framework for Acoustic Scene Classification", ["Lam Dang Pham", "Ian Vince McLoughlin", "Huy Phan", "Ramaswamy Palaniappan"], "https://doi.org/10.21437/Interspeech.2019-1841", 5, "interspeech", 2019], ["Spatio-Temporal Attention Pooling for Audio Scene Classification", ["Huy Phan", "Oliver Y. Chen", "Lam Pham", "Philipp Koch", "Maarten De Vos", "Ian Vince McLoughlin", "Alfred Mertins"], "https://doi.org/10.21437/Interspeech.2019-3040", 5, "interspeech", 2019]], "A. Kanagasundaram": [0, ["LEAP Diarization System for the Second DIHARD Challenge", ["Prachi Singh", "Harsha Vardhan", "Sriram Ganapathy", "A. Kanagasundaram"], "https://doi.org/10.21437/Interspeech.2019-2716", 5, "interspeech", 2019]], "Abhinav Garg": [0, ["Improved Vocal Tract Length Perturbation for a State-of-the-Art End-to-End Speech Recognition System", ["Chanwoo Kim", "Minkyu Shin", "Abhinav Garg", "Dhananjaya Gowda"], "https://doi.org/10.21437/Interspeech.2019-3227", 5, "interspeech", 2019], ["Multi-Task Multi-Resolution Char-to-BPE Cross-Attention Decoder for End-to-End Speech Recognition", ["Dhananjaya Gowda", "Abhinav Garg", "Kwangyoun Kim", "Mehul Kumar", "Chanwoo Kim"], "https://doi.org/10.21437/Interspeech.2019-3216", 5, "interspeech", 2019]], "Julien Epps": [0, ["An Adaptive-Q Cochlear Model for Replay Spoofing Detection", ["Tharshini Gunendradasan", "Eliathamby Ambikairajah", "Julien Epps", "Haizhou Li"], "https://doi.org/10.21437/Interspeech.2019-2361", 5, "interspeech", 2019], ["Biologically Inspired Adaptive-Q Filterbanks for Replay Spoofing Attack Detection", ["Buddhi Wickramasinghe", "Eliathamby Ambikairajah", "Julien Epps"], "https://doi.org/10.21437/Interspeech.2019-1535", 5, "interspeech", 2019], ["Direct Modelling of Speech Emotion from Raw Speech", ["Siddique Latif", "Rajib Rana", "Sara Khalifa", "Raja Jurdak", "Julien Epps"], "https://doi.org/10.21437/Interspeech.2019-3252", 5, "interspeech", 2019]], "Shen Huang": [0, ["Multimedia Simultaneous Translation System for Minority Language Communication with Mandarin", ["Shen Huang", "Bojie Hu", "Shan Huang", "Pengfei Hu", "Jian Kang", "Zhiqiang Lv", "Jinghao Yan", "Qi Ju", "Shiyin Kang", "Deyi Tuo", "Guangzhi Li", "Nurmemet Yolwas"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8020.html", 2, "interspeech", 2019]], "Shuai Wang": [2.6364129013245474e-07, ["Bayesian HMM Based x-Vector Clustering for Speaker Diarization", ["Mireia Diez", "Lukas Burget", "Shuai Wang", "Johan Rohdin", "Jan Cernocky"], "https://doi.org/10.21437/Interspeech.2019-2813", 5, "interspeech", 2019], ["The SJTU Robust Anti-Spoofing System for the ASVspoof 2019 Challenge", ["Yexin Yang", "Hongji Wang", "Heinrich Dinkel", "Zhengyang Chen", "Shuai Wang", "Yanmin Qian", "Kai Yu"], "https://doi.org/10.21437/Interspeech.2019-2170", 5, "interspeech", 2019], ["On the Usage of Phonetic Information for Text-Independent Speaker Embedding Extraction", ["Shuai Wang", "Johan Rohdin", "Lukas Burget", "Oldrich Plchot", "Yanmin Qian", "Kai Yu", "Jan Cernocky"], "https://doi.org/10.21437/Interspeech.2019-3036", 5, "interspeech", 2019], ["Data Augmentation Using Variational Autoencoder for Embedding Based Speaker Verification", ["Zhanghao Wu", "Shuai Wang", "Yanmin Qian", "Kai Yu"], "https://doi.org/10.21437/Interspeech.2019-2248", 5, "interspeech", 2019], ["Cross-Domain Replay Spoofing Attack Detection Using Domain Adversarial Training", ["Hongji Wang", "Heinrich Dinkel", "Shuai Wang", "Yanmin Qian", "Kai Yu"], "https://doi.org/10.21437/Interspeech.2019-2120", 5, "interspeech", 2019]], "Robert Lee": [2.4219152074470007e-12, ["Mirroring to Build Trust in Digital Assistants", ["Katherine Metcalf", "Barry-John Theobald", "Garrett Weinberg", "Robert Lee", "Ing-Marie Jonsson", "Russ Webb", "Nicholas Apostoloff"], "https://doi.org/10.21437/Interspeech.2019-1829", 5, "interspeech", 2019]], "Mohammed Salah Al-Radhi": [0, ["Ultrasound-Based Silent Speech Interface Built on a Continuous Vocoder", ["Tamas Gabor Csapo", "Mohammed Salah Al-Radhi", "Geza Nemeth", "Gabor Gosztolya", "Tamas Grosz", "Laszlo Toth", "Alexandra Marko"], "https://doi.org/10.21437/Interspeech.2019-2046", 5, "interspeech", 2019]], "Mathew Magimai-Doss": [0, ["Understanding and Visualizing Raw Waveform-Based CNNs", ["Hannah Muckenhirn", "Vinayak Abrol", "Mathew Magimai-Doss", "Sebastien Marcel"], "https://doi.org/10.21437/Interspeech.2019-2341", 5, "interspeech", 2019], ["Using Speech Production Knowledge for Raw Waveform Modelling Based Styrian Dialect Identification", ["S. Pavankumar Dubagunta", "Mathew Magimai-Doss"], "https://doi.org/10.21437/Interspeech.2019-2398", 5, "interspeech", 2019]], "Dhananjaya Gowda": [0, ["Improved Vocal Tract Length Perturbation for a State-of-the-Art End-to-End Speech Recognition System", ["Chanwoo Kim", "Minkyu Shin", "Abhinav Garg", "Dhananjaya Gowda"], "https://doi.org/10.21437/Interspeech.2019-3227", 5, "interspeech", 2019], ["Multi-Task Multi-Resolution Char-to-BPE Cross-Attention Decoder for End-to-End Speech Recognition", ["Dhananjaya Gowda", "Abhinav Garg", "Kwangyoun Kim", "Mehul Kumar", "Chanwoo Kim"], "https://doi.org/10.21437/Interspeech.2019-3216", 5, "interspeech", 2019]], "Ting Dang": [0, ["Speech Based Emotion Prediction: Can a Linear Model Work?", ["Anda Ouyang", "Ting Dang", "Vidhyasaharan Sethu", "Eliathamby Ambikairajah"], "https://doi.org/10.21437/Interspeech.2019-3149", 5, "interspeech", 2019]], "Sanjeev Kwatra": [0, ["Topical-Chat: Towards Knowledge-Grounded Open-Domain Conversations", ["Karthik Gopalakrishnan", "Behnam Hedayatnia", "Qinglang Chen", "Anna Gottardi", "Sanjeev Kwatra", "Anu Venkatesh", "Raefer Gabriel", "Dilek Hakkani-Tur"], "https://doi.org/10.21437/Interspeech.2019-3079", 5, "interspeech", 2019]], "Sebastian Schnieder": [0, ["The INTERSPEECH 2019 Computational Paralinguistics Challenge: Styrian Dialects, Continuous Sleepiness, Baby Sounds & Orca Activity", ["Bjorn W. Schuller", "Anton Batliner", "Christian Bergler", "Florian B. Pokorny", "Jarek Krajewski", "Margaret Cychosz", "Ralf Vollmann", "Sonja-Dana Roelen", "Sebastian Schnieder", "Elika Bergelson", "Alejandrina Cristia", "Amanda Seidl", "Anne S. Warlaumont", "Lisa Yankowitz", "Elmar Noth", "Shahin Amiriparian", "Simone Hantke", "Maximilian Schmitt"], "https://doi.org/10.21437/Interspeech.2019-1122", 5, "interspeech", 2019]], "Lam Pham": [0, ["Spatio-Temporal Attention Pooling for Audio Scene Classification", ["Huy Phan", "Oliver Y. Chen", "Lam Pham", "Philipp Koch", "Maarten De Vos", "Ian Vince McLoughlin", "Alfred Mertins"], "https://doi.org/10.21437/Interspeech.2019-3040", 5, "interspeech", 2019]], "Md Asif Jalal": [0, ["Learning Temporal Clusters Using Capsule Routing for Speech Emotion Recognition", ["Md Asif Jalal", "Erfan Loweimi", "Roger K. Moore", "Thomas Hain"], "https://doi.org/10.21437/Interspeech.2019-3068", 5, "interspeech", 2019]], "Philipp Klumpp": [0, ["Phonet: A Tool Based on Gated Recurrent Neural Networks to Extract Phonological Posteriors from Speech", ["Juan Camilo Vasquez-Correa", "Philipp Klumpp", "Juan Rafael Orozco-Arroyave", "Elmar Noth"], "https://doi.org/10.21437/Interspeech.2019-1405", 5, "interspeech", 2019], ["Apkinson: A Mobile Solution for Multimodal Assessment of Patients with Parkinson's Disease", ["Juan Camilo Vasquez-Correa", "Tomas Arias-Vergara", "Philipp Klumpp", "M. Strauss", "Arne Kuderle", "Nils Roth", "S. Bayerl", "Nicanor Garcia-Ospina", "Paula Andrea Perez-Toro", "L. Felipe Parra-Gallego", "Cristian David Rios-Urrego", "D. Escobar-Grisales", "Juan Rafael Orozco-Arroyave", "Bjorn Eskofier", "Elmar Noth"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8003.html", 2, "interspeech", 2019], ["Feature Space Visualization with Spatial Similarity Maps for Pathological Speech Data", ["Philipp Klumpp", "Juan Camilo Vasquez-Correa", "Tino Haderlein", "Elmar Noth"], "https://doi.org/10.21437/Interspeech.2019-2080", 5, "interspeech", 2019]], "Andreas Seiderer": [0, ["Relevance-Based Feature Masking: Improving Neural Network Based Whale Classification Through Explainable Artificial Intelligence", ["Dominik Schiller", "Tobias Huber", "Florian Lingenfelser", "Michael Dietz", "Andreas Seiderer", "Elisabeth Andre"], "https://doi.org/10.21437/Interspeech.2019-2707", 5, "interspeech", 2019]], "Lisa Gustavsson": [0, ["No Distributional Learning in Adults from Attended Listening to Non-Speech", ["Ellen Marklund", "Johan Sjons", "Lisa Gustavsson", "Elisabet Eir Cortes"], "https://doi.org/10.21437/Interspeech.2019-1674", 5, "interspeech", 2019]], "William Chan": [0, ["SpecAugment: A Simple Data Augmentation Method for Automatic Speech Recognition", ["Daniel S. Park", "William Chan", "Yu Zhang", "Chung-Cheng Chiu", "Barret Zoph", "Ekin D. Cubuk", "Quoc V. Le"], "https://doi.org/10.21437/Interspeech.2019-2680", 5, "interspeech", 2019]], "Catherine Robinson": [0, ["R2SPIN: Re-Recording the Revised Speech Perception in Noise Test", ["Lauren Ward", "Catherine Robinson", "Matthew Paradis", "Katherine M. Tucker", "Ben G. Shirley"], "https://doi.org/10.21437/Interspeech.2019-1281", 5, "interspeech", 2019]], "Boris Ginsburg": [0, ["Jasper: An End-to-End Convolutional Neural Acoustic Model", ["Jason Li", "Vitaly Lavrukhin", "Boris Ginsburg", "Ryan Leary", "Oleksii Kuchaiev", "Jonathan M. Cohen", "Huyen Nguyen", "Ravi Teja Gadde"], "https://doi.org/10.21437/Interspeech.2019-1819", 5, "interspeech", 2019]], "Irena Yanushevskaya": [0, ["The Role of Voice Quality in the Perception of Prominence in Synthetic Speech", ["Andy Murphy", "Irena Yanushevskaya", "Ailbhe Ni Chasaide", "Christer Gobl"], "https://doi.org/10.21437/Interspeech.2019-2761", 5, "interspeech", 2019]], "Colleen Richey": [0, ["The VOiCES from a Distance Challenge 2019", ["Mahesh Kumar Nandwana", "Julien van Hout", "Colleen Richey", "Mitchell McLaren", "Maria Auxiliadora Barrios", "Aaron Lawson"], "https://doi.org/10.21437/Interspeech.2019-1837", 5, "interspeech", 2019], ["The VOiCES from a Distance Challenge 2019", ["Mahesh Kumar Nandwana", "Julien van Hout", "Colleen Richey", "Mitchell McLaren", "Maria Alejandra Barrios", "Aaron Lawson"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/abs14.html", 0, "interspeech", 2019]], "Rahul Prasad": [0, ["Neural Network Distillation on IoT Platforms for Sound Event Detection", ["Gianmarco Cerutti", "Rahul Prasad", "Alessio Brutti", "Elisabetta Farella"], "https://doi.org/10.21437/Interspeech.2019-2394", 5, "interspeech", 2019]], "Valer Kaszas": [0, ["Assessing the Semantic Space Bias Caused by ASR Error Propagation and its Effect on Spoken Document Summarization", ["Mate Akos Tundik", "Valer Kaszas", "Gyorgy Szaszak"], "https://doi.org/10.21437/Interspeech.2019-2154", 5, "interspeech", 2019]], "Nicolas Hernandez": [0, ["Qualitative Evaluation of ASR Adaptation in a Lecture Context: Application to the PASTEL Corpus", ["Salima Mdhaffar", "Yannick Esteve", "Nicolas Hernandez", "Antoine Laurent", "Richard Dufour", "Solen Quiniou"], "https://doi.org/10.21437/Interspeech.2019-2661", 5, "interspeech", 2019]], "Ahmed Ali": [0, ["Analyzing Phonetic and Graphemic Representations in End-to-End Automatic Speech Recognition", ["Yonatan Belinkov", "Ahmed Ali", "James R. Glass"], "https://doi.org/10.21437/Interspeech.2019-2599", 5, "interspeech", 2019], ["Towards Variability Resistant Dialectal Speech Evaluation", ["Ahmed Ali", "Salam Khalifa", "Nizar Habash"], "https://doi.org/10.21437/Interspeech.2019-2692", 5, "interspeech", 2019], ["Predicting the Leading Political Ideology of YouTube Channels Using Acoustic, Textual, and Metadata Information", ["Yoan Dinkov", "Ahmed Ali", "Ivan Koychev", "Preslav Nakov"], "https://doi.org/10.21437/Interspeech.2019-2965", 5, "interspeech", 2019], ["FarSpeech: Arabic Natural Language Processing for Live Arabic Speech", ["Mohamed Eldesouki", "Naassih Gopee", "Ahmed Ali", "Kareem Darwish"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8030.html", 2, "interspeech", 2019]], "Beatrice Alex": [0, ["Detecting Topic-Oriented Speaker Stance in Conversational Speech", ["Catherine Lai", "Beatrice Alex", "Johanna D. Moore", "Leimin Tian", "Tatsuro Hori", "Gianpiero Francesca"], "https://doi.org/10.21437/Interspeech.2019-2632", 5, "interspeech", 2019]], "Heidi Christensen": [0, ["Automatic Hierarchical Attention Neural Network for Detecting AD", ["Yilin Pan", "Bahman Mirheidari", "Markus Reuber", "Annalena Venneri", "Daniel Blackburn", "Heidi Christensen"], "https://doi.org/10.21437/Interspeech.2019-1799", 5, "interspeech", 2019]], "Ryandhimas E. Zezario": [0, ["Specialized Speech Enhancement Model Selection Based on Learned Non-Intrusive Quality Assessment Metric", ["Ryandhimas E. Zezario", "Szu-Wei Fu", "Xugang Lu", "Hsin-Min Wang", "Yu Tsao"], "https://doi.org/10.21437/Interspeech.2019-2425", 5, "interspeech", 2019]], "Hao Sun": [0.05930156260728836, ["Token-Level Ensemble Distillation for Grapheme-to-Phoneme Conversion", ["Hao Sun", "Xu Tan", "Jun-Wei Gan", "Hongzhi Liu", "Sheng Zhao", "Tao Qin", "Tie-Yan Liu"], "https://doi.org/10.21437/Interspeech.2019-1208", 5, "interspeech", 2019]], "Berrak Sisman": [0, ["VQVAE Unsupervised Unit Discovery and Multi-Scale Code2Spec Inverter for Zerospeech Challenge 2019", ["Andros Tjandra", "Berrak Sisman", "Mingyang Zhang", "Sakriani Sakti", "Haizhou Li", "Satoshi Nakamura"], "https://doi.org/10.21437/Interspeech.2019-3232", 5, "interspeech", 2019]], "Victor Ardulov": [0, ["Identifying Therapist and Client Personae for Therapeutic Alliance Estimation", ["Victor R. Martinez", "Nikolaos Flemotomos", "Victor Ardulov", "Krishna Somandepalli", "Simon B. Goldberg", "Zac E. Imel", "David C. Atkins", "Shrikanth Narayanan"], "https://doi.org/10.21437/Interspeech.2019-2829", 5, "interspeech", 2019]], "Rajeev Rajan": [0, ["Design and Development of a Multi-Lingual Speech Corpora (TaMaR-EmoDB) for Emotion Analysis", ["Rajeev Rajan", "Haritha U. G.", "Sujitha A. C.", "Rejisha T. M."], "https://doi.org/10.21437/Interspeech.2019-2034", 5, "interspeech", 2019]], "Thai-Son Nguyen": [0, ["Very Deep Self-Attention Networks for End-to-End Speech Recognition", ["Ngoc-Quan Pham", "Thai-Son Nguyen", "Jan Niehues", "Markus Muller", "Alex Waibel"], "https://doi.org/10.21437/Interspeech.2019-2702", 5, "interspeech", 2019]], "Jean-Francois Bonastre": [0, ["Effects of Waveform PMF on Anti-Spoofing Detection", ["Itshak Lapidot", "Jean-Francois Bonastre"], "https://doi.org/10.21437/Interspeech.2019-2607", 5, "interspeech", 2019]], "Daniele Giacobello": [0, ["Exploiting Multi-Channel Speech Presence Probability in Parametric Multi-Channel Wiener Filter", ["Saeed Bagheri", "Daniele Giacobello"], "https://doi.org/10.21437/Interspeech.2019-2665", 5, "interspeech", 2019]], "Parvaneh Janbakhshi": [0, ["Spectral Subspace Analysis for Automatic Assessment of Pathological Speech Intelligibility", ["Parvaneh Janbakhshi", "Ina Kodrasi", "Herve Bourlard"], "https://doi.org/10.21437/Interspeech.2019-2791", 5, "interspeech", 2019]], "Eva Szekely": [0, ["Off the Cuff: Exploring Extemporaneous Speech Delivery with TTS", ["Eva Szekely", "Gustav Eje Henter", "Jonas Beskow", "Joakim Gustafson"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8026.html", 2, "interspeech", 2019], ["The Greennn Tree - Lengthening Position Influences Uncertainty Perception", ["Simon Betz", "Sina Zarriess", "Eva Szekely", "Petra Wagner"], "https://doi.org/10.21437/Interspeech.2019-2572", 5, "interspeech", 2019], ["Spontaneous Conversational Speech Synthesis from Found Data", ["Eva Szekely", "Gustav Eje Henter", "Jonas Beskow", "Joakim Gustafson"], "https://doi.org/10.21437/Interspeech.2019-2836", 5, "interspeech", 2019]], "Nadee Seneviratne": [0, ["Multi-Corpus Acoustic-to-Articulatory Speech Inversion", ["Nadee Seneviratne", "Ganesh Sivaraman", "Carol Y. Espy-Wilson"], "https://doi.org/10.21437/Interspeech.2019-3168", 5, "interspeech", 2019], ["Assessing Neuromotor Coordination in Depression Using Inverted Vocal Tract Variables", ["Carol Y. Espy-Wilson", "Adam C. Lammert", "Nadee Seneviratne", "Thomas F. Quatieri"], "https://doi.org/10.21437/Interspeech.2019-1815", 5, "interspeech", 2019], ["Multi-Modal Learning for Speech Emotion Recognition: An Analysis and Comparison of ASR Outputs with Ground Truth Transcription", ["Saurabh Sahu", "Vikramjit Mitra", "Nadee Seneviratne", "Carol Y. Espy-Wilson"], "https://doi.org/10.21437/Interspeech.2019-1149", 5, "interspeech", 2019]], "Yin-Chun Tsai": [0, ["Using Attention Networks and Adversarial Augmentation for Styrian Dialect Continuous Sleepiness and Baby Sound Recognition", ["Sung-Lin Yeh", "Gao-Yi Chao", "Bo-Hao Su", "Yu-Lin Huang", "Meng-Han Lin", "Yin-Chun Tsai", "Yu-Wen Tai", "Zheng-Chi Lu", "Chieh-Yu Chen", "Tsung-Ming Tai", "Chiu-Wang Tseng", "Cheng-Kuang Lee", "Chi-Chun Lee"], "https://doi.org/10.21437/Interspeech.2019-2110", 5, "interspeech", 2019]], "Junho Park": [0.6315406113862991, ["Deep Learning Based Mandarin Accent Identification for Accent Robust ASR", ["Felix Weninger", "Yang Sun", "Junho Park", "Daniel Willett", "Puming Zhan"], "https://doi.org/10.21437/Interspeech.2019-2737", 5, "interspeech", 2019]], "Janaki Sheth": [0, ["Identifying Input Features for Development of Real-Time Translation of Neural Signals to Text", ["Janaki Sheth", "Ariel Tankus", "Michelle Tran", "Lindy Comstock", "Itzhak Fried", "William Speier"], "https://doi.org/10.21437/Interspeech.2019-3092", 5, "interspeech", 2019]], "Mortaza Doulaty": [0, ["Latent Dirichlet Allocation Based Acoustic Data Selection for Automatic Speech Recognition", ["Mortaza Doulaty", "Thomas Hain"], "https://doi.org/10.21437/Interspeech.2019-1797", 5, "interspeech", 2019]], "Karen Livescu": [0, ["On the Contributions of Visual and Textual Supervision in Low-Resource Semantic Speech Retrieval", ["Ankita Pasad", "Bowen Shi", "Herman Kamper", "Karen Livescu"], "https://doi.org/10.21437/Interspeech.2019-3051", 5, "interspeech", 2019], ["Pre-Trained Text Embeddings for Enhanced Text-to-Speech Synthesis", ["Tomoki Hayashi", "Shinji Watanabe", "Tomoki Toda", "Kazuya Takeda", "Shubham Toshniwal", "Karen Livescu"], "https://doi.org/10.21437/Interspeech.2019-3177", 5, "interspeech", 2019]], "Natalie Lewandowski": [0, ["Individual Differences in Implicit Attention to Phonetic Detail in Speech Perception", ["Natalie Lewandowski", "Daniel Duran"], "https://doi.org/10.21437/Interspeech.2019-2989", 5, "interspeech", 2019]], "Hugo Van hamme": [0, ["Practical Applicability of Deep Neural Networks for Overlapping Speaker Separation", ["Pieter Appeltans", "Jeroen Zegers", "Hugo Van hamme"], "https://doi.org/10.21437/Interspeech.2019-1807", 5, "interspeech", 2019], ["CNN-LSTM Models for Multi-Speaker Source Separation Using Bayesian Hyper Parameter Optimization", ["Jeroen Zegers", "Hugo Van hamme"], "https://doi.org/10.21437/Interspeech.2019-2423", 5, "interspeech", 2019]], "Catherine Jasserand": [0, ["The GDPR & Speech Data: Reflections of Legal and Technology Communities, First Steps Towards a Common Understanding", ["Andreas Nautsch", "Catherine Jasserand", "Els Kindt", "Massimiliano Todisco", "Isabel Trancoso", "Nicholas W. D. Evans"], "https://doi.org/10.21437/Interspeech.2019-2647", 5, "interspeech", 2019]], "Jongmo Sung": [0.9080194979906082, ["Cascaded Cross-Module Residual Learning Towards Lightweight End-to-End Speech Coding", ["Kai Zhen", "Jongmo Sung", "Mi Suk Lee", "Seungkwon Beack", "Minje Kim"], "https://doi.org/10.21437/Interspeech.2019-1816", 5, "interspeech", 2019]], "Hari Krishna Vydana": [0, ["Bayesian Subspace Hidden Markov Model for Acoustic Unit Discovery", ["Lucas Ondel", "Hari Krishna Vydana", "Lukas Burget", "Jan Cernocky"], "https://doi.org/10.21437/Interspeech.2019-2224", 5, "interspeech", 2019]], "Maulik C. Madhavi": [0, ["A Unified Framework for Speaker and Utterance Verification", ["Tianchi Liu", "Maulik C. Madhavi", "Rohan Kumar Das", "Haizhou Li"], "https://doi.org/10.21437/Interspeech.2019-1994", 5, "interspeech", 2019]], "Michael Neumann": [0, ["CycleGAN-Based Emotion Style Transfer as Data Augmentation for Speech Emotion Recognition", ["Fang Bao", "Michael Neumann", "Ngoc Thang Vu"], "https://doi.org/10.21437/Interspeech.2019-2293", 5, "interspeech", 2019]], "David B. Ramsay": [0, ["Low-Dimensional Bottleneck Features for On-Device Continuous Speech Recognition", ["David B. Ramsay", "Kevin Kilgour", "Dominik Roblek", "Matthew Sharifi"], "https://doi.org/10.21437/Interspeech.2019-2193", 4, "interspeech", 2019]], "Chiranjeevi Yarra": [0, ["ASR Inspired Syllable Stress Detection for Pronunciation Evaluation Without Using a Supervised Classifier and Syllable Level Features", ["Manoj Kumar Ramanathi", "Chiranjeevi Yarra", "Prasanta Kumar Ghosh"], "https://doi.org/10.21437/Interspeech.2019-2091", 5, "interspeech", 2019], ["An Improved Goodness of Pronunciation (GoP) Measure for Pronunciation Evaluation with DNN-HMM System Considering HMM Transition Probabilities", ["Sweekar Sudhakara", "Manoj Kumar Ramanathi", "Chiranjeevi Yarra", "Prasanta Kumar Ghosh"], "https://doi.org/10.21437/Interspeech.2019-2363", 5, "interspeech", 2019], ["Low Resource Automatic Intonation Classification Using Gated Recurrent Unit (GRU) Networks Pre-Trained with Synthesized Pitch Patterns", ["Atreyee Saha", "Chiranjeevi Yarra", "Prasanta Kumar Ghosh"], "https://doi.org/10.21437/Interspeech.2019-2351", 5, "interspeech", 2019], ["SPIRE-fluent: A Self-Learning App for Tutoring Oral Fluency to Second Language English Learners", ["Chiranjeevi Yarra", "Aparna Srinivasan", "Sravani Gottimukkala", "Prasanta Kumar Ghosh"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8008.html", 2, "interspeech", 2019]], "Alex Mayle": [0, ["Diagnosing Dysarthria with Long Short-Term Memory Networks", ["Alex Mayle", "Zhiwei Mou", "Razvan C. Bunescu", "Sadegh Mirshekarian", "Li Xu", "Chang Liu"], "https://doi.org/10.21437/Interspeech.2019-2903", 5, "interspeech", 2019]], "Philipp Aichinger": [0, ["Aerodynamics and Lumped-Masses Combined with Delay Lines for Modeling Vertical and Anterior-Posterior Phase Differences in Pathological Vocal Fold Vibration", ["Carlo Drioli", "Philipp Aichinger"], "https://doi.org/10.21437/Interspeech.2019-2338", 5, "interspeech", 2019], ["Analysis and Synthesis of Vocal Flutter and Vocal Jitter", ["Jean Schoentgen", "Philipp Aichinger"], "https://doi.org/10.21437/Interspeech.2019-1998", 5, "interspeech", 2019]], "Mikhail Belkin": [0, ["Kernel Machines Beat Deep Neural Networks on Mask-Based Single-Channel Speech Enhancement", ["Like Hui", "Siyuan Ma", "Mikhail Belkin"], "https://doi.org/10.21437/Interspeech.2019-1344", 5, "interspeech", 2019]], "Sangwook Park": [0.9990171939134598, ["A Study of a Cross-Language Perception Based on Cortical Analysis Using Biomimetic STRFs", ["Sangwook Park", "David K. Han", "Mounya Elhilali"], "https://doi.org/10.21437/Interspeech.2019-2507", 5, "interspeech", 2019]], "Matthew Wiesner": [0, ["Analysis of Multilingual Sequence-to-Sequence Speech Recognition Systems", ["Martin Karafiat", "Murali Karthick Baskar", "Shinji Watanabe", "Takaaki Hori", "Matthew Wiesner", "Jan Cernocky"], "https://doi.org/10.21437/Interspeech.2019-2355", 5, "interspeech", 2019], ["Pretraining by Backtranslation for End-to-End ASR in Low-Resource Settings", ["Matthew Wiesner", "Adithya Renduchintala", "Shinji Watanabe", "Chunxi Liu", "Najim Dehak", "Sanjeev Khudanpur"], "https://doi.org/10.21437/Interspeech.2019-3254", 5, "interspeech", 2019]], "Denis Filimonov": [0, ["Scalable Multi Corpora Neural Language Models for ASR", ["Anirudh Raju", "Denis Filimonov", "Gautam Tiwari", "Guitang Lan", "Ariya Rastrow"], "https://doi.org/10.21437/Interspeech.2019-3060", 5, "interspeech", 2019]], "Martin Kersner": [0, ["Temporal Convolution for Real-Time Keyword Spotting on Mobile Devices", ["Seungwoo Choi", "Seokjun Seo", "Beomjun Shin", "Hyeongmin Byun", "Martin Kersner", "Beomsu Kim", "Dongyoung Kim", "Sungjoo Ha"], "https://doi.org/10.21437/Interspeech.2019-1363", 5, "interspeech", 2019]], "Anqi Xu": [0, ["Sentence Prosody and Wh-Indeterminates in Taiwan Mandarin", ["Yu-Yin Hsu", "Anqi Xu"], "https://doi.org/10.21437/Interspeech.2019-2545", 5, "interspeech", 2019]], "Hideki Kawahara": [0, ["Investigating the Physiological and Acoustic Contrasts Between Choral and Operatic Singing", ["Hiroko Terasawa", "Kenta Wakasa", "Hideki Kawahara", "Ken-Ichi Sakakibara"], "https://doi.org/10.21437/Interspeech.2019-1864", 5, "interspeech", 2019]], "Rupayan Chakraborty": [0, ["Front-End Feature Compensation and Denoising for Noise Robust Speech Emotion Recognition", ["Rupayan Chakraborty", "Ashish Panda", "Meghna Pandharipande", "Sonal Joshi", "Sunil Kumar Kopparapu"], "https://doi.org/10.21437/Interspeech.2019-2243", 5, "interspeech", 2019]], "Hyung Yong Kim": [0.8755508661270142, ["End-to-End Multi-Channel Speech Enhancement Using Inter-Channel Time-Restricted Attention on Raw Waveform", ["Hyeon Seung Lee", "Hyung Yong Kim", "Woo Hyun Kang", "Jeunghun Kim", "Nam Soo Kim"], "https://doi.org/10.21437/Interspeech.2019-2397", 5, "interspeech", 2019]], "Jia Xin Koh": [1.8766590947905115e-08, ["Building the Singapore English National Speech Corpus", ["Jia Xin Koh", "Aqilah Mislan", "Kevin Khoo", "Brian Ang", "Wilson Ang", "Charmaine Ng", "Ying-Ying Tan"], "https://doi.org/10.21437/Interspeech.2019-1525", 5, "interspeech", 2019]], "Yun Lei": [0, ["Towards a Fault-Tolerant Speaker Verification System: A Regularization Approach to Reduce the Condition Number", ["Siqi Zheng", "Gang Liu", "Hongbin Suo", "Yun Lei"], "https://doi.org/10.21437/Interspeech.2019-1442", 5, "interspeech", 2019], ["Autoencoder-Based Semi-Supervised Curriculum Learning for Out-of-Domain Speaker Verification", ["Siqi Zheng", "Gang Liu", "Hongbin Suo", "Yun Lei"], "https://doi.org/10.21437/Interspeech.2019-1440", 5, "interspeech", 2019]], "Cheng-Kuang Lee": [3.4297721995812935e-08, ["Using Attention Networks and Adversarial Augmentation for Styrian Dialect Continuous Sleepiness and Baby Sound Recognition", ["Sung-Lin Yeh", "Gao-Yi Chao", "Bo-Hao Su", "Yu-Lin Huang", "Meng-Han Lin", "Yin-Chun Tsai", "Yu-Wen Tai", "Zheng-Chi Lu", "Chieh-Yu Chen", "Tsung-Ming Tai", "Chiu-Wang Tseng", "Cheng-Kuang Lee", "Chi-Chun Lee"], "https://doi.org/10.21437/Interspeech.2019-2110", 5, "interspeech", 2019]], "Kohei Hara": [0, ["Turn-Taking Prediction Based on Detection of Transition Relevance Place", ["Kohei Hara", "Koji Inoue", "Katsuya Takanashi", "Tatsuya Kawahara"], "https://doi.org/10.21437/Interspeech.2019-1537", 5, "interspeech", 2019]], "Rohit Sinha": [0, ["SpeechMarker: A Voice Based Multi-Level Attendance Application", ["Sarfaraz Jelil", "Abhishek Shrivastava", "Rohan Kumar Das", "S. R. Mahadeva Prasanna", "Rohit Sinha"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8014.html", 2, "interspeech", 2019]], "Wikus Pienaar": [0, ["Online Speech Processing and Analysis Suite", ["Wikus Pienaar", "Daan Wissing"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8007.html", 2, "interspeech", 2019]], "Zhongfu Ye": [9.416424306962767e-09, ["Acoustic Model Ensembling Using Effective Data Augmentation for CHiME-5 Challenge", ["Feng Ma", "Li Chai", "Jun Du", "Diyuan Liu", "Zhongfu Ye", "Chin-Hui Lee"], "https://doi.org/10.21437/Interspeech.2019-2601", 5, "interspeech", 2019]], "Patricia Thaine": [0, ["Extracting Mel-Frequency and Bark-Frequency Cepstral Coefficients from Encrypted Signals", ["Patricia Thaine", "Gerald Penn"], "https://doi.org/10.21437/Interspeech.2019-1136", 5, "interspeech", 2019]], "Nikos Bampounis": [0, ["Unified Verbalization for Speech Recognition & Synthesis Across Languages", ["Sandy Ritchie", "Richard Sproat", "Kyle Gorman", "Daan van Esch", "Christian Schallhart", "Nikos Bampounis", "Benoit Brard", "Jonas Fromseier Mortensen", "Millie Holt", "Eoin Mahon"], "https://doi.org/10.21437/Interspeech.2019-2807", 5, "interspeech", 2019]], "Xueliang Zhang": [0, ["Investigation of Cost Function for Supervised Monaural Speech Separation", ["Yun Liu", "Hui Zhang", "Xueliang Zhang", "Yuhang Cao"], "https://doi.org/10.21437/Interspeech.2019-1897", 5, "interspeech", 2019]], "Nirmesh J. Shah": [0, ["Phone Aware Nearest Neighbor Technique Using Spectral Transition Measure for Non-Parallel Voice Conversion", ["Nirmesh J. Shah", "Hemant A. Patil"], "https://doi.org/10.21437/Interspeech.2019-1504", 5, "interspeech", 2019], ["Whether to Pretrain DNN or not?: An Empirical Analysis for Voice Conversion", ["Nirmesh J. Shah", "Hardik B. Sailor", "Hemant A. Patil"], "https://doi.org/10.21437/Interspeech.2019-2608", 5, "interspeech", 2019]], "Xixin Wu": [1.2604690624584691e-08, ["Jointly Trained Conversion Model and WaveNet Vocoder for Non-Parallel Voice Conversion Using Mel-Spectrograms and Phonetic Posteriorgrams", ["Songxiang Liu", "Yuewen Cao", "Xixin Wu", "Lifa Sun", "Xunying Liu", "Helen Meng"], "https://doi.org/10.21437/Interspeech.2019-1316", 5, "interspeech", 2019], ["Disambiguation of Chinese Polyphones in an End-to-End Framework with Semantic Features Extracted by Pre-Trained BERT", ["Dongyang Dai", "Zhiyong Wu", "Shiyin Kang", "Xixin Wu", "Jia Jia", "Dan Su", "Dong Yu", "Helen Meng"], "https://doi.org/10.21437/Interspeech.2019-2292", 5, "interspeech", 2019], ["LF-MMI Training of Bayesian and Gaussian Process Time Delay Neural Networks for Speech Recognition", ["Shoukang Hu", "Xurong Xie", "Shansong Liu", "Max W. Y. Lam", "Jianwei Yu", "Xixin Wu", "Xunying Liu", "Helen Meng"], "https://doi.org/10.21437/Interspeech.2019-2379", 5, "interspeech", 2019], ["Unsupervised Methods for Audio Classification from Lecture Discussion Recordings", ["Hang Su", "Borislav Dzodzo", "Xixin Wu", "Xunying Liu", "Helen Meng"], "https://doi.org/10.21437/Interspeech.2019-2384", 5, "interspeech", 2019], ["Comparative Study of Parametric and Representation Uncertainty Modeling for Recurrent Neural Network Language Models", ["Jianwei Yu", "Max W. Y. Lam", "Shoukang Hu", "Xixin Wu", "Xu Li", "Yuewen Cao", "Xunying Liu", "Helen Meng"], "https://doi.org/10.21437/Interspeech.2019-1927", 5, "interspeech", 2019]], "Antoine Deleforge": [0, ["A Statistically Principled and Computationally Efficient Approach to Speech Enhancement Using Variational Autoencoders", ["Manuel Pariente", "Antoine Deleforge", "Emmanuel Vincent"], "https://doi.org/10.21437/Interspeech.2019-1398", 5, "interspeech", 2019]], "Carlo Drioli": [0, ["Aerodynamics and Lumped-Masses Combined with Delay Lines for Modeling Vertical and Anterior-Posterior Phase Differences in Pathological Vocal Fold Vibration", ["Carlo Drioli", "Philipp Aichinger"], "https://doi.org/10.21437/Interspeech.2019-2338", 5, "interspeech", 2019], ["End-to-End Speaker Identification in Noisy and Reverberant Environments Using Raw Waveform Convolutional Neural Networks", ["Daniele Salvati", "Carlo Drioli", "Gian Luca Foresti"], "https://doi.org/10.21437/Interspeech.2019-2403", 5, "interspeech", 2019]], "Hitoshi Aoki": [0, ["Extending the E-Model Towards Super-Wideband and Fullband Speech Communication Scenarios", ["Sebastian Moller", "Gabriel Mittag", "Thilo Michael", "Vincent Barriac", "Hitoshi Aoki"], "https://doi.org/10.21437/Interspeech.2019-1340", 5, "interspeech", 2019]], "Michele Gubian": [0, ["Tracking the New Zealand English NEAR/SQUARE Merger Using Functional Principal Components Analysis", ["Michele Gubian", "Jonathan Harrington", "Mary Stevens", "Florian Schiel", "Paul Warren"], "https://doi.org/10.21437/Interspeech.2019-2115", 5, "interspeech", 2019], ["Zooming in on Spatiotemporal V-to-C Coarticulation with Functional PCA", ["Michele Gubian", "Manfred Pastatter", "Marianne Pouplier"], "https://doi.org/10.21437/Interspeech.2019-2143", 5, "interspeech", 2019]], "Wiebke Ahlers": [0, ["Sibilant Variation in New Englishes: A Comparative Sociophonetic Study of Trinidadian and American English /s(tr)/-Retraction", ["Wiebke Ahlers", "Philipp Meer"], "https://doi.org/10.21437/Interspeech.2019-1821", 5, "interspeech", 2019]], "Nelly Barbot": [0, ["Corpus Design Using Convolutional Auto-Encoder Embeddings for Audio-Book Synthesis", ["Meysam Shamsi", "Damien Lolive", "Nelly Barbot", "Jonathan Chevelu"], "https://doi.org/10.21437/Interspeech.2019-2190", 5, "interspeech", 2019]], "Qiuying Shi": [0, ["Subspace Pooling Based Temporal Features Extraction for Audio Event Recognition", ["Qiuying Shi", "Hui Luo", "Jiqing Han"], "https://doi.org/10.21437/Interspeech.2019-2047", 5, "interspeech", 2019]], "Ruchao Fan": [0, ["An Online Attention-Based Model for Speech Recognition", ["Ruchao Fan", "Pan Zhou", "Wei Chen", "Jia Jia", "Gang Liu"], "https://doi.org/10.21437/Interspeech.2019-2218", 5, "interspeech", 2019]], "Jian Huang": [0, ["Conversational Emotion Analysis via Attention Mechanisms", ["Zheng Lian", "Jianhua Tao", "Bin Liu", "Jian Huang"], "https://doi.org/10.21437/Interspeech.2019-1577", 5, "interspeech", 2019], ["Unsupervised Representation Learning with Future Observation Prediction for Speech Emotion Recognition", ["Zheng Lian", "Jianhua Tao", "Bin Liu", "Jian Huang"], "https://doi.org/10.21437/Interspeech.2019-1582", 5, "interspeech", 2019]], "Oleg Petrov": [0, ["R-Vectors: New Technique for Adaptation to Room Acoustics", ["Yuri Y. Khokhlov", "Alexander Zatvornitskiy", "Ivan Medennikov", "Ivan Sorokin", "Tatiana Prisyach", "Aleksei Romanenko", "Anton Mitrofanov", "Vladimir Bataev", "Andrei Andrusenko", "Mariya Korenevskaya", "Oleg Petrov"], "https://doi.org/10.21437/Interspeech.2019-2645", 5, "interspeech", 2019], ["The STC ASR System for the VOiCES from a Distance Challenge 2019", ["Ivan Medennikov", "Yuri Y. Khokhlov", "Aleksei Romanenko", "Ivan Sorokin", "Anton Mitrofanov", "Vladimir Bataev", "Andrei Andrusenko", "Tatiana Prisyach", "Mariya Korenevskaya", "Oleg Petrov", "Alexander Zatvornitskiy"], "https://doi.org/10.21437/Interspeech.2019-1574", 5, "interspeech", 2019], ["The STC ASR System for the VOiCES from a Distance Challenge 2019", ["Ivan Medennikov", "Yuri Y. Khokhlov", "Aleksei Romanenko", "Ivan Sorokin", "Anton Mitrofanov", "Vladimir Bataev", "Andrei Andrusenko", "Tatiana Prisyach", "Mariya Korenevskaya", "Oleg Petrov", "Alexander Zatvornitskiy"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/abs17.html", 0, "interspeech", 2019]], "Julien van Hout": [0, ["The VOiCES from a Distance Challenge 2019", ["Mahesh Kumar Nandwana", "Julien van Hout", "Colleen Richey", "Mitchell McLaren", "Maria Auxiliadora Barrios", "Aaron Lawson"], "https://doi.org/10.21437/Interspeech.2019-1837", 5, "interspeech", 2019], ["The VOiCES from a Distance Challenge 2019", ["Mahesh Kumar Nandwana", "Julien van Hout", "Colleen Richey", "Mitchell McLaren", "Maria Alejandra Barrios", "Aaron Lawson"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/abs14.html", 0, "interspeech", 2019]], "Daan van Esch": [0, ["Building Large-Vocabulary ASR Systems for Languages Without Any Audio Training Data", ["Manasa Prasad", "Daan van Esch", "Sandy Ritchie", "Jonas Fromseier Mortensen"], "https://doi.org/10.21437/Interspeech.2019-1775", 5, "interspeech", 2019], ["Developing Pronunciation Models in New Languages Faster by Exploiting Common Grapheme-to-Phoneme Correspondences Across Languages", ["Harry Bleyan", "Sandy Ritchie", "Jonas Fromseier Mortensen", "Daan van Esch"], "https://doi.org/10.21437/Interspeech.2019-1781", 5, "interspeech", 2019], ["Unified Verbalization for Speech Recognition & Synthesis Across Languages", ["Sandy Ritchie", "Richard Sproat", "Kyle Gorman", "Daan van Esch", "Christian Schallhart", "Nikos Bampounis", "Benoit Brard", "Jonas Fromseier Mortensen", "Millie Holt", "Eoin Mahon"], "https://doi.org/10.21437/Interspeech.2019-2807", 5, "interspeech", 2019]], "Sriram Srinivasan": [0, ["A Scalable Noisy Speech Dataset and Online Subjective Test Framework", ["Chandan K. A. Reddy", "Ebrahim Beyrami", "Jamie Pool", "Ross Cutler", "Sriram Srinivasan", "Johannes Gehrke"], "https://doi.org/10.21437/Interspeech.2019-3087", 5, "interspeech", 2019]], "Dilip Kumar Margam": [0, ["Real Time Online Visual End Point Detection Using Unidirectional LSTM", ["Tanay Sharma", "Rohith Chandrashekar Aralikatti", "Dilip Kumar Margam", "Abhinav Thanda", "Sharad Roy", "Pujitha Appan Kandala", "Shankar M. Venkatesan"], "https://doi.org/10.21437/Interspeech.2019-3253", 5, "interspeech", 2019], ["Speaker Adaptation for Lip-Reading Using Visual Identity Vectors", ["Pujitha Appan Kandala", "Abhinav Thanda", "Dilip Kumar Margam", "Rohith Chandrashekar Aralikatti", "Tanay Sharma", "Sharad Roy", "Shankar M. Venkatesan"], "https://doi.org/10.21437/Interspeech.2019-3237", 5, "interspeech", 2019]], "Heike Schoormann": [0, ["Towards the Prosody of Persuasion in Competitive Negotiation. The Relationship Between f0 and Negotiation Success in Same Sex Sales Tasks", ["Jan Michalsky", "Heike Schoormann", "Thomas Schultze"], "https://doi.org/10.21437/Interspeech.2019-3031", 5, "interspeech", 2019]], "Oliver Watts": [0, ["Improving Speech Synthesis with Discourse Relations", ["Adele Aubin", "Alessandra Cervone", "Oliver Watts", "Simon King"], "https://doi.org/10.21437/Interspeech.2019-1945", 5, "interspeech", 2019]], "T. Douglas Mast": [0, ["Using Ultrasound Imaging to Create Augmented Visual Biofeedback for Articulatory Practice", ["Colin T. Annand", "Maurice Lamb", "Sarah Dugan", "Sarah R. Li", "Hannah M. Woeste", "T. Douglas Mast", "Michael A. Riley", "Jack A. Masterson", "Neeraja Mahalingam", "Kathryn J. Eary", "Caroline Spencer", "Suzanne Boyce", "Stephanie Jackson", "Anoosha Baxi", "Renee Seward"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8036.html", 2, "interspeech", 2019]], "Vincent Barriac": [0, ["Extending the E-Model Towards Super-Wideband and Fullband Speech Communication Scenarios", ["Sebastian Moller", "Gabriel Mittag", "Thilo Michael", "Vincent Barriac", "Hitoshi Aoki"], "https://doi.org/10.21437/Interspeech.2019-1340", 5, "interspeech", 2019]], "Hui-Ting Hong": [1.5810451827746874e-06, ["Investigating the Variability of Voice Quality and Pain Levels as a Function of Multiple Clinical Parameters", ["Hui-Ting Hong", "Jeng-Lin Li", "Yi-Ming Weng", "Chip-Jin Ng", "Chi-Chun Lee"], "https://doi.org/10.21437/Interspeech.2019-2247", 5, "interspeech", 2019]], "Luis Bernardo": [0, ["Unbabel Talk - Human Verified Translations for Voice Instant Messaging", ["Luis Bernardo", "Mathieu Giquel", "Sebastiao Quintas", "Paulo Dimas", "Helena Moniz", "Isabel Trancoso"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8034.html", 2, "interspeech", 2019]], "Nigel G. Ward": [0, ["Survey Talk: Prosody Research and Applications: The State of the Art", ["Nigel G. Ward"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/abs20.html", 0, "interspeech", 2019]], "Albert Zeyer": [0, ["RWTH ASR Systems for LibriSpeech: Hybrid vs Attention", ["Christoph Luscher", "Eugen Beck", "Kazuki Irie", "Markus Kitza", "Wilfried Michel", "Albert Zeyer", "Ralf Schluter", "Hermann Ney"], "https://doi.org/10.21437/Interspeech.2019-1780", 5, "interspeech", 2019], ["An Analysis of Local Monotonic Attention Variants", ["Andre Merboldt", "Albert Zeyer", "Ralf Schluter", "Hermann Ney"], "https://doi.org/10.21437/Interspeech.2019-2879", 5, "interspeech", 2019], ["Language Modeling with Deep Transformers", ["Kazuki Irie", "Albert Zeyer", "Ralf Schluter", "Hermann Ney"], "https://doi.org/10.21437/Interspeech.2019-2225", 5, "interspeech", 2019]], "Mingye Dong": [0.0735570676624775, ["Vocal Pitch Extraction in Polyphonic Music Using Convolutional Residual Network", ["Mingye Dong", "Jie Wu", "Jian Luan"], "https://doi.org/10.21437/Interspeech.2019-2286", 5, "interspeech", 2019]], "Gabriel Synnaeve": [0, ["Who Needs Words? Lexicon-Free Speech Recognition", ["Tatiana Likhomanenko", "Gabriel Synnaeve", "Ronan Collobert"], "https://doi.org/10.21437/Interspeech.2019-3107", 5, "interspeech", 2019]], "Wiehan Agenbag": [0, ["Improving Automatically Induced Lexicons for Highly Agglutinating Languages Using Data-Driven Morphological Segmentation", ["Wiehan Agenbag", "Thomas Niesler"], "https://doi.org/10.21437/Interspeech.2019-2164", 5, "interspeech", 2019]], "Guohong Ding": [0, ["I4U Submission to NIST SRE 2018: Leveraging from a Decade of Shared Experiences", ["Kong Aik Lee", "Ville Hautamaki", "Tomi H. Kinnunen", "Hitoshi Yamamoto", "Koji Okabe", "Ville Vestman", "Jing Huang", "Guohong Ding", "Hanwu Sun", "Anthony Larcher", "Rohan Kumar Das", "Haizhou Li", "Mickael Rouvier", "Pierre-Michel Bousquet", "Wei Rao", "Qing Wang", "Chunlei Zhang", "Fahimeh Bahmaninezhad", "Hector Delgado", "Massimiliano Todisco"], "https://doi.org/10.21437/Interspeech.2019-1533", 5, "interspeech", 2019], ["Direct-Path Signal Cross-Correlation Estimation for Sound Source Localization in Reverberation", ["Wei Xue", "Ying Tong", "Guohong Ding", "Chao Zhang", "Tao Ma", "Xiaodong He", "Bowen Zhou"], "https://doi.org/10.21437/Interspeech.2019-1488", 5, "interspeech", 2019]], "Achuth Rao M. V": [0, ["Whisper to Neutral Mapping Using Cosine Similarity Maximization in i-Vector Space for Speaker Verification", ["Abinay Reddy Naini", "Achuth Rao M. V", "Prasanta Kumar Ghosh"], "https://doi.org/10.21437/Interspeech.2019-2280", 5, "interspeech", 2019]], "Daniel Povey": [0, ["Advances in Automatic Speech Recognition for Child Speech Using Factored Time Delay Neural Network", ["Fei Wu", "Leibny Paola Garcia-Perera", "Daniel Povey", "Sanjeev Khudanpur"], "https://doi.org/10.21437/Interspeech.2019-2980", 5, "interspeech", 2019], ["Multi-PLDA Diarization on Children's Speech", ["Jiamin Xie", "Leibny Paola Garcia-Perera", "Daniel Povey", "Sanjeev Khudanpur"], "https://doi.org/10.21437/Interspeech.2019-2961", 5, "interspeech", 2019], ["State-of-the-Art Speaker Recognition for Telephone and Video Speech: The JHU-MIT Submission for NIST SRE18", ["Jesus Villalba", "Nanxin Chen", "David Snyder", "Daniel Garcia-Romero", "Alan McCree", "Gregory Sell", "Jonas Borgstrom", "Fred Richardson", "Suwon Shon", "Francois Grondin", "Reda Dehak", "Leibny Paola Garcia-Perera", "Daniel Povey", "Pedro A. Torres-Carrasquillo", "Sanjeev Khudanpur", "Najim Dehak"], "https://doi.org/10.21437/Interspeech.2019-2713", 5, "interspeech", 2019], ["x-Vector DNN Refinement with Full-Length Recordings for Speaker Recognition", ["Daniel Garcia-Romero", "David Snyder", "Gregory Sell", "Alan McCree", "Daniel Povey", "Sanjeev Khudanpur"], "https://doi.org/10.21437/Interspeech.2019-2205", 4, "interspeech", 2019], ["Speaker Recognition Benchmark Using the CHiME-5 Corpus", ["Daniel Garcia-Romero", "David Snyder", "Shinji Watanabe", "Gregory Sell", "Alan McCree", "Daniel Povey", "Sanjeev Khudanpur"], "https://doi.org/10.21437/Interspeech.2019-2174", 5, "interspeech", 2019], ["The JHU Speaker Recognition System for the VOiCES 2019 Challenge", ["David Snyder", "Jesus Villalba", "Nanxin Chen", "Daniel Povey", "Gregory Sell", "Najim Dehak", "Sanjeev Khudanpur"], "https://doi.org/10.21437/Interspeech.2019-2979", 5, "interspeech", 2019], ["The JHU ASR System for VOiCES from a Distance Challenge 2019", ["Yiming Wang", "David Snyder", "Hainan Xu", "Vimal Manohar", "Phani Sankar Nidadavolu", "Daniel Povey", "Sanjeev Khudanpur"], "https://doi.org/10.21437/Interspeech.2019-1948", 5, "interspeech", 2019], ["Improving Emotion Identification Using Phone Posteriors in Raw Speech Waveform Based DNN", ["Mousmita Sarma", "Pegah Ghahremani", "Daniel Povey", "Nagendra Kumar Goel", "Kandarpa Kumar Sarma", "Najim Dehak"], "https://doi.org/10.21437/Interspeech.2019-2093", 5, "interspeech", 2019]], "Anand Mohan": [0, ["Attention Based Hybrid i-Vector BLSTM Model for Language Recognition", ["Bharat Padi", "Anand Mohan", "Sriram Ganapathy"], "https://doi.org/10.21437/Interspeech.2019-2371", 5, "interspeech", 2019]], "Ludi E. Smeele": [0, ["CNN-Based Phoneme Classifier from Vocal Tract MRI Learns Embedding Consistent with Articulatory Topology", ["K. G. van Leeuwen", "P. Bos", "Stefano Trebeschi", "Maarten J. A. van Alphen", "Luuk Voskuilen", "Ludi E. Smeele", "Ferdi van der Heijden", "R. J. J. H. van Son"], "https://doi.org/10.21437/Interspeech.2019-1173", 5, "interspeech", 2019]], "Suwon Shon": [0, ["MCE 2018: The 1st Multi-Target Speaker Detection and Identification Challenge Evaluation", ["Suwon Shon", "Najim Dehak", "Douglas A. Reynolds", "James R. Glass"], "https://doi.org/10.21437/Interspeech.2019-1572", 5, "interspeech", 2019], ["State-of-the-Art Speaker Recognition for Telephone and Video Speech: The JHU-MIT Submission for NIST SRE18", ["Jesus Villalba", "Nanxin Chen", "David Snyder", "Daniel Garcia-Romero", "Alan McCree", "Gregory Sell", "Jonas Borgstrom", "Fred Richardson", "Suwon Shon", "Francois Grondin", "Reda Dehak", "Leibny Paola Garcia-Perera", "Daniel Povey", "Pedro A. Torres-Carrasquillo", "Sanjeev Khudanpur", "Najim Dehak"], "https://doi.org/10.21437/Interspeech.2019-2713", 5, "interspeech", 2019], ["VoiceID Loss: Speech Enhancement for Speaker Verification", ["Suwon Shon", "Hao Tang", "James R. Glass"], "https://doi.org/10.21437/Interspeech.2019-1496", 5, "interspeech", 2019], ["Large-Scale Speaker Retrieval on Random Speaker Variability Subspace", ["Suwon Shon", "Younggun Lee", "Taesu Kim"], "https://doi.org/10.21437/Interspeech.2019-1498", 5, "interspeech", 2019]], "John S. Novak III": [0, ["The Effects of Time Expansion on English as a Second Language Individuals", ["John S. Novak III", "Daniel Bunn", "Robert V. Kenyon"], "https://doi.org/10.21437/Interspeech.2019-2763", 5, "interspeech", 2019]], "Ankur Bapna": [0, ["Large-Scale Multilingual Speech Recognition with a Streaming End-to-End Model", ["Anjuli Kannan", "Arindrima Datta", "Tara N. Sainath", "Eugene Weinstein", "Bhuvana Ramabhadran", "Yonghui Wu", "Ankur Bapna", "Zhifeng Chen", "Seungji Lee"], "https://doi.org/10.21437/Interspeech.2019-2858", 5, "interspeech", 2019]], "R. H. Y. So": [0.5, ["Effects of Base-Frequency and Spectral Envelope on Deep-Learning Speech Separation and Recognition Models", ["J. Hui", "Y. Wei", "S. T. Chen", "R. H. Y. So"], "https://doi.org/10.21437/Interspeech.2019-1715", 5, "interspeech", 2019]], "Julian Hough": [0, ["Detecting Depression with Word-Level Multimodal Fusion", ["Morteza Rohanian", "Julian Hough", "Matthew Purver"], "https://doi.org/10.21437/Interspeech.2019-2283", 5, "interspeech", 2019]], "Anna-Riikka Smolander": [0, ["Transparent Pronunciation Scoring Using Articulatorily Weighted Phoneme Edit Distance", ["Reima Karhila", "Anna-Riikka Smolander", "Sari Ylinen", "Mikko Kurimo"], "https://doi.org/10.21437/Interspeech.2019-1785", 5, "interspeech", 2019]], "Akhilesh Kumar Dubey": [0, ["Hypernasality Severity Detection Using Constant Q Cepstral Coefficients", ["Akhilesh Kumar Dubey", "S. R. Mahadeva Prasanna", "S. Dandapat"], "https://doi.org/10.21437/Interspeech.2019-2151", 5, "interspeech", 2019]], "Jian Gao": [0, ["Nonparallel Emotional Speech Conversion", ["Jian Gao", "Deep Chakraborty", "Hamidou Tembine", "Olaitan Olaleye"], "https://doi.org/10.21437/Interspeech.2019-2878", 5, "interspeech", 2019]], "Cassia Valentini-Botinhao": [0, ["Evaluating Near End Listening Enhancement Algorithms in Realistic Environments", ["Carol Chermaz", "Cassia Valentini-Botinhao", "Henning F. Schepker", "Simon King"], "https://doi.org/10.21437/Interspeech.2019-1800", 5, "interspeech", 2019]], "Toshio Irino": [0, ["Predicting Speech Intelligibility of Enhanced Speech Using Phone Accuracy of DNN-Based ASR System", ["Kenichi Arai", "Shoko Araki", "Atsunori Ogawa", "Keisuke Kinoshita", "Tomohiro Nakatani", "Katsuhiko Yamamoto", "Toshio Irino"], "https://doi.org/10.21437/Interspeech.2019-1381", 5, "interspeech", 2019]], "Ankita Pasad": [0, ["On the Contributions of Visual and Textual Supervision in Low-Resource Semantic Speech Retrieval", ["Ankita Pasad", "Bowen Shi", "Herman Kamper", "Karen Livescu"], "https://doi.org/10.21437/Interspeech.2019-3051", 5, "interspeech", 2019]], "Gene-Ping Yang": [2.743683413797271e-08, ["Improved Speech Separation with Time-and-Frequency Cross-Domain Joint Embedding and Clustering", ["Gene-Ping Yang", "Chao-I Tuan", "Hung-yi Lee", "Lin-Shan Lee"], "https://doi.org/10.21437/Interspeech.2019-2181", 5, "interspeech", 2019]], "Jens Heitkaemper": [0, ["Multi-Channel Block-Online Source Extraction Based on Utterance Adaptation", ["Juan M. Martin-Donas", "Jens Heitkaemper", "Reinhold Haeb-Umbach", "Angel M. Gomez", "Antonio M. Peinado"], "https://doi.org/10.21437/Interspeech.2019-2244", 5, "interspeech", 2019], ["Guided Source Separation Meets a Strong ASR Backend: Hitachi/Paderborn University Joint Investigation for Dinner Party ASR", ["Naoyuki Kanda", "Christoph Boddeker", "Jens Heitkaemper", "Yusuke Fujita", "Shota Horiguchi", "Kenji Nagamatsu", "Reinhold Haeb-Umbach"], "https://doi.org/10.21437/Interspeech.2019-1167", 5, "interspeech", 2019]], "Zheng-Chi Lu": [0, ["Using Attention Networks and Adversarial Augmentation for Styrian Dialect Continuous Sleepiness and Baby Sound Recognition", ["Sung-Lin Yeh", "Gao-Yi Chao", "Bo-Hao Su", "Yu-Lin Huang", "Meng-Han Lin", "Yin-Chun Tsai", "Yu-Wen Tai", "Zheng-Chi Lu", "Chieh-Yu Chen", "Tsung-Ming Tai", "Chiu-Wang Tseng", "Cheng-Kuang Lee", "Chi-Chun Lee"], "https://doi.org/10.21437/Interspeech.2019-2110", 5, "interspeech", 2019]], "Gabor Gosztolya": [0, ["Calibrating DNN Posterior Probability Estimates of HMM/DNN Models to Improve Social Signal Detection from Audio Data", ["Gabor Gosztolya", "Laszlo Toth"], "https://doi.org/10.21437/Interspeech.2019-2552", 5, "interspeech", 2019], ["Ultrasound-Based Silent Speech Interface Built on a Continuous Vocoder", ["Tamas Gabor Csapo", "Mohammed Salah Al-Radhi", "Geza Nemeth", "Gabor Gosztolya", "Tamas Grosz", "Laszlo Toth", "Alexandra Marko"], "https://doi.org/10.21437/Interspeech.2019-2046", 5, "interspeech", 2019], ["Using Fisher Vector and Bag-of-Audio-Words Representations to Identify Styrian Dialects, Sleepiness, Baby & Orca Sounds", ["Gabor Gosztolya"], "https://doi.org/10.21437/Interspeech.2019-1726", 5, "interspeech", 2019], ["Assessing Parkinson's Disease from Speech Using Fisher Vectors", ["Jose Vicente Egas Lopez", "Juan Rafael Orozco-Arroyave", "Gabor Gosztolya"], "https://doi.org/10.21437/Interspeech.2019-2217", 5, "interspeech", 2019], ["Using the Bag-of-Audio-Word Feature Representation of ASR DNN Posteriors for Paralinguistic Classification", ["Gabor Gosztolya"], "https://doi.org/10.21437/Interspeech.2019-1163", 5, "interspeech", 2019]], "Subhadeep Dey": [0, ["Exploiting Semi-Supervised Training Through a Dropout Regularization in End-to-End Speech Recognition", ["Subhadeep Dey", "Petr Motlicek", "Trung Bui", "Franck Dernoncourt"], "https://doi.org/10.21437/Interspeech.2019-3246", 5, "interspeech", 2019]], "Stefan Werner": [0, ["Recognition of Creaky Voice from Emergency Calls", ["Lauri Tavi", "Tanel Alumae", "Stefan Werner"], "https://doi.org/10.21437/Interspeech.2019-1253", 5, "interspeech", 2019]], "Florian Metze": [0, ["Multilingual Speech Recognition with Corpus Relatedness Sampling", ["Xinjian Li", "Siddharth Dalmia", "Alan W. Black", "Florian Metze"], "https://doi.org/10.21437/Interspeech.2019-3052", 5, "interspeech", 2019], ["Survey Talk: Multimodal Processing of Speech and Language", ["Florian Metze"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/abs22.html", 0, "interspeech", 2019], ["SANTLR: Speech Annotation Toolkit for Low Resource Languages", ["Xinjian Li", "Zhong Zhou", "Siddharth Dalmia", "Alan W. Black", "Florian Metze"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8040.html", 2, "interspeech", 2019], ["Cross-Attention End-to-End ASR for Two-Party Conversations", ["Suyoun Kim", "Siddharth Dalmia", "Florian Metze"], "https://doi.org/10.21437/Interspeech.2019-3173", 5, "interspeech", 2019]], "Khaled Lakhdhar": [0, ["Pindrop Labs' Submission to the First Multi-Target Speaker Detection and Identification Challenge", ["Elie Khoury", "Khaled Lakhdhar", "Andrew Vaughan", "Ganesh Sivaraman", "Parav Nagarsheth"], "https://doi.org/10.21437/Interspeech.2019-3179", 4, "interspeech", 2019]], "Diane Hirschfeld": [0, ["Cross-Lingual Transfer Learning for Affective Spoken Dialogue Systems", ["Kristijan Gjoreski", "Aleksandar Gjoreski", "Ivan Kraljevski", "Diane Hirschfeld"], "https://doi.org/10.21437/Interspeech.2019-2163", 5, "interspeech", 2019]], "Ferdi van der Heijden": [0, ["CNN-Based Phoneme Classifier from Vocal Tract MRI Learns Embedding Consistent with Articulatory Topology", ["K. G. van Leeuwen", "P. Bos", "Stefano Trebeschi", "Maarten J. A. van Alphen", "Luuk Voskuilen", "Ludi E. Smeele", "Ferdi van der Heijden", "R. J. J. H. van Son"], "https://doi.org/10.21437/Interspeech.2019-1173", 5, "interspeech", 2019]], "Taehwan Kim": [0.925512820482254, ["One-Shot Voice Conversion with Disentangled Representations by Leveraging Phonetic Posteriorgrams", ["Seyed Hamidreza Mohammadi", "Taehwan Kim"], "https://doi.org/10.21437/Interspeech.2019-1798", 5, "interspeech", 2019]], "Visar Berisha": [0, ["Objective Assessment of Social Skills Using Automated Language Analysis for Identification of Schizophrenia and Bipolar Disorder", ["Rohit Voleti", "Stephanie Woolridge", "Julie M. Liss", "Melissa Milanovic", "Christopher R. Bowie", "Visar Berisha"], "https://doi.org/10.21437/Interspeech.2019-2960", 5, "interspeech", 2019], ["Do Conversational Partners Entrain on Articulatory Precision?", ["Nichola Lubold", "Stephanie A. Borrie", "Tyson S. Barrett", "Megan M. Willi", "Visar Berisha"], "https://doi.org/10.21437/Interspeech.2019-1786", 5, "interspeech", 2019], ["Say What? A Dataset for Exploring the Error Patterns That Two ASR Engines Make", ["Meredith Moore", "Michael Saxon", "Hemanth Venkateswara", "Visar Berisha", "Sethuraman Panchanathan"], "https://doi.org/10.21437/Interspeech.2019-3096", 5, "interspeech", 2019], ["Residual + Capsule Networks (ResCap) for Simultaneous Single-Channel Overlapped Keyword Recognition", ["Yan Xiong", "Visar Berisha", "Chaitali Chakrabarti"], "https://doi.org/10.21437/Interspeech.2019-2913", 5, "interspeech", 2019]], "Xiaoqi Li": [0, ["A Convolutional Neural Network with Non-Local Module for Speech Enhancement", ["Xiaoqi Li", "Yaxing Li", "Meng Li", "Shan Xu", "Yuanjie Dong", "Xinrong Sun", "Shengwu Xiong"], "https://doi.org/10.21437/Interspeech.2019-2472", 5, "interspeech", 2019]], "Avinatan Hassidim": [0, ["Personalizing ASR for Dysarthric and Accented Speech with Limited Data", ["Joel Shor", "Dotan Emanuel", "Oran Lang", "Omry Tuval", "Michael Brenner", "Julie Cattiau", "Fernando Vieira", "Maeve McNally", "Taylor Charbonneau", "Melissa Nollstadt", "Avinatan Hassidim", "Yossi Matias"], "https://doi.org/10.21437/Interspeech.2019-1427", 5, "interspeech", 2019]], "Manuel Sam Ribeiro": [0, ["Ultrasound Tongue Imaging for Diarization and Alignment of Child Speech Therapy Sessions", ["Manuel Sam Ribeiro", "Aciel Eshky", "Korin Richmond", "Steve Renals"], "https://doi.org/10.21437/Interspeech.2019-2612", 5, "interspeech", 2019], ["Synchronising Audio and Ultrasound by Learning Cross-Modal Embeddings", ["Aciel Eshky", "Manuel Sam Ribeiro", "Korin Richmond", "Steve Renals"], "https://doi.org/10.21437/Interspeech.2019-1804", 5, "interspeech", 2019]], "Samuel S. Silva": [0, ["Exploring Critical Articulator Identification from 50Hz RT-MRI Data of the Vocal Tract", ["Samuel S. Silva", "Antonio J. S. Teixeira", "Conceicao Cunha", "Nuno Almeida", "Arun A. Joseph", "Jens Frahm"], "https://doi.org/10.21437/Interspeech.2019-2897", 5, "interspeech", 2019], ["On the Role of Oral Configurations in European Portuguese Nasal Vowels", ["Conceicao Cunha", "Samuel S. Silva", "Antonio J. S. Teixeira", "Catarina Oliveira", "Paula Martins", "Arun A. Joseph", "Jens Frahm"], "https://doi.org/10.21437/Interspeech.2019-2232", 5, "interspeech", 2019]], "Xue Bai": [1.5237832030834397e-05, ["A Hybrid Approach to Acoustic Scene Classification Based on Universal Acoustic Models", ["Xue Bai", "Jun Du", "Zi-Rui Wang", "Chin-Hui Lee"], "https://doi.org/10.21437/Interspeech.2019-2171", 5, "interspeech", 2019]], "Venkataraja Aithal": [0, ["NITK Kids' Speech Corpus", ["Pravin Bhaskar Ramteke", "Sujata Supanekar", "Pradyoth Hegde", "Hanna Nelson", "Venkataraja Aithal", "Shashidhar G. Koolagudi"], "https://doi.org/10.21437/Interspeech.2019-2061", 5, "interspeech", 2019]], "Meng Yu": [0.0010469693806953728, ["Improved Speaker-Dependent Separation for CHiME-5 Challenge", ["Jian Wu", "Yong Xu", "Shi-Xiong Zhang", "Lianwu Chen", "Meng Yu", "Lei Xie", "Dong Yu"], "https://doi.org/10.21437/Interspeech.2019-1569", 5, "interspeech", 2019], ["Jointly Adversarial Enhancement Training for Robust End-to-End Speech Recognition", ["Bin Liu", "Shuai Nie", "Shan Liang", "Wenju Liu", "Meng Yu", "Lianwu Chen", "Shouye Peng", "Changliang Li"], "https://doi.org/10.21437/Interspeech.2019-1242", 5, "interspeech", 2019], ["Direction-Aware Speaker Beam for Multi-Channel Speaker Extraction", ["Guanjun Li", "Shan Liang", "Shuai Nie", "Wenju Liu", "Meng Yu", "Lianwu Chen", "Shouye Peng", "Changliang Li"], "https://doi.org/10.21437/Interspeech.2019-1474", 5, "interspeech", 2019], ["Neural Spatial Filter: Target Speaker Speech Separation Assisted with Directional Information", ["Rongzhi Gu", "Lianwu Chen", "Shi-Xiong Zhang", "Jimeng Zheng", "Yong Xu", "Meng Yu", "Dan Su", "Yuexian Zou", "Dong Yu"], "https://doi.org/10.21437/Interspeech.2019-2266", 5, "interspeech", 2019], ["A Comprehensive Study of Speech Separation: Spectrogram vs Waveform Separation", ["Fahimeh Bahmaninezhad", "Jian Wu", "Rongzhi Gu", "Shi-Xiong Zhang", "Yong Xu", "Meng Yu", "Dong Yu"], "https://doi.org/10.21437/Interspeech.2019-3181", 5, "interspeech", 2019]], "Gabor Kiss": [0, ["Depression State Assessment: Application for Detection of Depression by Speech", ["Gabor Kiss", "David Sztaho", "Klara Vicsi"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8004.html", 2, "interspeech", 2019]], "Tobias Bocklet": [0, ["Ultra-Compact NLU: Neuronal Network Binarization as Regularization", ["Munir Georges", "Krzysztof Czarnowski", "Tobias Bocklet"], "https://doi.org/10.21437/Interspeech.2019-2591", 5, "interspeech", 2019], ["Intel Far-Field Speaker Recognition System for VOiCES Challenge 2019", ["Jonathan Huang", "Tobias Bocklet"], "https://doi.org/10.21437/Interspeech.2019-2894", 5, "interspeech", 2019]], "Ruizhi Li": [0, ["Performance Monitoring for End-to-End Speech Recognition", ["Ruizhi Li", "Gregory Sell", "Hynek Hermansky"], "https://doi.org/10.21437/Interspeech.2019-3137", 5, "interspeech", 2019], ["Exploring Methods for the Automatic Detection of Errors in Manual Transcription", ["Xiaofei Wang", "Jinyi Yang", "Ruizhi Li", "Samik Sadhu", "Hynek Hermansky"], "https://doi.org/10.21437/Interspeech.2019-1343", 5, "interspeech", 2019]], "Bin Ma": [0, ["Fast Learning for Non-Parallel Many-to-Many Voice Conversion with Residual Star Generative Adversarial Networks", ["Shengkui Zhao", "Trung Hieu Nguyen", "Hao Wang", "Bin Ma"], "https://doi.org/10.21437/Interspeech.2019-2067", 5, "interspeech", 2019], ["Multi-Task Multi-Network Joint-Learning of Deep Residual Networks and Cycle-Consistency Generative Adversarial Networks for Robust Speech Recognition", ["Shengkui Zhao", "Chongjia Ni", "Rong Tong", "Bin Ma"], "https://doi.org/10.21437/Interspeech.2019-2078", 5, "interspeech", 2019], ["Constrained Output Embeddings for End-to-End Code-Switching Speech Recognition with Only Monolingual Data", ["Yerbolat Khassanov", "Haihua Xu", "Van Tung Pham", "Zhiping Zeng", "Eng Siong Chng", "Chongjia Ni", "Bin Ma"], "https://doi.org/10.21437/Interspeech.2019-1867", 5, "interspeech", 2019], ["Towards Language-Universal Mandarin-English Speech Recognition", ["Shiliang Zhang", "Yuan Liu", "Ming Lei", "Bin Ma", "Lei Xie"], "https://doi.org/10.21437/Interspeech.2019-1365", 5, "interspeech", 2019]], "Taylor Charbonneau": [0, ["Personalizing ASR for Dysarthric and Accented Speech with Limited Data", ["Joel Shor", "Dotan Emanuel", "Oran Lang", "Omry Tuval", "Michael Brenner", "Julie Cattiau", "Fernando Vieira", "Maeve McNally", "Taylor Charbonneau", "Melissa Nollstadt", "Avinatan Hassidim", "Yossi Matias"], "https://doi.org/10.21437/Interspeech.2019-1427", 5, "interspeech", 2019]], "Stephanie A. Borrie": [0, ["Do Conversational Partners Entrain on Articulatory Precision?", ["Nichola Lubold", "Stephanie A. Borrie", "Tyson S. Barrett", "Megan M. Willi", "Visar Berisha"], "https://doi.org/10.21437/Interspeech.2019-1786", 5, "interspeech", 2019]], "Leimin Tian": [0, ["Detecting Topic-Oriented Speaker Stance in Conversational Speech", ["Catherine Lai", "Beatrice Alex", "Johanna D. Moore", "Leimin Tian", "Tatsuro Hori", "Gianpiero Francesca"], "https://doi.org/10.21437/Interspeech.2019-2632", 5, "interspeech", 2019]], "Zhen-Hua Ling": [0, ["A Chinese Dataset for Identifying Speakers in Novels", ["Jia-Xiang Chen", "Zhen-Hua Ling", "Li-Rong Dai"], "https://doi.org/10.21437/Interspeech.2019-1614", 5, "interspeech", 2019], ["Singing Voice Synthesis Using Deep Autoregressive Neural Networks for Acoustic Modeling", ["Yuan-Hao Yi", "Yang Ai", "Zhen-Hua Ling", "Li-Rong Dai"], "https://doi.org/10.21437/Interspeech.2019-1563", 5, "interspeech", 2019], ["Neural Text Clustering with Document-Level Attention Based on Dynamic Soft Labels", ["Zhi Chen", "Wu Guo", "Li-Rong Dai", "Zhen-Hua Ling", "Jun Du"], "https://doi.org/10.21437/Interspeech.2019-1417", 5, "interspeech", 2019]], "Luuk Voskuilen": [0, ["CNN-Based Phoneme Classifier from Vocal Tract MRI Learns Embedding Consistent with Articulatory Topology", ["K. G. van Leeuwen", "P. Bos", "Stefano Trebeschi", "Maarten J. A. van Alphen", "Luuk Voskuilen", "Ludi E. Smeele", "Ferdi van der Heijden", "R. J. J. H. van Son"], "https://doi.org/10.21437/Interspeech.2019-1173", 5, "interspeech", 2019]], "K. Sri Rama Murty": [0, ["Unsupervised Acoustic Segmentation and Clustering Using Siamese Network Embeddings", ["Saurabhchand Bhati", "Shekhar Nayak", "K. Sri Rama Murty", "Najim Dehak"], "https://doi.org/10.21437/Interspeech.2019-2981", 5, "interspeech", 2019]], "Suryakanth V. Gangashetty": [0, ["Excitation Source and Vocal Tract System Based Acoustic Features for Detection of Nasals in Continuous Speech", ["Bhanu Teja Nellore", "Sri Harsha Dumpala", "Karan Nathwani", "Suryakanth V. Gangashetty"], "https://doi.org/10.21437/Interspeech.2019-2785", 5, "interspeech", 2019]], "Amanda Stent": [0, ["Hush-Hush Speak: Speech Reconstruction Using Silent Videos", ["Shashwat Uttam", "Yaman Kumar", "Dhruva Sahrawat", "Mansi Aggarwal", "Rajiv Ratn Shah", "Debanjan Mahata", "Amanda Stent"], "https://doi.org/10.21437/Interspeech.2019-3269", 5, "interspeech", 2019], ["MobiVSR : Efficient and Light-Weight Neural Network for Visual Speech Recognition on Mobile Devices", ["Nilay Shrivastava", "Astitwa Saxena", "Yaman Kumar", "Rajiv Ratn Shah", "Amanda Stent", "Debanjan Mahata", "Preeti Kaur", "Roger Zimmermann"], "https://doi.org/10.21437/Interspeech.2019-3273", 5, "interspeech", 2019]], "Lucy Skidmore": [0, ["Using Alexa for Flashcard-Based Learning", ["Lucy Skidmore", "Roger K. Moore"], "https://doi.org/10.21437/Interspeech.2019-2893", 5, "interspeech", 2019], ["On the Use/Misuse of the Term 'Phoneme'", ["Roger K. Moore", "Lucy Skidmore"], "https://doi.org/10.21437/Interspeech.2019-2711", 5, "interspeech", 2019]], "Alvaro Martin Iturralde Zurita": [0, ["Compensation for French Liquid Deletion During Auditory Sentence Processing", ["Sharon Peperkamp", "Alvaro Martin Iturralde Zurita"], "https://doi.org/10.21437/Interspeech.2019-2950", 5, "interspeech", 2019]], "Preslav Nakov": [0, ["Predicting the Leading Political Ideology of YouTube Channels Using Acoustic, Textual, and Metadata Information", ["Yoan Dinkov", "Ahmed Ali", "Ivan Koychev", "Preslav Nakov"], "https://doi.org/10.21437/Interspeech.2019-2965", 5, "interspeech", 2019]], "Alejo J. Nevado-Holgado": [0, ["A Path Signature Approach for Speech Emotion Recognition", ["Bo Wang", "Maria Liakata", "Hao Ni", "Terry Lyons", "Alejo J. Nevado-Holgado", "Kate Saunders"], "https://doi.org/10.21437/Interspeech.2019-2624", 5, "interspeech", 2019]], "Seungkwon Beack": [0, ["Cascaded Cross-Module Residual Learning Towards Lightweight End-to-End Speech Coding", ["Kai Zhen", "Jongmo Sung", "Mi Suk Lee", "Seungkwon Beack", "Minje Kim"], "https://doi.org/10.21437/Interspeech.2019-1816", 5, "interspeech", 2019]], "Lukas Drude": [0, ["Unsupervised Training of Neural Mask-Based Beamforming", ["Lukas Drude", "Jahn Heymann", "Reinhold Haeb-Umbach"], "https://doi.org/10.21437/Interspeech.2019-2549", 5, "interspeech", 2019]], "John Gideon": [0, ["Emotion Recognition from Natural Phone Conversations in Individuals with and without Recent Suicidal Ideation", ["John Gideon", "Heather T. Schatten", "Melvin G. McInnis", "Emily Mower Provost"], "https://doi.org/10.21437/Interspeech.2019-1830", 5, "interspeech", 2019]], "Shinnosuke Takamichi": [0, ["Speech Quality Evaluation of Synthesized Japanese Speech Using EEG", ["Ivan Halim Parmonangan", "Hiroki Tanaka", "Sakriani Sakti", "Shinnosuke Takamichi", "Satoshi Nakamura"], "https://doi.org/10.21437/Interspeech.2019-2059", 5, "interspeech", 2019]], "Andzhukaev Tseren": [0, ["STC Antispoofing Systems for the ASVspoof2019 Challenge", ["Galina Lavrentyeva", "Sergey Novoselov", "Andzhukaev Tseren", "Marina Volkova", "Artem Gorlanov", "Alexandr Kozlov"], "https://doi.org/10.21437/Interspeech.2019-1768", 5, "interspeech", 2019]], "Anirudh Raju": [0, ["Scalable Multi Corpora Neural Language Models for ASR", ["Anirudh Raju", "Denis Filimonov", "Gautam Tiwari", "Guitang Lan", "Ariya Rastrow"], "https://doi.org/10.21437/Interspeech.2019-3060", 5, "interspeech", 2019]], "Ajda Gokcen": [0, ["Dual Encoder Classifier Models as Constraints in Neural Text Normalization", ["Ajda Gokcen", "Hao Zhang", "Richard Sproat"], "https://doi.org/10.21437/Interspeech.2019-1135", 5, "interspeech", 2019]], "Ming Lei": [0, ["Towards Language-Universal Mandarin-English Speech Recognition", ["Shiliang Zhang", "Yuan Liu", "Ming Lei", "Bin Ma", "Lei Xie"], "https://doi.org/10.21437/Interspeech.2019-1365", 5, "interspeech", 2019], ["Investigation of Transformer Based Spelling Correction Model for CTC-Based End-to-End Mandarin Speech Recognition", ["Shiliang Zhang", "Ming Lei", "Zhijie Yan"], "https://doi.org/10.21437/Interspeech.2019-1290", 5, "interspeech", 2019], ["Audio Tagging with Compact Feedforward Sequential Memory Network and Audio-to-Audio Ratio Based Data Augmentation", ["Zhiying Huang", "Shiliang Zhang", "Ming Lei"], "https://doi.org/10.21437/Interspeech.2019-1302", 5, "interspeech", 2019]], "P. P. Manakul": [0, ["Impact of ASR Performance on Spoken Grammatical Error Detection", ["Yiting Lu", "Mark J. F. Gales", "Kate M. Knill", "P. P. Manakul", "Linlin Wang", "Y. Wang"], "https://doi.org/10.21437/Interspeech.2019-1706", 5, "interspeech", 2019]], "Seokjun Seo": [0.9999825656414032, ["Temporal Convolution for Real-Time Keyword Spotting on Mobile Devices", ["Seungwoo Choi", "Seokjun Seo", "Beomjun Shin", "Hyeongmin Byun", "Martin Kersner", "Beomsu Kim", "Dongyoung Kim", "Sungjoo Ha"], "https://doi.org/10.21437/Interspeech.2019-1363", 5, "interspeech", 2019]], "Bin Li": [0, ["Influence of Contextuality on Prosodic Realization of Information Structure in Chinese Dialogues", ["Bin Li", "Yuan Jia"], "https://doi.org/10.21437/Interspeech.2019-2291", 5, "interspeech", 2019]], "Masayuki Suzuki": [0, ["Direct Neuron-Wise Fusion of Cognate Neural Networks", ["Takashi Fukuda", "Masayuki Suzuki", "Gakuto Kurata"], "https://doi.org/10.21437/Interspeech.2019-1930", 5, "interspeech", 2019]], "Di Xie": [0, ["An End-to-End Audio Classification System Based on Raw Waveforms and Mix-Training Strategy", ["Jiaxu Chen", "Jing Hao", "Kai Chen", "Di Xie", "Shicai Yang", "Shiliang Pu"], "https://doi.org/10.21437/Interspeech.2019-1579", 5, "interspeech", 2019]], "Bolaji Yusuf": [0, ["Temporally-Aware Acoustic Unit Discovery for Zerospeech 2019 Challenge", ["Bolaji Yusuf", "Alican Gok", "Batuhan Gundogdu", "Oyku Deniz Kose", "Murat Saraclar"], "https://doi.org/10.21437/Interspeech.2019-1430", 5, "interspeech", 2019], ["An Empirical Evaluation of DTW Subsampling Methods for Keyword Search", ["Bolaji Yusuf", "Murat Saraclar"], "https://doi.org/10.21437/Interspeech.2019-2413", 5, "interspeech", 2019]], "Ramon Prieto": [0, ["Survey Talk: When Attention Meets Speech Applications: Speech & Speaker Recognition Perspective", ["Kyu J. Han", "Ramon Prieto", "Tao Ma"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/abs5.html", 0, "interspeech", 2019]], "Juan Manuel Montero": [0, ["Predicting Group-Level Skin Attention to Short Movies from Audio-Based LSTM-Mixture of Experts Models", ["Ricardo Kleinlein", "Cristina Luna Jimenez", "Juan Manuel Montero", "Zoraida Callejas", "Fernando Fernandez-Martinez"], "https://doi.org/10.21437/Interspeech.2019-2799", 5, "interspeech", 2019], ["A Saliency-Based Attention LSTM Model for Cognitive Load Classification from Speech", ["Ascension Gallardo-Antolin", "Juan Manuel Montero"], "https://doi.org/10.21437/Interspeech.2019-1603", 5, "interspeech", 2019]], "Kazuki Irie": [0, ["RWTH ASR Systems for LibriSpeech: Hybrid vs Attention", ["Christoph Luscher", "Eugen Beck", "Kazuki Irie", "Markus Kitza", "Wilfried Michel", "Albert Zeyer", "Ralf Schluter", "Hermann Ney"], "https://doi.org/10.21437/Interspeech.2019-1780", 5, "interspeech", 2019], ["On the Choice of Modeling Unit for Sequence-to-Sequence Speech Recognition", ["Kazuki Irie", "Rohit Prabhavalkar", "Anjuli Kannan", "Antoine Bruguier", "David Rybach", "Patrick Nguyen"], "https://doi.org/10.21437/Interspeech.2019-2277", 5, "interspeech", 2019], ["Language Modeling with Deep Transformers", ["Kazuki Irie", "Albert Zeyer", "Ralf Schluter", "Hermann Ney"], "https://doi.org/10.21437/Interspeech.2019-2225", 5, "interspeech", 2019]], "Pengcheng Guo": [0, ["Unsupervised Adaptation with Adversarial Dropout Regularization for Robust Speech Recognition", ["Pengcheng Guo", "Sining Sun", "Lei Xie"], "https://doi.org/10.21437/Interspeech.2019-2544", 5, "interspeech", 2019], ["Adversarial Regularization for End-to-End Robust Speaker Verification", ["Qing Wang", "Pengcheng Guo", "Sining Sun", "Lei Xie", "John H. L. Hansen"], "https://doi.org/10.21437/Interspeech.2019-2983", 5, "interspeech", 2019]], "Patrick Ignoto": [0, ["Speech Model Pre-Training for End-to-End Spoken Language Understanding", ["Loren Lugosch", "Mirco Ravanelli", "Patrick Ignoto", "Vikrant Singh Tomar", "Yoshua Bengio"], "https://doi.org/10.21437/Interspeech.2019-2396", 5, "interspeech", 2019]], "Georges Linares": [0, ["M2H-GAN: A GAN-Based Mapping from Machine to Human Transcripts for Speech Understanding", ["Titouan Parcollet", "Mohamed Morchid", "Xavier Bost", "Georges Linares"], "https://doi.org/10.21437/Interspeech.2019-2662", 5, "interspeech", 2019], ["Real to H-Space Encoder for Speech Recognition", ["Titouan Parcollet", "Mohamed Morchid", "Georges Linares", "Renato De Mori"], "https://doi.org/10.21437/Interspeech.2019-1539", 5, "interspeech", 2019]], "Melvin Johnson": [0, ["Direct Speech-to-Speech Translation with a Sequence-to-Sequence Model", ["Ye Jia", "Ron J. Weiss", "Fadi Biadsy", "Wolfgang Macherey", "Melvin Johnson", "Zhifeng Chen", "Yonghui Wu"], "https://doi.org/10.21437/Interspeech.2019-1951", 5, "interspeech", 2019]], "Bahman Mirheidari": [0, ["Automatic Hierarchical Attention Neural Network for Detecting AD", ["Yilin Pan", "Bahman Mirheidari", "Markus Reuber", "Annalena Venneri", "Daniel Blackburn", "Heidi Christensen"], "https://doi.org/10.21437/Interspeech.2019-1799", 5, "interspeech", 2019]], "Arindrima Datta": [0, ["Large-Scale Multilingual Speech Recognition with a Streaming End-to-End Model", ["Anjuli Kannan", "Arindrima Datta", "Tara N. Sainath", "Eugene Weinstein", "Bhuvana Ramabhadran", "Yonghui Wu", "Ankur Bapna", "Zhifeng Chen", "Seungji Lee"], "https://doi.org/10.21437/Interspeech.2019-2858", 5, "interspeech", 2019]], "Kyu J. Han": [0.11794104427099228, ["Survey Talk: When Attention Meets Speech Applications: Speech & Speaker Recognition Perspective", ["Kyu J. Han", "Ramon Prieto", "Tao Ma"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/abs5.html", 0, "interspeech", 2019], ["Speaker Diarization with Lexical Information", ["Tae Jin Park", "Kyu J. Han", "Jing Huang", "Xiaodong He", "Bowen Zhou", "Panayiotis G. Georgiou", "Shrikanth Narayanan"], "https://doi.org/10.21437/Interspeech.2019-1947", 5, "interspeech", 2019], ["Multi-Stride Self-Attention for Speech Recognition", ["Kyu J. Han", "Jing Huang", "Yun Tang", "Xiaodong He", "Bowen Zhou"], "https://doi.org/10.21437/Interspeech.2019-1973", 5, "interspeech", 2019]], "Marvin Rajwadi": [0, ["Explaining Sentiment Classification", ["Marvin Rajwadi", "Cornelius Glackin", "Julie A. Wall", "Gerard Chollet", "Nigel Cannings"], "https://doi.org/10.21437/Interspeech.2019-2743", 5, "interspeech", 2019]], "Min-Jae Hwang": [0.8463334739208221, ["Parameter Enhancement for MELP Speech Codec in Noisy Communication Environment", ["Min-Jae Hwang", "Hong-Goo Kang"], "https://doi.org/10.21437/Interspeech.2019-3249", 5, "interspeech", 2019]], "Florian B. Pokorny": [0, ["The INTERSPEECH 2019 Computational Paralinguistics Challenge: Styrian Dialects, Continuous Sleepiness, Baby Sounds & Orca Activity", ["Bjorn W. Schuller", "Anton Batliner", "Christian Bergler", "Florian B. Pokorny", "Jarek Krajewski", "Margaret Cychosz", "Ralf Vollmann", "Sonja-Dana Roelen", "Sebastian Schnieder", "Elika Bergelson", "Alejandrina Cristia", "Amanda Seidl", "Anne S. Warlaumont", "Lisa Yankowitz", "Elmar Noth", "Shahin Amiriparian", "Simone Hantke", "Maximilian Schmitt"], "https://doi.org/10.21437/Interspeech.2019-1122", 5, "interspeech", 2019]], "Yoshiko Arimoto": [0, ["Conversational and Social Laughter Synthesis with WaveNet", ["Hiroki Mori", "Tomohiro Nagata", "Yoshiko Arimoto"], "https://doi.org/10.21437/Interspeech.2019-2131", 4, "interspeech", 2019]], "Chao Wang": [0.3783327341079712, ["Sub-Band Convolutional Neural Networks for Small-Footprint Spoken Term Classification", ["Chieh-Chi Kao", "Ming Sun", "Yixin Gao", "Shiv Vitaladevuni", "Chao Wang"], "https://doi.org/10.21437/Interspeech.2019-1766", 5, "interspeech", 2019], ["Compression of Acoustic Event Detection Models with Quantized Distillation", ["Bowen Shi", "Ming Sun", "Chieh-Chi Kao", "Viktor Rozgic", "Spyros Matsoukas", "Chao Wang"], "https://doi.org/10.21437/Interspeech.2019-1747", 5, "interspeech", 2019]], "Omid Ghahabi": [0, ["Speaker-Corrupted Embeddings for Online Speaker Diarization", ["Omid Ghahabi", "Volker Fischer"], "https://doi.org/10.21437/Interspeech.2019-2756", 5, "interspeech", 2019]], "Judith Gaspers": [0, ["Neural Named Entity Recognition from Subword Units", ["Abdalghani Abujabal", "Judith Gaspers"], "https://doi.org/10.21437/Interspeech.2019-1305", 5, "interspeech", 2019]], "Yanping Chen": [0, ["Rare Sound Event Detection Using Deep Learning and Data Augmentation", ["Yanping Chen", "Hongxia Jin"], "https://doi.org/10.21437/Interspeech.2019-1985", 5, "interspeech", 2019]], "Alfons Juan": [0, ["Real-Time One-Pass Decoder for Speech Recognition Using LSTM Language Models", ["Javier Jorge", "Adria Gimenez", "Javier Iranzo-Sanchez", "Jorge Civera", "Albert Sanchis", "Alfons Juan"], "https://doi.org/10.21437/Interspeech.2019-2798", 5, "interspeech", 2019]], "Paul Ferrari": [0, ["Towards a Speaker Independent Speech-BCI Using Speaker Adaptation", ["Debadatta Dash", "Alan Wisler", "Paul Ferrari", "Jun Wang"], "https://doi.org/10.21437/Interspeech.2019-3109", 5, "interspeech", 2019], ["Spatial and Spectral Fingerprint in the Brain: Speaker Identification from Single Trial MEG Signals", ["Debadatta Dash", "Paul Ferrari", "Jun Wang"], "https://doi.org/10.21437/Interspeech.2019-3105", 5, "interspeech", 2019]], "Prathusha Kameswara Sarma": [0, ["Multi-Modal Sentiment Analysis Using Deep Canonical Correlation Analysis", ["Zhongkai Sun", "Prathusha Kameswara Sarma", "William A. Sethares", "Erik P. Bucy"], "https://doi.org/10.21437/Interspeech.2019-2482", 5, "interspeech", 2019]], "Nataliya Bryhadyr": [0, ["Pitch Accent Trajectories Across Different Conditions of Visibility and Information Structure - Evidence from Spontaneous Dyadic Interaction", ["Petra Wagner", "Nataliya Bryhadyr", "Marin Schroer"], "https://doi.org/10.21437/Interspeech.2019-1619", 5, "interspeech", 2019]], "Bajibabu Bollepalli": [0, ["GELP: GAN-Excited Linear Prediction for Speech Synthesis from Mel-Spectrogram", ["Lauri Juvela", "Bajibabu Bollepalli", "Junichi Yamagishi", "Paavo Alku"], "https://doi.org/10.21437/Interspeech.2019-2008", 5, "interspeech", 2019], ["Lombard Speech Synthesis Using Transfer Learning in a Tacotron Text-to-Speech System", ["Bajibabu Bollepalli", "Lauri Juvela", "Paavo Alku"], "https://doi.org/10.21437/Interspeech.2019-1333", 5, "interspeech", 2019]], "Slava Shechtman": [0, ["High Quality, Lightweight and Adaptable TTS Using LPCNet", ["Zvi Kons", "Slava Shechtman", "Alexander Sorin", "Carmel Rabinovitz", "Ron Hoory"], "https://doi.org/10.21437/Interspeech.2019-1705", 5, "interspeech", 2019]], "Valerian Girard": [0, ["Conditional Variational Auto-Encoder for Text-Driven Expressive AudioVisual Speech Synthesis", ["Sara Dahmani", "Vincent Colotte", "Valerian Girard", "Slim Ouni"], "https://doi.org/10.21437/Interspeech.2019-2848", 5, "interspeech", 2019]], "Volker Leutnant": [0, ["Acoustic Model Bootstrapping Using Semi-Supervised Learning", ["Langzhou Chen", "Volker Leutnant"], "https://doi.org/10.21437/Interspeech.2019-2818", 5, "interspeech", 2019]], "Steffen Schneider": [0, ["wav2vec: Unsupervised Pre-Training for Speech Recognition", ["Steffen Schneider", "Alexei Baevski", "Ronan Collobert", "Michael Auli"], "https://doi.org/10.21437/Interspeech.2019-1873", 5, "interspeech", 2019]], "Hao Ni": [0, ["A Path Signature Approach for Speech Emotion Recognition", ["Bo Wang", "Maria Liakata", "Hao Ni", "Terry Lyons", "Alejo J. Nevado-Holgado", "Kate Saunders"], "https://doi.org/10.21437/Interspeech.2019-2624", 5, "interspeech", 2019]], "Shuang Liang": [0, ["Cross-Lingual, Multi-Speaker Text-To-Speech Synthesis Using Neural Speaker Embedding", ["Mengnan Chen", "Minchuan Chen", "Shuang Liang", "Jun Ma", "Lei Chen", "Shaojun Wang", "Jing Xiao"], "https://doi.org/10.21437/Interspeech.2019-1632", 5, "interspeech", 2019]], "Yide Ma": [0, ["Speech Augmentation via Speaker-Specific Noise in Unseen Environment", ["Yanan Guo", "Ziping Zhao", "Yide Ma", "Bjorn W. Schuller"], "https://doi.org/10.21437/Interspeech.2019-2712", 5, "interspeech", 2019]], "Hirokazu Kameoka": [0, ["StarGAN-VC2: Rethinking Conditional Methods for StarGAN-Based Voice Conversion", ["Takuhiro Kaneko", "Hirokazu Kameoka", "Kou Tanaka", "Nobukatsu Hojo"], "https://doi.org/10.21437/Interspeech.2019-2236", 5, "interspeech", 2019], ["A Modified Algorithm for Multiple Input Spectrogram Inversion", ["Dongxiao Wang", "Hirokazu Kameoka", "Koichi Shinoda"], "https://doi.org/10.21437/Interspeech.2019-3242", 5, "interspeech", 2019]], "Mark Antoniou": [0, ["Cognitive Factors in Thai-Na\u00efve Mandarin Speakers' Imitation of Thai Lexical Tones", ["Juqiang Chen", "Catherine T. Best", "Mark Antoniou"], "https://doi.org/10.21437/Interspeech.2019-1403", 5, "interspeech", 2019]], "Gokce Keskin": [0, ["Semi-Supervised Voice Conversion with Amortized Variational Inference", ["Cory Stephenson", "Gokce Keskin", "Anil Thomas", "Oguz H. Elibol"], "https://doi.org/10.21437/Interspeech.2019-1840", 5, "interspeech", 2019]], "Jinming Zhao": [0, ["Speech Emotion Recognition in Dyadic Dialogues with Attentive Interaction Modeling", ["Jinming Zhao", "Shizhe Chen", "Jingjun Liang", "Qin Jin"], "https://doi.org/10.21437/Interspeech.2019-2103", 5, "interspeech", 2019]], "Jens Edlund": [0, ["How to Annotate 100 Hours in 45 Minutes", ["Per Fallgren", "Zofia Malisz", "Jens Edlund"], "https://doi.org/10.21437/Interspeech.2019-1648", 5, "interspeech", 2019], ["Spot the Pleasant People! Navigating the Cocktail Party Buzz", ["Christina Tannander", "Per Fallgren", "Jens Edlund", "Joakim Gusafsson"], "https://doi.org/10.21437/Interspeech.2019-1553", 5, "interspeech", 2019]], "Markus Reuber": [0, ["Automatic Hierarchical Attention Neural Network for Detecting AD", ["Yilin Pan", "Bahman Mirheidari", "Markus Reuber", "Annalena Venneri", "Daniel Blackburn", "Heidi Christensen"], "https://doi.org/10.21437/Interspeech.2019-1799", 5, "interspeech", 2019]], "Aline Villavicencio": [0, ["Empirical Evaluation of Sequence-to-Sequence Models for Word Discovery in Low-Resource Settings", ["Marcely Zanon Boito", "Aline Villavicencio", "Laurent Besacier"], "https://doi.org/10.21437/Interspeech.2019-2029", 5, "interspeech", 2019]], "Charlotte Dugrain": [0, ["The Zero Resource Speech Challenge 2019: TTS Without T", ["Ewan Dunbar", "Robin Algayres", "Julien Karadayi", "Mathieu Bernard", "Juan Benjumea", "Xuan-Nga Cao", "Lucie Miskic", "Charlotte Dugrain", "Lucas Ondel", "Alan W. Black", "Laurent Besacier", "Sakriani Sakti", "Emmanuel Dupoux"], "https://doi.org/10.21437/Interspeech.2019-2904", 5, "interspeech", 2019]], "Pradyoth Hegde": [0, ["NITK Kids' Speech Corpus", ["Pravin Bhaskar Ramteke", "Sujata Supanekar", "Pradyoth Hegde", "Hanna Nelson", "Venkataraja Aithal", "Shashidhar G. Koolagudi"], "https://doi.org/10.21437/Interspeech.2019-2061", 5, "interspeech", 2019]], "Chongyuan Lian": [0, ["Towards the Speech Features of Mild Cognitive Impairment: Universal Evidence from Structured and Unstructured Connected Speech of Chinese", ["Tianqi Wang", "Chongyuan Lian", "Jingshen Pan", "Quanlei Yan", "Feiqi Zhu", "Manwa L. Ng", "Lan Wang", "Nan Yan"], "https://doi.org/10.21437/Interspeech.2019-2414", 5, "interspeech", 2019]], "Jeroen van de Weijer": [0, ["Acoustic Characteristics of Lexical Tone Disruption in Mandarin Speakers After Brain Damage", ["Wenjun Chen", "Jeroen van de Weijer", "Shuangshuang Zhu", "Qian Qian", "Manna Wang"], "https://doi.org/10.21437/Interspeech.2019-2432", 5, "interspeech", 2019]], "Zhi Chen": [0, ["Neural Text Clustering with Document-Level Attention Based on Dynamic Soft Labels", ["Zhi Chen", "Wu Guo", "Li-Rong Dai", "Zhen-Hua Ling", "Jun Du"], "https://doi.org/10.21437/Interspeech.2019-1417", 5, "interspeech", 2019]], "Leijing Hou": [0, ["Code-Switching Sentence Generation by Bert and Generative Adversarial Networks", ["Yingying Gao", "Junlan Feng", "Ying Liu", "Leijing Hou", "Xin Pan", "Yong Ma"], "https://doi.org/10.21437/Interspeech.2019-2501", 5, "interspeech", 2019]], "Changmin Kim": [0.5, ["Shortcut Connections Based Deep Speaker Embeddings for End-to-End Speaker Verification System", ["Soonshin Seo", "Daniel Jun Rim", "Minkyu Lim", "Donghyun Lee", "Hosung Park", "Junseok Oh", "Changmin Kim", "Ji-Hwan Kim"], "https://doi.org/10.21437/Interspeech.2019-2195", 5, "interspeech", 2019]], "Jorge Civera": [0, ["Real-Time One-Pass Decoder for Speech Recognition Using LSTM Language Models", ["Javier Jorge", "Adria Gimenez", "Javier Iranzo-Sanchez", "Jorge Civera", "Albert Sanchis", "Alfons Juan"], "https://doi.org/10.21437/Interspeech.2019-2798", 5, "interspeech", 2019]], "Md. Sahidullah": [0, ["ASVspoof 2019: Future Horizons in Spoofed and Fake Audio Detection", ["Massimiliano Todisco", "Xin Wang", "Ville Vestman", "Md. Sahidullah", "Hector Delgado", "Andreas Nautsch", "Junichi Yamagishi", "Nicholas W. D. Evans", "Tomi H. Kinnunen", "Kong Aik Lee"], "https://doi.org/10.21437/Interspeech.2019-2249", 5, "interspeech", 2019]], "James Chan": [0, ["Use of Beiwe Smartphone App to Identify and Track Speech Decline in Amyotrophic Lateral Sclerosis (ALS)", ["Kathryn P. Connaghan", "Jordan R. Green", "Sabrina Paganoni", "James Chan", "Harli Weber", "Ella Collins", "Brian Richburg", "Marziye Eshghi", "Jukka-Pekka Onnela", "James D. Berry"], "https://doi.org/10.21437/Interspeech.2019-3126", 5, "interspeech", 2019]], "Najim Dehak": [0, ["MCE 2018: The 1st Multi-Target Speaker Detection and Identification Challenge Evaluation", ["Suwon Shon", "Najim Dehak", "Douglas A. Reynolds", "James R. Glass"], "https://doi.org/10.21437/Interspeech.2019-1572", 5, "interspeech", 2019], ["ASSERT: Anti-Spoofing with Squeeze-Excitation and Residual Networks", ["Cheng-I Lai", "Nanxin Chen", "Jesus Villalba", "Najim Dehak"], "https://doi.org/10.21437/Interspeech.2019-1794", 5, "interspeech", 2019], ["State-of-the-Art Speaker Recognition for Telephone and Video Speech: The JHU-MIT Submission for NIST SRE18", ["Jesus Villalba", "Nanxin Chen", "David Snyder", "Daniel Garcia-Romero", "Alan McCree", "Gregory Sell", "Jonas Borgstrom", "Fred Richardson", "Suwon Shon", "Francois Grondin", "Reda Dehak", "Leibny Paola Garcia-Perera", "Daniel Povey", "Pedro A. Torres-Carrasquillo", "Sanjeev Khudanpur", "Najim Dehak"], "https://doi.org/10.21437/Interspeech.2019-2713", 5, "interspeech", 2019], ["The JHU Speaker Recognition System for the VOiCES 2019 Challenge", ["David Snyder", "Jesus Villalba", "Nanxin Chen", "Daniel Povey", "Gregory Sell", "Najim Dehak", "Sanjeev Khudanpur"], "https://doi.org/10.21437/Interspeech.2019-2979", 5, "interspeech", 2019], ["Unsupervised Acoustic Segmentation and Clustering Using Siamese Network Embeddings", ["Saurabhchand Bhati", "Shekhar Nayak", "K. Sri Rama Murty", "Najim Dehak"], "https://doi.org/10.21437/Interspeech.2019-2981", 5, "interspeech", 2019], ["Tied Mixture of Factor Analyzers Layer to Combine Frame Level Representations in Neural Speaker Embeddings", ["Nanxin Chen", "Jesus Villalba", "Najim Dehak"], "https://doi.org/10.21437/Interspeech.2019-1782", 5, "interspeech", 2019], ["Study of the Performance of Automatic Speech Recognition Systems in Speakers with Parkinson's Disease", ["Laureano Moro-Velazquez", "Jaejin Cho", "Shinji Watanabe", "Mark A. Hasegawa-Johnson", "Odette Scharenborg", "Heejin Kim", "Najim Dehak"], "https://doi.org/10.21437/Interspeech.2019-2993", 5, "interspeech", 2019], ["Improving Emotion Identification Using Phone Posteriors in Raw Speech Waveform Based DNN", ["Mousmita Sarma", "Pegah Ghahremani", "Daniel Povey", "Nagendra Kumar Goel", "Kandarpa Kumar Sarma", "Najim Dehak"], "https://doi.org/10.21437/Interspeech.2019-2093", 5, "interspeech", 2019], ["Pretraining by Backtranslation for End-to-End ASR in Low-Resource Settings", ["Matthew Wiesner", "Adithya Renduchintala", "Shinji Watanabe", "Chunxi Liu", "Najim Dehak", "Sanjeev Khudanpur"], "https://doi.org/10.21437/Interspeech.2019-3254", 5, "interspeech", 2019]], "Venkata Srikanth Nallanthighal": [0, ["Deep Sensing of Breathing Signal During Conversational Speech", ["Venkata Srikanth Nallanthighal", "Aki Harma", "Helmer Strik"], "https://doi.org/10.21437/Interspeech.2019-1796", 5, "interspeech", 2019]], "Yilin Shen": [0, ["Iterative Delexicalization for Improved Spoken Language Understanding", ["Avik Ray", "Yilin Shen", "Hongxia Jin"], "https://doi.org/10.21437/Interspeech.2019-2955", 5, "interspeech", 2019], ["Interpreting and Improving Deep Neural SLU Models via Vocabulary Importance", ["Yilin Shen", "Wenhu Chen", "Hongxia Jin"], "https://doi.org/10.21437/Interspeech.2019-3184", 5, "interspeech", 2019]], "David Harwath": [0, ["Towards Bilingual Lexicon Discovery From Visually Grounded Speech Audio", ["Emmanuel Azuh", "David Harwath", "James R. Glass"], "https://doi.org/10.21437/Interspeech.2019-1718", 5, "interspeech", 2019], ["Transfer Learning from Audio-Visual Grounding to Speech Recognition", ["Wei-Ning Hsu", "David Harwath", "James R. Glass"], "https://doi.org/10.21437/Interspeech.2019-1227", 5, "interspeech", 2019]], "Gaofeng Cheng": [0, ["Online Hybrid CTC/Attention Architecture for End-to-End Speech Recognition", ["Haoran Miao", "Gaofeng Cheng", "Pengyuan Zhang", "Ta Li", "Yonghong Yan"], "https://doi.org/10.21437/Interspeech.2019-2018", 5, "interspeech", 2019]], "Jonathan M. Cohen": [0, ["Jasper: An End-to-End Convolutional Neural Acoustic Model", ["Jason Li", "Vitaly Lavrukhin", "Boris Ginsburg", "Ryan Leary", "Oleksii Kuchaiev", "Jonathan M. Cohen", "Huyen Nguyen", "Ravi Teja Gadde"], "https://doi.org/10.21437/Interspeech.2019-1819", 5, "interspeech", 2019]], "Chengqing Zong": [0, ["End-to-End Speech Translation with Knowledge Distillation", ["Yuchen Liu", "Hao Xiong", "Jiajun Zhang", "Zhongjun He", "Hua Wu", "Haifeng Wang", "Chengqing Zong"], "https://doi.org/10.21437/Interspeech.2019-2582", 5, "interspeech", 2019]], "Hangting Chen": [0, ["Speaker-Invariant Feature-Mapping for Distant Speech Recognition via Adversarial Teacher-Student Learning", ["Long Wu", "Hangting Chen", "Li Wang", "Pengyuan Zhang", "Yonghong Yan"], "https://doi.org/10.21437/Interspeech.2019-2136", 5, "interspeech", 2019]], "Wenjie Li": [0, ["Target Speaker Recovery and Recognition Network with Average x-Vector and Global Training", ["Wenjie Li", "Pengyuan Zhang", "Yonghong Yan"], "https://doi.org/10.21437/Interspeech.2019-1692", 5, "interspeech", 2019]], "Khazar Khorrami": [0, ["A Computational Model of Early Language Acquisition from Audiovisual Experiences of Young Infants", ["Okko Rasanen", "Khazar Khorrami"], "https://doi.org/10.21437/Interspeech.2019-1523", 5, "interspeech", 2019]], "Songxiang Liu": [0, ["Jointly Trained Conversion Model and WaveNet Vocoder for Non-Parallel Voice Conversion Using Mel-Spectrograms and Phonetic Posteriorgrams", ["Songxiang Liu", "Yuewen Cao", "Xixin Wu", "Lifa Sun", "Xunying Liu", "Helen Meng"], "https://doi.org/10.21437/Interspeech.2019-1316", 5, "interspeech", 2019]], "Emmett McQuinn": [0, ["WHAM!: Extending Speech Separation to Noisy Environments", ["Gordon Wichern", "Joe Antognini", "Michael Flynn", "Licheng Richard Zhu", "Emmett McQuinn", "Dwight Crow", "Ethan Manilow", "Jonathan Le Roux"], "https://doi.org/10.21437/Interspeech.2019-2821", 5, "interspeech", 2019]], "Nguyen Bach": [0, ["Noisy BiLSTM-Based Models for Disfluency Detection", ["Nguyen Bach", "Fei Huang"], "https://doi.org/10.21437/Interspeech.2019-1336", 5, "interspeech", 2019]], "Gabriele Chignoli": [0, ["Are IP Initial Vowels Acoustically More Distinct? Results from LDA and CNN Classifications", ["Fanny Guitard-Ivent", "Gabriele Chignoli", "Cecile Fougeron", "Laurianne Georgeton"], "https://doi.org/10.21437/Interspeech.2019-2153", 5, "interspeech", 2019]], "Shashwat Uttam": [0, ["Hush-Hush Speak: Speech Reconstruction Using Silent Videos", ["Shashwat Uttam", "Yaman Kumar", "Dhruva Sahrawat", "Mansi Aggarwal", "Rajiv Ratn Shah", "Debanjan Mahata", "Amanda Stent"], "https://doi.org/10.21437/Interspeech.2019-3269", 5, "interspeech", 2019]], "Jingyang Zhang": [0, ["Multi-Scale Time-Frequency Attention for Acoustic Event Detection", ["Jingyang Zhang", "Wenhao Ding", "Jintao Kang", "Liang He"], "https://doi.org/10.21437/Interspeech.2019-1587", 5, "interspeech", 2019]], "S. Prachi": [0, ["A Study of x-Vector Based Speaker Recognition on Short Utterances", ["Ahilan Kanagasundaram", "Sridha Sridharan", "Ganapathy Sriram", "S. Prachi", "Clinton Fookes"], "https://doi.org/10.21437/Interspeech.2019-1891", 5, "interspeech", 2019]], "Malu Zhang": [0, ["Robust Sound Recognition: A Neuromorphic Approach", ["Jibin Wu", "Zihan Pan", "Malu Zhang", "Rohan Kumar Das", "Yansong Chua", "Haizhou Li"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8032.html", 2, "interspeech", 2019]], "Pedro Sa-Couto": [0, ["Age-Related Changes in European Portuguese Vowel Acoustics", ["Luciana Albuquerque", "Catarina Oliveira", "Antonio J. S. Teixeira", "Pedro Sa-Couto", "Daniela Figueiredo"], "https://doi.org/10.21437/Interspeech.2019-1818", 5, "interspeech", 2019]], "Mingyang Zhang": [0, ["VQVAE Unsupervised Unit Discovery and Multi-Scale Code2Spec Inverter for Zerospeech Challenge 2019", ["Andros Tjandra", "Berrak Sisman", "Mingyang Zhang", "Sakriani Sakti", "Haizhou Li", "Satoshi Nakamura"], "https://doi.org/10.21437/Interspeech.2019-3232", 5, "interspeech", 2019], ["Joint Training Framework for Text-to-Speech and Voice Conversion Using Multi-Source Tacotron and WaveNet", ["Mingyang Zhang", "Xin Wang", "Fuming Fang", "Haizhou Li", "Junichi Yamagishi"], "https://doi.org/10.21437/Interspeech.2019-1357", 5, "interspeech", 2019]], "Qiongqiong Wang": [1.7704599993093734e-13, ["The NEC-TT 2018 Speaker Verification System", ["Kong Aik Lee", "Hitoshi Yamamoto", "Koji Okabe", "Qiongqiong Wang", "Ling Guo", "Takafumi Koshinaka", "Jiacen Zhang", "Koichi Shinoda"], "https://doi.org/10.21437/Interspeech.2019-1517", 5, "interspeech", 2019]], "Maria Julia Carbajal": [0, ["Liquid Deletion in French Child-Directed Speech", ["Sharon Peperkamp", "Monica Hegde", "Maria Julia Carbajal"], "https://doi.org/10.21437/Interspeech.2019-2838", 5, "interspeech", 2019]], "Xianyun Wang": [6.437032880057814e-07, ["Masking Estimation with Phase Restoration of Clean Speech for Monaural Speech Enhancement", ["Xianyun Wang", "Changchun Bao"], "https://doi.org/10.21437/Interspeech.2019-1141", 5, "interspeech", 2019]], "Antonio Miguel": [0, ["ViVoLAB Speaker Diarization System for the DIHARD 2019 Challenge", ["Ignacio Vinals", "Pablo Gimeno", "Alfonso Ortega Gimenez", "Antonio Miguel", "Eduardo Lleida"], "https://doi.org/10.21437/Interspeech.2019-2462", 5, "interspeech", 2019], ["Speech Enhancement with Wide Residual Networks in Reverberant Environments", ["Jorge Llombart", "Dayana Ribas", "Antonio Miguel", "Luis Vicente", "Alfonso Ortega Gimenez", "Eduardo Lleida"], "https://doi.org/10.21437/Interspeech.2019-1745", 5, "interspeech", 2019], ["Optimization of False Acceptance/Rejection Rates and Decision Threshold for End-to-End Text-Dependent Speaker Verification Systems", ["Victoria Mingote", "Antonio Miguel", "Dayana Ribas", "Alfonso Ortega Gimenez", "Eduardo Lleida"], "https://doi.org/10.21437/Interspeech.2019-2550", 5, "interspeech", 2019], ["Progressive Speech Enhancement with Residual Connections", ["Jorge Llombart", "Dayana Ribas", "Antonio Miguel", "Luis Vicente", "Alfonso Ortega Gimenez", "Eduardo Lleida"], "https://doi.org/10.21437/Interspeech.2019-1748", 5, "interspeech", 2019], ["Language Recognition Using Triplet Neural Networks", ["Victoria Mingote", "Diego Castan", "Mitchell McLaren", "Mahesh Kumar Nandwana", "Alfonso Ortega Gimenez", "Eduardo Lleida", "Antonio Miguel"], "https://doi.org/10.21437/Interspeech.2019-2437", 5, "interspeech", 2019], ["Phonetically-Aware Embeddings, Wide Residual Networks with Time-Delay Neural Networks and Self Attention Models for the 2018 NIST Speaker Recognition Evaluation", ["Ignacio Vinals", "Dayana Ribas", "Victoria Mingote", "Jorge Llombart", "Pablo Gimeno", "Antonio Miguel", "Alfonso Ortega Gimenez", "Eduardo Lleida"], "https://doi.org/10.21437/Interspeech.2019-2417", 5, "interspeech", 2019]], "Mads G. Christensen": [0, ["Validation of the Non-Intrusive Codebook-Based Short Time Objective Intelligibility Metric for Processed Speech", ["Charlotte Sorensen", "Jesper B. Boldt", "Mads G. Christensen"], "https://doi.org/10.21437/Interspeech.2019-1625", 5, "interspeech", 2019]], "Thomas Kisler": [0, ["Styrian Dialect Classification: Comparing and Fusing Classifiers Based on a Feature Selection Using a Genetic Algorithm", ["Thomas Kisler", "Raphael Winkelmann", "Florian Schiel"], "https://doi.org/10.21437/Interspeech.2019-2540", 5, "interspeech", 2019], ["BAS Web Services for Automatic Subtitle Creation and Anonymization", ["Florian Schiel", "Thomas Kisler"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8001.html", 2, "interspeech", 2019]], "Deepti Bhatia": [0, ["Shallow-Fusion End-to-End Contextual Biasing", ["Ding Zhao", "Tara N. Sainath", "David Rybach", "Pat Rondon", "Deepti Bhatia", "Bo Li", "Ruoming Pang"], "https://doi.org/10.21437/Interspeech.2019-1209", 5, "interspeech", 2019]], "Santiago Barreda": [0, ["The Role of Musical Experience in the Perceptual Weighting of Acoustic Cues for the Obstruent Coda Voicing Contrast in American English", ["Michelle Cohn", "Georgia Zellou", "Santiago Barreda"], "https://doi.org/10.21437/Interspeech.2019-3103", 5, "interspeech", 2019]], "Qiao Liang": [0, ["Two-Pass End-to-End Speech Recognition", ["Tara N. Sainath", "Ruoming Pang", "David Rybach", "Yanzhang He", "Rohit Prabhavalkar", "Wei Li", "Mirko Visontai", "Qiao Liang", "Trevor Strohman", "Yonghui Wu", "Ian McGraw", "Chung-Cheng Chiu"], "https://doi.org/10.21437/Interspeech.2019-1341", 5, "interspeech", 2019]], "Eugene Weinstein": [0, ["Large-Scale Multilingual Speech Recognition with a Streaming End-to-End Model", ["Anjuli Kannan", "Arindrima Datta", "Tara N. Sainath", "Eugene Weinstein", "Bhuvana Ramabhadran", "Yonghui Wu", "Ankur Bapna", "Zhifeng Chen", "Seungji Lee"], "https://doi.org/10.21437/Interspeech.2019-2858", 5, "interspeech", 2019]], "Linda Taschenberger": [0, ["Subjective Evaluation of Communicative Effort for Younger and Older Adults in Interactive Tasks with Energetic and Informational Masking", ["Valerie Hazan", "Outi Tuomainen", "Linda Taschenberger"], "https://doi.org/10.21437/Interspeech.2019-2215", 5, "interspeech", 2019]], "Sam Tilsen": [0, ["Strength and Structure: Coupling Tones with Oral Constriction Gestures", ["Doris Mucke", "Anne Hermes", "Sam Tilsen"], "https://doi.org/10.21437/Interspeech.2019-2650", 5, "interspeech", 2019]], "Joseph Keshet": [0, ["Dr.VOT: Measuring Positive and Negative Voice Onset Time in the Wild", ["Yosi Shrem", "Matthew Goldrick", "Joseph Keshet"], "https://doi.org/10.21437/Interspeech.2019-1735", 5, "interspeech", 2019], ["SpeechYOLO: Detection and Localization of Speech Objects", ["Yael Segal", "Tzeviya Sylvia Fuchs", "Joseph Keshet"], "https://doi.org/10.21437/Interspeech.2019-1749", 5, "interspeech", 2019]], "Andrei Andrusenko": [0, ["R-Vectors: New Technique for Adaptation to Room Acoustics", ["Yuri Y. Khokhlov", "Alexander Zatvornitskiy", "Ivan Medennikov", "Ivan Sorokin", "Tatiana Prisyach", "Aleksei Romanenko", "Anton Mitrofanov", "Vladimir Bataev", "Andrei Andrusenko", "Mariya Korenevskaya", "Oleg Petrov"], "https://doi.org/10.21437/Interspeech.2019-2645", 5, "interspeech", 2019], ["The STC ASR System for the VOiCES from a Distance Challenge 2019", ["Ivan Medennikov", "Yuri Y. Khokhlov", "Aleksei Romanenko", "Ivan Sorokin", "Anton Mitrofanov", "Vladimir Bataev", "Andrei Andrusenko", "Tatiana Prisyach", "Mariya Korenevskaya", "Oleg Petrov", "Alexander Zatvornitskiy"], "https://doi.org/10.21437/Interspeech.2019-1574", 5, "interspeech", 2019], ["The STC ASR System for the VOiCES from a Distance Challenge 2019", ["Ivan Medennikov", "Yuri Y. Khokhlov", "Aleksei Romanenko", "Ivan Sorokin", "Anton Mitrofanov", "Vladimir Bataev", "Andrei Andrusenko", "Tatiana Prisyach", "Mariya Korenevskaya", "Oleg Petrov", "Alexander Zatvornitskiy"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/abs17.html", 0, "interspeech", 2019]], "Gautam Mantena": [0, ["Bandwidth Embeddings for Mixed-Bandwidth Speech Recognition", ["Gautam Mantena", "Ozlem Kalinli", "Ossama Abdel-Hamid", "Don McAllaster"], "https://doi.org/10.21437/Interspeech.2019-2589", 5, "interspeech", 2019]], "Karyna Isaieva": [0, ["Towards a Method of Dynamic Vocal Tract Shapes Generation by Combining Static 3D and Dynamic 2D MRI Speech Data", ["Ioannis K. Douros", "Anastasiia Tsukanova", "Karyna Isaieva", "Pierre-Andre Vuissoz", "Yves Laprie"], "https://doi.org/10.21437/Interspeech.2019-2880", 5, "interspeech", 2019], ["A Multimodal Real-Time MRI Articulatory Corpus of French for Speech Research", ["Ioannis K. Douros", "Jacques Felblinger", "Jens Frahm", "Karyna Isaieva", "Arun A. Joseph", "Yves Laprie", "Freddy Odille", "Anastasiia Tsukanova", "Dirk Voit", "Pierre-Andre Vuissoz"], "https://doi.org/10.21437/Interspeech.2019-1700", 5, "interspeech", 2019]], "Hoirin Kim": [0.12472110986709595, ["Spatial Pyramid Encoding with Convex Length Normalization for Text-Independent Speaker Verification", ["Youngmoon Jung", "Younggwan Kim", "Hyungjun Lim", "Yeunju Choi", "Hoirin Kim"], "https://doi.org/10.21437/Interspeech.2019-2177", 5, "interspeech", 2019]], "Oldrich Plchot": [0, ["On the Usage of Phonetic Information for Text-Independent Speaker Embedding Extraction", ["Shuai Wang", "Johan Rohdin", "Lukas Burget", "Oldrich Plchot", "Yanmin Qian", "Kai Yu", "Jan Cernocky"], "https://doi.org/10.21437/Interspeech.2019-3036", 5, "interspeech", 2019], ["Analysis of BUT Submission in Far-Field Scenarios of VOiCES 2019 Challenge", ["Pavel Matejka", "Oldrich Plchot", "Hossein Zeinali", "Ladislav Mosner", "Anna Silnova", "Lukas Burget", "Ondrej Novotny", "Ondrej Glembek"], "https://doi.org/10.21437/Interspeech.2019-2471", 5, "interspeech", 2019], ["Analysis of BUT Submission in Far-Field Scenarios of VOiCES 2019 Challenge", ["Pavel Matejka", "Oldrich Plchot", "Hossein Zeinali", "Ladislav Mosner", "Anna Silnova", "Lukas Burget", "Ondrej Novotny", "Ondrej Glembek"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/abs16.html", 0, "interspeech", 2019], ["Self-Supervised Speaker Embeddings", ["Themos Stafylakis", "Johan Rohdin", "Oldrich Plchot", "Petr Mizera", "Lukas Burget"], "https://doi.org/10.21437/Interspeech.2019-2842", 5, "interspeech", 2019], ["Factorization of Discriminatively Trained i-Vector Extractor for Speaker Recognition", ["Ondrej Novotny", "Oldrich Plchot", "Ondrej Glembek", "Lukas Burget"], "https://doi.org/10.21437/Interspeech.2019-1757", 5, "interspeech", 2019]], "Konstantinos Vougioukas": [0, ["Video-Driven Speech Reconstruction Using Generative Adversarial Networks", ["Konstantinos Vougioukas", "Pingchuan Ma", "Stavros Petridis", "Maja Pantic"], "https://doi.org/10.21437/Interspeech.2019-1445", 5, "interspeech", 2019]], "Qiang Gao": [0, ["ToneNet: A CNN Model of Tone Classification of Mandarin Chinese", ["Qiang Gao", "Shutao Sun", "Yaping Yang"], "https://doi.org/10.21437/Interspeech.2019-1483", 5, "interspeech", 2019]], "Seungwoo Choi": [0.9979142248630524, ["Temporal Convolution for Real-Time Keyword Spotting on Mobile Devices", ["Seungwoo Choi", "Seokjun Seo", "Beomjun Shin", "Hyeongmin Byun", "Martin Kersner", "Beomsu Kim", "Dongyoung Kim", "Sungjoo Ha"], "https://doi.org/10.21437/Interspeech.2019-1363", 5, "interspeech", 2019]], "Insoo Oh": [0.9920652210712433, ["Robust Keyword Spotting via Recycle-Pooling for Mobile Game", ["Shounan An", "Youngsoo Kim", "Hu Xu", "Jinwoo Lee", "Myungwoo Lee", "Insoo Oh"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8010.html", 2, "interspeech", 2019]], "Ladislav Lenc": [0, ["Multi-Lingual Dialogue Act Recognition with Deep Learning Methods", ["Jiri Martinek", "Pavel Kral", "Ladislav Lenc", "Christophe Cerisara"], "https://doi.org/10.21437/Interspeech.2019-1691", 5, "interspeech", 2019]], "Jesus Villalba": [0, ["ASSERT: Anti-Spoofing with Squeeze-Excitation and Residual Networks", ["Cheng-I Lai", "Nanxin Chen", "Jesus Villalba", "Najim Dehak"], "https://doi.org/10.21437/Interspeech.2019-1794", 5, "interspeech", 2019], ["State-of-the-Art Speaker Recognition for Telephone and Video Speech: The JHU-MIT Submission for NIST SRE18", ["Jesus Villalba", "Nanxin Chen", "David Snyder", "Daniel Garcia-Romero", "Alan McCree", "Gregory Sell", "Jonas Borgstrom", "Fred Richardson", "Suwon Shon", "Francois Grondin", "Reda Dehak", "Leibny Paola Garcia-Perera", "Daniel Povey", "Pedro A. Torres-Carrasquillo", "Sanjeev Khudanpur", "Najim Dehak"], "https://doi.org/10.21437/Interspeech.2019-2713", 5, "interspeech", 2019], ["The JHU Speaker Recognition System for the VOiCES 2019 Challenge", ["David Snyder", "Jesus Villalba", "Nanxin Chen", "Daniel Povey", "Gregory Sell", "Najim Dehak", "Sanjeev Khudanpur"], "https://doi.org/10.21437/Interspeech.2019-2979", 5, "interspeech", 2019], ["Tied Mixture of Factor Analyzers Layer to Combine Frame Level Representations in Neural Speaker Embeddings", ["Nanxin Chen", "Jesus Villalba", "Najim Dehak"], "https://doi.org/10.21437/Interspeech.2019-1782", 5, "interspeech", 2019]], "Sakriani Sakti": [0, ["The Zero Resource Speech Challenge 2019: TTS Without T", ["Ewan Dunbar", "Robin Algayres", "Julien Karadayi", "Mathieu Bernard", "Juan Benjumea", "Xuan-Nga Cao", "Lucie Miskic", "Charlotte Dugrain", "Lucas Ondel", "Alan W. Black", "Laurent Besacier", "Sakriani Sakti", "Emmanuel Dupoux"], "https://doi.org/10.21437/Interspeech.2019-2904", 5, "interspeech", 2019], ["VQVAE Unsupervised Unit Discovery and Multi-Scale Code2Spec Inverter for Zerospeech Challenge 2019", ["Andros Tjandra", "Berrak Sisman", "Mingyang Zhang", "Sakriani Sakti", "Haizhou Li", "Satoshi Nakamura"], "https://doi.org/10.21437/Interspeech.2019-3232", 5, "interspeech", 2019], ["Speech Quality Evaluation of Synthesized Japanese Speech Using EEG", ["Ivan Halim Parmonangan", "Hiroki Tanaka", "Sakriani Sakti", "Shinnosuke Takamichi", "Satoshi Nakamura"], "https://doi.org/10.21437/Interspeech.2019-2059", 5, "interspeech", 2019], ["Sequence-to-Sequence Learning via Attention Transfer for Incremental Speech Recognition", ["Sashi Novitasari", "Andros Tjandra", "Sakriani Sakti", "Satoshi Nakamura"], "https://doi.org/10.21437/Interspeech.2019-2985", 5, "interspeech", 2019]], "Maria Auxiliadora Barrios": [0, ["The VOiCES from a Distance Challenge 2019", ["Mahesh Kumar Nandwana", "Julien van Hout", "Colleen Richey", "Mitchell McLaren", "Maria Auxiliadora Barrios", "Aaron Lawson"], "https://doi.org/10.21437/Interspeech.2019-1837", 5, "interspeech", 2019]], "Peijie Huang": [0, ["Latent Topic Attention for Domain Classification", ["Peisong Huang", "Peijie Huang", "Wencheng Ai", "Jiande Ding", "Jinchuan Zhang"], "https://doi.org/10.21437/Interspeech.2019-2228", 5, "interspeech", 2019]], "Fang Hu": [0, ["Frication as a Vowel Feature? - Evidence from the Rui'an Wu Chinese Dialect", ["Fang Hu", "Youjue He"], "https://doi.org/10.21437/Interspeech.2019-1134", 5, "interspeech", 2019], ["Vowels and Diphthongs in the Xupu Xiang Chinese Dialect", ["Zhenrui Zhang", "Fang Hu"], "https://doi.org/10.21437/Interspeech.2019-1174", 5, "interspeech", 2019]], "Hao Wang": [0.05930156260728836, ["Fast Learning for Non-Parallel Many-to-Many Voice Conversion with Residual Star Generative Adversarial Networks", ["Shengkui Zhao", "Trung Hieu Nguyen", "Hao Wang", "Bin Ma"], "https://doi.org/10.21437/Interspeech.2019-2067", 5, "interspeech", 2019]], "Stefanos Laskaridis": [0, ["ShrinkML: End-to-End ASR Model Compression Using Reinforcement Learning", ["Lukasz Dudziak", "Mohamed S. Abdelfattah", "Ravichander Vipperla", "Stefanos Laskaridis", "Nicholas D. Lane"], "https://doi.org/10.21437/Interspeech.2019-2811", 5, "interspeech", 2019]], "Meng-Han Lin": [0, ["Using Attention Networks and Adversarial Augmentation for Styrian Dialect Continuous Sleepiness and Baby Sound Recognition", ["Sung-Lin Yeh", "Gao-Yi Chao", "Bo-Hao Su", "Yu-Lin Huang", "Meng-Han Lin", "Yin-Chun Tsai", "Yu-Wen Tai", "Zheng-Chi Lu", "Chieh-Yu Chen", "Tsung-Ming Tai", "Chiu-Wang Tseng", "Cheng-Kuang Lee", "Chi-Chun Lee"], "https://doi.org/10.21437/Interspeech.2019-2110", 5, "interspeech", 2019]], "Yingming Gao": [0, ["Articulatory Copy Synthesis Based on a Genetic Algorithm", ["Yingming Gao", "Simon Stone", "Peter Birkholz"], "https://doi.org/10.21437/Interspeech.2019-1334", 5, "interspeech", 2019]], "Yoshikazu Yamaguchi": [0, ["Neural Whispered Speech Detection with Imbalanced Learning", ["Takanori Ashihara", "Yusuke Shinohara", "Hiroshi Sato", "Takafumi Moriya", "Kiyoaki Matsui", "Takaaki Fukutomi", "Yoshikazu Yamaguchi", "Yushi Aono"], "https://doi.org/10.21437/Interspeech.2019-2161", 5, "interspeech", 2019], ["Joint Maximization Decoder with Neural Converters for Fully Neural Network-Based Japanese Speech Recognition", ["Takafumi Moriya", "Jian Wang", "Tomohiro Tanaka", "Ryo Masumura", "Yusuke Shinohara", "Yoshikazu Yamaguchi", "Yushi Aono"], "https://doi.org/10.21437/Interspeech.2019-1558", 5, "interspeech", 2019]], "Jerome Farinas": [0, ["The Airbus Air Traffic Control Speech Recognition 2018 Challenge: Towards ATC Automatic Transcription and Call Sign Detection", ["Thomas Pellegrini", "Jerome Farinas", "Estelle Delpech", "Francois Lancelot"], "https://doi.org/10.21437/Interspeech.2019-1962", 5, "interspeech", 2019]], "Elif Eyigoz": [0, ["A New Approach for Automating Analysis of Responses on Verbal Fluency Tests from Subjects At-Risk for Schizophrenia", ["Mary Pietrowicz", "Carla Agurto", "Raquel Norel", "Elif Eyigoz", "Guillermo A. Cecchi", "Zarina R. Bilgrami", "Cheryl Corcoran"], "https://doi.org/10.21437/Interspeech.2019-2987", 5, "interspeech", 2019]], "Chang-Bin Jeon": [0.6679591983556747, ["Adversarially Trained End-to-End Korean Singing Voice Synthesis System", ["Juheon Lee", "Hyeong-Seok Choi", "Chang-Bin Jeon", "Junghyun Koo", "Kyogu Lee"], "https://doi.org/10.21437/Interspeech.2019-1722", 5, "interspeech", 2019]], "Bowen Zhou": [0, ["Speaker Diarization with Lexical Information", ["Tae Jin Park", "Kyu J. Han", "Jing Huang", "Xiaodong He", "Bowen Zhou", "Panayiotis G. Georgiou", "Shrikanth Narayanan"], "https://doi.org/10.21437/Interspeech.2019-1947", 5, "interspeech", 2019], ["Direct-Path Signal Cross-Correlation Estimation for Sound Source Localization in Reverberation", ["Wei Xue", "Ying Tong", "Guohong Ding", "Chao Zhang", "Tao Ma", "Xiaodong He", "Bowen Zhou"], "https://doi.org/10.21437/Interspeech.2019-1488", 5, "interspeech", 2019], ["Multi-Stride Self-Attention for Speech Recognition", ["Kyu J. Han", "Jing Huang", "Yun Tang", "Xiaodong He", "Bowen Zhou"], "https://doi.org/10.21437/Interspeech.2019-1973", 5, "interspeech", 2019]], "Azaria Cohen": [0, ["A Storyteller's Tale: Literature Audiobooks Genre Classification Using CNN and RNN Architectures", ["Nehory Carmi", "Azaria Cohen", "Mireille Avigal", "Anat Lerner"], "https://doi.org/10.21437/Interspeech.2019-1154", 4, "interspeech", 2019]], "Tara N. Sainath": [0, ["Shallow-Fusion End-to-End Contextual Biasing", ["Ding Zhao", "Tara N. Sainath", "David Rybach", "Pat Rondon", "Deepti Bhatia", "Bo Li", "Ruoming Pang"], "https://doi.org/10.21437/Interspeech.2019-1209", 5, "interspeech", 2019], ["Large-Scale Multilingual Speech Recognition with a Streaming End-to-End Model", ["Anjuli Kannan", "Arindrima Datta", "Tara N. Sainath", "Eugene Weinstein", "Bhuvana Ramabhadran", "Yonghui Wu", "Ankur Bapna", "Zhifeng Chen", "Seungji Lee"], "https://doi.org/10.21437/Interspeech.2019-2858", 5, "interspeech", 2019], ["Phoneme-Based Contextualization for Cross-Lingual Speech Recognition in End-to-End Models", ["Ke Hu", "Antoine Bruguier", "Tara N. Sainath", "Rohit Prabhavalkar", "Golan Pundak"], "https://doi.org/10.21437/Interspeech.2019-1868", 5, "interspeech", 2019], ["Improving Performance of End-to-End ASR on Numeric Sequences", ["Cal Peyser", "Hao Zhang", "Tara N. Sainath", "Zelin Wu"], "https://doi.org/10.21437/Interspeech.2019-1345", 5, "interspeech", 2019], ["Two-Pass End-to-End Speech Recognition", ["Tara N. Sainath", "Ruoming Pang", "David Rybach", "Yanzhang He", "Rohit Prabhavalkar", "Wei Li", "Mirko Visontai", "Qiao Liang", "Trevor Strohman", "Yonghui Wu", "Ian McGraw", "Chung-Cheng Chiu"], "https://doi.org/10.21437/Interspeech.2019-1341", 5, "interspeech", 2019]], "Heinrich Dinkel": [0, ["The SJTU Robust Anti-Spoofing System for the ASVspoof 2019 Challenge", ["Yexin Yang", "Hongji Wang", "Heinrich Dinkel", "Zhengyang Chen", "Shuai Wang", "Yanmin Qian", "Kai Yu"], "https://doi.org/10.21437/Interspeech.2019-2170", 5, "interspeech", 2019], ["Cross-Domain Replay Spoofing Attack Detection Using Domain Adversarial Training", ["Hongji Wang", "Heinrich Dinkel", "Shuai Wang", "Yanmin Qian", "Kai Yu"], "https://doi.org/10.21437/Interspeech.2019-2120", 5, "interspeech", 2019]], "Chiu-Wang Tseng": [0, ["Using Attention Networks and Adversarial Augmentation for Styrian Dialect Continuous Sleepiness and Baby Sound Recognition", ["Sung-Lin Yeh", "Gao-Yi Chao", "Bo-Hao Su", "Yu-Lin Huang", "Meng-Han Lin", "Yin-Chun Tsai", "Yu-Wen Tai", "Zheng-Chi Lu", "Chieh-Yu Chen", "Tsung-Ming Tai", "Chiu-Wang Tseng", "Cheng-Kuang Lee", "Chi-Chun Lee"], "https://doi.org/10.21437/Interspeech.2019-2110", 5, "interspeech", 2019]], "Zhiyong Wu": [4.808835365111008e-05, ["One-Shot Voice Conversion with Global Speaker Embeddings", ["Hui Lu", "Zhiyong Wu", "Dongyang Dai", "Runnan Li", "Shiyin Kang", "Jia Jia", "Helen Meng"], "https://doi.org/10.21437/Interspeech.2019-2365", 5, "interspeech", 2019], ["Disambiguation of Chinese Polyphones in an End-to-End Framework with Semantic Features Extracted by Pre-Trained BERT", ["Dongyang Dai", "Zhiyong Wu", "Shiyin Kang", "Xixin Wu", "Jia Jia", "Dan Su", "Dong Yu", "Helen Meng"], "https://doi.org/10.21437/Interspeech.2019-2292", 5, "interspeech", 2019], ["Knowledge-Based Linguistic Encoding for End-to-End Mandarin Text-to-Speech Synthesis", ["Jingbei Li", "Zhiyong Wu", "Runnan Li", "Pengpeng Zhi", "Song Yang", "Helen Meng"], "https://doi.org/10.21437/Interspeech.2019-1118", 5, "interspeech", 2019]], "Fadi Biadsy": [0, ["Direct Speech-to-Speech Translation with a Sequence-to-Sequence Model", ["Ye Jia", "Ron J. Weiss", "Fadi Biadsy", "Wolfgang Macherey", "Melvin Johnson", "Zhifeng Chen", "Yonghui Wu"], "https://doi.org/10.21437/Interspeech.2019-1951", 5, "interspeech", 2019], ["Parrotron: An End-to-End Speech-to-Speech Conversion Model and its Applications to Hearing-Impaired Speech and Speech Separation", ["Fadi Biadsy", "Ron J. Weiss", "Pedro J. Moreno", "Dimitri Kanvesky", "Ye Jia"], "https://doi.org/10.21437/Interspeech.2019-1789", 5, "interspeech", 2019]], "Xuankai Chang": [1.0287378045779894e-12, ["Knowledge Distillation for End-to-End Monaural Multi-Talker ASR System", ["Wangyou Zhang", "Xuankai Chang", "Yanmin Qian"], "https://doi.org/10.21437/Interspeech.2019-3192", 5, "interspeech", 2019]], "Nelson Enrique Yalta Soplin": [0, ["Improving Transformer-Based End-to-End Speech Recognition with Connectionist Temporal Classification and Language Model Integration", ["Shigeki Karita", "Nelson Enrique Yalta Soplin", "Shinji Watanabe", "Marc Delcroix", "Atsunori Ogawa", "Tomohiro Nakatani"], "https://doi.org/10.21437/Interspeech.2019-1938", 5, "interspeech", 2019]], "Qing-Yuan Jiang": [0, ["Deep Hashing for Speaker Identification and Retrieval", ["Lei Fan", "Qing-Yuan Jiang", "Ya-Qi Yu", "Wu-Jun Li"], "https://doi.org/10.21437/Interspeech.2019-2457", 5, "interspeech", 2019]], "Mateusz Matuszewski": [0, ["Robust Bayesian and Light Neural Networks for Voice Spoofing Detection", ["Radoslaw Bialobrzeski", "Michal Kosmider", "Mateusz Matuszewski", "Marcin Plata", "Alexander Rakowski"], "https://doi.org/10.21437/Interspeech.2019-2676", 5, "interspeech", 2019]], "Ming Sun": [0.0060784968081861734, ["Sub-Band Convolutional Neural Networks for Small-Footprint Spoken Term Classification", ["Chieh-Chi Kao", "Ming Sun", "Yixin Gao", "Shiv Vitaladevuni", "Chao Wang"], "https://doi.org/10.21437/Interspeech.2019-1766", 5, "interspeech", 2019], ["Compression of Acoustic Event Detection Models with Quantized Distillation", ["Bowen Shi", "Ming Sun", "Chieh-Chi Kao", "Viktor Rozgic", "Spyros Matsoukas", "Chao Wang"], "https://doi.org/10.21437/Interspeech.2019-1747", 5, "interspeech", 2019]], "Li Chai": [0, ["Acoustic Model Ensembling Using Effective Data Augmentation for CHiME-5 Challenge", ["Feng Ma", "Li Chai", "Jun Du", "Diyuan Liu", "Zhongfu Ye", "Chin-Hui Lee"], "https://doi.org/10.21437/Interspeech.2019-2601", 5, "interspeech", 2019], ["KL-Divergence Regularized Deep Neural Network Adaptation for Low-Resource Speaker-Dependent Speech Enhancement", ["Li Chai", "Jun Du", "Chin-Hui Lee"], "https://doi.org/10.21437/Interspeech.2019-2426", 5, "interspeech", 2019], ["A Cross-Entropy-Guided (CEG) Measure for Speech Enhancement Front-End Assessing Performances of Back-End Automatic Speech Recognition", ["Li Chai", "Jun Du", "Chin-Hui Lee"], "https://doi.org/10.21437/Interspeech.2019-2511", 5, "interspeech", 2019]], "Michael A. Riley": [0, ["Using Ultrasound Imaging to Create Augmented Visual Biofeedback for Articulatory Practice", ["Colin T. Annand", "Maurice Lamb", "Sarah Dugan", "Sarah R. Li", "Hannah M. Woeste", "T. Douglas Mast", "Michael A. Riley", "Jack A. Masterson", "Neeraja Mahalingam", "Kathryn J. Eary", "Caroline Spencer", "Suzanne Boyce", "Stephanie Jackson", "Anoosha Baxi", "Renee Seward"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8036.html", 2, "interspeech", 2019]], "Okko Rasanen": [0, ["Augmented CycleGANs for Continuous Scale Normal-to-Lombard Speaking Style Conversion", ["Shreyas Seshadri", "Lauri Juvela", "Paavo Alku", "Okko Rasanen"], "https://doi.org/10.21437/Interspeech.2019-1681", 5, "interspeech", 2019], ["A Computational Model of Early Language Acquisition from Audiovisual Experiences of Young Infants", ["Okko Rasanen", "Khazar Khorrami"], "https://doi.org/10.21437/Interspeech.2019-1523", 5, "interspeech", 2019]], "Sang-Hun Kim": [0.9204378575086594, ["Extending an Acoustic Data-Driven Phone Set for Spontaneous Speech Recognition", ["Jeong-Uk Bang", "Mu-Yeol Choi", "Sang-Hun Kim", "Oh-Wook Kwon"], "https://doi.org/10.21437/Interspeech.2019-1979", 5, "interspeech", 2019]], "Matthew Goldrick": [0, ["Dr.VOT: Measuring Positive and Negative Voice Onset Time in the Wild", ["Yosi Shrem", "Matthew Goldrick", "Joseph Keshet"], "https://doi.org/10.21437/Interspeech.2019-1735", 5, "interspeech", 2019]], "Ke Tan": [0, ["Bridging the Gap Between Monaural Speech Enhancement and Recognition with Distortion-Independent Acoustic Modeling", ["Peidong Wang", "Ke Tan", "DeLiang Wang"], "https://doi.org/10.21437/Interspeech.2019-1495", 5, "interspeech", 2019], ["Deep Learning for Joint Acoustic Echo and Noise Cancellation with Nonlinear Distortions", ["Hao Zhang", "Ke Tan", "DeLiang Wang"], "https://doi.org/10.21437/Interspeech.2019-2651", 5, "interspeech", 2019]], "Wu-Jun Li": [0, ["Deep Hashing for Speaker Identification and Retrieval", ["Lei Fan", "Qing-Yuan Jiang", "Ya-Qi Yu", "Wu-Jun Li"], "https://doi.org/10.21437/Interspeech.2019-2457", 5, "interspeech", 2019]], "Hyeon Seung Lee": [0.999962717294693, ["End-to-End Multi-Channel Speech Enhancement Using Inter-Channel Time-Restricted Attention on Raw Waveform", ["Hyeon Seung Lee", "Hyung Yong Kim", "Woo Hyun Kang", "Jeunghun Kim", "Nam Soo Kim"], "https://doi.org/10.21437/Interspeech.2019-2397", 5, "interspeech", 2019]], "Jazmin Vidal": [0, ["EpaDB: A Database for Development of Pronunciation Assessment Systems", ["Jazmin Vidal", "Luciana Ferrer", "Leonardo Brambilla"], "https://doi.org/10.21437/Interspeech.2019-1839", 5, "interspeech", 2019]], "Jian Wang": [0.40413545072078705, ["Joint Maximization Decoder with Neural Converters for Fully Neural Network-Based Japanese Speech Recognition", ["Takafumi Moriya", "Jian Wang", "Tomohiro Tanaka", "Ryo Masumura", "Yusuke Shinohara", "Yoshikazu Yamaguchi", "Yushi Aono"], "https://doi.org/10.21437/Interspeech.2019-1558", 5, "interspeech", 2019]], "Zhiqiang Huang": [0, ["A Mandarin Prosodic Boundary Prediction Model Based on Multi-Task Learning", ["Huashan Pan", "Xiulin Li", "Zhiqiang Huang"], "https://doi.org/10.21437/Interspeech.2019-1400", 4, "interspeech", 2019]], "David A. Braude": [0, ["All Together Now: The Living Audio Dataset", ["David A. Braude", "Matthew P. Aylett", "Caoimhin Laoide-Kemp", "Simone Ashby", "Kristen M. Scott", "Brian O Raghallaigh", "Anna Braudo", "Alex Brouwer", "Adriana Stan"], "https://doi.org/10.21437/Interspeech.2019-2448", 5, "interspeech", 2019]], "Yu-Lin Huang": [0, ["Using Attention Networks and Adversarial Augmentation for Styrian Dialect Continuous Sleepiness and Baby Sound Recognition", ["Sung-Lin Yeh", "Gao-Yi Chao", "Bo-Hao Su", "Yu-Lin Huang", "Meng-Han Lin", "Yin-Chun Tsai", "Yu-Wen Tai", "Zheng-Chi Lu", "Chieh-Yu Chen", "Tsung-Ming Tai", "Chiu-Wang Tseng", "Cheng-Kuang Lee", "Chi-Chun Lee"], "https://doi.org/10.21437/Interspeech.2019-2110", 5, "interspeech", 2019]], "Esther Janse": [0, ["An Acoustic and Lexical Analysis of Emotional Valence in Spontaneous Speech: Autobiographical Memory Recall in Older Adults", ["Deniece S. Nazareth", "Ellen Tournier", "Sarah Leimkotter", "Esther Janse", "Dirk Heylen", "Gerben J. Westerhof", "Khiet P. Truong"], "https://doi.org/10.21437/Interspeech.2019-1823", 5, "interspeech", 2019]], "Mary Pietrowicz": [0, ["A New Approach for Automating Analysis of Responses on Verbal Fluency Tests from Subjects At-Risk for Schizophrenia", ["Mary Pietrowicz", "Carla Agurto", "Raquel Norel", "Elif Eyigoz", "Guillermo A. Cecchi", "Zarina R. Bilgrami", "Cheryl Corcoran"], "https://doi.org/10.21437/Interspeech.2019-2987", 5, "interspeech", 2019]], "Saurabhchand Bhati": [0, ["Unsupervised Acoustic Segmentation and Clustering Using Siamese Network Embeddings", ["Saurabhchand Bhati", "Shekhar Nayak", "K. Sri Rama Murty", "Najim Dehak"], "https://doi.org/10.21437/Interspeech.2019-2981", 5, "interspeech", 2019]], "Dayana Ribas": [0, ["Speech Enhancement with Wide Residual Networks in Reverberant Environments", ["Jorge Llombart", "Dayana Ribas", "Antonio Miguel", "Luis Vicente", "Alfonso Ortega Gimenez", "Eduardo Lleida"], "https://doi.org/10.21437/Interspeech.2019-1745", 5, "interspeech", 2019], ["Optimization of False Acceptance/Rejection Rates and Decision Threshold for End-to-End Text-Dependent Speaker Verification Systems", ["Victoria Mingote", "Antonio Miguel", "Dayana Ribas", "Alfonso Ortega Gimenez", "Eduardo Lleida"], "https://doi.org/10.21437/Interspeech.2019-2550", 5, "interspeech", 2019], ["Progressive Speech Enhancement with Residual Connections", ["Jorge Llombart", "Dayana Ribas", "Antonio Miguel", "Luis Vicente", "Alfonso Ortega Gimenez", "Eduardo Lleida"], "https://doi.org/10.21437/Interspeech.2019-1748", 5, "interspeech", 2019], ["Phonetically-Aware Embeddings, Wide Residual Networks with Time-Delay Neural Networks and Self Attention Models for the 2018 NIST Speaker Recognition Evaluation", ["Ignacio Vinals", "Dayana Ribas", "Victoria Mingote", "Jorge Llombart", "Pablo Gimeno", "Antonio Miguel", "Alfonso Ortega Gimenez", "Eduardo Lleida"], "https://doi.org/10.21437/Interspeech.2019-2417", 5, "interspeech", 2019]], "Ka Ho Wong": [0, ["The CUHK Dysarthric Speech Recognition Systems for English and Cantonese", ["Shoukang Hu", "Shansong Liu", "Heng Fai Chang", "Mengzhe Geng", "Jiani Chen", "Lau Wing Chung", "To Ka Hei", "Jianwei Yu", "Ka Ho Wong", "Xunying Liu", "Helen Meng"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8047.html", 2, "interspeech", 2019]], "Bilal Soomro": [0, ["Towards Debugging Deep Neural Networks by Generating Speech Utterances", ["Bilal Soomro", "Anssi Kanervisto", "Trung Ngo Trong", "Ville Hautamaki"], "https://doi.org/10.21437/Interspeech.2019-2339", 5, "interspeech", 2019]], "Ivan Koychev": [0, ["Predicting the Leading Political Ideology of YouTube Channels Using Acoustic, Textual, and Metadata Information", ["Yoan Dinkov", "Ahmed Ali", "Ivan Koychev", "Preslav Nakov"], "https://doi.org/10.21437/Interspeech.2019-2965", 5, "interspeech", 2019]], "Ria Ghosh": [0, ["Quantifying Cochlear Implant Users' Ability for Speaker Identification Using CI Auditory Stimuli", ["Nursadul Mamun", "Ria Ghosh", "John H. L. Hansen"], "https://doi.org/10.21437/Interspeech.2019-1852", 5, "interspeech", 2019]], "Sethuraman Panchanathan": [0, ["Say What? A Dataset for Exploring the Error Patterns That Two ASR Engines Make", ["Meredith Moore", "Michael Saxon", "Hemanth Venkateswara", "Visar Berisha", "Sethuraman Panchanathan"], "https://doi.org/10.21437/Interspeech.2019-3096", 5, "interspeech", 2019]], "Kyuwoong Hwang": [0.9981933534145355, ["An End-to-End Text-Independent Speaker Verification Framework with a Keyword Adversarial Network", ["Sungrack Yun", "Janghoon Cho", "Jungyun Eum", "Wonil Chang", "Kyuwoong Hwang"], "https://doi.org/10.21437/Interspeech.2019-2208", 5, "interspeech", 2019]], "Anda Ouyang": [0, ["Speech Based Emotion Prediction: Can a Linear Model Work?", ["Anda Ouyang", "Ting Dang", "Vidhyasaharan Sethu", "Eliathamby Ambikairajah"], "https://doi.org/10.21437/Interspeech.2019-3149", 5, "interspeech", 2019]], "Eunwoo Song": [0.9905647486448288, ["Probability Density Distillation with Generative Adversarial Networks for High-Quality Parallel Waveform Generation", ["Ryuichi Yamamoto", "Eunwoo Song", "Jae-Min Kim"], "https://doi.org/10.21437/Interspeech.2019-1965", 5, "interspeech", 2019]], "Justine T. Kao": [0, ["Active Learning for Domain Classification in a Commercial Spoken Personal Assistant", ["Xi C. Chen", "Adithya Sagar", "Justine T. Kao", "Tony Y. Li", "Christopher Klein", "Stephen Pulman", "Ashish Garg", "Jason D. Williams"], "https://doi.org/10.21437/Interspeech.2019-1315", 5, "interspeech", 2019]], "Ahmad Al-Dahle": [0, ["Coarse-to-Fine Optimization for Speech Enhancement", ["Jian Yao", "Ahmad Al-Dahle"], "https://doi.org/10.21437/Interspeech.2019-2792", 5, "interspeech", 2019]], "Farinaz Koushanfar": [0, ["Universal Adversarial Perturbations for Speech Recognition Systems", ["Paarth Neekhara", "Shehzeen Hussain", "Prakhar Pandey", "Shlomo Dubnov", "Julian J. McAuley", "Farinaz Koushanfar"], "https://doi.org/10.21437/Interspeech.2019-1353", 5, "interspeech", 2019]], "Tobias Huber": [0, ["Relevance-Based Feature Masking: Improving Neural Network Based Whale Classification Through Explainable Artificial Intelligence", ["Dominik Schiller", "Tobias Huber", "Florian Lingenfelser", "Michael Dietz", "Andreas Seiderer", "Elisabeth Andre"], "https://doi.org/10.21437/Interspeech.2019-2707", 5, "interspeech", 2019]], "Ali Shariq Imran": [0, ["A Phonetic-Level Analysis of Different Input Features for Articulatory Inversion", ["Abdolreza Sabzi Shahrebabaki", "Negar Olfati", "Ali Shariq Imran", "Sabato Marco Siniscalchi", "Torbjorn Svendsen"], "https://doi.org/10.21437/Interspeech.2019-2526", 5, "interspeech", 2019]], "Kathryn J. Eary": [0, ["Using Ultrasound Imaging to Create Augmented Visual Biofeedback for Articulatory Practice", ["Colin T. Annand", "Maurice Lamb", "Sarah Dugan", "Sarah R. Li", "Hannah M. Woeste", "T. Douglas Mast", "Michael A. Riley", "Jack A. Masterson", "Neeraja Mahalingam", "Kathryn J. Eary", "Caroline Spencer", "Suzanne Boyce", "Stephanie Jackson", "Anoosha Baxi", "Renee Seward"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8036.html", 2, "interspeech", 2019]], "Raouf Hamzaoui": [0, ["Two-Dimensional Convolutional Recurrent Neural Networks for Speech Activity Detection", ["Anastasios Vafeiadis", "Eleftherios Fanioudakis", "Ilyas Potamitis", "Konstantinos Votis", "Dimitrios Giakoumis", "Dimitrios Tzovaras", "Liming Chen", "Raouf Hamzaoui"], "https://doi.org/10.21437/Interspeech.2019-1354", 5, "interspeech", 2019]], "Cristian David Rios-Urrego": [0, ["Apkinson: A Mobile Solution for Multimodal Assessment of Patients with Parkinson's Disease", ["Juan Camilo Vasquez-Correa", "Tomas Arias-Vergara", "Philipp Klumpp", "M. Strauss", "Arne Kuderle", "Nils Roth", "S. Bayerl", "Nicanor Garcia-Ospina", "Paula Andrea Perez-Toro", "L. Felipe Parra-Gallego", "Cristian David Rios-Urrego", "D. Escobar-Grisales", "Juan Rafael Orozco-Arroyave", "Bjorn Eskofier", "Elmar Noth"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8003.html", 2, "interspeech", 2019], ["Feature Representation of Pathophysiology of Parkinsonian Dysarthria", ["Alice Rueda", "Juan Camilo Vasquez-Correa", "Cristian David Rios-Urrego", "Juan Rafael Orozco-Arroyave", "Sridhar Krishnan", "Elmar Noth"], "https://doi.org/10.21437/Interspeech.2019-2490", 5, "interspeech", 2019]], "Archana Venkataraman": [0, ["VESUS: A Crowd-Annotated Database to Study Emotion Production and Perception in Spoken English", ["Jacob Sager", "Ravi Shankar", "Jacob Reinhold", "Archana Venkataraman"], "https://doi.org/10.21437/Interspeech.2019-1413", 5, "interspeech", 2019], ["Weakly Supervised Syllable Segmentation by Vowel-Consonant Peak Classification", ["Ravi Shankar", "Archana Venkataraman"], "https://doi.org/10.21437/Interspeech.2019-1450", 5, "interspeech", 2019], ["A Multi-Speaker Emotion Morphing Model Using Highway Networks and Maximum Likelihood Objective", ["Ravi Shankar", "Jacob Sager", "Archana Venkataraman"], "https://doi.org/10.21437/Interspeech.2019-2512", 5, "interspeech", 2019], ["Automated Emotion Morphing in Speech Based on Diffeomorphic Curve Registration and Highway Networks", ["Ravi Shankar", "Hsi-Wei Hsieh", "Nicolas Charon", "Archana Venkataraman"], "https://doi.org/10.21437/Interspeech.2019-2386", 5, "interspeech", 2019]], "Benjamin van Niekerk": [0, ["Unsupervised Acoustic Unit Discovery for Speech Synthesis Using Discrete Latent-Variable Neural Networks", ["Ryan Eloff", "Andre Nortje", "Benjamin van Niekerk", "Avashna Govender", "Leanne Nortje", "Arnu Pretorius", "Elan Van Biljon", "Ewald van der Westhuizen", "Lisa van Staden", "Herman Kamper"], "https://doi.org/10.21437/Interspeech.2019-1518", 5, "interspeech", 2019]], "Xueyang Wu": [3.381589340278879e-05, ["Topic-Aware Dialogue Speech Recognition with Transfer Learning", ["Yuanfeng Song", "Di Jiang", "Xueyang Wu", "Qian Xu", "Raymond Chi-Wing Wong", "Qiang Yang"], "https://doi.org/10.21437/Interspeech.2019-1694", 5, "interspeech", 2019]], "Danwei Cai": [0, ["The DKU Replay Detection System for the ASVspoof 2019 Challenge: On Data Augmentation, Feature Representation, Classification, and Fusion", ["Weicheng Cai", "Haiwei Wu", "Danwei Cai", "Ming Li"], "https://doi.org/10.21437/Interspeech.2019-1230", 5, "interspeech", 2019], ["Survey Talk: End-to-End Deep Neural Network Based Speaker and Language Recognition", ["Ming Li", "Weicheng Cai", "Danwei Cai"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/abs10.html", 0, "interspeech", 2019], ["The DKU System for the Speaker Recognition Task of the 2019 VOiCES from a Distance Challenge", ["Danwei Cai", "Xiaoyi Qin", "Weicheng Cai", "Ming Li"], "https://doi.org/10.21437/Interspeech.2019-1435", 5, "interspeech", 2019], ["Far-Field End-to-End Text-Dependent Speaker Verification Based on Mixed Training Data with Transfer Learning and Enrollment Data Augmentation", ["Xiaoyi Qin", "Danwei Cai", "Ming Li"], "https://doi.org/10.21437/Interspeech.2019-1542", 5, "interspeech", 2019], ["Multi-Channel Training for End-to-End Speaker Recognition Under Reverberant and Noisy Environment", ["Danwei Cai", "Xiaoyi Qin", "Ming Li"], "https://doi.org/10.21437/Interspeech.2019-1437", 5, "interspeech", 2019], ["The DKU-SMIIP System for NIST 2018 Speaker Recognition Evaluation", ["Danwei Cai", "Weicheng Cai", "Ming Li"], "https://doi.org/10.21437/Interspeech.2019-1436", 5, "interspeech", 2019]], "Pablo Gimeno": [0, ["ViVoLAB Speaker Diarization System for the DIHARD 2019 Challenge", ["Ignacio Vinals", "Pablo Gimeno", "Alfonso Ortega Gimenez", "Antonio Miguel", "Eduardo Lleida"], "https://doi.org/10.21437/Interspeech.2019-2462", 5, "interspeech", 2019], ["Phonetically-Aware Embeddings, Wide Residual Networks with Time-Delay Neural Networks and Self Attention Models for the 2018 NIST Speaker Recognition Evaluation", ["Ignacio Vinals", "Dayana Ribas", "Victoria Mingote", "Jorge Llombart", "Pablo Gimeno", "Antonio Miguel", "Alfonso Ortega Gimenez", "Eduardo Lleida"], "https://doi.org/10.21437/Interspeech.2019-2417", 5, "interspeech", 2019]], "Markus Muller": [0, ["Very Deep Self-Attention Networks for End-to-End Speech Recognition", ["Ngoc-Quan Pham", "Thai-Son Nguyen", "Jan Niehues", "Markus Muller", "Alex Waibel"], "https://doi.org/10.21437/Interspeech.2019-2702", 5, "interspeech", 2019]], "Daniel Korzekwa": [0, ["Interpretable Deep Learning Model for the Detection and Reconstruction of Dysarthric Speech", ["Daniel Korzekwa", "Roberto Barra-Chicote", "Bozena Kostek", "Thomas Drugman", "Mateusz Lajszczak"], "https://doi.org/10.21437/Interspeech.2019-1206", 5, "interspeech", 2019]], "M. Strauss": [0, ["Apkinson: A Mobile Solution for Multimodal Assessment of Patients with Parkinson's Disease", ["Juan Camilo Vasquez-Correa", "Tomas Arias-Vergara", "Philipp Klumpp", "M. Strauss", "Arne Kuderle", "Nils Roth", "S. Bayerl", "Nicanor Garcia-Ospina", "Paula Andrea Perez-Toro", "L. Felipe Parra-Gallego", "Cristian David Rios-Urrego", "D. Escobar-Grisales", "Juan Rafael Orozco-Arroyave", "Bjorn Eskofier", "Elmar Noth"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8003.html", 2, "interspeech", 2019]], "Daniel Garcia-Romero": [0, ["Speaker Diarization Using Leave-One-Out Gaussian PLDA Clustering of DNN Embeddings", ["Alan McCree", "Gregory Sell", "Daniel Garcia-Romero"], "https://doi.org/10.21437/Interspeech.2019-2912", 5, "interspeech", 2019], ["State-of-the-Art Speaker Recognition for Telephone and Video Speech: The JHU-MIT Submission for NIST SRE18", ["Jesus Villalba", "Nanxin Chen", "David Snyder", "Daniel Garcia-Romero", "Alan McCree", "Gregory Sell", "Jonas Borgstrom", "Fred Richardson", "Suwon Shon", "Francois Grondin", "Reda Dehak", "Leibny Paola Garcia-Perera", "Daniel Povey", "Pedro A. Torres-Carrasquillo", "Sanjeev Khudanpur", "Najim Dehak"], "https://doi.org/10.21437/Interspeech.2019-2713", 5, "interspeech", 2019], ["x-Vector DNN Refinement with Full-Length Recordings for Speaker Recognition", ["Daniel Garcia-Romero", "David Snyder", "Gregory Sell", "Alan McCree", "Daniel Povey", "Sanjeev Khudanpur"], "https://doi.org/10.21437/Interspeech.2019-2205", 4, "interspeech", 2019], ["Speaker Recognition Benchmark Using the CHiME-5 Corpus", ["Daniel Garcia-Romero", "David Snyder", "Shinji Watanabe", "Gregory Sell", "Alan McCree", "Daniel Povey", "Sanjeev Khudanpur"], "https://doi.org/10.21437/Interspeech.2019-2174", 5, "interspeech", 2019]], "Martin Karafiat": [0, ["Analysis of Multilingual Sequence-to-Sequence Speech Recognition Systems", ["Martin Karafiat", "Murali Karthick Baskar", "Shinji Watanabe", "Takaaki Hori", "Matthew Wiesner", "Jan Cernocky"], "https://doi.org/10.21437/Interspeech.2019-2355", 5, "interspeech", 2019]], "Terry Lyons": [0, ["A Path Signature Approach for Speech Emotion Recognition", ["Bo Wang", "Maria Liakata", "Hao Ni", "Terry Lyons", "Alejo J. Nevado-Holgado", "Kate Saunders"], "https://doi.org/10.21437/Interspeech.2019-2624", 5, "interspeech", 2019]], "Dong Wang": [0.1973298266530037, ["VAE-Based Regularization for Deep Speaker Embedding", ["Yang Zhang", "Lantian Li", "Dong Wang"], "https://doi.org/10.21437/Interspeech.2019-2486", 5, "interspeech", 2019]], "Bridget Cheng": [0, ["Leveraging Acoustic Cues and Paralinguistic Embeddings to Detect Expression from Voice", ["Vikramjit Mitra", "Sue Booker", "Erik Marchi", "David Scott Farrar", "Ute Dorothea Peitz", "Bridget Cheng", "Ermine Teves", "Anuj Mehta", "Devang Naik"], "https://doi.org/10.21437/Interspeech.2019-2998", 5, "interspeech", 2019]], "Deepika Gupta": [0, ["Artificial Bandwidth Extension Using H\u221e Optimization", ["Deepika Gupta", "Hanumant Singh Shekhawat"], "https://doi.org/10.21437/Interspeech.2019-1580", 5, "interspeech", 2019]], "Albert Sanchis": [0, ["Real-Time One-Pass Decoder for Speech Recognition Using LSTM Language Models", ["Javier Jorge", "Adria Gimenez", "Javier Iranzo-Sanchez", "Jorge Civera", "Albert Sanchis", "Alfons Juan"], "https://doi.org/10.21437/Interspeech.2019-2798", 5, "interspeech", 2019]], "Umair Khan": [0, ["Auto-Encoding Nearest Neighbor i-Vectors for Speaker Verification", ["Umair Khan", "Miquel India", "Javier Hernando"], "https://doi.org/10.21437/Interspeech.2019-1444", 5, "interspeech", 2019]], "Cheng-chieh Yeh": [0, ["End-to-End Text-to-Speech for Low-Resource Languages by Cross-Lingual Transfer Learning", ["Yuan-Jui Chen", "Tao Tu", "Cheng-chieh Yeh", "Hung-yi Lee"], "https://doi.org/10.21437/Interspeech.2019-2730", 5, "interspeech", 2019]], "Kevin Kilgour": [0, ["Fr\u00e9chet Audio Distance: A Reference-Free Metric for Evaluating Music Enhancement Algorithms", ["Kevin Kilgour", "Mauricio Zuluaga", "Dominik Roblek", "Matthew Sharifi"], "https://doi.org/10.21437/Interspeech.2019-2219", 5, "interspeech", 2019], ["Low-Dimensional Bottleneck Features for On-Device Continuous Speech Recognition", ["David B. Ramsay", "Kevin Kilgour", "Dominik Roblek", "Matthew Sharifi"], "https://doi.org/10.21437/Interspeech.2019-2193", 4, "interspeech", 2019]], "Takuma Okamoto": [0, ["Real-Time Neural Text-to-Speech with Sequence-to-Sequence Acoustic Model and WaveGlow or Single Gaussian WaveRNN Vocoders", ["Takuma Okamoto", "Tomoki Toda", "Yoshinori Shiga", "Hisashi Kawai"], "https://doi.org/10.21437/Interspeech.2019-1288", 5, "interspeech", 2019]], "Zice Wei": [0, ["Speech Enhancement Using Forked Generative Adversarial Networks with Spectral Subtraction", ["Ju Lin", "Sufeng Niu", "Zice Wei", "Xiang Lan", "Adriaan J. van Wijngaarden", "Melissa C. Smith", "Kuang-Ching Wang"], "https://doi.org/10.21437/Interspeech.2019-2954", 5, "interspeech", 2019]], "Anna Silnova": [0, ["Analysis of BUT Submission in Far-Field Scenarios of VOiCES 2019 Challenge", ["Pavel Matejka", "Oldrich Plchot", "Hossein Zeinali", "Ladislav Mosner", "Anna Silnova", "Lukas Burget", "Ondrej Novotny", "Ondrej Glembek"], "https://doi.org/10.21437/Interspeech.2019-2471", 5, "interspeech", 2019], ["Analysis of BUT Submission in Far-Field Scenarios of VOiCES 2019 Challenge", ["Pavel Matejka", "Oldrich Plchot", "Hossein Zeinali", "Ladislav Mosner", "Anna Silnova", "Lukas Burget", "Ondrej Novotny", "Ondrej Glembek"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/abs16.html", 0, "interspeech", 2019]], "Johannes Stahl": [0, ["Maximum a posteriori Speech Enhancement Based on Double Spectrum", ["Pejman Mowlaee", "Daniel Scheran", "Johannes Stahl", "Sean U. N. Wood", "W. Bastiaan Kleijn"], "https://doi.org/10.21437/Interspeech.2019-1197", 5, "interspeech", 2019]], "Jibin Wu": [0.4061788022518158, ["Robust Sound Recognition: A Neuromorphic Approach", ["Jibin Wu", "Zihan Pan", "Malu Zhang", "Rohan Kumar Das", "Yansong Chua", "Haizhou Li"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8032.html", 2, "interspeech", 2019]], "Richard Dufour": [0, ["Qualitative Evaluation of ASR Adaptation in a Lecture Context: Application to the PASTEL Corpus", ["Salima Mdhaffar", "Yannick Esteve", "Nicolas Hernandez", "Antoine Laurent", "Richard Dufour", "Solen Quiniou"], "https://doi.org/10.21437/Interspeech.2019-2661", 5, "interspeech", 2019]], "Jing Xiao": [0, ["Cross-Lingual, Multi-Speaker Text-To-Speech Synthesis Using Neural Speaker Embedding", ["Mengnan Chen", "Minchuan Chen", "Shuang Liang", "Jun Ma", "Lei Chen", "Shaojun Wang", "Jing Xiao"], "https://doi.org/10.21437/Interspeech.2019-1632", 5, "interspeech", 2019]], "Yishay Carmiel": [0, ["Avaya Conversational Intelligence: A Real-Time System for Spoken Language Understanding in Human-Human Call Center Conversations", ["Jan Mizgajski", "Adrian Szymczak", "Robert Glowski", "Piotr Szymanski", "Piotr Zelasko", "Lukasz Augustyniak", "Mikolaj Morzy", "Yishay Carmiel", "Jeff Hodson", "Lukasz Wojciak", "Daniel Smoczyk", "Adam Wrobel", "Bartosz Borowik", "Adam Artajew", "Marcin Baran", "Cezary Kwiatkowski", "Marzena Zyla-Hoppe"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8002.html", 2, "interspeech", 2019]], "Pujitha Appan Kandala": [0, ["Real Time Online Visual End Point Detection Using Unidirectional LSTM", ["Tanay Sharma", "Rohith Chandrashekar Aralikatti", "Dilip Kumar Margam", "Abhinav Thanda", "Sharad Roy", "Pujitha Appan Kandala", "Shankar M. Venkatesan"], "https://doi.org/10.21437/Interspeech.2019-3253", 5, "interspeech", 2019], ["Speaker Adaptation for Lip-Reading Using Visual Identity Vectors", ["Pujitha Appan Kandala", "Abhinav Thanda", "Dilip Kumar Margam", "Rohith Chandrashekar Aralikatti", "Tanay Sharma", "Sharad Roy", "Shankar M. Venkatesan"], "https://doi.org/10.21437/Interspeech.2019-3237", 5, "interspeech", 2019]], "Jan Niehues": [0, ["Very Deep Self-Attention Networks for End-to-End Speech Recognition", ["Ngoc-Quan Pham", "Thai-Son Nguyen", "Jan Niehues", "Markus Muller", "Alex Waibel"], "https://doi.org/10.21437/Interspeech.2019-2702", 5, "interspeech", 2019], ["Survey Talk: A Survey on Speech Translation", ["Jan Niehues"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/abs9.html", 0, "interspeech", 2019]], "Bhaskar D. Rao": [0, ["On Mitigating Acoustic Feedback in Hearing Aids with Frequency Warping by All-Pass Networks", ["Ching Hua Lee", "Kuan-Lin Chen", "Fredric J. Harris", "Bhaskar D. Rao", "Harinath Garudadri"], "https://doi.org/10.21437/Interspeech.2019-3195", 5, "interspeech", 2019]], "Michael Saxon": [0, ["Say What? A Dataset for Exploring the Error Patterns That Two ASR Engines Make", ["Meredith Moore", "Michael Saxon", "Hemanth Venkateswara", "Visar Berisha", "Sethuraman Panchanathan"], "https://doi.org/10.21437/Interspeech.2019-3096", 5, "interspeech", 2019]], "Huashan Pan": [0, ["A Mandarin Prosodic Boundary Prediction Model Based on Multi-Task Learning", ["Huashan Pan", "Xiulin Li", "Zhiqiang Huang"], "https://doi.org/10.21437/Interspeech.2019-1400", 4, "interspeech", 2019]], "Bhuvana Ramabhadran": [0, ["Learning to Speak Fluently in a Foreign Language: Multilingual Speech Synthesis and Cross-Language Voice Cloning", ["Yu Zhang", "Ron J. Weiss", "Heiga Zen", "Yonghui Wu", "Zhifeng Chen", "R. J. Skerry-Ryan", "Ye Jia", "Andrew Rosenberg", "Bhuvana Ramabhadran"], "https://doi.org/10.21437/Interspeech.2019-2668", 5, "interspeech", 2019], ["Large-Scale Multilingual Speech Recognition with a Streaming End-to-End Model", ["Anjuli Kannan", "Arindrima Datta", "Tara N. Sainath", "Eugene Weinstein", "Bhuvana Ramabhadran", "Yonghui Wu", "Ankur Bapna", "Zhifeng Chen", "Seungji Lee"], "https://doi.org/10.21437/Interspeech.2019-2858", 5, "interspeech", 2019]], "Sabrina Paganoni": [0, ["Use of Beiwe Smartphone App to Identify and Track Speech Decline in Amyotrophic Lateral Sclerosis (ALS)", ["Kathryn P. Connaghan", "Jordan R. Green", "Sabrina Paganoni", "James Chan", "Harli Weber", "Ella Collins", "Brian Richburg", "Marziye Eshghi", "Jukka-Pekka Onnela", "James D. Berry"], "https://doi.org/10.21437/Interspeech.2019-3126", 5, "interspeech", 2019]], "Mireia Diez": [0, ["Bayesian HMM Based x-Vector Clustering for Speaker Diarization", ["Mireia Diez", "Lukas Burget", "Shuai Wang", "Johan Rohdin", "Jan Cernocky"], "https://doi.org/10.21437/Interspeech.2019-2813", 5, "interspeech", 2019]], "Guanghui Xu": [0, ["Building a Mixed-Lingual Neural TTS System with Only Monolingual Data", ["Liumeng Xue", "Wei Song", "Guanghui Xu", "Lei Xie", "Zhizheng Wu"], "https://doi.org/10.21437/Interspeech.2019-3191", 5, "interspeech", 2019]], "Daniel Jun Rim": [0, ["Shortcut Connections Based Deep Speaker Embeddings for End-to-End Speaker Verification System", ["Soonshin Seo", "Daniel Jun Rim", "Minkyu Lim", "Donghyun Lee", "Hosung Park", "Junseok Oh", "Changmin Kim", "Ji-Hwan Kim"], "https://doi.org/10.21437/Interspeech.2019-2195", 5, "interspeech", 2019]], "Vimal Manohar": [0, ["The JHU ASR System for VOiCES from a Distance Challenge 2019", ["Yiming Wang", "David Snyder", "Hainan Xu", "Vimal Manohar", "Phani Sankar Nidadavolu", "Daniel Povey", "Sanjeev Khudanpur"], "https://doi.org/10.21437/Interspeech.2019-1948", 5, "interspeech", 2019]], "Raja Jurdak": [0, ["Direct Modelling of Speech Emotion from Raw Speech", ["Siddique Latif", "Rajib Rana", "Sara Khalifa", "Raja Jurdak", "Julien Epps"], "https://doi.org/10.21437/Interspeech.2019-3252", 5, "interspeech", 2019]], "Ing-Marie Jonsson": [0, ["Mirroring to Build Trust in Digital Assistants", ["Katherine Metcalf", "Barry-John Theobald", "Garrett Weinberg", "Robert Lee", "Ing-Marie Jonsson", "Russ Webb", "Nicholas Apostoloff"], "https://doi.org/10.21437/Interspeech.2019-1829", 5, "interspeech", 2019]], "Kate M. Knill": [0, ["Splash: Speech and Language Assessment in Schools and Homes", ["A. Miwardelli", "I. Gallagher", "J. Gibson", "Napoleon Katsos", "Kate M. Knill", "H. Wood"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8027.html", 2, "interspeech", 2019], ["A Deep Learning Approach to Automatic Characterisation of Rhythm in Non-Native English Speech", ["Konstantinos Kyriakopoulos", "Kate M. Knill", "Mark J. F. Gales"], "https://doi.org/10.21437/Interspeech.2019-3186", 5, "interspeech", 2019], ["Impact of ASR Performance on Spoken Grammatical Error Detection", ["Yiting Lu", "Mark J. F. Gales", "Kate M. Knill", "P. P. Manakul", "Linlin Wang", "Y. Wang"], "https://doi.org/10.21437/Interspeech.2019-1706", 5, "interspeech", 2019]], "Cornelius Glackin": [0, ["Explaining Sentiment Classification", ["Marvin Rajwadi", "Cornelius Glackin", "Julie A. Wall", "Gerard Chollet", "Nigel Cannings"], "https://doi.org/10.21437/Interspeech.2019-2743", 5, "interspeech", 2019]], "Mohamed S. Abdelfattah": [0, ["ShrinkML: End-to-End ASR Model Compression Using Reinforcement Learning", ["Lukasz Dudziak", "Mohamed S. Abdelfattah", "Ravichander Vipperla", "Stefanos Laskaridis", "Nicholas D. Lane"], "https://doi.org/10.21437/Interspeech.2019-2811", 5, "interspeech", 2019]], "Vinayak Abrol": [0, ["Understanding and Visualizing Raw Waveform-Based CNNs", ["Hannah Muckenhirn", "Vinayak Abrol", "Mathew Magimai-Doss", "Sebastien Marcel"], "https://doi.org/10.21437/Interspeech.2019-2341", 5, "interspeech", 2019]], "Volker Dellwo": [0, ["Formant Pattern and Spectral Shape Ambiguity of Vowel Sounds, and Related Phenomena of Vowel Acoustics - Exemplary Evidence", ["Dieter Maurer", "Heidy Suter", "Christian dHereuse", "Volker Dellwo"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8017.html", 2, "interspeech", 2019], ["Fundamental Frequency Accommodation in Multi-Party Human-Robot Game Interactions: The Effect of Winning or Losing", ["Omnia Ibrahim", "Gabriel Skantze", "Sabine Stoll", "Volker Dellwo"], "https://doi.org/10.21437/Interspeech.2019-2496", 5, "interspeech", 2019]], "Tsubasa Goto": [0, ["Speech Organ Contour Extraction Using Real-Time MRI and Machine Learning Method", ["Hironori Takemoto", "Tsubasa Goto", "Yuya Hagihara", "Sayaka Hamanaka", "Tatsuya Kitamura", "Yukiko Nota", "Kikuo Maekawa"], "https://doi.org/10.21437/Interspeech.2019-1593", 5, "interspeech", 2019]], "Tabea Thies": [0, ["Intragestural Variation in Natural Sentence Production: Essential Tremor Patients Treated with DBS", ["Anne Hermes", "Doris Mucke", "Tabea Thies", "Michael T. Barbe"], "https://doi.org/10.21437/Interspeech.2019-2389", 5, "interspeech", 2019]], "Vishnu Vidyadhara Raju Vegesna": [0, ["Sound Privacy: A Conversational Speech Corpus for Quantifying the Experience of Privacy", ["Pablo Perez Zarazaga", "Sneha Das", "Tom Backstrom", "Vishnu Vidyadhara Raju Vegesna", "Anil Kumar Vuppala"], "https://doi.org/10.21437/Interspeech.2019-1172", 5, "interspeech", 2019]], "Wentao Gu": [1.1605677252557456e-09, ["Prosodic Characteristics of Mandarin Declarative and Interrogative Utterances in Parkinson's Disease", ["Lei Liu", "Meng Jian", "Wentao Gu"], "https://doi.org/10.21437/Interspeech.2019-3276", 5, "interspeech", 2019]], "Sabato Marco Siniscalchi": [0, ["A Phonetic-Level Analysis of Different Input Features for Articulatory Inversion", ["Abdolreza Sabzi Shahrebabaki", "Negar Olfati", "Ali Shariq Imran", "Sabato Marco Siniscalchi", "Torbjorn Svendsen"], "https://doi.org/10.21437/Interspeech.2019-2526", 5, "interspeech", 2019]], "Susanne Drechsel": [0, ["Perceptual Optimization of an Enhanced Geometric Vocal Fold Model for Articulatory Speech Synthesis", ["Peter Birkholz", "Susanne Drechsel", "Simon Stone"], "https://doi.org/10.21437/Interspeech.2019-2410", 5, "interspeech", 2019]], "Silvain Gerber": [0, ["A Perceptual Study of CV Syllables in Both Spoken and Whistled Speech: A Tashlhiyt Berber Perspective", ["Julien Meyer", "Laure Dentel", "Silvain Gerber", "Rachid Ridouane"], "https://doi.org/10.21437/Interspeech.2019-2251", 5, "interspeech", 2019]], "Jeff Hodson": [0, ["Avaya Conversational Intelligence: A Real-Time System for Spoken Language Understanding in Human-Human Call Center Conversations", ["Jan Mizgajski", "Adrian Szymczak", "Robert Glowski", "Piotr Szymanski", "Piotr Zelasko", "Lukasz Augustyniak", "Mikolaj Morzy", "Yishay Carmiel", "Jeff Hodson", "Lukasz Wojciak", "Daniel Smoczyk", "Adam Wrobel", "Bartosz Borowik", "Adam Artajew", "Marcin Baran", "Cezary Kwiatkowski", "Marzena Zyla-Hoppe"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8002.html", 2, "interspeech", 2019]], "Mohammed Sidi Yakoub": [0, ["Linear Discriminant Differential Evolution for Feature Selection in Emotional Speech Recognition", ["Soumaya Gharsellaoui", "Sid-Ahmed Selouani", "Mohammed Sidi Yakoub"], "https://doi.org/10.21437/Interspeech.2019-1218", 5, "interspeech", 2019]], "Yi-Ming Weng": [0, ["Investigating the Variability of Voice Quality and Pain Levels as a Function of Multiple Clinical Parameters", ["Hui-Ting Hong", "Jeng-Lin Li", "Yi-Ming Weng", "Chip-Jin Ng", "Chi-Chun Lee"], "https://doi.org/10.21437/Interspeech.2019-2247", 5, "interspeech", 2019]], "Daisuke Saito": [0, ["Analysis of Native Listeners' Facial Microexpressions While Shadowing Non-Native Speech - Potential of Shadowers' Facial Expressions for Comprehensibility Prediction", ["Tasavat Trisitichoke", "Shintaro Ando", "Daisuke Saito", "Nobuaki Minematsu"], "https://doi.org/10.21437/Interspeech.2019-1953", 5, "interspeech", 2019]], "Wu Guo": [0, ["Multi-Task Learning with High-Order Statistics for x-Vector Based Text-Independent Speaker Verification", ["Lanhua You", "Wu Guo", "Li-Rong Dai", "Jun Du"], "https://doi.org/10.21437/Interspeech.2019-2264", 5, "interspeech", 2019], ["Deep Neural Network Embeddings with Gating Mechanisms for Text-Independent Speaker Verification", ["Lanhua You", "Wu Guo", "Li-Rong Dai", "Jun Du"], "https://doi.org/10.21437/Interspeech.2019-1746", 5, "interspeech", 2019], ["Neural Text Clustering with Document-Level Attention Based on Dynamic Soft Labels", ["Zhi Chen", "Wu Guo", "Li-Rong Dai", "Zhen-Hua Ling", "Jun Du"], "https://doi.org/10.21437/Interspeech.2019-1417", 5, "interspeech", 2019]], "Mirjam Ernestus": [0, ["ERP Signal Analysis with Temporal Resolution Using a Time Window Bank", ["Annika Nijveld", "Louis ten Bosch", "Mirjam Ernestus"], "https://doi.org/10.21437/Interspeech.2019-2729", 5, "interspeech", 2019], ["Language Learning Using Speech to Image Retrieval", ["Danny Merkx", "Stefan L. Frank", "Mirjam Ernestus"], "https://doi.org/10.21437/Interspeech.2019-3067", 5, "interspeech", 2019], ["Listening with Great Expectations: An Investigation of Word Form Anticipations in Naturalistic Speech", ["M. Bentum", "Louis ten Bosch", "Antal van den Bosch", "Mirjam Ernestus"], "https://doi.org/10.21437/Interspeech.2019-2741", 5, "interspeech", 2019], ["Quantifying Expectation Modulation in Human Speech Processing", ["M. Bentum", "Louis ten Bosch", "Antal van den Bosch", "Mirjam Ernestus"], "https://doi.org/10.21437/Interspeech.2019-2685", 5, "interspeech", 2019], ["Lexically Guided Perceptual Learning of a Vowel Shift in an Interactive L2 Listening Context", ["E. Felker", "Mirjam Ernestus", "Mirjam Broersma"], "https://doi.org/10.21437/Interspeech.2019-1414", 5, "interspeech", 2019]], "Maria Schuster": [0, ["Phone-Attribute Posteriors to Evaluate the Speech of Cochlear Implant Users", ["Tomas Arias-Vergara", "Juan Rafael Orozco-Arroyave", "Milos Cernak", "Sandra Gollwitzer", "Maria Schuster", "Elmar Noth"], "https://doi.org/10.21437/Interspeech.2019-2144", 5, "interspeech", 2019]], "Florian Schiel": [0, ["Tracking the New Zealand English NEAR/SQUARE Merger Using Functional Principal Components Analysis", ["Michele Gubian", "Jonathan Harrington", "Mary Stevens", "Florian Schiel", "Paul Warren"], "https://doi.org/10.21437/Interspeech.2019-2115", 5, "interspeech", 2019], ["Styrian Dialect Classification: Comparing and Fusing Classifiers Based on a Feature Selection Using a Genetic Algorithm", ["Thomas Kisler", "Raphael Winkelmann", "Florian Schiel"], "https://doi.org/10.21437/Interspeech.2019-2540", 5, "interspeech", 2019], ["BAS Web Services for Automatic Subtitle Creation and Anonymization", ["Florian Schiel", "Thomas Kisler"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8001.html", 2, "interspeech", 2019]], "Balamurali B. T.": [0, ["Analyzing Intra-Speaker and Inter-Speaker Vocal Tract Impedance Characteristics in a Low-Dimensional Feature Space Using t-SNE", ["Balamurali B. T.", "Jer-Ming Chen"], "https://doi.org/10.21437/Interspeech.2019-1492", 4, "interspeech", 2019]], "Daisuke Fukunaga": [0, ["GPU-Based WFST Decoding with Extra Large Language Model", ["Daisuke Fukunaga", "Yoshiki Tanaka", "Yuichi Kageyama"], "https://doi.org/10.21437/Interspeech.2019-2101", 5, "interspeech", 2019]], "Ryan Leary": [0, ["Jasper: An End-to-End Convolutional Neural Acoustic Model", ["Jason Li", "Vitaly Lavrukhin", "Boris Ginsburg", "Ryan Leary", "Oleksii Kuchaiev", "Jonathan M. Cohen", "Huyen Nguyen", "Ravi Teja Gadde"], "https://doi.org/10.21437/Interspeech.2019-1819", 5, "interspeech", 2019]], "Shansong Liu": [0, ["LF-MMI Training of Bayesian and Gaussian Process Time Delay Neural Networks for Speech Recognition", ["Shoukang Hu", "Xurong Xie", "Shansong Liu", "Max W. Y. Lam", "Jianwei Yu", "Xixin Wu", "Xunying Liu", "Helen Meng"], "https://doi.org/10.21437/Interspeech.2019-2379", 5, "interspeech", 2019], ["The CUHK Dysarthric Speech Recognition Systems for English and Cantonese", ["Shoukang Hu", "Shansong Liu", "Heng Fai Chang", "Mengzhe Geng", "Jiani Chen", "Lau Wing Chung", "To Ka Hei", "Jianwei Yu", "Ka Ho Wong", "Xunying Liu", "Helen Meng"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8047.html", 2, "interspeech", 2019], ["Exploiting Visual Features Using Bayesian Gated Neural Networks for Disordered Speech Recognition", ["Shansong Liu", "Shoukang Hu", "Yi Wang", "Jianwei Yu", "Rongfeng Su", "Xunying Liu", "Helen Meng"], "https://doi.org/10.21437/Interspeech.2019-1536", 5, "interspeech", 2019], ["On the Use of Pitch Features for Disordered Speech Recognition", ["Shansong Liu", "Shoukang Hu", "Xunying Liu", "Helen Meng"], "https://doi.org/10.21437/Interspeech.2019-2609", 5, "interspeech", 2019]], "Andreas Stolcke": [0, ["Meeting Transcription Using Asynchronous Distant Microphones", ["Takuya Yoshioka", "Dimitrios Dimitriadis", "Andreas Stolcke", "William Hinthorn", "Zhuo Chen", "Michael Zeng", "Xuedong Huang"], "https://doi.org/10.21437/Interspeech.2019-3088", 5, "interspeech", 2019]], "Meng Ge": [0, ["Environment-Dependent Attention-Driven Recurrent Convolutional Neural Network for Robust Speech Enhancement", ["Meng Ge", "Longbiao Wang", "Nan Li", "Hao Shi", "Jianwu Dang", "Xiangang Li"], "https://doi.org/10.21437/Interspeech.2019-1477", 5, "interspeech", 2019]], "Shota Horiguchi": [0, ["Auxiliary Interference Speaker Loss for Target-Speaker Speech Recognition", ["Naoyuki Kanda", "Shota Horiguchi", "Ryoichi Takashima", "Yusuke Fujita", "Kenji Nagamatsu", "Shinji Watanabe"], "https://doi.org/10.21437/Interspeech.2019-1126", 5, "interspeech", 2019], ["Guided Source Separation Meets a Strong ASR Backend: Hitachi/Paderborn University Joint Investigation for Dinner Party ASR", ["Naoyuki Kanda", "Christoph Boddeker", "Jens Heitkaemper", "Yusuke Fujita", "Shota Horiguchi", "Kenji Nagamatsu", "Reinhold Haeb-Umbach"], "https://doi.org/10.21437/Interspeech.2019-1167", 5, "interspeech", 2019], ["Multimodal Response Obligation Detection with Unsupervised Online Domain Adaptation", ["Shota Horiguchi", "Naoyuki Kanda", "Kenji Nagamatsu"], "https://doi.org/10.21437/Interspeech.2019-1313", 5, "interspeech", 2019], ["End-to-End Neural Speaker Diarization with Permutation-Free Objectives", ["Yusuke Fujita", "Naoyuki Kanda", "Shota Horiguchi", "Kenji Nagamatsu", "Shinji Watanabe"], "https://doi.org/10.21437/Interspeech.2019-2899", 5, "interspeech", 2019]], "Caoimhin Laoide-Kemp": [0, ["All Together Now: The Living Audio Dataset", ["David A. Braude", "Matthew P. Aylett", "Caoimhin Laoide-Kemp", "Simone Ashby", "Kristen M. Scott", "Brian O Raghallaigh", "Anna Braudo", "Alex Brouwer", "Adriana Stan"], "https://doi.org/10.21437/Interspeech.2019-2448", 5, "interspeech", 2019]], "Youjue He": [0, ["Frication as a Vowel Feature? - Evidence from the Rui'an Wu Chinese Dialect", ["Fang Hu", "Youjue He"], "https://doi.org/10.21437/Interspeech.2019-1134", 5, "interspeech", 2019]], "Eduardo Coutinho": [0, ["Sincerity in Acted Speech: Presenting the Sincere Apology Corpus and Results", ["Alice Baird", "Eduardo Coutinho", "Julia Hirschberg", "Bjorn W. Schuller"], "https://doi.org/10.21437/Interspeech.2019-1349", 5, "interspeech", 2019]], "Aaron Lawson": [0, ["The VOiCES from a Distance Challenge 2019", ["Mahesh Kumar Nandwana", "Julien van Hout", "Colleen Richey", "Mitchell McLaren", "Maria Auxiliadora Barrios", "Aaron Lawson"], "https://doi.org/10.21437/Interspeech.2019-1837", 5, "interspeech", 2019], ["The VOiCES from a Distance Challenge 2019", ["Mahesh Kumar Nandwana", "Julien van Hout", "Colleen Richey", "Mitchell McLaren", "Maria Alejandra Barrios", "Aaron Lawson"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/abs14.html", 0, "interspeech", 2019], ["Analysis of Critical Metadata Factors for the Calibration of Speaker Recognition Systems", ["Mahesh Kumar Nandwana", "Luciana Ferrer", "Mitchell McLaren", "Diego Castan", "Aaron Lawson"], "https://doi.org/10.21437/Interspeech.2019-1808", 5, "interspeech", 2019]], "Vanessa Lopes": [0, ["Sustained Vowel Game: A Computer Therapy Game for Children with Dysphonia", ["Vanessa Lopes", "Joao Magalhaes", "Sofia Cavaco"], "https://doi.org/10.21437/Interspeech.2019-3017", 5, "interspeech", 2019]], "Odette Scharenborg": [0, ["The Neural Correlates Underlying Lexically-Guided Perceptual Learning", ["Odette Scharenborg", "Jiska Koemans", "Cybelle Smith", "Mark A. Hasegawa-Johnson", "Kara D. Federmeier"], "https://doi.org/10.21437/Interspeech.2019-2328", 5, "interspeech", 2019], ["Study of the Performance of Automatic Speech Recognition Systems in Speakers with Parkinson's Disease", ["Laureano Moro-Velazquez", "Jaejin Cho", "Shinji Watanabe", "Mark A. Hasegawa-Johnson", "Odette Scharenborg", "Heejin Kim", "Najim Dehak"], "https://doi.org/10.21437/Interspeech.2019-2993", 5, "interspeech", 2019], ["Survey Talk: Reaching Over the Gap: Cross- and Interdisciplinary Research on Human and Automatic Speech Processing", ["Odette Scharenborg"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/abs25.html", 0, "interspeech", 2019]], "Fred Richardson": [0, ["State-of-the-Art Speaker Recognition for Telephone and Video Speech: The JHU-MIT Submission for NIST SRE18", ["Jesus Villalba", "Nanxin Chen", "David Snyder", "Daniel Garcia-Romero", "Alan McCree", "Gregory Sell", "Jonas Borgstrom", "Fred Richardson", "Suwon Shon", "Francois Grondin", "Reda Dehak", "Leibny Paola Garcia-Perera", "Daniel Povey", "Pedro A. Torres-Carrasquillo", "Sanjeev Khudanpur", "Najim Dehak"], "https://doi.org/10.21437/Interspeech.2019-2713", 5, "interspeech", 2019]], "Anthony Pak-Hin Kong": [5.5142583207934415e-12, ["Automatic Assessment of Language Impairment Based on Raw ASR Output", ["Ying Qin", "Tan Lee", "Anthony Pak-Hin Kong"], "https://doi.org/10.21437/Interspeech.2019-1688", 5, "interspeech", 2019]], "Takaaki Fukutomi": [0, ["Neural Whispered Speech Detection with Imbalanced Learning", ["Takanori Ashihara", "Yusuke Shinohara", "Hiroshi Sato", "Takafumi Moriya", "Kiyoaki Matsui", "Takaaki Fukutomi", "Yoshikazu Yamaguchi", "Yushi Aono"], "https://doi.org/10.21437/Interspeech.2019-2161", 5, "interspeech", 2019]], "Cheng-I Lai": [0, ["ASSERT: Anti-Spoofing with Squeeze-Excitation and Residual Networks", ["Cheng-I Lai", "Nanxin Chen", "Jesus Villalba", "Najim Dehak"], "https://doi.org/10.21437/Interspeech.2019-1794", 5, "interspeech", 2019]], "Brian Richburg": [0, ["Use of Beiwe Smartphone App to Identify and Track Speech Decline in Amyotrophic Lateral Sclerosis (ALS)", ["Kathryn P. Connaghan", "Jordan R. Green", "Sabrina Paganoni", "James Chan", "Harli Weber", "Ella Collins", "Brian Richburg", "Marziye Eshghi", "Jukka-Pekka Onnela", "James D. Berry"], "https://doi.org/10.21437/Interspeech.2019-3126", 5, "interspeech", 2019]], "Tao Ma": [0, ["Survey Talk: When Attention Meets Speech Applications: Speech & Speaker Recognition Perspective", ["Kyu J. Han", "Ramon Prieto", "Tao Ma"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/abs5.html", 0, "interspeech", 2019], ["Direct-Path Signal Cross-Correlation Estimation for Sound Source Localization in Reverberation", ["Wei Xue", "Ying Tong", "Guohong Ding", "Chao Zhang", "Tao Ma", "Xiaodong He", "Bowen Zhou"], "https://doi.org/10.21437/Interspeech.2019-1488", 5, "interspeech", 2019]], "Fang Zhou": [0, ["Pyramid Memory Block and Timestep Attention for Speech Emotion Recognition", ["Miao Cao", "Chun Yang", "Fang Zhou", "Xu-Cheng Yin"], "https://doi.org/10.21437/Interspeech.2019-3140", 5, "interspeech", 2019]], "Mari Ostendorf": [0, ["Disfluencies and Human Speech Transcription Errors", ["Vicky Zayats", "Trang Tran", "Richard A. Wright", "Courtney Mansfield", "Mari Ostendorf"], "https://doi.org/10.21437/Interspeech.2019-3134", 5, "interspeech", 2019], ["On the Role of Style in Parsing Speech with Neural Models", ["Trang Tran", "Jiahong Yuan", "Yang Liu", "Mari Ostendorf"], "https://doi.org/10.21437/Interspeech.2019-3122", 5, "interspeech", 2019]], "Natalia A. Tomashenko": [0, ["Curriculum-Based Transfer Learning for an Effective End-to-End Spoken Language Understanding and Domain Portability", ["Antoine Caubriere", "Natalia A. Tomashenko", "Antoine Laurent", "Emmanuel Morin", "Nathalie Camelin", "Yannick Esteve"], "https://doi.org/10.21437/Interspeech.2019-1832", 5, "interspeech", 2019]], "Reiko Mazuka": [0, ["Nasal Consonant Discrimination in Infant- and Adult-Directed Speech", ["Bogdan Ludusan", "Annett Jorschick", "Reiko Mazuka"], "https://doi.org/10.21437/Interspeech.2019-1737", 5, "interspeech", 2019]], "Ivan Lopez-Espejo": [0, ["Keyword Spotting for Hearing Assistive Devices Robust to External Speakers", ["Ivan Lopez-Espejo", "Zheng-Hua Tan", "Jesper Jensen"], "https://doi.org/10.21437/Interspeech.2019-2010", 5, "interspeech", 2019]], "Il-Ho Yang": [0.8665457963943481, ["End-to-End Losses Based on Speaker Basis Vectors and All-Speaker Hard Negative Mining for Speaker Verification", ["Hee-Soo Heo", "Jee-weon Jung", "Il-Ho Yang", "Sung-Hyun Yoon", "Hye-jin Shim", "Ha-Jin Yu"], "https://doi.org/10.21437/Interspeech.2019-1986", 5, "interspeech", 2019]], "Ondrej Klejch": [0, ["Lattice-Based Lightly-Supervised Acoustic Model Training", ["Joachim Fainberg", "Ondrej Klejch", "Steve Renals", "Peter Bell"], "https://doi.org/10.21437/Interspeech.2019-2533", 5, "interspeech", 2019]], "Luis Vicente": [0, ["Speech Enhancement with Wide Residual Networks in Reverberant Environments", ["Jorge Llombart", "Dayana Ribas", "Antonio Miguel", "Luis Vicente", "Alfonso Ortega Gimenez", "Eduardo Lleida"], "https://doi.org/10.21437/Interspeech.2019-1745", 5, "interspeech", 2019], ["Progressive Speech Enhancement with Residual Connections", ["Jorge Llombart", "Dayana Ribas", "Antonio Miguel", "Luis Vicente", "Alfonso Ortega Gimenez", "Eduardo Lleida"], "https://doi.org/10.21437/Interspeech.2019-1748", 5, "interspeech", 2019]], "Oyku Deniz Kose": [0, ["Temporally-Aware Acoustic Unit Discovery for Zerospeech 2019 Challenge", ["Bolaji Yusuf", "Alican Gok", "Batuhan Gundogdu", "Oyku Deniz Kose", "Murat Saraclar"], "https://doi.org/10.21437/Interspeech.2019-1430", 5, "interspeech", 2019]], "Alican Gok": [0, ["Temporally-Aware Acoustic Unit Discovery for Zerospeech 2019 Challenge", ["Bolaji Yusuf", "Alican Gok", "Batuhan Gundogdu", "Oyku Deniz Kose", "Murat Saraclar"], "https://doi.org/10.21437/Interspeech.2019-1430", 5, "interspeech", 2019]], "Carlos Mendes": [0, ["Recognition of Latin American Spanish Using Multi-Task Learning", ["Carlos Mendes", "Alberto Abad", "Joao Paulo Neto", "Isabel Trancoso"], "https://doi.org/10.21437/Interspeech.2019-2772", 5, "interspeech", 2019]], "Stavros Petridis": [0, ["Investigating the Lombard Effect Influence on End-to-End Audio-Visual Speech Recognition", ["Pingchuan Ma", "Stavros Petridis", "Maja Pantic"], "https://doi.org/10.21437/Interspeech.2019-2726", 5, "interspeech", 2019], ["Video-Driven Speech Reconstruction Using Generative Adversarial Networks", ["Konstantinos Vougioukas", "Pingchuan Ma", "Stavros Petridis", "Maja Pantic"], "https://doi.org/10.21437/Interspeech.2019-1445", 5, "interspeech", 2019]], "Engin Erzin": [0, ["Speech Driven Backchannel Generation Using Deep Q-Network for Enhancing Engagement in Human-Robot Interaction", ["Nusrah Hussain", "Engin Erzin", "T. Metin Sezgin", "Yucel Yemez"], "https://doi.org/10.21437/Interspeech.2019-2521", 5, "interspeech", 2019]], "Fernando Villavicencio": [0, ["A Strategy for Improved Phone-Level Lyrics-to-Audio Alignment for Speech-to-Singing Synthesis", ["David Ayllon", "Fernando Villavicencio", "Pierre Lanchantin"], "https://doi.org/10.21437/Interspeech.2019-3049", 5, "interspeech", 2019]], "Santiago Pascual": [0, ["Learning Problem-Agnostic Speech Representations from Multiple Self-Supervised Tasks", ["Santiago Pascual", "Mirco Ravanelli", "Joan Serra", "Antonio Bonafonte", "Yoshua Bengio"], "https://doi.org/10.21437/Interspeech.2019-2605", 5, "interspeech", 2019], ["Towards Generalized Speech Enhancement with Generative Adversarial Networks", ["Santiago Pascual", "Joan Serra", "Antonio Bonafonte"], "https://doi.org/10.21437/Interspeech.2019-2688", 5, "interspeech", 2019]], "Kikuo Maekawa": [0, ["Speech Organ Contour Extraction Using Real-Time MRI and Machine Learning Method", ["Hironori Takemoto", "Tsubasa Goto", "Yuya Hagihara", "Sayaka Hamanaka", "Tatsuya Kitamura", "Yukiko Nota", "Kikuo Maekawa"], "https://doi.org/10.21437/Interspeech.2019-1593", 5, "interspeech", 2019]], "Terry Amorese": [0, ["The Dependability of Voice on Elders' Acceptance of Humanoid Agents", ["Anna Esposito", "Terry Amorese", "Marialucia Cuciniello", "Maria Teresa Riviello", "Antonietta Maria Esposito", "Alda Troncone", "Gennaro Cordasco"], "https://doi.org/10.21437/Interspeech.2019-1734", 5, "interspeech", 2019]], "Jer-Ming Chen": [0, ["Analyzing Intra-Speaker and Inter-Speaker Vocal Tract Impedance Characteristics in a Low-Dimensional Feature Space Using t-SNE", ["Balamurali B. T.", "Jer-Ming Chen"], "https://doi.org/10.21437/Interspeech.2019-1492", 4, "interspeech", 2019]], "Daniel Stoller": [0, ["Ensemble Models for Spoofing Detection in Automatic Speaker Verification", ["Bhusan Chettri", "Daniel Stoller", "Veronica Morfi", "Marco A. Martinez Ramirez", "Emmanouil Benetos", "Bob L. Sturm"], "https://doi.org/10.21437/Interspeech.2019-2505", 5, "interspeech", 2019]], "Julien Meyer": [0, ["A Perceptual Study of CV Syllables in Both Spoken and Whistled Speech: A Tashlhiyt Berber Perspective", ["Julien Meyer", "Laure Dentel", "Silvain Gerber", "Rachid Ridouane"], "https://doi.org/10.21437/Interspeech.2019-2251", 5, "interspeech", 2019]], "Xingfeng Li": [0, ["The Contribution of Acoustic Features Analysis to Model Emotion Perceptual Process for Language Diversity", ["Xingfeng Li", "Masato Akagi"], "https://doi.org/10.21437/Interspeech.2019-2229", 5, "interspeech", 2019]], "Sonia DApolito": [0, ["L2 Pronunciation Accuracy and Context: A Pilot Study on the Realization of Geminates in Italian as L2 by French Learners", ["Sonia DApolito", "Barbara Gili Fivela"], "https://doi.org/10.21437/Interspeech.2019-2934", 5, "interspeech", 2019]], "Xu Li": [0, ["Comparative Study of Parametric and Representation Uncertainty Modeling for Recurrent Neural Network Language Models", ["Jianwei Yu", "Max W. Y. Lam", "Shoukang Hu", "Xixin Wu", "Xu Li", "Yuewen Cao", "Xunying Liu", "Helen Meng"], "https://doi.org/10.21437/Interspeech.2019-1927", 5, "interspeech", 2019]], "Sadegh Mirshekarian": [0, ["Diagnosing Dysarthria with Long Short-Term Memory Networks", ["Alex Mayle", "Zhiwei Mou", "Razvan C. Bunescu", "Sadegh Mirshekarian", "Li Xu", "Chang Liu"], "https://doi.org/10.21437/Interspeech.2019-2903", 5, "interspeech", 2019]], "Shiliang Zhang": [0, ["Towards Language-Universal Mandarin-English Speech Recognition", ["Shiliang Zhang", "Yuan Liu", "Ming Lei", "Bin Ma", "Lei Xie"], "https://doi.org/10.21437/Interspeech.2019-1365", 5, "interspeech", 2019], ["Investigation of Transformer Based Spelling Correction Model for CTC-Based End-to-End Mandarin Speech Recognition", ["Shiliang Zhang", "Ming Lei", "Zhijie Yan"], "https://doi.org/10.21437/Interspeech.2019-1290", 5, "interspeech", 2019], ["Audio Tagging with Compact Feedforward Sequential Memory Network and Audio-to-Audio Ratio Based Data Augmentation", ["Zhiying Huang", "Shiliang Zhang", "Ming Lei"], "https://doi.org/10.21437/Interspeech.2019-1302", 5, "interspeech", 2019]], "Lei Chen": [0, ["Cross-Lingual, Multi-Speaker Text-To-Speech Synthesis Using Neural Speaker Embedding", ["Mengnan Chen", "Minchuan Chen", "Shuang Liang", "Jun Ma", "Lei Chen", "Shaojun Wang", "Jing Xiao"], "https://doi.org/10.21437/Interspeech.2019-1632", 5, "interspeech", 2019]], "Miquel India": [0, ["Auto-Encoding Nearest Neighbor i-Vectors for Speaker Verification", ["Umair Khan", "Miquel India", "Javier Hernando"], "https://doi.org/10.21437/Interspeech.2019-1444", 5, "interspeech", 2019], ["Self Multi-Head Attention for Speaker Recognition", ["Miquel India", "Pooyan Safari", "Javier Hernando"], "https://doi.org/10.21437/Interspeech.2019-2616", 5, "interspeech", 2019]], "Hynek Hermansky": [0, ["Performance Monitoring for End-to-End Speech Recognition", ["Ruizhi Li", "Gregory Sell", "Hynek Hermansky"], "https://doi.org/10.21437/Interspeech.2019-3137", 5, "interspeech", 2019], ["Exploring Methods for the Automatic Detection of Errors in Manual Transcription", ["Xiaofei Wang", "Jinyi Yang", "Ruizhi Li", "Samik Sadhu", "Hynek Hermansky"], "https://doi.org/10.21437/Interspeech.2019-1343", 5, "interspeech", 2019], ["Modulation Vectors as Robust Feature Representation for ASR in Domain Mismatched Conditions", ["Samik Sadhu", "Hynek Hermansky"], "https://doi.org/10.21437/Interspeech.2019-2723", 5, "interspeech", 2019]], "Seung Hee Yang": [0.9917360246181488, ["Self-Imitating Feedback Generation Using GAN for Computer-Assisted Pronunciation Training", ["Seung Hee Yang", "Minhwa Chung"], "https://doi.org/10.21437/Interspeech.2019-1478", 5, "interspeech", 2019]], "Debanjan Mahata": [0, ["Hush-Hush Speak: Speech Reconstruction Using Silent Videos", ["Shashwat Uttam", "Yaman Kumar", "Dhruva Sahrawat", "Mansi Aggarwal", "Rajiv Ratn Shah", "Debanjan Mahata", "Amanda Stent"], "https://doi.org/10.21437/Interspeech.2019-3269", 5, "interspeech", 2019], ["MobiVSR : Efficient and Light-Weight Neural Network for Visual Speech Recognition on Mobile Devices", ["Nilay Shrivastava", "Astitwa Saxena", "Yaman Kumar", "Rajiv Ratn Shah", "Amanda Stent", "Debanjan Mahata", "Preeti Kaur", "Roger Zimmermann"], "https://doi.org/10.21437/Interspeech.2019-3273", 5, "interspeech", 2019]], "Dimitris Sgouropoulos": [0, ["Data Augmentation Using GANs for Speech Emotion Recognition", ["Aggelina Chatziagapi", "Georgios Paraskevopoulos", "Dimitris Sgouropoulos", "Georgios Pantazopoulos", "Malvina Nikandrou", "Theodoros Giannakopoulos", "Athanasios Katsamanis", "Alexandros Potamianos", "Shrikanth Narayanan"], "https://doi.org/10.21437/Interspeech.2019-2561", 5, "interspeech", 2019]], "Haisong Ding": [0, ["Compression of CTC-Trained Acoustic Models by Dynamic Frame-Wise Distillation or Segment-Wise N-Best Hypotheses Imitation", ["Haisong Ding", "Kai Chen", "Qiang Huo"], "https://doi.org/10.21437/Interspeech.2019-2182", 5, "interspeech", 2019]], "Paula Andrea Perez-Toro": [0, ["Apkinson: A Mobile Solution for Multimodal Assessment of Patients with Parkinson's Disease", ["Juan Camilo Vasquez-Correa", "Tomas Arias-Vergara", "Philipp Klumpp", "M. Strauss", "Arne Kuderle", "Nils Roth", "S. Bayerl", "Nicanor Garcia-Ospina", "Paula Andrea Perez-Toro", "L. Felipe Parra-Gallego", "Cristian David Rios-Urrego", "D. Escobar-Grisales", "Juan Rafael Orozco-Arroyave", "Bjorn Eskofier", "Elmar Noth"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8003.html", 2, "interspeech", 2019]], "Tomoki Toda": [0, ["Quasi-Periodic WaveNet Vocoder: A Pitch Dependent Dilated Convolution Model for Parametric Speech Generation", ["Yi-Chiao Wu", "Tomoki Hayashi", "Patrick Lumban Tobing", "Kazuhiro Kobayashi", "Tomoki Toda"], "https://doi.org/10.21437/Interspeech.2019-1232", 5, "interspeech", 2019], ["Non-Parallel Voice Conversion with Cyclic Variational Autoencoder", ["Patrick Lumban Tobing", "Yi-Chiao Wu", "Tomoki Hayashi", "Kazuhiro Kobayashi", "Tomoki Toda"], "https://doi.org/10.21437/Interspeech.2019-2307", 5, "interspeech", 2019], ["Robustness of Statistical Voice Conversion Based on Direct Waveform Modification Against Background Sounds", ["Yusuke Kurita", "Kazuhiro Kobayashi", "Kazuya Takeda", "Tomoki Toda"], "https://doi.org/10.21437/Interspeech.2019-2206", 5, "interspeech", 2019], ["Investigation of F0 Conditioning and Fully Convolutional Networks in Variational Autoencoder Based Voice Conversion", ["Wen-Chin Huang", "Yi-Chiao Wu", "Chen-Chou Lo", "Patrick Lumban Tobing", "Tomoki Hayashi", "Kazuhiro Kobayashi", "Tomoki Toda", "Yu Tsao", "Hsin-Min Wang"], "https://doi.org/10.21437/Interspeech.2019-1774", 5, "interspeech", 2019], ["Real-Time Neural Text-to-Speech with Sequence-to-Sequence Acoustic Model and WaveGlow or Single Gaussian WaveRNN Vocoders", ["Takuma Okamoto", "Tomoki Toda", "Yoshinori Shiga", "Hisashi Kawai"], "https://doi.org/10.21437/Interspeech.2019-1288", 5, "interspeech", 2019], ["Pre-Trained Text Embeddings for Enhanced Text-to-Speech Synthesis", ["Tomoki Hayashi", "Shinji Watanabe", "Tomoki Toda", "Kazuya Takeda", "Shubham Toshniwal", "Karen Livescu"], "https://doi.org/10.21437/Interspeech.2019-3177", 5, "interspeech", 2019]], "Qiantong Xu": [0, ["Sequence-to-Sequence Speech Recognition with Time-Depth Separable Convolutions", ["Awni Hannun", "Ann Lee", "Qiantong Xu", "Ronan Collobert"], "https://doi.org/10.21437/Interspeech.2019-2460", 5, "interspeech", 2019]], "Anastasia Avdeeva": [0, ["Speaker Diarization with Deep Speaker Embeddings for DIHARD Challenge II", ["Sergey Novoselov", "Aleksei Gusev", "Artem Ivanov", "Timur Pekhovsky", "Andrey Shulipa", "Anastasia Avdeeva", "Artem Gorlanov", "Alexandr Kozlov"], "https://doi.org/10.21437/Interspeech.2019-2757", 5, "interspeech", 2019]], "Francois Lancelot": [0, ["The Airbus Air Traffic Control Speech Recognition 2018 Challenge: Towards ATC Automatic Transcription and Call Sign Detection", ["Thomas Pellegrini", "Jerome Farinas", "Estelle Delpech", "Francois Lancelot"], "https://doi.org/10.21437/Interspeech.2019-1962", 5, "interspeech", 2019]], "Krishna Somandepalli": [0, ["Identifying Therapist and Client Personae for Therapeutic Alliance Estimation", ["Victor R. Martinez", "Nikolaos Flemotomos", "Victor Ardulov", "Krishna Somandepalli", "Simon B. Goldberg", "Zac E. Imel", "David C. Atkins", "Shrikanth Narayanan"], "https://doi.org/10.21437/Interspeech.2019-2829", 5, "interspeech", 2019], ["Multiview Shared Subspace Learning Across Speakers and Speech Commands", ["Krishna Somandepalli", "Naveen Kumar", "Arindam Jati", "Panayiotis G. Georgiou", "Shrikanth Narayanan"], "https://doi.org/10.21437/Interspeech.2019-3130", 5, "interspeech", 2019]], "Rohan Kumar Das": [0, ["Long Range Acoustic Features for Spoofed Speech Detection", ["Rohan Kumar Das", "Jichen Yang", "Haizhou Li"], "https://doi.org/10.21437/Interspeech.2019-1887", 5, "interspeech", 2019], ["I4U Submission to NIST SRE 2018: Leveraging from a Decade of Shared Experiences", ["Kong Aik Lee", "Ville Hautamaki", "Tomi H. Kinnunen", "Hitoshi Yamamoto", "Koji Okabe", "Ville Vestman", "Jing Huang", "Guohong Ding", "Hanwu Sun", "Anthony Larcher", "Rohan Kumar Das", "Haizhou Li", "Mickael Rouvier", "Pierre-Michel Bousquet", "Wei Rao", "Qing Wang", "Chunlei Zhang", "Fahimeh Bahmaninezhad", "Hector Delgado", "Massimiliano Todisco"], "https://doi.org/10.21437/Interspeech.2019-1533", 5, "interspeech", 2019], ["Multi-Level Adaptive Speech Activity Detector for Speech in Naturalistic Environments", ["Bidisha Sharma", "Rohan Kumar Das", "Haizhou Li"], "https://doi.org/10.21437/Interspeech.2019-1928", 5, "interspeech", 2019], ["On the Importance of Audio-Source Separation for Singer Identification in Polyphonic Music", ["Bidisha Sharma", "Rohan Kumar Das", "Haizhou Li"], "https://doi.org/10.21437/Interspeech.2019-1925", 5, "interspeech", 2019], ["Instantaneous Phase and Long-Term Acoustic Cues for Orca Activity Detection", ["Rohan Kumar Das", "Haizhou Li"], "https://doi.org/10.21437/Interspeech.2019-1894", 5, "interspeech", 2019], ["SpeechMarker: A Voice Based Multi-Level Attendance Application", ["Sarfaraz Jelil", "Abhishek Shrivastava", "Rohan Kumar Das", "S. R. Mahadeva Prasanna", "Rohit Sinha"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8014.html", 2, "interspeech", 2019], ["Robust Sound Recognition: A Neuromorphic Approach", ["Jibin Wu", "Zihan Pan", "Malu Zhang", "Rohan Kumar Das", "Yansong Chua", "Haizhou Li"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8032.html", 2, "interspeech", 2019], ["A Unified Framework for Speaker and Utterance Verification", ["Tianchi Liu", "Maulik C. Madhavi", "Rohan Kumar Das", "Haizhou Li"], "https://doi.org/10.21437/Interspeech.2019-1994", 5, "interspeech", 2019]], "Ayush Jaiswal": [0, ["NIESR: Nuisance Invariant End-to-End Speech Recognition", ["I-Hung Hsu", "Ayush Jaiswal", "Premkumar Natarajan"], "https://doi.org/10.21437/Interspeech.2019-1836", 5, "interspeech", 2019]], "Eduardo Lleida": [0, ["ViVoLAB Speaker Diarization System for the DIHARD 2019 Challenge", ["Ignacio Vinals", "Pablo Gimeno", "Alfonso Ortega Gimenez", "Antonio Miguel", "Eduardo Lleida"], "https://doi.org/10.21437/Interspeech.2019-2462", 5, "interspeech", 2019], ["Speech Enhancement with Wide Residual Networks in Reverberant Environments", ["Jorge Llombart", "Dayana Ribas", "Antonio Miguel", "Luis Vicente", "Alfonso Ortega Gimenez", "Eduardo Lleida"], "https://doi.org/10.21437/Interspeech.2019-1745", 5, "interspeech", 2019], ["Optimization of False Acceptance/Rejection Rates and Decision Threshold for End-to-End Text-Dependent Speaker Verification Systems", ["Victoria Mingote", "Antonio Miguel", "Dayana Ribas", "Alfonso Ortega Gimenez", "Eduardo Lleida"], "https://doi.org/10.21437/Interspeech.2019-2550", 5, "interspeech", 2019], ["Progressive Speech Enhancement with Residual Connections", ["Jorge Llombart", "Dayana Ribas", "Antonio Miguel", "Luis Vicente", "Alfonso Ortega Gimenez", "Eduardo Lleida"], "https://doi.org/10.21437/Interspeech.2019-1748", 5, "interspeech", 2019], ["Language Recognition Using Triplet Neural Networks", ["Victoria Mingote", "Diego Castan", "Mitchell McLaren", "Mahesh Kumar Nandwana", "Alfonso Ortega Gimenez", "Eduardo Lleida", "Antonio Miguel"], "https://doi.org/10.21437/Interspeech.2019-2437", 5, "interspeech", 2019], ["Phonetically-Aware Embeddings, Wide Residual Networks with Time-Delay Neural Networks and Self Attention Models for the 2018 NIST Speaker Recognition Evaluation", ["Ignacio Vinals", "Dayana Ribas", "Victoria Mingote", "Jorge Llombart", "Pablo Gimeno", "Antonio Miguel", "Alfonso Ortega Gimenez", "Eduardo Lleida"], "https://doi.org/10.21437/Interspeech.2019-2417", 5, "interspeech", 2019]], "Younggun Lee": [0.995842307806015, ["Large-Scale Speaker Retrieval on Random Speaker Variability Subspace", ["Suwon Shon", "Younggun Lee", "Taesu Kim"], "https://doi.org/10.21437/Interspeech.2019-1498", 5, "interspeech", 2019]], "Andros Tjandra": [0, ["VQVAE Unsupervised Unit Discovery and Multi-Scale Code2Spec Inverter for Zerospeech Challenge 2019", ["Andros Tjandra", "Berrak Sisman", "Mingyang Zhang", "Sakriani Sakti", "Haizhou Li", "Satoshi Nakamura"], "https://doi.org/10.21437/Interspeech.2019-3232", 5, "interspeech", 2019], ["Sequence-to-Sequence Learning via Attention Transfer for Incremental Speech Recognition", ["Sashi Novitasari", "Andros Tjandra", "Sakriani Sakti", "Satoshi Nakamura"], "https://doi.org/10.21437/Interspeech.2019-2985", 5, "interspeech", 2019]], "Abdelwahab Heba": [0, ["Char+CV-CTC: Combining Graphemes and Consonant/Vowel Units for CTC-Based ASR Using Multitask Learning", ["Abdelwahab Heba", "Thomas Pellegrini", "Jean-Pierre Lorre", "Regine Andre-Obrecht"], "https://doi.org/10.21437/Interspeech.2019-1975", 5, "interspeech", 2019]], "Man-Wai Mak": [0, ["Variational Domain Adversarial Learning for Speaker Verification", ["Youzhi Tu", "Man-Wai Mak", "Jen-Tzung Chien"], "https://doi.org/10.21437/Interspeech.2019-2168", 5, "interspeech", 2019]], "Bernd T. Meyer": [0, ["\"Computer, Test My Hearing\": Accurate Speech Audiometry with Smart Speakers", ["Jasper Ooster", "Pia Nancy Porysek Moreta", "Jorg-Hendrik Bach", "Inga Holube", "Bernd T. Meyer"], "https://doi.org/10.21437/Interspeech.2019-2118", 5, "interspeech", 2019]], "Christian Raymond": [0, ["Mining Polysemous Triplets with Recurrent Neural Networks for Spoken Language Understanding", ["Vedran Vukotic", "Christian Raymond"], "https://doi.org/10.21437/Interspeech.2019-2977", 5, "interspeech", 2019], ["Benchmarking Benchmarks: Introducing New Automatic Indicators for Benchmarking Spoken Language Understanding Corpora", ["Frederic Bechet", "Christian Raymond"], "https://doi.org/10.21437/Interspeech.2019-3033", 5, "interspeech", 2019]], "Emer Gilmartin": [0, ["Identifying Personality Traits Using Overlap Dynamics in Multiparty Dialogue", ["Mingzhi Yu", "Emer Gilmartin", "Diane J. Litman"], "https://doi.org/10.21437/Interspeech.2019-1886", 5, "interspeech", 2019]], "Michael L. Seltzer": [0, ["Joint Grapheme and Phoneme Embeddings for Contextual End-to-End ASR", ["Zhehuai Chen", "Mahaveer Jain", "Yongqiang Wang", "Michael L. Seltzer", "Christian Fuegen"], "https://doi.org/10.21437/Interspeech.2019-1434", 5, "interspeech", 2019]], "Tsubasa Ochiai": [0, ["End-to-End SpeakerBeam for Single Channel Target Speech Recognition", ["Marc Delcroix", "Shinji Watanabe", "Tsubasa Ochiai", "Keisuke Kinoshita", "Shigeki Karita", "Atsunori Ogawa", "Tomohiro Nakatani"], "https://doi.org/10.21437/Interspeech.2019-1856", 5, "interspeech", 2019], ["Multimodal SpeakerBeam: Single Channel Target Speech Extraction with Audio-Visual Speaker Clues", ["Tsubasa Ochiai", "Marc Delcroix", "Keisuke Kinoshita", "Atsunori Ogawa", "Tomohiro Nakatani"], "https://doi.org/10.21437/Interspeech.2019-1513", 5, "interspeech", 2019]], "Yannick Esteve": [0, ["Qualitative Evaluation of ASR Adaptation in a Lecture Context: Application to the PASTEL Corpus", ["Salima Mdhaffar", "Yannick Esteve", "Nicolas Hernandez", "Antoine Laurent", "Richard Dufour", "Solen Quiniou"], "https://doi.org/10.21437/Interspeech.2019-2661", 5, "interspeech", 2019], ["Investigating Adaptation and Transfer Learning for End-to-End Spoken Language Understanding from Speech", ["Natalia Tomashenko", "Antoine Caubriere", "Yannick Esteve"], "https://doi.org/10.21437/Interspeech.2019-2158", 5, "interspeech", 2019], ["Curriculum-Based Transfer Learning for an Effective End-to-End Spoken Language Understanding and Domain Portability", ["Antoine Caubriere", "Natalia A. Tomashenko", "Antoine Laurent", "Emmanuel Morin", "Nathalie Camelin", "Yannick Esteve"], "https://doi.org/10.21437/Interspeech.2019-1832", 5, "interspeech", 2019]], "Daryush D. Mehta": [0, ["Vocal Biomarker Assessment Following Pediatric Traumatic Brain Injury: A Retrospective Cohort Study", ["Camille Noufi", "Adam C. Lammert", "Daryush D. Mehta", "James R. Williamson", "Gregory Ciccarelli", "Douglas E. Sturim", "Jordan R. Green", "Thomas F. Campbell", "Thomas F. Quatieri"], "https://doi.org/10.21437/Interspeech.2019-1200", 5, "interspeech", 2019]], "David Tavarez": [0, ["Parallel vs. Non-Parallel Voice Conversion for Esophageal Speech", ["Luis Serrano", "Sneha Raman", "David Tavarez", "Eva Navas", "Inma Hernaez"], "https://doi.org/10.21437/Interspeech.2019-2194", 5, "interspeech", 2019]], "Dan Oneata": [0, ["Kite: Automatic Speech Recognition for Unmanned Aerial Vehicles", ["Dan Oneata", "Horia Cucu"], "https://doi.org/10.21437/Interspeech.2019-1390", 5, "interspeech", 2019]], "Celeste Mason": [0, ["Comparative Analysis of Think-Aloud Methods for Everyday Activities in the Context of Cognitive Robotics", ["Moritz Meier", "Celeste Mason", "Felix Putze", "Tanja Schultz"], "https://doi.org/10.21437/Interspeech.2019-3072", 5, "interspeech", 2019]], "Dan Su": [0, ["Disambiguation of Chinese Polyphones in an End-to-End Framework with Semantic Features Extracted by Pre-Trained BERT", ["Dongyang Dai", "Zhiyong Wu", "Shiyin Kang", "Xixin Wu", "Jia Jia", "Dan Su", "Dong Yu", "Helen Meng"], "https://doi.org/10.21437/Interspeech.2019-2292", 5, "interspeech", 2019], ["Extract, Adapt and Recognize: An End-to-End Neural Network for Corrupted Monaural Speech Recognition", ["Max W. Y. Lam", "Jun Wang", "Xunying Liu", "Helen Meng", "Dan Su", "Dong Yu"], "https://doi.org/10.21437/Interspeech.2019-1626", 5, "interspeech", 2019], ["Neural Spatial Filter: Target Speaker Speech Separation Assisted with Directional Information", ["Rongzhi Gu", "Lianwu Chen", "Shi-Xiong Zhang", "Jimeng Zheng", "Yong Xu", "Meng Yu", "Dan Su", "Yuexian Zou", "Dong Yu"], "https://doi.org/10.21437/Interspeech.2019-2266", 5, "interspeech", 2019]], "Koichi Shinoda": [0, ["The NEC-TT 2018 Speaker Verification System", ["Kong Aik Lee", "Hitoshi Yamamoto", "Koji Okabe", "Qiongqiong Wang", "Ling Guo", "Takafumi Koshinaka", "Jiacen Zhang", "Koichi Shinoda"], "https://doi.org/10.21437/Interspeech.2019-1517", 5, "interspeech", 2019], ["A Modified Algorithm for Multiple Input Spectrogram Inversion", ["Dongxiao Wang", "Hirokazu Kameoka", "Koichi Shinoda"], "https://doi.org/10.21437/Interspeech.2019-3242", 5, "interspeech", 2019]], "Siyuan Feng": [0, ["Improving Unsupervised Subword Modeling via Disentangled Speech Representation Learning and Transformation", ["Siyuan Feng", "Tan Lee"], "https://doi.org/10.21437/Interspeech.2019-1338", 5, "interspeech", 2019], ["Combining Adversarial Training and Disentangled Speech Representation for Robust Zero-Resource Subword Modeling", ["Siyuan Feng", "Tan Lee", "Zhiyuan Peng"], "https://doi.org/10.21437/Interspeech.2019-1337", 5, "interspeech", 2019]], "Ron Hoory": [0, ["High Quality, Lightweight and Adaptable TTS Using LPCNet", ["Zvi Kons", "Slava Shechtman", "Alexander Sorin", "Carmel Rabinovitz", "Ron Hoory"], "https://doi.org/10.21437/Interspeech.2019-1705", 5, "interspeech", 2019]], "Jean-Marc Valin": [0, ["A Real-Time Wideband Neural Vocoder at 1.6kb/s Using LPCNet", ["Jean-Marc Valin", "Jan Skoglund"], "https://doi.org/10.21437/Interspeech.2019-1255", 5, "interspeech", 2019]], "Lu Wang": [8.899776003090665e-05, ["Parameter-Transfer Learning for Low-Resource Individualization of Head-Related Transfer Functions", ["Xiaoke Qi", "Lu Wang"], "https://doi.org/10.21437/Interspeech.2019-2558", 5, "interspeech", 2019]], "Lucas Kessler": [0, ["Synthesized Spoken Names: Biases Impacting Perception", ["Lucas Kessler", "Cecilia Ovesdotter Alm", "Reynold Bailey"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8031.html", 2, "interspeech", 2019]], "Tao Qin": [0, ["Token-Level Ensemble Distillation for Grapheme-to-Phoneme Conversion", ["Hao Sun", "Xu Tan", "Jun-Wei Gan", "Hongzhi Liu", "Sheng Zhao", "Tao Qin", "Tie-Yan Liu"], "https://doi.org/10.21437/Interspeech.2019-1208", 5, "interspeech", 2019]], "Zhuohuang Zhang": [0, ["Listener Preference on the Local Criterion for Ideal Binary-Masked Speech", ["Zhuohuang Zhang", "Yi Shen"], "https://doi.org/10.21437/Interspeech.2019-1369", 5, "interspeech", 2019]], "Nanxin Chen": [0, ["ASSERT: Anti-Spoofing with Squeeze-Excitation and Residual Networks", ["Cheng-I Lai", "Nanxin Chen", "Jesus Villalba", "Najim Dehak"], "https://doi.org/10.21437/Interspeech.2019-1794", 5, "interspeech", 2019], ["State-of-the-Art Speaker Recognition for Telephone and Video Speech: The JHU-MIT Submission for NIST SRE18", ["Jesus Villalba", "Nanxin Chen", "David Snyder", "Daniel Garcia-Romero", "Alan McCree", "Gregory Sell", "Jonas Borgstrom", "Fred Richardson", "Suwon Shon", "Francois Grondin", "Reda Dehak", "Leibny Paola Garcia-Perera", "Daniel Povey", "Pedro A. Torres-Carrasquillo", "Sanjeev Khudanpur", "Najim Dehak"], "https://doi.org/10.21437/Interspeech.2019-2713", 5, "interspeech", 2019], ["The JHU Speaker Recognition System for the VOiCES 2019 Challenge", ["David Snyder", "Jesus Villalba", "Nanxin Chen", "Daniel Povey", "Gregory Sell", "Najim Dehak", "Sanjeev Khudanpur"], "https://doi.org/10.21437/Interspeech.2019-2979", 5, "interspeech", 2019], ["Tied Mixture of Factor Analyzers Layer to Combine Frame Level Representations in Neural Speaker Embeddings", ["Nanxin Chen", "Jesus Villalba", "Najim Dehak"], "https://doi.org/10.21437/Interspeech.2019-1782", 5, "interspeech", 2019]], "Laetitia Jeancolas": [0, ["Comparison of Telephone Recordings and Professional Microphone Recordings for Early Detection of Parkinson's Disease, Using Mel-Frequency Cepstral Coefficients with Gaussian Mixture Models", ["Laetitia Jeancolas", "Graziella Mangone", "Jean-Christophe Corvol", "Marie Vidailhet", "Stephane Lehericy", "Badr-Eddine Benkelfat", "Habib Benali", "Dijana Petrovska-Delacretaz"], "https://doi.org/10.21437/Interspeech.2019-2825", 5, "interspeech", 2019]], "John Quinn": [0, ["Feature Exploration for Almost Zero-Resource ASR-Free Keyword Spotting Using a Multilingual Bottleneck Extractor and Correspondence Autoencoders", ["Raghav Menon", "Herman Kamper", "Ewald van der Westhuizen", "John Quinn", "Thomas Niesler"], "https://doi.org/10.21437/Interspeech.2019-1665", 5, "interspeech", 2019]], "Lauri Juvela": [0, ["GELP: GAN-Excited Linear Prediction for Speech Synthesis from Mel-Spectrogram", ["Lauri Juvela", "Bajibabu Bollepalli", "Junichi Yamagishi", "Paavo Alku"], "https://doi.org/10.21437/Interspeech.2019-2008", 5, "interspeech", 2019], ["Lombard Speech Synthesis Using Transfer Learning in a Tacotron Text-to-Speech System", ["Bajibabu Bollepalli", "Lauri Juvela", "Paavo Alku"], "https://doi.org/10.21437/Interspeech.2019-1333", 5, "interspeech", 2019], ["Augmented CycleGANs for Continuous Scale Normal-to-Lombard Speaking Style Conversion", ["Shreyas Seshadri", "Lauri Juvela", "Paavo Alku", "Okko Rasanen"], "https://doi.org/10.21437/Interspeech.2019-1681", 5, "interspeech", 2019]], "Maria Alejandra Barrios": [0, ["The VOiCES from a Distance Challenge 2019", ["Mahesh Kumar Nandwana", "Julien van Hout", "Colleen Richey", "Mitchell McLaren", "Maria Alejandra Barrios", "Aaron Lawson"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/abs14.html", 0, "interspeech", 2019]], "Lantian Li": [0, ["VAE-Based Regularization for Deep Speaker Embedding", ["Yang Zhang", "Lantian Li", "Dong Wang"], "https://doi.org/10.21437/Interspeech.2019-2486", 5, "interspeech", 2019]], "Anastasiia Tsukanova": [0, ["Towards a Method of Dynamic Vocal Tract Shapes Generation by Combining Static 3D and Dynamic 2D MRI Speech Data", ["Ioannis K. Douros", "Anastasiia Tsukanova", "Karyna Isaieva", "Pierre-Andre Vuissoz", "Yves Laprie"], "https://doi.org/10.21437/Interspeech.2019-2880", 5, "interspeech", 2019], ["A Multimodal Real-Time MRI Articulatory Corpus of French for Speech Research", ["Ioannis K. Douros", "Jacques Felblinger", "Jens Frahm", "Karyna Isaieva", "Arun A. Joseph", "Yves Laprie", "Freddy Odille", "Anastasiia Tsukanova", "Dirk Voit", "Pierre-Andre Vuissoz"], "https://doi.org/10.21437/Interspeech.2019-1700", 5, "interspeech", 2019]], "Yaogen Yang": [1.076108055997338e-07, ["Polyphone Disambiguation for Mandarin Chinese Using Conditional Neural Network with Multi-Level Embedding Features", ["Zexin Cai", "Yaogen Yang", "Chuxiong Zhang", "Xiaoyi Qin", "Ming Li"], "https://doi.org/10.21437/Interspeech.2019-1235", 5, "interspeech", 2019]], "Liumeng Xue": [0, ["Building a Mixed-Lingual Neural TTS System with Only Monolingual Data", ["Liumeng Xue", "Wei Song", "Guanghui Xu", "Lei Xie", "Zhizheng Wu"], "https://doi.org/10.21437/Interspeech.2019-3191", 5, "interspeech", 2019]], "Veronica Morfi": [0, ["Ensemble Models for Spoofing Detection in Automatic Speaker Verification", ["Bhusan Chettri", "Daniel Stoller", "Veronica Morfi", "Marco A. Martinez Ramirez", "Emmanouil Benetos", "Bob L. Sturm"], "https://doi.org/10.21437/Interspeech.2019-2505", 5, "interspeech", 2019]], "Thomas Drugman": [0, ["Towards Achieving Robust Universal Neural Vocoding", ["Jaime Lorenzo-Trueba", "Thomas Drugman", "Javier Latorre", "Thomas Merritt", "Bartosz Putrycz", "Roberto Barra-Chicote", "Alexis Moinet", "Vatsal Aggarwal"], "https://doi.org/10.21437/Interspeech.2019-1424", 5, "interspeech", 2019], ["Interpretable Deep Learning Model for the Detection and Reconstruction of Dysarthric Speech", ["Daniel Korzekwa", "Roberto Barra-Chicote", "Bozena Kostek", "Thomas Drugman", "Mateusz Lajszczak"], "https://doi.org/10.21437/Interspeech.2019-1206", 5, "interspeech", 2019], ["Fine-Grained Robust Prosody Transfer for Single-Speaker Neural Text-To-Speech", ["Viacheslav Klimkov", "Srikanth Ronanki", "Jonas Rohnke", "Thomas Drugman"], "https://doi.org/10.21437/Interspeech.2019-2571", 5, "interspeech", 2019]], "Wei Li": [0, ["Two-Pass End-to-End Speech Recognition", ["Tara N. Sainath", "Ruoming Pang", "David Rybach", "Yanzhang He", "Rohit Prabhavalkar", "Wei Li", "Mirko Visontai", "Qiao Liang", "Trevor Strohman", "Yonghui Wu", "Ian McGraw", "Chung-Cheng Chiu"], "https://doi.org/10.21437/Interspeech.2019-1341", 5, "interspeech", 2019]], "Timm Koppelmann": [0, ["Privacy-Preserving Siamese Feature Extraction for Gender Recognition versus Speaker Identification", ["Alexandru Nelus", "Silas Rech", "Timm Koppelmann", "Henrik Biermann", "Rainer Martin"], "https://doi.org/10.21437/Interspeech.2019-1148", 5, "interspeech", 2019]], "Carina Lozo": [0, ["Sound Tools eXtended (STx) 5.0 - A Powerful Sound Analysis Tool Optimized for Speech", ["Anton Noll", "Jonathan Stuefer", "Nicola Klingler", "Hannah Leykum", "Carina Lozo", "Jan Luttenberger", "Michael Pucher", "Carolin Schmid"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8022.html", 2, "interspeech", 2019]], "Helen Meng": [0, ["One-Shot Voice Conversion with Global Speaker Embeddings", ["Hui Lu", "Zhiyong Wu", "Dongyang Dai", "Runnan Li", "Shiyin Kang", "Jia Jia", "Helen Meng"], "https://doi.org/10.21437/Interspeech.2019-2365", 5, "interspeech", 2019], ["Jointly Trained Conversion Model and WaveNet Vocoder for Non-Parallel Voice Conversion Using Mel-Spectrograms and Phonetic Posteriorgrams", ["Songxiang Liu", "Yuewen Cao", "Xixin Wu", "Lifa Sun", "Xunying Liu", "Helen Meng"], "https://doi.org/10.21437/Interspeech.2019-1316", 5, "interspeech", 2019], ["Disambiguation of Chinese Polyphones in an End-to-End Framework with Semantic Features Extracted by Pre-Trained BERT", ["Dongyang Dai", "Zhiyong Wu", "Shiyin Kang", "Xixin Wu", "Jia Jia", "Dan Su", "Dong Yu", "Helen Meng"], "https://doi.org/10.21437/Interspeech.2019-2292", 5, "interspeech", 2019], ["Extract, Adapt and Recognize: An End-to-End Neural Network for Corrupted Monaural Speech Recognition", ["Max W. Y. Lam", "Jun Wang", "Xunying Liu", "Helen Meng", "Dan Su", "Dong Yu"], "https://doi.org/10.21437/Interspeech.2019-1626", 5, "interspeech", 2019], ["LF-MMI Training of Bayesian and Gaussian Process Time Delay Neural Networks for Speech Recognition", ["Shoukang Hu", "Xurong Xie", "Shansong Liu", "Max W. Y. Lam", "Jianwei Yu", "Xixin Wu", "Xunying Liu", "Helen Meng"], "https://doi.org/10.21437/Interspeech.2019-2379", 5, "interspeech", 2019], ["Unsupervised Methods for Audio Classification from Lecture Discussion Recordings", ["Hang Su", "Borislav Dzodzo", "Xixin Wu", "Xunying Liu", "Helen Meng"], "https://doi.org/10.21437/Interspeech.2019-2384", 5, "interspeech", 2019], ["Comparative Study of Parametric and Representation Uncertainty Modeling for Recurrent Neural Network Language Models", ["Jianwei Yu", "Max W. Y. Lam", "Shoukang Hu", "Xixin Wu", "Xu Li", "Yuewen Cao", "Xunying Liu", "Helen Meng"], "https://doi.org/10.21437/Interspeech.2019-1927", 5, "interspeech", 2019], ["The CUHK Dysarthric Speech Recognition Systems for English and Cantonese", ["Shoukang Hu", "Shansong Liu", "Heng Fai Chang", "Mengzhe Geng", "Jiani Chen", "Lau Wing Chung", "To Ka Hei", "Jianwei Yu", "Ka Ho Wong", "Xunying Liu", "Helen Meng"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8047.html", 2, "interspeech", 2019], ["Exploiting Visual Features Using Bayesian Gated Neural Networks for Disordered Speech Recognition", ["Shansong Liu", "Shoukang Hu", "Yi Wang", "Jianwei Yu", "Rongfeng Su", "Xunying Liu", "Helen Meng"], "https://doi.org/10.21437/Interspeech.2019-1536", 5, "interspeech", 2019], ["On the Use of Pitch Features for Disordered Speech Recognition", ["Shansong Liu", "Shoukang Hu", "Xunying Liu", "Helen Meng"], "https://doi.org/10.21437/Interspeech.2019-2609", 5, "interspeech", 2019], ["Knowledge-Based Linguistic Encoding for End-to-End Mandarin Text-to-Speech Synthesis", ["Jingbei Li", "Zhiyong Wu", "Runnan Li", "Pengpeng Zhi", "Song Yang", "Helen Meng"], "https://doi.org/10.21437/Interspeech.2019-1118", 5, "interspeech", 2019]], "Ariel Tankus": [0, ["Identifying Input Features for Development of Real-Time Translation of Neural Signals to Text", ["Janaki Sheth", "Ariel Tankus", "Michelle Tran", "Lindy Comstock", "Itzhak Fried", "William Speier"], "https://doi.org/10.21437/Interspeech.2019-3092", 5, "interspeech", 2019]], "Norihide Kitaoka": [0, ["Small-Footprint Magic Word Detection Method Using Convolutional LSTM Neural Network", ["Taiki Yamamoto", "Ryota Nishimura", "Masayuki Misaki", "Norihide Kitaoka"], "https://doi.org/10.21437/Interspeech.2019-1662", 5, "interspeech", 2019]], "Andreas Nautsch": [0, ["ASVspoof 2019: Future Horizons in Spoofed and Fake Audio Detection", ["Massimiliano Todisco", "Xin Wang", "Ville Vestman", "Md. Sahidullah", "Hector Delgado", "Andreas Nautsch", "Junichi Yamagishi", "Nicholas W. D. Evans", "Tomi H. Kinnunen", "Kong Aik Lee"], "https://doi.org/10.21437/Interspeech.2019-2249", 5, "interspeech", 2019], ["Survey Talk: Preserving Privacy in Speaker and Speech Characterisation", ["Andreas Nautsch"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/abs11.html", 0, "interspeech", 2019], ["Privacy-Preserving Speaker Recognition with Cohort Score Normalisation", ["Andreas Nautsch", "Jose Patino", "Amos Treiber", "Themos Stafylakis", "Petr Mizera", "Massimiliano Todisco", "Thomas Schneider", "Nicholas W. D. Evans"], "https://doi.org/10.21437/Interspeech.2019-2638", 5, "interspeech", 2019], ["The GDPR & Speech Data: Reflections of Legal and Technology Communities, First Steps Towards a Common Understanding", ["Andreas Nautsch", "Catherine Jasserand", "Els Kindt", "Massimiliano Todisco", "Isabel Trancoso", "Nicholas W. D. Evans"], "https://doi.org/10.21437/Interspeech.2019-2647", 5, "interspeech", 2019]], "Jan Skoglund": [0, ["Salient Speech Representations Based on Cloned Networks", ["W. Bastiaan Kleijn", "Felicia S. C. Lim", "Michael Chinen", "Jan Skoglund"], "https://doi.org/10.21437/Interspeech.2019-1861", 5, "interspeech", 2019], ["A Real-Time Wideband Neural Vocoder at 1.6kb/s Using LPCNet", ["Jean-Marc Valin", "Jan Skoglund"], "https://doi.org/10.21437/Interspeech.2019-1255", 5, "interspeech", 2019]], "Chong Min Lee": [0.05315150320529938, ["Development of Robust Automated Scoring Models Using Adversarial Input for Oral Proficiency Assessment", ["Su-Youn Yoon", "Chong Min Lee", "Klaus Zechner", "Keelan Evanini"], "https://doi.org/10.21437/Interspeech.2019-1711", 5, "interspeech", 2019]], "Calbert Graham": [0, ["Articulation Rate as a Metric in Spoken Language Assessment", ["Calbert Graham", "Francis Nolan"], "https://doi.org/10.21437/Interspeech.2019-2098", 5, "interspeech", 2019]], "Dina El Zarka": [0, ["Acoustic Cues to Topic and Narrow Focus in Egyptian Arabic", ["Dina El Zarka", "Barbara Schuppler", "Francesco Cangemi"], "https://doi.org/10.21437/Interspeech.2019-1189", 5, "interspeech", 2019]], "Feng Huang": [0, ["Harmonic-Aligned Frame Mask Based on Non-Stationary Gabor Transform with Application to Content-Dependent Speaker Comparison", ["Feng Huang", "Peter Balazs"], "https://doi.org/10.21437/Interspeech.2019-1327", 5, "interspeech", 2019]], "Shoko Araki": [0, ["Predicting Speech Intelligibility of Enhanced Speech Using Phone Accuracy of DNN-Based ASR System", ["Kenichi Arai", "Shoko Araki", "Atsunori Ogawa", "Keisuke Kinoshita", "Tomohiro Nakatani", "Katsuhiko Yamamoto", "Toshio Irino"], "https://doi.org/10.21437/Interspeech.2019-1381", 5, "interspeech", 2019]], "Shuiyang Mao": [0, ["Deep Learning of Segment-Level Feature Representation with Multiple Instance Learning for Utterance-Level Speech Emotion Recognition", ["Shuiyang Mao", "P. C. Ching", "Tan Lee"], "https://doi.org/10.21437/Interspeech.2019-1968", 5, "interspeech", 2019]], "Carlos Toshinori Ishi": [0, ["A Neural Turn-Taking Model without RNN", ["Chaoran Liu", "Carlos Toshinori Ishi", "Hiroshi Ishiguro"], "https://doi.org/10.21437/Interspeech.2019-2270", 5, "interspeech", 2019]], "Themos Stafylakis": [0, ["Detecting Spoofing Attacks Using VGG and SincNet: BUT-Omilia Submission to ASVspoof 2019 Challenge", ["Hossein Zeinali", "Themos Stafylakis", "Georgia Athanasopoulou", "Johan Rohdin", "Ioannis Gkinis", "Lukas Burget", "Jan Cernocky"], "https://doi.org/10.21437/Interspeech.2019-2892", 5, "interspeech", 2019], ["Self-Supervised Speaker Embeddings", ["Themos Stafylakis", "Johan Rohdin", "Oldrich Plchot", "Petr Mizera", "Lukas Burget"], "https://doi.org/10.21437/Interspeech.2019-2842", 5, "interspeech", 2019], ["Privacy-Preserving Speaker Recognition with Cohort Score Normalisation", ["Andreas Nautsch", "Jose Patino", "Amos Treiber", "Themos Stafylakis", "Petr Mizera", "Massimiliano Todisco", "Thomas Schneider", "Nicholas W. D. Evans"], "https://doi.org/10.21437/Interspeech.2019-2638", 5, "interspeech", 2019]], "Ravi Teja Gadde": [0, ["Jasper: An End-to-End Convolutional Neural Acoustic Model", ["Jason Li", "Vitaly Lavrukhin", "Boris Ginsburg", "Ryan Leary", "Oleksii Kuchaiev", "Jonathan M. Cohen", "Huyen Nguyen", "Ravi Teja Gadde"], "https://doi.org/10.21437/Interspeech.2019-1819", 5, "interspeech", 2019]], "Hannah King": [0, ["The Contribution of Lip Protrusion to Anglo-English /r/: Evidence from Hyper- and Non-Hyperarticulated Speech", ["Hannah King", "Emmanuel Ferragne"], "https://doi.org/10.21437/Interspeech.2019-2851", 5, "interspeech", 2019]], "Tom Ko": [0.00024866758030839264, ["Mixup Learning Strategies for Text-Independent Speaker Verification", ["Yingke Zhu", "Tom Ko", "Brian Mak"], "https://doi.org/10.21437/Interspeech.2019-2250", 5, "interspeech", 2019]], "Olaitan Olaleye": [0, ["Nonparallel Emotional Speech Conversion", ["Jian Gao", "Deep Chakraborty", "Hamidou Tembine", "Olaitan Olaleye"], "https://doi.org/10.21437/Interspeech.2019-2878", 5, "interspeech", 2019]], "Dirk Van Compernolle": [0, ["Examining the Combination of Multi-Band Processing and Channel Dropout for Robust Speech Recognition", ["Gyorgy Kovacs", "Laszlo Toth", "Dirk Van Compernolle", "Marcus Liwicki"], "https://doi.org/10.21437/Interspeech.2019-3215", 5, "interspeech", 2019]], "Martine Adda-Decker": [0, ["\" Gra[f] e!\" Word-Final Devoicing of Obstruents in Standard French: An Acoustic Study Based on Large Corpora", ["Adele Jatteau", "Ioana Vasilescu", "Lori Lamel", "Martine Adda-Decker", "Nicolas Audibert"], "https://doi.org/10.21437/Interspeech.2019-2329", 5, "interspeech", 2019]], "Yuka Kobayashi": [0, ["Slot Filling with Weighted Multi-Encoders for Out-of-Domain Values", ["Yuka Kobayashi", "Takami Yoshida", "Kenji Iwata", "Hiroshi Fujimura"], "https://doi.org/10.21437/Interspeech.2019-1226", 5, "interspeech", 2019]], "Anil Thomas": [0, ["Semi-Supervised Voice Conversion with Amortized Variational Inference", ["Cory Stephenson", "Gokce Keskin", "Anil Thomas", "Oguz H. Elibol"], "https://doi.org/10.21437/Interspeech.2019-1840", 5, "interspeech", 2019]], "Yang Ai": [0, ["Singing Voice Synthesis Using Deep Autoregressive Neural Networks for Acoustic Modeling", ["Yuan-Hao Yi", "Yang Ai", "Zhen-Hua Ling", "Li-Rong Dai"], "https://doi.org/10.21437/Interspeech.2019-1563", 5, "interspeech", 2019]], "Helena Moniz": [0, ["Unbabel Talk - Human Verified Translations for Voice Instant Messaging", ["Luis Bernardo", "Mathieu Giquel", "Sebastiao Quintas", "Paulo Dimas", "Helena Moniz", "Isabel Trancoso"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8034.html", 2, "interspeech", 2019]], "Tamsin M. McKelvey": [0, ["Using Prosody to Discover Word Order Alternations in a Novel Language", ["Anouschka Foltz", "Sarah Cooper", "Tamsin M. McKelvey"], "https://doi.org/10.21437/Interspeech.2019-1183", 5, "interspeech", 2019]], "Vincent Colotte": [0, ["Conditional Variational Auto-Encoder for Text-Driven Expressive AudioVisual Speech Synthesis", ["Sara Dahmani", "Vincent Colotte", "Valerian Girard", "Slim Ouni"], "https://doi.org/10.21437/Interspeech.2019-2848", 5, "interspeech", 2019]], "Guofu Yang": [4.500220462944071e-08, ["Two-Stage Training for Chinese Dialect Recognition", ["Zongze Ren", "Guofu Yang", "Shugong Xu"], "https://doi.org/10.21437/Interspeech.2019-1522", 5, "interspeech", 2019]], "Estelle Delpech": [0, ["The Airbus Air Traffic Control Speech Recognition 2018 Challenge: Towards ATC Automatic Transcription and Call Sign Detection", ["Thomas Pellegrini", "Jerome Farinas", "Estelle Delpech", "Francois Lancelot"], "https://doi.org/10.21437/Interspeech.2019-1962", 5, "interspeech", 2019]], "Antal van den Bosch": [0, ["Listening with Great Expectations: An Investigation of Word Form Anticipations in Naturalistic Speech", ["M. Bentum", "Louis ten Bosch", "Antal van den Bosch", "Mirjam Ernestus"], "https://doi.org/10.21437/Interspeech.2019-2741", 5, "interspeech", 2019], ["Quantifying Expectation Modulation in Human Speech Processing", ["M. Bentum", "Louis ten Bosch", "Antal van den Bosch", "Mirjam Ernestus"], "https://doi.org/10.21437/Interspeech.2019-2685", 5, "interspeech", 2019]], "Ebrahim Beyrami": [0, ["A Scalable Noisy Speech Dataset and Online Subjective Test Framework", ["Chandan K. A. Reddy", "Ebrahim Beyrami", "Jamie Pool", "Ross Cutler", "Sriram Srinivasan", "Johannes Gehrke"], "https://doi.org/10.21437/Interspeech.2019-3087", 5, "interspeech", 2019]], "Sandra Gollwitzer": [0, ["Phone-Attribute Posteriors to Evaluate the Speech of Cochlear Implant Users", ["Tomas Arias-Vergara", "Juan Rafael Orozco-Arroyave", "Milos Cernak", "Sandra Gollwitzer", "Maria Schuster", "Elmar Noth"], "https://doi.org/10.21437/Interspeech.2019-2144", 5, "interspeech", 2019]], "Jorg-Hendrik Bach": [0, ["\"Computer, Test My Hearing\": Accurate Speech Audiometry with Smart Speakers", ["Jasper Ooster", "Pia Nancy Porysek Moreta", "Jorg-Hendrik Bach", "Inga Holube", "Bernd T. Meyer"], "https://doi.org/10.21437/Interspeech.2019-2118", 5, "interspeech", 2019]], "Seyed Omid Sadjadi": [0, ["The 2018 NIST Speaker Recognition Evaluation", ["Seyed Omid Sadjadi", "Craig S. Greenberg", "Elliot Singer", "Douglas A. Reynolds", "Lisa P. Mason", "Jaime Hernandez-Cordero"], "https://doi.org/10.21437/Interspeech.2019-1351", 5, "interspeech", 2019]], "Manuel Schmitt": [0, ["Deep Learning for Orca Call Type Identification - A Fully Unsupervised Approach", ["Christian Bergler", "Manuel Schmitt", "Rachael Xi Cheng", "Andreas K. Maier", "Volker Barth", "Elmar Noth"], "https://doi.org/10.21437/Interspeech.2019-1857", 5, "interspeech", 2019]], "Sarah Dugan": [0, ["Using Ultrasound Imaging to Create Augmented Visual Biofeedback for Articulatory Practice", ["Colin T. Annand", "Maurice Lamb", "Sarah Dugan", "Sarah R. Li", "Hannah M. Woeste", "T. Douglas Mast", "Michael A. Riley", "Jack A. Masterson", "Neeraja Mahalingam", "Kathryn J. Eary", "Caroline Spencer", "Suzanne Boyce", "Stephanie Jackson", "Anoosha Baxi", "Renee Seward"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8036.html", 2, "interspeech", 2019]], "Piotr Pietrzak": [0, ["Lattice Generation in Attention-Based Speech Recognition Models", ["Michal Zapotoczny", "Piotr Pietrzak", "Adrian Lancucki", "Jan Chorowski"], "https://doi.org/10.21437/Interspeech.2019-2667", 5, "interspeech", 2019]], "Hao Shi": [0, ["Environment-Dependent Attention-Driven Recurrent Convolutional Neural Network for Robust Speech Enhancement", ["Meng Ge", "Longbiao Wang", "Nan Li", "Hao Shi", "Jianwu Dang", "Xiangang Li"], "https://doi.org/10.21437/Interspeech.2019-1477", 5, "interspeech", 2019]], "Yuke Si": [0, ["CNN-BLSTM Based Question Detection from Dialogs Considering Phase and Context Information", ["Yuke Si", "Longbiao Wang", "Jianwu Dang", "Mengfei Wu", "Aijun Li"], "https://doi.org/10.21437/Interspeech.2019-1701", 5, "interspeech", 2019]], "Thilo Michael": [0, ["Extending the E-Model Towards Super-Wideband and Fullband Speech Communication Scenarios", ["Sebastian Moller", "Gabriel Mittag", "Thilo Michael", "Vincent Barriac", "Hitoshi Aoki"], "https://doi.org/10.21437/Interspeech.2019-1340", 5, "interspeech", 2019]], "Denis Peskov": [0, ["Mitigating Noisy Inputs for Question Answering", ["Denis Peskov", "Joe Barrow", "Pedro Rodriguez", "Graham Neubig", "Jordan L. Boyd-Graber"], "https://doi.org/10.21437/Interspeech.2019-3154", 5, "interspeech", 2019]], "Zikra Iqbal": [0, ["CaptionAI: A Real-Time Multilingual Captioning Application", ["Nagendra Kumar Goel", "Mousmita Sarma", "Saikiran Valluri", "Dharmeshkumar Agrawal", "Steve Braich", "Tejendra Singh Kuswah", "Zikra Iqbal", "Surbhi Chauhan", "Raj Karbar"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8039.html", 2, "interspeech", 2019]], "Simon Stone": [0, ["Perceptual Optimization of an Enhanced Geometric Vocal Fold Model for Articulatory Speech Synthesis", ["Peter Birkholz", "Susanne Drechsel", "Simon Stone"], "https://doi.org/10.21437/Interspeech.2019-2410", 5, "interspeech", 2019], ["Articulatory Copy Synthesis Based on a Genetic Algorithm", ["Yingming Gao", "Simon Stone", "Peter Birkholz"], "https://doi.org/10.21437/Interspeech.2019-1334", 5, "interspeech", 2019]], "Bin Liu": [0, ["Jointly Adversarial Enhancement Training for Robust End-to-End Speech Recognition", ["Bin Liu", "Shuai Nie", "Shan Liang", "Wenju Liu", "Meng Yu", "Lianwu Chen", "Shouye Peng", "Changliang Li"], "https://doi.org/10.21437/Interspeech.2019-1242", 5, "interspeech", 2019], ["Conversational Emotion Analysis via Attention Mechanisms", ["Zheng Lian", "Jianhua Tao", "Bin Liu", "Jian Huang"], "https://doi.org/10.21437/Interspeech.2019-1577", 5, "interspeech", 2019], ["Unsupervised Representation Learning with Future Observation Prediction for Speech Emotion Recognition", ["Zheng Lian", "Jianhua Tao", "Bin Liu", "Jian Huang"], "https://doi.org/10.21437/Interspeech.2019-1582", 5, "interspeech", 2019], ["Automatic Depression Level Detection via \u2113p-Norm Pooling", ["Mingyue Niu", "Jianhua Tao", "Bin Liu", "Cunhang Fan"], "https://doi.org/10.21437/Interspeech.2019-1617", 5, "interspeech", 2019], ["Discriminative Learning for Monaural Speech Separation Using Deep Embedding Features", ["Cunhang Fan", "Bin Liu", "Jianhua Tao", "Jiangyan Yi", "Zhengqi Wen"], "https://doi.org/10.21437/Interspeech.2019-1940", 5, "interspeech", 2019]], "Xinjian Li": [0, ["Multilingual Speech Recognition with Corpus Relatedness Sampling", ["Xinjian Li", "Siddharth Dalmia", "Alan W. Black", "Florian Metze"], "https://doi.org/10.21437/Interspeech.2019-3052", 5, "interspeech", 2019], ["SANTLR: Speech Annotation Toolkit for Low Resource Languages", ["Xinjian Li", "Zhong Zhou", "Siddharth Dalmia", "Alan W. Black", "Florian Metze"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8040.html", 2, "interspeech", 2019]], "Haihua Xu": [0, ["Constrained Output Embeddings for End-to-End Code-Switching Speech Recognition with Only Monolingual Data", ["Yerbolat Khassanov", "Haihua Xu", "Van Tung Pham", "Zhiping Zeng", "Eng Siong Chng", "Chongjia Ni", "Bin Ma"], "https://doi.org/10.21437/Interspeech.2019-1867", 5, "interspeech", 2019], ["On the End-to-End Solution to Mandarin-English Code-Switching Speech Recognition", ["Zhiping Zeng", "Yerbolat Khassanov", "Van Tung Pham", "Haihua Xu", "Eng Siong Chng", "Haizhou Li"], "https://doi.org/10.21437/Interspeech.2019-1429", 5, "interspeech", 2019], ["Enriching Rare Word Representations in Neural Language Models by Embedding Matrix Augmentation", ["Yerbolat Khassanov", "Zhiping Zeng", "Van Tung Pham", "Haihua Xu", "Eng Siong Chng"], "https://doi.org/10.21437/Interspeech.2019-1858", 5, "interspeech", 2019]], "Javier Ferreiros Lopez": [0, ["Attention-Based Word Vector Prediction with LSTMs and its Application to the OOV Problem in ASR", ["Alejandro Coucheiro-Limeres", "Fernando Fernandez-Martinez", "Ruben San Segundo", "Javier Ferreiros Lopez"], "https://doi.org/10.21437/Interspeech.2019-2347", 5, "interspeech", 2019]], "Alexandre Riviello": [0, ["Binary Speech Features for Keyword Spotting Tasks", ["Alexandre Riviello", "Jean-Pierre David"], "https://doi.org/10.21437/Interspeech.2019-1877", 5, "interspeech", 2019]], "Richard A. Wright": [0, ["Disfluencies and Human Speech Transcription Errors", ["Vicky Zayats", "Trang Tran", "Richard A. Wright", "Courtney Mansfield", "Mari Ostendorf"], "https://doi.org/10.21437/Interspeech.2019-3134", 5, "interspeech", 2019]], "Swapnil Bhosale": [0, ["End-to-End Spoken Language Understanding: Bootstrapping in Low Resource Scenarios", ["Swapnil Bhosale", "Imran Sheikh", "Sri Harsha Dumpala", "Sunil Kumar Kopparapu"], "https://doi.org/10.21437/Interspeech.2019-2366", 5, "interspeech", 2019]], "Cunhang Fan": [0, ["A Time Delay Neural Network with Shared Weight Self-Attention for Small-Footprint Keyword Spotting", ["Ye Bai", "Jiangyan Yi", "Jianhua Tao", "Zhengqi Wen", "Zhengkun Tian", "Chenghao Zhao", "Cunhang Fan"], "https://doi.org/10.21437/Interspeech.2019-1676", 5, "interspeech", 2019], ["Automatic Depression Level Detection via \u2113p-Norm Pooling", ["Mingyue Niu", "Jianhua Tao", "Bin Liu", "Cunhang Fan"], "https://doi.org/10.21437/Interspeech.2019-1617", 5, "interspeech", 2019], ["Discriminative Learning for Monaural Speech Separation Using Deep Embedding Features", ["Cunhang Fan", "Bin Liu", "Jianhua Tao", "Jiangyan Yi", "Zhengqi Wen"], "https://doi.org/10.21437/Interspeech.2019-1940", 5, "interspeech", 2019]], "Giuliano Tortoreto": [0, ["Active Annotation: Bootstrapping Annotation Lexicon and Guidelines for Supervised NLU Learning", ["Federico Marinelli", "Alessandra Cervone", "Giuliano Tortoreto", "Evgeny A. Stepanov", "Giuseppe Di Fabbrizio", "Giuseppe Riccardi"], "https://doi.org/10.21437/Interspeech.2019-2537", 5, "interspeech", 2019]], "Jesper Bunsow Boldt": [0, ["Harmonic Beamformers for Non-Intrusive Speech Intelligibility Prediction", ["Charlotte Sorensen", "Jesper Bunsow Boldt", "Mads Graesboll Christensen"], "https://doi.org/10.21437/Interspeech.2019-2929", 5, "interspeech", 2019]], "Georgios Pantazopoulos": [0, ["Data Augmentation Using GANs for Speech Emotion Recognition", ["Aggelina Chatziagapi", "Georgios Paraskevopoulos", "Dimitris Sgouropoulos", "Georgios Pantazopoulos", "Malvina Nikandrou", "Theodoros Giannakopoulos", "Athanasios Katsamanis", "Alexandros Potamianos", "Shrikanth Narayanan"], "https://doi.org/10.21437/Interspeech.2019-2561", 5, "interspeech", 2019]], "Anu Venkatesh": [0, ["Topical-Chat: Towards Knowledge-Grounded Open-Domain Conversations", ["Karthik Gopalakrishnan", "Behnam Hedayatnia", "Qinglang Chen", "Anna Gottardi", "Sanjeev Kwatra", "Anu Venkatesh", "Raefer Gabriel", "Dilek Hakkani-Tur"], "https://doi.org/10.21437/Interspeech.2019-3079", 5, "interspeech", 2019]], "Steve Braich": [0, ["CaptionAI: A Real-Time Multilingual Captioning Application", ["Nagendra Kumar Goel", "Mousmita Sarma", "Saikiran Valluri", "Dharmeshkumar Agrawal", "Steve Braich", "Tejendra Singh Kuswah", "Zikra Iqbal", "Surbhi Chauhan", "Raj Karbar"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8039.html", 2, "interspeech", 2019]], "Md. Nasir": [0, ["Modeling Interpersonal Linguistic Coordination in Conversations Using Word Mover's Distance", ["Md. Nasir", "Sandeep Nallan Chakravarthula", "Brian R. W. Baucom", "David C. Atkins", "Panayiotis G. Georgiou", "Shrikanth Narayanan"], "https://doi.org/10.21437/Interspeech.2019-1900", 5, "interspeech", 2019]], "Ji Ming": [0, ["Full-Sentence Correlation: A Method to Handle Unpredictable Noise for Robust Speech Recognition", ["Ji Ming", "Danny Crookes"], "https://doi.org/10.21437/Interspeech.2019-2127", 5, "interspeech", 2019]], "Martin Jaggi": [0, ["Open-Vocabulary Keyword Spotting with Audio and Text Embeddings", ["Niccolo Sacchi", "Alexandre Nanchen", "Martin Jaggi", "Milos Cernak"], "https://doi.org/10.21437/Interspeech.2019-1846", 5, "interspeech", 2019]], "Yossi Matias": [0, ["Personalizing ASR for Dysarthric and Accented Speech with Limited Data", ["Joel Shor", "Dotan Emanuel", "Oran Lang", "Omry Tuval", "Michael Brenner", "Julie Cattiau", "Fernando Vieira", "Maeve McNally", "Taylor Charbonneau", "Melissa Nollstadt", "Avinatan Hassidim", "Yossi Matias"], "https://doi.org/10.21437/Interspeech.2019-1427", 5, "interspeech", 2019]], "Chitralekha Gupta": [0, ["Acoustic Modeling for Automatic Lyrics-to-Audio Alignment", ["Chitralekha Gupta", "Emre Yilmaz", "Haizhou Li"], "https://doi.org/10.21437/Interspeech.2019-1520", 5, "interspeech", 2019], ["NUS Speak-to-Sing: A Web Platform for Personalized Speech-to-Singing Conversion", ["Chitralekha Gupta", "Karthika Vijayan", "Bidisha Sharma", "Xiaoxue Gao", "Haizhou Li"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8041.html", 2, "interspeech", 2019]], "Jing Shi": [0, ["Which Ones Are Speaking? Speaker-Inferred Model for Multi-Talker Speech Separation", ["Jing Shi", "Jiaming Xu", "Bo Xu"], "https://doi.org/10.21437/Interspeech.2019-1591", 5, "interspeech", 2019]], "Jiaqi Zhong": [0, ["Pre-Trained Text Representations for Improving Front-End Text Processing in Mandarin Text-to-Speech Synthesis", ["Bing Yang", "Jiaqi Zhong", "Shan Liu"], "https://doi.org/10.21437/Interspeech.2019-1418", 5, "interspeech", 2019]], "Petr Zadrazil": [0, ["An Investigation into On-Device Personalization of End-to-End Automatic Speech Recognition Models", ["Khe Chai Sim", "Petr Zadrazil", "Francoise Beaufays"], "https://doi.org/10.21437/Interspeech.2019-1752", 5, "interspeech", 2019]], "Thomas Niesler": [0, ["Improved Low-Resource Somali Speech Recognition by Semi-Supervised Acoustic and Language Model Training", ["Astik Biswas", "Raghav Menon", "Ewald van der Westhuizen", "Thomas Niesler"], "https://doi.org/10.21437/Interspeech.2019-1328", 5, "interspeech", 2019], ["Feature Exploration for Almost Zero-Resource ASR-Free Keyword Spotting Using a Multilingual Bottleneck Extractor and Correspondence Autoencoders", ["Raghav Menon", "Herman Kamper", "Ewald van der Westhuizen", "John Quinn", "Thomas Niesler"], "https://doi.org/10.21437/Interspeech.2019-1665", 5, "interspeech", 2019], ["Improving Automatically Induced Lexicons for Highly Agglutinating Languages Using Data-Driven Morphological Segmentation", ["Wiehan Agenbag", "Thomas Niesler"], "https://doi.org/10.21437/Interspeech.2019-2164", 5, "interspeech", 2019], ["Semi-Supervised Acoustic Model Training for Five-Lingual Code-Switched ASR", ["Astik Biswas", "Emre Yilmaz", "Febe de Wet", "Ewald van der Westhuizen", "Thomas Niesler"], "https://doi.org/10.21437/Interspeech.2019-1325", 5, "interspeech", 2019]], "Athanasios Katsamanis": [0, ["Data Augmentation Using GANs for Speech Emotion Recognition", ["Aggelina Chatziagapi", "Georgios Paraskevopoulos", "Dimitris Sgouropoulos", "Georgios Pantazopoulos", "Malvina Nikandrou", "Theodoros Giannakopoulos", "Athanasios Katsamanis", "Alexandros Potamianos", "Shrikanth Narayanan"], "https://doi.org/10.21437/Interspeech.2019-2561", 5, "interspeech", 2019]], "Pedro J. Moreno": [0, ["Parrotron: An End-to-End Speech-to-Speech Conversion Model and its Applications to Hearing-Impaired Speech and Speech Separation", ["Fadi Biadsy", "Ron J. Weiss", "Pedro J. Moreno", "Dimitri Kanvesky", "Ye Jia"], "https://doi.org/10.21437/Interspeech.2019-1789", 5, "interspeech", 2019]], "Jia Cui": [0, ["Large Margin Training for Attention Based End-to-End Speech Recognition", ["Peidong Wang", "Jia Cui", "Chao Weng", "Dong Yu"], "https://doi.org/10.21437/Interspeech.2019-1680", 5, "interspeech", 2019]], "Anna Esposito": [0, ["The Dependability of Voice on Elders' Acceptance of Humanoid Agents", ["Anna Esposito", "Terry Amorese", "Marialucia Cuciniello", "Maria Teresa Riviello", "Antonietta Maria Esposito", "Alda Troncone", "Gennaro Cordasco"], "https://doi.org/10.21437/Interspeech.2019-1734", 5, "interspeech", 2019]], "Barbara Gili Fivela": [0, ["L2 Pronunciation Accuracy and Context: A Pilot Study on the Realization of Geminates in Italian as L2 by French Learners", ["Sonia DApolito", "Barbara Gili Fivela"], "https://doi.org/10.21437/Interspeech.2019-2934", 5, "interspeech", 2019]], "Ryoichi Takashima": [0, ["Auxiliary Interference Speaker Loss for Target-Speaker Speech Recognition", ["Naoyuki Kanda", "Shota Horiguchi", "Ryoichi Takashima", "Yusuke Fujita", "Kenji Nagamatsu", "Shinji Watanabe"], "https://doi.org/10.21437/Interspeech.2019-1126", 5, "interspeech", 2019]], "Sandy Ritchie": [0, ["Building Large-Vocabulary ASR Systems for Languages Without Any Audio Training Data", ["Manasa Prasad", "Daan van Esch", "Sandy Ritchie", "Jonas Fromseier Mortensen"], "https://doi.org/10.21437/Interspeech.2019-1775", 5, "interspeech", 2019], ["Developing Pronunciation Models in New Languages Faster by Exploiting Common Grapheme-to-Phoneme Correspondences Across Languages", ["Harry Bleyan", "Sandy Ritchie", "Jonas Fromseier Mortensen", "Daan van Esch"], "https://doi.org/10.21437/Interspeech.2019-1781", 5, "interspeech", 2019], ["Unified Verbalization for Speech Recognition & Synthesis Across Languages", ["Sandy Ritchie", "Richard Sproat", "Kyle Gorman", "Daan van Esch", "Christian Schallhart", "Nikos Bampounis", "Benoit Brard", "Jonas Fromseier Mortensen", "Millie Holt", "Eoin Mahon"], "https://doi.org/10.21437/Interspeech.2019-2807", 5, "interspeech", 2019]], "Fang Bao": [0, ["CycleGAN-Based Emotion Style Transfer as Data Augmentation for Speech Emotion Recognition", ["Fang Bao", "Michael Neumann", "Ngoc Thang Vu"], "https://doi.org/10.21437/Interspeech.2019-2293", 5, "interspeech", 2019]], "Yamini Belur": [0, ["Comparison of Speech Tasks and Recording Devices for Voice Based Automatic Classification of Healthy Subjects and Patients with Amyotrophic Lateral Sclerosis", ["Suhas B. N.", "Deep Patel", "Nithin Rao Koluguri", "Yamini Belur", "Pradeep Reddy", "Atchayaram Nalini", "Ravi Yadav", "Dipanjan Gope", "Prasanta Kumar Ghosh"], "https://doi.org/10.21437/Interspeech.2019-1285", 5, "interspeech", 2019]], "Kevin Hogan": [0, ["Regression and Classification for Direction-of-Arrival Estimation with Convolutional Recurrent Neural Networks", ["Zhenyu Tang", "John D. Kanu", "Kevin Hogan", "Dinesh Manocha"], "https://doi.org/10.21437/Interspeech.2019-1111", 5, "interspeech", 2019]], "Kristin Haake": [0, ["Do Hesitations Facilitate Processing of Partially Defective System Utterances? An Exploratory Eye Tracking Study", ["Kristin Haake", "Sarah Schimke", "Simon Betz", "Sina Zarriess"], "https://doi.org/10.21437/Interspeech.2019-2820", 5, "interspeech", 2019]], "Jan Vanek": [0, ["UWB-NTIS Speaker Diarization System for the DIHARD II 2019 Challenge", ["Zbynek Zajic", "Marie Kunesova", "Marek Hruz", "Jan Vanek"], "https://doi.org/10.21437/Interspeech.2019-1385", 5, "interspeech", 2019]], "Pegah Ghahremani": [0, ["Improving Emotion Identification Using Phone Posteriors in Raw Speech Waveform Based DNN", ["Mousmita Sarma", "Pegah Ghahremani", "Daniel Povey", "Nagendra Kumar Goel", "Kandarpa Kumar Sarma", "Najim Dehak"], "https://doi.org/10.21437/Interspeech.2019-2093", 5, "interspeech", 2019]], "Johan Sjons": [0, ["No Distributional Learning in Adults from Attended Listening to Non-Speech", ["Ellen Marklund", "Johan Sjons", "Lisa Gustavsson", "Elisabet Eir Cortes"], "https://doi.org/10.21437/Interspeech.2019-1674", 5, "interspeech", 2019]], "Jan Mizgajski": [0, ["Avaya Conversational Intelligence: A Real-Time System for Spoken Language Understanding in Human-Human Call Center Conversations", ["Jan Mizgajski", "Adrian Szymczak", "Robert Glowski", "Piotr Szymanski", "Piotr Zelasko", "Lukasz Augustyniak", "Mikolaj Morzy", "Yishay Carmiel", "Jeff Hodson", "Lukasz Wojciak", "Daniel Smoczyk", "Adam Wrobel", "Bartosz Borowik", "Adam Artajew", "Marcin Baran", "Cezary Kwiatkowski", "Marzena Zyla-Hoppe"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8002.html", 2, "interspeech", 2019]], "Tetsunori Kobayashi": [0, ["Multi-Channel Speech Enhancement Using Time-Domain Convolutional Denoising Autoencoder", ["Naohiro Tawara", "Tetsunori Kobayashi", "Tetsuji Ogawa"], "https://doi.org/10.21437/Interspeech.2019-3197", 5, "interspeech", 2019], ["Speaker Adversarial Training of DPGMM-Based Feature Extractor for Zero-Resource Languages", ["Yosuke Higuchi", "Naohiro Tawara", "Tetsunori Kobayashi", "Tetsuji Ogawa"], "https://doi.org/10.21437/Interspeech.2019-2052", 5, "interspeech", 2019], ["Recognition of Intentions of Users' Short Responses for Conversational News Delivery System", ["Hiroaki Takatsu", "Katsuya Yokoyama", "Yoichi Matsuyama", "Hiroshi Honda", "Shinya Fujie", "Tetsunori Kobayashi"], "https://doi.org/10.21437/Interspeech.2019-2121", 5, "interspeech", 2019]], "Hongji Wang": [0.0962471030652523, ["The SJTU Robust Anti-Spoofing System for the ASVspoof 2019 Challenge", ["Yexin Yang", "Hongji Wang", "Heinrich Dinkel", "Zhengyang Chen", "Shuai Wang", "Yanmin Qian", "Kai Yu"], "https://doi.org/10.21437/Interspeech.2019-2170", 5, "interspeech", 2019], ["Cross-Domain Replay Spoofing Attack Detection Using Domain Adversarial Training", ["Hongji Wang", "Heinrich Dinkel", "Shuai Wang", "Yanmin Qian", "Kai Yu"], "https://doi.org/10.21437/Interspeech.2019-2120", 5, "interspeech", 2019]], "Bartosz Putrycz": [0, ["Towards Achieving Robust Universal Neural Vocoding", ["Jaime Lorenzo-Trueba", "Thomas Drugman", "Javier Latorre", "Thomas Merritt", "Bartosz Putrycz", "Roberto Barra-Chicote", "Alexis Moinet", "Vatsal Aggarwal"], "https://doi.org/10.21437/Interspeech.2019-1424", 5, "interspeech", 2019]], "Tomoki Morita": [0, ["Lyrics Recognition from Singing Voice Focused on Correspondence Between Voice and Notes", ["Motoyuki Suzuki", "Sho Tomita", "Tomoki Morita"], "https://doi.org/10.21437/Interspeech.2019-1318", 4, "interspeech", 2019]], "Xuyang Wang": [1.0101209682034096e-05, ["The LeVoice Far-Field Speech Recognition System for VOiCES from a Distance Challenge 2019", ["Yulong Liang", "Lin Yang", "Xuyang Wang", "Yingjie Li", "Chen Jia", "Junjie Wang"], "https://doi.org/10.21437/Interspeech.2019-1944", 5, "interspeech", 2019]], "Robin Algayres": [0, ["The Zero Resource Speech Challenge 2019: TTS Without T", ["Ewan Dunbar", "Robin Algayres", "Julien Karadayi", "Mathieu Bernard", "Juan Benjumea", "Xuan-Nga Cao", "Lucie Miskic", "Charlotte Dugrain", "Lucas Ondel", "Alan W. Black", "Laurent Besacier", "Sakriani Sakti", "Emmanuel Dupoux"], "https://doi.org/10.21437/Interspeech.2019-2904", 5, "interspeech", 2019]], "Hongyin Luo": [0, ["Integrating Video Retrieval and Moment Detection in a Unified Corpus for Video Question Answering", ["Hongyin Luo", "Mitra Mohtarami", "James R. Glass", "Karthik Krishnamurthy", "Brigitte Richardson"], "https://doi.org/10.21437/Interspeech.2019-1736", 5, "interspeech", 2019]], "Senthil Mani": [0, ["Adversarial Black-Box Attacks on Automatic Speech Recognition Systems Using Multi-Objective Evolutionary Optimization", ["Shreya Khare", "Rahul Aralikatte", "Senthil Mani"], "https://doi.org/10.21437/Interspeech.2019-2420", 5, "interspeech", 2019]], "Utsav Prabhu": [0, ["Large-Scale Visual Speech Recognition", ["Brendan Shillingford", "Yannis M. Assael", "Matthew W. Hoffman", "Thomas Paine", "Cian Hughes", "Utsav Prabhu", "Hank Liao", "Hasim Sak", "Kanishka Rao", "Lorrayne Bennett", "Marie Mulville", "Misha Denil", "Ben Coppin", "Ben Laurie", "Andrew W. Senior", "Nando de Freitas"], "https://doi.org/10.21437/Interspeech.2019-1669", 5, "interspeech", 2019]], "Mitchell McLaren": [0, ["The VOiCES from a Distance Challenge 2019", ["Mahesh Kumar Nandwana", "Julien van Hout", "Colleen Richey", "Mitchell McLaren", "Maria Auxiliadora Barrios", "Aaron Lawson"], "https://doi.org/10.21437/Interspeech.2019-1837", 5, "interspeech", 2019], ["The VOiCES from a Distance Challenge 2019", ["Mahesh Kumar Nandwana", "Julien van Hout", "Colleen Richey", "Mitchell McLaren", "Maria Alejandra Barrios", "Aaron Lawson"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/abs14.html", 0, "interspeech", 2019], ["Language Recognition Using Triplet Neural Networks", ["Victoria Mingote", "Diego Castan", "Mitchell McLaren", "Mahesh Kumar Nandwana", "Alfonso Ortega Gimenez", "Eduardo Lleida", "Antonio Miguel"], "https://doi.org/10.21437/Interspeech.2019-2437", 5, "interspeech", 2019], ["Analysis of Critical Metadata Factors for the Calibration of Speaker Recognition Systems", ["Mahesh Kumar Nandwana", "Luciana Ferrer", "Mitchell McLaren", "Diego Castan", "Aaron Lawson"], "https://doi.org/10.21437/Interspeech.2019-1808", 5, "interspeech", 2019], ["Optimizing a Speaker Embedding Extractor Through Backend-Driven Regularization", ["Luciana Ferrer", "Mitchell McLaren"], "https://doi.org/10.21437/Interspeech.2019-1820", 5, "interspeech", 2019]], "Shih-Hau Fang": [0, ["Speaker-Aware Deep Denoising Autoencoder with Embedded Speaker Identity for Speech Enhancement", ["Fu-Kai Chuang", "Syu-Siang Wang", "Jeih-weih Hung", "Yu Tsao", "Shih-Hau Fang"], "https://doi.org/10.21437/Interspeech.2019-2108", 5, "interspeech", 2019]], "Amirhossein Hajavi": [0, ["A Deep Neural Network for Short-Segment Speaker Recognition", ["Amirhossein Hajavi", "Ali Etemad"], "https://doi.org/10.21437/Interspeech.2019-2240", 5, "interspeech", 2019]], "Rodrigo C. G. Pena": [0, ["Evaluating Audiovisual Source Separation in the Context of Video Conferencing", ["Berkay Inan", "Milos Cernak", "Helmut Grabner", "Helena Peic Tukuljac", "Rodrigo C. G. Pena", "Benjamin Ricaud"], "https://doi.org/10.21437/Interspeech.2019-2671", 5, "interspeech", 2019]], "Kangkang Lu": [0, ["Semi-Supervised Audio Classification with Consistency-Based Regularization", ["Kangkang Lu", "Chuan-Sheng Foo", "Kah Kuan Teh", "Huy Dat Tran", "Vijay Ramaseshan Chandrasekhar"], "https://doi.org/10.21437/Interspeech.2019-1231", 5, "interspeech", 2019]], "Lianwu Chen": [0, ["Improved Speaker-Dependent Separation for CHiME-5 Challenge", ["Jian Wu", "Yong Xu", "Shi-Xiong Zhang", "Lianwu Chen", "Meng Yu", "Lei Xie", "Dong Yu"], "https://doi.org/10.21437/Interspeech.2019-1569", 5, "interspeech", 2019], ["Jointly Adversarial Enhancement Training for Robust End-to-End Speech Recognition", ["Bin Liu", "Shuai Nie", "Shan Liang", "Wenju Liu", "Meng Yu", "Lianwu Chen", "Shouye Peng", "Changliang Li"], "https://doi.org/10.21437/Interspeech.2019-1242", 5, "interspeech", 2019], ["Direction-Aware Speaker Beam for Multi-Channel Speaker Extraction", ["Guanjun Li", "Shan Liang", "Shuai Nie", "Wenju Liu", "Meng Yu", "Lianwu Chen", "Shouye Peng", "Changliang Li"], "https://doi.org/10.21437/Interspeech.2019-1474", 5, "interspeech", 2019], ["Neural Spatial Filter: Target Speaker Speech Separation Assisted with Directional Information", ["Rongzhi Gu", "Lianwu Chen", "Shi-Xiong Zhang", "Jimeng Zheng", "Yong Xu", "Meng Yu", "Dan Su", "Yuexian Zou", "Dong Yu"], "https://doi.org/10.21437/Interspeech.2019-2266", 5, "interspeech", 2019]], "Dipanjan Gope": [0, ["Comparison of Speech Tasks and Recording Devices for Voice Based Automatic Classification of Healthy Subjects and Patients with Amyotrophic Lateral Sclerosis", ["Suhas B. N.", "Deep Patel", "Nithin Rao Koluguri", "Yamini Belur", "Pradeep Reddy", "Atchayaram Nalini", "Ravi Yadav", "Dipanjan Gope", "Prasanta Kumar Ghosh"], "https://doi.org/10.21437/Interspeech.2019-1285", 5, "interspeech", 2019]], "Ignacio Lopez-Moreno": [0, ["Improving Keyword Spotting and Language Identification via Neural Architecture Search at Scale", ["Hanna Mazzawi", "Xavi Gonzalvo", "Aleks Kracun", "Prashant Sridhar", "Niranjan Subrahmanya", "Ignacio Lopez-Moreno", "Hyun-Jin Park", "Patrick Violette"], "https://doi.org/10.21437/Interspeech.2019-1916", 5, "interspeech", 2019], ["VoiceFilter: Targeted Voice Separation by Speaker-Conditioned Spectrogram Masking", ["Quan Wang", "Hannah Muckenhirn", "Kevin W. Wilson", "Prashant Sridhar", "Zelin Wu", "John R. Hershey", "Rif A. Saurous", "Ron J. Weiss", "Ye Jia", "Ignacio Lopez-Moreno"], "https://doi.org/10.21437/Interspeech.2019-1101", 5, "interspeech", 2019]], "Guillaume Fuchs": [0, ["Super-Wideband Spectral Envelope Modeling for Speech Coding", ["Guillaume Fuchs", "Chamran Ashour", "Tom Backstrom"], "https://doi.org/10.21437/Interspeech.2019-1620", 5, "interspeech", 2019]], "Khiet P. Truong": [0, ["Towards an Annotation Scheme for Complex Laughter in Speech Corpora", ["Khiet P. Truong", "Jurgen Trouvain", "Michel-Pierre Jansen"], "https://doi.org/10.21437/Interspeech.2019-1557", 5, "interspeech", 2019], ["An Acoustic and Lexical Analysis of Emotional Valence in Spontaneous Speech: Autobiographical Memory Recall in Older Adults", ["Deniece S. Nazareth", "Ellen Tournier", "Sarah Leimkotter", "Esther Janse", "Dirk Heylen", "Gerben J. Westerhof", "Khiet P. Truong"], "https://doi.org/10.21437/Interspeech.2019-1823", 5, "interspeech", 2019]], "Roi Reichart": [0, ["GECKO - A Tool for Effective Annotation of Human Conversations", ["Golan Levy", "Raquel Sitman", "Ido Amir", "Eduard Golshtein", "Ran Mochary", "Eilon Reshef", "Roi Reichart", "Omri Allouche"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8025.html", 2, "interspeech", 2019]], "Kevin El Haddad": [0, ["Visualization and Interpretation of Latent Spaces for Controlling Expressive Speech Synthesis Through Audio Analysis", ["Noe Tits", "Fengna Wang", "Kevin El Haddad", "Vincent Pagel", "Thierry Dutoit"], "https://doi.org/10.21437/Interspeech.2019-1426", 5, "interspeech", 2019]], "Tatiana Likhomanenko": [0, ["Who Needs Words? Lexicon-Free Speech Recognition", ["Tatiana Likhomanenko", "Gabriel Synnaeve", "Ronan Collobert"], "https://doi.org/10.21437/Interspeech.2019-3107", 5, "interspeech", 2019]], "Xiulin Li": [0, ["A Mandarin Prosodic Boundary Prediction Model Based on Multi-Task Learning", ["Huashan Pan", "Xiulin Li", "Zhiqiang Huang"], "https://doi.org/10.21437/Interspeech.2019-1400", 4, "interspeech", 2019]], "Jianhua Tao": [0, ["Forward-Backward Decoding for Regularizing End-to-End TTS", ["Yibin Zheng", "Xi Wang", "Lei He", "Shifeng Pan", "Frank K. Soong", "Zhengqi Wen", "Jianhua Tao"], "https://doi.org/10.21437/Interspeech.2019-2325", 5, "interspeech", 2019], ["Conversational Emotion Analysis via Attention Mechanisms", ["Zheng Lian", "Jianhua Tao", "Bin Liu", "Jian Huang"], "https://doi.org/10.21437/Interspeech.2019-1577", 5, "interspeech", 2019], ["A Time Delay Neural Network with Shared Weight Self-Attention for Small-Footprint Keyword Spotting", ["Ye Bai", "Jiangyan Yi", "Jianhua Tao", "Zhengqi Wen", "Zhengkun Tian", "Chenghao Zhao", "Cunhang Fan"], "https://doi.org/10.21437/Interspeech.2019-1676", 5, "interspeech", 2019], ["Learn Spelling from Teachers: Transferring Knowledge from Language Models to Sequence-to-Sequence Speech Recognition", ["Ye Bai", "Jiangyan Yi", "Jianhua Tao", "Zhengkun Tian", "Zhengqi Wen"], "https://doi.org/10.21437/Interspeech.2019-1554", 5, "interspeech", 2019], ["Unsupervised Representation Learning with Future Observation Prediction for Speech Emotion Recognition", ["Zheng Lian", "Jianhua Tao", "Bin Liu", "Jian Huang"], "https://doi.org/10.21437/Interspeech.2019-1582", 5, "interspeech", 2019], ["Self-Attention Transducers for End-to-End Speech Recognition", ["Zhengkun Tian", "Jiangyan Yi", "Jianhua Tao", "Ye Bai", "Zhengqi Wen"], "https://doi.org/10.21437/Interspeech.2019-2203", 5, "interspeech", 2019], ["Automatic Depression Level Detection via \u2113p-Norm Pooling", ["Mingyue Niu", "Jianhua Tao", "Bin Liu", "Cunhang Fan"], "https://doi.org/10.21437/Interspeech.2019-1617", 5, "interspeech", 2019], ["Discriminative Learning for Monaural Speech Separation Using Deep Embedding Features", ["Cunhang Fan", "Bin Liu", "Jianhua Tao", "Jiangyan Yi", "Zhengqi Wen"], "https://doi.org/10.21437/Interspeech.2019-1940", 5, "interspeech", 2019]], "Vishwa Gupta": [0, ["CRIM's Speech Transcription and Call Sign Detection System for the ATC Airbus Challenge Task", ["Vishwa Gupta", "Lise Rebout", "Gilles Boulianne", "Pierre Andre Menard", "Jahangir Alam"], "https://doi.org/10.21437/Interspeech.2019-1131", 5, "interspeech", 2019]], "Mei-Yuh Hwang": [0.0003176184036419727, ["A Novel Method to Correct Steering Vectors in MVDR Beamformer for Noise Robust ASR", ["Suliang Bu", "Yunxin Zhao", "Mei-Yuh Hwang"], "https://doi.org/10.21437/Interspeech.2019-2944", 5, "interspeech", 2019]], "Zhixuan Li": [0, ["Towards Discriminative Representations and Unbiased Predictions: Class-Specific Angular Softmax for Speech Emotion Recognition", ["Zhixuan Li", "Liang He", "Jingyang Li", "Li Wang", "Wei-Qiang Zhang"], "https://doi.org/10.21437/Interspeech.2019-1683", 5, "interspeech", 2019]], "Kevin Khoo": [0, ["Building the Singapore English National Speech Corpus", ["Jia Xin Koh", "Aqilah Mislan", "Kevin Khoo", "Brian Ang", "Wilson Ang", "Charmaine Ng", "Ying-Ying Tan"], "https://doi.org/10.21437/Interspeech.2019-1525", 5, "interspeech", 2019]], "Lin Yang": [0.002806207921821624, ["The LeVoice Far-Field Speech Recognition System for VOiCES from a Distance Challenge 2019", ["Yulong Liang", "Lin Yang", "Xuyang Wang", "Yingjie Li", "Chen Jia", "Junjie Wang"], "https://doi.org/10.21437/Interspeech.2019-1944", 5, "interspeech", 2019]], "Sri Garimella": [0, ["Multi-Dialect Acoustic Modeling Using Phone Mapping and Online i-Vectors", ["Harish Arsikere", "Ashtosh Sapru", "Sri Garimella"], "https://doi.org/10.21437/Interspeech.2019-2881", 5, "interspeech", 2019], ["Improving ASR Confidence Scores for Alexa Using Acoustic and Hypothesis Embeddings", ["Prakhar Swarup", "Roland Maas", "Sri Garimella", "Sri Harish Mallidi", "Bjorn Hoffmeister"], "https://doi.org/10.21437/Interspeech.2019-1241", 5, "interspeech", 2019]], "Jilt Sebastian": [0, ["Fusion Techniques for Utterance-Level Emotion Recognition Combining Speech and Transcripts", ["Jilt Sebastian", "Piero Pierucci"], "https://doi.org/10.21437/Interspeech.2019-3201", 5, "interspeech", 2019]], "Peter Smit": [0, ["Subword RNNLM Approximations for Out-Of-Vocabulary Keyword Search", ["Mittul Singh", "Sami Virpioja", "Peter Smit", "Mikko Kurimo"], "https://doi.org/10.21437/Interspeech.2019-1329", 5, "interspeech", 2019]], "Melissa Wilson": [0, ["Better Morphology Prediction for Better Speech Systems", ["Dravyansh Sharma", "Melissa Wilson", "Antoine Bruguier"], "https://doi.org/10.21437/Interspeech.2019-3207", 5, "interspeech", 2019]], "Ondrej Glembek": [0, ["Analysis of BUT Submission in Far-Field Scenarios of VOiCES 2019 Challenge", ["Pavel Matejka", "Oldrich Plchot", "Hossein Zeinali", "Ladislav Mosner", "Anna Silnova", "Lukas Burget", "Ondrej Novotny", "Ondrej Glembek"], "https://doi.org/10.21437/Interspeech.2019-2471", 5, "interspeech", 2019], ["Analysis of BUT Submission in Far-Field Scenarios of VOiCES 2019 Challenge", ["Pavel Matejka", "Oldrich Plchot", "Hossein Zeinali", "Ladislav Mosner", "Anna Silnova", "Lukas Burget", "Ondrej Novotny", "Ondrej Glembek"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/abs16.html", 0, "interspeech", 2019], ["Factorization of Discriminatively Trained i-Vector Extractor for Speaker Recognition", ["Ondrej Novotny", "Oldrich Plchot", "Ondrej Glembek", "Lukas Burget"], "https://doi.org/10.21437/Interspeech.2019-1757", 5, "interspeech", 2019]], "Mingzhi Yu": [4.386826839286595e-11, ["Identifying Personality Traits Using Overlap Dynamics in Multiparty Dialogue", ["Mingzhi Yu", "Emer Gilmartin", "Diane J. Litman"], "https://doi.org/10.21437/Interspeech.2019-1886", 5, "interspeech", 2019]], "Mounya Elhilali": [0, ["A Study of a Cross-Language Perception Based on Cortical Analysis Using Biomimetic STRFs", ["Sangwook Park", "David K. Han", "Mounya Elhilali"], "https://doi.org/10.21437/Interspeech.2019-2507", 5, "interspeech", 2019]], "Dwight Crow": [0, ["WHAM!: Extending Speech Separation to Noisy Environments", ["Gordon Wichern", "Joe Antognini", "Michael Flynn", "Licheng Richard Zhu", "Emmett McQuinn", "Dwight Crow", "Ethan Manilow", "Jonathan Le Roux"], "https://doi.org/10.21437/Interspeech.2019-2821", 5, "interspeech", 2019]], "Mirella Lapata": [0, ["Learning Natural Language Interfaces with Neural Models", ["Mirella Lapata"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/abs23.html", 0, "interspeech", 2019]], "Gerhard Backfried": [0, ["The SAIL LABS Media Mining Indexer and the CAVA Framework", ["Erinc Dikici", "Gerhard Backfried", "Jurgen Riedler"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8029.html", 2, "interspeech", 2019]], "Xiaohan Zhang": [0, ["Individual Difference of Relative Tongue Size and its Acoustic Effects", ["Xiaohan Zhang", "Chongke Bi", "Kiyoshi Honda", "Wenhuan Lu", "Jianguo Wei"], "https://doi.org/10.21437/Interspeech.2019-2452", 5, "interspeech", 2019]], "Yu-Wen Tai": [0, ["Using Attention Networks and Adversarial Augmentation for Styrian Dialect Continuous Sleepiness and Baby Sound Recognition", ["Sung-Lin Yeh", "Gao-Yi Chao", "Bo-Hao Su", "Yu-Lin Huang", "Meng-Han Lin", "Yin-Chun Tsai", "Yu-Wen Tai", "Zheng-Chi Lu", "Chieh-Yu Chen", "Tsung-Ming Tai", "Chiu-Wang Tseng", "Cheng-Kuang Lee", "Chi-Chun Lee"], "https://doi.org/10.21437/Interspeech.2019-2110", 5, "interspeech", 2019]], "Sevinj Yolchuyeva": [0, ["Transformer Based Grapheme-to-Phoneme Conversion", ["Sevinj Yolchuyeva", "Geza Nemeth", "Balint Gyires-Toth"], "https://doi.org/10.21437/Interspeech.2019-1954", 5, "interspeech", 2019]], "Tamas Grosz": [0, ["Ultrasound-Based Silent Speech Interface Built on a Continuous Vocoder", ["Tamas Gabor Csapo", "Mohammed Salah Al-Radhi", "Geza Nemeth", "Gabor Gosztolya", "Tamas Grosz", "Laszlo Toth", "Alexandra Marko"], "https://doi.org/10.21437/Interspeech.2019-2046", 5, "interspeech", 2019]], "Arne Kuderle": [0, ["Apkinson: A Mobile Solution for Multimodal Assessment of Patients with Parkinson's Disease", ["Juan Camilo Vasquez-Correa", "Tomas Arias-Vergara", "Philipp Klumpp", "M. Strauss", "Arne Kuderle", "Nils Roth", "S. Bayerl", "Nicanor Garcia-Ospina", "Paula Andrea Perez-Toro", "L. Felipe Parra-Gallego", "Cristian David Rios-Urrego", "D. Escobar-Grisales", "Juan Rafael Orozco-Arroyave", "Bjorn Eskofier", "Elmar Noth"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8003.html", 2, "interspeech", 2019]], "Chia-Ping Chen": [0, ["Transfer-Representation Learning for Detecting Spoofing Attacks with Converted and Synthesized Speech in Automatic Speaker Verification System", ["Su-Yu Chang", "Kai-Cheng Wu", "Chia-Ping Chen"], "https://doi.org/10.21437/Interspeech.2019-2014", 5, "interspeech", 2019]], "Pan Zhou": [0, ["An Online Attention-Based Model for Speech Recognition", ["Ruchao Fan", "Pan Zhou", "Wei Chen", "Jia Jia", "Gang Liu"], "https://doi.org/10.21437/Interspeech.2019-2218", 5, "interspeech", 2019]], "Wenhao Ding": [0, ["Multi-Scale Time-Frequency Attention for Acoustic Event Detection", ["Jingyang Zhang", "Wenhao Ding", "Jintao Kang", "Liang He"], "https://doi.org/10.21437/Interspeech.2019-1587", 5, "interspeech", 2019]], "Joon-Young Yang": [0.9999984800815582, ["Joint Optimization of Neural Acoustic Beamforming and Dereverberation with x-Vectors for Robust Speaker Verification", ["Joon-Young Yang", "Joon-Hyuk Chang"], "https://doi.org/10.21437/Interspeech.2019-1356", 5, "interspeech", 2019]], "Georgia Athanasopoulou": [0, ["Detecting Spoofing Attacks Using VGG and SincNet: BUT-Omilia Submission to ASVspoof 2019 Challenge", ["Hossein Zeinali", "Themos Stafylakis", "Georgia Athanasopoulou", "Johan Rohdin", "Ioannis Gkinis", "Lukas Burget", "Jan Cernocky"], "https://doi.org/10.21437/Interspeech.2019-2892", 5, "interspeech", 2019]], "Ben Laurie": [0, ["Large-Scale Visual Speech Recognition", ["Brendan Shillingford", "Yannis M. Assael", "Matthew W. Hoffman", "Thomas Paine", "Cian Hughes", "Utsav Prabhu", "Hank Liao", "Hasim Sak", "Kanishka Rao", "Lorrayne Bennett", "Marie Mulville", "Misha Denil", "Ben Coppin", "Ben Laurie", "Andrew W. Senior", "Nando de Freitas"], "https://doi.org/10.21437/Interspeech.2019-1669", 5, "interspeech", 2019]], "Milos Cernak": [0, ["End-to-End Accented Speech Recognition", ["Thibault Viglino", "Petr Motlicek", "Milos Cernak"], "https://doi.org/10.21437/Interspeech.2019-2122", 5, "interspeech", 2019], ["Phone-Attribute Posteriors to Evaluate the Speech of Cochlear Implant Users", ["Tomas Arias-Vergara", "Juan Rafael Orozco-Arroyave", "Milos Cernak", "Sandra Gollwitzer", "Maria Schuster", "Elmar Noth"], "https://doi.org/10.21437/Interspeech.2019-2144", 5, "interspeech", 2019], ["Open-Vocabulary Keyword Spotting with Audio and Text Embeddings", ["Niccolo Sacchi", "Alexandre Nanchen", "Martin Jaggi", "Milos Cernak"], "https://doi.org/10.21437/Interspeech.2019-1846", 5, "interspeech", 2019], ["Evaluating Audiovisual Source Separation in the Context of Video Conferencing", ["Berkay Inan", "Milos Cernak", "Helmut Grabner", "Helena Peic Tukuljac", "Rodrigo C. G. Pena", "Benjamin Ricaud"], "https://doi.org/10.21437/Interspeech.2019-2671", 5, "interspeech", 2019]], "Daniel Elsner": [0, ["Deep Neural Baselines for Computational Paralinguistics", ["Daniel Elsner", "Stefan Langer", "Fabian Ritz", "Robert Muller", "Steffen Illium"], "https://doi.org/10.21437/Interspeech.2019-2478", 5, "interspeech", 2019]], "T. Metin Sezgin": [0, ["Speech Driven Backchannel Generation Using Deep Q-Network for Enhancing Engagement in Human-Robot Interaction", ["Nusrah Hussain", "Engin Erzin", "T. Metin Sezgin", "Yucel Yemez"], "https://doi.org/10.21437/Interspeech.2019-2521", 5, "interspeech", 2019]], "Isabel Trancoso": [0, ["Recognition of Latin American Spanish Using Multi-Task Learning", ["Carlos Mendes", "Alberto Abad", "Joao Paulo Neto", "Isabel Trancoso"], "https://doi.org/10.21437/Interspeech.2019-2772", 5, "interspeech", 2019], ["Unbabel Talk - Human Verified Translations for Voice Instant Messaging", ["Luis Bernardo", "Mathieu Giquel", "Sebastiao Quintas", "Paulo Dimas", "Helena Moniz", "Isabel Trancoso"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8034.html", 2, "interspeech", 2019], ["The GDPR & Speech Data: Reflections of Legal and Technology Communities, First Steps Towards a Common Understanding", ["Andreas Nautsch", "Catherine Jasserand", "Els Kindt", "Massimiliano Todisco", "Isabel Trancoso", "Nicholas W. D. Evans"], "https://doi.org/10.21437/Interspeech.2019-2647", 5, "interspeech", 2019]], "Pengpeng Zhi": [0, ["Knowledge-Based Linguistic Encoding for End-to-End Mandarin Text-to-Speech Synthesis", ["Jingbei Li", "Zhiyong Wu", "Runnan Li", "Pengpeng Zhi", "Song Yang", "Helen Meng"], "https://doi.org/10.21437/Interspeech.2019-1118", 5, "interspeech", 2019]], "Gregory Sell": [0, ["Speaker Diarization Using Leave-One-Out Gaussian PLDA Clustering of DNN Embeddings", ["Alan McCree", "Gregory Sell", "Daniel Garcia-Romero"], "https://doi.org/10.21437/Interspeech.2019-2912", 5, "interspeech", 2019], ["State-of-the-Art Speaker Recognition for Telephone and Video Speech: The JHU-MIT Submission for NIST SRE18", ["Jesus Villalba", "Nanxin Chen", "David Snyder", "Daniel Garcia-Romero", "Alan McCree", "Gregory Sell", "Jonas Borgstrom", "Fred Richardson", "Suwon Shon", "Francois Grondin", "Reda Dehak", "Leibny Paola Garcia-Perera", "Daniel Povey", "Pedro A. Torres-Carrasquillo", "Sanjeev Khudanpur", "Najim Dehak"], "https://doi.org/10.21437/Interspeech.2019-2713", 5, "interspeech", 2019], ["x-Vector DNN Refinement with Full-Length Recordings for Speaker Recognition", ["Daniel Garcia-Romero", "David Snyder", "Gregory Sell", "Alan McCree", "Daniel Povey", "Sanjeev Khudanpur"], "https://doi.org/10.21437/Interspeech.2019-2205", 4, "interspeech", 2019], ["Speaker Recognition Benchmark Using the CHiME-5 Corpus", ["Daniel Garcia-Romero", "David Snyder", "Shinji Watanabe", "Gregory Sell", "Alan McCree", "Daniel Povey", "Sanjeev Khudanpur"], "https://doi.org/10.21437/Interspeech.2019-2174", 5, "interspeech", 2019], ["Performance Monitoring for End-to-End Speech Recognition", ["Ruizhi Li", "Gregory Sell", "Hynek Hermansky"], "https://doi.org/10.21437/Interspeech.2019-3137", 5, "interspeech", 2019], ["The JHU Speaker Recognition System for the VOiCES 2019 Challenge", ["David Snyder", "Jesus Villalba", "Nanxin Chen", "Daniel Povey", "Gregory Sell", "Najim Dehak", "Sanjeev Khudanpur"], "https://doi.org/10.21437/Interspeech.2019-2979", 5, "interspeech", 2019]], "Beomsu Kim": [0.9992358833551407, ["Temporal Convolution for Real-Time Keyword Spotting on Mobile Devices", ["Seungwoo Choi", "Seokjun Seo", "Beomjun Shin", "Hyeongmin Byun", "Martin Kersner", "Beomsu Kim", "Dongyoung Kim", "Sungjoo Ha"], "https://doi.org/10.21437/Interspeech.2019-1363", 5, "interspeech", 2019]], "Jianguo Wei": [0, ["Individual Difference of Relative Tongue Size and its Acoustic Effects", ["Xiaohan Zhang", "Chongke Bi", "Kiyoshi Honda", "Wenhuan Lu", "Jianguo Wei"], "https://doi.org/10.21437/Interspeech.2019-2452", 5, "interspeech", 2019], ["Acoustic and Articulatory Study of Ewe Vowels: A Comparative Study of Male and Female", ["Kowovi Comivi Alowonou", "Jianguo Wei", "Wenhuan Lu", "Zhicheng Liu", "Kiyoshi Honda", "Jianwu Dang"], "https://doi.org/10.21437/Interspeech.2019-2196", 5, "interspeech", 2019]], "Shakti P. Rath": [0, ["Far-Field Speech Enhancement Using Heteroscedastic Autoencoder for Improved Speech Recognition", ["Shashi Kumar", "Shakti P. Rath"], "https://doi.org/10.21437/Interspeech.2019-2032", 5, "interspeech", 2019], ["A Multi-Accent Acoustic Model Using Mixture of Experts for Speech Recognition", ["Abhinav Jain", "Vishwanath P. Singh", "Shakti P. Rath"], "https://doi.org/10.21437/Interspeech.2019-1667", 5, "interspeech", 2019]], "Mirko Hannemann": [0, ["Connecting and Comparing Language Model Interpolation Techniques", ["Ernest Pusateri", "Christophe Van Gysel", "Rami Botros", "Sameer Badaskar", "Mirko Hannemann", "Youssef Oualil", "Ilya Oparin"], "https://doi.org/10.21437/Interspeech.2019-1822", 5, "interspeech", 2019]], "Hung-yi Lee": [5.747688737756107e-05, ["Code-Switching Sentence Generation by Generative Adversarial Networks and its Application to Data Augmentation", ["Ching-Ting Chang", "Shun-Po Chuang", "Hung-yi Lee"], "https://doi.org/10.21437/Interspeech.2019-3214", 5, "interspeech", 2019], ["One-Shot Voice Conversion by Separating Speaker and Content Representations with Instance Normalization", ["Ju-Chieh Chou", "Hung-yi Lee"], "https://doi.org/10.21437/Interspeech.2019-2663", 5, "interspeech", 2019], ["Generative Adversarial Networks for Unpaired Voice Transformation on Impaired Speech", ["Li-Wei Chen", "Hung-yi Lee", "Yu Tsao"], "https://doi.org/10.21437/Interspeech.2019-1265", 5, "interspeech", 2019], ["Unsupervised End-to-End Learning of Discrete Linguistic Units for Voice Conversion", ["Andy T. Liu", "Po-chun Hsu", "Hung-yi Lee"], "https://doi.org/10.21437/Interspeech.2019-2048", 5, "interspeech", 2019], ["Improved Speech Separation with Time-and-Frequency Cross-Domain Joint Embedding and Clustering", ["Gene-Ping Yang", "Chao-I Tuan", "Hung-yi Lee", "Lin-Shan Lee"], "https://doi.org/10.21437/Interspeech.2019-2181", 5, "interspeech", 2019], ["Completely Unsupervised Phoneme Recognition by a Generative Adversarial Network Harmonized with Iteratively Refined Hidden Markov Models", ["Kuan-Yu Chen", "Che-Ping Tsai", "Da-Rong Liu", "Hung-yi Lee", "Lin-Shan Lee"], "https://doi.org/10.21437/Interspeech.2019-2068", 5, "interspeech", 2019], ["End-to-End Text-to-Speech for Low-Resource Languages by Cross-Lingual Transfer Learning", ["Yuan-Jui Chen", "Tao Tu", "Cheng-chieh Yeh", "Hung-yi Lee"], "https://doi.org/10.21437/Interspeech.2019-2730", 5, "interspeech", 2019], ["Noise Adaptive Speech Enhancement Using Domain Adversarial Training", ["Chien-Feng Liao", "Yu Tsao", "Hung-yi Lee", "Hsin-Min Wang"], "https://doi.org/10.21437/Interspeech.2019-1519", 5, "interspeech", 2019], ["Personalized Dialogue Response Generation Learned from Monologues", ["Feng-Guang Su", "Aliyah R. Hsu", "Yi-Lin Tuan", "Hung-yi Lee"], "https://doi.org/10.21437/Interspeech.2019-1696", 5, "interspeech", 2019]], "Haruna Miyamoto": [0, ["Investigation on Blind Bandwidth Extension with a Non-Linear Function and its Evaluation of x-Vector-Based Speaker Verification", ["Ryota Kaminishi", "Haruna Miyamoto", "Sayaka Shiota", "Hitoshi Kiya"], "https://doi.org/10.21437/Interspeech.2019-1510", 5, "interspeech", 2019]], "Jindrich Matousek": [0, ["Web-Based Speech Synthesis Editor", ["Martin Gruber", "Jakub Vit", "Jindrich Matousek"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8013.html", 2, "interspeech", 2019], ["Framework for Conducting Tasks Requiring Human Assessment", ["Martin Gruber", "Adam Chylek", "Jindrich Matousek"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8009.html", 2, "interspeech", 2019]], "Yuewen Cao": [0, ["Jointly Trained Conversion Model and WaveNet Vocoder for Non-Parallel Voice Conversion Using Mel-Spectrograms and Phonetic Posteriorgrams", ["Songxiang Liu", "Yuewen Cao", "Xixin Wu", "Lifa Sun", "Xunying Liu", "Helen Meng"], "https://doi.org/10.21437/Interspeech.2019-1316", 5, "interspeech", 2019], ["Comparative Study of Parametric and Representation Uncertainty Modeling for Recurrent Neural Network Language Models", ["Jianwei Yu", "Max W. Y. Lam", "Shoukang Hu", "Xixin Wu", "Xu Li", "Yuewen Cao", "Xunying Liu", "Helen Meng"], "https://doi.org/10.21437/Interspeech.2019-1927", 5, "interspeech", 2019]], "Rob Clark": [0, ["LibriTTS: A Corpus Derived from LibriSpeech for Text-to-Speech", ["Heiga Zen", "Viet Dang", "Rob Clark", "Yu Zhang", "Ron J. Weiss", "Ye Jia", "Zhifeng Chen", "Yonghui Wu"], "https://doi.org/10.21437/Interspeech.2019-2441", 5, "interspeech", 2019]], "Jiska Koemans": [0, ["The Neural Correlates Underlying Lexically-Guided Perceptual Learning", ["Odette Scharenborg", "Jiska Koemans", "Cybelle Smith", "Mark A. Hasegawa-Johnson", "Kara D. Federmeier"], "https://doi.org/10.21437/Interspeech.2019-2328", 5, "interspeech", 2019]], "Samuel Cohen": [0, ["Multi-Graph Decoding for Code-Switching ASR", ["Emre Yilmaz", "Samuel Cohen", "Xianghu Yue", "David A. van Leeuwen", "Haizhou Li"], "https://doi.org/10.21437/Interspeech.2019-1125", 5, "interspeech", 2019]], "Mads Graesboll Christensen": [0, ["Harmonic Beamformers for Non-Intrusive Speech Intelligibility Prediction", ["Charlotte Sorensen", "Jesper Bunsow Boldt", "Mads Graesboll Christensen"], "https://doi.org/10.21437/Interspeech.2019-2929", 5, "interspeech", 2019]], "Vassilis Tsiaras": [0, ["Speech Enhancement for Noise-Robust Speech Synthesis Using Wasserstein GAN", ["Nagaraj Adiga", "Yannis Pantazis", "Vassilis Tsiaras", "Yannis Stylianou"], "https://doi.org/10.21437/Interspeech.2019-2648", 5, "interspeech", 2019], ["A Non-Causal FFTNet Architecture for Speech Enhancement", ["P. V. Muhammed Shifas", "Nagaraj Adiga", "Vassilis Tsiaras", "Yannis Stylianou"], "https://doi.org/10.21437/Interspeech.2019-2622", 5, "interspeech", 2019]], "Sai Krishna Rallabandi": [0, ["Ordinal Triplet Loss: Investigating Sleepiness Detection from Speech", ["Peter Wu", "Sai Krishna Rallabandi", "Alan W. Black", "Eric Nyberg"], "https://doi.org/10.21437/Interspeech.2019-2278", 5, "interspeech", 2019], ["Variational Attention Using Articulatory Priors for Generating Code Mixed Speech Using Monolingual Corpora", ["Sai Krishna Rallabandi", "Alan W. Black"], "https://doi.org/10.21437/Interspeech.2019-1103", 5, "interspeech", 2019]], "Minhwa Chung": [0.9872890114784241, ["Self-Imitating Feedback Generation Using GAN for Computer-Assisted Pronunciation Training", ["Seung Hee Yang", "Minhwa Chung"], "https://doi.org/10.21437/Interspeech.2019-1478", 5, "interspeech", 2019]], "Gian Luca Foresti": [0, ["End-to-End Speaker Identification in Noisy and Reverberant Environments Using Raw Waveform Convolutional Neural Networks", ["Daniele Salvati", "Carlo Drioli", "Gian Luca Foresti"], "https://doi.org/10.21437/Interspeech.2019-2403", 5, "interspeech", 2019]], "Viacheslav Klimkov": [0, ["Fine-Grained Robust Prosody Transfer for Single-Speaker Neural Text-To-Speech", ["Viacheslav Klimkov", "Srikanth Ronanki", "Jonas Rohnke", "Thomas Drugman"], "https://doi.org/10.21437/Interspeech.2019-2571", 5, "interspeech", 2019]], "Jonathan Lebensold": [0, ["Neural Transfer Learning for Cry-Based Diagnosis of Perinatal Asphyxia", ["Charles C. Onu", "Jonathan Lebensold", "William L. Hamilton", "Doina Precup"], "https://doi.org/10.21437/Interspeech.2019-2340", 5, "interspeech", 2019]], "Izhak Shafran": [0, ["Joint Speech Recognition and Speaker Diarization via Sequence Transduction", ["Laurent El Shafey", "Hagen Soltau", "Izhak Shafran"], "https://doi.org/10.21437/Interspeech.2019-1943", 5, "interspeech", 2019]], "Hyeongmin Byun": [0.990629255771637, ["Temporal Convolution for Real-Time Keyword Spotting on Mobile Devices", ["Seungwoo Choi", "Seokjun Seo", "Beomjun Shin", "Hyeongmin Byun", "Martin Kersner", "Beomsu Kim", "Dongyoung Kim", "Sungjoo Ha"], "https://doi.org/10.21437/Interspeech.2019-1363", 5, "interspeech", 2019]], "Kai Yu": [0.007579648867249489, ["The SJTU Robust Anti-Spoofing System for the ASVspoof 2019 Challenge", ["Yexin Yang", "Hongji Wang", "Heinrich Dinkel", "Zhengyang Chen", "Shuai Wang", "Yanmin Qian", "Kai Yu"], "https://doi.org/10.21437/Interspeech.2019-2170", 5, "interspeech", 2019], ["On the Usage of Phonetic Information for Text-Independent Speaker Embedding Extraction", ["Shuai Wang", "Johan Rohdin", "Lukas Burget", "Oldrich Plchot", "Yanmin Qian", "Kai Yu", "Jan Cernocky"], "https://doi.org/10.21437/Interspeech.2019-3036", 5, "interspeech", 2019], ["Data Augmentation Using Variational Autoencoder for Embedding Based Speaker Verification", ["Zhanghao Wu", "Shuai Wang", "Yanmin Qian", "Kai Yu"], "https://doi.org/10.21437/Interspeech.2019-2248", 5, "interspeech", 2019], ["Joint Decoding of CTC Based Systems for Speech Recognition", ["Jiaqi Guo", "Yongbin You", "Yanmin Qian", "Kai Yu"], "https://doi.org/10.21437/Interspeech.2019-2026", 5, "interspeech", 2019], ["Cross-Domain Replay Spoofing Attack Detection Using Domain Adversarial Training", ["Hongji Wang", "Heinrich Dinkel", "Shuai Wang", "Yanmin Qian", "Kai Yu"], "https://doi.org/10.21437/Interspeech.2019-2120", 5, "interspeech", 2019]], "Andrew W. Senior": [0, ["Large-Scale Visual Speech Recognition", ["Brendan Shillingford", "Yannis M. Assael", "Matthew W. Hoffman", "Thomas Paine", "Cian Hughes", "Utsav Prabhu", "Hank Liao", "Hasim Sak", "Kanishka Rao", "Lorrayne Bennett", "Marie Mulville", "Misha Denil", "Ben Coppin", "Ben Laurie", "Andrew W. Senior", "Nando de Freitas"], "https://doi.org/10.21437/Interspeech.2019-1669", 5, "interspeech", 2019]], "Laurent Besacier": [0, ["The Zero Resource Speech Challenge 2019: TTS Without T", ["Ewan Dunbar", "Robin Algayres", "Julien Karadayi", "Mathieu Bernard", "Juan Benjumea", "Xuan-Nga Cao", "Lucie Miskic", "Charlotte Dugrain", "Lucas Ondel", "Alan W. Black", "Laurent Besacier", "Sakriani Sakti", "Emmanuel Dupoux"], "https://doi.org/10.21437/Interspeech.2019-2904", 5, "interspeech", 2019], ["Empirical Evaluation of Sequence-to-Sequence Models for Word Discovery in Low-Resource Settings", ["Marcely Zanon Boito", "Aline Villavicencio", "Laurent Besacier"], "https://doi.org/10.21437/Interspeech.2019-2029", 5, "interspeech", 2019]], "Febe de Wet": [0, ["Semi-Supervised Acoustic Model Training for Five-Lingual Code-Switched ASR", ["Astik Biswas", "Emre Yilmaz", "Febe de Wet", "Ewald van der Westhuizen", "Thomas Niesler"], "https://doi.org/10.21437/Interspeech.2019-1325", 5, "interspeech", 2019]], "Giuseppe Di Fabbrizio": [0, ["Active Annotation: Bootstrapping Annotation Lexicon and Guidelines for Supervised NLU Learning", ["Federico Marinelli", "Alessandra Cervone", "Giuliano Tortoreto", "Evgeny A. Stepanov", "Giuseppe Di Fabbrizio", "Giuseppe Riccardi"], "https://doi.org/10.21437/Interspeech.2019-2537", 5, "interspeech", 2019]], "Reynold Bailey": [0, ["Synthesized Spoken Names: Biases Impacting Perception", ["Lucas Kessler", "Cecilia Ovesdotter Alm", "Reynold Bailey"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8031.html", 2, "interspeech", 2019]], "Anna Braudo": [0, ["All Together Now: The Living Audio Dataset", ["David A. Braude", "Matthew P. Aylett", "Caoimhin Laoide-Kemp", "Simone Ashby", "Kristen M. Scott", "Brian O Raghallaigh", "Anna Braudo", "Alex Brouwer", "Adriana Stan"], "https://doi.org/10.21437/Interspeech.2019-2448", 5, "interspeech", 2019]], "Dabre Raj": [0, ["Improving Transformer-Based Speech Recognition Systems with Compressed Structure and Speech Attributes Augmentation", ["Sheng Li", "Dabre Raj", "Xugang Lu", "Peng Shen", "Tatsuya Kawahara", "Hisashi Kawai"], "https://doi.org/10.21437/Interspeech.2019-2112", 5, "interspeech", 2019]], "Sarah R. Li": [0, ["Using Ultrasound Imaging to Create Augmented Visual Biofeedback for Articulatory Practice", ["Colin T. Annand", "Maurice Lamb", "Sarah Dugan", "Sarah R. Li", "Hannah M. Woeste", "T. Douglas Mast", "Michael A. Riley", "Jack A. Masterson", "Neeraja Mahalingam", "Kathryn J. Eary", "Caroline Spencer", "Suzanne Boyce", "Stephanie Jackson", "Anoosha Baxi", "Renee Seward"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8036.html", 2, "interspeech", 2019]], "Bingyan Hu": [0, ["Predicting Humor by Learning from Time-Aligned Comments", ["Zixiaofan Yang", "Bingyan Hu", "Julia Hirschberg"], "https://doi.org/10.21437/Interspeech.2019-3113", 5, "interspeech", 2019]], "Sung-Hyun Yoon": [0.9931042641401291, ["End-to-End Losses Based on Speaker Basis Vectors and All-Speaker Hard Negative Mining for Speaker Verification", ["Hee-Soo Heo", "Jee-weon Jung", "Il-Ho Yang", "Sung-Hyun Yoon", "Hye-jin Shim", "Ha-Jin Yu"], "https://doi.org/10.21437/Interspeech.2019-1986", 5, "interspeech", 2019]], "Panayiotis G. Georgiou": [0, ["Speaker Diarization with Lexical Information", ["Tae Jin Park", "Kyu J. Han", "Jing Huang", "Xiaodong He", "Bowen Zhou", "Panayiotis G. Georgiou", "Shrikanth Narayanan"], "https://doi.org/10.21437/Interspeech.2019-1947", 5, "interspeech", 2019], ["Spoken Language Intent Detection Using Confusion2Vec", ["Prashanth Gurunath Shivakumar", "Mu Yang", "Panayiotis G. Georgiou"], "https://doi.org/10.21437/Interspeech.2019-2226", 5, "interspeech", 2019], ["The Second DIHARD Challenge: System Description for USC-SAIL Team", ["Tae Jin Park", "Manoj Kumar", "Nikolaos Flemotomos", "Monisankha Pal", "Raghuveer Peri", "Rimita Lahiri", "Panayiotis G. Georgiou", "Shrikanth Narayanan"], "https://doi.org/10.21437/Interspeech.2019-1903", 5, "interspeech", 2019], ["Modeling Interpersonal Linguistic Coordination in Conversations Using Word Mover's Distance", ["Md. Nasir", "Sandeep Nallan Chakravarthula", "Brian R. W. Baucom", "David C. Atkins", "Panayiotis G. Georgiou", "Shrikanth Narayanan"], "https://doi.org/10.21437/Interspeech.2019-1900", 5, "interspeech", 2019], ["Multiview Shared Subspace Learning Across Speakers and Speech Commands", ["Krishna Somandepalli", "Naveen Kumar", "Arindam Jati", "Panayiotis G. Georgiou", "Shrikanth Narayanan"], "https://doi.org/10.21437/Interspeech.2019-3130", 5, "interspeech", 2019], ["Multi-Task Discriminative Training of Hybrid DNN-TVM Model for Speaker Verification with Noisy and Far-Field Speech", ["Arindam Jati", "Raghuveer Peri", "Monisankha Pal", "Tae Jin Park", "Naveen Kumar", "Ruchir Travadi", "Panayiotis G. Georgiou", "Shrikanth Narayanan"], "https://doi.org/10.21437/Interspeech.2019-3010", 5, "interspeech", 2019], ["Predicting Behavior in Cancer-Afflicted Patient and Spouse Interactions Using Speech and Language", ["Sandeep Nallan Chakravarthula", "Haoqi Li", "Shao-Yen Tseng", "Maija Reblin", "Panayiotis G. Georgiou"], "https://doi.org/10.21437/Interspeech.2019-1888", 5, "interspeech", 2019]], "Kenji Nagamatsu": [0, ["Auxiliary Interference Speaker Loss for Target-Speaker Speech Recognition", ["Naoyuki Kanda", "Shota Horiguchi", "Ryoichi Takashima", "Yusuke Fujita", "Kenji Nagamatsu", "Shinji Watanabe"], "https://doi.org/10.21437/Interspeech.2019-1126", 5, "interspeech", 2019], ["Guided Source Separation Meets a Strong ASR Backend: Hitachi/Paderborn University Joint Investigation for Dinner Party ASR", ["Naoyuki Kanda", "Christoph Boddeker", "Jens Heitkaemper", "Yusuke Fujita", "Shota Horiguchi", "Kenji Nagamatsu", "Reinhold Haeb-Umbach"], "https://doi.org/10.21437/Interspeech.2019-1167", 5, "interspeech", 2019], ["Multimodal Response Obligation Detection with Unsupervised Online Domain Adaptation", ["Shota Horiguchi", "Naoyuki Kanda", "Kenji Nagamatsu"], "https://doi.org/10.21437/Interspeech.2019-1313", 5, "interspeech", 2019], ["End-to-End Neural Speaker Diarization with Permutation-Free Objectives", ["Yusuke Fujita", "Naoyuki Kanda", "Shota Horiguchi", "Kenji Nagamatsu", "Shinji Watanabe"], "https://doi.org/10.21437/Interspeech.2019-2899", 5, "interspeech", 2019]], "Zbynek Zajic": [0, ["UWB-NTIS Speaker Diarization System for the DIHARD II 2019 Challenge", ["Zbynek Zajic", "Marie Kunesova", "Marek Hruz", "Jan Vanek"], "https://doi.org/10.21437/Interspeech.2019-1385", 5, "interspeech", 2019]], "Jinghao Yan": [0, ["Multimedia Simultaneous Translation System for Minority Language Communication with Mandarin", ["Shen Huang", "Bojie Hu", "Shan Huang", "Pengfei Hu", "Jian Kang", "Zhiqiang Lv", "Jinghao Yan", "Qi Ju", "Shiyin Kang", "Deyi Tuo", "Guangzhi Li", "Nurmemet Yolwas"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8020.html", 2, "interspeech", 2019]], "Alexander Zatvornitskiy": [0, ["R-Vectors: New Technique for Adaptation to Room Acoustics", ["Yuri Y. Khokhlov", "Alexander Zatvornitskiy", "Ivan Medennikov", "Ivan Sorokin", "Tatiana Prisyach", "Aleksei Romanenko", "Anton Mitrofanov", "Vladimir Bataev", "Andrei Andrusenko", "Mariya Korenevskaya", "Oleg Petrov"], "https://doi.org/10.21437/Interspeech.2019-2645", 5, "interspeech", 2019], ["The STC ASR System for the VOiCES from a Distance Challenge 2019", ["Ivan Medennikov", "Yuri Y. Khokhlov", "Aleksei Romanenko", "Ivan Sorokin", "Anton Mitrofanov", "Vladimir Bataev", "Andrei Andrusenko", "Tatiana Prisyach", "Mariya Korenevskaya", "Oleg Petrov", "Alexander Zatvornitskiy"], "https://doi.org/10.21437/Interspeech.2019-1574", 5, "interspeech", 2019], ["The STC ASR System for the VOiCES from a Distance Challenge 2019", ["Ivan Medennikov", "Yuri Y. Khokhlov", "Aleksei Romanenko", "Ivan Sorokin", "Anton Mitrofanov", "Vladimir Bataev", "Andrei Andrusenko", "Tatiana Prisyach", "Mariya Korenevskaya", "Oleg Petrov", "Alexander Zatvornitskiy"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/abs17.html", 0, "interspeech", 2019]], "Truc Nguyen": [0, ["Acoustic Scene Classification with Mismatched Devices Using CliqueNets and Mixup Data Augmentation", ["Truc Nguyen", "Franz Pernkopf"], "https://doi.org/10.21437/Interspeech.2019-3002", 5, "interspeech", 2019]], "Imran Sheikh": [0, ["End-to-End Spoken Language Understanding: Bootstrapping in Low Resource Scenarios", ["Swapnil Bhosale", "Imran Sheikh", "Sri Harsha Dumpala", "Sunil Kumar Kopparapu"], "https://doi.org/10.21437/Interspeech.2019-2366", 5, "interspeech", 2019]], "Johan Rohdin": [0, ["Bayesian HMM Based x-Vector Clustering for Speaker Diarization", ["Mireia Diez", "Lukas Burget", "Shuai Wang", "Johan Rohdin", "Jan Cernocky"], "https://doi.org/10.21437/Interspeech.2019-2813", 5, "interspeech", 2019], ["Detecting Spoofing Attacks Using VGG and SincNet: BUT-Omilia Submission to ASVspoof 2019 Challenge", ["Hossein Zeinali", "Themos Stafylakis", "Georgia Athanasopoulou", "Johan Rohdin", "Ioannis Gkinis", "Lukas Burget", "Jan Cernocky"], "https://doi.org/10.21437/Interspeech.2019-2892", 5, "interspeech", 2019], ["On the Usage of Phonetic Information for Text-Independent Speaker Embedding Extraction", ["Shuai Wang", "Johan Rohdin", "Lukas Burget", "Oldrich Plchot", "Yanmin Qian", "Kai Yu", "Jan Cernocky"], "https://doi.org/10.21437/Interspeech.2019-3036", 5, "interspeech", 2019], ["Self-Supervised Speaker Embeddings", ["Themos Stafylakis", "Johan Rohdin", "Oldrich Plchot", "Petr Mizera", "Lukas Burget"], "https://doi.org/10.21437/Interspeech.2019-2842", 5, "interspeech", 2019]], "Minkyu Lim": [0.9969374090433121, ["Shortcut Connections Based Deep Speaker Embeddings for End-to-End Speaker Verification System", ["Soonshin Seo", "Daniel Jun Rim", "Minkyu Lim", "Donghyun Lee", "Hosung Park", "Junseok Oh", "Changmin Kim", "Ji-Hwan Kim"], "https://doi.org/10.21437/Interspeech.2019-2195", 5, "interspeech", 2019]], "Jack A. Masterson": [0, ["Using Ultrasound Imaging to Create Augmented Visual Biofeedback for Articulatory Practice", ["Colin T. Annand", "Maurice Lamb", "Sarah Dugan", "Sarah R. Li", "Hannah M. Woeste", "T. Douglas Mast", "Michael A. Riley", "Jack A. Masterson", "Neeraja Mahalingam", "Kathryn J. Eary", "Caroline Spencer", "Suzanne Boyce", "Stephanie Jackson", "Anoosha Baxi", "Renee Seward"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8036.html", 2, "interspeech", 2019]], "Aggelina Chatziagapi": [0, ["Data Augmentation Using GANs for Speech Emotion Recognition", ["Aggelina Chatziagapi", "Georgios Paraskevopoulos", "Dimitris Sgouropoulos", "Georgios Pantazopoulos", "Malvina Nikandrou", "Theodoros Giannakopoulos", "Athanasios Katsamanis", "Alexandros Potamianos", "Shrikanth Narayanan"], "https://doi.org/10.21437/Interspeech.2019-2561", 5, "interspeech", 2019]], "Guanlong Zhao": [0, ["Foreign Accent Conversion by Synthesizing Speech from Phonetic Posteriorgrams", ["Guanlong Zhao", "Shaojin Ding", "Ricardo Gutierrez-Osuna"], "https://doi.org/10.21437/Interspeech.2019-1778", 5, "interspeech", 2019]], "Pin-Tuan Huang": [0, ["Exploring the Encoder Layers of Discriminative Autoencoders for LVCSR", ["Pin-Tuan Huang", "Hung-Shin Lee", "Syu-Siang Wang", "Kuan-Yu Chen", "Yu Tsao", "Hsin-Min Wang"], "https://doi.org/10.21437/Interspeech.2019-1717", 5, "interspeech", 2019]], "Pramit Saha": [0, ["SPEAK YOUR MIND! Towards Imagined Speech Recognition with Hierarchical Deep Learning", ["Pramit Saha", "Muhammad Abdul-Mageed", "Sidney S. Fels"], "https://doi.org/10.21437/Interspeech.2019-3041", 5, "interspeech", 2019]], "Jiani Chen": [0, ["The CUHK Dysarthric Speech Recognition Systems for English and Cantonese", ["Shoukang Hu", "Shansong Liu", "Heng Fai Chang", "Mengzhe Geng", "Jiani Chen", "Lau Wing Chung", "To Ka Hei", "Jianwei Yu", "Ka Ho Wong", "Xunying Liu", "Helen Meng"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8047.html", 2, "interspeech", 2019]], "Nurmemet Yolwas": [0, ["Multimedia Simultaneous Translation System for Minority Language Communication with Mandarin", ["Shen Huang", "Bojie Hu", "Shan Huang", "Pengfei Hu", "Jian Kang", "Zhiqiang Lv", "Jinghao Yan", "Qi Ju", "Shiyin Kang", "Deyi Tuo", "Guangzhi Li", "Nurmemet Yolwas"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8020.html", 2, "interspeech", 2019]], "Mehul Kumar": [0, ["Multi-Task Multi-Resolution Char-to-BPE Cross-Attention Decoder for End-to-End Speech Recognition", ["Dhananjaya Gowda", "Abhinav Garg", "Kwangyoun Kim", "Mehul Kumar", "Chanwoo Kim"], "https://doi.org/10.21437/Interspeech.2019-3216", 5, "interspeech", 2019]], "Keiichi Tokuda": [0, ["Statistical Approach to Speech Synthesis: Past, Present and Future", ["Keiichi Tokuda"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/abs1.html", 0, "interspeech", 2019]], "Reima Karhila": [0, ["Transparent Pronunciation Scoring Using Articulatorily Weighted Phoneme Edit Distance", ["Reima Karhila", "Anna-Riikka Smolander", "Sari Ylinen", "Mikko Kurimo"], "https://doi.org/10.21437/Interspeech.2019-1785", 5, "interspeech", 2019]], "Sishir Kalita": [0, ["Nasal Air Emission in Sibilant Fricatives of Cleft Lip and Palate Speech", ["Sishir Kalita", "Protima Nomo Sudro", "S. R. Mahadeva Prasanna", "Samarendra Dandapat"], "https://doi.org/10.21437/Interspeech.2019-2345", 5, "interspeech", 2019]], "Zhiyuan Peng": [0, ["Combining Adversarial Training and Disentangled Speech Representation for Robust Zero-Resource Subword Modeling", ["Siyuan Feng", "Tan Lee", "Zhiyuan Peng"], "https://doi.org/10.21437/Interspeech.2019-1337", 5, "interspeech", 2019], ["Child Speech Disorder Detection with Siamese Recurrent Network Using Speech Attribute Features", ["Jiarui Wang", "Ying Qin", "Zhiyuan Peng", "Tan Lee"], "https://doi.org/10.21437/Interspeech.2019-2320", 5, "interspeech", 2019]], "Xinrong Sun": [1.3841411600878928e-05, ["A Convolutional Neural Network with Non-Local Module for Speech Enhancement", ["Xiaoqi Li", "Yaxing Li", "Meng Li", "Shan Xu", "Yuanjie Dong", "Xinrong Sun", "Shengwu Xiong"], "https://doi.org/10.21437/Interspeech.2019-2472", 5, "interspeech", 2019]], "Tae-Ho Kim": [0.7232944220304489, ["Adjusting Pleasure-Arousal-Dominance for Continuous Emotional Text-to-Speech Synthesizer", ["Azam Rabiee", "Tae-Ho Kim", "Soo-Young Lee"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8045.html", 2, "interspeech", 2019]], "Jesper B. Boldt": [0, ["Validation of the Non-Intrusive Codebook-Based Short Time Objective Intelligibility Metric for Processed Speech", ["Charlotte Sorensen", "Jesper B. Boldt", "Mads G. Christensen"], "https://doi.org/10.21437/Interspeech.2019-1625", 5, "interspeech", 2019]], "Danny Crookes": [0, ["Full-Sentence Correlation: A Method to Handle Unpredictable Noise for Robust Speech Recognition", ["Ji Ming", "Danny Crookes"], "https://doi.org/10.21437/Interspeech.2019-2127", 5, "interspeech", 2019]], "Kate Saunders": [0, ["A Path Signature Approach for Speech Emotion Recognition", ["Bo Wang", "Maria Liakata", "Hao Ni", "Terry Lyons", "Alejo J. Nevado-Holgado", "Kate Saunders"], "https://doi.org/10.21437/Interspeech.2019-2624", 5, "interspeech", 2019]], "Kristijan Gjoreski": [0, ["Cross-Lingual Transfer Learning for Affective Spoken Dialogue Systems", ["Kristijan Gjoreski", "Aleksandar Gjoreski", "Ivan Kraljevski", "Diane Hirschfeld"], "https://doi.org/10.21437/Interspeech.2019-2163", 5, "interspeech", 2019]], "Gilles Boulianne": [0, ["CRIM's Speech Transcription and Call Sign Detection System for the ATC Airbus Challenge Task", ["Vishwa Gupta", "Lise Rebout", "Gilles Boulianne", "Pierre Andre Menard", "Jahangir Alam"], "https://doi.org/10.21437/Interspeech.2019-1131", 5, "interspeech", 2019]], "Jian Yang": [0.40413545072078705, ["ReMASC: Realistic Replay Attack Corpus for Voice Controlled Systems", ["Yuan Gong", "Jian Yang", "Jacob Huber", "Mitchell MacKnight", "Christian Poellabauer"], "https://doi.org/10.21437/Interspeech.2019-1541", 5, "interspeech", 2019]], "Huy Dat Tran": [0, ["Device Feature Extractor for Replay Spoofing Detection", ["Chang Huai You", "Jichen Yang", "Huy Dat Tran"], "https://doi.org/10.21437/Interspeech.2019-2137", 5, "interspeech", 2019], ["Semi-Supervised Audio Classification with Consistency-Based Regularization", ["Kangkang Lu", "Chuan-Sheng Foo", "Kah Kuan Teh", "Huy Dat Tran", "Vijay Ramaseshan Chandrasekhar"], "https://doi.org/10.21437/Interspeech.2019-1231", 5, "interspeech", 2019]], "Sue Booker": [0, ["Leveraging Acoustic Cues and Paralinguistic Embeddings to Detect Expression from Voice", ["Vikramjit Mitra", "Sue Booker", "Erik Marchi", "David Scott Farrar", "Ute Dorothea Peitz", "Bridget Cheng", "Ermine Teves", "Anuj Mehta", "Devang Naik"], "https://doi.org/10.21437/Interspeech.2019-2998", 5, "interspeech", 2019]], "Melvyn Hunt": [0, ["Neural Network-Based Modeling of Phonetic Durations", ["Xizi Wei", "Melvyn Hunt", "Adrian Skilling"], "https://doi.org/10.21437/Interspeech.2019-2102", 5, "interspeech", 2019]], "Shiyin Kang": [1.356270360020062e-06, ["One-Shot Voice Conversion with Global Speaker Embeddings", ["Hui Lu", "Zhiyong Wu", "Dongyang Dai", "Runnan Li", "Shiyin Kang", "Jia Jia", "Helen Meng"], "https://doi.org/10.21437/Interspeech.2019-2365", 5, "interspeech", 2019], ["Disambiguation of Chinese Polyphones in an End-to-End Framework with Semantic Features Extracted by Pre-Trained BERT", ["Dongyang Dai", "Zhiyong Wu", "Shiyin Kang", "Xixin Wu", "Jia Jia", "Dan Su", "Dong Yu", "Helen Meng"], "https://doi.org/10.21437/Interspeech.2019-2292", 5, "interspeech", 2019], ["Multimedia Simultaneous Translation System for Minority Language Communication with Mandarin", ["Shen Huang", "Bojie Hu", "Shan Huang", "Pengfei Hu", "Jian Kang", "Zhiqiang Lv", "Jinghao Yan", "Qi Ju", "Shiyin Kang", "Deyi Tuo", "Guangzhi Li", "Nurmemet Yolwas"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8020.html", 2, "interspeech", 2019]], "Ziqiang Shi": [0, ["Deep Attention Gated Dilated Temporal Convolutional Networks with Intra-Parallel Convolutional Modules for End-to-End Monaural Speech Separation", ["Ziqiang Shi", "Huibin Lin", "Liu Liu", "Rujie Liu", "Jiqing Han", "Anyan Shi"], "https://doi.org/10.21437/Interspeech.2019-1373", 5, "interspeech", 2019], ["End-to-End Monaural Speech Separation with Multi-Scale Dynamic Weighted Gated Dilated Convolutional Pyramid Network", ["Ziqiang Shi", "Huibin Lin", "Liu Liu", "Rujie Liu", "Shoji Hayakawa", "Shouji Harada", "Jiqing Han"], "https://doi.org/10.21437/Interspeech.2019-1292", 5, "interspeech", 2019]], "Yu-Chen Lin": [0, ["IA-NET: Acceleration and Compression of Speech Enhancement Using Integer-Adder Deep Neural Network", ["Yu-Chen Lin", "Yi-Te Hsu", "Szu-Wei Fu", "Yu Tsao", "Tei-Wei Kuo"], "https://doi.org/10.21437/Interspeech.2019-1207", 5, "interspeech", 2019]], "Juan M. Martin-Donas": [0, ["Multi-Channel Block-Online Source Extraction Based on Utterance Adaptation", ["Juan M. Martin-Donas", "Jens Heitkaemper", "Reinhold Haeb-Umbach", "Angel M. Gomez", "Antonio M. Peinado"], "https://doi.org/10.21437/Interspeech.2019-2244", 5, "interspeech", 2019]], "Tzeviya Sylvia Fuchs": [0, ["SpeechYOLO: Detection and Localization of Speech Objects", ["Yael Segal", "Tzeviya Sylvia Fuchs", "Joseph Keshet"], "https://doi.org/10.21437/Interspeech.2019-1749", 5, "interspeech", 2019]], "Chuan-Sheng Foo": [0, ["Semi-Supervised Audio Classification with Consistency-Based Regularization", ["Kangkang Lu", "Chuan-Sheng Foo", "Kah Kuan Teh", "Huy Dat Tran", "Vijay Ramaseshan Chandrasekhar"], "https://doi.org/10.21437/Interspeech.2019-1231", 5, "interspeech", 2019]], "Xu-Cheng Yin": [0, ["Pyramid Memory Block and Timestep Attention for Speech Emotion Recognition", ["Miao Cao", "Chun Yang", "Fang Zhou", "Xu-Cheng Yin"], "https://doi.org/10.21437/Interspeech.2019-3140", 5, "interspeech", 2019]], "Chen-Chou Lo": [0, ["Investigation of F0 Conditioning and Fully Convolutional Networks in Variational Autoencoder Based Voice Conversion", ["Wen-Chin Huang", "Yi-Chiao Wu", "Chen-Chou Lo", "Patrick Lumban Tobing", "Tomoki Hayashi", "Kazuhiro Kobayashi", "Tomoki Toda", "Yu Tsao", "Hsin-Min Wang"], "https://doi.org/10.21437/Interspeech.2019-1774", 5, "interspeech", 2019], ["MOSNet: Deep Learning-Based Objective Assessment for Voice Conversion", ["Chen-Chou Lo", "Szu-Wei Fu", "Wen-Chin Huang", "Xin Wang", "Junichi Yamagishi", "Yu Tsao", "Hsin-Min Wang"], "https://doi.org/10.21437/Interspeech.2019-2003", 5, "interspeech", 2019]], "Erinc Dikici": [0, ["The SAIL LABS Media Mining Indexer and the CAVA Framework", ["Erinc Dikici", "Gerhard Backfried", "Jurgen Riedler"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8029.html", 2, "interspeech", 2019]], "Jana Brunner": [0, ["Assessing Acoustic and Articulatory Dimensions of Speech Motor Adaptation with Random Forests", ["Eugen Klein", "Jana Brunner", "Phil Hoole"], "https://doi.org/10.21437/Interspeech.2019-1812", 5, "interspeech", 2019]], "Jianwu Dang": [0, ["Acoustic and Articulatory Study of Ewe Vowels: A Comparative Study of Male and Female", ["Kowovi Comivi Alowonou", "Jianguo Wei", "Wenhuan Lu", "Zhicheng Liu", "Kiyoshi Honda", "Jianwu Dang"], "https://doi.org/10.21437/Interspeech.2019-2196", 5, "interspeech", 2019], ["Environment-Dependent Attention-Driven Recurrent Convolutional Neural Network for Robust Speech Enhancement", ["Meng Ge", "Longbiao Wang", "Nan Li", "Hao Shi", "Jianwu Dang", "Xiangang Li"], "https://doi.org/10.21437/Interspeech.2019-1477", 5, "interspeech", 2019], ["CNN-BLSTM Based Question Detection from Dialogs Considering Phase and Context Information", ["Yuke Si", "Longbiao Wang", "Jianwu Dang", "Mengfei Wu", "Aijun Li"], "https://doi.org/10.21437/Interspeech.2019-1701", 5, "interspeech", 2019]], "Adria Mallol-Ragolta": [0, ["A Hierarchical Attention Network-Based Approach for Depression Detection from Transcribed Clinical Interviews", ["Adria Mallol-Ragolta", "Ziping Zhao", "Lukas Stappen", "Nicholas Cummins", "Bjorn W. Schuller"], "https://doi.org/10.21437/Interspeech.2019-2036", 5, "interspeech", 2019]], "Nicholas Lambourne": [0, ["Elpis, an Accessible Speech-to-Text Tool", ["Ben Foley", "Alina Rakhi", "Nicholas Lambourne", "Nicholas Buckeridge", "Janet Wiles"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8006.html", 2, "interspeech", 2019]], "Yusuke Kida": [0, ["Simultaneous Detection and Localization of a Wake-Up Word Using Multi-Task Learning of the Duration and Endpoint", ["Takashi Maekaku", "Yusuke Kida", "Akihiko Sugiyama"], "https://doi.org/10.21437/Interspeech.2019-1180", 5, "interspeech", 2019]], "Solen Quiniou": [0, ["Qualitative Evaluation of ASR Adaptation in a Lecture Context: Application to the PASTEL Corpus", ["Salima Mdhaffar", "Yannick Esteve", "Nicolas Hernandez", "Antoine Laurent", "Richard Dufour", "Solen Quiniou"], "https://doi.org/10.21437/Interspeech.2019-2661", 5, "interspeech", 2019]], "Siddique Latif": [0, ["Direct Modelling of Speech Emotion from Raw Speech", ["Siddique Latif", "Rajib Rana", "Sara Khalifa", "Raja Jurdak", "Julien Epps"], "https://doi.org/10.21437/Interspeech.2019-3252", 5, "interspeech", 2019]], "Jennifer Williams": [0, ["Speech Replay Detection with x-Vector Attack Embeddings and Spectral Features", ["Jennifer Williams", "Joanna Rownicka"], "https://doi.org/10.21437/Interspeech.2019-1760", 5, "interspeech", 2019], ["Disentangling Style Factors from Speaker Representations", ["Jennifer Williams", "Simon King"], "https://doi.org/10.21437/Interspeech.2019-1769", 5, "interspeech", 2019]], "Rif A. Saurous": [0, ["VoiceFilter: Targeted Voice Separation by Speaker-Conditioned Spectrogram Masking", ["Quan Wang", "Hannah Muckenhirn", "Kevin W. Wilson", "Prashant Sridhar", "Zelin Wu", "John R. Hershey", "Rif A. Saurous", "Ron J. Weiss", "Ye Jia", "Ignacio Lopez-Moreno"], "https://doi.org/10.21437/Interspeech.2019-1101", 5, "interspeech", 2019]], "Hanna Mazzawi": [0, ["Improving Keyword Spotting and Language Identification via Neural Architecture Search at Scale", ["Hanna Mazzawi", "Xavi Gonzalvo", "Aleks Kracun", "Prashant Sridhar", "Niranjan Subrahmanya", "Ignacio Lopez-Moreno", "Hyun-Jin Park", "Patrick Violette"], "https://doi.org/10.21437/Interspeech.2019-1916", 5, "interspeech", 2019]], "Neeraja Mahalingam": [0, ["Using Ultrasound Imaging to Create Augmented Visual Biofeedback for Articulatory Practice", ["Colin T. Annand", "Maurice Lamb", "Sarah Dugan", "Sarah R. Li", "Hannah M. Woeste", "T. Douglas Mast", "Michael A. Riley", "Jack A. Masterson", "Neeraja Mahalingam", "Kathryn J. Eary", "Caroline Spencer", "Suzanne Boyce", "Stephanie Jackson", "Anoosha Baxi", "Renee Seward"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8036.html", 2, "interspeech", 2019]], "Hee-Soo Heo": [0.996008962392807, ["Acoustic Scene Classification Using Teacher-Student Learning with Soft-Labels", ["Hee-Soo Heo", "Jee-weon Jung", "Hye-jin Shim", "Ha-Jin Yu"], "https://doi.org/10.21437/Interspeech.2019-1989", 5, "interspeech", 2019], ["Replay Attack Detection with Complementary High-Resolution Information Using End-to-End DNN for the ASVspoof 2019 Challenge", ["Jee-weon Jung", "Hye-jin Shim", "Hee-Soo Heo", "Ha-Jin Yu"], "https://doi.org/10.21437/Interspeech.2019-1991", 5, "interspeech", 2019], ["RawNet: Advanced End-to-End Deep Neural Network Using Raw Waveforms for Text-Independent Speaker Verification", ["Jee-weon Jung", "Hee-Soo Heo", "Ju-ho Kim", "Hye-jin Shim", "Ha-Jin Yu"], "https://doi.org/10.21437/Interspeech.2019-1982", 5, "interspeech", 2019], ["End-to-End Losses Based on Speaker Basis Vectors and All-Speaker Hard Negative Mining for Speaker Verification", ["Hee-Soo Heo", "Jee-weon Jung", "Il-Ho Yang", "Sung-Hyun Yoon", "Hye-jin Shim", "Ha-Jin Yu"], "https://doi.org/10.21437/Interspeech.2019-1986", 5, "interspeech", 2019]], "Annika Nijveld": [0, ["ERP Signal Analysis with Temporal Resolution Using a Time Window Bank", ["Annika Nijveld", "Louis ten Bosch", "Mirjam Ernestus"], "https://doi.org/10.21437/Interspeech.2019-2729", 5, "interspeech", 2019]], "Niko Brummer": [0, ["Large-Scale Speaker Diarization of Radio Broadcast Archives", ["Emre Yilmaz", "Adem Derinel", "Kun Zhou", "Henk van den Heuvel", "Niko Brummer", "Haizhou Li", "David A. van Leeuwen"], "https://doi.org/10.21437/Interspeech.2019-1399", 5, "interspeech", 2019]], "Divesh Lala": [0, ["Analysis of Effect and Timing of Fillers in Natural Turn-Taking", ["Divesh Lala", "Shizuka Nakamura", "Tatsuya Kawahara"], "https://doi.org/10.21437/Interspeech.2019-1527", 5, "interspeech", 2019]], "Jiajun Zhang": [0, ["End-to-End Speech Translation with Knowledge Distillation", ["Yuchen Liu", "Hao Xiong", "Jiajun Zhang", "Zhongjun He", "Hua Wu", "Haifeng Wang", "Chengqing Zong"], "https://doi.org/10.21437/Interspeech.2019-2582", 5, "interspeech", 2019]], "Michael Picheny": [0, ["Large-Scale Mixed-Bandwidth Deep Neural Network Acoustic Modeling for Automatic Speech Recognition", ["Khoi-Nguyen C. Mac", "Xiaodong Cui", "Wei Zhang", "Michael Picheny"], "https://doi.org/10.21437/Interspeech.2019-2641", 5, "interspeech", 2019], ["Challenging the Boundaries of Speech Recognition: The MALACH Corpus", ["Michael Picheny", "Zoltan Tuske", "Brian Kingsbury", "Kartik Audhkhasi", "Xiaodong Cui", "George Saon"], "https://doi.org/10.21437/Interspeech.2019-1907", 5, "interspeech", 2019], ["Acoustic Model Optimization Based on Evolutionary Stochastic Gradient Descent with Anchors for Automatic Speech Recognition", ["Xiaodong Cui", "Michael Picheny"], "https://doi.org/10.21437/Interspeech.2019-2620", 5, "interspeech", 2019], ["Identifying Mood Episodes Using Dialogue Features from Clinical Interviews", ["Zakaria Aldeneh", "Mimansa Jaiswal", "Michael Picheny", "Melvin G. McInnis", "Emily Mower Provost"], "https://doi.org/10.21437/Interspeech.2019-1878", 5, "interspeech", 2019], ["Forget a Bit to Learn Better: Soft Forgetting for CTC-Based Automatic Speech Recognition", ["Kartik Audhkhasi", "George Saon", "Zoltan Tuske", "Brian Kingsbury", "Michael Picheny"], "https://doi.org/10.21437/Interspeech.2019-2841", 5, "interspeech", 2019], ["A Highly Efficient Distributed Deep Learning System for Automatic Speech Recognition", ["Wei Zhang", "Xiaodong Cui", "Ulrich Finkler", "George Saon", "Abdullah Kayi", "Alper Buyuktosunoglu", "Brian Kingsbury", "David S. Kung", "Michael Picheny"], "https://doi.org/10.21437/Interspeech.2019-2700", 5, "interspeech", 2019], ["Detection and Recovery of OOVs for Improved English Broadcast News Captioning", ["Samuel Thomas", "Kartik Audhkhasi", "Zoltan Tuske", "Yinghui Huang", "Michael Picheny"], "https://doi.org/10.21437/Interspeech.2019-2793", 5, "interspeech", 2019]], "Andy T. Liu": [0, ["Unsupervised End-to-End Learning of Discrete Linguistic Units for Voice Conversion", ["Andy T. Liu", "Po-chun Hsu", "Hung-yi Lee"], "https://doi.org/10.21437/Interspeech.2019-2048", 5, "interspeech", 2019]], "Gautam Bhattacharya": [0, ["Deep Speaker Recognition: Modular or Monolithic?", ["Gautam Bhattacharya", "Md. Jahangir Alam", "Patrick Kenny"], "https://doi.org/10.21437/Interspeech.2019-3146", 5, "interspeech", 2019]], "Dirk Voit": [0, ["A Multimodal Real-Time MRI Articulatory Corpus of French for Speech Research", ["Ioannis K. Douros", "Jacques Felblinger", "Jens Frahm", "Karyna Isaieva", "Arun A. Joseph", "Yves Laprie", "Freddy Odille", "Anastasiia Tsukanova", "Dirk Voit", "Pierre-Andre Vuissoz"], "https://doi.org/10.21437/Interspeech.2019-1700", 5, "interspeech", 2019]], "Andreas Triantafyllopoulos": [0, ["Towards Robust Speech Emotion Recognition Using Deep Residual Networks for Speech Enhancement", ["Andreas Triantafyllopoulos", "Gil Keren", "Johannes Wagner", "Ingmar Steiner", "Bjorn W. Schuller"], "https://doi.org/10.21437/Interspeech.2019-1811", 5, "interspeech", 2019], ["Robust Speech Emotion Recognition Under Different Encoding Conditions", ["Christopher Oates", "Andreas Triantafyllopoulos", "Ingmar Steiner", "Bjorn W. Schuller"], "https://doi.org/10.21437/Interspeech.2019-1658", 5, "interspeech", 2019]], "Francesco Cangemi": [0, ["Acoustic Cues to Topic and Narrow Focus in Egyptian Arabic", ["Dina El Zarka", "Barbara Schuppler", "Francesco Cangemi"], "https://doi.org/10.21437/Interspeech.2019-1189", 5, "interspeech", 2019]], "Noa Diamant": [0, ["Identifying Distinctive Acoustic and Spectral Features in Parkinson's Disease", ["Yermiyahu Hauptman", "Ruth Aloni-Lavi", "Itshak Lapidot", "Tanya Gurevich", "Yael Manor", "Stav Naor", "Noa Diamant", "Irit Opher"], "https://doi.org/10.21437/Interspeech.2019-2465", 5, "interspeech", 2019]], "Volker Fischer": [0, ["Speaker-Corrupted Embeddings for Online Speaker Diarization", ["Omid Ghahabi", "Volker Fischer"], "https://doi.org/10.21437/Interspeech.2019-2756", 5, "interspeech", 2019]], "Ye Bai": [0.001440670166630298, ["A Time Delay Neural Network with Shared Weight Self-Attention for Small-Footprint Keyword Spotting", ["Ye Bai", "Jiangyan Yi", "Jianhua Tao", "Zhengqi Wen", "Zhengkun Tian", "Chenghao Zhao", "Cunhang Fan"], "https://doi.org/10.21437/Interspeech.2019-1676", 5, "interspeech", 2019], ["Learn Spelling from Teachers: Transferring Knowledge from Language Models to Sequence-to-Sequence Speech Recognition", ["Ye Bai", "Jiangyan Yi", "Jianhua Tao", "Zhengkun Tian", "Zhengqi Wen"], "https://doi.org/10.21437/Interspeech.2019-1554", 5, "interspeech", 2019], ["Self-Attention Transducers for End-to-End Speech Recognition", ["Zhengkun Tian", "Jiangyan Yi", "Jianhua Tao", "Ye Bai", "Zhengqi Wen"], "https://doi.org/10.21437/Interspeech.2019-2203", 5, "interspeech", 2019]], "Xavier Serra": [0, ["End-to-End Music Source Separation: Is it Possible in the Waveform Domain?", ["Francesc Lluis", "Jordi Pons", "Xavier Serra"], "https://doi.org/10.21437/Interspeech.2019-1177", 5, "interspeech", 2019]], "Yaman Kumar": [0, ["Hush-Hush Speak: Speech Reconstruction Using Silent Videos", ["Shashwat Uttam", "Yaman Kumar", "Dhruva Sahrawat", "Mansi Aggarwal", "Rajiv Ratn Shah", "Debanjan Mahata", "Amanda Stent"], "https://doi.org/10.21437/Interspeech.2019-3269", 5, "interspeech", 2019], ["MobiVSR : Efficient and Light-Weight Neural Network for Visual Speech Recognition on Mobile Devices", ["Nilay Shrivastava", "Astitwa Saxena", "Yaman Kumar", "Rajiv Ratn Shah", "Amanda Stent", "Debanjan Mahata", "Preeti Kaur", "Roger Zimmermann"], "https://doi.org/10.21437/Interspeech.2019-3273", 5, "interspeech", 2019]], "Masafumi Nishimura": [0, ["Knowledge Distillation for Throat Microphone Speech Recognition", ["Takahito Suzuki", "Jun Ogata", "Takashi Tsunakawa", "Masafumi Nishida", "Masafumi Nishimura"], "https://doi.org/10.21437/Interspeech.2019-1597", 5, "interspeech", 2019]], "Jun Ogata": [0, ["Knowledge Distillation for Throat Microphone Speech Recognition", ["Takahito Suzuki", "Jun Ogata", "Takashi Tsunakawa", "Masafumi Nishida", "Masafumi Nishimura"], "https://doi.org/10.21437/Interspeech.2019-1597", 5, "interspeech", 2019]], "Chaoran Liu": [0, ["A Neural Turn-Taking Model without RNN", ["Chaoran Liu", "Carlos Toshinori Ishi", "Hiroshi Ishiguro"], "https://doi.org/10.21437/Interspeech.2019-2270", 5, "interspeech", 2019]], "Chao Weng": [0, ["Large Margin Training for Attention Based End-to-End Speech Recognition", ["Peidong Wang", "Jia Cui", "Chao Weng", "Dong Yu"], "https://doi.org/10.21437/Interspeech.2019-1680", 5, "interspeech", 2019]], "P. V. Muhammed Shifas": [0, ["A Non-Causal FFTNet Architecture for Speech Enhancement", ["P. V. Muhammed Shifas", "Nagaraj Adiga", "Vassilis Tsiaras", "Yannis Stylianou"], "https://doi.org/10.21437/Interspeech.2019-2622", 5, "interspeech", 2019]], "Awni Hannun": [0, ["Sequence-to-Sequence Speech Recognition with Time-Depth Separable Convolutions", ["Awni Hannun", "Ann Lee", "Qiantong Xu", "Ronan Collobert"], "https://doi.org/10.21437/Interspeech.2019-2460", 5, "interspeech", 2019]], "Tao Tu": [0, ["End-to-End Text-to-Speech for Low-Resource Languages by Cross-Lingual Transfer Learning", ["Yuan-Jui Chen", "Tao Tu", "Cheng-chieh Yeh", "Hung-yi Lee"], "https://doi.org/10.21437/Interspeech.2019-2730", 5, "interspeech", 2019]], "Tetsuji Ogawa": [0, ["Multi-Channel Speech Enhancement Using Time-Domain Convolutional Denoising Autoencoder", ["Naohiro Tawara", "Tetsunori Kobayashi", "Tetsuji Ogawa"], "https://doi.org/10.21437/Interspeech.2019-3197", 5, "interspeech", 2019], ["Speaker Adversarial Training of DPGMM-Based Feature Extractor for Zero-Resource Languages", ["Yosuke Higuchi", "Naohiro Tawara", "Tetsunori Kobayashi", "Tetsuji Ogawa"], "https://doi.org/10.21437/Interspeech.2019-2052", 5, "interspeech", 2019]], "Yerbolat Khassanov": [0, ["Constrained Output Embeddings for End-to-End Code-Switching Speech Recognition with Only Monolingual Data", ["Yerbolat Khassanov", "Haihua Xu", "Van Tung Pham", "Zhiping Zeng", "Eng Siong Chng", "Chongjia Ni", "Bin Ma"], "https://doi.org/10.21437/Interspeech.2019-1867", 5, "interspeech", 2019], ["On the End-to-End Solution to Mandarin-English Code-Switching Speech Recognition", ["Zhiping Zeng", "Yerbolat Khassanov", "Van Tung Pham", "Haihua Xu", "Eng Siong Chng", "Haizhou Li"], "https://doi.org/10.21437/Interspeech.2019-1429", 5, "interspeech", 2019], ["Enriching Rare Word Representations in Neural Language Models by Embedding Matrix Augmentation", ["Yerbolat Khassanov", "Zhiping Zeng", "Van Tung Pham", "Haihua Xu", "Eng Siong Chng"], "https://doi.org/10.21437/Interspeech.2019-1858", 5, "interspeech", 2019]], "Doina Precup": [0, ["Neural Transfer Learning for Cry-Based Diagnosis of Perinatal Asphyxia", ["Charles C. Onu", "Jonathan Lebensold", "William L. Hamilton", "Doina Precup"], "https://doi.org/10.21437/Interspeech.2019-2340", 5, "interspeech", 2019]], "Weiqing Wang": [4.758086591394317e-09, ["The DKU-LENOVO Systems for the INTERSPEECH 2019 Computational Paralinguistic Challenge", ["Haiwei Wu", "Weiqing Wang", "Ming Li"], "https://doi.org/10.21437/Interspeech.2019-1386", 5, "interspeech", 2019]], "Abhishek Shrivastava": [0, ["SpeechMarker: A Voice Based Multi-Level Attendance Application", ["Sarfaraz Jelil", "Abhishek Shrivastava", "Rohan Kumar Das", "S. R. Mahadeva Prasanna", "Rohit Sinha"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8014.html", 2, "interspeech", 2019]], "Jiahong Yuan": [0, ["On the Role of Style in Parsing Speech with Neural Models", ["Trang Tran", "Jiahong Yuan", "Yang Liu", "Mari Ostendorf"], "https://doi.org/10.21437/Interspeech.2019-3122", 5, "interspeech", 2019]], "Hyeong-Seok Choi": [0.9999090731143951, ["Adversarially Trained End-to-End Korean Singing Voice Synthesis System", ["Juheon Lee", "Hyeong-Seok Choi", "Chang-Bin Jeon", "Junghyun Koo", "Kyogu Lee"], "https://doi.org/10.21437/Interspeech.2019-1722", 5, "interspeech", 2019]], "Philipp Meer": [0, ["Sibilant Variation in New Englishes: A Comparative Sociophonetic Study of Trinidadian and American English /s(tr)/-Retraction", ["Wiebke Ahlers", "Philipp Meer"], "https://doi.org/10.21437/Interspeech.2019-1821", 5, "interspeech", 2019]], "Julia Hirschberg": [0, ["Predicting Humor by Learning from Time-Aligned Comments", ["Zixiaofan Yang", "Bingyan Hu", "Julia Hirschberg"], "https://doi.org/10.21437/Interspeech.2019-3113", 5, "interspeech", 2019], ["Sincerity in Acted Speech: Presenting the Sincere Apology Corpus and Results", ["Alice Baird", "Eduardo Coutinho", "Julia Hirschberg", "Bjorn W. Schuller"], "https://doi.org/10.21437/Interspeech.2019-1349", 5, "interspeech", 2019], ["Linguistically-Informed Training of Acoustic Word Embeddings for Low-Resource Languages", ["Zixiaofan Yang", "Julia Hirschberg"], "https://doi.org/10.21437/Interspeech.2019-3119", 5, "interspeech", 2019], ["Improving Code-Switched Language Modeling Performance Using Cognate Features", ["Victor Soto", "Julia Hirschberg"], "https://doi.org/10.21437/Interspeech.2019-2681", 5, "interspeech", 2019]], "Rahul Gupta": [0, ["One-vs-All Models for Asynchronous Training: An Empirical Analysis", ["Rahul Gupta", "Aman Alok", "Shankar Ananthakrishnan"], "https://doi.org/10.21437/Interspeech.2019-2760", 5, "interspeech", 2019]], "Premkumar Natarajan": [0, ["NIESR: Nuisance Invariant End-to-End Speech Recognition", ["I-Hung Hsu", "Ayush Jaiswal", "Premkumar Natarajan"], "https://doi.org/10.21437/Interspeech.2019-1836", 5, "interspeech", 2019]], "Hansi Yang": [0.5, ["Music Genre Classification Using Duplicated Convolutional Layers in Neural Networks", ["Hansi Yang", "Wei-Qiang Zhang"], "https://doi.org/10.21437/Interspeech.2019-1298", 5, "interspeech", 2019]], "Rebecca Mead": [0, ["Analysis of Deep Learning Architectures for Cross-Corpus Speech Emotion Recognition", ["Jack Parry", "Dimitri Palaz", "Georgia Clarke", "Pauline Lecomte", "Rebecca Mead", "Michael Berger", "Gregor Hofer"], "https://doi.org/10.21437/Interspeech.2019-2753", 5, "interspeech", 2019]], "Pulikonda Krishna Aditya Sai": [0, ["Energy Separation-Based Instantaneous Frequency Estimation for Cochlear Cepstral Feature for Replay Spoof Detection", ["Ankur T. Patil", "Rajul Acharya", "Pulikonda Krishna Aditya Sai", "Hemant A. Patil"], "https://doi.org/10.21437/Interspeech.2019-2742", 5, "interspeech", 2019]], "Amin Edraki": [0, ["Improvement and Assessment of Spectro-Temporal Modulation Analysis for Speech Intelligibility Estimation", ["Amin Edraki", "Wai-Yip Chan", "Jesper Jensen", "Daniel Fogerty"], "https://doi.org/10.21437/Interspeech.2019-2898", 5, "interspeech", 2019]], "Christophe Cerisara": [0, ["Multi-Lingual Dialogue Act Recognition with Deep Learning Methods", ["Jiri Martinek", "Pavel Kral", "Ladislav Lenc", "Christophe Cerisara"], "https://doi.org/10.21437/Interspeech.2019-1691", 5, "interspeech", 2019]], "Cory Stephenson": [0, ["Semi-Supervised Voice Conversion with Amortized Variational Inference", ["Cory Stephenson", "Gokce Keskin", "Anil Thomas", "Oguz H. Elibol"], "https://doi.org/10.21437/Interspeech.2019-1840", 5, "interspeech", 2019]], "Emmanuel Ferragne": [0, ["The Contribution of Lip Protrusion to Anglo-English /r/: Evidence from Hyper- and Non-Hyperarticulated Speech", ["Hannah King", "Emmanuel Ferragne"], "https://doi.org/10.21437/Interspeech.2019-2851", 5, "interspeech", 2019]], "Jean-Pierre David": [0, ["Binary Speech Features for Keyword Spotting Tasks", ["Alexandre Riviello", "Jean-Pierre David"], "https://doi.org/10.21437/Interspeech.2019-1877", 5, "interspeech", 2019]], "Berkay Inan": [0, ["Evaluating Audiovisual Source Separation in the Context of Video Conferencing", ["Berkay Inan", "Milos Cernak", "Helmut Grabner", "Helena Peic Tukuljac", "Rodrigo C. G. Pena", "Benjamin Ricaud"], "https://doi.org/10.21437/Interspeech.2019-2671", 5, "interspeech", 2019]], "Pierre-Michel Bousquet": [0, ["I4U Submission to NIST SRE 2018: Leveraging from a Decade of Shared Experiences", ["Kong Aik Lee", "Ville Hautamaki", "Tomi H. Kinnunen", "Hitoshi Yamamoto", "Koji Okabe", "Ville Vestman", "Jing Huang", "Guohong Ding", "Hanwu Sun", "Anthony Larcher", "Rohan Kumar Das", "Haizhou Li", "Mickael Rouvier", "Pierre-Michel Bousquet", "Wei Rao", "Qing Wang", "Chunlei Zhang", "Fahimeh Bahmaninezhad", "Hector Delgado", "Massimiliano Todisco"], "https://doi.org/10.21437/Interspeech.2019-1533", 5, "interspeech", 2019], ["On Robustness of Unsupervised Domain Adaptation for Speaker Recognition", ["Pierre-Michel Bousquet", "Mickael Rouvier"], "https://doi.org/10.21437/Interspeech.2019-1524", 5, "interspeech", 2019]], "Jukka-Pekka Onnela": [0, ["Use of Beiwe Smartphone App to Identify and Track Speech Decline in Amyotrophic Lateral Sclerosis (ALS)", ["Kathryn P. Connaghan", "Jordan R. Green", "Sabrina Paganoni", "James Chan", "Harli Weber", "Ella Collins", "Brian Richburg", "Marziye Eshghi", "Jukka-Pekka Onnela", "James D. Berry"], "https://doi.org/10.21437/Interspeech.2019-3126", 5, "interspeech", 2019]], "Hongbin Suo": [0, ["Towards a Fault-Tolerant Speaker Verification System: A Regularization Approach to Reduce the Condition Number", ["Siqi Zheng", "Gang Liu", "Hongbin Suo", "Yun Lei"], "https://doi.org/10.21437/Interspeech.2019-1442", 5, "interspeech", 2019], ["Autoencoder-Based Semi-Supervised Curriculum Learning for Out-of-Domain Speaker Verification", ["Siqi Zheng", "Gang Liu", "Hongbin Suo", "Yun Lei"], "https://doi.org/10.21437/Interspeech.2019-1440", 5, "interspeech", 2019]], "I-Hung Hsu": [0, ["NIESR: Nuisance Invariant End-to-End Speech Recognition", ["I-Hung Hsu", "Ayush Jaiswal", "Premkumar Natarajan"], "https://doi.org/10.21437/Interspeech.2019-1836", 5, "interspeech", 2019]], "Tran Huy Dat": [0, ["The I2R's ASR System for the VOiCES from a Distance Challenge 2019", ["Tze Yuang Chong", "Kye Min Tan", "Kah Kuan Teh", "Chang Huai You", "Hanwu Sun", "Tran Huy Dat"], "https://doi.org/10.21437/Interspeech.2019-2130", 5, "interspeech", 2019], ["The I2R's ASR System for the VOiCES from a Distance Challenge 2019", ["Tze Yuang Chong", "Kye Min Tan", "Kah Kuan Teh", "Chang Huai You", "Hanwu Sun", "Tran Huy Dat"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/abs18.html", 0, "interspeech", 2019], ["The I2R's Submission to VOiCES Distance Speaker Recognition Challenge 2019", ["Hanwu Sun", "Kah Kuan Teh", "Ivan Kukanov", "Tran Huy Dat"], "https://doi.org/10.21437/Interspeech.2019-1997", 5, "interspeech", 2019]], "Jun-Wei Gan": [7.176375675044255e-06, ["Token-Level Ensemble Distillation for Grapheme-to-Phoneme Conversion", ["Hao Sun", "Xu Tan", "Jun-Wei Gan", "Hongzhi Liu", "Sheng Zhao", "Tao Qin", "Tie-Yan Liu"], "https://doi.org/10.21437/Interspeech.2019-1208", 5, "interspeech", 2019]], "Jun Chen": [0, ["An Attention-Based Hybrid Network for Automatic Detection of Alzheimer's Disease from Narrative Speech", ["Jun Chen", "Ji Zhu", "Jieping Ye"], "https://doi.org/10.21437/Interspeech.2019-2872", 5, "interspeech", 2019]], "John Sabatini": [0, ["Automated Estimation of Oral Reading Fluency During Summer Camp e-Book Reading with MyTurnToRead", ["Anastassia Loukina", "Beata Beigman Klebanov", "Patrick L. Lange", "Yao Qian", "Binod Gyawali", "Nitin Madnani", "Abhinav Misra", "Klaus Zechner", "Zuowei Wang", "John Sabatini"], "https://doi.org/10.21437/Interspeech.2019-2889", 5, "interspeech", 2019]], "Eric Sun": [4.787108991877176e-05, ["Layer Trajectory BLSTM", ["Eric Sun", "Jinyu Li", "Yifan Gong"], "https://doi.org/10.21437/Interspeech.2019-2971", 5, "interspeech", 2019], ["Self-Teaching Networks", ["Liang Lu", "Eric Sun", "Yifan Gong"], "https://doi.org/10.21437/Interspeech.2019-1467", 5, "interspeech", 2019]], "Minkyu Shin": [0.9969374090433121, ["Improved Vocal Tract Length Perturbation for a State-of-the-Art End-to-End Speech Recognition System", ["Chanwoo Kim", "Minkyu Shin", "Abhinav Garg", "Dhananjaya Gowda"], "https://doi.org/10.21437/Interspeech.2019-3227", 5, "interspeech", 2019]], "Chris Biemann": [0, ["SparseSpeech: Unsupervised Acoustic Unit Discovery with Memory-Augmented Sequence Autoencoders", ["Benjamin Milde", "Chris Biemann"], "https://doi.org/10.21437/Interspeech.2019-2938", 5, "interspeech", 2019]], "Pierre Lanchantin": [0, ["Investigating the Effects of Noisy and Reverberant Speech in Text-to-Speech Systems", ["David Ayllon", "Hector A. Sanchez-Hevia", "Carol Figueroa", "Pierre Lanchantin"], "https://doi.org/10.21437/Interspeech.2019-3104", 5, "interspeech", 2019], ["Selection and Training Schemes for Improving TTS Voice Built on Found Data", ["Fang-Yu Kuo", "Iris Chuoying Ouyang", "Sandesh Aryal", "Pierre Lanchantin"], "https://doi.org/10.21437/Interspeech.2019-2816", 5, "interspeech", 2019], ["A Strategy for Improved Phone-Level Lyrics-to-Audio Alignment for Speech-to-Singing Synthesis", ["David Ayllon", "Fernando Villavicencio", "Pierre Lanchantin"], "https://doi.org/10.21437/Interspeech.2019-3049", 5, "interspeech", 2019]], "Pingchuan Ma": [0, ["Investigating the Lombard Effect Influence on End-to-End Audio-Visual Speech Recognition", ["Pingchuan Ma", "Stavros Petridis", "Maja Pantic"], "https://doi.org/10.21437/Interspeech.2019-2726", 5, "interspeech", 2019], ["Video-Driven Speech Reconstruction Using Generative Adversarial Networks", ["Konstantinos Vougioukas", "Pingchuan Ma", "Stavros Petridis", "Maja Pantic"], "https://doi.org/10.21437/Interspeech.2019-1445", 5, "interspeech", 2019]], "Soheil Khorram": [0, ["Convolutional Neural Network-Based Speech Enhancement for Cochlear Implant Recipients", ["Nursadul Mamun", "Soheil Khorram", "John H. L. Hansen"], "https://doi.org/10.21437/Interspeech.2019-1850", 5, "interspeech", 2019], ["Probabilistic Permutation Invariant Training for Speech Separation", ["Midia Yousefi", "Soheil Khorram", "John H. L. Hansen"], "https://doi.org/10.21437/Interspeech.2019-1827", 5, "interspeech", 2019]], "Julie Carson-Berndsen": [0, ["The Effect of Phoneme Distribution on Perceptual Similarity in English", ["Emma ONeill", "Julie Carson-Berndsen"], "https://doi.org/10.21437/Interspeech.2019-3042", 5, "interspeech", 2019]], "Robin Dodsworth": [0, ["The Different Roles of Expectations in Phonetic and Lexical Processing", ["Shiri Lev-Ari", "Robin Dodsworth", "Jeff Mielke", "Sharon Peperkamp"], "https://doi.org/10.21437/Interspeech.2019-1795", 5, "interspeech", 2019]], "Dong Yu": [0.1973298266530037, ["Large Margin Training for Attention Based End-to-End Speech Recognition", ["Peidong Wang", "Jia Cui", "Chao Weng", "Dong Yu"], "https://doi.org/10.21437/Interspeech.2019-1680", 5, "interspeech", 2019], ["Improved Speaker-Dependent Separation for CHiME-5 Challenge", ["Jian Wu", "Yong Xu", "Shi-Xiong Zhang", "Lianwu Chen", "Meng Yu", "Lei Xie", "Dong Yu"], "https://doi.org/10.21437/Interspeech.2019-1569", 5, "interspeech", 2019], ["Disambiguation of Chinese Polyphones in an End-to-End Framework with Semantic Features Extracted by Pre-Trained BERT", ["Dongyang Dai", "Zhiyong Wu", "Shiyin Kang", "Xixin Wu", "Jia Jia", "Dan Su", "Dong Yu", "Helen Meng"], "https://doi.org/10.21437/Interspeech.2019-2292", 5, "interspeech", 2019], ["Extract, Adapt and Recognize: An End-to-End Neural Network for Corrupted Monaural Speech Recognition", ["Max W. Y. Lam", "Jun Wang", "Xunying Liu", "Helen Meng", "Dan Su", "Dong Yu"], "https://doi.org/10.21437/Interspeech.2019-1626", 5, "interspeech", 2019], ["Neural Spatial Filter: Target Speaker Speech Separation Assisted with Directional Information", ["Rongzhi Gu", "Lianwu Chen", "Shi-Xiong Zhang", "Jimeng Zheng", "Yong Xu", "Meng Yu", "Dan Su", "Yuexian Zou", "Dong Yu"], "https://doi.org/10.21437/Interspeech.2019-2266", 5, "interspeech", 2019], ["A Comprehensive Study of Speech Separation: Spectrogram vs Waveform Separation", ["Fahimeh Bahmaninezhad", "Jian Wu", "Rongzhi Gu", "Shi-Xiong Zhang", "Yong Xu", "Meng Yu", "Dong Yu"], "https://doi.org/10.21437/Interspeech.2019-3181", 5, "interspeech", 2019]], "Xurong Xie": [0, ["Fast DNN Acoustic Model Speaker Adaptation by Learning Hidden Unit Contribution Features", ["Xurong Xie", "Xunying Liu", "Tan Lee", "Lan Wang"], "https://doi.org/10.21437/Interspeech.2019-2050", 5, "interspeech", 2019], ["LF-MMI Training of Bayesian and Gaussian Process Time Delay Neural Networks for Speech Recognition", ["Shoukang Hu", "Xurong Xie", "Shansong Liu", "Max W. Y. Lam", "Jianwei Yu", "Xixin Wu", "Xunying Liu", "Helen Meng"], "https://doi.org/10.21437/Interspeech.2019-2379", 5, "interspeech", 2019]], "Geza Nemeth": [0, ["Ultrasound-Based Silent Speech Interface Built on a Continuous Vocoder", ["Tamas Gabor Csapo", "Mohammed Salah Al-Radhi", "Geza Nemeth", "Gabor Gosztolya", "Tamas Grosz", "Laszlo Toth", "Alexandra Marko"], "https://doi.org/10.21437/Interspeech.2019-2046", 5, "interspeech", 2019], ["Transformer Based Grapheme-to-Phoneme Conversion", ["Sevinj Yolchuyeva", "Geza Nemeth", "Balint Gyires-Toth"], "https://doi.org/10.21437/Interspeech.2019-1954", 5, "interspeech", 2019]], "Gianpiero Francesca": [0, ["Detecting Topic-Oriented Speaker Stance in Conversational Speech", ["Catherine Lai", "Beatrice Alex", "Johanna D. Moore", "Leimin Tian", "Tatsuro Hori", "Gianpiero Francesca"], "https://doi.org/10.21437/Interspeech.2019-2632", 5, "interspeech", 2019]], "Alex Waibel": [0, ["Very Deep Self-Attention Networks for End-to-End Speech Recognition", ["Ngoc-Quan Pham", "Thai-Son Nguyen", "Jan Niehues", "Markus Muller", "Alex Waibel"], "https://doi.org/10.21437/Interspeech.2019-2702", 5, "interspeech", 2019]], "Gabriel Murray": [0, ["Analyzing Verbal and Nonverbal Features for Predicting Group Performance", ["Uliyana Kubasova", "Gabriel Murray", "McKenzie Braley"], "https://doi.org/10.21437/Interspeech.2019-3062", 5, "interspeech", 2019]], "Qiang Yang": [0.004053857177495956, ["Topic-Aware Dialogue Speech Recognition with Transfer Learning", ["Yuanfeng Song", "Di Jiang", "Xueyang Wu", "Qian Xu", "Raymond Chi-Wing Wong", "Qiang Yang"], "https://doi.org/10.21437/Interspeech.2019-1694", 5, "interspeech", 2019]], "Antonio J. S. Teixeira": [0, ["Exploring Critical Articulator Identification from 50Hz RT-MRI Data of the Vocal Tract", ["Samuel S. Silva", "Antonio J. S. Teixeira", "Conceicao Cunha", "Nuno Almeida", "Arun A. Joseph", "Jens Frahm"], "https://doi.org/10.21437/Interspeech.2019-2897", 5, "interspeech", 2019], ["On the Role of Oral Configurations in European Portuguese Nasal Vowels", ["Conceicao Cunha", "Samuel S. Silva", "Antonio J. S. Teixeira", "Catarina Oliveira", "Paula Martins", "Arun A. Joseph", "Jens Frahm"], "https://doi.org/10.21437/Interspeech.2019-2232", 5, "interspeech", 2019], ["Age-Related Changes in European Portuguese Vowel Acoustics", ["Luciana Albuquerque", "Catarina Oliveira", "Antonio J. S. Teixeira", "Pedro Sa-Couto", "Daniela Figueiredo"], "https://doi.org/10.21437/Interspeech.2019-1818", 5, "interspeech", 2019]], "Adem Derinel": [0, ["Large-Scale Speaker Diarization of Radio Broadcast Archives", ["Emre Yilmaz", "Adem Derinel", "Kun Zhou", "Henk van den Heuvel", "Niko Brummer", "Haizhou Li", "David A. van Leeuwen"], "https://doi.org/10.21437/Interspeech.2019-1399", 5, "interspeech", 2019], ["Code-Switching Detection Using ASR-Generated Language Posteriors", ["Qinyi Wang", "Emre Yilmaz", "Adem Derinel", "Haizhou Li"], "https://doi.org/10.21437/Interspeech.2019-1161", 5, "interspeech", 2019]], "Parav Nagarsheth": [0, ["Pindrop Labs' Submission to the First Multi-Target Speaker Detection and Identification Challenge", ["Elie Khoury", "Khaled Lakhdhar", "Andrew Vaughan", "Ganesh Sivaraman", "Parav Nagarsheth"], "https://doi.org/10.21437/Interspeech.2019-3179", 4, "interspeech", 2019]], "Omnia Ibrahim": [0, ["Fundamental Frequency Accommodation in Multi-Party Human-Robot Game Interactions: The Effect of Winning or Losing", ["Omnia Ibrahim", "Gabriel Skantze", "Sabine Stoll", "Volker Dellwo"], "https://doi.org/10.21437/Interspeech.2019-2496", 5, "interspeech", 2019]], "Yosuke Higuchi": [0, ["Speaker Adversarial Training of DPGMM-Based Feature Extractor for Zero-Resource Languages", ["Yosuke Higuchi", "Naohiro Tawara", "Tetsunori Kobayashi", "Tetsuji Ogawa"], "https://doi.org/10.21437/Interspeech.2019-2052", 5, "interspeech", 2019]], "Zhuo Chen": [0, ["Meeting Transcription Using Asynchronous Distant Microphones", ["Takuya Yoshioka", "Dimitrios Dimitriadis", "Andreas Stolcke", "William Hinthorn", "Zhuo Chen", "Michael Zeng", "Xuedong Huang"], "https://doi.org/10.21437/Interspeech.2019-3088", 5, "interspeech", 2019]], "Ke-Xin He": [0, ["Learning How to Listen: A Temporal-Frequential Attention Model for Sound Event Detection", ["Yu-Han Shen", "Ke-Xin He", "Wei-Qiang Zhang"], "https://doi.org/10.21437/Interspeech.2019-2045", 5, "interspeech", 2019], ["Hierarchical Pooling Structure for Weakly Labeled Sound Event Detection", ["Ke-Xin He", "Yu-Han Shen", "Wei-Qiang Zhang"], "https://doi.org/10.21437/Interspeech.2019-2049", 5, "interspeech", 2019]], "Hemanth Venkateswara": [0, ["Say What? A Dataset for Exploring the Error Patterns That Two ASR Engines Make", ["Meredith Moore", "Michael Saxon", "Hemanth Venkateswara", "Visar Berisha", "Sethuraman Panchanathan"], "https://doi.org/10.21437/Interspeech.2019-3096", 5, "interspeech", 2019]], "Golan Levy": [0, ["GECKO - A Tool for Effective Annotation of Human Conversations", ["Golan Levy", "Raquel Sitman", "Ido Amir", "Eduard Golshtein", "Ran Mochary", "Eilon Reshef", "Roi Reichart", "Omri Allouche"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8025.html", 2, "interspeech", 2019]], "S. Dandapat": [0, ["Hypernasality Severity Detection Using Constant Q Cepstral Coefficients", ["Akhilesh Kumar Dubey", "S. R. Mahadeva Prasanna", "S. Dandapat"], "https://doi.org/10.21437/Interspeech.2019-2151", 5, "interspeech", 2019]], "Ngoc Thang Vu": [0, ["Automatic Compression of Subtitles with Neural Networks and its Effect on User Experience", ["Katrin Angerbauer", "Heike Adel", "Ngoc Thang Vu"], "https://doi.org/10.21437/Interspeech.2019-1750", 5, "interspeech", 2019], ["CycleGAN-Based Emotion Style Transfer as Data Augmentation for Speech Emotion Recognition", ["Fang Bao", "Michael Neumann", "Ngoc Thang Vu"], "https://doi.org/10.21437/Interspeech.2019-2293", 5, "interspeech", 2019], ["Multimodal Articulation-Based Pronunciation Error Detection with Spectrogram and Acoustic Features", ["Sabrina Jenne", "Ngoc Thang Vu"], "https://doi.org/10.21437/Interspeech.2019-1677", 5, "interspeech", 2019], ["End-to-End Multi-Speaker Speech Recognition Using Speaker Embeddings and Transfer Learning", ["Pavel Denisov", "Ngoc Thang Vu"], "https://doi.org/10.21437/Interspeech.2019-1130", 5, "interspeech", 2019]], "Zhihao Du": [0, ["Acoustic Scene Classification by Implicitly Identifying Distinct Sound Events", ["Hongwei Song", "Jiqing Han", "Shiwen Deng", "Zhihao Du"], "https://doi.org/10.21437/Interspeech.2019-2231", 5, "interspeech", 2019]], "Brian Kingsbury": [0, ["Challenging the Boundaries of Speech Recognition: The MALACH Corpus", ["Michael Picheny", "Zoltan Tuske", "Brian Kingsbury", "Kartik Audhkhasi", "Xiaodong Cui", "George Saon"], "https://doi.org/10.21437/Interspeech.2019-1907", 5, "interspeech", 2019], ["Forget a Bit to Learn Better: Soft Forgetting for CTC-Based Automatic Speech Recognition", ["Kartik Audhkhasi", "George Saon", "Zoltan Tuske", "Brian Kingsbury", "Michael Picheny"], "https://doi.org/10.21437/Interspeech.2019-2841", 5, "interspeech", 2019], ["A Highly Efficient Distributed Deep Learning System for Automatic Speech Recognition", ["Wei Zhang", "Xiaodong Cui", "Ulrich Finkler", "George Saon", "Abdullah Kayi", "Alper Buyuktosunoglu", "Brian Kingsbury", "David S. Kung", "Michael Picheny"], "https://doi.org/10.21437/Interspeech.2019-2700", 5, "interspeech", 2019]], "Lifa Sun": [0.008820109069347382, ["Jointly Trained Conversion Model and WaveNet Vocoder for Non-Parallel Voice Conversion Using Mel-Spectrograms and Phonetic Posteriorgrams", ["Songxiang Liu", "Yuewen Cao", "Xixin Wu", "Lifa Sun", "Xunying Liu", "Helen Meng"], "https://doi.org/10.21437/Interspeech.2019-1316", 5, "interspeech", 2019]], "Manoj Kumar Ramanathi": [0, ["ASR Inspired Syllable Stress Detection for Pronunciation Evaluation Without Using a Supervised Classifier and Syllable Level Features", ["Manoj Kumar Ramanathi", "Chiranjeevi Yarra", "Prasanta Kumar Ghosh"], "https://doi.org/10.21437/Interspeech.2019-2091", 5, "interspeech", 2019], ["An Improved Goodness of Pronunciation (GoP) Measure for Pronunciation Evaluation with DNN-HMM System Considering HMM Transition Probabilities", ["Sweekar Sudhakara", "Manoj Kumar Ramanathi", "Chiranjeevi Yarra", "Prasanta Kumar Ghosh"], "https://doi.org/10.21437/Interspeech.2019-2363", 5, "interspeech", 2019]], "Robert Glowski": [0, ["Avaya Conversational Intelligence: A Real-Time System for Spoken Language Understanding in Human-Human Call Center Conversations", ["Jan Mizgajski", "Adrian Szymczak", "Robert Glowski", "Piotr Szymanski", "Piotr Zelasko", "Lukasz Augustyniak", "Mikolaj Morzy", "Yishay Carmiel", "Jeff Hodson", "Lukasz Wojciak", "Daniel Smoczyk", "Adam Wrobel", "Bartosz Borowik", "Adam Artajew", "Marcin Baran", "Cezary Kwiatkowski", "Marzena Zyla-Hoppe"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8002.html", 2, "interspeech", 2019]], "Ascension Gallardo-Antolin": [0, ["A Saliency-Based Attention LSTM Model for Cognitive Load Classification from Speech", ["Ascension Gallardo-Antolin", "Juan Manuel Montero"], "https://doi.org/10.21437/Interspeech.2019-1603", 5, "interspeech", 2019]], "Julia Schottenhamml": [0, ["Analysis by Adversarial Synthesis - A Novel Approach for Speech Vocoding", ["Ahmed Mustafa", "Arijit Biswas", "Christian Bergler", "Julia Schottenhamml", "Andreas K. Maier"], "https://doi.org/10.21437/Interspeech.2019-1195", 5, "interspeech", 2019]], "Courtney Mansfield": [0, ["Disfluencies and Human Speech Transcription Errors", ["Vicky Zayats", "Trang Tran", "Richard A. Wright", "Courtney Mansfield", "Mari Ostendorf"], "https://doi.org/10.21437/Interspeech.2019-3134", 5, "interspeech", 2019]], "Anat Lerner": [0, ["A Storyteller's Tale: Literature Audiobooks Genre Classification Using CNN and RNN Architectures", ["Nehory Carmi", "Azaria Cohen", "Mireille Avigal", "Anat Lerner"], "https://doi.org/10.21437/Interspeech.2019-1154", 4, "interspeech", 2019]], "Paul Warren": [0, ["Tracking the New Zealand English NEAR/SQUARE Merger Using Functional Principal Components Analysis", ["Michele Gubian", "Jonathan Harrington", "Mary Stevens", "Florian Schiel", "Paul Warren"], "https://doi.org/10.21437/Interspeech.2019-2115", 5, "interspeech", 2019]], "Nam Soo Kim": [1, ["End-to-End Multi-Channel Speech Enhancement Using Inter-Channel Time-Restricted Attention on Raw Waveform", ["Hyeon Seung Lee", "Hyung Yong Kim", "Woo Hyun Kang", "Jeunghun Kim", "Nam Soo Kim"], "https://doi.org/10.21437/Interspeech.2019-2397", 5, "interspeech", 2019]], "Zhehuai Chen": [0, ["Joint Grapheme and Phoneme Embeddings for Contextual End-to-End ASR", ["Zhehuai Chen", "Mahaveer Jain", "Yongqiang Wang", "Michael L. Seltzer", "Christian Fuegen"], "https://doi.org/10.21437/Interspeech.2019-1434", 5, "interspeech", 2019]], "Rahul Goel": [0, ["Towards Universal Dialogue Act Tagging for Task-Oriented Dialogues", ["Shachi Paul", "Rahul Goel", "Dilek Hakkani-Tur"], "https://doi.org/10.21437/Interspeech.2019-1866", 5, "interspeech", 2019], ["HyST: A Hybrid Approach for Flexible and Accurate Dialogue State Tracking", ["Rahul Goel", "Shachi Paul", "Dilek Hakkani-Tur"], "https://doi.org/10.21437/Interspeech.2019-1863", 5, "interspeech", 2019]], "Elan Van Biljon": [0, ["Unsupervised Acoustic Unit Discovery for Speech Synthesis Using Discrete Latent-Variable Neural Networks", ["Ryan Eloff", "Andre Nortje", "Benjamin van Niekerk", "Avashna Govender", "Leanne Nortje", "Arnu Pretorius", "Elan Van Biljon", "Ewald van der Westhuizen", "Lisa van Staden", "Herman Kamper"], "https://doi.org/10.21437/Interspeech.2019-1518", 5, "interspeech", 2019]], "Meysam Asgari": [0, ["Improving ASR Systems for Children with Autism and Language Impairment Using Domain-Focused DNN Transfer Techniques", ["Robert Gale", "Liu Chen", "Jill Dolata", "Jan P. H. van Santen", "Meysam Asgari"], "https://doi.org/10.21437/Interspeech.2019-3161", 5, "interspeech", 2019]], "Mikolaj Morzy": [0, ["Avaya Conversational Intelligence: A Real-Time System for Spoken Language Understanding in Human-Human Call Center Conversations", ["Jan Mizgajski", "Adrian Szymczak", "Robert Glowski", "Piotr Szymanski", "Piotr Zelasko", "Lukasz Augustyniak", "Mikolaj Morzy", "Yishay Carmiel", "Jeff Hodson", "Lukasz Wojciak", "Daniel Smoczyk", "Adam Wrobel", "Bartosz Borowik", "Adam Artajew", "Marcin Baran", "Cezary Kwiatkowski", "Marzena Zyla-Hoppe"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8002.html", 2, "interspeech", 2019]], "Kou Tanaka": [0, ["StarGAN-VC2: Rethinking Conditional Methods for StarGAN-Based Voice Conversion", ["Takuhiro Kaneko", "Hirokazu Kameoka", "Kou Tanaka", "Nobukatsu Hojo"], "https://doi.org/10.21437/Interspeech.2019-2236", 5, "interspeech", 2019]], "Yaping Yang": [4.951884875481483e-06, ["ToneNet: A CNN Model of Tone Classification of Mandarin Chinese", ["Qiang Gao", "Shutao Sun", "Yaping Yang"], "https://doi.org/10.21437/Interspeech.2019-1483", 5, "interspeech", 2019]], "Shinya Fujie": [0, ["Recognition of Intentions of Users' Short Responses for Conversational News Delivery System", ["Hiroaki Takatsu", "Katsuya Yokoyama", "Yoichi Matsuyama", "Hiroshi Honda", "Shinya Fujie", "Tetsunori Kobayashi"], "https://doi.org/10.21437/Interspeech.2019-2121", 5, "interspeech", 2019]], "Ziping Zhao": [0, ["Attention-Enhanced Connectionist Temporal Classification for Discrete Speech Emotion Recognition", ["Ziping Zhao", "Zhongtian Bao", "Zixing Zhang", "Nicholas Cummins", "Haishuai Wang", "Bjorn W. Schuller"], "https://doi.org/10.21437/Interspeech.2019-1649", 5, "interspeech", 2019], ["A Hierarchical Attention Network-Based Approach for Depression Detection from Transcribed Clinical Interviews", ["Adria Mallol-Ragolta", "Ziping Zhao", "Lukas Stappen", "Nicholas Cummins", "Bjorn W. Schuller"], "https://doi.org/10.21437/Interspeech.2019-2036", 5, "interspeech", 2019], ["Speech Augmentation via Speaker-Specific Noise in Unseen Environment", ["Yanan Guo", "Ziping Zhao", "Yide Ma", "Bjorn W. Schuller"], "https://doi.org/10.21437/Interspeech.2019-2712", 5, "interspeech", 2019]], "Charles C. Onu": [0, ["Neural Transfer Learning for Cry-Based Diagnosis of Perinatal Asphyxia", ["Charles C. Onu", "Jonathan Lebensold", "William L. Hamilton", "Doina Precup"], "https://doi.org/10.21437/Interspeech.2019-2340", 5, "interspeech", 2019]], "Nicholas D. Lane": [0, ["ShrinkML: End-to-End ASR Model Compression Using Reinforcement Learning", ["Lukasz Dudziak", "Mohamed S. Abdelfattah", "Ravichander Vipperla", "Stefanos Laskaridis", "Nicholas D. Lane"], "https://doi.org/10.21437/Interspeech.2019-2811", 5, "interspeech", 2019]], "Wai-Yip Chan": [0, ["Improvement and Assessment of Spectro-Temporal Modulation Analysis for Speech Intelligibility Estimation", ["Amin Edraki", "Wai-Yip Chan", "Jesper Jensen", "Daniel Fogerty"], "https://doi.org/10.21437/Interspeech.2019-2898", 5, "interspeech", 2019]], "Apoorv Vyas": [0, ["Unbiased Semi-Supervised LF-MMI Training Using Dropout", ["Sibo Tong", "Apoorv Vyas", "Philip N. Garner", "Herve Bourlard"], "https://doi.org/10.21437/Interspeech.2019-2678", 5, "interspeech", 2019]], "Richard Sproat": [0, ["Unified Verbalization for Speech Recognition & Synthesis Across Languages", ["Sandy Ritchie", "Richard Sproat", "Kyle Gorman", "Daan van Esch", "Christian Schallhart", "Nikos Bampounis", "Benoit Brard", "Jonas Fromseier Mortensen", "Millie Holt", "Eoin Mahon"], "https://doi.org/10.21437/Interspeech.2019-2807", 5, "interspeech", 2019], ["Dual Encoder Classifier Models as Constraints in Neural Text Normalization", ["Ajda Gokcen", "Hao Zhang", "Richard Sproat"], "https://doi.org/10.21437/Interspeech.2019-1135", 5, "interspeech", 2019]], "Hongxia Jin": [1.1710628397988004e-12, ["Rare Sound Event Detection Using Deep Learning and Data Augmentation", ["Yanping Chen", "Hongxia Jin"], "https://doi.org/10.21437/Interspeech.2019-1985", 5, "interspeech", 2019], ["Iterative Delexicalization for Improved Spoken Language Understanding", ["Avik Ray", "Yilin Shen", "Hongxia Jin"], "https://doi.org/10.21437/Interspeech.2019-2955", 5, "interspeech", 2019], ["Interpreting and Improving Deep Neural SLU Models via Vocabulary Importance", ["Yilin Shen", "Wenhu Chen", "Hongxia Jin"], "https://doi.org/10.21437/Interspeech.2019-3184", 5, "interspeech", 2019]], "Zheng Lian": [0, ["Conversational Emotion Analysis via Attention Mechanisms", ["Zheng Lian", "Jianhua Tao", "Bin Liu", "Jian Huang"], "https://doi.org/10.21437/Interspeech.2019-1577", 5, "interspeech", 2019], ["Unsupervised Representation Learning with Future Observation Prediction for Speech Emotion Recognition", ["Zheng Lian", "Jianhua Tao", "Bin Liu", "Jian Huang"], "https://doi.org/10.21437/Interspeech.2019-1582", 5, "interspeech", 2019]], "Bjorn Eskofier": [0, ["Apkinson: A Mobile Solution for Multimodal Assessment of Patients with Parkinson's Disease", ["Juan Camilo Vasquez-Correa", "Tomas Arias-Vergara", "Philipp Klumpp", "M. Strauss", "Arne Kuderle", "Nils Roth", "S. Bayerl", "Nicanor Garcia-Ospina", "Paula Andrea Perez-Toro", "L. Felipe Parra-Gallego", "Cristian David Rios-Urrego", "D. Escobar-Grisales", "Juan Rafael Orozco-Arroyave", "Bjorn Eskofier", "Elmar Noth"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8003.html", 2, "interspeech", 2019]], "Y. Wei": [0, ["Effects of Base-Frequency and Spectral Envelope on Deep-Learning Speech Separation and Recognition Models", ["J. Hui", "Y. Wei", "S. T. Chen", "R. H. Y. So"], "https://doi.org/10.21437/Interspeech.2019-1715", 5, "interspeech", 2019]], "Haoran Miao": [0, ["Online Hybrid CTC/Attention Architecture for End-to-End Speech Recognition", ["Haoran Miao", "Gaofeng Cheng", "Pengyuan Zhang", "Ta Li", "Yonghong Yan"], "https://doi.org/10.21437/Interspeech.2019-2018", 5, "interspeech", 2019]], "Xuedong Huang": [0, ["Meeting Transcription Using Asynchronous Distant Microphones", ["Takuya Yoshioka", "Dimitrios Dimitriadis", "Andreas Stolcke", "William Hinthorn", "Zhuo Chen", "Michael Zeng", "Xuedong Huang"], "https://doi.org/10.21437/Interspeech.2019-3088", 5, "interspeech", 2019]], "Yoshinori Shiga": [0, ["Real-Time Neural Text-to-Speech with Sequence-to-Sequence Acoustic Model and WaveGlow or Single Gaussian WaveRNN Vocoders", ["Takuma Okamoto", "Tomoki Toda", "Yoshinori Shiga", "Hisashi Kawai"], "https://doi.org/10.21437/Interspeech.2019-1288", 5, "interspeech", 2019], ["Duration Modeling with Global Phoneme-Duration Vectors", ["Jinfu Ni", "Yoshinori Shiga", "Hisashi Kawai"], "https://doi.org/10.21437/Interspeech.2019-2126", 5, "interspeech", 2019]], "Rahul Aralikatte": [0, ["Adversarial Black-Box Attacks on Automatic Speech Recognition Systems Using Multi-Objective Evolutionary Optimization", ["Shreya Khare", "Rahul Aralikatte", "Senthil Mani"], "https://doi.org/10.21437/Interspeech.2019-2420", 5, "interspeech", 2019]], "Long Wu": [0.010015965672209859, ["Speaker-Invariant Feature-Mapping for Distant Speech Recognition via Adversarial Teacher-Student Learning", ["Long Wu", "Hangting Chen", "Li Wang", "Pengyuan Zhang", "Yonghong Yan"], "https://doi.org/10.21437/Interspeech.2019-2136", 5, "interspeech", 2019]], "Robert Rehr": [0, ["On Nonlinear Spatial Filtering in Multichannel Speech Enhancement", ["Kristina Tesch", "Robert Rehr", "Timo Gerkmann"], "https://doi.org/10.21437/Interspeech.2019-2751", 5, "interspeech", 2019]], "Katsuya Takanashi": [0, ["Turn-Taking Prediction Based on Detection of Transition Relevance Place", ["Kohei Hara", "Koji Inoue", "Katsuya Takanashi", "Tatsuya Kawahara"], "https://doi.org/10.21437/Interspeech.2019-1537", 5, "interspeech", 2019]], "Alessandra Cervone": [0, ["Active Annotation: Bootstrapping Annotation Lexicon and Guidelines for Supervised NLU Learning", ["Federico Marinelli", "Alessandra Cervone", "Giuliano Tortoreto", "Evgeny A. Stepanov", "Giuseppe Di Fabbrizio", "Giuseppe Riccardi"], "https://doi.org/10.21437/Interspeech.2019-2537", 5, "interspeech", 2019], ["Modeling User Context for Valence Prediction from Narratives", ["Aniruddha Tammewar", "Alessandra Cervone", "Eva-Maria Messner", "Giuseppe Riccardi"], "https://doi.org/10.21437/Interspeech.2019-2489", 5, "interspeech", 2019], ["Improving Speech Synthesis with Discourse Relations", ["Adele Aubin", "Alessandra Cervone", "Oliver Watts", "Simon King"], "https://doi.org/10.21437/Interspeech.2019-1945", 5, "interspeech", 2019]], "Julian J. McAuley": [0, ["Expediting TTS Synthesis with Adversarial Vocoding", ["Paarth Neekhara", "Chris Donahue", "Miller S. Puckette", "Shlomo Dubnov", "Julian J. McAuley"], "https://doi.org/10.21437/Interspeech.2019-3099", 5, "interspeech", 2019], ["Universal Adversarial Perturbations for Speech Recognition Systems", ["Paarth Neekhara", "Shehzeen Hussain", "Prakhar Pandey", "Shlomo Dubnov", "Julian J. McAuley", "Farinaz Koushanfar"], "https://doi.org/10.21437/Interspeech.2019-1353", 5, "interspeech", 2019]], "Axel Roebel": [0, ["Fully-Convolutional Network for Pitch Estimation of Speech Signals", ["Luc Ardaillon", "Axel Roebel"], "https://doi.org/10.21437/Interspeech.2019-2815", 5, "interspeech", 2019]], "Vishwanath P. Singh": [0, ["A Multi-Accent Acoustic Model Using Mixture of Experts for Speech Recognition", ["Abhinav Jain", "Vishwanath P. Singh", "Shakti P. Rath"], "https://doi.org/10.21437/Interspeech.2019-1667", 5, "interspeech", 2019]], "Mutian He": [0, ["Robust Sequence-to-Sequence Acoustic Modeling with Stepwise Monotonic Attention for Neural TTS", ["Mutian He", "Yan Deng", "Lei He"], "https://doi.org/10.21437/Interspeech.2019-1972", 5, "interspeech", 2019]], "Ann Lee": [0.010210888925939798, ["Sequence-to-Sequence Speech Recognition with Time-Depth Separable Convolutions", ["Awni Hannun", "Ann Lee", "Qiantong Xu", "Ronan Collobert"], "https://doi.org/10.21437/Interspeech.2019-2460", 5, "interspeech", 2019]], "Xugang Lu": [0, ["End-to-End Articulatory Attribute Modeling for Low-Resource Multilingual Speech Recognition", ["Sheng Li", "Chenchen Ding", "Xugang Lu", "Peng Shen", "Tatsuya Kawahara", "Hisashi Kawai"], "https://doi.org/10.21437/Interspeech.2019-2092", 5, "interspeech", 2019], ["Investigating Radical-Based End-to-End Speech Recognition Systems for Chinese Dialects and Japanese", ["Sheng Li", "Xugang Lu", "Chenchen Ding", "Peng Shen", "Tatsuya Kawahara", "Hisashi Kawai"], "https://doi.org/10.21437/Interspeech.2019-2104", 5, "interspeech", 2019], ["Incorporating Symbolic Sequential Modeling for Speech Enhancement", ["Chien-Feng Liao", "Yu Tsao", "Xugang Lu", "Hisashi Kawai"], "https://doi.org/10.21437/Interspeech.2019-1777", 5, "interspeech", 2019], ["Specialized Speech Enhancement Model Selection Based on Learned Non-Intrusive Quality Assessment Metric", ["Ryandhimas E. Zezario", "Szu-Wei Fu", "Xugang Lu", "Hsin-Min Wang", "Yu Tsao"], "https://doi.org/10.21437/Interspeech.2019-2425", 5, "interspeech", 2019], ["Class-Wise Centroid Distance Metric Learning for Acoustic Event Detection", ["Xugang Lu", "Peng Shen", "Sheng Li", "Yu Tsao", "Hisashi Kawai"], "https://doi.org/10.21437/Interspeech.2019-2271", 5, "interspeech", 2019], ["Improving Transformer-Based Speech Recognition Systems with Compressed Structure and Speech Attributes Augmentation", ["Sheng Li", "Dabre Raj", "Xugang Lu", "Peng Shen", "Tatsuya Kawahara", "Hisashi Kawai"], "https://doi.org/10.21437/Interspeech.2019-2112", 5, "interspeech", 2019]], "Amin Fazel": [0, ["Deep Multitask Acoustic Echo Cancellation", ["Amin Fazel", "Mostafa El-Khamy", "Jungwon Lee"], "https://doi.org/10.21437/Interspeech.2019-2908", 5, "interspeech", 2019]], "Jie Wu": [0.031336999498307705, ["Vocal Pitch Extraction in Polyphonic Music Using Convolutional Residual Network", ["Mingye Dong", "Jie Wu", "Jian Luan"], "https://doi.org/10.21437/Interspeech.2019-2286", 5, "interspeech", 2019]], "Deniece S. Nazareth": [0, ["An Acoustic and Lexical Analysis of Emotional Valence in Spontaneous Speech: Autobiographical Memory Recall in Older Adults", ["Deniece S. Nazareth", "Ellen Tournier", "Sarah Leimkotter", "Esther Janse", "Dirk Heylen", "Gerben J. Westerhof", "Khiet P. Truong"], "https://doi.org/10.21437/Interspeech.2019-1823", 5, "interspeech", 2019]], "Helmer Strik": [0, ["Deep Sensing of Breathing Signal During Conversational Speech", ["Venkata Srikanth Nallanthighal", "Aki Harma", "Helmer Strik"], "https://doi.org/10.21437/Interspeech.2019-1796", 5, "interspeech", 2019]], "Guillermo A. Cecchi": [0, ["A New Approach for Automating Analysis of Responses on Verbal Fluency Tests from Subjects At-Risk for Schizophrenia", ["Mary Pietrowicz", "Carla Agurto", "Raquel Norel", "Elif Eyigoz", "Guillermo A. Cecchi", "Zarina R. Bilgrami", "Cheryl Corcoran"], "https://doi.org/10.21437/Interspeech.2019-2987", 5, "interspeech", 2019]], "Laurianne Georgeton": [0, ["Are IP Initial Vowels Acoustically More Distinct? Results from LDA and CNN Classifications", ["Fanny Guitard-Ivent", "Gabriele Chignoli", "Cecile Fougeron", "Laurianne Georgeton"], "https://doi.org/10.21437/Interspeech.2019-2153", 5, "interspeech", 2019]], "Efthymios Tzinis": [0, ["Unsupervised Low-Rank Representations for Speech Emotion Recognition", ["Georgios Paraskevopoulos", "Efthymios Tzinis", "Nikolaos Ellinas", "Theodoros Giannakopoulos", "Alexandros Potamianos"], "https://doi.org/10.21437/Interspeech.2019-2769", 5, "interspeech", 2019]], "Angel M. Gomez": [0, ["Multi-Channel Block-Online Source Extraction Based on Utterance Adaptation", ["Juan M. Martin-Donas", "Jens Heitkaemper", "Reinhold Haeb-Umbach", "Angel M. Gomez", "Antonio M. Peinado"], "https://doi.org/10.21437/Interspeech.2019-2244", 5, "interspeech", 2019], ["A Light Convolutional GRU-RNN Deep Feature Extractor for ASV Spoofing Detection", ["Alejandro Gomez Alanis", "Antonio M. Peinado", "Jose A. Gonzalez", "Angel M. Gomez"], "https://doi.org/10.21437/Interspeech.2019-2212", 5, "interspeech", 2019]], "Christian Schallhart": [0, ["Unified Verbalization for Speech Recognition & Synthesis Across Languages", ["Sandy Ritchie", "Richard Sproat", "Kyle Gorman", "Daan van Esch", "Christian Schallhart", "Nikos Bampounis", "Benoit Brard", "Jonas Fromseier Mortensen", "Millie Holt", "Eoin Mahon"], "https://doi.org/10.21437/Interspeech.2019-2807", 5, "interspeech", 2019]], "Andrey Shulipa": [0, ["Speaker Diarization with Deep Speaker Embeddings for DIHARD Challenge II", ["Sergey Novoselov", "Aleksei Gusev", "Artem Ivanov", "Timur Pekhovsky", "Andrey Shulipa", "Anastasia Avdeeva", "Artem Gorlanov", "Alexandr Kozlov"], "https://doi.org/10.21437/Interspeech.2019-2757", 5, "interspeech", 2019], ["STC Speaker Recognition Systems for the VOiCES from a Distance Challenge", ["Sergey Novoselov", "Aleksei Gusev", "Artem Ivanov", "Timur Pekhovsky", "Andrey Shulipa", "Galina Lavrentyeva", "Vladimir Volokhov", "Alexandr Kozlov"], "https://doi.org/10.21437/Interspeech.2019-2783", 5, "interspeech", 2019], ["STC Speaker Recognition Systems for the VOiCES from a Distance Challenge", ["Sergey Novoselov", "Aleksei Gusev", "Artem Ivanov", "Timur Pekhovsky", "Andrey Shulipa", "Galina Lavrentyeva", "Vladimir Volokhov", "Alexandr Kozlov"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/abs15.html", 0, "interspeech", 2019]], "Jason D. Williams": [0, ["Active Learning for Domain Classification in a Commercial Spoken Personal Assistant", ["Xi C. Chen", "Adithya Sagar", "Justine T. Kao", "Tony Y. Li", "Christopher Klein", "Stephen Pulman", "Ashish Garg", "Jason D. Williams"], "https://doi.org/10.21437/Interspeech.2019-1315", 5, "interspeech", 2019]], "Yi Guo": [0, ["Towards the Speech Features of Early-Stage Dementia: Design and Application of the Mandarin Elderly Cognitive Speech Database", ["Tianqi Wang", "Quanlei Yan", "Jingshen Pan", "Feiqi Zhu", "Rongfeng Su", "Yi Guo", "Lan Wang", "Nan Yan"], "https://doi.org/10.21437/Interspeech.2019-2453", 5, "interspeech", 2019]], "Niranjan Subrahmanya": [0, ["Improving Keyword Spotting and Language Identification via Neural Architecture Search at Scale", ["Hanna Mazzawi", "Xavi Gonzalvo", "Aleks Kracun", "Prashant Sridhar", "Niranjan Subrahmanya", "Ignacio Lopez-Moreno", "Hyun-Jin Park", "Patrick Violette"], "https://doi.org/10.21437/Interspeech.2019-1916", 5, "interspeech", 2019]], "Wangyou Zhang": [0, ["Knowledge Distillation for End-to-End Monaural Multi-Talker ASR System", ["Wangyou Zhang", "Xuankai Chang", "Yanmin Qian"], "https://doi.org/10.21437/Interspeech.2019-3192", 5, "interspeech", 2019], ["Robust DOA Estimation Based on Convolutional Neural Network and Time-Frequency Masking", ["Wangyou Zhang", "Ying Zhou", "Yanmin Qian"], "https://doi.org/10.21437/Interspeech.2019-3158", 5, "interspeech", 2019]], "Christina Tannander": [0, ["Spot the Pleasant People! Navigating the Cocktail Party Buzz", ["Christina Tannander", "Per Fallgren", "Jens Edlund", "Joakim Gusafsson"], "https://doi.org/10.21437/Interspeech.2019-1553", 5, "interspeech", 2019]], "Eva-Maria Messner": [0, ["Using Speech to Predict Sequentially Measured Cortisol Levels During a Trier Social Stress Test", ["Alice Baird", "Shahin Amiriparian", "Nicholas Cummins", "Sarah Sturmbauer", "Johanna Janson", "Eva-Maria Messner", "Harald Baumeister", "Nicolas Rohleder", "Bjorn W. Schuller"], "https://doi.org/10.21437/Interspeech.2019-1352", 5, "interspeech", 2019], ["Modeling User Context for Valence Prediction from Narratives", ["Aniruddha Tammewar", "Alessandra Cervone", "Eva-Maria Messner", "Giuseppe Riccardi"], "https://doi.org/10.21437/Interspeech.2019-2489", 5, "interspeech", 2019]], "Ali Etemad": [0, ["A Deep Neural Network for Short-Segment Speaker Recognition", ["Amirhossein Hajavi", "Ali Etemad"], "https://doi.org/10.21437/Interspeech.2019-2240", 5, "interspeech", 2019]], "Huibin Lin": [0, ["Deep Attention Gated Dilated Temporal Convolutional Networks with Intra-Parallel Convolutional Modules for End-to-End Monaural Speech Separation", ["Ziqiang Shi", "Huibin Lin", "Liu Liu", "Rujie Liu", "Jiqing Han", "Anyan Shi"], "https://doi.org/10.21437/Interspeech.2019-1373", 5, "interspeech", 2019], ["End-to-End Monaural Speech Separation with Multi-Scale Dynamic Weighted Gated Dilated Convolutional Pyramid Network", ["Ziqiang Shi", "Huibin Lin", "Liu Liu", "Rujie Liu", "Shoji Hayakawa", "Shouji Harada", "Jiqing Han"], "https://doi.org/10.21437/Interspeech.2019-1292", 5, "interspeech", 2019]], "Nisad Jamakovic": [0, ["The Monophthongs of Formal Nigerian English: An Acoustic Analysis", ["Nisad Jamakovic", "Robert Fuchs"], "https://doi.org/10.21437/Interspeech.2019-2866", 5, "interspeech", 2019]], "Amos Treiber": [0, ["Privacy-Preserving Speaker Recognition with Cohort Score Normalisation", ["Andreas Nautsch", "Jose Patino", "Amos Treiber", "Themos Stafylakis", "Petr Mizera", "Massimiliano Todisco", "Thomas Schneider", "Nicholas W. D. Evans"], "https://doi.org/10.21437/Interspeech.2019-2638", 5, "interspeech", 2019]], "Yusuke Shinohara": [0, ["Neural Whispered Speech Detection with Imbalanced Learning", ["Takanori Ashihara", "Yusuke Shinohara", "Hiroshi Sato", "Takafumi Moriya", "Kiyoaki Matsui", "Takaaki Fukutomi", "Yoshikazu Yamaguchi", "Yushi Aono"], "https://doi.org/10.21437/Interspeech.2019-2161", 5, "interspeech", 2019], ["Joint Maximization Decoder with Neural Converters for Fully Neural Network-Based Japanese Speech Recognition", ["Takafumi Moriya", "Jian Wang", "Tomohiro Tanaka", "Ryo Masumura", "Yusuke Shinohara", "Yoshikazu Yamaguchi", "Yushi Aono"], "https://doi.org/10.21437/Interspeech.2019-1558", 5, "interspeech", 2019]], "Adria Gimenez": [0, ["Real-Time One-Pass Decoder for Speech Recognition Using LSTM Language Models", ["Javier Jorge", "Adria Gimenez", "Javier Iranzo-Sanchez", "Jorge Civera", "Albert Sanchis", "Alfons Juan"], "https://doi.org/10.21437/Interspeech.2019-2798", 5, "interspeech", 2019]], "Dimitrios Dimitriadis": [0, ["Meeting Transcription Using Asynchronous Distant Microphones", ["Takuya Yoshioka", "Dimitrios Dimitriadis", "Andreas Stolcke", "William Hinthorn", "Zhuo Chen", "Michael Zeng", "Xuedong Huang"], "https://doi.org/10.21437/Interspeech.2019-3088", 5, "interspeech", 2019]], "Di Jiang": [0, ["Topic-Aware Dialogue Speech Recognition with Transfer Learning", ["Yuanfeng Song", "Di Jiang", "Xueyang Wu", "Qian Xu", "Raymond Chi-Wing Wong", "Qiang Yang"], "https://doi.org/10.21437/Interspeech.2019-1694", 5, "interspeech", 2019]], "Carol Chermaz": [0, ["Evaluating Near End Listening Enhancement Algorithms in Realistic Environments", ["Carol Chermaz", "Cassia Valentini-Botinhao", "Henning F. Schepker", "Simon King"], "https://doi.org/10.21437/Interspeech.2019-1800", 5, "interspeech", 2019]], "Juraj Simko": [0, ["Prosodic Representations of Prominence Classification Neural Networks and Autoencoders Using Bottleneck Features", ["Sofoklis Kakouros", "Antti Suni", "Juraj Simko", "Martti Vainio"], "https://doi.org/10.21437/Interspeech.2019-2984", 5, "interspeech", 2019], ["Comparative Analysis of Prosodic Characteristics Using WaveNet Embeddings", ["Antti Suni", "Marcin Wlodarczak", "Martti Vainio", "Juraj Simko"], "https://doi.org/10.21437/Interspeech.2019-2373", 5, "interspeech", 2019]], "Ariya Rastrow": [0, ["Neural Machine Translation for Multilingual Grapheme-to-Phoneme Conversion", ["Alex Sokolov", "Tracy Rohlin", "Ariya Rastrow"], "https://doi.org/10.21437/Interspeech.2019-3176", 5, "interspeech", 2019], ["Scalable Multi Corpora Neural Language Models for ASR", ["Anirudh Raju", "Denis Filimonov", "Gautam Tiwari", "Guitang Lan", "Ariya Rastrow"], "https://doi.org/10.21437/Interspeech.2019-3060", 5, "interspeech", 2019]], "Noe Tits": [0, ["Visualization and Interpretation of Latent Spaces for Controlling Expressive Speech Synthesis Through Audio Analysis", ["Noe Tits", "Fengna Wang", "Kevin El Haddad", "Vincent Pagel", "Thierry Dutoit"], "https://doi.org/10.21437/Interspeech.2019-1426", 5, "interspeech", 2019]], "Younggwan Kim": [0.9961809366941452, ["Spatial Pyramid Encoding with Convex Length Normalization for Text-Independent Speaker Verification", ["Youngmoon Jung", "Younggwan Kim", "Hyungjun Lim", "Yeunju Choi", "Hoirin Kim"], "https://doi.org/10.21437/Interspeech.2019-2177", 5, "interspeech", 2019]], "Ian Vince McLoughlin": [0, ["A Robust Framework for Acoustic Scene Classification", ["Lam Dang Pham", "Ian Vince McLoughlin", "Huy Phan", "Ramaswamy Palaniappan"], "https://doi.org/10.21437/Interspeech.2019-1841", 5, "interspeech", 2019], ["GFM-Voc: A Real-Time Voice Quality Modification System", ["Olivier Perrotin", "Ian Vince McLoughlin"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8018.html", 2, "interspeech", 2019], ["Spatio-Temporal Attention Pooling for Audio Scene Classification", ["Huy Phan", "Oliver Y. Chen", "Lam Pham", "Philipp Koch", "Maarten De Vos", "Ian Vince McLoughlin", "Alfred Mertins"], "https://doi.org/10.21437/Interspeech.2019-3040", 5, "interspeech", 2019]], "Shashidhar G. Koolagudi": [0, ["NITK Kids' Speech Corpus", ["Pravin Bhaskar Ramteke", "Sujata Supanekar", "Pradyoth Hegde", "Hanna Nelson", "Venkataraja Aithal", "Shashidhar G. Koolagudi"], "https://doi.org/10.21437/Interspeech.2019-2061", 5, "interspeech", 2019], ["Locality-Constrained Linear Coding Based Fused Visual Features for Robust Acoustic Event Classification", ["Manjunath Mulimani", "Shashidhar G. Koolagudi"], "https://doi.org/10.21437/Interspeech.2019-1421", 5, "interspeech", 2019]], "Xiang Hao": [0, ["UNetGAN: A Robust Speech Enhancement Approach in Time Domain for Extremely Low Signal-to-Noise Ratio Condition", ["Xiang Hao", "Xiangdong Su", "Zhiyu Wang", "Hui Zhang", "Batushiren"], "https://doi.org/10.21437/Interspeech.2019-1567", 5, "interspeech", 2019]], "Joe Antognini": [0, ["WHAM!: Extending Speech Separation to Noisy Environments", ["Gordon Wichern", "Joe Antognini", "Michael Flynn", "Licheng Richard Zhu", "Emmett McQuinn", "Dwight Crow", "Ethan Manilow", "Jonathan Le Roux"], "https://doi.org/10.21437/Interspeech.2019-2821", 5, "interspeech", 2019]], "Pierre-Andre Vuissoz": [0, ["Towards a Method of Dynamic Vocal Tract Shapes Generation by Combining Static 3D and Dynamic 2D MRI Speech Data", ["Ioannis K. Douros", "Anastasiia Tsukanova", "Karyna Isaieva", "Pierre-Andre Vuissoz", "Yves Laprie"], "https://doi.org/10.21437/Interspeech.2019-2880", 5, "interspeech", 2019], ["A Multimodal Real-Time MRI Articulatory Corpus of French for Speech Research", ["Ioannis K. Douros", "Jacques Felblinger", "Jens Frahm", "Karyna Isaieva", "Arun A. Joseph", "Yves Laprie", "Freddy Odille", "Anastasiia Tsukanova", "Dirk Voit", "Pierre-Andre Vuissoz"], "https://doi.org/10.21437/Interspeech.2019-1700", 5, "interspeech", 2019]], "Tekla Etelka Graczi": [0, ["V-to-V Coarticulation Induced Acoustic and Articulatory Variability of Vowels: The Effect of Pitch-Accent", ["Andrea Deme", "Marton Bartok", "Tekla Etelka Graczi", "Tamas Gabor Csapo", "Alexandra Marko"], "https://doi.org/10.21437/Interspeech.2019-2890", 5, "interspeech", 2019], ["Articulatory Analysis of Transparent Vowel /i\u02d0/ in Harmonic and Antiharmonic Hungarian Stems: Is There a Difference?", ["Alexandra Marko", "Marton Bartok", "Tamas Gabor Csapo", "Tekla Etelka Graczi", "Andrea Deme"], "https://doi.org/10.21437/Interspeech.2019-2352", 5, "interspeech", 2019]], "Shlomo Dubnov": [0, ["Expediting TTS Synthesis with Adversarial Vocoding", ["Paarth Neekhara", "Chris Donahue", "Miller S. Puckette", "Shlomo Dubnov", "Julian J. McAuley"], "https://doi.org/10.21437/Interspeech.2019-3099", 5, "interspeech", 2019], ["Universal Adversarial Perturbations for Speech Recognition Systems", ["Paarth Neekhara", "Shehzeen Hussain", "Prakhar Pandey", "Shlomo Dubnov", "Julian J. McAuley", "Farinaz Koushanfar"], "https://doi.org/10.21437/Interspeech.2019-1353", 5, "interspeech", 2019]], "Maria Teresa Riviello": [0, ["The Dependability of Voice on Elders' Acceptance of Humanoid Agents", ["Anna Esposito", "Terry Amorese", "Marialucia Cuciniello", "Maria Teresa Riviello", "Antonietta Maria Esposito", "Alda Troncone", "Gennaro Cordasco"], "https://doi.org/10.21437/Interspeech.2019-1734", 5, "interspeech", 2019]], "Sabine Stoll": [0, ["Fundamental Frequency Accommodation in Multi-Party Human-Robot Game Interactions: The Effect of Winning or Losing", ["Omnia Ibrahim", "Gabriel Skantze", "Sabine Stoll", "Volker Dellwo"], "https://doi.org/10.21437/Interspeech.2019-2496", 5, "interspeech", 2019]], "Anders Eriksson": [0, ["Quantifying Fundamental Frequency Modulation as a Function of Language, Speaking Style and Speaker", ["Pablo Arantes", "Anders Eriksson"], "https://doi.org/10.21437/Interspeech.2019-2857", 5, "interspeech", 2019]], "Jian Luan": [0, ["Vocal Pitch Extraction in Polyphonic Music Using Convolutional Residual Network", ["Mingye Dong", "Jie Wu", "Jian Luan"], "https://doi.org/10.21437/Interspeech.2019-2286", 5, "interspeech", 2019]], "Partha Pratim Das": [0, ["Glottal Closure Instants Detection from Speech Signal by Deep Features Extracted from Raw Speech and Linear Prediction Residual", ["Gurunath Reddy M.", "K. Sreenivasa Rao", "Partha Pratim Das"], "https://doi.org/10.21437/Interspeech.2019-1981", 5, "interspeech", 2019]], "Amber Afshan": [0, ["Voice Quality and Between-Frame Entropy for Sleepiness Estimation", ["Vijay Ravi", "Soo Jin Park", "Amber Afshan", "Abeer Alwan"], "https://doi.org/10.21437/Interspeech.2019-2988", 5, "interspeech", 2019]], "Satoshi Kobashikawa": [0, ["Improving Conversation-Context Language Models with Multiple Spoken Language Understanding Models", ["Ryo Masumura", "Tomohiro Tanaka", "Atsushi Ando", "Hosana Kamiyama", "Takanobu Oba", "Satoshi Kobashikawa", "Yushi Aono"], "https://doi.org/10.21437/Interspeech.2019-1534", 5, "interspeech", 2019], ["Speech Emotion Recognition Based on Multi-Label Emotion Existence Model", ["Atsushi Ando", "Ryo Masumura", "Hosana Kamiyama", "Satoshi Kobashikawa", "Yushi Aono"], "https://doi.org/10.21437/Interspeech.2019-2524", 5, "interspeech", 2019], ["Does the Lombard Effect Improve Emotional Communication in Noise? - Analysis of Emotional Speech Acted in Noise", ["Yi Zhao", "Atsushi Ando", "Shinji Takaki", "Junichi Yamagishi", "Satoshi Kobashikawa"], "https://doi.org/10.21437/Interspeech.2019-1605", 5, "interspeech", 2019]], "Wei Xiang Lieow": [0, ["Meta Learning for Hyperparameter Optimization in Dialogue System", ["Jen-Tzung Chien", "Wei Xiang Lieow"], "https://doi.org/10.21437/Interspeech.2019-1383", 5, "interspeech", 2019]], "Nobuyuki Nishizawa": [0, ["Training Multi-Speaker Neural Text-to-Speech Systems Using Speaker-Imbalanced Speech Corpora", ["Hieu-Thi Luong", "Xin Wang", "Junichi Yamagishi", "Nobuyuki Nishizawa"], "https://doi.org/10.21437/Interspeech.2019-1311", 5, "interspeech", 2019]], "Sunghye Cho": [0.9963593035936356, ["Automatic Detection of Autism Spectrum Disorder in Children Using Acoustic and Text Features from Brief Natural Conversations", ["Sunghye Cho", "Mark Liberman", "Neville Ryant", "Meredith Cola", "Robert T. Schultz", "Julia Parish-Morris"], "https://doi.org/10.21437/Interspeech.2019-1452", 5, "interspeech", 2019], ["Automatic Detection of Prosodic Focus in American English", ["Sunghye Cho", "Mark Liberman", "Yong-cheol Lee"], "https://doi.org/10.21437/Interspeech.2019-1668", 5, "interspeech", 2019]], "Camille Noufi": [0, ["Vocal Biomarker Assessment Following Pediatric Traumatic Brain Injury: A Retrospective Cohort Study", ["Camille Noufi", "Adam C. Lammert", "Daryush D. Mehta", "James R. Williamson", "Gregory Ciccarelli", "Douglas E. Sturim", "Jordan R. Green", "Thomas F. Campbell", "Thomas F. Quatieri"], "https://doi.org/10.21437/Interspeech.2019-1200", 5, "interspeech", 2019]], "Nobukatsu Hojo": [0, ["StarGAN-VC2: Rethinking Conditional Methods for StarGAN-Based Voice Conversion", ["Takuhiro Kaneko", "Hirokazu Kameoka", "Kou Tanaka", "Nobukatsu Hojo"], "https://doi.org/10.21437/Interspeech.2019-2236", 5, "interspeech", 2019], ["Evaluating Intention Communication by TTS Using Explicit Definitions of Illocutionary Act Performance", ["Nobukatsu Hojo", "Noboru Miyazaki"], "https://doi.org/10.21437/Interspeech.2019-2188", 5, "interspeech", 2019]], "Linlin Wang": [1.1947428902203683e-05, ["Impact of ASR Performance on Spoken Grammatical Error Detection", ["Yiting Lu", "Mark J. F. Gales", "Kate M. Knill", "P. P. Manakul", "Linlin Wang", "Y. Wang"], "https://doi.org/10.21437/Interspeech.2019-1706", 5, "interspeech", 2019]], "Piotr Szymanski": [0, ["Avaya Conversational Intelligence: A Real-Time System for Spoken Language Understanding in Human-Human Call Center Conversations", ["Jan Mizgajski", "Adrian Szymczak", "Robert Glowski", "Piotr Szymanski", "Piotr Zelasko", "Lukasz Augustyniak", "Mikolaj Morzy", "Yishay Carmiel", "Jeff Hodson", "Lukasz Wojciak", "Daniel Smoczyk", "Adam Wrobel", "Bartosz Borowik", "Adam Artajew", "Marcin Baran", "Cezary Kwiatkowski", "Marzena Zyla-Hoppe"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8002.html", 2, "interspeech", 2019]], "Adriana Stan": [0, ["All Together Now: The Living Audio Dataset", ["David A. Braude", "Matthew P. Aylett", "Caoimhin Laoide-Kemp", "Simone Ashby", "Kristen M. Scott", "Brian O Raghallaigh", "Anna Braudo", "Alex Brouwer", "Adriana Stan"], "https://doi.org/10.21437/Interspeech.2019-2448", 5, "interspeech", 2019]], "Toshiyuki Kumakura": [0, ["End-to-End Adaptation with Backpropagation Through WFST for On-Device Speech Recognition System", ["Emiru Tsunoo", "Yosuke Kashiwagi", "Satoshi Asakawa", "Toshiyuki Kumakura"], "https://doi.org/10.21437/Interspeech.2019-1880", 5, "interspeech", 2019]], "Yixin Gao": [0, ["Sub-Band Convolutional Neural Networks for Small-Footprint Spoken Term Classification", ["Chieh-Chi Kao", "Ming Sun", "Yixin Gao", "Shiv Vitaladevuni", "Chao Wang"], "https://doi.org/10.21437/Interspeech.2019-1766", 5, "interspeech", 2019]], "Prasanta Kumar Ghosh": [0, ["An Investigation on Speaker Specific Articulatory Synthesis with Speaker Independent Articulatory Inversion", ["Aravind Illa", "Prasanta Kumar Ghosh"], "https://doi.org/10.21437/Interspeech.2019-2664", 5, "interspeech", 2019], ["ASR Inspired Syllable Stress Detection for Pronunciation Evaluation Without Using a Supervised Classifier and Syllable Level Features", ["Manoj Kumar Ramanathi", "Chiranjeevi Yarra", "Prasanta Kumar Ghosh"], "https://doi.org/10.21437/Interspeech.2019-2091", 5, "interspeech", 2019], ["Acoustic and Articulatory Feature Based Speech Rate Estimation Using a Convolutional Dense Neural Network", ["Renuka Mannem", "Jhansi Mallela", "Aravind Illa", "Prasanta Kumar Ghosh"], "https://doi.org/10.21437/Interspeech.2019-2295", 5, "interspeech", 2019], ["An Improved Goodness of Pronunciation (GoP) Measure for Pronunciation Evaluation with DNN-HMM System Considering HMM Transition Probabilities", ["Sweekar Sudhakara", "Manoj Kumar Ramanathi", "Chiranjeevi Yarra", "Prasanta Kumar Ghosh"], "https://doi.org/10.21437/Interspeech.2019-2363", 5, "interspeech", 2019], ["Low Resource Automatic Intonation Classification Using Gated Recurrent Unit (GRU) Networks Pre-Trained with Synthesized Pitch Patterns", ["Atreyee Saha", "Chiranjeevi Yarra", "Prasanta Kumar Ghosh"], "https://doi.org/10.21437/Interspeech.2019-2351", 5, "interspeech", 2019], ["SPIRE-fluent: A Self-Learning App for Tutoring Oral Fluency to Second Language English Learners", ["Chiranjeevi Yarra", "Aparna Srinivasan", "Sravani Gottimukkala", "Prasanta Kumar Ghosh"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8008.html", 2, "interspeech", 2019], ["Whisper to Neutral Mapping Using Cosine Similarity Maximization in i-Vector Space for Speaker Verification", ["Abinay Reddy Naini", "Achuth Rao M. V", "Prasanta Kumar Ghosh"], "https://doi.org/10.21437/Interspeech.2019-2280", 5, "interspeech", 2019], ["Comparison of Speech Tasks and Recording Devices for Voice Based Automatic Classification of Healthy Subjects and Patients with Amyotrophic Lateral Sclerosis", ["Suhas B. N.", "Deep Patel", "Nithin Rao Koluguri", "Yamini Belur", "Pradeep Reddy", "Atchayaram Nalini", "Ravi Yadav", "Dipanjan Gope", "Prasanta Kumar Ghosh"], "https://doi.org/10.21437/Interspeech.2019-1285", 5, "interspeech", 2019]], "Steffen Illium": [0, ["Deep Neural Baselines for Computational Paralinguistics", ["Daniel Elsner", "Stefan Langer", "Fabian Ritz", "Robert Muller", "Steffen Illium"], "https://doi.org/10.21437/Interspeech.2019-2478", 5, "interspeech", 2019]], "Javier Latorre": [0, ["Towards Achieving Robust Universal Neural Vocoding", ["Jaime Lorenzo-Trueba", "Thomas Drugman", "Javier Latorre", "Thomas Merritt", "Bartosz Putrycz", "Roberto Barra-Chicote", "Alexis Moinet", "Vatsal Aggarwal"], "https://doi.org/10.21437/Interspeech.2019-1424", 5, "interspeech", 2019]], "Eduard Golshtein": [0, ["GECKO - A Tool for Effective Annotation of Human Conversations", ["Golan Levy", "Raquel Sitman", "Ido Amir", "Eduard Golshtein", "Ran Mochary", "Eilon Reshef", "Roi Reichart", "Omri Allouche"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8025.html", 2, "interspeech", 2019]], "Michal Kosmider": [0, ["Robust Bayesian and Light Neural Networks for Voice Spoofing Detection", ["Radoslaw Bialobrzeski", "Michal Kosmider", "Mateusz Matuszewski", "Marcin Plata", "Alexander Rakowski"], "https://doi.org/10.21437/Interspeech.2019-2676", 5, "interspeech", 2019]], "Ilya Oparin": [0, ["Connecting and Comparing Language Model Interpolation Techniques", ["Ernest Pusateri", "Christophe Van Gysel", "Rami Botros", "Sameer Badaskar", "Mirko Hannemann", "Youssef Oualil", "Ilya Oparin"], "https://doi.org/10.21437/Interspeech.2019-1822", 5, "interspeech", 2019]], "Mingyue Niu": [0, ["Automatic Depression Level Detection via \u2113p-Norm Pooling", ["Mingyue Niu", "Jianhua Tao", "Bin Liu", "Cunhang Fan"], "https://doi.org/10.21437/Interspeech.2019-1617", 5, "interspeech", 2019]], "Jianfeng Zhou": [0, ["Deep Speaker Embedding Extraction with Channel-Wise Feature Responses and Additive Supervision Softmax Loss Function", ["Jianfeng Zhou", "Tao Jiang", "Zheng Li", "Lin Li", "Qingyang Hong"], "https://doi.org/10.21437/Interspeech.2019-1704", 5, "interspeech", 2019]], "Pavel A. Skrelin": [0, ["Prosodic Factors Influencing Vowel Reduction in Russian", ["Daniil Kocharov", "Tatiana Kachkovskaia", "Pavel A. Skrelin"], "https://doi.org/10.21437/Interspeech.2019-2918", 5, "interspeech", 2019]], "Dinesh Manocha": [0, ["Regression and Classification for Direction-of-Arrival Estimation with Convolutional Recurrent Neural Networks", ["Zhenyu Tang", "John D. Kanu", "Kevin Hogan", "Dinesh Manocha"], "https://doi.org/10.21437/Interspeech.2019-1111", 5, "interspeech", 2019]], "Ruth Aloni-Lavi": [0, ["Identifying Distinctive Acoustic and Spectral Features in Parkinson's Disease", ["Yermiyahu Hauptman", "Ruth Aloni-Lavi", "Itshak Lapidot", "Tanya Gurevich", "Yael Manor", "Stav Naor", "Noa Diamant", "Irit Opher"], "https://doi.org/10.21437/Interspeech.2019-2465", 5, "interspeech", 2019]], "Tatiana Prisyach": [0, ["R-Vectors: New Technique for Adaptation to Room Acoustics", ["Yuri Y. Khokhlov", "Alexander Zatvornitskiy", "Ivan Medennikov", "Ivan Sorokin", "Tatiana Prisyach", "Aleksei Romanenko", "Anton Mitrofanov", "Vladimir Bataev", "Andrei Andrusenko", "Mariya Korenevskaya", "Oleg Petrov"], "https://doi.org/10.21437/Interspeech.2019-2645", 5, "interspeech", 2019], ["The STC ASR System for the VOiCES from a Distance Challenge 2019", ["Ivan Medennikov", "Yuri Y. Khokhlov", "Aleksei Romanenko", "Ivan Sorokin", "Anton Mitrofanov", "Vladimir Bataev", "Andrei Andrusenko", "Tatiana Prisyach", "Mariya Korenevskaya", "Oleg Petrov", "Alexander Zatvornitskiy"], "https://doi.org/10.21437/Interspeech.2019-1574", 5, "interspeech", 2019], ["The STC ASR System for the VOiCES from a Distance Challenge 2019", ["Ivan Medennikov", "Yuri Y. Khokhlov", "Aleksei Romanenko", "Ivan Sorokin", "Anton Mitrofanov", "Vladimir Bataev", "Andrei Andrusenko", "Tatiana Prisyach", "Mariya Korenevskaya", "Oleg Petrov", "Alexander Zatvornitskiy"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/abs17.html", 0, "interspeech", 2019]], "Horia Cucu": [0, ["Kite: Automatic Speech Recognition for Unmanned Aerial Vehicles", ["Dan Oneata", "Horia Cucu"], "https://doi.org/10.21437/Interspeech.2019-1390", 5, "interspeech", 2019]], "Franz Pernkopf": [0, ["Acoustic Scene Classification with Mismatched Devices Using CliqueNets and Mixup Data Augmentation", ["Truc Nguyen", "Franz Pernkopf"], "https://doi.org/10.21437/Interspeech.2019-3002", 5, "interspeech", 2019]], "Efthymios Georgiou": [0, ["Deep Hierarchical Fusion with Application in Sentiment Analysis", ["Efthymios Georgiou", "Charilaos Papaioannou", "Alexandros Potamianos"], "https://doi.org/10.21437/Interspeech.2019-3243", 5, "interspeech", 2019]], "Rejisha T. M.": [0, ["Design and Development of a Multi-Lingual Speech Corpora (TaMaR-EmoDB) for Emotion Analysis", ["Rajeev Rajan", "Haritha U. G.", "Sujitha A. C.", "Rejisha T. M."], "https://doi.org/10.21437/Interspeech.2019-2034", 5, "interspeech", 2019]], "Atchayaram Nalini": [0, ["Comparison of Speech Tasks and Recording Devices for Voice Based Automatic Classification of Healthy Subjects and Patients with Amyotrophic Lateral Sclerosis", ["Suhas B. N.", "Deep Patel", "Nithin Rao Koluguri", "Yamini Belur", "Pradeep Reddy", "Atchayaram Nalini", "Ravi Yadav", "Dipanjan Gope", "Prasanta Kumar Ghosh"], "https://doi.org/10.21437/Interspeech.2019-1285", 5, "interspeech", 2019]], "Justin Tabrizi": [0, ["Speech-Based Web Navigation for Limited Mobility Users", ["Vasiliy Radostev", "Serge Berger", "Justin Tabrizi", "Pasha Kamyshev", "Hisami Suzuki"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8042.html", 2, "interspeech", 2019]], "Takuya Yoshioka": [0, ["Meeting Transcription Using Asynchronous Distant Microphones", ["Takuya Yoshioka", "Dimitrios Dimitriadis", "Andreas Stolcke", "William Hinthorn", "Zhuo Chen", "Michael Zeng", "Xuedong Huang"], "https://doi.org/10.21437/Interspeech.2019-3088", 5, "interspeech", 2019]], "Aleksei Gusev": [0, ["Speaker Diarization with Deep Speaker Embeddings for DIHARD Challenge II", ["Sergey Novoselov", "Aleksei Gusev", "Artem Ivanov", "Timur Pekhovsky", "Andrey Shulipa", "Anastasia Avdeeva", "Artem Gorlanov", "Alexandr Kozlov"], "https://doi.org/10.21437/Interspeech.2019-2757", 5, "interspeech", 2019], ["STC Speaker Recognition Systems for the VOiCES from a Distance Challenge", ["Sergey Novoselov", "Aleksei Gusev", "Artem Ivanov", "Timur Pekhovsky", "Andrey Shulipa", "Galina Lavrentyeva", "Vladimir Volokhov", "Alexandr Kozlov"], "https://doi.org/10.21437/Interspeech.2019-2783", 5, "interspeech", 2019], ["STC Speaker Recognition Systems for the VOiCES from a Distance Challenge", ["Sergey Novoselov", "Aleksei Gusev", "Artem Ivanov", "Timur Pekhovsky", "Andrey Shulipa", "Galina Lavrentyeva", "Vladimir Volokhov", "Alexandr Kozlov"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/abs15.html", 0, "interspeech", 2019]], "Charles Costello": [0, ["Optimizing Voice Activity Detection for Noisy Conditions", ["Ruixi Lin", "Charles Costello", "Charles Jankowski", "Vishwas Mruthyunjaya"], "https://doi.org/10.21437/Interspeech.2019-1776", 5, "interspeech", 2019]], "Anita Dromey": [0, ["Listeners' Ability to Identify the Gender of Preadolescent Children in Different Linguistic Contexts", ["Shawn L. Nissen", "Sharalee Blunck", "Anita Dromey", "Christopher Dromey"], "https://doi.org/10.21437/Interspeech.2019-1865", 5, "interspeech", 2019]], "Shan Huang": [0, ["Multimedia Simultaneous Translation System for Minority Language Communication with Mandarin", ["Shen Huang", "Bojie Hu", "Shan Huang", "Pengfei Hu", "Jian Kang", "Zhiqiang Lv", "Jinghao Yan", "Qi Ju", "Shiyin Kang", "Deyi Tuo", "Guangzhi Li", "Nurmemet Yolwas"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8020.html", 2, "interspeech", 2019]], "Daniel T. Braithwaite": [0, ["Speech Enhancement with Variance Constrained Autoencoders", ["Daniel T. Braithwaite", "W. Bastiaan Kleijn"], "https://doi.org/10.21437/Interspeech.2019-1809", 5, "interspeech", 2019]], "Leyuan Qu": [0, ["LipSound: Neural Mel-Spectrogram Reconstruction for Lip Reading", ["Leyuan Qu", "Cornelius Weber", "Stefan Wermter"], "https://doi.org/10.21437/Interspeech.2019-1393", 5, "interspeech", 2019]], "Inma Hernaez": [0, ["Parallel vs. Non-Parallel Voice Conversion for Esophageal Speech", ["Luis Serrano", "Sneha Raman", "David Tavarez", "Eva Navas", "Inma Hernaez"], "https://doi.org/10.21437/Interspeech.2019-2194", 5, "interspeech", 2019]], "Lori Lamel": [0, ["\" Gra[f] e!\" Word-Final Devoicing of Obstruents in Standard French: An Acoustic Study Based on Large Corpora", ["Adele Jatteau", "Ioana Vasilescu", "Lori Lamel", "Martine Adda-Decker", "Nicolas Audibert"], "https://doi.org/10.21437/Interspeech.2019-2329", 5, "interspeech", 2019]], "Ahmed Mustafa": [0, ["Analysis by Adversarial Synthesis - A Novel Approach for Speech Vocoding", ["Ahmed Mustafa", "Arijit Biswas", "Christian Bergler", "Julia Schottenhamml", "Andreas K. Maier"], "https://doi.org/10.21437/Interspeech.2019-1195", 5, "interspeech", 2019]], "Sung-Lin Yeh": [0, ["Using Attention Networks and Adversarial Augmentation for Styrian Dialect Continuous Sleepiness and Baby Sound Recognition", ["Sung-Lin Yeh", "Gao-Yi Chao", "Bo-Hao Su", "Yu-Lin Huang", "Meng-Han Lin", "Yin-Chun Tsai", "Yu-Wen Tai", "Zheng-Chi Lu", "Chieh-Yu Chen", "Tsung-Ming Tai", "Chiu-Wang Tseng", "Cheng-Kuang Lee", "Chi-Chun Lee"], "https://doi.org/10.21437/Interspeech.2019-2110", 5, "interspeech", 2019]], "Mathieu Bernard": [0, ["The Zero Resource Speech Challenge 2019: TTS Without T", ["Ewan Dunbar", "Robin Algayres", "Julien Karadayi", "Mathieu Bernard", "Juan Benjumea", "Xuan-Nga Cao", "Lucie Miskic", "Charlotte Dugrain", "Lucas Ondel", "Alan W. Black", "Laurent Besacier", "Sakriani Sakti", "Emmanuel Dupoux"], "https://doi.org/10.21437/Interspeech.2019-2904", 5, "interspeech", 2019]], "Ina Kodrasi": [0, ["Spectral Subspace Analysis for Automatic Assessment of Pathological Speech Intelligibility", ["Parvaneh Janbakhshi", "Ina Kodrasi", "Herve Bourlard"], "https://doi.org/10.21437/Interspeech.2019-2791", 5, "interspeech", 2019]], "Sayaka Hamanaka": [0, ["Speech Organ Contour Extraction Using Real-Time MRI and Machine Learning Method", ["Hironori Takemoto", "Tsubasa Goto", "Yuya Hagihara", "Sayaka Hamanaka", "Tatsuya Kitamura", "Yukiko Nota", "Kikuo Maekawa"], "https://doi.org/10.21437/Interspeech.2019-1593", 5, "interspeech", 2019]], "Jiande Ding": [0, ["Latent Topic Attention for Domain Classification", ["Peisong Huang", "Peijie Huang", "Wencheng Ai", "Jiande Ding", "Jinchuan Zhang"], "https://doi.org/10.21437/Interspeech.2019-2228", 5, "interspeech", 2019]], "Eliathamby Ambikairajah": [0, ["Speech Based Emotion Prediction: Can a Linear Model Work?", ["Anda Ouyang", "Ting Dang", "Vidhyasaharan Sethu", "Eliathamby Ambikairajah"], "https://doi.org/10.21437/Interspeech.2019-3149", 5, "interspeech", 2019], ["An Adaptive-Q Cochlear Model for Replay Spoofing Detection", ["Tharshini Gunendradasan", "Eliathamby Ambikairajah", "Julien Epps", "Haizhou Li"], "https://doi.org/10.21437/Interspeech.2019-2361", 5, "interspeech", 2019], ["Biologically Inspired Adaptive-Q Filterbanks for Replay Spoofing Attack Detection", ["Buddhi Wickramasinghe", "Eliathamby Ambikairajah", "Julien Epps"], "https://doi.org/10.21437/Interspeech.2019-1535", 5, "interspeech", 2019]], "Stefan Wermter": [0, ["Predictive Auxiliary Variational Autoencoder for Representation Learning of Global Speech Characteristics", ["Sebastian Springenberg", "Egor Lakomkin", "Cornelius Weber", "Stefan Wermter"], "https://doi.org/10.21437/Interspeech.2019-2845", 5, "interspeech", 2019], ["LipSound: Neural Mel-Spectrogram Reconstruction for Lip Reading", ["Leyuan Qu", "Cornelius Weber", "Stefan Wermter"], "https://doi.org/10.21437/Interspeech.2019-1393", 5, "interspeech", 2019]], "Ruixi Lin": [0, ["Optimizing Voice Activity Detection for Noisy Conditions", ["Ruixi Lin", "Charles Costello", "Charles Jankowski", "Vishwas Mruthyunjaya"], "https://doi.org/10.21437/Interspeech.2019-1776", 5, "interspeech", 2019]], "Patrick Nguyen": [0, ["On the Choice of Modeling Unit for Sequence-to-Sequence Speech Recognition", ["Kazuki Irie", "Rohit Prabhavalkar", "Anjuli Kannan", "Antoine Bruguier", "David Rybach", "Patrick Nguyen"], "https://doi.org/10.21437/Interspeech.2019-2277", 5, "interspeech", 2019]], "Laszlo Toth": [0, ["Examining the Combination of Multi-Band Processing and Channel Dropout for Robust Speech Recognition", ["Gyorgy Kovacs", "Laszlo Toth", "Dirk Van Compernolle", "Marcus Liwicki"], "https://doi.org/10.21437/Interspeech.2019-3215", 5, "interspeech", 2019], ["Calibrating DNN Posterior Probability Estimates of HMM/DNN Models to Improve Social Signal Detection from Audio Data", ["Gabor Gosztolya", "Laszlo Toth"], "https://doi.org/10.21437/Interspeech.2019-2552", 5, "interspeech", 2019], ["Ultrasound-Based Silent Speech Interface Built on a Continuous Vocoder", ["Tamas Gabor Csapo", "Mohammed Salah Al-Radhi", "Geza Nemeth", "Gabor Gosztolya", "Tamas Grosz", "Laszlo Toth", "Alexandra Marko"], "https://doi.org/10.21437/Interspeech.2019-2046", 5, "interspeech", 2019]], "Yosuke Kashiwagi": [0, ["End-to-End Adaptation with Backpropagation Through WFST for On-Device Speech Recognition System", ["Emiru Tsunoo", "Yosuke Kashiwagi", "Satoshi Asakawa", "Toshiyuki Kumakura"], "https://doi.org/10.21437/Interspeech.2019-1880", 5, "interspeech", 2019]], "Siyuan Ma": [0, ["Kernel Machines Beat Deep Neural Networks on Mask-Based Single-Channel Speech Enhancement", ["Like Hui", "Siyuan Ma", "Mikhail Belkin"], "https://doi.org/10.21437/Interspeech.2019-1344", 5, "interspeech", 2019]], "Gurunath Reddy M.": [0, ["Glottal Closure Instants Detection from Speech Signal by Deep Features Extracted from Raw Speech and Linear Prediction Residual", ["Gurunath Reddy M.", "K. Sreenivasa Rao", "Partha Pratim Das"], "https://doi.org/10.21437/Interspeech.2019-1981", 5, "interspeech", 2019]], "Tim K. Marks": [0, ["Joint Student-Teacher Learning for Audio-Visual Scene-Aware Dialog", ["Chiori Hori", "Anoop Cherian", "Tim K. Marks", "Takaaki Hori"], "https://doi.org/10.21437/Interspeech.2019-3143", 5, "interspeech", 2019]], "Maarten De Vos": [0, ["Spatio-Temporal Attention Pooling for Audio Scene Classification", ["Huy Phan", "Oliver Y. Chen", "Lam Pham", "Philipp Koch", "Maarten De Vos", "Ian Vince McLoughlin", "Alfred Mertins"], "https://doi.org/10.21437/Interspeech.2019-3040", 5, "interspeech", 2019]], "Katja Stark": [0, ["The Influence of Distraction on Speech Processing: How Selective is Selective Attention?", ["Sandra I. Parhammer", "Miriam Ebersberg", "Jenny Tippmann", "Katja Stark", "Andreas Opitz", "Barbara Hinger", "Sonja Rossi"], "https://doi.org/10.21437/Interspeech.2019-2699", 5, "interspeech", 2019]], "Maarten J. A. van Alphen": [0, ["CNN-Based Phoneme Classifier from Vocal Tract MRI Learns Embedding Consistent with Articulatory Topology", ["K. G. van Leeuwen", "P. Bos", "Stefano Trebeschi", "Maarten J. A. van Alphen", "Luuk Voskuilen", "Ludi E. Smeele", "Ferdi van der Heijden", "R. J. J. H. van Son"], "https://doi.org/10.21437/Interspeech.2019-1173", 5, "interspeech", 2019]], "Yashesh Gaur": [0, ["Speaker Adaptation for Attention-Based End-to-End Speech Recognition", ["Zhong Meng", "Yashesh Gaur", "Jinyu Li", "Yifan Gong"], "https://doi.org/10.21437/Interspeech.2019-3135", 5, "interspeech", 2019], ["Acoustic-to-Phrase Models for Speech Recognition", ["Yashesh Gaur", "Jinyu Li", "Zhong Meng", "Yifan Gong"], "https://doi.org/10.21437/Interspeech.2019-3056", 5, "interspeech", 2019]], "Lara Keshishian": [0, ["The Voicing Contrast in Stops and Affricates in the Western Armenian of Lebanon", ["Niamh E. Kelly", "Lara Keshishian"], "https://doi.org/10.21437/Interspeech.2019-2529", 5, "interspeech", 2019]], "Fuming Fang": [0, ["Joint Training Framework for Text-to-Speech and Voice Conversion Using Multi-Source Tacotron and WaveNet", ["Mingyang Zhang", "Xin Wang", "Fuming Fang", "Haizhou Li", "Junichi Yamagishi"], "https://doi.org/10.21437/Interspeech.2019-1357", 5, "interspeech", 2019]], "Shiliang Pu": [0, ["An End-to-End Audio Classification System Based on Raw Waveforms and Mix-Training Strategy", ["Jiaxu Chen", "Jing Hao", "Kai Chen", "Di Xie", "Shicai Yang", "Shiliang Pu"], "https://doi.org/10.21437/Interspeech.2019-1579", 5, "interspeech", 2019]], "Muhammad Abdul-Mageed": [0, ["SPEAK YOUR MIND! Towards Imagined Speech Recognition with Hierarchical Deep Learning", ["Pramit Saha", "Muhammad Abdul-Mageed", "Sidney S. Fels"], "https://doi.org/10.21437/Interspeech.2019-3041", 5, "interspeech", 2019]], "Ganapathy Sriram": [0, ["A Study of x-Vector Based Speaker Recognition on Short Utterances", ["Ahilan Kanagasundaram", "Sridha Sridharan", "Ganapathy Sriram", "S. Prachi", "Clinton Fookes"], "https://doi.org/10.21437/Interspeech.2019-1891", 5, "interspeech", 2019]], "Han-Chi Hsieh": [0, ["Consonant Classification in Mandarin Based on the Depth Image Feature: A Pilot Study", ["Han-Chi Hsieh", "Wei-Zhong Zheng", "Ko-Chiang Chen", "Ying-Hui Lai"], "https://doi.org/10.21437/Interspeech.2019-1893", 5, "interspeech", 2019]], "Chao Zhang": [0, ["Multi-Span Acoustic Modelling Using Raw Waveform Signals", ["Patrick von Platen", "Chao Zhang", "Philip C. Woodland"], "https://doi.org/10.21437/Interspeech.2019-2454", 5, "interspeech", 2019], ["Direct-Path Signal Cross-Correlation Estimation for Sound Source Localization in Reverberation", ["Wei Xue", "Ying Tong", "Guohong Ding", "Chao Zhang", "Tao Ma", "Xiaodong He", "Bowen Zhou"], "https://doi.org/10.21437/Interspeech.2019-1488", 5, "interspeech", 2019]], "Luis Serrano": [0, ["Parallel vs. Non-Parallel Voice Conversion for Esophageal Speech", ["Luis Serrano", "Sneha Raman", "David Tavarez", "Eva Navas", "Inma Hernaez"], "https://doi.org/10.21437/Interspeech.2019-2194", 5, "interspeech", 2019]], "Prashant Sridhar": [0, ["Improving Keyword Spotting and Language Identification via Neural Architecture Search at Scale", ["Hanna Mazzawi", "Xavi Gonzalvo", "Aleks Kracun", "Prashant Sridhar", "Niranjan Subrahmanya", "Ignacio Lopez-Moreno", "Hyun-Jin Park", "Patrick Violette"], "https://doi.org/10.21437/Interspeech.2019-1916", 5, "interspeech", 2019], ["VoiceFilter: Targeted Voice Separation by Speaker-Conditioned Spectrogram Masking", ["Quan Wang", "Hannah Muckenhirn", "Kevin W. Wilson", "Prashant Sridhar", "Zelin Wu", "John R. Hershey", "Rif A. Saurous", "Ron J. Weiss", "Ye Jia", "Ignacio Lopez-Moreno"], "https://doi.org/10.21437/Interspeech.2019-1101", 5, "interspeech", 2019]], "Elmar Noth": [0, ["Phonet: A Tool Based on Gated Recurrent Neural Networks to Extract Phonological Posteriors from Speech", ["Juan Camilo Vasquez-Correa", "Philipp Klumpp", "Juan Rafael Orozco-Arroyave", "Elmar Noth"], "https://doi.org/10.21437/Interspeech.2019-1405", 5, "interspeech", 2019], ["Apkinson: A Mobile Solution for Multimodal Assessment of Patients with Parkinson's Disease", ["Juan Camilo Vasquez-Correa", "Tomas Arias-Vergara", "Philipp Klumpp", "M. Strauss", "Arne Kuderle", "Nils Roth", "S. Bayerl", "Nicanor Garcia-Ospina", "Paula Andrea Perez-Toro", "L. Felipe Parra-Gallego", "Cristian David Rios-Urrego", "D. Escobar-Grisales", "Juan Rafael Orozco-Arroyave", "Bjorn Eskofier", "Elmar Noth"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8003.html", 2, "interspeech", 2019], ["The INTERSPEECH 2019 Computational Paralinguistics Challenge: Styrian Dialects, Continuous Sleepiness, Baby Sounds & Orca Activity", ["Bjorn W. Schuller", "Anton Batliner", "Christian Bergler", "Florian B. Pokorny", "Jarek Krajewski", "Margaret Cychosz", "Ralf Vollmann", "Sonja-Dana Roelen", "Sebastian Schnieder", "Elika Bergelson", "Alejandrina Cristia", "Amanda Seidl", "Anne S. Warlaumont", "Lisa Yankowitz", "Elmar Noth", "Shahin Amiriparian", "Simone Hantke", "Maximilian Schmitt"], "https://doi.org/10.21437/Interspeech.2019-1122", 5, "interspeech", 2019], ["Feature Representation of Pathophysiology of Parkinsonian Dysarthria", ["Alice Rueda", "Juan Camilo Vasquez-Correa", "Cristian David Rios-Urrego", "Juan Rafael Orozco-Arroyave", "Sridhar Krishnan", "Elmar Noth"], "https://doi.org/10.21437/Interspeech.2019-2490", 5, "interspeech", 2019], ["Feature Space Visualization with Spatial Similarity Maps for Pathological Speech Data", ["Philipp Klumpp", "Juan Camilo Vasquez-Correa", "Tino Haderlein", "Elmar Noth"], "https://doi.org/10.21437/Interspeech.2019-2080", 5, "interspeech", 2019], ["Phone-Attribute Posteriors to Evaluate the Speech of Cochlear Implant Users", ["Tomas Arias-Vergara", "Juan Rafael Orozco-Arroyave", "Milos Cernak", "Sandra Gollwitzer", "Maria Schuster", "Elmar Noth"], "https://doi.org/10.21437/Interspeech.2019-2144", 5, "interspeech", 2019], ["Deep Learning for Orca Call Type Identification - A Fully Unsupervised Approach", ["Christian Bergler", "Manuel Schmitt", "Rachael Xi Cheng", "Andreas K. Maier", "Volker Barth", "Elmar Noth"], "https://doi.org/10.21437/Interspeech.2019-1857", 5, "interspeech", 2019]], "Zheng Li": [0, ["Anti-Spoofing Speaker Verification System with Multi-Feature Integration and Multi-Task Learning", ["Rongjin Li", "Miao Zhao", "Zheng Li", "Lin Li", "Qingyang Hong"], "https://doi.org/10.21437/Interspeech.2019-1698", 5, "interspeech", 2019], ["Deep Speaker Embedding Extraction with Channel-Wise Feature Responses and Additive Supervision Softmax Loss Function", ["Jianfeng Zhou", "Tao Jiang", "Zheng Li", "Lin Li", "Qingyang Hong"], "https://doi.org/10.21437/Interspeech.2019-1704", 5, "interspeech", 2019]], "Sujitha A. C.": [0, ["Design and Development of a Multi-Lingual Speech Corpora (TaMaR-EmoDB) for Emotion Analysis", ["Rajeev Rajan", "Haritha U. G.", "Sujitha A. C.", "Rejisha T. M."], "https://doi.org/10.21437/Interspeech.2019-2034", 5, "interspeech", 2019]], "Jing Hao": [0, ["An End-to-End Audio Classification System Based on Raw Waveforms and Mix-Training Strategy", ["Jiaxu Chen", "Jing Hao", "Kai Chen", "Di Xie", "Shicai Yang", "Shiliang Pu"], "https://doi.org/10.21437/Interspeech.2019-1579", 5, "interspeech", 2019]], "Shoji Hayakawa": [0, ["End-to-End Monaural Speech Separation with Multi-Scale Dynamic Weighted Gated Dilated Convolutional Pyramid Network", ["Ziqiang Shi", "Huibin Lin", "Liu Liu", "Rujie Liu", "Shoji Hayakawa", "Shouji Harada", "Jiqing Han"], "https://doi.org/10.21437/Interspeech.2019-1292", 5, "interspeech", 2019]], "Akihiko Sugiyama": [0, ["Simultaneous Detection and Localization of a Wake-Up Word Using Multi-Task Learning of the Duration and Endpoint", ["Takashi Maekaku", "Yusuke Kida", "Akihiko Sugiyama"], "https://doi.org/10.21437/Interspeech.2019-1180", 5, "interspeech", 2019]], "Sameer Badaskar": [0, ["Connecting and Comparing Language Model Interpolation Techniques", ["Ernest Pusateri", "Christophe Van Gysel", "Rami Botros", "Sameer Badaskar", "Mirko Hannemann", "Youssef Oualil", "Ilya Oparin"], "https://doi.org/10.21437/Interspeech.2019-1822", 5, "interspeech", 2019]], "Rongjin Li": [0, ["Anti-Spoofing Speaker Verification System with Multi-Feature Integration and Multi-Task Learning", ["Rongjin Li", "Miao Zhao", "Zheng Li", "Lin Li", "Qingyang Hong"], "https://doi.org/10.21437/Interspeech.2019-1698", 5, "interspeech", 2019]], "Raj Karbar": [0, ["CaptionAI: A Real-Time Multilingual Captioning Application", ["Nagendra Kumar Goel", "Mousmita Sarma", "Saikiran Valluri", "Dharmeshkumar Agrawal", "Steve Braich", "Tejendra Singh Kuswah", "Zikra Iqbal", "Surbhi Chauhan", "Raj Karbar"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8039.html", 2, "interspeech", 2019]], "Jose Patino": [0, ["Privacy-Preserving Speaker Recognition with Cohort Score Normalisation", ["Andreas Nautsch", "Jose Patino", "Amos Treiber", "Themos Stafylakis", "Petr Mizera", "Massimiliano Todisco", "Thomas Schneider", "Nicholas W. D. Evans"], "https://doi.org/10.21437/Interspeech.2019-2638", 5, "interspeech", 2019]], "Emmanuel Morin": [0, ["Curriculum-Based Transfer Learning for an Effective End-to-End Spoken Language Understanding and Domain Portability", ["Antoine Caubriere", "Natalia A. Tomashenko", "Antoine Laurent", "Emmanuel Morin", "Nathalie Camelin", "Yannick Esteve"], "https://doi.org/10.21437/Interspeech.2019-1832", 5, "interspeech", 2019]], "Azam Rabiee": [0, ["Adjusting Pleasure-Arousal-Dominance for Continuous Emotional Text-to-Speech Synthesizer", ["Azam Rabiee", "Tae-Ho Kim", "Soo-Young Lee"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8045.html", 2, "interspeech", 2019]], "Dimitri Palaz": [0, ["Analysis of Deep Learning Architectures for Cross-Corpus Speech Emotion Recognition", ["Jack Parry", "Dimitri Palaz", "Georgia Clarke", "Pauline Lecomte", "Rebecca Mead", "Michael Berger", "Gregor Hofer"], "https://doi.org/10.21437/Interspeech.2019-2753", 5, "interspeech", 2019]], "Chieh-Chi Kao": [0, ["Sub-Band Convolutional Neural Networks for Small-Footprint Spoken Term Classification", ["Chieh-Chi Kao", "Ming Sun", "Yixin Gao", "Shiv Vitaladevuni", "Chao Wang"], "https://doi.org/10.21437/Interspeech.2019-1766", 5, "interspeech", 2019], ["Compression of Acoustic Event Detection Models with Quantized Distillation", ["Bowen Shi", "Ming Sun", "Chieh-Chi Kao", "Viktor Rozgic", "Spyros Matsoukas", "Chao Wang"], "https://doi.org/10.21437/Interspeech.2019-1747", 5, "interspeech", 2019]], "Sarah Sturmbauer": [0, ["Using Speech to Predict Sequentially Measured Cortisol Levels During a Trier Social Stress Test", ["Alice Baird", "Shahin Amiriparian", "Nicholas Cummins", "Sarah Sturmbauer", "Johanna Janson", "Eva-Maria Messner", "Harald Baumeister", "Nicolas Rohleder", "Bjorn W. Schuller"], "https://doi.org/10.21437/Interspeech.2019-1352", 5, "interspeech", 2019]], "Mohamed Eldesouki": [0, ["FarSpeech: Arabic Natural Language Processing for Live Arabic Speech", ["Mohamed Eldesouki", "Naassih Gopee", "Ahmed Ali", "Kareem Darwish"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8030.html", 2, "interspeech", 2019]], "Carlos Busso": [0, ["Speech Emotion Recognition with a Reject Option", ["Kusha Sridhar", "Carlos Busso"], "https://doi.org/10.21437/Interspeech.2019-1842", 5, "interspeech", 2019]], "Massimiliano Todisco": [0, ["ASVspoof 2019: Future Horizons in Spoofed and Fake Audio Detection", ["Massimiliano Todisco", "Xin Wang", "Ville Vestman", "Md. Sahidullah", "Hector Delgado", "Andreas Nautsch", "Junichi Yamagishi", "Nicholas W. D. Evans", "Tomi H. Kinnunen", "Kong Aik Lee"], "https://doi.org/10.21437/Interspeech.2019-2249", 5, "interspeech", 2019], ["I4U Submission to NIST SRE 2018: Leveraging from a Decade of Shared Experiences", ["Kong Aik Lee", "Ville Hautamaki", "Tomi H. Kinnunen", "Hitoshi Yamamoto", "Koji Okabe", "Ville Vestman", "Jing Huang", "Guohong Ding", "Hanwu Sun", "Anthony Larcher", "Rohan Kumar Das", "Haizhou Li", "Mickael Rouvier", "Pierre-Michel Bousquet", "Wei Rao", "Qing Wang", "Chunlei Zhang", "Fahimeh Bahmaninezhad", "Hector Delgado", "Massimiliano Todisco"], "https://doi.org/10.21437/Interspeech.2019-1533", 5, "interspeech", 2019], ["Privacy-Preserving Speaker Recognition with Cohort Score Normalisation", ["Andreas Nautsch", "Jose Patino", "Amos Treiber", "Themos Stafylakis", "Petr Mizera", "Massimiliano Todisco", "Thomas Schneider", "Nicholas W. D. Evans"], "https://doi.org/10.21437/Interspeech.2019-2638", 5, "interspeech", 2019], ["The GDPR & Speech Data: Reflections of Legal and Technology Communities, First Steps Towards a Common Understanding", ["Andreas Nautsch", "Catherine Jasserand", "Els Kindt", "Massimiliano Todisco", "Isabel Trancoso", "Nicholas W. D. Evans"], "https://doi.org/10.21437/Interspeech.2019-2647", 5, "interspeech", 2019]], "Katsuhiko Yamamoto": [0, ["Predicting Speech Intelligibility of Enhanced Speech Using Phone Accuracy of DNN-Based ASR System", ["Kenichi Arai", "Shoko Araki", "Atsunori Ogawa", "Keisuke Kinoshita", "Tomohiro Nakatani", "Katsuhiko Yamamoto", "Toshio Irino"], "https://doi.org/10.21437/Interspeech.2019-1381", 5, "interspeech", 2019]], "Ernest Pusateri": [0, ["Connecting and Comparing Language Model Interpolation Techniques", ["Ernest Pusateri", "Christophe Van Gysel", "Rami Botros", "Sameer Badaskar", "Mirko Hannemann", "Youssef Oualil", "Ilya Oparin"], "https://doi.org/10.21437/Interspeech.2019-1822", 5, "interspeech", 2019]], "Francoise Beaufays": [0, ["An Investigation into On-Device Personalization of End-to-End Automatic Speech Recognition Models", ["Khe Chai Sim", "Petr Zadrazil", "Francoise Beaufays"], "https://doi.org/10.21437/Interspeech.2019-1752", 5, "interspeech", 2019]], "Sushant Kafle": [0, ["Fusion Strategy for Prosodic and Lexical Representations of Word Importance", ["Sushant Kafle", "Cecilia Ovesdotter Alm", "Matt Huenerfauth"], "https://doi.org/10.21437/Interspeech.2019-1898", 5, "interspeech", 2019]], "Abhijeet Sangwan": [0, ["Toeplitz Inverse Covariance Based Robust Speaker Clustering for Naturalistic Audio Streams", ["Harishchandra Dubey", "Abhijeet Sangwan", "John H. L. Hansen"], "https://doi.org/10.21437/Interspeech.2019-1102", 5, "interspeech", 2019], ["The 2019 Inaugural Fearless Steps Challenge: A Giant Leap for Naturalistic Audio", ["John H. L. Hansen", "Aditya Joglekar", "Meena Chandra Shekhar", "Vinay Kothapally", "Chengzhu Yu", "Lakshmish Kaushik", "Abhijeet Sangwan"], "https://doi.org/10.21437/Interspeech.2019-2301", 5, "interspeech", 2019]], "Jiaming Xu": [0, ["Which Ones Are Speaking? Speaker-Inferred Model for Multi-Talker Speech Separation", ["Jing Shi", "Jiaming Xu", "Bo Xu"], "https://doi.org/10.21437/Interspeech.2019-1591", 5, "interspeech", 2019]], "Christopher Dromey": [0, ["Listeners' Ability to Identify the Gender of Preadolescent Children in Different Linguistic Contexts", ["Shawn L. Nissen", "Sharalee Blunck", "Anita Dromey", "Christopher Dromey"], "https://doi.org/10.21437/Interspeech.2019-1865", 5, "interspeech", 2019]], "Jieping Ye": [4.120562024922947e-08, ["An Attention-Based Hybrid Network for Automatic Detection of Alzheimer's Disease from Narrative Speech", ["Jun Chen", "Ji Zhu", "Jieping Ye"], "https://doi.org/10.21437/Interspeech.2019-2872", 5, "interspeech", 2019]], "Meet H. Soni": [0, ["Label Driven Time-Frequency Masking for Robust Continuous Speech Recognition", ["Meet H. Soni", "Ashish Panda"], "https://doi.org/10.21437/Interspeech.2019-2172", 5, "interspeech", 2019], ["Generative Noise Modeling and Channel Simulation for Robust Speech Recognition in Unseen Conditions", ["Meet H. Soni", "Sonal Joshi", "Ashish Panda"], "https://doi.org/10.21437/Interspeech.2019-2090", 5, "interspeech", 2019]], "Dongyang Dai": [0, ["One-Shot Voice Conversion with Global Speaker Embeddings", ["Hui Lu", "Zhiyong Wu", "Dongyang Dai", "Runnan Li", "Shiyin Kang", "Jia Jia", "Helen Meng"], "https://doi.org/10.21437/Interspeech.2019-2365", 5, "interspeech", 2019], ["Disambiguation of Chinese Polyphones in an End-to-End Framework with Semantic Features Extracted by Pre-Trained BERT", ["Dongyang Dai", "Zhiyong Wu", "Shiyin Kang", "Xixin Wu", "Jia Jia", "Dan Su", "Dong Yu", "Helen Meng"], "https://doi.org/10.21437/Interspeech.2019-2292", 5, "interspeech", 2019]], "Seungji Lee": [0.9998576194047928, ["Large-Scale Multilingual Speech Recognition with a Streaming End-to-End Model", ["Anjuli Kannan", "Arindrima Datta", "Tara N. Sainath", "Eugene Weinstein", "Bhuvana Ramabhadran", "Yonghui Wu", "Ankur Bapna", "Zhifeng Chen", "Seungji Lee"], "https://doi.org/10.21437/Interspeech.2019-2858", 5, "interspeech", 2019]], "Zhizheng Wu": [1.3821066166541662e-10, ["Building a Mixed-Lingual Neural TTS System with Only Monolingual Data", ["Liumeng Xue", "Wei Song", "Guanghui Xu", "Lei Xie", "Zhizheng Wu"], "https://doi.org/10.21437/Interspeech.2019-3191", 5, "interspeech", 2019]], "Christian Poellabauer": [0, ["ReMASC: Realistic Replay Attack Corpus for Voice Controlled Systems", ["Yuan Gong", "Jian Yang", "Jacob Huber", "Mitchell MacKnight", "Christian Poellabauer"], "https://doi.org/10.21437/Interspeech.2019-1541", 5, "interspeech", 2019]], "Vladimir Bataev": [0, ["R-Vectors: New Technique for Adaptation to Room Acoustics", ["Yuri Y. Khokhlov", "Alexander Zatvornitskiy", "Ivan Medennikov", "Ivan Sorokin", "Tatiana Prisyach", "Aleksei Romanenko", "Anton Mitrofanov", "Vladimir Bataev", "Andrei Andrusenko", "Mariya Korenevskaya", "Oleg Petrov"], "https://doi.org/10.21437/Interspeech.2019-2645", 5, "interspeech", 2019], ["The STC ASR System for the VOiCES from a Distance Challenge 2019", ["Ivan Medennikov", "Yuri Y. Khokhlov", "Aleksei Romanenko", "Ivan Sorokin", "Anton Mitrofanov", "Vladimir Bataev", "Andrei Andrusenko", "Tatiana Prisyach", "Mariya Korenevskaya", "Oleg Petrov", "Alexander Zatvornitskiy"], "https://doi.org/10.21437/Interspeech.2019-1574", 5, "interspeech", 2019], ["The STC ASR System for the VOiCES from a Distance Challenge 2019", ["Ivan Medennikov", "Yuri Y. Khokhlov", "Aleksei Romanenko", "Ivan Sorokin", "Anton Mitrofanov", "Vladimir Bataev", "Andrei Andrusenko", "Tatiana Prisyach", "Mariya Korenevskaya", "Oleg Petrov", "Alexander Zatvornitskiy"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/abs17.html", 0, "interspeech", 2019]], "Arun A. Joseph": [0, ["Exploring Critical Articulator Identification from 50Hz RT-MRI Data of the Vocal Tract", ["Samuel S. Silva", "Antonio J. S. Teixeira", "Conceicao Cunha", "Nuno Almeida", "Arun A. Joseph", "Jens Frahm"], "https://doi.org/10.21437/Interspeech.2019-2897", 5, "interspeech", 2019], ["A Multimodal Real-Time MRI Articulatory Corpus of French for Speech Research", ["Ioannis K. Douros", "Jacques Felblinger", "Jens Frahm", "Karyna Isaieva", "Arun A. Joseph", "Yves Laprie", "Freddy Odille", "Anastasiia Tsukanova", "Dirk Voit", "Pierre-Andre Vuissoz"], "https://doi.org/10.21437/Interspeech.2019-1700", 5, "interspeech", 2019], ["On the Role of Oral Configurations in European Portuguese Nasal Vowels", ["Conceicao Cunha", "Samuel S. Silva", "Antonio J. S. Teixeira", "Catarina Oliveira", "Paula Martins", "Arun A. Joseph", "Jens Frahm"], "https://doi.org/10.21437/Interspeech.2019-2232", 5, "interspeech", 2019]], "Gang Feng": [0, ["Automatic Detection of the Temporal Segmentation of Hand Movements in British English Cued Speech", ["Li Liu", "Jianze Li", "Gang Feng", "Xiao-Ping Steven Zhang"], "https://doi.org/10.21437/Interspeech.2019-2353", 5, "interspeech", 2019]], "Christine Mooshammer": [0, ["Temporal Coordination of Articulatory and Respiratory Events Prior to Speech Initiation", ["Oksana Rasskazova", "Christine Mooshammer", "Susanne Fuchs"], "https://doi.org/10.21437/Interspeech.2019-2876", 5, "interspeech", 2019]], "Michael Berger": [0, ["Analysis of Deep Learning Architectures for Cross-Corpus Speech Emotion Recognition", ["Jack Parry", "Dimitri Palaz", "Georgia Clarke", "Pauline Lecomte", "Rebecca Mead", "Michael Berger", "Gregor Hofer"], "https://doi.org/10.21437/Interspeech.2019-2753", 5, "interspeech", 2019]], "Jindrich Zdansky": [0, ["An Approach to Online Speaker Change Point Detection Using DNNs and WFSTs", ["Lukas Mateju", "Petr Cerva", "Jindrich Zdansky"], "https://doi.org/10.21437/Interspeech.2019-1407", 5, "interspeech", 2019]], "Ching-Ting Chang": [8.276199459089639e-08, ["Code-Switching Sentence Generation by Generative Adversarial Networks and its Application to Data Augmentation", ["Ching-Ting Chang", "Shun-Po Chuang", "Hung-yi Lee"], "https://doi.org/10.21437/Interspeech.2019-3214", 5, "interspeech", 2019]], "Yuki Mitsufuji": [0, ["Recursive Speech Separation for Unknown Number of Speakers", ["Naoya Takahashi", "Sudarsanam Parthasaarathy", "Nabarun Goswami", "Yuki Mitsufuji"], "https://doi.org/10.21437/Interspeech.2019-1550", 5, "interspeech", 2019]], "Volker Barth": [0, ["Deep Learning for Orca Call Type Identification - A Fully Unsupervised Approach", ["Christian Bergler", "Manuel Schmitt", "Rachael Xi Cheng", "Andreas K. Maier", "Volker Barth", "Elmar Noth"], "https://doi.org/10.21437/Interspeech.2019-1857", 5, "interspeech", 2019]], "Vedran Vukotic": [0, ["Mining Polysemous Triplets with Recurrent Neural Networks for Spoken Language Understanding", ["Vedran Vukotic", "Christian Raymond"], "https://doi.org/10.21437/Interspeech.2019-2977", 5, "interspeech", 2019]], "Leanne Nortje": [0, ["Unsupervised Acoustic Unit Discovery for Speech Synthesis Using Discrete Latent-Variable Neural Networks", ["Ryan Eloff", "Andre Nortje", "Benjamin van Niekerk", "Avashna Govender", "Leanne Nortje", "Arnu Pretorius", "Elan Van Biljon", "Ewald van der Westhuizen", "Lisa van Staden", "Herman Kamper"], "https://doi.org/10.21437/Interspeech.2019-1518", 5, "interspeech", 2019]], "Gordon Wichern": [0, ["WHAM!: Extending Speech Separation to Noisy Environments", ["Gordon Wichern", "Joe Antognini", "Michael Flynn", "Licheng Richard Zhu", "Emmett McQuinn", "Dwight Crow", "Ethan Manilow", "Jonathan Le Roux"], "https://doi.org/10.21437/Interspeech.2019-2821", 5, "interspeech", 2019]], "Konstantinos Kyriakopoulos": [0, ["A Deep Learning Approach to Automatic Characterisation of Rhythm in Non-Native English Speech", ["Konstantinos Kyriakopoulos", "Kate M. Knill", "Mark J. F. Gales"], "https://doi.org/10.21437/Interspeech.2019-3186", 5, "interspeech", 2019]], "Manfred Pastatter": [0, ["Zooming in on Spatiotemporal V-to-C Coarticulation with Functional PCA", ["Michele Gubian", "Manfred Pastatter", "Marianne Pouplier"], "https://doi.org/10.21437/Interspeech.2019-2143", 5, "interspeech", 2019]], "Hitoshi Kiya": [0, ["Investigation on Blind Bandwidth Extension with a Non-Linear Function and its Evaluation of x-Vector-Based Speaker Verification", ["Ryota Kaminishi", "Haruna Miyamoto", "Sayaka Shiota", "Hitoshi Kiya"], "https://doi.org/10.21437/Interspeech.2019-1510", 5, "interspeech", 2019]], "Frank K. Soong": [0, ["Forward-Backward Decoding for Regularizing End-to-End TTS", ["Yibin Zheng", "Xi Wang", "Lei He", "Shifeng Pan", "Frank K. Soong", "Zhengqi Wen", "Jianhua Tao"], "https://doi.org/10.21437/Interspeech.2019-2325", 5, "interspeech", 2019], ["A New GAN-Based End-to-End TTS Training Algorithm", ["Haohan Guo", "Frank K. Soong", "Lei He", "Lei Xie"], "https://doi.org/10.21437/Interspeech.2019-2176", 5, "interspeech", 2019], ["Exploiting Syntactic Features in a Parsed Tree to Improve End-to-End TTS", ["Haohan Guo", "Frank K. Soong", "Lei He", "Lei Xie"], "https://doi.org/10.21437/Interspeech.2019-2167", 5, "interspeech", 2019]], "Johannes Wagner": [0, ["Towards Robust Speech Emotion Recognition Using Deep Residual Networks for Speech Enhancement", ["Andreas Triantafyllopoulos", "Gil Keren", "Johannes Wagner", "Ingmar Steiner", "Bjorn W. Schuller"], "https://doi.org/10.21437/Interspeech.2019-1811", 5, "interspeech", 2019]], "Phil Hoole": [0, ["Assessing Acoustic and Articulatory Dimensions of Speech Motor Adaptation with Random Forests", ["Eugen Klein", "Jana Brunner", "Phil Hoole"], "https://doi.org/10.21437/Interspeech.2019-1812", 5, "interspeech", 2019]], "Bozena Kostek": [0, ["Interpretable Deep Learning Model for the Detection and Reconstruction of Dysarthric Speech", ["Daniel Korzekwa", "Roberto Barra-Chicote", "Bozena Kostek", "Thomas Drugman", "Mateusz Lajszczak"], "https://doi.org/10.21437/Interspeech.2019-1206", 5, "interspeech", 2019]], "Da-Rong Liu": [0, ["Completely Unsupervised Phoneme Recognition by a Generative Adversarial Network Harmonized with Iteratively Refined Hidden Markov Models", ["Kuan-Yu Chen", "Che-Ping Tsai", "Da-Rong Liu", "Hung-yi Lee", "Lin-Shan Lee"], "https://doi.org/10.21437/Interspeech.2019-2068", 5, "interspeech", 2019]], "Luciana Albuquerque": [0, ["Age-Related Changes in European Portuguese Vowel Acoustics", ["Luciana Albuquerque", "Catarina Oliveira", "Antonio J. S. Teixeira", "Pedro Sa-Couto", "Daniela Figueiredo"], "https://doi.org/10.21437/Interspeech.2019-1818", 5, "interspeech", 2019]], "Saurabh Sahu": [0, ["Multi-Modal Learning for Speech Emotion Recognition: An Analysis and Comparison of ASR Outputs with Ground Truth Transcription", ["Saurabh Sahu", "Vikramjit Mitra", "Nadee Seneviratne", "Carol Y. Espy-Wilson"], "https://doi.org/10.21437/Interspeech.2019-1149", 5, "interspeech", 2019]], "Ran Mochary": [0, ["GECKO - A Tool for Effective Annotation of Human Conversations", ["Golan Levy", "Raquel Sitman", "Ido Amir", "Eduard Golshtein", "Ran Mochary", "Eilon Reshef", "Roi Reichart", "Omri Allouche"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8025.html", 2, "interspeech", 2019]], "Fanny Guitard-Ivent": [0, ["Are IP Initial Vowels Acoustically More Distinct? Results from LDA and CNN Classifications", ["Fanny Guitard-Ivent", "Gabriele Chignoli", "Cecile Fougeron", "Laurianne Georgeton"], "https://doi.org/10.21437/Interspeech.2019-2153", 5, "interspeech", 2019]], "Jordi Pons": [0, ["End-to-End Music Source Separation: Is it Possible in the Waveform Domain?", ["Francesc Lluis", "Jordi Pons", "Xavier Serra"], "https://doi.org/10.21437/Interspeech.2019-1177", 5, "interspeech", 2019]], "Andreas K. Maier": [0, ["Analysis by Adversarial Synthesis - A Novel Approach for Speech Vocoding", ["Ahmed Mustafa", "Arijit Biswas", "Christian Bergler", "Julia Schottenhamml", "Andreas K. Maier"], "https://doi.org/10.21437/Interspeech.2019-1195", 5, "interspeech", 2019], ["Deep Learning for Orca Call Type Identification - A Fully Unsupervised Approach", ["Christian Bergler", "Manuel Schmitt", "Rachael Xi Cheng", "Andreas K. Maier", "Volker Barth", "Elmar Noth"], "https://doi.org/10.21437/Interspeech.2019-1857", 5, "interspeech", 2019]], "P. Bos": [0, ["CNN-Based Phoneme Classifier from Vocal Tract MRI Learns Embedding Consistent with Articulatory Topology", ["K. G. van Leeuwen", "P. Bos", "Stefano Trebeschi", "Maarten J. A. van Alphen", "Luuk Voskuilen", "Ludi E. Smeele", "Ferdi van der Heijden", "R. J. J. H. van Son"], "https://doi.org/10.21437/Interspeech.2019-1173", 5, "interspeech", 2019]], "Qiang Huang": [0, ["Detecting Mismatch Between Speech and Transcription Using Cross-Modal Attention", ["Qiang Huang", "Thomas Hain"], "https://doi.org/10.21437/Interspeech.2019-2125", 5, "interspeech", 2019]], "Wei-Zhong Zheng": [0, ["Consonant Classification in Mandarin Based on the Depth Image Feature: A Pilot Study", ["Han-Chi Hsieh", "Wei-Zhong Zheng", "Ko-Chiang Chen", "Ying-Hui Lai"], "https://doi.org/10.21437/Interspeech.2019-1893", 5, "interspeech", 2019]], "Olivier Perrotin": [0, ["GFM-Voc: A Real-Time Voice Quality Modification System", ["Olivier Perrotin", "Ian Vince McLoughlin"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8018.html", 2, "interspeech", 2019]], "Yukiko Nota": [0, ["Speech Organ Contour Extraction Using Real-Time MRI and Machine Learning Method", ["Hironori Takemoto", "Tsubasa Goto", "Yuya Hagihara", "Sayaka Hamanaka", "Tatsuya Kitamura", "Yukiko Nota", "Kikuo Maekawa"], "https://doi.org/10.21437/Interspeech.2019-1593", 5, "interspeech", 2019]], "Tsung-Ming Tai": [0, ["Using Attention Networks and Adversarial Augmentation for Styrian Dialect Continuous Sleepiness and Baby Sound Recognition", ["Sung-Lin Yeh", "Gao-Yi Chao", "Bo-Hao Su", "Yu-Lin Huang", "Meng-Han Lin", "Yin-Chun Tsai", "Yu-Wen Tai", "Zheng-Chi Lu", "Chieh-Yu Chen", "Tsung-Ming Tai", "Chiu-Wang Tseng", "Cheng-Kuang Lee", "Chi-Chun Lee"], "https://doi.org/10.21437/Interspeech.2019-2110", 5, "interspeech", 2019]], "Suhas B. N.": [0, ["Comparison of Speech Tasks and Recording Devices for Voice Based Automatic Classification of Healthy Subjects and Patients with Amyotrophic Lateral Sclerosis", ["Suhas B. N.", "Deep Patel", "Nithin Rao Koluguri", "Yamini Belur", "Pradeep Reddy", "Atchayaram Nalini", "Ravi Yadav", "Dipanjan Gope", "Prasanta Kumar Ghosh"], "https://doi.org/10.21437/Interspeech.2019-1285", 5, "interspeech", 2019]], "Heidy Suter": [0, ["Formant Pattern and Spectral Shape Ambiguity of Vowel Sounds, and Related Phenomena of Vowel Acoustics - Exemplary Evidence", ["Dieter Maurer", "Heidy Suter", "Christian dHereuse", "Volker Dellwo"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8017.html", 2, "interspeech", 2019]], "Alper Buyuktosunoglu": [0, ["A Highly Efficient Distributed Deep Learning System for Automatic Speech Recognition", ["Wei Zhang", "Xiaodong Cui", "Ulrich Finkler", "George Saon", "Abdullah Kayi", "Alper Buyuktosunoglu", "Brian Kingsbury", "David S. Kung", "Michael Picheny"], "https://doi.org/10.21437/Interspeech.2019-2700", 5, "interspeech", 2019]], "Yoan Dinkov": [0, ["Predicting the Leading Political Ideology of YouTube Channels Using Acoustic, Textual, and Metadata Information", ["Yoan Dinkov", "Ahmed Ali", "Ivan Koychev", "Preslav Nakov"], "https://doi.org/10.21437/Interspeech.2019-2965", 5, "interspeech", 2019]], "Hsin-Min Wang": [0.0006203114317031577, ["Investigation of F0 Conditioning and Fully Convolutional Networks in Variational Autoencoder Based Voice Conversion", ["Wen-Chin Huang", "Yi-Chiao Wu", "Chen-Chou Lo", "Patrick Lumban Tobing", "Tomoki Hayashi", "Kazuhiro Kobayashi", "Tomoki Toda", "Yu Tsao", "Hsin-Min Wang"], "https://doi.org/10.21437/Interspeech.2019-1774", 5, "interspeech", 2019], ["MOSNet: Deep Learning-Based Objective Assessment for Voice Conversion", ["Chen-Chou Lo", "Szu-Wei Fu", "Wen-Chin Huang", "Xin Wang", "Junichi Yamagishi", "Yu Tsao", "Hsin-Min Wang"], "https://doi.org/10.21437/Interspeech.2019-2003", 5, "interspeech", 2019], ["Exploring the Encoder Layers of Discriminative Autoencoders for LVCSR", ["Pin-Tuan Huang", "Hung-Shin Lee", "Syu-Siang Wang", "Kuan-Yu Chen", "Yu Tsao", "Hsin-Min Wang"], "https://doi.org/10.21437/Interspeech.2019-1717", 5, "interspeech", 2019], ["Noise Adaptive Speech Enhancement Using Domain Adversarial Training", ["Chien-Feng Liao", "Yu Tsao", "Hung-yi Lee", "Hsin-Min Wang"], "https://doi.org/10.21437/Interspeech.2019-1519", 5, "interspeech", 2019], ["Specialized Speech Enhancement Model Selection Based on Learned Non-Intrusive Quality Assessment Metric", ["Ryandhimas E. Zezario", "Szu-Wei Fu", "Xugang Lu", "Hsin-Min Wang", "Yu Tsao"], "https://doi.org/10.21437/Interspeech.2019-2425", 5, "interspeech", 2019]], "Nicholas Buckeridge": [0, ["Elpis, an Accessible Speech-to-Text Tool", ["Ben Foley", "Alina Rakhi", "Nicholas Lambourne", "Nicholas Buckeridge", "Janet Wiles"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8006.html", 2, "interspeech", 2019]], "Liang He": [0, ["Towards Discriminative Representations and Unbiased Predictions: Class-Specific Angular Softmax for Speech Emotion Recognition", ["Zhixuan Li", "Liang He", "Jingyang Li", "Li Wang", "Wei-Qiang Zhang"], "https://doi.org/10.21437/Interspeech.2019-1683", 5, "interspeech", 2019], ["Large Margin Softmax Loss for Speaker Verification", ["Yi Liu", "Liang He", "Jia Liu"], "https://doi.org/10.21437/Interspeech.2019-2357", 5, "interspeech", 2019], ["Multi-Scale Time-Frequency Attention for Acoustic Event Detection", ["Jingyang Zhang", "Wenhao Ding", "Jintao Kang", "Liang He"], "https://doi.org/10.21437/Interspeech.2019-1587", 5, "interspeech", 2019]], "Munir Georges": [0, ["Ultra-Compact NLU: Neuronal Network Binarization as Regularization", ["Munir Georges", "Krzysztof Czarnowski", "Tobias Bocklet"], "https://doi.org/10.21437/Interspeech.2019-2591", 5, "interspeech", 2019]], "Keelan Evanini": [0, ["Development of Robust Automated Scoring Models Using Adversarial Input for Oral Proficiency Assessment", ["Su-Youn Yoon", "Chong Min Lee", "Klaus Zechner", "Keelan Evanini"], "https://doi.org/10.21437/Interspeech.2019-1711", 5, "interspeech", 2019], ["Automatic Detection of Off-Topic Spoken Responses Using Very Deep Convolutional Neural Networks", ["Xinhao Wang", "Su-Youn Yoon", "Keelan Evanini", "Klaus Zechner", "Yao Qian"], "https://doi.org/10.21437/Interspeech.2019-1848", 5, "interspeech", 2019]], "Chris Donahue": [0, ["Expediting TTS Synthesis with Adversarial Vocoding", ["Paarth Neekhara", "Chris Donahue", "Miller S. Puckette", "Shlomo Dubnov", "Julian J. McAuley"], "https://doi.org/10.21437/Interspeech.2019-3099", 5, "interspeech", 2019]], "Zhenrui Zhang": [0, ["Vowels and Diphthongs in the Xupu Xiang Chinese Dialect", ["Zhenrui Zhang", "Fang Hu"], "https://doi.org/10.21437/Interspeech.2019-1174", 5, "interspeech", 2019]], "Mateusz Lajszczak": [0, ["Interpretable Deep Learning Model for the Detection and Reconstruction of Dysarthric Speech", ["Daniel Korzekwa", "Roberto Barra-Chicote", "Bozena Kostek", "Thomas Drugman", "Mateusz Lajszczak"], "https://doi.org/10.21437/Interspeech.2019-1206", 5, "interspeech", 2019]], "Benoit Brard": [0, ["Unified Verbalization for Speech Recognition & Synthesis Across Languages", ["Sandy Ritchie", "Richard Sproat", "Kyle Gorman", "Daan van Esch", "Christian Schallhart", "Nikos Bampounis", "Benoit Brard", "Jonas Fromseier Mortensen", "Millie Holt", "Eoin Mahon"], "https://doi.org/10.21437/Interspeech.2019-2807", 5, "interspeech", 2019]], "Muhammad Umar Farooq": [0, ["Improving Large Vocabulary Urdu Speech Recognition System Using Deep Neural Networks", ["Muhammad Umar Farooq", "Farah Adeeba", "Sahar Rauf", "Sarmad Hussain"], "https://doi.org/10.21437/Interspeech.2019-2629", 5, "interspeech", 2019]], "Syu-Siang Wang": [0.004344350192695856, ["Exploring the Encoder Layers of Discriminative Autoencoders for LVCSR", ["Pin-Tuan Huang", "Hung-Shin Lee", "Syu-Siang Wang", "Kuan-Yu Chen", "Yu Tsao", "Hsin-Min Wang"], "https://doi.org/10.21437/Interspeech.2019-1717", 5, "interspeech", 2019], ["Speaker-Aware Deep Denoising Autoencoder with Embedded Speaker Identity for Speech Enhancement", ["Fu-Kai Chuang", "Syu-Siang Wang", "Jeih-weih Hung", "Yu Tsao", "Shih-Hau Fang"], "https://doi.org/10.21437/Interspeech.2019-2108", 5, "interspeech", 2019]], "Marialucia Cuciniello": [0, ["The Dependability of Voice on Elders' Acceptance of Humanoid Agents", ["Anna Esposito", "Terry Amorese", "Marialucia Cuciniello", "Maria Teresa Riviello", "Antonietta Maria Esposito", "Alda Troncone", "Gennaro Cordasco"], "https://doi.org/10.21437/Interspeech.2019-1734", 5, "interspeech", 2019]], "Pia Nancy Porysek Moreta": [0, ["\"Computer, Test My Hearing\": Accurate Speech Audiometry with Smart Speakers", ["Jasper Ooster", "Pia Nancy Porysek Moreta", "Jorg-Hendrik Bach", "Inga Holube", "Bernd T. Meyer"], "https://doi.org/10.21437/Interspeech.2019-2118", 5, "interspeech", 2019]], "Kusha Sridhar": [0, ["Speech Emotion Recognition with a Reject Option", ["Kusha Sridhar", "Carlos Busso"], "https://doi.org/10.21437/Interspeech.2019-1842", 5, "interspeech", 2019]], "Claude Montacie": [0, ["Spatial, Temporal and Spectral Multiresolution Analysis for the INTERSPEECH 2019 ComParE Challenge", ["Marie-Jose Caraty", "Claude Montacie"], "https://doi.org/10.21437/Interspeech.2019-1693", 5, "interspeech", 2019]], "Frederic Bechet": [0, ["Adapting a FrameNet Semantic Parser for Spoken Language Understanding Using Adversarial Learning", ["Gabriel Marzinotto", "Geraldine Damnati", "Frederic Bechet"], "https://doi.org/10.21437/Interspeech.2019-2732", 5, "interspeech", 2019], ["Benchmarking Benchmarks: Introducing New Automatic Indicators for Benchmarking Spoken Language Understanding Corpora", ["Frederic Bechet", "Christian Raymond"], "https://doi.org/10.21437/Interspeech.2019-3033", 5, "interspeech", 2019]], "Nobuaki Minematsu": [0, ["Analysis of Native Listeners' Facial Microexpressions While Shadowing Non-Native Speech - Potential of Shadowers' Facial Expressions for Comprehensibility Prediction", ["Tasavat Trisitichoke", "Shintaro Ando", "Daisuke Saito", "Nobuaki Minematsu"], "https://doi.org/10.21437/Interspeech.2019-1953", 5, "interspeech", 2019]], "To Ka Hei": [0, ["The CUHK Dysarthric Speech Recognition Systems for English and Cantonese", ["Shoukang Hu", "Shansong Liu", "Heng Fai Chang", "Mengzhe Geng", "Jiani Chen", "Lau Wing Chung", "To Ka Hei", "Jianwei Yu", "Ka Ho Wong", "Xunying Liu", "Helen Meng"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8047.html", 2, "interspeech", 2019]], "Julie Cattiau": [0, ["Personalizing ASR for Dysarthric and Accented Speech with Limited Data", ["Joel Shor", "Dotan Emanuel", "Oran Lang", "Omry Tuval", "Michael Brenner", "Julie Cattiau", "Fernando Vieira", "Maeve McNally", "Taylor Charbonneau", "Melissa Nollstadt", "Avinatan Hassidim", "Yossi Matias"], "https://doi.org/10.21437/Interspeech.2019-1427", 5, "interspeech", 2019]], "Russ Webb": [0, ["Mirroring to Build Trust in Digital Assistants", ["Katherine Metcalf", "Barry-John Theobald", "Garrett Weinberg", "Robert Lee", "Ing-Marie Jonsson", "Russ Webb", "Nicholas Apostoloff"], "https://doi.org/10.21437/Interspeech.2019-1829", 5, "interspeech", 2019]], "Zhiwei Mou": [0, ["Diagnosing Dysarthria with Long Short-Term Memory Networks", ["Alex Mayle", "Zhiwei Mou", "Razvan C. Bunescu", "Sadegh Mirshekarian", "Li Xu", "Chang Liu"], "https://doi.org/10.21437/Interspeech.2019-2903", 5, "interspeech", 2019]], "Jinchuan Zhang": [0, ["Latent Topic Attention for Domain Classification", ["Peisong Huang", "Peijie Huang", "Wencheng Ai", "Jiande Ding", "Jinchuan Zhang"], "https://doi.org/10.21437/Interspeech.2019-2228", 5, "interspeech", 2019]], "Ilya Sklyar": [0, ["Analysis of Deep Clustering as Preprocessing for Automatic Speech Recognition of Sparsely Overlapping Speech", ["Tobias Menne", "Ilya Sklyar", "Ralf Schluter", "Hermann Ney"], "https://doi.org/10.21437/Interspeech.2019-1728", 5, "interspeech", 2019]], "Bob L. Sturm": [0, ["Ensemble Models for Spoofing Detection in Automatic Speaker Verification", ["Bhusan Chettri", "Daniel Stoller", "Veronica Morfi", "Marco A. Martinez Ramirez", "Emmanouil Benetos", "Bob L. Sturm"], "https://doi.org/10.21437/Interspeech.2019-2505", 5, "interspeech", 2019]], "Sebastian Springenberg": [0, ["Predictive Auxiliary Variational Autoencoder for Representation Learning of Global Speech Characteristics", ["Sebastian Springenberg", "Egor Lakomkin", "Cornelius Weber", "Stefan Wermter"], "https://doi.org/10.21437/Interspeech.2019-2845", 5, "interspeech", 2019]], "Ying Qin": [0, ["Automatic Assessment of Language Impairment Based on Raw ASR Output", ["Ying Qin", "Tan Lee", "Anthony Pak-Hin Kong"], "https://doi.org/10.21437/Interspeech.2019-1688", 5, "interspeech", 2019], ["Child Speech Disorder Detection with Siamese Recurrent Network Using Speech Attribute Features", ["Jiarui Wang", "Ying Qin", "Zhiyuan Peng", "Tan Lee"], "https://doi.org/10.21437/Interspeech.2019-2320", 5, "interspeech", 2019]], "Mirjam Broersma": [0, ["Foreign-Language Knowledge Enhances Artificial-Language Segmentation", ["Annie Tremblay", "Mirjam Broersma"], "https://doi.org/10.21437/Interspeech.2019-2446", 5, "interspeech", 2019], ["Lexically Guided Perceptual Learning of a Vowel Shift in an Interactive L2 Listening Context", ["E. Felker", "Mirjam Ernestus", "Mirjam Broersma"], "https://doi.org/10.21437/Interspeech.2019-1414", 5, "interspeech", 2019]], "Fei Chen": [0, ["Contributions of Consonant-Vowel Transitions to Mandarin Tone Identification in Simulated Electric-Acoustic Hearing", ["Fei Chen"], "https://doi.org/10.21437/Interspeech.2019-1124", 5, "interspeech", 2019]], "Adrian Skilling": [0, ["Neural Network-Based Modeling of Phonetic Durations", ["Xizi Wei", "Melvyn Hunt", "Adrian Skilling"], "https://doi.org/10.21437/Interspeech.2019-2102", 5, "interspeech", 2019]], "Paarth Neekhara": [0, ["Expediting TTS Synthesis with Adversarial Vocoding", ["Paarth Neekhara", "Chris Donahue", "Miller S. Puckette", "Shlomo Dubnov", "Julian J. McAuley"], "https://doi.org/10.21437/Interspeech.2019-3099", 5, "interspeech", 2019], ["Universal Adversarial Perturbations for Speech Recognition Systems", ["Paarth Neekhara", "Shehzeen Hussain", "Prakhar Pandey", "Shlomo Dubnov", "Julian J. McAuley", "Farinaz Koushanfar"], "https://doi.org/10.21437/Interspeech.2019-1353", 5, "interspeech", 2019]], "William Hinthorn": [0, ["Meeting Transcription Using Asynchronous Distant Microphones", ["Takuya Yoshioka", "Dimitrios Dimitriadis", "Andreas Stolcke", "William Hinthorn", "Zhuo Chen", "Michael Zeng", "Xuedong Huang"], "https://doi.org/10.21437/Interspeech.2019-3088", 5, "interspeech", 2019]], "Alexandre Nanchen": [0, ["Open-Vocabulary Keyword Spotting with Audio and Text Embeddings", ["Niccolo Sacchi", "Alexandre Nanchen", "Martin Jaggi", "Milos Cernak"], "https://doi.org/10.21437/Interspeech.2019-1846", 5, "interspeech", 2019]], "Li Wang": [0.00029262965836096555, ["Speaker-Invariant Feature-Mapping for Distant Speech Recognition via Adversarial Teacher-Student Learning", ["Long Wu", "Hangting Chen", "Li Wang", "Pengyuan Zhang", "Yonghong Yan"], "https://doi.org/10.21437/Interspeech.2019-2136", 5, "interspeech", 2019], ["Multi-Accent Adaptation Based on Gate Mechanism", ["Han Zhu", "Li Wang", "Pengyuan Zhang", "Yonghong Yan"], "https://doi.org/10.21437/Interspeech.2019-3155", 5, "interspeech", 2019], ["Towards Discriminative Representations and Unbiased Predictions: Class-Specific Angular Softmax for Speech Emotion Recognition", ["Zhixuan Li", "Liang He", "Jingyang Li", "Li Wang", "Wei-Qiang Zhang"], "https://doi.org/10.21437/Interspeech.2019-1683", 5, "interspeech", 2019]], "Hiroki Tanaka": [0, ["Speech Quality Evaluation of Synthesized Japanese Speech Using EEG", ["Ivan Halim Parmonangan", "Hiroki Tanaka", "Sakriani Sakti", "Shinnosuke Takamichi", "Satoshi Nakamura"], "https://doi.org/10.21437/Interspeech.2019-2059", 5, "interspeech", 2019]], "Aniruddha Tammewar": [0, ["Modeling User Context for Valence Prediction from Narratives", ["Aniruddha Tammewar", "Alessandra Cervone", "Eva-Maria Messner", "Giuseppe Riccardi"], "https://doi.org/10.21437/Interspeech.2019-2489", 5, "interspeech", 2019]], "Lorrayne Bennett": [0, ["Large-Scale Visual Speech Recognition", ["Brendan Shillingford", "Yannis M. Assael", "Matthew W. Hoffman", "Thomas Paine", "Cian Hughes", "Utsav Prabhu", "Hank Liao", "Hasim Sak", "Kanishka Rao", "Lorrayne Bennett", "Marie Mulville", "Misha Denil", "Ben Coppin", "Ben Laurie", "Andrew W. Senior", "Nando de Freitas"], "https://doi.org/10.21437/Interspeech.2019-1669", 5, "interspeech", 2019]], "Christopher R. Bowie": [0, ["Objective Assessment of Social Skills Using Automated Language Analysis for Identification of Schizophrenia and Bipolar Disorder", ["Rohit Voleti", "Stephanie Woolridge", "Julie M. Liss", "Melissa Milanovic", "Christopher R. Bowie", "Visar Berisha"], "https://doi.org/10.21437/Interspeech.2019-2960", 5, "interspeech", 2019]], "Theodoros Giannakopoulos": [0, ["Data Augmentation Using GANs for Speech Emotion Recognition", ["Aggelina Chatziagapi", "Georgios Paraskevopoulos", "Dimitris Sgouropoulos", "Georgios Pantazopoulos", "Malvina Nikandrou", "Theodoros Giannakopoulos", "Athanasios Katsamanis", "Alexandros Potamianos", "Shrikanth Narayanan"], "https://doi.org/10.21437/Interspeech.2019-2561", 5, "interspeech", 2019], ["Unsupervised Low-Rank Representations for Speech Emotion Recognition", ["Georgios Paraskevopoulos", "Efthymios Tzinis", "Nikolaos Ellinas", "Theodoros Giannakopoulos", "Alexandros Potamianos"], "https://doi.org/10.21437/Interspeech.2019-2769", 5, "interspeech", 2019]], "Annie Tremblay": [0, ["Foreign-Language Knowledge Enhances Artificial-Language Segmentation", ["Annie Tremblay", "Mirjam Broersma"], "https://doi.org/10.21437/Interspeech.2019-2446", 5, "interspeech", 2019]], "Yong-cheol Lee": [0.9995790272951126, ["Automatic Detection of Prosodic Focus in American English", ["Sunghye Cho", "Mark Liberman", "Yong-cheol Lee"], "https://doi.org/10.21437/Interspeech.2019-1668", 5, "interspeech", 2019]], "Tomohiro Nakatani": [0, ["Simultaneous Denoising and Dereverberation for Low-Latency Applications Using Frame-by-Frame Online Unified Convolutional Beamformer", ["Tomohiro Nakatani", "Keisuke Kinoshita"], "https://doi.org/10.21437/Interspeech.2019-1286", 5, "interspeech", 2019], ["End-to-End SpeakerBeam for Single Channel Target Speech Recognition", ["Marc Delcroix", "Shinji Watanabe", "Tsubasa Ochiai", "Keisuke Kinoshita", "Shigeki Karita", "Atsunori Ogawa", "Tomohiro Nakatani"], "https://doi.org/10.21437/Interspeech.2019-1856", 5, "interspeech", 2019], ["Improving Transformer-Based End-to-End Speech Recognition with Connectionist Temporal Classification and Language Model Integration", ["Shigeki Karita", "Nelson Enrique Yalta Soplin", "Shinji Watanabe", "Marc Delcroix", "Atsunori Ogawa", "Tomohiro Nakatani"], "https://doi.org/10.21437/Interspeech.2019-1938", 5, "interspeech", 2019], ["Multimodal SpeakerBeam: Single Channel Target Speech Extraction with Audio-Visual Speaker Clues", ["Tsubasa Ochiai", "Marc Delcroix", "Keisuke Kinoshita", "Atsunori Ogawa", "Tomohiro Nakatani"], "https://doi.org/10.21437/Interspeech.2019-1513", 5, "interspeech", 2019], ["Improved Deep Duel Model for Rescoring N-Best Speech Recognition List Using Backward LSTMLM and Ensemble Encoders", ["Atsunori Ogawa", "Marc Delcroix", "Shigeki Karita", "Tomohiro Nakatani"], "https://doi.org/10.21437/Interspeech.2019-1949", 5, "interspeech", 2019], ["Predicting Speech Intelligibility of Enhanced Speech Using Phone Accuracy of DNN-Based ASR System", ["Kenichi Arai", "Shoko Araki", "Atsunori Ogawa", "Keisuke Kinoshita", "Tomohiro Nakatani", "Katsuhiko Yamamoto", "Toshio Irino"], "https://doi.org/10.21437/Interspeech.2019-1381", 5, "interspeech", 2019]], "Gregor Hofer": [0, ["Analysis of Deep Learning Architectures for Cross-Corpus Speech Emotion Recognition", ["Jack Parry", "Dimitri Palaz", "Georgia Clarke", "Pauline Lecomte", "Rebecca Mead", "Michael Berger", "Gregor Hofer"], "https://doi.org/10.21437/Interspeech.2019-2753", 5, "interspeech", 2019]], "Saikiran Valluri": [0, ["CaptionAI: A Real-Time Multilingual Captioning Application", ["Nagendra Kumar Goel", "Mousmita Sarma", "Saikiran Valluri", "Dharmeshkumar Agrawal", "Steve Braich", "Tejendra Singh Kuswah", "Zikra Iqbal", "Surbhi Chauhan", "Raj Karbar"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8039.html", 2, "interspeech", 2019]], "Fabian Ritz": [0, ["Deep Neural Baselines for Computational Paralinguistics", ["Daniel Elsner", "Stefan Langer", "Fabian Ritz", "Robert Muller", "Steffen Illium"], "https://doi.org/10.21437/Interspeech.2019-2478", 5, "interspeech", 2019]], "Ruben San Segundo": [0, ["Attention-Based Word Vector Prediction with LSTMs and its Application to the OOV Problem in ASR", ["Alejandro Coucheiro-Limeres", "Fernando Fernandez-Martinez", "Ruben San Segundo", "Javier Ferreiros Lopez"], "https://doi.org/10.21437/Interspeech.2019-2347", 5, "interspeech", 2019]], "Hsi-Wei Hsieh": [0, ["Automated Emotion Morphing in Speech Based on Diffeomorphic Curve Registration and Highway Networks", ["Ravi Shankar", "Hsi-Wei Hsieh", "Nicolas Charon", "Archana Venkataraman"], "https://doi.org/10.21437/Interspeech.2019-2386", 5, "interspeech", 2019]], "Stephane Lehericy": [0, ["Comparison of Telephone Recordings and Professional Microphone Recordings for Early Detection of Parkinson's Disease, Using Mel-Frequency Cepstral Coefficients with Gaussian Mixture Models", ["Laetitia Jeancolas", "Graziella Mangone", "Jean-Christophe Corvol", "Marie Vidailhet", "Stephane Lehericy", "Badr-Eddine Benkelfat", "Habib Benali", "Dijana Petrovska-Delacretaz"], "https://doi.org/10.21437/Interspeech.2019-2825", 5, "interspeech", 2019]], "Jing Huang": [0, ["Speaker Diarization with Lexical Information", ["Tae Jin Park", "Kyu J. Han", "Jing Huang", "Xiaodong He", "Bowen Zhou", "Panayiotis G. Georgiou", "Shrikanth Narayanan"], "https://doi.org/10.21437/Interspeech.2019-1947", 5, "interspeech", 2019], ["I4U Submission to NIST SRE 2018: Leveraging from a Decade of Shared Experiences", ["Kong Aik Lee", "Ville Hautamaki", "Tomi H. Kinnunen", "Hitoshi Yamamoto", "Koji Okabe", "Ville Vestman", "Jing Huang", "Guohong Ding", "Hanwu Sun", "Anthony Larcher", "Rohan Kumar Das", "Haizhou Li", "Mickael Rouvier", "Pierre-Michel Bousquet", "Wei Rao", "Qing Wang", "Chunlei Zhang", "Fahimeh Bahmaninezhad", "Hector Delgado", "Massimiliano Todisco"], "https://doi.org/10.21437/Interspeech.2019-1533", 5, "interspeech", 2019], ["Multi-Stride Self-Attention for Speech Recognition", ["Kyu J. Han", "Jing Huang", "Yun Tang", "Xiaodong He", "Bowen Zhou"], "https://doi.org/10.21437/Interspeech.2019-1973", 5, "interspeech", 2019]], "Tiago H. Falk": [0, ["Blind Channel Response Estimation for Replay Attack Detection", ["Anderson R. Avila", "Md. Jahangir Alam", "Douglas D. OShaughnessy", "Tiago H. Falk"], "https://doi.org/10.21437/Interspeech.2019-2956", 5, "interspeech", 2019], ["Combining Speaker Recognition and Metric Learning for Speaker-Dependent Representation Learning", ["Joao Monteiro", "Md. Jahangir Alam", "Tiago H. Falk"], "https://doi.org/10.21437/Interspeech.2019-2974", 5, "interspeech", 2019]], "Jun Du": [0, ["The Second DIHARD Diarization Challenge: Dataset, Task, and Baselines", ["Neville Ryant", "Kenneth Church", "Christopher Cieri", "Alejandrina Cristia", "Jun Du", "Sriram Ganapathy", "Mark Liberman"], "https://doi.org/10.21437/Interspeech.2019-1268", 5, "interspeech", 2019], ["Multi-Task Learning with High-Order Statistics for x-Vector Based Text-Independent Speaker Verification", ["Lanhua You", "Wu Guo", "Li-Rong Dai", "Jun Du"], "https://doi.org/10.21437/Interspeech.2019-2264", 5, "interspeech", 2019], ["Deep Neural Network Embeddings with Gating Mechanisms for Text-Independent Speaker Verification", ["Lanhua You", "Wu Guo", "Li-Rong Dai", "Jun Du"], "https://doi.org/10.21437/Interspeech.2019-1746", 5, "interspeech", 2019], ["Acoustic Model Ensembling Using Effective Data Augmentation for CHiME-5 Challenge", ["Feng Ma", "Li Chai", "Jun Du", "Diyuan Liu", "Zhongfu Ye", "Chin-Hui Lee"], "https://doi.org/10.21437/Interspeech.2019-2601", 5, "interspeech", 2019], ["KL-Divergence Regularized Deep Neural Network Adaptation for Low-Resource Speaker-Dependent Speech Enhancement", ["Li Chai", "Jun Du", "Chin-Hui Lee"], "https://doi.org/10.21437/Interspeech.2019-2426", 5, "interspeech", 2019], ["A Cross-Entropy-Guided (CEG) Measure for Speech Enhancement Front-End Assessing Performances of Back-End Automatic Speech Recognition", ["Li Chai", "Jun Du", "Chin-Hui Lee"], "https://doi.org/10.21437/Interspeech.2019-2511", 5, "interspeech", 2019], ["A Hybrid Approach to Acoustic Scene Classification Based on Universal Acoustic Models", ["Xue Bai", "Jun Du", "Zi-Rui Wang", "Chin-Hui Lee"], "https://doi.org/10.21437/Interspeech.2019-2171", 5, "interspeech", 2019], ["Neural Text Clustering with Document-Level Attention Based on Dynamic Soft Labels", ["Zhi Chen", "Wu Guo", "Li-Rong Dai", "Zhen-Hua Ling", "Jun Du"], "https://doi.org/10.21437/Interspeech.2019-1417", 5, "interspeech", 2019]], "Ian McGraw": [0, ["Two-Pass End-to-End Speech Recognition", ["Tara N. Sainath", "Ruoming Pang", "David Rybach", "Yanzhang He", "Rohit Prabhavalkar", "Wei Li", "Mirko Visontai", "Qiao Liang", "Trevor Strohman", "Yonghui Wu", "Ian McGraw", "Chung-Cheng Chiu"], "https://doi.org/10.21437/Interspeech.2019-1341", 5, "interspeech", 2019]], "Renuka Mannem": [0, ["Acoustic and Articulatory Feature Based Speech Rate Estimation Using a Convolutional Dense Neural Network", ["Renuka Mannem", "Jhansi Mallela", "Aravind Illa", "Prasanta Kumar Ghosh"], "https://doi.org/10.21437/Interspeech.2019-2295", 5, "interspeech", 2019]], "Hye-jin Shim": [0.820603758096695, ["Acoustic Scene Classification Using Teacher-Student Learning with Soft-Labels", ["Hee-Soo Heo", "Jee-weon Jung", "Hye-jin Shim", "Ha-Jin Yu"], "https://doi.org/10.21437/Interspeech.2019-1989", 5, "interspeech", 2019], ["Replay Attack Detection with Complementary High-Resolution Information Using End-to-End DNN for the ASVspoof 2019 Challenge", ["Jee-weon Jung", "Hye-jin Shim", "Hee-Soo Heo", "Ha-Jin Yu"], "https://doi.org/10.21437/Interspeech.2019-1991", 5, "interspeech", 2019], ["RawNet: Advanced End-to-End Deep Neural Network Using Raw Waveforms for Text-Independent Speaker Verification", ["Jee-weon Jung", "Hee-Soo Heo", "Ju-ho Kim", "Hye-jin Shim", "Ha-Jin Yu"], "https://doi.org/10.21437/Interspeech.2019-1982", 5, "interspeech", 2019], ["End-to-End Losses Based on Speaker Basis Vectors and All-Speaker Hard Negative Mining for Speaker Verification", ["Hee-Soo Heo", "Jee-weon Jung", "Il-Ho Yang", "Sung-Hyun Yoon", "Hye-jin Shim", "Ha-Jin Yu"], "https://doi.org/10.21437/Interspeech.2019-1986", 5, "interspeech", 2019]], "Ido Amir": [0, ["GECKO - A Tool for Effective Annotation of Human Conversations", ["Golan Levy", "Raquel Sitman", "Ido Amir", "Eduard Golshtein", "Ran Mochary", "Eilon Reshef", "Roi Reichart", "Omri Allouche"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8025.html", 2, "interspeech", 2019]], "Kenta Wakasa": [0, ["Investigating the Physiological and Acoustic Contrasts Between Choral and Operatic Singing", ["Hiroko Terasawa", "Kenta Wakasa", "Hideki Kawahara", "Ken-Ichi Sakakibara"], "https://doi.org/10.21437/Interspeech.2019-1864", 5, "interspeech", 2019]], "Ya-Qi Yu": [0.0002151111330022104, ["Deep Hashing for Speaker Identification and Retrieval", ["Lei Fan", "Qing-Yuan Jiang", "Ya-Qi Yu", "Wu-Jun Li"], "https://doi.org/10.21437/Interspeech.2019-2457", 5, "interspeech", 2019]], "Liang Lu": [0, ["Self-Teaching Networks", ["Liang Lu", "Eric Sun", "Yifan Gong"], "https://doi.org/10.21437/Interspeech.2019-1467", 5, "interspeech", 2019]], "Tyson S. Barrett": [0, ["Do Conversational Partners Entrain on Articulatory Precision?", ["Nichola Lubold", "Stephanie A. Borrie", "Tyson S. Barrett", "Megan M. Willi", "Visar Berisha"], "https://doi.org/10.21437/Interspeech.2019-1786", 5, "interspeech", 2019]], "Jeih-weih Hung": [0, ["Speaker-Aware Deep Denoising Autoencoder with Embedded Speaker Identity for Speech Enhancement", ["Fu-Kai Chuang", "Syu-Siang Wang", "Jeih-weih Hung", "Yu Tsao", "Shih-Hau Fang"], "https://doi.org/10.21437/Interspeech.2019-2108", 5, "interspeech", 2019]], "Mattias Heldner": [0, ["Voice Quality as a Turn-Taking Cue", ["Mattias Heldner", "Marcin Wlodarczak", "Stefan Benus", "Agustin Gravano"], "https://doi.org/10.21437/Interspeech.2019-1592", 5, "interspeech", 2019]], "Cecile Fougeron": [0, ["Are IP Initial Vowels Acoustically More Distinct? Results from LDA and CNN Classifications", ["Fanny Guitard-Ivent", "Gabriele Chignoli", "Cecile Fougeron", "Laurianne Georgeton"], "https://doi.org/10.21437/Interspeech.2019-2153", 5, "interspeech", 2019]], "Jordan L. Boyd-Graber": [0, ["Mitigating Noisy Inputs for Question Answering", ["Denis Peskov", "Joe Barrow", "Pedro Rodriguez", "Graham Neubig", "Jordan L. Boyd-Graber"], "https://doi.org/10.21437/Interspeech.2019-3154", 5, "interspeech", 2019]], "Marie Vidailhet": [0, ["Comparison of Telephone Recordings and Professional Microphone Recordings for Early Detection of Parkinson's Disease, Using Mel-Frequency Cepstral Coefficients with Gaussian Mixture Models", ["Laetitia Jeancolas", "Graziella Mangone", "Jean-Christophe Corvol", "Marie Vidailhet", "Stephane Lehericy", "Badr-Eddine Benkelfat", "Habib Benali", "Dijana Petrovska-Delacretaz"], "https://doi.org/10.21437/Interspeech.2019-2825", 5, "interspeech", 2019]], "Lise Rebout": [0, ["CRIM's Speech Transcription and Call Sign Detection System for the ATC Airbus Challenge Task", ["Vishwa Gupta", "Lise Rebout", "Gilles Boulianne", "Pierre Andre Menard", "Jahangir Alam"], "https://doi.org/10.21437/Interspeech.2019-1131", 5, "interspeech", 2019]], "Hanna Nelson": [0, ["NITK Kids' Speech Corpus", ["Pravin Bhaskar Ramteke", "Sujata Supanekar", "Pradyoth Hegde", "Hanna Nelson", "Venkataraja Aithal", "Shashidhar G. Koolagudi"], "https://doi.org/10.21437/Interspeech.2019-2061", 5, "interspeech", 2019]], "David Rybach": [0, ["Shallow-Fusion End-to-End Contextual Biasing", ["Ding Zhao", "Tara N. Sainath", "David Rybach", "Pat Rondon", "Deepti Bhatia", "Bo Li", "Ruoming Pang"], "https://doi.org/10.21437/Interspeech.2019-1209", 5, "interspeech", 2019], ["Two-Pass End-to-End Speech Recognition", ["Tara N. Sainath", "Ruoming Pang", "David Rybach", "Yanzhang He", "Rohit Prabhavalkar", "Wei Li", "Mirko Visontai", "Qiao Liang", "Trevor Strohman", "Yonghui Wu", "Ian McGraw", "Chung-Cheng Chiu"], "https://doi.org/10.21437/Interspeech.2019-1341", 5, "interspeech", 2019], ["On the Choice of Modeling Unit for Sequence-to-Sequence Speech Recognition", ["Kazuki Irie", "Rohit Prabhavalkar", "Anjuli Kannan", "Antoine Bruguier", "David Rybach", "Patrick Nguyen"], "https://doi.org/10.21437/Interspeech.2019-2277", 5, "interspeech", 2019]], "Ioannis Gkinis": [0, ["Detecting Spoofing Attacks Using VGG and SincNet: BUT-Omilia Submission to ASVspoof 2019 Challenge", ["Hossein Zeinali", "Themos Stafylakis", "Georgia Athanasopoulou", "Johan Rohdin", "Ioannis Gkinis", "Lukas Burget", "Jan Cernocky"], "https://doi.org/10.21437/Interspeech.2019-2892", 5, "interspeech", 2019]], "Neville Ryant": [0, ["The Second DIHARD Diarization Challenge: Dataset, Task, and Baselines", ["Neville Ryant", "Kenneth Church", "Christopher Cieri", "Alejandrina Cristia", "Jun Du", "Sriram Ganapathy", "Mark Liberman"], "https://doi.org/10.21437/Interspeech.2019-1268", 5, "interspeech", 2019], ["Automatic Detection of Autism Spectrum Disorder in Children Using Acoustic and Text Features from Brief Natural Conversations", ["Sunghye Cho", "Mark Liberman", "Neville Ryant", "Meredith Cola", "Robert T. Schultz", "Julia Parish-Morris"], "https://doi.org/10.21437/Interspeech.2019-1452", 5, "interspeech", 2019]], "Manwa L. Ng": [0, ["Towards the Speech Features of Mild Cognitive Impairment: Universal Evidence from Structured and Unstructured Connected Speech of Chinese", ["Tianqi Wang", "Chongyuan Lian", "Jingshen Pan", "Quanlei Yan", "Feiqi Zhu", "Manwa L. Ng", "Lan Wang", "Nan Yan"], "https://doi.org/10.21437/Interspeech.2019-2414", 5, "interspeech", 2019]], "Chun-Min Chang": [0.46355031430721283, ["Predicting Group Performances Using a Personality Composite-Network Architecture During Collaborative Task", ["Shun-Chang Zhong", "Yun-Shao Lin", "Chun-Min Chang", "Yi-Ching Liu", "Chi-Chun Lee"], "https://doi.org/10.21437/Interspeech.2019-2087", 5, "interspeech", 2019], ["Enforcing Semantic Consistency for Cross Corpus Valence Regression from Speech Using Adversarial Discrepancy Learning", ["Gao-Yi Chao", "Yun-Shao Lin", "Chun-Min Chang", "Chi-Chun Lee"], "https://doi.org/10.21437/Interspeech.2019-2037", 5, "interspeech", 2019]], "Mohit Goyal": [0, ["Detection of Glottal Closure Instants from Raw Speech Using Convolutional Neural Networks", ["Mohit Goyal", "Varun Srivastava", "Prathosh A. P."], "https://doi.org/10.21437/Interspeech.2019-2587", 5, "interspeech", 2019]], "Yang Lu": [0, ["Optimizing Speech-Input Length for Speaker-Independent Depression Classification", ["Tomasz Rutowski", "Amir Harati", "Yang Lu", "Elizabeth Shriberg"], "https://doi.org/10.21437/Interspeech.2019-3095", 5, "interspeech", 2019]], "Yanmin Qian": [0, ["The SJTU Robust Anti-Spoofing System for the ASVspoof 2019 Challenge", ["Yexin Yang", "Hongji Wang", "Heinrich Dinkel", "Zhengyang Chen", "Shuai Wang", "Yanmin Qian", "Kai Yu"], "https://doi.org/10.21437/Interspeech.2019-2170", 5, "interspeech", 2019], ["On the Usage of Phonetic Information for Text-Independent Speaker Embedding Extraction", ["Shuai Wang", "Johan Rohdin", "Lukas Burget", "Oldrich Plchot", "Yanmin Qian", "Kai Yu", "Jan Cernocky"], "https://doi.org/10.21437/Interspeech.2019-3036", 5, "interspeech", 2019], ["Data Augmentation Using Variational Autoencoder for Embedding Based Speaker Verification", ["Zhanghao Wu", "Shuai Wang", "Yanmin Qian", "Kai Yu"], "https://doi.org/10.21437/Interspeech.2019-2248", 5, "interspeech", 2019], ["Joint Decoding of CTC Based Systems for Speech Recognition", ["Jiaqi Guo", "Yongbin You", "Yanmin Qian", "Kai Yu"], "https://doi.org/10.21437/Interspeech.2019-2026", 5, "interspeech", 2019], ["Knowledge Distillation for End-to-End Monaural Multi-Talker ASR System", ["Wangyou Zhang", "Xuankai Chang", "Yanmin Qian"], "https://doi.org/10.21437/Interspeech.2019-3192", 5, "interspeech", 2019], ["Robust DOA Estimation Based on Convolutional Neural Network and Time-Frequency Masking", ["Wangyou Zhang", "Ying Zhou", "Yanmin Qian"], "https://doi.org/10.21437/Interspeech.2019-3158", 5, "interspeech", 2019], ["Cross-Domain Replay Spoofing Attack Detection Using Domain Adversarial Training", ["Hongji Wang", "Heinrich Dinkel", "Shuai Wang", "Yanmin Qian", "Kai Yu"], "https://doi.org/10.21437/Interspeech.2019-2120", 5, "interspeech", 2019], ["Prosody Usage Optimization for Children Speech Recognition with Zero Resource Children Speech", ["Chenda Li", "Yanmin Qian"], "https://doi.org/10.21437/Interspeech.2019-2659", 5, "interspeech", 2019]], "Julie A. Wall": [0, ["Explaining Sentiment Classification", ["Marvin Rajwadi", "Cornelius Glackin", "Julie A. Wall", "Gerard Chollet", "Nigel Cannings"], "https://doi.org/10.21437/Interspeech.2019-2743", 5, "interspeech", 2019]], "Kowovi Comivi Alowonou": [0, ["Acoustic and Articulatory Study of Ewe Vowels: A Comparative Study of Male and Female", ["Kowovi Comivi Alowonou", "Jianguo Wei", "Wenhuan Lu", "Zhicheng Liu", "Kiyoshi Honda", "Jianwu Dang"], "https://doi.org/10.21437/Interspeech.2019-2196", 5, "interspeech", 2019]], "Renato De Mori": [0, ["Real to H-Space Encoder for Speech Recognition", ["Titouan Parcollet", "Mohamed Morchid", "Georges Linares", "Renato De Mori"], "https://doi.org/10.21437/Interspeech.2019-1539", 5, "interspeech", 2019]], "Kathryn P. Connaghan": [0, ["Use of Beiwe Smartphone App to Identify and Track Speech Decline in Amyotrophic Lateral Sclerosis (ALS)", ["Kathryn P. Connaghan", "Jordan R. Green", "Sabrina Paganoni", "James Chan", "Harli Weber", "Ella Collins", "Brian Richburg", "Marziye Eshghi", "Jukka-Pekka Onnela", "James D. Berry"], "https://doi.org/10.21437/Interspeech.2019-3126", 5, "interspeech", 2019]], "Ashtosh Sapru": [0, ["Multi-Dialect Acoustic Modeling Using Phone Mapping and Online i-Vectors", ["Harish Arsikere", "Ashtosh Sapru", "Sri Garimella"], "https://doi.org/10.21437/Interspeech.2019-2881", 5, "interspeech", 2019]], "Hu Xu": [0, ["Robust Keyword Spotting via Recycle-Pooling for Mobile Game", ["Shounan An", "Youngsoo Kim", "Hu Xu", "Jinwoo Lee", "Myungwoo Lee", "Insoo Oh"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8010.html", 2, "interspeech", 2019]], "Petra Wagner": [0, ["Laughter Dynamics in Dyadic Conversations", ["Bogdan Ludusan", "Petra Wagner"], "https://doi.org/10.21437/Interspeech.2019-1733", 5, "interspeech", 2019], ["A User-Friendly and Adaptable Re-Implementation of an Acoustic Prominence Detection and Annotation Tool", ["Jana Vosse", "Petra Wagner"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8015.html", 2, "interspeech", 2019], ["Pitch Accent Trajectories Across Different Conditions of Visibility and Information Structure - Evidence from Spontaneous Dyadic Interaction", ["Petra Wagner", "Nataliya Bryhadyr", "Marin Schroer"], "https://doi.org/10.21437/Interspeech.2019-1619", 5, "interspeech", 2019], ["The Greennn Tree - Lengthening Position Influences Uncertainty Perception", ["Simon Betz", "Sina Zarriess", "Eva Szekely", "Petra Wagner"], "https://doi.org/10.21437/Interspeech.2019-2572", 5, "interspeech", 2019]], "Sravani Gottimukkala": [0, ["SPIRE-fluent: A Self-Learning App for Tutoring Oral Fluency to Second Language English Learners", ["Chiranjeevi Yarra", "Aparna Srinivasan", "Sravani Gottimukkala", "Prasanta Kumar Ghosh"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8008.html", 2, "interspeech", 2019]], "Elika Bergelson": [0, ["The INTERSPEECH 2019 Computational Paralinguistics Challenge: Styrian Dialects, Continuous Sleepiness, Baby Sounds & Orca Activity", ["Bjorn W. Schuller", "Anton Batliner", "Christian Bergler", "Florian B. Pokorny", "Jarek Krajewski", "Margaret Cychosz", "Ralf Vollmann", "Sonja-Dana Roelen", "Sebastian Schnieder", "Elika Bergelson", "Alejandrina Cristia", "Amanda Seidl", "Anne S. Warlaumont", "Lisa Yankowitz", "Elmar Noth", "Shahin Amiriparian", "Simone Hantke", "Maximilian Schmitt"], "https://doi.org/10.21437/Interspeech.2019-1122", 5, "interspeech", 2019]], "Chandra Sekhar Seelamantula": [0, ["On the Suitability of the Riesz Spectro-Temporal Envelope for WaveNet Based Speech Synthesis", ["Jitendra Kumar Dhiman", "Nagaraj Adiga", "Chandra Sekhar Seelamantula"], "https://doi.org/10.21437/Interspeech.2019-2626", 5, "interspeech", 2019]], "Hannah Muckenhirn": [0, ["Understanding and Visualizing Raw Waveform-Based CNNs", ["Hannah Muckenhirn", "Vinayak Abrol", "Mathew Magimai-Doss", "Sebastien Marcel"], "https://doi.org/10.21437/Interspeech.2019-2341", 5, "interspeech", 2019], ["VoiceFilter: Targeted Voice Separation by Speaker-Conditioned Spectrogram Masking", ["Quan Wang", "Hannah Muckenhirn", "Kevin W. Wilson", "Prashant Sridhar", "Zelin Wu", "John R. Hershey", "Rif A. Saurous", "Ron J. Weiss", "Ye Jia", "Ignacio Lopez-Moreno"], "https://doi.org/10.21437/Interspeech.2019-1101", 5, "interspeech", 2019]], "Jimeng Zheng": [0, ["Neural Spatial Filter: Target Speaker Speech Separation Assisted with Directional Information", ["Rongzhi Gu", "Lianwu Chen", "Shi-Xiong Zhang", "Jimeng Zheng", "Yong Xu", "Meng Yu", "Dan Su", "Yuexian Zou", "Dong Yu"], "https://doi.org/10.21437/Interspeech.2019-2266", 5, "interspeech", 2019]], "Marie Kunesova": [0, ["UWB-NTIS Speaker Diarization System for the DIHARD II 2019 Challenge", ["Zbynek Zajic", "Marie Kunesova", "Marek Hruz", "Jan Vanek"], "https://doi.org/10.21437/Interspeech.2019-1385", 5, "interspeech", 2019]], "Jian Kang": [0.40413545072078705, ["Multimedia Simultaneous Translation System for Minority Language Communication with Mandarin", ["Shen Huang", "Bojie Hu", "Shan Huang", "Pengfei Hu", "Jian Kang", "Zhiqiang Lv", "Jinghao Yan", "Qi Ju", "Shiyin Kang", "Deyi Tuo", "Guangzhi Li", "Nurmemet Yolwas"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8020.html", 2, "interspeech", 2019]], "Xinyu Li": [0, ["Speech Audio Super-Resolution for Speech Recognition", ["Xinyu Li", "Venkata Chebiyyam", "Katrin Kirchhoff"], "https://doi.org/10.21437/Interspeech.2019-3043", 5, "interspeech", 2019], ["Multi-Stream Network with Temporal Attention for Environmental Sound Classification", ["Xinyu Li", "Venkata Chebiyyam", "Katrin Kirchhoff"], "https://doi.org/10.21437/Interspeech.2019-3019", 5, "interspeech", 2019]], "Jesper Jensen": [0, ["Improvement and Assessment of Spectro-Temporal Modulation Analysis for Speech Intelligibility Estimation", ["Amin Edraki", "Wai-Yip Chan", "Jesper Jensen", "Daniel Fogerty"], "https://doi.org/10.21437/Interspeech.2019-2898", 5, "interspeech", 2019], ["Keyword Spotting for Hearing Assistive Devices Robust to External Speakers", ["Ivan Lopez-Espejo", "Zheng-Hua Tan", "Jesper Jensen"], "https://doi.org/10.21437/Interspeech.2019-2010", 5, "interspeech", 2019]], "Shrikanth Narayanan": [0, ["Data Augmentation Using GANs for Speech Emotion Recognition", ["Aggelina Chatziagapi", "Georgios Paraskevopoulos", "Dimitris Sgouropoulos", "Georgios Pantazopoulos", "Malvina Nikandrou", "Theodoros Giannakopoulos", "Athanasios Katsamanis", "Alexandros Potamianos", "Shrikanth Narayanan"], "https://doi.org/10.21437/Interspeech.2019-2561", 5, "interspeech", 2019], ["Speaker Diarization with Lexical Information", ["Tae Jin Park", "Kyu J. Han", "Jing Huang", "Xiaodong He", "Bowen Zhou", "Panayiotis G. Georgiou", "Shrikanth Narayanan"], "https://doi.org/10.21437/Interspeech.2019-1947", 5, "interspeech", 2019], ["The Second DIHARD Challenge: System Description for USC-SAIL Team", ["Tae Jin Park", "Manoj Kumar", "Nikolaos Flemotomos", "Monisankha Pal", "Raghuveer Peri", "Rimita Lahiri", "Panayiotis G. Georgiou", "Shrikanth Narayanan"], "https://doi.org/10.21437/Interspeech.2019-1903", 5, "interspeech", 2019], ["Modeling Interpersonal Linguistic Coordination in Conversations Using Word Mover's Distance", ["Md. Nasir", "Sandeep Nallan Chakravarthula", "Brian R. W. Baucom", "David C. Atkins", "Panayiotis G. Georgiou", "Shrikanth Narayanan"], "https://doi.org/10.21437/Interspeech.2019-1900", 5, "interspeech", 2019], ["Identifying Therapist and Client Personae for Therapeutic Alliance Estimation", ["Victor R. Martinez", "Nikolaos Flemotomos", "Victor Ardulov", "Krishna Somandepalli", "Simon B. Goldberg", "Zac E. Imel", "David C. Atkins", "Shrikanth Narayanan"], "https://doi.org/10.21437/Interspeech.2019-2829", 5, "interspeech", 2019], ["Multiview Shared Subspace Learning Across Speakers and Speech Commands", ["Krishna Somandepalli", "Naveen Kumar", "Arindam Jati", "Panayiotis G. Georgiou", "Shrikanth Narayanan"], "https://doi.org/10.21437/Interspeech.2019-3130", 5, "interspeech", 2019], ["Multi-Task Discriminative Training of Hybrid DNN-TVM Model for Speaker Verification with Noisy and Far-Field Speech", ["Arindam Jati", "Raghuveer Peri", "Monisankha Pal", "Tae Jin Park", "Naveen Kumar", "Ruchir Travadi", "Panayiotis G. Georgiou", "Shrikanth Narayanan"], "https://doi.org/10.21437/Interspeech.2019-3010", 5, "interspeech", 2019]], "Chung-Cheng Chiu": [0, ["SpecAugment: A Simple Data Augmentation Method for Automatic Speech Recognition", ["Daniel S. Park", "William Chan", "Yu Zhang", "Chung-Cheng Chiu", "Barret Zoph", "Ekin D. Cubuk", "Quoc V. Le"], "https://doi.org/10.21437/Interspeech.2019-2680", 5, "interspeech", 2019], ["Two-Pass End-to-End Speech Recognition", ["Tara N. Sainath", "Ruoming Pang", "David Rybach", "Yanzhang He", "Rohit Prabhavalkar", "Wei Li", "Mirko Visontai", "Qiao Liang", "Trevor Strohman", "Yonghui Wu", "Ian McGraw", "Chung-Cheng Chiu"], "https://doi.org/10.21437/Interspeech.2019-1341", 5, "interspeech", 2019]], "Anastassia Loukina": [0, ["Automated Estimation of Oral Reading Fluency During Summer Camp e-Book Reading with MyTurnToRead", ["Anastassia Loukina", "Beata Beigman Klebanov", "Patrick L. Lange", "Yao Qian", "Binod Gyawali", "Nitin Madnani", "Abhinav Misra", "Klaus Zechner", "Zuowei Wang", "John Sabatini"], "https://doi.org/10.21437/Interspeech.2019-2889", 5, "interspeech", 2019]], "Ermine Teves": [0, ["Leveraging Acoustic Cues and Paralinguistic Embeddings to Detect Expression from Voice", ["Vikramjit Mitra", "Sue Booker", "Erik Marchi", "David Scott Farrar", "Ute Dorothea Peitz", "Bridget Cheng", "Ermine Teves", "Anuj Mehta", "Devang Naik"], "https://doi.org/10.21437/Interspeech.2019-2998", 5, "interspeech", 2019]], "Rong Tong": [0, ["Multi-Task Multi-Network Joint-Learning of Deep Residual Networks and Cycle-Consistency Generative Adversarial Networks for Robust Speech Recognition", ["Shengkui Zhao", "Chongjia Ni", "Rong Tong", "Bin Ma"], "https://doi.org/10.21437/Interspeech.2019-2078", 5, "interspeech", 2019]], "Alan W. Black": [0, ["The Zero Resource Speech Challenge 2019: TTS Without T", ["Ewan Dunbar", "Robin Algayres", "Julien Karadayi", "Mathieu Bernard", "Juan Benjumea", "Xuan-Nga Cao", "Lucie Miskic", "Charlotte Dugrain", "Lucas Ondel", "Alan W. Black", "Laurent Besacier", "Sakriani Sakti", "Emmanuel Dupoux"], "https://doi.org/10.21437/Interspeech.2019-2904", 5, "interspeech", 2019], ["Unsupervised Phonetic and Word Level Discovery for Speech to Speech Translation for Unwritten Languages", ["Steven Hillis", "Anushree Prasanna Kumar", "Alan W. Black"], "https://doi.org/10.21437/Interspeech.2019-3026", 5, "interspeech", 2019], ["Bag-of-Acoustic-Words for Mental Health Assessment: A Deep Autoencoding Approach", ["Wenchao Du", "Louis-Philippe Morency", "Jeffrey F. Cohn", "Alan W. Black"], "https://doi.org/10.21437/Interspeech.2019-3059", 5, "interspeech", 2019], ["Multilingual Speech Recognition with Corpus Relatedness Sampling", ["Xinjian Li", "Siddharth Dalmia", "Alan W. Black", "Florian Metze"], "https://doi.org/10.21437/Interspeech.2019-3052", 5, "interspeech", 2019], ["Ordinal Triplet Loss: Investigating Sleepiness Detection from Speech", ["Peter Wu", "Sai Krishna Rallabandi", "Alan W. Black", "Eric Nyberg"], "https://doi.org/10.21437/Interspeech.2019-2278", 5, "interspeech", 2019], ["SANTLR: Speech Annotation Toolkit for Low Resource Languages", ["Xinjian Li", "Zhong Zhou", "Siddharth Dalmia", "Alan W. Black", "Florian Metze"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8040.html", 2, "interspeech", 2019], ["Variational Attention Using Articulatory Priors for Generating Code Mixed Speech Using Monolingual Corpora", ["Sai Krishna Rallabandi", "Alan W. Black"], "https://doi.org/10.21437/Interspeech.2019-1103", 5, "interspeech", 2019]], "David S. Kung": [2.5525283969818346e-10, ["A Highly Efficient Distributed Deep Learning System for Automatic Speech Recognition", ["Wei Zhang", "Xiaodong Cui", "Ulrich Finkler", "George Saon", "Abdullah Kayi", "Alper Buyuktosunoglu", "Brian Kingsbury", "David S. Kung", "Michael Picheny"], "https://doi.org/10.21437/Interspeech.2019-2700", 5, "interspeech", 2019]], "Ville Vestman": [0, ["Unleashing the Unused Potential of i-Vectors Enabled by GPU Acceleration", ["Ville Vestman", "Kong Aik Lee", "Tomi H. Kinnunen", "Takafumi Koshinaka"], "https://doi.org/10.21437/Interspeech.2019-1955", 5, "interspeech", 2019], ["ASVspoof 2019: Future Horizons in Spoofed and Fake Audio Detection", ["Massimiliano Todisco", "Xin Wang", "Ville Vestman", "Md. Sahidullah", "Hector Delgado", "Andreas Nautsch", "Junichi Yamagishi", "Nicholas W. D. Evans", "Tomi H. Kinnunen", "Kong Aik Lee"], "https://doi.org/10.21437/Interspeech.2019-2249", 5, "interspeech", 2019], ["I4U Submission to NIST SRE 2018: Leveraging from a Decade of Shared Experiences", ["Kong Aik Lee", "Ville Hautamaki", "Tomi H. Kinnunen", "Hitoshi Yamamoto", "Koji Okabe", "Ville Vestman", "Jing Huang", "Guohong Ding", "Hanwu Sun", "Anthony Larcher", "Rohan Kumar Das", "Haizhou Li", "Mickael Rouvier", "Pierre-Michel Bousquet", "Wei Rao", "Qing Wang", "Chunlei Zhang", "Fahimeh Bahmaninezhad", "Hector Delgado", "Massimiliano Todisco"], "https://doi.org/10.21437/Interspeech.2019-1533", 5, "interspeech", 2019]], "Ryota Kaminishi": [0, ["Investigation on Blind Bandwidth Extension with a Non-Linear Function and its Evaluation of x-Vector-Based Speaker Verification", ["Ryota Kaminishi", "Haruna Miyamoto", "Sayaka Shiota", "Hitoshi Kiya"], "https://doi.org/10.21437/Interspeech.2019-1510", 5, "interspeech", 2019]], "Beata Beigman Klebanov": [0, ["Automated Estimation of Oral Reading Fluency During Summer Camp e-Book Reading with MyTurnToRead", ["Anastassia Loukina", "Beata Beigman Klebanov", "Patrick L. Lange", "Yao Qian", "Binod Gyawali", "Nitin Madnani", "Abhinav Misra", "Klaus Zechner", "Zuowei Wang", "John Sabatini"], "https://doi.org/10.21437/Interspeech.2019-2889", 5, "interspeech", 2019]], "Jungyun Eum": [0.8612027019262314, ["An End-to-End Text-Independent Speaker Verification Framework with a Keyword Adversarial Network", ["Sungrack Yun", "Janghoon Cho", "Jungyun Eum", "Wonil Chang", "Kyuwoong Hwang"], "https://doi.org/10.21437/Interspeech.2019-2208", 5, "interspeech", 2019]], "Hector A. Sanchez-Hevia": [0, ["Investigating the Effects of Noisy and Reverberant Speech in Text-to-Speech Systems", ["David Ayllon", "Hector A. Sanchez-Hevia", "Carol Figueroa", "Pierre Lanchantin"], "https://doi.org/10.21437/Interspeech.2019-3104", 5, "interspeech", 2019]], "Tomoki Koriyama": [0, ["Semi-Supervised Prosody Modeling Using Deep Gaussian Process Latent Variable Model", ["Tomoki Koriyama", "Takao Kobayashi"], "https://doi.org/10.21437/Interspeech.2019-2497", 5, "interspeech", 2019]], "Michal Zapotoczny": [0, ["Lattice Generation in Attention-Based Speech Recognition Models", ["Michal Zapotoczny", "Piotr Pietrzak", "Adrian Lancucki", "Jan Chorowski"], "https://doi.org/10.21437/Interspeech.2019-2667", 5, "interspeech", 2019], ["Towards Using Context-Dependent Symbols in CTC Without State-Tying Decision Trees", ["Jan Chorowski", "Adrian Lancucki", "Bartosz Kostka", "Michal Zapotoczny"], "https://doi.org/10.21437/Interspeech.2019-2720", 5, "interspeech", 2019]], "Yushi Aono": [0, ["Improving Conversation-Context Language Models with Multiple Spoken Language Understanding Models", ["Ryo Masumura", "Tomohiro Tanaka", "Atsushi Ando", "Hosana Kamiyama", "Takanobu Oba", "Satoshi Kobashikawa", "Yushi Aono"], "https://doi.org/10.21437/Interspeech.2019-1534", 5, "interspeech", 2019], ["A Joint End-to-End and DNN-HMM Hybrid Automatic Speech Recognition System with Transferring Sharable Knowledge", ["Tomohiro Tanaka", "Ryo Masumura", "Takafumi Moriya", "Takanobu Oba", "Yushi Aono"], "https://doi.org/10.21437/Interspeech.2019-2263", 5, "interspeech", 2019], ["Speech Emotion Recognition Based on Multi-Label Emotion Existence Model", ["Atsushi Ando", "Ryo Masumura", "Hosana Kamiyama", "Satoshi Kobashikawa", "Yushi Aono"], "https://doi.org/10.21437/Interspeech.2019-2524", 5, "interspeech", 2019], ["Neural Whispered Speech Detection with Imbalanced Learning", ["Takanori Ashihara", "Yusuke Shinohara", "Hiroshi Sato", "Takafumi Moriya", "Kiyoaki Matsui", "Takaaki Fukutomi", "Yoshikazu Yamaguchi", "Yushi Aono"], "https://doi.org/10.21437/Interspeech.2019-2161", 5, "interspeech", 2019], ["Joint Maximization Decoder with Neural Converters for Fully Neural Network-Based Japanese Speech Recognition", ["Takafumi Moriya", "Jian Wang", "Tomohiro Tanaka", "Ryo Masumura", "Yusuke Shinohara", "Yoshikazu Yamaguchi", "Yushi Aono"], "https://doi.org/10.21437/Interspeech.2019-1558", 5, "interspeech", 2019]], "Morteza Rohanian": [0, ["Detecting Depression with Word-Level Multimodal Fusion", ["Morteza Rohanian", "Julian Hough", "Matthew Purver"], "https://doi.org/10.21437/Interspeech.2019-2283", 5, "interspeech", 2019]], "Tae Jin Park": [0.8472927659749985, ["Speaker Diarization with Lexical Information", ["Tae Jin Park", "Kyu J. Han", "Jing Huang", "Xiaodong He", "Bowen Zhou", "Panayiotis G. Georgiou", "Shrikanth Narayanan"], "https://doi.org/10.21437/Interspeech.2019-1947", 5, "interspeech", 2019], ["The Second DIHARD Challenge: System Description for USC-SAIL Team", ["Tae Jin Park", "Manoj Kumar", "Nikolaos Flemotomos", "Monisankha Pal", "Raghuveer Peri", "Rimita Lahiri", "Panayiotis G. Georgiou", "Shrikanth Narayanan"], "https://doi.org/10.21437/Interspeech.2019-1903", 5, "interspeech", 2019], ["Multi-Task Discriminative Training of Hybrid DNN-TVM Model for Speaker Verification with Noisy and Far-Field Speech", ["Arindam Jati", "Raghuveer Peri", "Monisankha Pal", "Tae Jin Park", "Naveen Kumar", "Ruchir Travadi", "Panayiotis G. Georgiou", "Shrikanth Narayanan"], "https://doi.org/10.21437/Interspeech.2019-3010", 5, "interspeech", 2019]], "Lindy Comstock": [0, ["Identifying Input Features for Development of Real-Time Translation of Neural Signals to Text", ["Janaki Sheth", "Ariel Tankus", "Michelle Tran", "Lindy Comstock", "Itzhak Fried", "William Speier"], "https://doi.org/10.21437/Interspeech.2019-3092", 5, "interspeech", 2019]], "Vladimir Volokhov": [0, ["STC Speaker Recognition Systems for the VOiCES from a Distance Challenge", ["Sergey Novoselov", "Aleksei Gusev", "Artem Ivanov", "Timur Pekhovsky", "Andrey Shulipa", "Galina Lavrentyeva", "Vladimir Volokhov", "Alexandr Kozlov"], "https://doi.org/10.21437/Interspeech.2019-2783", 5, "interspeech", 2019], ["STC Speaker Recognition Systems for the VOiCES from a Distance Challenge", ["Sergey Novoselov", "Aleksei Gusev", "Artem Ivanov", "Timur Pekhovsky", "Andrey Shulipa", "Galina Lavrentyeva", "Vladimir Volokhov", "Alexandr Kozlov"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/abs15.html", 0, "interspeech", 2019]], "Yu-An Chung": [0.18233120441436768, ["An Unsupervised Autoregressive Model for Speech Representation Learning", ["Yu-An Chung", "Wei-Ning Hsu", "Hao Tang", "James R. Glass"], "https://doi.org/10.21437/Interspeech.2019-1473", 5, "interspeech", 2019]], "Jonas Rohnke": [0, ["Fine-Grained Robust Prosody Transfer for Single-Speaker Neural Text-To-Speech", ["Viacheslav Klimkov", "Srikanth Ronanki", "Jonas Rohnke", "Thomas Drugman"], "https://doi.org/10.21437/Interspeech.2019-2571", 5, "interspeech", 2019]], "Mirko Visontai": [0, ["Two-Pass End-to-End Speech Recognition", ["Tara N. Sainath", "Ruoming Pang", "David Rybach", "Yanzhang He", "Rohit Prabhavalkar", "Wei Li", "Mirko Visontai", "Qiao Liang", "Trevor Strohman", "Yonghui Wu", "Ian McGraw", "Chung-Cheng Chiu"], "https://doi.org/10.21437/Interspeech.2019-1341", 5, "interspeech", 2019]], "Mikko Kurimo": [0, ["Transparent Pronunciation Scoring Using Articulatorily Weighted Phoneme Edit Distance", ["Reima Karhila", "Anna-Riikka Smolander", "Sari Ylinen", "Mikko Kurimo"], "https://doi.org/10.21437/Interspeech.2019-1785", 5, "interspeech", 2019], ["Subword RNNLM Approximations for Out-Of-Vocabulary Keyword Search", ["Mittul Singh", "Sami Virpioja", "Peter Smit", "Mikko Kurimo"], "https://doi.org/10.21437/Interspeech.2019-1329", 5, "interspeech", 2019]], "Andre Merboldt": [0, ["An Analysis of Local Monotonic Attention Variants", ["Andre Merboldt", "Albert Zeyer", "Ralf Schluter", "Hermann Ney"], "https://doi.org/10.21437/Interspeech.2019-2879", 5, "interspeech", 2019]], "Chih-Hsiang Huang": [0, ["Acoustic Indicators of Deception in Mandarin Daily Conversations Recorded from an Interactive Game", ["Chih-Hsiang Huang", "Huang-Cheng Chou", "Yi-Tong Wu", "Chi-Chun Lee", "Yi-Wen Liu"], "https://doi.org/10.21437/Interspeech.2019-2216", 5, "interspeech", 2019]], "Daniel Scheran": [0, ["Maximum a posteriori Speech Enhancement Based on Double Spectrum", ["Pejman Mowlaee", "Daniel Scheran", "Johannes Stahl", "Sean U. N. Wood", "W. Bastiaan Kleijn"], "https://doi.org/10.21437/Interspeech.2019-1197", 5, "interspeech", 2019]], "Alice Baird": [0, ["Using Speech to Predict Sequentially Measured Cortisol Levels During a Trier Social Stress Test", ["Alice Baird", "Shahin Amiriparian", "Nicholas Cummins", "Sarah Sturmbauer", "Johanna Janson", "Eva-Maria Messner", "Harald Baumeister", "Nicolas Rohleder", "Bjorn W. Schuller"], "https://doi.org/10.21437/Interspeech.2019-1352", 5, "interspeech", 2019], ["Sincerity in Acted Speech: Presenting the Sincere Apology Corpus and Results", ["Alice Baird", "Eduardo Coutinho", "Julia Hirschberg", "Bjorn W. Schuller"], "https://doi.org/10.21437/Interspeech.2019-1349", 5, "interspeech", 2019]], "Oriol Guasch": [0, ["Survey Talk: Realistic Physics-Based Computational Voice Production", ["Oriol Guasch"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/abs24.html", 0, "interspeech", 2019]], "Takao Kobayashi": [0, ["Semi-Supervised Prosody Modeling Using Deep Gaussian Process Latent Variable Model", ["Tomoki Koriyama", "Takao Kobayashi"], "https://doi.org/10.21437/Interspeech.2019-2497", 5, "interspeech", 2019]], "Liu Liu": [0, ["Deep Attention Gated Dilated Temporal Convolutional Networks with Intra-Parallel Convolutional Modules for End-to-End Monaural Speech Separation", ["Ziqiang Shi", "Huibin Lin", "Liu Liu", "Rujie Liu", "Jiqing Han", "Anyan Shi"], "https://doi.org/10.21437/Interspeech.2019-1373", 5, "interspeech", 2019], ["End-to-End Monaural Speech Separation with Multi-Scale Dynamic Weighted Gated Dilated Convolutional Pyramid Network", ["Ziqiang Shi", "Huibin Lin", "Liu Liu", "Rujie Liu", "Shoji Hayakawa", "Shouji Harada", "Jiqing Han"], "https://doi.org/10.21437/Interspeech.2019-1292", 5, "interspeech", 2019]], "Yunxin Zhao": [0, ["A Novel Method to Correct Steering Vectors in MVDR Beamformer for Noise Robust ASR", ["Suliang Bu", "Yunxin Zhao", "Mei-Yuh Hwang"], "https://doi.org/10.21437/Interspeech.2019-2944", 5, "interspeech", 2019]], "Haishuai Wang": [3.3426786246389963e-15, ["Attention-Enhanced Connectionist Temporal Classification for Discrete Speech Emotion Recognition", ["Ziping Zhao", "Zhongtian Bao", "Zixing Zhang", "Nicholas Cummins", "Haishuai Wang", "Bjorn W. Schuller"], "https://doi.org/10.21437/Interspeech.2019-1649", 5, "interspeech", 2019]], "Christian Fuegen": [0, ["Joint Grapheme and Phoneme Embeddings for Contextual End-to-End ASR", ["Zhehuai Chen", "Mahaveer Jain", "Yongqiang Wang", "Michael L. Seltzer", "Christian Fuegen"], "https://doi.org/10.21437/Interspeech.2019-1434", 5, "interspeech", 2019]], "Petar S. Aleksic": [0, ["Contextual Recovery of Out-of-Lattice Named Entities in Automatic Speech Recognition", ["Jack Serrino", "Leonid Velikovich", "Petar S. Aleksic", "Cyril Allauzen"], "https://doi.org/10.21437/Interspeech.2019-2962", 5, "interspeech", 2019]], "Naoki Sawada": [0, ["Audio Classification of Bit-Representation Waveform", ["Masaki Okawa", "Takuya Saito", "Naoki Sawada", "Hiromitsu Nishizaki"], "https://doi.org/10.21437/Interspeech.2019-1855", 5, "interspeech", 2019]], "Chung-Hsien Wu": [2.071165852157719e-06, ["Follow-Up Question Generation Using Neural Tensor Network-Based Domain Ontology Population in an Interview Coaching System", ["Ming-Hsiang Su", "Chung-Hsien Wu", "Yi Chang"], "https://doi.org/10.21437/Interspeech.2019-1300", 5, "interspeech", 2019]], "Yifan Gong": [0.0002331648356630467, ["Speaker Adaptation for Attention-Based End-to-End Speech Recognition", ["Zhong Meng", "Yashesh Gaur", "Jinyu Li", "Yifan Gong"], "https://doi.org/10.21437/Interspeech.2019-3135", 5, "interspeech", 2019], ["Layer Trajectory BLSTM", ["Eric Sun", "Jinyu Li", "Yifan Gong"], "https://doi.org/10.21437/Interspeech.2019-2971", 5, "interspeech", 2019], ["Acoustic-to-Phrase Models for Speech Recognition", ["Yashesh Gaur", "Jinyu Li", "Zhong Meng", "Yifan Gong"], "https://doi.org/10.21437/Interspeech.2019-3056", 5, "interspeech", 2019], ["Self-Teaching Networks", ["Liang Lu", "Eric Sun", "Yifan Gong"], "https://doi.org/10.21437/Interspeech.2019-1467", 5, "interspeech", 2019]], "Pavel Golik": [0, ["Cumulative Adaptation for BLSTM Acoustic Models", ["Markus Kitza", "Pavel Golik", "Ralf Schluter", "Hermann Ney"], "https://doi.org/10.21437/Interspeech.2019-2162", 5, "interspeech", 2019]], "Kristen M. Scott": [0, ["All Together Now: The Living Audio Dataset", ["David A. Braude", "Matthew P. Aylett", "Caoimhin Laoide-Kemp", "Simone Ashby", "Kristen M. Scott", "Brian O Raghallaigh", "Anna Braudo", "Alex Brouwer", "Adriana Stan"], "https://doi.org/10.21437/Interspeech.2019-2448", 5, "interspeech", 2019]], "Chaitanya Narisetty": [0, ["A Unified Bayesian Source Modelling for Determined Blind Source Separation", ["Chaitanya Narisetty"], "https://doi.org/10.21437/Interspeech.2019-1272", 5, "interspeech", 2019]], "Ievgen Karaulov": [0, ["Attention Model for Articulatory Features Detection", ["Ievgen Karaulov", "Dmytro Tkanov"], "https://doi.org/10.21437/Interspeech.2019-3020", 5, "interspeech", 2019]], "Yongqiang Wang": [1.582056219362471e-08, ["Joint Grapheme and Phoneme Embeddings for Contextual End-to-End ASR", ["Zhehuai Chen", "Mahaveer Jain", "Yongqiang Wang", "Michael L. Seltzer", "Christian Fuegen"], "https://doi.org/10.21437/Interspeech.2019-1434", 5, "interspeech", 2019]], "Jingjun Liang": [0, ["Speech Emotion Recognition in Dyadic Dialogues with Attentive Interaction Modeling", ["Jinming Zhao", "Shizhe Chen", "Jingjun Liang", "Qin Jin"], "https://doi.org/10.21437/Interspeech.2019-2103", 5, "interspeech", 2019]], "Christophe Van Gysel": [0, ["Connecting and Comparing Language Model Interpolation Techniques", ["Ernest Pusateri", "Christophe Van Gysel", "Rami Botros", "Sameer Badaskar", "Mirko Hannemann", "Youssef Oualil", "Ilya Oparin"], "https://doi.org/10.21437/Interspeech.2019-1822", 5, "interspeech", 2019]], "Dongyoung Kim": [0.9999763071537018, ["Temporal Convolution for Real-Time Keyword Spotting on Mobile Devices", ["Seungwoo Choi", "Seokjun Seo", "Beomjun Shin", "Hyeongmin Byun", "Martin Kersner", "Beomsu Kim", "Dongyoung Kim", "Sungjoo Ha"], "https://doi.org/10.21437/Interspeech.2019-1363", 5, "interspeech", 2019]], "Nithin Rao Koluguri": [0, ["Comparison of Speech Tasks and Recording Devices for Voice Based Automatic Classification of Healthy Subjects and Patients with Amyotrophic Lateral Sclerosis", ["Suhas B. N.", "Deep Patel", "Nithin Rao Koluguri", "Yamini Belur", "Pradeep Reddy", "Atchayaram Nalini", "Ravi Yadav", "Dipanjan Gope", "Prasanta Kumar Ghosh"], "https://doi.org/10.21437/Interspeech.2019-1285", 5, "interspeech", 2019]], "Tao Jiang": [0, ["Deep Speaker Embedding Extraction with Channel-Wise Feature Responses and Additive Supervision Softmax Loss Function", ["Jianfeng Zhou", "Tao Jiang", "Zheng Li", "Lin Li", "Qingyang Hong"], "https://doi.org/10.21437/Interspeech.2019-1704", 5, "interspeech", 2019]], "Yun Tang": [0, ["Multi-Stride Self-Attention for Speech Recognition", ["Kyu J. Han", "Jing Huang", "Yun Tang", "Xiaodong He", "Bowen Zhou"], "https://doi.org/10.21437/Interspeech.2019-1973", 5, "interspeech", 2019]], "Trung Hieu Nguyen": [0, ["Fast Learning for Non-Parallel Many-to-Many Voice Conversion with Residual Star Generative Adversarial Networks", ["Shengkui Zhao", "Trung Hieu Nguyen", "Hao Wang", "Bin Ma"], "https://doi.org/10.21437/Interspeech.2019-2067", 5, "interspeech", 2019]], "Joanna Rownicka": [0, ["Speech Replay Detection with x-Vector Attack Embeddings and Spectral Features", ["Jennifer Williams", "Joanna Rownicka"], "https://doi.org/10.21437/Interspeech.2019-1760", 5, "interspeech", 2019]], "Takashi Tsunakawa": [0, ["Knowledge Distillation for Throat Microphone Speech Recognition", ["Takahito Suzuki", "Jun Ogata", "Takashi Tsunakawa", "Masafumi Nishida", "Masafumi Nishimura"], "https://doi.org/10.21437/Interspeech.2019-1597", 5, "interspeech", 2019]], "Rujie Liu": [0, ["Deep Attention Gated Dilated Temporal Convolutional Networks with Intra-Parallel Convolutional Modules for End-to-End Monaural Speech Separation", ["Ziqiang Shi", "Huibin Lin", "Liu Liu", "Rujie Liu", "Jiqing Han", "Anyan Shi"], "https://doi.org/10.21437/Interspeech.2019-1373", 5, "interspeech", 2019], ["End-to-End Monaural Speech Separation with Multi-Scale Dynamic Weighted Gated Dilated Convolutional Pyramid Network", ["Ziqiang Shi", "Huibin Lin", "Liu Liu", "Rujie Liu", "Shoji Hayakawa", "Shouji Harada", "Jiqing Han"], "https://doi.org/10.21437/Interspeech.2019-1292", 5, "interspeech", 2019]], "Peidong Wang": [8.108182191790547e-05, ["Large Margin Training for Attention Based End-to-End Speech Recognition", ["Peidong Wang", "Jia Cui", "Chao Weng", "Dong Yu"], "https://doi.org/10.21437/Interspeech.2019-1680", 5, "interspeech", 2019], ["Bridging the Gap Between Monaural Speech Enhancement and Recognition with Distortion-Independent Acoustic Modeling", ["Peidong Wang", "Ke Tan", "DeLiang Wang"], "https://doi.org/10.21437/Interspeech.2019-1495", 5, "interspeech", 2019], ["Enhanced Spectral Features for Distortion-Independent Acoustic Modeling", ["Peidong Wang", "DeLiang Wang"], "https://doi.org/10.21437/Interspeech.2019-1493", 5, "interspeech", 2019]], "Carol Y. Espy-Wilson": [0, ["Multi-Corpus Acoustic-to-Articulatory Speech Inversion", ["Nadee Seneviratne", "Ganesh Sivaraman", "Carol Y. Espy-Wilson"], "https://doi.org/10.21437/Interspeech.2019-3168", 5, "interspeech", 2019], ["Assessing Neuromotor Coordination in Depression Using Inverted Vocal Tract Variables", ["Carol Y. Espy-Wilson", "Adam C. Lammert", "Nadee Seneviratne", "Thomas F. Quatieri"], "https://doi.org/10.21437/Interspeech.2019-1815", 5, "interspeech", 2019], ["Multi-Modal Learning for Speech Emotion Recognition: An Analysis and Comparison of ASR Outputs with Ground Truth Transcription", ["Saurabh Sahu", "Vikramjit Mitra", "Nadee Seneviratne", "Carol Y. Espy-Wilson"], "https://doi.org/10.21437/Interspeech.2019-1149", 5, "interspeech", 2019]], "Guozhen An": [1.6238163157850094e-11, ["Mitigating Gender and L1 Differences to Improve State and Trait Recognition", ["Guozhen An", "Rivka Levitan"], "https://doi.org/10.21437/Interspeech.2019-2868", 4, "interspeech", 2019]], "Geraldine Damnati": [0, ["Adapting a FrameNet Semantic Parser for Spoken Language Understanding Using Adversarial Learning", ["Gabriel Marzinotto", "Geraldine Damnati", "Frederic Bechet"], "https://doi.org/10.21437/Interspeech.2019-2732", 5, "interspeech", 2019]], "Wenjun Chen": [0, ["Acoustic Characteristics of Lexical Tone Disruption in Mandarin Speakers After Brain Damage", ["Wenjun Chen", "Jeroen van de Weijer", "Shuangshuang Zhu", "Qian Qian", "Manna Wang"], "https://doi.org/10.21437/Interspeech.2019-2432", 5, "interspeech", 2019]], "Krzysztof Czarnowski": [0, ["Ultra-Compact NLU: Neuronal Network Binarization as Regularization", ["Munir Georges", "Krzysztof Czarnowski", "Tobias Bocklet"], "https://doi.org/10.21437/Interspeech.2019-2591", 5, "interspeech", 2019]], "Bhanu Teja Nellore": [0, ["Excitation Source and Vocal Tract System Based Acoustic Features for Detection of Nasals in Continuous Speech", ["Bhanu Teja Nellore", "Sri Harsha Dumpala", "Karan Nathwani", "Suryakanth V. Gangashetty"], "https://doi.org/10.21437/Interspeech.2019-2785", 5, "interspeech", 2019]], "Renee Seward": [0, ["Using Ultrasound Imaging to Create Augmented Visual Biofeedback for Articulatory Practice", ["Colin T. Annand", "Maurice Lamb", "Sarah Dugan", "Sarah R. Li", "Hannah M. Woeste", "T. Douglas Mast", "Michael A. Riley", "Jack A. Masterson", "Neeraja Mahalingam", "Kathryn J. Eary", "Caroline Spencer", "Suzanne Boyce", "Stephanie Jackson", "Anoosha Baxi", "Renee Seward"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8036.html", 2, "interspeech", 2019]], "Astitwa Saxena": [0, ["MobiVSR : Efficient and Light-Weight Neural Network for Visual Speech Recognition on Mobile Devices", ["Nilay Shrivastava", "Astitwa Saxena", "Yaman Kumar", "Rajiv Ratn Shah", "Amanda Stent", "Debanjan Mahata", "Preeti Kaur", "Roger Zimmermann"], "https://doi.org/10.21437/Interspeech.2019-3273", 5, "interspeech", 2019]], "Sarah Schimke": [0, ["Do Hesitations Facilitate Processing of Partially Defective System Utterances? An Exploratory Eye Tracking Study", ["Kristin Haake", "Sarah Schimke", "Simon Betz", "Sina Zarriess"], "https://doi.org/10.21437/Interspeech.2019-2820", 5, "interspeech", 2019]], "Susanne Fuchs": [0, ["Temporal Coordination of Articulatory and Respiratory Events Prior to Speech Initiation", ["Oksana Rasskazova", "Christine Mooshammer", "Susanne Fuchs"], "https://doi.org/10.21437/Interspeech.2019-2876", 5, "interspeech", 2019]], "Agustin Gravano": [0, ["Voice Quality as a Turn-Taking Cue", ["Mattias Heldner", "Marcin Wlodarczak", "Stefan Benus", "Agustin Gravano"], "https://doi.org/10.21437/Interspeech.2019-1592", 5, "interspeech", 2019]], "Kevin W. Wilson": [0, ["VoiceFilter: Targeted Voice Separation by Speaker-Conditioned Spectrogram Masking", ["Quan Wang", "Hannah Muckenhirn", "Kevin W. Wilson", "Prashant Sridhar", "Zelin Wu", "John R. Hershey", "Rif A. Saurous", "Ron J. Weiss", "Ye Jia", "Ignacio Lopez-Moreno"], "https://doi.org/10.21437/Interspeech.2019-1101", 5, "interspeech", 2019]], "Janghoon Cho": [0.9982708245515823, ["An End-to-End Text-Independent Speaker Verification Framework with a Keyword Adversarial Network", ["Sungrack Yun", "Janghoon Cho", "Jungyun Eum", "Wonil Chang", "Kyuwoong Hwang"], "https://doi.org/10.21437/Interspeech.2019-2208", 5, "interspeech", 2019]], "Minchuan Chen": [0, ["Cross-Lingual, Multi-Speaker Text-To-Speech Synthesis Using Neural Speaker Embedding", ["Mengnan Chen", "Minchuan Chen", "Shuang Liang", "Jun Ma", "Lei Chen", "Shaojun Wang", "Jing Xiao"], "https://doi.org/10.21437/Interspeech.2019-1632", 5, "interspeech", 2019]], "Ling Guo": [0, ["The NEC-TT 2018 Speaker Verification System", ["Kong Aik Lee", "Hitoshi Yamamoto", "Koji Okabe", "Qiongqiong Wang", "Ling Guo", "Takafumi Koshinaka", "Jiacen Zhang", "Koichi Shinoda"], "https://doi.org/10.21437/Interspeech.2019-1517", 5, "interspeech", 2019]], "Quan Wang": [0.0009247225534636527, ["VoiceFilter: Targeted Voice Separation by Speaker-Conditioned Spectrogram Masking", ["Quan Wang", "Hannah Muckenhirn", "Kevin W. Wilson", "Prashant Sridhar", "Zelin Wu", "John R. Hershey", "Rif A. Saurous", "Ron J. Weiss", "Ye Jia", "Ignacio Lopez-Moreno"], "https://doi.org/10.21437/Interspeech.2019-1101", 5, "interspeech", 2019]], "Abinay Reddy Naini": [0, ["Whisper to Neutral Mapping Using Cosine Similarity Maximization in i-Vector Space for Speaker Verification", ["Abinay Reddy Naini", "Achuth Rao M. V", "Prasanta Kumar Ghosh"], "https://doi.org/10.21437/Interspeech.2019-2280", 5, "interspeech", 2019]], "Ruoming Pang": [0, ["Shallow-Fusion End-to-End Contextual Biasing", ["Ding Zhao", "Tara N. Sainath", "David Rybach", "Pat Rondon", "Deepti Bhatia", "Bo Li", "Ruoming Pang"], "https://doi.org/10.21437/Interspeech.2019-1209", 5, "interspeech", 2019], ["Two-Pass End-to-End Speech Recognition", ["Tara N. Sainath", "Ruoming Pang", "David Rybach", "Yanzhang He", "Rohit Prabhavalkar", "Wei Li", "Mirko Visontai", "Qiao Liang", "Trevor Strohman", "Yonghui Wu", "Ian McGraw", "Chung-Cheng Chiu"], "https://doi.org/10.21437/Interspeech.2019-1341", 5, "interspeech", 2019]], "Hector Delgado": [0, ["ASVspoof 2019: Future Horizons in Spoofed and Fake Audio Detection", ["Massimiliano Todisco", "Xin Wang", "Ville Vestman", "Md. Sahidullah", "Hector Delgado", "Andreas Nautsch", "Junichi Yamagishi", "Nicholas W. D. Evans", "Tomi H. Kinnunen", "Kong Aik Lee"], "https://doi.org/10.21437/Interspeech.2019-2249", 5, "interspeech", 2019], ["I4U Submission to NIST SRE 2018: Leveraging from a Decade of Shared Experiences", ["Kong Aik Lee", "Ville Hautamaki", "Tomi H. Kinnunen", "Hitoshi Yamamoto", "Koji Okabe", "Ville Vestman", "Jing Huang", "Guohong Ding", "Hanwu Sun", "Anthony Larcher", "Rohan Kumar Das", "Haizhou Li", "Mickael Rouvier", "Pierre-Michel Bousquet", "Wei Rao", "Qing Wang", "Chunlei Zhang", "Fahimeh Bahmaninezhad", "Hector Delgado", "Massimiliano Todisco"], "https://doi.org/10.21437/Interspeech.2019-1533", 5, "interspeech", 2019]], "Peter Bell": [0, ["Untranscribed Web Audio for Low Resource Speech Recognition", ["Andrea Carmantini", "Peter Bell", "Steve Renals"], "https://doi.org/10.21437/Interspeech.2019-2623", 5, "interspeech", 2019], ["Trainable Dynamic Subsampling for End-to-End Speech Recognition", ["Shucong Zhang", "Erfan Loweimi", "Yumo Xu", "Peter Bell", "Steve Renals"], "https://doi.org/10.21437/Interspeech.2019-2778", 5, "interspeech", 2019], ["Lattice-Based Lightly-Supervised Acoustic Model Training", ["Joachim Fainberg", "Ondrej Klejch", "Steve Renals", "Peter Bell"], "https://doi.org/10.21437/Interspeech.2019-2533", 5, "interspeech", 2019], ["On Learning Interpretable CNNs with Parametric Modulated Kernel-Based Filters", ["Erfan Loweimi", "Peter Bell", "Steve Renals"], "https://doi.org/10.21437/Interspeech.2019-1257", 5, "interspeech", 2019]], "Ossama Abdel-Hamid": [0, ["Bandwidth Embeddings for Mixed-Bandwidth Speech Recognition", ["Gautam Mantena", "Ozlem Kalinli", "Ossama Abdel-Hamid", "Don McAllaster"], "https://doi.org/10.21437/Interspeech.2019-2589", 5, "interspeech", 2019]], "Joon Son Chung": [0.7989451438188553, ["Who Said That?: Audio-Visual Speaker Diarisation of Real-World Meetings", ["Joon Son Chung", "Bong-Jin Lee", "Icksang Han"], "https://doi.org/10.21437/Interspeech.2019-3116", 5, "interspeech", 2019], ["My Lips Are Concealed: Audio-Visual Speech Enhancement Through Obstructions", ["Triantafyllos Afouras", "Joon Son Chung", "Andrew Zisserman"], "https://doi.org/10.21437/Interspeech.2019-3114", 5, "interspeech", 2019]], "Feiqi Zhu": [0, ["Towards the Speech Features of Mild Cognitive Impairment: Universal Evidence from Structured and Unstructured Connected Speech of Chinese", ["Tianqi Wang", "Chongyuan Lian", "Jingshen Pan", "Quanlei Yan", "Feiqi Zhu", "Manwa L. Ng", "Lan Wang", "Nan Yan"], "https://doi.org/10.21437/Interspeech.2019-2414", 5, "interspeech", 2019], ["Towards the Speech Features of Early-Stage Dementia: Design and Application of the Mandarin Elderly Cognitive Speech Database", ["Tianqi Wang", "Quanlei Yan", "Jingshen Pan", "Feiqi Zhu", "Rongfeng Su", "Yi Guo", "Lan Wang", "Nan Yan"], "https://doi.org/10.21437/Interspeech.2019-2453", 5, "interspeech", 2019]], "Jitendra Kumar Dhiman": [0, ["On the Suitability of the Riesz Spectro-Temporal Envelope for WaveNet Based Speech Synthesis", ["Jitendra Kumar Dhiman", "Nagaraj Adiga", "Chandra Sekhar Seelamantula"], "https://doi.org/10.21437/Interspeech.2019-2626", 5, "interspeech", 2019]], "Mireia Farrus": [0, ["Prosodic Phrase Alignment for Machine Dubbing", ["Alp Oktem", "Mireia Farrus", "Antonio Bonafonte"], "https://doi.org/10.21437/Interspeech.2019-1621", 5, "interspeech", 2019]], "Juan Benjumea": [0, ["The Zero Resource Speech Challenge 2019: TTS Without T", ["Ewan Dunbar", "Robin Algayres", "Julien Karadayi", "Mathieu Bernard", "Juan Benjumea", "Xuan-Nga Cao", "Lucie Miskic", "Charlotte Dugrain", "Lucas Ondel", "Alan W. Black", "Laurent Besacier", "Sakriani Sakti", "Emmanuel Dupoux"], "https://doi.org/10.21437/Interspeech.2019-2904", 5, "interspeech", 2019]], "Yuxiang Zou": [0, ["Boosting Character-Based Chinese Speech Synthesis via Multi-Task Learning and Dictionary Tutoring", ["Yuxiang Zou", "Linhao Dong", "Bo Xu"], "https://doi.org/10.21437/Interspeech.2019-3233", 5, "interspeech", 2019]], "Jiangyan Yi": [1.0964096190946293e-06, ["A Time Delay Neural Network with Shared Weight Self-Attention for Small-Footprint Keyword Spotting", ["Ye Bai", "Jiangyan Yi", "Jianhua Tao", "Zhengqi Wen", "Zhengkun Tian", "Chenghao Zhao", "Cunhang Fan"], "https://doi.org/10.21437/Interspeech.2019-1676", 5, "interspeech", 2019], ["Learn Spelling from Teachers: Transferring Knowledge from Language Models to Sequence-to-Sequence Speech Recognition", ["Ye Bai", "Jiangyan Yi", "Jianhua Tao", "Zhengkun Tian", "Zhengqi Wen"], "https://doi.org/10.21437/Interspeech.2019-1554", 5, "interspeech", 2019], ["Self-Attention Transducers for End-to-End Speech Recognition", ["Zhengkun Tian", "Jiangyan Yi", "Jianhua Tao", "Ye Bai", "Zhengqi Wen"], "https://doi.org/10.21437/Interspeech.2019-2203", 5, "interspeech", 2019], ["Discriminative Learning for Monaural Speech Separation Using Deep Embedding Features", ["Cunhang Fan", "Bin Liu", "Jianhua Tao", "Jiangyan Yi", "Zhengqi Wen"], "https://doi.org/10.21437/Interspeech.2019-1940", 5, "interspeech", 2019]], "Cheng Yi": [0.0026509094168432057, ["Ectc-Docd: An End-to-End Structure with CTC Encoder and OCD Decoder for Speech Recognition", ["Cheng Yi", "Feng Wang", "Bo Xu"], "https://doi.org/10.21437/Interspeech.2019-1212", 5, "interspeech", 2019]], "Vikramjit Mitra": [0, ["Leveraging Acoustic Cues and Paralinguistic Embeddings to Detect Expression from Voice", ["Vikramjit Mitra", "Sue Booker", "Erik Marchi", "David Scott Farrar", "Ute Dorothea Peitz", "Bridget Cheng", "Ermine Teves", "Anuj Mehta", "Devang Naik"], "https://doi.org/10.21437/Interspeech.2019-2998", 5, "interspeech", 2019], ["Multi-Modal Learning for Speech Emotion Recognition: An Analysis and Comparison of ASR Outputs with Ground Truth Transcription", ["Saurabh Sahu", "Vikramjit Mitra", "Nadee Seneviratne", "Carol Y. Espy-Wilson"], "https://doi.org/10.21437/Interspeech.2019-1149", 5, "interspeech", 2019]], "Wencheng Ai": [0, ["Latent Topic Attention for Domain Classification", ["Peisong Huang", "Peijie Huang", "Wencheng Ai", "Jiande Ding", "Jinchuan Zhang"], "https://doi.org/10.21437/Interspeech.2019-2228", 5, "interspeech", 2019]], "Sarfaraz Jelil": [0, ["SpeechMarker: A Voice Based Multi-Level Attendance Application", ["Sarfaraz Jelil", "Abhishek Shrivastava", "Rohan Kumar Das", "S. R. Mahadeva Prasanna", "Rohit Sinha"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8014.html", 2, "interspeech", 2019]], "Regine Andre-Obrecht": [0, ["Char+CV-CTC: Combining Graphemes and Consonant/Vowel Units for CTC-Based ASR Using Multitask Learning", ["Abdelwahab Heba", "Thomas Pellegrini", "Jean-Pierre Lorre", "Regine Andre-Obrecht"], "https://doi.org/10.21437/Interspeech.2019-1975", 5, "interspeech", 2019]], "Hardik B. Sailor": [0, ["Whether to Pretrain DNN or not?: An Empirical Analysis for Voice Conversion", ["Nirmesh J. Shah", "Hardik B. Sailor", "Hemant A. Patil"], "https://doi.org/10.21437/Interspeech.2019-2608", 5, "interspeech", 2019]], "Su-Yu Chang": [0.24821341037750244, ["Transfer-Representation Learning for Detecting Spoofing Attacks with Converted and Synthesized Speech in Automatic Speaker Verification System", ["Su-Yu Chang", "Kai-Cheng Wu", "Chia-Ping Chen"], "https://doi.org/10.21437/Interspeech.2019-2014", 5, "interspeech", 2019]], "Timo Gerkmann": [0, ["On Nonlinear Spatial Filtering in Multichannel Speech Enhancement", ["Kristina Tesch", "Robert Rehr", "Timo Gerkmann"], "https://doi.org/10.21437/Interspeech.2019-2751", 5, "interspeech", 2019], ["Influence of Speaker-Specific Parameters on Speech Separation Systems", ["David Ditter", "Timo Gerkmann"], "https://doi.org/10.21437/Interspeech.2019-2459", 5, "interspeech", 2019]], "Anushree Prasanna Kumar": [0, ["Unsupervised Phonetic and Word Level Discovery for Speech to Speech Translation for Unwritten Languages", ["Steven Hillis", "Anushree Prasanna Kumar", "Alan W. Black"], "https://doi.org/10.21437/Interspeech.2019-3026", 5, "interspeech", 2019]], "Victor R. Martinez": [0, ["Identifying Therapist and Client Personae for Therapeutic Alliance Estimation", ["Victor R. Martinez", "Nikolaos Flemotomos", "Victor Ardulov", "Krishna Somandepalli", "Simon B. Goldberg", "Zac E. Imel", "David C. Atkins", "Shrikanth Narayanan"], "https://doi.org/10.21437/Interspeech.2019-2829", 5, "interspeech", 2019]], "Wolfgang Macherey": [0, ["Direct Speech-to-Speech Translation with a Sequence-to-Sequence Model", ["Ye Jia", "Ron J. Weiss", "Fadi Biadsy", "Wolfgang Macherey", "Melvin Johnson", "Zhifeng Chen", "Yonghui Wu"], "https://doi.org/10.21437/Interspeech.2019-1951", 5, "interspeech", 2019]], "Sonal Joshi": [0, ["Generative Noise Modeling and Channel Simulation for Robust Speech Recognition in Unseen Conditions", ["Meet H. Soni", "Sonal Joshi", "Ashish Panda"], "https://doi.org/10.21437/Interspeech.2019-2090", 5, "interspeech", 2019], ["Front-End Feature Compensation and Denoising for Noise Robust Speech Emotion Recognition", ["Rupayan Chakraborty", "Ashish Panda", "Meghna Pandharipande", "Sonal Joshi", "Sunil Kumar Kopparapu"], "https://doi.org/10.21437/Interspeech.2019-2243", 5, "interspeech", 2019]], "James R. Glass": [0, ["Analyzing Phonetic and Graphemic Representations in End-to-End Automatic Speech Recognition", ["Yonatan Belinkov", "Ahmed Ali", "James R. Glass"], "https://doi.org/10.21437/Interspeech.2019-2599", 5, "interspeech", 2019], ["An Unsupervised Autoregressive Model for Speech Representation Learning", ["Yu-An Chung", "Wei-Ning Hsu", "Hao Tang", "James R. Glass"], "https://doi.org/10.21437/Interspeech.2019-1473", 5, "interspeech", 2019], ["Towards Bilingual Lexicon Discovery From Visually Grounded Speech Audio", ["Emmanuel Azuh", "David Harwath", "James R. Glass"], "https://doi.org/10.21437/Interspeech.2019-1718", 5, "interspeech", 2019], ["MCE 2018: The 1st Multi-Target Speaker Detection and Identification Challenge Evaluation", ["Suwon Shon", "Najim Dehak", "Douglas A. Reynolds", "James R. Glass"], "https://doi.org/10.21437/Interspeech.2019-1572", 5, "interspeech", 2019], ["Integrating Video Retrieval and Moment Detection in a Unified Corpus for Video Question Answering", ["Hongyin Luo", "Mitra Mohtarami", "James R. Glass", "Karthik Krishnamurthy", "Brigitte Richardson"], "https://doi.org/10.21437/Interspeech.2019-1736", 5, "interspeech", 2019], ["A Comparison of Deep Learning Methods for Language Understanding", ["Mandy Korpusik", "Zoe Liu", "James R. Glass"], "https://doi.org/10.21437/Interspeech.2019-1262", 5, "interspeech", 2019], ["A Deep Residual Network for Large-Scale Acoustic Scene Analysis", ["Logan Ford", "Hao Tang", "Francois Grondin", "James R. Glass"], "https://doi.org/10.21437/Interspeech.2019-2731", 5, "interspeech", 2019], ["Multiple Sound Source Localization with SVD-PHAT", ["Francois Grondin", "James R. Glass"], "https://doi.org/10.21437/Interspeech.2019-2653", 5, "interspeech", 2019], ["VoiceID Loss: Speech Enhancement for Speaker Verification", ["Suwon Shon", "Hao Tang", "James R. Glass"], "https://doi.org/10.21437/Interspeech.2019-1496", 5, "interspeech", 2019], ["Transfer Learning from Audio-Visual Grounding to Speech Recognition", ["Wei-Ning Hsu", "David Harwath", "James R. Glass"], "https://doi.org/10.21437/Interspeech.2019-1227", 5, "interspeech", 2019]], "Douglas E. Sturim": [0, ["Vocal Biomarker Assessment Following Pediatric Traumatic Brain Injury: A Retrospective Cohort Study", ["Camille Noufi", "Adam C. Lammert", "Daryush D. Mehta", "James R. Williamson", "Gregory Ciccarelli", "Douglas E. Sturim", "Jordan R. Green", "Thomas F. Campbell", "Thomas F. Quatieri"], "https://doi.org/10.21437/Interspeech.2019-1200", 5, "interspeech", 2019]], "Pejman Mowlaee": [0, ["Maximum a posteriori Speech Enhancement Based on Double Spectrum", ["Pejman Mowlaee", "Daniel Scheran", "Johannes Stahl", "Sean U. N. Wood", "W. Bastiaan Kleijn"], "https://doi.org/10.21437/Interspeech.2019-1197", 5, "interspeech", 2019]], "Patrick Kenny": [0, ["Deep Speaker Recognition: Modular or Monolithic?", ["Gautam Bhattacharya", "Md. Jahangir Alam", "Patrick Kenny"], "https://doi.org/10.21437/Interspeech.2019-3146", 5, "interspeech", 2019]], "Benjamin Kane": [0, ["Investigating Linguistic and Semantic Features for Turn-Taking Prediction in Open-Domain Human-Computer Conversation", ["Seyedeh Zahra Razavi", "Benjamin Kane", "Lenhart K. Schubert"], "https://doi.org/10.21437/Interspeech.2019-3152", 5, "interspeech", 2019]], "Michael Auli": [0, ["wav2vec: Unsupervised Pre-Training for Speech Recognition", ["Steffen Schneider", "Alexei Baevski", "Ronan Collobert", "Michael Auli"], "https://doi.org/10.21437/Interspeech.2019-1873", 5, "interspeech", 2019]], "S. Pavankumar Dubagunta": [0, ["Using Speech Production Knowledge for Raw Waveform Modelling Based Styrian Dialect Identification", ["S. Pavankumar Dubagunta", "Mathew Magimai-Doss"], "https://doi.org/10.21437/Interspeech.2019-2398", 5, "interspeech", 2019]], "Zac E. Imel": [0, ["Identifying Therapist and Client Personae for Therapeutic Alliance Estimation", ["Victor R. Martinez", "Nikolaos Flemotomos", "Victor Ardulov", "Krishna Somandepalli", "Simon B. Goldberg", "Zac E. Imel", "David C. Atkins", "Shrikanth Narayanan"], "https://doi.org/10.21437/Interspeech.2019-2829", 5, "interspeech", 2019]], "Hemant A. Patil": [0, ["Phone Aware Nearest Neighbor Technique Using Spectral Transition Measure for Non-Parallel Voice Conversion", ["Nirmesh J. Shah", "Hemant A. Patil"], "https://doi.org/10.21437/Interspeech.2019-1504", 5, "interspeech", 2019], ["Whether to Pretrain DNN or not?: An Empirical Analysis for Voice Conversion", ["Nirmesh J. Shah", "Hardik B. Sailor", "Hemant A. Patil"], "https://doi.org/10.21437/Interspeech.2019-2608", 5, "interspeech", 2019], ["Energy Separation-Based Instantaneous Frequency Estimation for Cochlear Cepstral Feature for Replay Spoof Detection", ["Ankur T. Patil", "Rajul Acharya", "Pulikonda Krishna Aditya Sai", "Hemant A. Patil"], "https://doi.org/10.21437/Interspeech.2019-2742", 5, "interspeech", 2019]], "Janet Beck": [0, ["Reliability of Clinical Voice Parameters Captured with Smartphones - Measurements of Added Noise and Spectral Tilt", ["Felix Schaeffler", "Stephen Jannetts", "Janet Beck"], "https://doi.org/10.21437/Interspeech.2019-2910", 5, "interspeech", 2019]], "Eugen Beck": [0, ["RWTH ASR Systems for LibriSpeech: Hybrid vs Attention", ["Christoph Luscher", "Eugen Beck", "Kazuki Irie", "Markus Kitza", "Wilfried Michel", "Albert Zeyer", "Ralf Schluter", "Hermann Ney"], "https://doi.org/10.21437/Interspeech.2019-1780", 5, "interspeech", 2019], ["Rescoring Keyword Search Confidence Estimates with Graph-Based Re-Ranking Using Acoustic Word Embeddings", ["Anna Piunova", "Eugen Beck", "Ralf Schluter", "Hermann Ney"], "https://doi.org/10.21437/Interspeech.2019-1817", 5, "interspeech", 2019]], "Lam Dang Pham": [0, ["A Robust Framework for Acoustic Scene Classification", ["Lam Dang Pham", "Ian Vince McLoughlin", "Huy Phan", "Ramaswamy Palaniappan"], "https://doi.org/10.21437/Interspeech.2019-1841", 5, "interspeech", 2019]], "Kai Chen": [0, ["Speech Separation Using Independent Vector Analysis with an Amplitude Variable Gaussian Mixture Model", ["Zhaoyi Gu", "Jing Lu", "Kai Chen"], "https://doi.org/10.21437/Interspeech.2019-2076", 5, "interspeech", 2019], ["Compression of CTC-Trained Acoustic Models by Dynamic Frame-Wise Distillation or Segment-Wise N-Best Hypotheses Imitation", ["Haisong Ding", "Kai Chen", "Qiang Huo"], "https://doi.org/10.21437/Interspeech.2019-2182", 5, "interspeech", 2019], ["An End-to-End Audio Classification System Based on Raw Waveforms and Mix-Training Strategy", ["Jiaxu Chen", "Jing Hao", "Kai Chen", "Di Xie", "Shicai Yang", "Shiliang Pu"], "https://doi.org/10.21437/Interspeech.2019-1579", 5, "interspeech", 2019]], "Mariya Korenevskaya": [0, ["R-Vectors: New Technique for Adaptation to Room Acoustics", ["Yuri Y. Khokhlov", "Alexander Zatvornitskiy", "Ivan Medennikov", "Ivan Sorokin", "Tatiana Prisyach", "Aleksei Romanenko", "Anton Mitrofanov", "Vladimir Bataev", "Andrei Andrusenko", "Mariya Korenevskaya", "Oleg Petrov"], "https://doi.org/10.21437/Interspeech.2019-2645", 5, "interspeech", 2019], ["The STC ASR System for the VOiCES from a Distance Challenge 2019", ["Ivan Medennikov", "Yuri Y. Khokhlov", "Aleksei Romanenko", "Ivan Sorokin", "Anton Mitrofanov", "Vladimir Bataev", "Andrei Andrusenko", "Tatiana Prisyach", "Mariya Korenevskaya", "Oleg Petrov", "Alexander Zatvornitskiy"], "https://doi.org/10.21437/Interspeech.2019-1574", 5, "interspeech", 2019], ["The STC ASR System for the VOiCES from a Distance Challenge 2019", ["Ivan Medennikov", "Yuri Y. Khokhlov", "Aleksei Romanenko", "Ivan Sorokin", "Anton Mitrofanov", "Vladimir Bataev", "Andrei Andrusenko", "Tatiana Prisyach", "Mariya Korenevskaya", "Oleg Petrov", "Alexander Zatvornitskiy"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/abs17.html", 0, "interspeech", 2019]], "Jonathan S. Brumberg": [0, ["Monaural Speech Enhancement with Dilated Convolutions", ["Shadi Pirhosseinloo", "Jonathan S. Brumberg"], "https://doi.org/10.21437/Interspeech.2019-2782", 5, "interspeech", 2019]], "Zongze Ren": [0, ["Two-Stage Training for Chinese Dialect Recognition", ["Zongze Ren", "Guofu Yang", "Shugong Xu"], "https://doi.org/10.21437/Interspeech.2019-1522", 5, "interspeech", 2019]], "Manfred Kaltenbacher": [0, ["Physiology and Physics of Voice Production", ["Manfred Kaltenbacher"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/abs12.html", 0, "interspeech", 2019]], "Els Kindt": [0, ["The GDPR & Speech Data: Reflections of Legal and Technology Communities, First Steps Towards a Common Understanding", ["Andreas Nautsch", "Catherine Jasserand", "Els Kindt", "Massimiliano Todisco", "Isabel Trancoso", "Nicholas W. D. Evans"], "https://doi.org/10.21437/Interspeech.2019-2647", 5, "interspeech", 2019]], "Dmytro Tkanov": [0, ["Attention Model for Articulatory Features Detection", ["Ievgen Karaulov", "Dmytro Tkanov"], "https://doi.org/10.21437/Interspeech.2019-3020", 5, "interspeech", 2019]], "Elizabeth Shriberg": [0, ["Optimizing Speech-Input Length for Speaker-Independent Depression Classification", ["Tomasz Rutowski", "Amir Harati", "Yang Lu", "Elizabeth Shriberg"], "https://doi.org/10.21437/Interspeech.2019-3095", 5, "interspeech", 2019]], "William Speier": [0, ["Identifying Input Features for Development of Real-Time Translation of Neural Signals to Text", ["Janaki Sheth", "Ariel Tankus", "Michelle Tran", "Lindy Comstock", "Itzhak Fried", "William Speier"], "https://doi.org/10.21437/Interspeech.2019-3092", 5, "interspeech", 2019]], "Ashish Garg": [0, ["Active Learning for Domain Classification in a Commercial Spoken Personal Assistant", ["Xi C. Chen", "Adithya Sagar", "Justine T. Kao", "Tony Y. Li", "Christopher Klein", "Stephen Pulman", "Ashish Garg", "Jason D. Williams"], "https://doi.org/10.21437/Interspeech.2019-1315", 5, "interspeech", 2019]], "M. Bentum": [0, ["Listening with Great Expectations: An Investigation of Word Form Anticipations in Naturalistic Speech", ["M. Bentum", "Louis ten Bosch", "Antal van den Bosch", "Mirjam Ernestus"], "https://doi.org/10.21437/Interspeech.2019-2741", 5, "interspeech", 2019], ["Quantifying Expectation Modulation in Human Speech Processing", ["M. Bentum", "Louis ten Bosch", "Antal van den Bosch", "Mirjam Ernestus"], "https://doi.org/10.21437/Interspeech.2019-2685", 5, "interspeech", 2019]], "Christer Gobl": [0, ["Time to Frequency Domain Mapping of the Voice Source: The Influence of Open Quotient and Glottal Skew on the Low End of the Source Spectrum", ["Christer Gobl", "Ailbhe Ni Chasaide"], "https://doi.org/10.21437/Interspeech.2019-2888", 5, "interspeech", 2019], ["The Role of Voice Quality in the Perception of Prominence in Synthetic Speech", ["Andy Murphy", "Irena Yanushevskaya", "Ailbhe Ni Chasaide", "Christer Gobl"], "https://doi.org/10.21437/Interspeech.2019-2761", 5, "interspeech", 2019]], "Hiroko Terasawa": [0, ["Investigating the Physiological and Acoustic Contrasts Between Choral and Operatic Singing", ["Hiroko Terasawa", "Kenta Wakasa", "Hideki Kawahara", "Ken-Ichi Sakakibara"], "https://doi.org/10.21437/Interspeech.2019-1864", 5, "interspeech", 2019]], "Melissa C. Smith": [0, ["Speech Enhancement Using Forked Generative Adversarial Networks with Spectral Subtraction", ["Ju Lin", "Sufeng Niu", "Zice Wei", "Xiang Lan", "Adriaan J. van Wijngaarden", "Melissa C. Smith", "Kuang-Ching Wang"], "https://doi.org/10.21437/Interspeech.2019-2954", 5, "interspeech", 2019]], "Rajib Rana": [0, ["Direct Modelling of Speech Emotion from Raw Speech", ["Siddique Latif", "Rajib Rana", "Sara Khalifa", "Raja Jurdak", "Julien Epps"], "https://doi.org/10.21437/Interspeech.2019-3252", 5, "interspeech", 2019]], "Alexander Gutkin": [0, ["Cross-Lingual Consistency of Phonological Features: An Empirical Study", ["Cibu Johny", "Alexander Gutkin", "Martin Jansche"], "https://doi.org/10.21437/Interspeech.2019-2184", 5, "interspeech", 2019], ["Sampling from Stochastic Finite Automata with Applications to CTC Decoding", ["Martin Jansche", "Alexander Gutkin"], "https://doi.org/10.21437/Interspeech.2019-2740", 5, "interspeech", 2019]], "Chandan K. A. Reddy": [0, ["A Scalable Noisy Speech Dataset and Online Subjective Test Framework", ["Chandan K. A. Reddy", "Ebrahim Beyrami", "Jamie Pool", "Ross Cutler", "Sriram Srinivasan", "Johannes Gehrke"], "https://doi.org/10.21437/Interspeech.2019-3087", 5, "interspeech", 2019], ["Supervised Classifiers for Audio Impairments with Noisy Labels", ["Chandan K. A. Reddy", "Ross Cutler", "Johannes Gehrke"], "https://doi.org/10.21437/Interspeech.2019-3074", 5, "interspeech", 2019]], "Gerasimos Potamianos": [0, ["End-to-End Convolutional Sequence Learning for ASL Fingerspelling Recognition", ["Katerina Papadimitriou", "Gerasimos Potamianos"], "https://doi.org/10.21437/Interspeech.2019-2422", 5, "interspeech", 2019], ["MobiLipNet: Resource-Efficient Deep Learning Based Lipreading", ["Alexandros Koumparoulis", "Gerasimos Potamianos"], "https://doi.org/10.21437/Interspeech.2019-2618", 5, "interspeech", 2019]], "Matt Huenerfauth": [0, ["Fusion Strategy for Prosodic and Lexical Representations of Word Importance", ["Sushant Kafle", "Cecilia Ovesdotter Alm", "Matt Huenerfauth"], "https://doi.org/10.21437/Interspeech.2019-1898", 5, "interspeech", 2019]], "Shinji Watanabe": [0, ["Auxiliary Interference Speaker Loss for Target-Speaker Speech Recognition", ["Naoyuki Kanda", "Shota Horiguchi", "Ryoichi Takashima", "Yusuke Fujita", "Kenji Nagamatsu", "Shinji Watanabe"], "https://doi.org/10.21437/Interspeech.2019-1126", 5, "interspeech", 2019], ["End-to-End SpeakerBeam for Single Channel Target Speech Recognition", ["Marc Delcroix", "Shinji Watanabe", "Tsubasa Ochiai", "Keisuke Kinoshita", "Shigeki Karita", "Atsunori Ogawa", "Tomohiro Nakatani"], "https://doi.org/10.21437/Interspeech.2019-1856", 5, "interspeech", 2019], ["Improving Transformer-Based End-to-End Speech Recognition with Connectionist Temporal Classification and Language Model Integration", ["Shigeki Karita", "Nelson Enrique Yalta Soplin", "Shinji Watanabe", "Marc Delcroix", "Atsunori Ogawa", "Tomohiro Nakatani"], "https://doi.org/10.21437/Interspeech.2019-1938", 5, "interspeech", 2019], ["Speaker Recognition Benchmark Using the CHiME-5 Corpus", ["Daniel Garcia-Romero", "David Snyder", "Shinji Watanabe", "Gregory Sell", "Alan McCree", "Daniel Povey", "Sanjeev Khudanpur"], "https://doi.org/10.21437/Interspeech.2019-2174", 5, "interspeech", 2019], ["Analysis of Multilingual Sequence-to-Sequence Speech Recognition Systems", ["Martin Karafiat", "Murali Karthick Baskar", "Shinji Watanabe", "Takaaki Hori", "Matthew Wiesner", "Jan Cernocky"], "https://doi.org/10.21437/Interspeech.2019-2355", 5, "interspeech", 2019], ["End-to-End Multilingual Multi-Speaker Speech Recognition", ["Hiroshi Seki", "Takaaki Hori", "Shinji Watanabe", "Jonathan Le Roux", "John R. Hershey"], "https://doi.org/10.21437/Interspeech.2019-3038", 5, "interspeech", 2019], ["Semi-Supervised Sequence-to-Sequence ASR Using Unpaired Speech and Text", ["Murali Karthick Baskar", "Shinji Watanabe", "Ramon Fernandez Astudillo", "Takaaki Hori", "Lukas Burget", "Jan Cernocky"], "https://doi.org/10.21437/Interspeech.2019-3167", 5, "interspeech", 2019], ["Vectorized Beam Search for CTC-Attention-Based Speech Recognition", ["Hiroshi Seki", "Takaaki Hori", "Shinji Watanabe", "Niko Moritz", "Jonathan Le Roux"], "https://doi.org/10.21437/Interspeech.2019-2860", 5, "interspeech", 2019], ["Study of the Performance of Automatic Speech Recognition Systems in Speakers with Parkinson's Disease", ["Laureano Moro-Velazquez", "Jaejin Cho", "Shinji Watanabe", "Mark A. Hasegawa-Johnson", "Odette Scharenborg", "Heejin Kim", "Najim Dehak"], "https://doi.org/10.21437/Interspeech.2019-2993", 5, "interspeech", 2019], ["End-to-End Neural Speaker Diarization with Permutation-Free Objectives", ["Yusuke Fujita", "Naoyuki Kanda", "Shota Horiguchi", "Kenji Nagamatsu", "Shinji Watanabe"], "https://doi.org/10.21437/Interspeech.2019-2899", 5, "interspeech", 2019], ["Pretraining by Backtranslation for End-to-End ASR in Low-Resource Settings", ["Matthew Wiesner", "Adithya Renduchintala", "Shinji Watanabe", "Chunxi Liu", "Najim Dehak", "Sanjeev Khudanpur"], "https://doi.org/10.21437/Interspeech.2019-3254", 5, "interspeech", 2019], ["Pre-Trained Text Embeddings for Enhanced Text-to-Speech Synthesis", ["Tomoki Hayashi", "Shinji Watanabe", "Tomoki Toda", "Kazuya Takeda", "Shubham Toshniwal", "Karen Livescu"], "https://doi.org/10.21437/Interspeech.2019-3177", 5, "interspeech", 2019]], "Vincent Pagel": [0, ["Visualization and Interpretation of Latent Spaces for Controlling Expressive Speech Synthesis Through Audio Analysis", ["Noe Tits", "Fengna Wang", "Kevin El Haddad", "Vincent Pagel", "Thierry Dutoit"], "https://doi.org/10.21437/Interspeech.2019-1426", 5, "interspeech", 2019]], "Pengfei Hu": [0, ["Multimedia Simultaneous Translation System for Minority Language Communication with Mandarin", ["Shen Huang", "Bojie Hu", "Shan Huang", "Pengfei Hu", "Jian Kang", "Zhiqiang Lv", "Jinghao Yan", "Qi Ju", "Shiyin Kang", "Deyi Tuo", "Guangzhi Li", "Nurmemet Yolwas"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8020.html", 2, "interspeech", 2019]], "Simone Ashby": [0, ["All Together Now: The Living Audio Dataset", ["David A. Braude", "Matthew P. Aylett", "Caoimhin Laoide-Kemp", "Simone Ashby", "Kristen M. Scott", "Brian O Raghallaigh", "Anna Braudo", "Alex Brouwer", "Adriana Stan"], "https://doi.org/10.21437/Interspeech.2019-2448", 5, "interspeech", 2019]], "Minje Kim": [0.867972731590271, ["Cascaded Cross-Module Residual Learning Towards Lightweight End-to-End Speech Coding", ["Kai Zhen", "Jongmo Sung", "Mi Suk Lee", "Seungkwon Beack", "Minje Kim"], "https://doi.org/10.21437/Interspeech.2019-1816", 5, "interspeech", 2019]], "Megan M. Willi": [0, ["Do Conversational Partners Entrain on Articulatory Precision?", ["Nichola Lubold", "Stephanie A. Borrie", "Tyson S. Barrett", "Megan M. Willi", "Visar Berisha"], "https://doi.org/10.21437/Interspeech.2019-1786", 5, "interspeech", 2019]], "Viet Dang": [0, ["LibriTTS: A Corpus Derived from LibriSpeech for Text-to-Speech", ["Heiga Zen", "Viet Dang", "Rob Clark", "Yu Zhang", "Ron J. Weiss", "Ye Jia", "Zhifeng Chen", "Yonghui Wu"], "https://doi.org/10.21437/Interspeech.2019-2441", 5, "interspeech", 2019]], "Daniel S. Park": [3.925836655760406e-09, ["SpecAugment: A Simple Data Augmentation Method for Automatic Speech Recognition", ["Daniel S. Park", "William Chan", "Yu Zhang", "Chung-Cheng Chiu", "Barret Zoph", "Ekin D. Cubuk", "Quoc V. Le"], "https://doi.org/10.21437/Interspeech.2019-2680", 5, "interspeech", 2019]], "Ying-Ying Tan": [0, ["Building the Singapore English National Speech Corpus", ["Jia Xin Koh", "Aqilah Mislan", "Kevin Khoo", "Brian Ang", "Wilson Ang", "Charmaine Ng", "Ying-Ying Tan"], "https://doi.org/10.21437/Interspeech.2019-1525", 5, "interspeech", 2019]], "Anuj Mehta": [0, ["Leveraging Acoustic Cues and Paralinguistic Embeddings to Detect Expression from Voice", ["Vikramjit Mitra", "Sue Booker", "Erik Marchi", "David Scott Farrar", "Ute Dorothea Peitz", "Bridget Cheng", "Ermine Teves", "Anuj Mehta", "Devang Naik"], "https://doi.org/10.21437/Interspeech.2019-2998", 5, "interspeech", 2019]], "Reda Dehak": [0, ["State-of-the-Art Speaker Recognition for Telephone and Video Speech: The JHU-MIT Submission for NIST SRE18", ["Jesus Villalba", "Nanxin Chen", "David Snyder", "Daniel Garcia-Romero", "Alan McCree", "Gregory Sell", "Jonas Borgstrom", "Fred Richardson", "Suwon Shon", "Francois Grondin", "Reda Dehak", "Leibny Paola Garcia-Perera", "Daniel Povey", "Pedro A. Torres-Carrasquillo", "Sanjeev Khudanpur", "Najim Dehak"], "https://doi.org/10.21437/Interspeech.2019-2713", 5, "interspeech", 2019]], "Maurice Lamb": [0, ["Using Ultrasound Imaging to Create Augmented Visual Biofeedback for Articulatory Practice", ["Colin T. Annand", "Maurice Lamb", "Sarah Dugan", "Sarah R. Li", "Hannah M. Woeste", "T. Douglas Mast", "Michael A. Riley", "Jack A. Masterson", "Neeraja Mahalingam", "Kathryn J. Eary", "Caroline Spencer", "Suzanne Boyce", "Stephanie Jackson", "Anoosha Baxi", "Renee Seward"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8036.html", 2, "interspeech", 2019]], "Xiangang Li": [0, ["Environment-Dependent Attention-Driven Recurrent Convolutional Neural Network for Robust Speech Enhancement", ["Meng Ge", "Longbiao Wang", "Nan Li", "Hao Shi", "Jianwu Dang", "Xiangang Li"], "https://doi.org/10.21437/Interspeech.2019-1477", 5, "interspeech", 2019], ["Learning Alignment for Multimodal Emotion Recognition from Speech", ["Haiyang Xu", "Hui Zhang", "Kun Han", "Yun Wang", "Yiping Peng", "Xiangang Li"], "https://doi.org/10.21437/Interspeech.2019-3247", 5, "interspeech", 2019]], "Beata Lukaszewicz": [0, ["An Acoustic Study of Vowel Undershoot in a System with Several Degrees of Prominence", ["Janina Molczanow", "Beata Lukaszewicz", "Anna Lukaszewicz"], "https://doi.org/10.21437/Interspeech.2019-1806", 5, "interspeech", 2019]], "Marcus Liwicki": [0, ["Examining the Combination of Multi-Band Processing and Channel Dropout for Robust Speech Recognition", ["Gyorgy Kovacs", "Laszlo Toth", "Dirk Van Compernolle", "Marcus Liwicki"], "https://doi.org/10.21437/Interspeech.2019-3215", 5, "interspeech", 2019]], "Helmut Grabner": [0, ["Evaluating Audiovisual Source Separation in the Context of Video Conferencing", ["Berkay Inan", "Milos Cernak", "Helmut Grabner", "Helena Peic Tukuljac", "Rodrigo C. G. Pena", "Benjamin Ricaud"], "https://doi.org/10.21437/Interspeech.2019-2671", 5, "interspeech", 2019]], "Jonathan Harrington": [0, ["Tracking the New Zealand English NEAR/SQUARE Merger Using Functional Principal Components Analysis", ["Michele Gubian", "Jonathan Harrington", "Mary Stevens", "Florian Schiel", "Paul Warren"], "https://doi.org/10.21437/Interspeech.2019-2115", 5, "interspeech", 2019]], "Shiwen Deng": [0, ["Acoustic Scene Classification by Implicitly Identifying Distinct Sound Events", ["Hongwei Song", "Jiqing Han", "Shiwen Deng", "Zhihao Du"], "https://doi.org/10.21437/Interspeech.2019-2231", 5, "interspeech", 2019]], "Zhiyu Wang": [1.569323512740084e-05, ["UNetGAN: A Robust Speech Enhancement Approach in Time Domain for Extremely Low Signal-to-Noise Ratio Condition", ["Xiang Hao", "Xiangdong Su", "Zhiyu Wang", "Hui Zhang", "Batushiren"], "https://doi.org/10.21437/Interspeech.2019-1567", 5, "interspeech", 2019]], "Zhanghao Wu": [7.778910978903375e-12, ["Data Augmentation Using Variational Autoencoder for Embedding Based Speaker Verification", ["Zhanghao Wu", "Shuai Wang", "Yanmin Qian", "Kai Yu"], "https://doi.org/10.21437/Interspeech.2019-2248", 5, "interspeech", 2019]], "Zihan Pan": [0, ["Robust Sound Recognition: A Neuromorphic Approach", ["Jibin Wu", "Zihan Pan", "Malu Zhang", "Rohan Kumar Das", "Yansong Chua", "Haizhou Li"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8032.html", 2, "interspeech", 2019]], "I. Gallagher": [0, ["Splash: Speech and Language Assessment in Schools and Homes", ["A. Miwardelli", "I. Gallagher", "J. Gibson", "Napoleon Katsos", "Kate M. Knill", "H. Wood"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8027.html", 2, "interspeech", 2019]], "Shengkui Zhao": [0, ["Fast Learning for Non-Parallel Many-to-Many Voice Conversion with Residual Star Generative Adversarial Networks", ["Shengkui Zhao", "Trung Hieu Nguyen", "Hao Wang", "Bin Ma"], "https://doi.org/10.21437/Interspeech.2019-2067", 5, "interspeech", 2019], ["Multi-Task Multi-Network Joint-Learning of Deep Residual Networks and Cycle-Consistency Generative Adversarial Networks for Robust Speech Recognition", ["Shengkui Zhao", "Chongjia Ni", "Rong Tong", "Bin Ma"], "https://doi.org/10.21437/Interspeech.2019-2078", 5, "interspeech", 2019]], "Suzanne Boyce": [0, ["Using Ultrasound Imaging to Create Augmented Visual Biofeedback for Articulatory Practice", ["Colin T. Annand", "Maurice Lamb", "Sarah Dugan", "Sarah R. Li", "Hannah M. Woeste", "T. Douglas Mast", "Michael A. Riley", "Jack A. Masterson", "Neeraja Mahalingam", "Kathryn J. Eary", "Caroline Spencer", "Suzanne Boyce", "Stephanie Jackson", "Anoosha Baxi", "Renee Seward"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8036.html", 2, "interspeech", 2019]], "Tze Yuang Chong": [2.8871034629673886e-07, ["The I2R's ASR System for the VOiCES from a Distance Challenge 2019", ["Tze Yuang Chong", "Kye Min Tan", "Kah Kuan Teh", "Chang Huai You", "Hanwu Sun", "Tran Huy Dat"], "https://doi.org/10.21437/Interspeech.2019-2130", 5, "interspeech", 2019], ["The I2R's ASR System for the VOiCES from a Distance Challenge 2019", ["Tze Yuang Chong", "Kye Min Tan", "Kah Kuan Teh", "Chang Huai You", "Hanwu Sun", "Tran Huy Dat"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/abs18.html", 0, "interspeech", 2019]], "Hung-Shin Lee": [5.500723204932001e-06, ["Exploring the Encoder Layers of Discriminative Autoencoders for LVCSR", ["Pin-Tuan Huang", "Hung-Shin Lee", "Syu-Siang Wang", "Kuan-Yu Chen", "Yu Tsao", "Hsin-Min Wang"], "https://doi.org/10.21437/Interspeech.2019-1717", 5, "interspeech", 2019]], "Ta Li": [0, ["Online Hybrid CTC/Attention Architecture for End-to-End Speech Recognition", ["Haoran Miao", "Gaofeng Cheng", "Pengyuan Zhang", "Ta Li", "Yonghong Yan"], "https://doi.org/10.21437/Interspeech.2019-2018", 5, "interspeech", 2019]], "Maida Percival": [0, ["Articulatory Characteristics of Secondary Palatalization in Romanian Fricatives", ["Laura Spinu", "Maida Percival", "Alexei Kochetov"], "https://doi.org/10.21437/Interspeech.2019-3039", 5, "interspeech", 2019]], "Shan Xu": [0, ["A Convolutional Neural Network with Non-Local Module for Speech Enhancement", ["Xiaoqi Li", "Yaxing Li", "Meng Li", "Shan Xu", "Yuanjie Dong", "Xinrong Sun", "Shengwu Xiong"], "https://doi.org/10.21437/Interspeech.2019-2472", 5, "interspeech", 2019]], "R. J. J. H. van Son": [4.967731911165174e-05, ["CNN-Based Phoneme Classifier from Vocal Tract MRI Learns Embedding Consistent with Articulatory Topology", ["K. G. van Leeuwen", "P. Bos", "Stefano Trebeschi", "Maarten J. A. van Alphen", "Luuk Voskuilen", "Ludi E. Smeele", "Ferdi van der Heijden", "R. J. J. H. van Son"], "https://doi.org/10.21437/Interspeech.2019-1173", 5, "interspeech", 2019]], "Reinhold Haeb-Umbach": [0, ["Multi-Channel Block-Online Source Extraction Based on Utterance Adaptation", ["Juan M. Martin-Donas", "Jens Heitkaemper", "Reinhold Haeb-Umbach", "Angel M. Gomez", "Antonio M. Peinado"], "https://doi.org/10.21437/Interspeech.2019-2244", 5, "interspeech", 2019], ["Guided Source Separation Meets a Strong ASR Backend: Hitachi/Paderborn University Joint Investigation for Dinner Party ASR", ["Naoyuki Kanda", "Christoph Boddeker", "Jens Heitkaemper", "Yusuke Fujita", "Shota Horiguchi", "Kenji Nagamatsu", "Reinhold Haeb-Umbach"], "https://doi.org/10.21437/Interspeech.2019-1167", 5, "interspeech", 2019], ["Unsupervised Training of Neural Mask-Based Beamforming", ["Lukas Drude", "Jahn Heymann", "Reinhold Haeb-Umbach"], "https://doi.org/10.21437/Interspeech.2019-2549", 5, "interspeech", 2019], ["Privacy-Preserving Variational Information Feature Extraction for Domestic Activity Monitoring versus Speaker Identification", ["Alexandru Nelus", "Janek Ebbers", "Reinhold Haeb-Umbach", "Rainer Martin"], "https://doi.org/10.21437/Interspeech.2019-1703", 5, "interspeech", 2019]], "Shiv Vitaladevuni": [0, ["Sub-Band Convolutional Neural Networks for Small-Footprint Spoken Term Classification", ["Chieh-Chi Kao", "Ming Sun", "Yixin Gao", "Shiv Vitaladevuni", "Chao Wang"], "https://doi.org/10.21437/Interspeech.2019-1766", 5, "interspeech", 2019]], "Shaojun Wang": [9.557537055115972e-07, ["Cross-Lingual, Multi-Speaker Text-To-Speech Synthesis Using Neural Speaker Embedding", ["Mengnan Chen", "Minchuan Chen", "Shuang Liang", "Jun Ma", "Lei Chen", "Shaojun Wang", "Jing Xiao"], "https://doi.org/10.21437/Interspeech.2019-1632", 5, "interspeech", 2019]], "Pilar Oplustil Gallegos": [0, ["Investigating the Robustness of Sequence-to-Sequence Text-to-Speech Models to Imperfectly-Transcribed Training Data", ["Jason Fong", "Pilar Oplustil Gallegos", "Zack Hodari", "Simon King"], "https://doi.org/10.21437/Interspeech.2019-1824", 5, "interspeech", 2019]], "Jeong-Uk Bang": [0.9999900758266449, ["Extending an Acoustic Data-Driven Phone Set for Spontaneous Speech Recognition", ["Jeong-Uk Bang", "Mu-Yeol Choi", "Sang-Hun Kim", "Oh-Wook Kwon"], "https://doi.org/10.21437/Interspeech.2019-1979", 5, "interspeech", 2019]], "Clinton Fookes": [0, ["A Study of x-Vector Based Speaker Recognition on Short Utterances", ["Ahilan Kanagasundaram", "Sridha Sridharan", "Ganapathy Sriram", "S. Prachi", "Clinton Fookes"], "https://doi.org/10.21437/Interspeech.2019-1891", 5, "interspeech", 2019]], "Jiaqi Guo": [0, ["Joint Decoding of CTC Based Systems for Speech Recognition", ["Jiaqi Guo", "Yongbin You", "Yanmin Qian", "Kai Yu"], "https://doi.org/10.21437/Interspeech.2019-2026", 5, "interspeech", 2019]], "Murali Karthick Baskar": [0, ["Analysis of Multilingual Sequence-to-Sequence Speech Recognition Systems", ["Martin Karafiat", "Murali Karthick Baskar", "Shinji Watanabe", "Takaaki Hori", "Matthew Wiesner", "Jan Cernocky"], "https://doi.org/10.21437/Interspeech.2019-2355", 5, "interspeech", 2019], ["Semi-Supervised Sequence-to-Sequence ASR Using Unpaired Speech and Text", ["Murali Karthick Baskar", "Shinji Watanabe", "Ramon Fernandez Astudillo", "Takaaki Hori", "Lukas Burget", "Jan Cernocky"], "https://doi.org/10.21437/Interspeech.2019-3167", 5, "interspeech", 2019]], "Jenny Tippmann": [0, ["The Influence of Distraction on Speech Processing: How Selective is Selective Attention?", ["Sandra I. Parhammer", "Miriam Ebersberg", "Jenny Tippmann", "Katja Stark", "Andreas Opitz", "Barbara Hinger", "Sonja Rossi"], "https://doi.org/10.21437/Interspeech.2019-2699", 5, "interspeech", 2019]], "Sri Harsha Dumpala": [0, ["Excitation Source and Vocal Tract System Based Acoustic Features for Detection of Nasals in Continuous Speech", ["Bhanu Teja Nellore", "Sri Harsha Dumpala", "Karan Nathwani", "Suryakanth V. Gangashetty"], "https://doi.org/10.21437/Interspeech.2019-2785", 5, "interspeech", 2019], ["End-to-End Spoken Language Understanding: Bootstrapping in Low Resource Scenarios", ["Swapnil Bhosale", "Imran Sheikh", "Sri Harsha Dumpala", "Sunil Kumar Kopparapu"], "https://doi.org/10.21437/Interspeech.2019-2366", 5, "interspeech", 2019]], "Langzhou Chen": [0, ["Acoustic Model Bootstrapping Using Semi-Supervised Learning", ["Langzhou Chen", "Volker Leutnant"], "https://doi.org/10.21437/Interspeech.2019-2818", 5, "interspeech", 2019]], "Takashi Maekaku": [0, ["Simultaneous Detection and Localization of a Wake-Up Word Using Multi-Task Learning of the Duration and Endpoint", ["Takashi Maekaku", "Yusuke Kida", "Akihiko Sugiyama"], "https://doi.org/10.21437/Interspeech.2019-1180", 5, "interspeech", 2019]], "Zhong Meng": [0, ["Speaker Adaptation for Attention-Based End-to-End Speech Recognition", ["Zhong Meng", "Yashesh Gaur", "Jinyu Li", "Yifan Gong"], "https://doi.org/10.21437/Interspeech.2019-3135", 5, "interspeech", 2019], ["Acoustic-to-Phrase Models for Speech Recognition", ["Yashesh Gaur", "Jinyu Li", "Zhong Meng", "Yifan Gong"], "https://doi.org/10.21437/Interspeech.2019-3056", 5, "interspeech", 2019]], "Xiaoxiao Miao": [0, ["A New Time-Frequency Attention Mechanism for TDNN and CNN-LSTM-TDNN, with Application to Language Identification", ["Xiaoxiao Miao", "Ian McLoughlin", "Yonghong Yan"], "https://doi.org/10.21437/Interspeech.2019-1256", 5, "interspeech", 2019]], "Anoop Cherian": [0, ["Joint Student-Teacher Learning for Audio-Visual Scene-Aware Dialog", ["Chiori Hori", "Anoop Cherian", "Tim K. Marks", "Takaaki Hori"], "https://doi.org/10.21437/Interspeech.2019-3143", 5, "interspeech", 2019]], "Alexander Sorin": [0, ["High Quality, Lightweight and Adaptable TTS Using LPCNet", ["Zvi Kons", "Slava Shechtman", "Alexander Sorin", "Carmel Rabinovitz", "Ron Hoory"], "https://doi.org/10.21437/Interspeech.2019-1705", 5, "interspeech", 2019]], "Ying Zhou": [0, ["Robust DOA Estimation Based on Convolutional Neural Network and Time-Frequency Masking", ["Wangyou Zhang", "Ying Zhou", "Yanmin Qian"], "https://doi.org/10.21437/Interspeech.2019-3158", 5, "interspeech", 2019]], "Sandra I. Parhammer": [0, ["The Influence of Distraction on Speech Processing: How Selective is Selective Attention?", ["Sandra I. Parhammer", "Miriam Ebersberg", "Jenny Tippmann", "Katja Stark", "Andreas Opitz", "Barbara Hinger", "Sonja Rossi"], "https://doi.org/10.21437/Interspeech.2019-2699", 5, "interspeech", 2019]], "Daniele Salvati": [0, ["End-to-End Speaker Identification in Noisy and Reverberant Environments Using Raw Waveform Convolutional Neural Networks", ["Daniele Salvati", "Carlo Drioli", "Gian Luca Foresti"], "https://doi.org/10.21437/Interspeech.2019-2403", 5, "interspeech", 2019]], "Soumaya Gharsellaoui": [0, ["Linear Discriminant Differential Evolution for Feature Selection in Emotional Speech Recognition", ["Soumaya Gharsellaoui", "Sid-Ahmed Selouani", "Mohammed Sidi Yakoub"], "https://doi.org/10.21437/Interspeech.2019-1218", 5, "interspeech", 2019]], "Tanel Alumae": [0, ["Recognition of Creaky Voice from Emergency Calls", ["Lauri Tavi", "Tanel Alumae", "Stefan Werner"], "https://doi.org/10.21437/Interspeech.2019-1253", 5, "interspeech", 2019]], "Atsushi Ando": [0, ["Improving Conversation-Context Language Models with Multiple Spoken Language Understanding Models", ["Ryo Masumura", "Tomohiro Tanaka", "Atsushi Ando", "Hosana Kamiyama", "Takanobu Oba", "Satoshi Kobashikawa", "Yushi Aono"], "https://doi.org/10.21437/Interspeech.2019-1534", 5, "interspeech", 2019], ["Speech Emotion Recognition Based on Multi-Label Emotion Existence Model", ["Atsushi Ando", "Ryo Masumura", "Hosana Kamiyama", "Satoshi Kobashikawa", "Yushi Aono"], "https://doi.org/10.21437/Interspeech.2019-2524", 5, "interspeech", 2019], ["Does the Lombard Effect Improve Emotional Communication in Noise? - Analysis of Emotional Speech Acted in Noise", ["Yi Zhao", "Atsushi Ando", "Shinji Takaki", "Junichi Yamagishi", "Satoshi Kobashikawa"], "https://doi.org/10.21437/Interspeech.2019-1605", 5, "interspeech", 2019]], "Guanjun Li": [0, ["Direction-Aware Speaker Beam for Multi-Channel Speaker Extraction", ["Guanjun Li", "Shan Liang", "Shuai Nie", "Wenju Liu", "Meng Yu", "Lianwu Chen", "Shouye Peng", "Changliang Li"], "https://doi.org/10.21437/Interspeech.2019-1474", 5, "interspeech", 2019]], "John Chen": [0, ["Neural Transition Systems for Modeling Hierarchical Semantic Representations", ["Riyaz Ahmad Bhat", "John Chen", "Rashmi Prasad", "Srinivas Bangalore"], "https://doi.org/10.21437/Interspeech.2019-3075", 5, "interspeech", 2019]], "Sidney S. Fels": [0, ["SPEAK YOUR MIND! Towards Imagined Speech Recognition with Hierarchical Deep Learning", ["Pramit Saha", "Muhammad Abdul-Mageed", "Sidney S. Fels"], "https://doi.org/10.21437/Interspeech.2019-3041", 5, "interspeech", 2019], ["An Extended Two-Dimensional Vocal Tract Model for Fast Acoustic Simulation of Single-Axis Symmetric Three-Dimensional Tubes", ["Debasish Ray Mohapatra", "Victor Zappi", "Sidney S. Fels"], "https://doi.org/10.21437/Interspeech.2019-1764", 5, "interspeech", 2019]], "Atsunori Ogawa": [0, ["End-to-End SpeakerBeam for Single Channel Target Speech Recognition", ["Marc Delcroix", "Shinji Watanabe", "Tsubasa Ochiai", "Keisuke Kinoshita", "Shigeki Karita", "Atsunori Ogawa", "Tomohiro Nakatani"], "https://doi.org/10.21437/Interspeech.2019-1856", 5, "interspeech", 2019], ["Improving Transformer-Based End-to-End Speech Recognition with Connectionist Temporal Classification and Language Model Integration", ["Shigeki Karita", "Nelson Enrique Yalta Soplin", "Shinji Watanabe", "Marc Delcroix", "Atsunori Ogawa", "Tomohiro Nakatani"], "https://doi.org/10.21437/Interspeech.2019-1938", 5, "interspeech", 2019], ["Multimodal SpeakerBeam: Single Channel Target Speech Extraction with Audio-Visual Speaker Clues", ["Tsubasa Ochiai", "Marc Delcroix", "Keisuke Kinoshita", "Atsunori Ogawa", "Tomohiro Nakatani"], "https://doi.org/10.21437/Interspeech.2019-1513", 5, "interspeech", 2019], ["Improved Deep Duel Model for Rescoring N-Best Speech Recognition List Using Backward LSTMLM and Ensemble Encoders", ["Atsunori Ogawa", "Marc Delcroix", "Shigeki Karita", "Tomohiro Nakatani"], "https://doi.org/10.21437/Interspeech.2019-1949", 5, "interspeech", 2019], ["Predicting Speech Intelligibility of Enhanced Speech Using Phone Accuracy of DNN-Based ASR System", ["Kenichi Arai", "Shoko Araki", "Atsunori Ogawa", "Keisuke Kinoshita", "Tomohiro Nakatani", "Katsuhiko Yamamoto", "Toshio Irino"], "https://doi.org/10.21437/Interspeech.2019-1381", 5, "interspeech", 2019]], "Julien Karadayi": [0, ["The Zero Resource Speech Challenge 2019: TTS Without T", ["Ewan Dunbar", "Robin Algayres", "Julien Karadayi", "Mathieu Bernard", "Juan Benjumea", "Xuan-Nga Cao", "Lucie Miskic", "Charlotte Dugrain", "Lucas Ondel", "Alan W. Black", "Laurent Besacier", "Sakriani Sakti", "Emmanuel Dupoux"], "https://doi.org/10.21437/Interspeech.2019-2904", 5, "interspeech", 2019]], "Hannah Leykum": [0, ["Sound Tools eXtended (STx) 5.0 - A Powerful Sound Analysis Tool Optimized for Speech", ["Anton Noll", "Jonathan Stuefer", "Nicola Klingler", "Hannah Leykum", "Carina Lozo", "Jan Luttenberger", "Michael Pucher", "Carolin Schmid"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8022.html", 2, "interspeech", 2019]], "Federico Marinelli": [0, ["Active Annotation: Bootstrapping Annotation Lexicon and Guidelines for Supervised NLU Learning", ["Federico Marinelli", "Alessandra Cervone", "Giuliano Tortoreto", "Evgeny A. Stepanov", "Giuseppe Di Fabbrizio", "Giuseppe Riccardi"], "https://doi.org/10.21437/Interspeech.2019-2537", 5, "interspeech", 2019]], "Christopher Oates": [0, ["Robust Speech Emotion Recognition Under Different Encoding Conditions", ["Christopher Oates", "Andreas Triantafyllopoulos", "Ingmar Steiner", "Bjorn W. Schuller"], "https://doi.org/10.21437/Interspeech.2019-1658", 5, "interspeech", 2019]], "Jichen Yang": [0.00023265991330845281, ["Long Range Acoustic Features for Spoofed Speech Detection", ["Rohan Kumar Das", "Jichen Yang", "Haizhou Li"], "https://doi.org/10.21437/Interspeech.2019-1887", 5, "interspeech", 2019], ["Device Feature Extractor for Replay Spoofing Detection", ["Chang Huai You", "Jichen Yang", "Huy Dat Tran"], "https://doi.org/10.21437/Interspeech.2019-2137", 5, "interspeech", 2019]], "Jeff Mielke": [0, ["The Different Roles of Expectations in Phonetic and Lexical Processing", ["Shiri Lev-Ari", "Robin Dodsworth", "Jeff Mielke", "Sharon Peperkamp"], "https://doi.org/10.21437/Interspeech.2019-1795", 5, "interspeech", 2019]], "Thomas F. Quatieri": [0, ["Assessing Neuromotor Coordination in Depression Using Inverted Vocal Tract Variables", ["Carol Y. Espy-Wilson", "Adam C. Lammert", "Nadee Seneviratne", "Thomas F. Quatieri"], "https://doi.org/10.21437/Interspeech.2019-1815", 5, "interspeech", 2019], ["Vocal Biomarker Assessment Following Pediatric Traumatic Brain Injury: A Retrospective Cohort Study", ["Camille Noufi", "Adam C. Lammert", "Daryush D. Mehta", "James R. Williamson", "Gregory Ciccarelli", "Douglas E. Sturim", "Jordan R. Green", "Thomas F. Campbell", "Thomas F. Quatieri"], "https://doi.org/10.21437/Interspeech.2019-1200", 5, "interspeech", 2019]], "Gerard Chollet": [0, ["Explaining Sentiment Classification", ["Marvin Rajwadi", "Cornelius Glackin", "Julie A. Wall", "Gerard Chollet", "Nigel Cannings"], "https://doi.org/10.21437/Interspeech.2019-2743", 5, "interspeech", 2019]], "Wei Xue": [0, ["Direct-Path Signal Cross-Correlation Estimation for Sound Source Localization in Reverberation", ["Wei Xue", "Ying Tong", "Guohong Ding", "Chao Zhang", "Tao Ma", "Xiaodong He", "Bowen Zhou"], "https://doi.org/10.21437/Interspeech.2019-1488", 5, "interspeech", 2019]], "Doris Mucke": [0, ["Strength and Structure: Coupling Tones with Oral Constriction Gestures", ["Doris Mucke", "Anne Hermes", "Sam Tilsen"], "https://doi.org/10.21437/Interspeech.2019-2650", 5, "interspeech", 2019], ["Dimensions of Prosodic Prominence in an Attractor Model", ["Simon Roessig", "Doris Mucke", "Lena Pagel"], "https://doi.org/10.21437/Interspeech.2019-2227", 5, "interspeech", 2019], ["Intragestural Variation in Natural Sentence Production: Essential Tremor Patients Treated with DBS", ["Anne Hermes", "Doris Mucke", "Tabea Thies", "Michael T. Barbe"], "https://doi.org/10.21437/Interspeech.2019-2389", 5, "interspeech", 2019]], "Youngmoon Jung": [0.9995688796043396, ["Spatial Pyramid Encoding with Convex Length Normalization for Text-Independent Speaker Verification", ["Youngmoon Jung", "Younggwan Kim", "Hyungjun Lim", "Yeunju Choi", "Hoirin Kim"], "https://doi.org/10.21437/Interspeech.2019-2177", 5, "interspeech", 2019]], "Tracy Rohlin": [0, ["Neural Machine Translation for Multilingual Grapheme-to-Phoneme Conversion", ["Alex Sokolov", "Tracy Rohlin", "Ariya Rastrow"], "https://doi.org/10.21437/Interspeech.2019-3176", 5, "interspeech", 2019]], "Beomjun Shin": [0.9999888241291046, ["Temporal Convolution for Real-Time Keyword Spotting on Mobile Devices", ["Seungwoo Choi", "Seokjun Seo", "Beomjun Shin", "Hyeongmin Byun", "Martin Kersner", "Beomsu Kim", "Dongyoung Kim", "Sungjoo Ha"], "https://doi.org/10.21437/Interspeech.2019-1363", 5, "interspeech", 2019]], "Stefano Trebeschi": [0, ["CNN-Based Phoneme Classifier from Vocal Tract MRI Learns Embedding Consistent with Articulatory Topology", ["K. G. van Leeuwen", "P. Bos", "Stefano Trebeschi", "Maarten J. A. van Alphen", "Luuk Voskuilen", "Ludi E. Smeele", "Ferdi van der Heijden", "R. J. J. H. van Son"], "https://doi.org/10.21437/Interspeech.2019-1173", 5, "interspeech", 2019]], "Kenneth Church": [0, ["The Second DIHARD Diarization Challenge: Dataset, Task, and Baselines", ["Neville Ryant", "Kenneth Church", "Christopher Cieri", "Alejandrina Cristia", "Jun Du", "Sriram Ganapathy", "Mark Liberman"], "https://doi.org/10.21437/Interspeech.2019-1268", 5, "interspeech", 2019]], "Sheng Zhao": [0, ["Token-Level Ensemble Distillation for Grapheme-to-Phoneme Conversion", ["Hao Sun", "Xu Tan", "Jun-Wei Gan", "Hongzhi Liu", "Sheng Zhao", "Tao Qin", "Tie-Yan Liu"], "https://doi.org/10.21437/Interspeech.2019-1208", 5, "interspeech", 2019]], "Uliyana Kubasova": [0, ["Analyzing Verbal and Nonverbal Features for Predicting Group Performance", ["Uliyana Kubasova", "Gabriel Murray", "McKenzie Braley"], "https://doi.org/10.21437/Interspeech.2019-3062", 5, "interspeech", 2019]], "Daniel Duran": [0, ["Individual Differences in Implicit Attention to Phonetic Detail in Speech Perception", ["Natalie Lewandowski", "Daniel Duran"], "https://doi.org/10.21437/Interspeech.2019-2989", 5, "interspeech", 2019]], "Radoslaw Bialobrzeski": [0, ["Robust Bayesian and Light Neural Networks for Voice Spoofing Detection", ["Radoslaw Bialobrzeski", "Michal Kosmider", "Mateusz Matuszewski", "Marcin Plata", "Alexander Rakowski"], "https://doi.org/10.21437/Interspeech.2019-2676", 5, "interspeech", 2019]], "Jun Deng": [0, ["Autonomous Emotion Learning in Speech: A View of Zero-Shot Speech Emotion Recognition", ["Xinzhou Xu", "Jun Deng", "Nicholas Cummins", "Zixing Zhang", "Li Zhao", "Bjorn W. Schuller"], "https://doi.org/10.21437/Interspeech.2019-2406", 5, "interspeech", 2019]], "Yermiyahu Hauptman": [0, ["Identifying Distinctive Acoustic and Spectral Features in Parkinson's Disease", ["Yermiyahu Hauptman", "Ruth Aloni-Lavi", "Itshak Lapidot", "Tanya Gurevich", "Yael Manor", "Stav Naor", "Noa Diamant", "Irit Opher"], "https://doi.org/10.21437/Interspeech.2019-2465", 5, "interspeech", 2019]], "Samarendra Dandapat": [0, ["Nasal Air Emission in Sibilant Fricatives of Cleft Lip and Palate Speech", ["Sishir Kalita", "Protima Nomo Sudro", "S. R. Mahadeva Prasanna", "Samarendra Dandapat"], "https://doi.org/10.21437/Interspeech.2019-2345", 5, "interspeech", 2019]], "Felix Schaeffler": [0, ["Reliability of Clinical Voice Parameters Captured with Smartphones - Measurements of Added Noise and Spectral Tilt", ["Felix Schaeffler", "Stephen Jannetts", "Janet Beck"], "https://doi.org/10.21437/Interspeech.2019-2910", 5, "interspeech", 2019]], "Haiwei Wu": [5.125520146975759e-06, ["The DKU Replay Detection System for the ASVspoof 2019 Challenge: On Data Augmentation, Feature Representation, Classification, and Fusion", ["Weicheng Cai", "Haiwei Wu", "Danwei Cai", "Ming Li"], "https://doi.org/10.21437/Interspeech.2019-1230", 5, "interspeech", 2019], ["The DKU-LENOVO Systems for the INTERSPEECH 2019 Computational Paralinguistic Challenge", ["Haiwei Wu", "Weiqing Wang", "Ming Li"], "https://doi.org/10.21437/Interspeech.2019-1386", 5, "interspeech", 2019]], "Mansi Aggarwal": [0, ["Hush-Hush Speak: Speech Reconstruction Using Silent Videos", ["Shashwat Uttam", "Yaman Kumar", "Dhruva Sahrawat", "Mansi Aggarwal", "Rajiv Ratn Shah", "Debanjan Mahata", "Amanda Stent"], "https://doi.org/10.21437/Interspeech.2019-3269", 5, "interspeech", 2019]], "Lubos Smidl": [0, ["Multimodal Dialog with the MALACH Audiovisual Archive", ["Adam Chylek", "Lubos Smidl", "Jan Svec"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8011.html", 2, "interspeech", 2019]], "Johannes Gehrke": [0, ["A Scalable Noisy Speech Dataset and Online Subjective Test Framework", ["Chandan K. A. Reddy", "Ebrahim Beyrami", "Jamie Pool", "Ross Cutler", "Sriram Srinivasan", "Johannes Gehrke"], "https://doi.org/10.21437/Interspeech.2019-3087", 5, "interspeech", 2019], ["Supervised Classifiers for Audio Impairments with Noisy Labels", ["Chandan K. A. Reddy", "Ross Cutler", "Johannes Gehrke"], "https://doi.org/10.21437/Interspeech.2019-3074", 5, "interspeech", 2019]], "Guitang Lan": [0, ["Scalable Multi Corpora Neural Language Models for ASR", ["Anirudh Raju", "Denis Filimonov", "Gautam Tiwari", "Guitang Lan", "Ariya Rastrow"], "https://doi.org/10.21437/Interspeech.2019-3060", 5, "interspeech", 2019]], "Nitin Madnani": [0, ["Automated Estimation of Oral Reading Fluency During Summer Camp e-Book Reading with MyTurnToRead", ["Anastassia Loukina", "Beata Beigman Klebanov", "Patrick L. Lange", "Yao Qian", "Binod Gyawali", "Nitin Madnani", "Abhinav Misra", "Klaus Zechner", "Zuowei Wang", "John Sabatini"], "https://doi.org/10.21437/Interspeech.2019-2889", 5, "interspeech", 2019]], "Manna Wang": [0.007606753846630454, ["Acoustic Characteristics of Lexical Tone Disruption in Mandarin Speakers After Brain Damage", ["Wenjun Chen", "Jeroen van de Weijer", "Shuangshuang Zhu", "Qian Qian", "Manna Wang"], "https://doi.org/10.21437/Interspeech.2019-2432", 5, "interspeech", 2019]], "Bettina Braun": [0, ["The Processing of Prosodic Cues to Rhetorical Question Interpretation: Psycholinguistic and Neurolinguistics Evidence", ["Mariya Kharaman", "Manluolan Xu", "Carsten Eulitz", "Bettina Braun"], "https://doi.org/10.21437/Interspeech.2019-2528", 5, "interspeech", 2019]], "Bidisha Sharma": [0, ["A Combination of Model-Based and Feature-Based Strategy for Speech-to-Singing Alignment", ["Bidisha Sharma", "Haizhou Li"], "https://doi.org/10.21437/Interspeech.2019-1942", 5, "interspeech", 2019], ["Multi-Level Adaptive Speech Activity Detector for Speech in Naturalistic Environments", ["Bidisha Sharma", "Rohan Kumar Das", "Haizhou Li"], "https://doi.org/10.21437/Interspeech.2019-1928", 5, "interspeech", 2019], ["On the Importance of Audio-Source Separation for Singer Identification in Polyphonic Music", ["Bidisha Sharma", "Rohan Kumar Das", "Haizhou Li"], "https://doi.org/10.21437/Interspeech.2019-1925", 5, "interspeech", 2019], ["NUS Speak-to-Sing: A Web Platform for Personalized Speech-to-Singing Conversion", ["Chitralekha Gupta", "Karthika Vijayan", "Bidisha Sharma", "Xiaoxue Gao", "Haizhou Li"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8041.html", 2, "interspeech", 2019]], "Pradeep Reddy": [0, ["Comparison of Speech Tasks and Recording Devices for Voice Based Automatic Classification of Healthy Subjects and Patients with Amyotrophic Lateral Sclerosis", ["Suhas B. N.", "Deep Patel", "Nithin Rao Koluguri", "Yamini Belur", "Pradeep Reddy", "Atchayaram Nalini", "Ravi Yadav", "Dipanjan Gope", "Prasanta Kumar Ghosh"], "https://doi.org/10.21437/Interspeech.2019-1285", 5, "interspeech", 2019]], "Jarek Krajewski": [0, ["The INTERSPEECH 2019 Computational Paralinguistics Challenge: Styrian Dialects, Continuous Sleepiness, Baby Sounds & Orca Activity", ["Bjorn W. Schuller", "Anton Batliner", "Christian Bergler", "Florian B. Pokorny", "Jarek Krajewski", "Margaret Cychosz", "Ralf Vollmann", "Sonja-Dana Roelen", "Sebastian Schnieder", "Elika Bergelson", "Alejandrina Cristia", "Amanda Seidl", "Anne S. Warlaumont", "Lisa Yankowitz", "Elmar Noth", "Shahin Amiriparian", "Simone Hantke", "Maximilian Schmitt"], "https://doi.org/10.21437/Interspeech.2019-1122", 5, "interspeech", 2019]], "Suyoun Kim": [0.9995113462209702, ["Cross-Attention End-to-End ASR for Two-Party Conversations", ["Suyoun Kim", "Siddharth Dalmia", "Florian Metze"], "https://doi.org/10.21437/Interspeech.2019-3173", 5, "interspeech", 2019]], "Shankar M. Venkatesan": [0, ["Real Time Online Visual End Point Detection Using Unidirectional LSTM", ["Tanay Sharma", "Rohith Chandrashekar Aralikatti", "Dilip Kumar Margam", "Abhinav Thanda", "Sharad Roy", "Pujitha Appan Kandala", "Shankar M. Venkatesan"], "https://doi.org/10.21437/Interspeech.2019-3253", 5, "interspeech", 2019], ["Speaker Adaptation for Lip-Reading Using Visual Identity Vectors", ["Pujitha Appan Kandala", "Abhinav Thanda", "Dilip Kumar Margam", "Rohith Chandrashekar Aralikatti", "Tanay Sharma", "Sharad Roy", "Shankar M. Venkatesan"], "https://doi.org/10.21437/Interspeech.2019-3237", 5, "interspeech", 2019]], "Yi Chang": [0.0003460402149357833, ["Follow-Up Question Generation Using Neural Tensor Network-Based Domain Ontology Population in an Interview Coaching System", ["Ming-Hsiang Su", "Chung-Hsien Wu", "Yi Chang"], "https://doi.org/10.21437/Interspeech.2019-1300", 5, "interspeech", 2019]], "Jia Liu": [0, ["Large Margin Softmax Loss for Speaker Verification", ["Yi Liu", "Liang He", "Jia Liu"], "https://doi.org/10.21437/Interspeech.2019-2357", 5, "interspeech", 2019]], "Liming Chen": [0, ["Two-Dimensional Convolutional Recurrent Neural Networks for Speech Activity Detection", ["Anastasios Vafeiadis", "Eleftherios Fanioudakis", "Ilyas Potamitis", "Konstantinos Votis", "Dimitrios Giakoumis", "Dimitrios Tzovaras", "Liming Chen", "Raouf Hamzaoui"], "https://doi.org/10.21437/Interspeech.2019-1354", 5, "interspeech", 2019]], "Junjie Wang": [0.001049823418725282, ["The LeVoice Far-Field Speech Recognition System for VOiCES from a Distance Challenge 2019", ["Yulong Liang", "Lin Yang", "Xuyang Wang", "Yingjie Li", "Chen Jia", "Junjie Wang"], "https://doi.org/10.21437/Interspeech.2019-1944", 5, "interspeech", 2019]], "Xiaoyi Qin": [0, ["Polyphone Disambiguation for Mandarin Chinese Using Conditional Neural Network with Multi-Level Embedding Features", ["Zexin Cai", "Yaogen Yang", "Chuxiong Zhang", "Xiaoyi Qin", "Ming Li"], "https://doi.org/10.21437/Interspeech.2019-1235", 5, "interspeech", 2019], ["The DKU System for the Speaker Recognition Task of the 2019 VOiCES from a Distance Challenge", ["Danwei Cai", "Xiaoyi Qin", "Weicheng Cai", "Ming Li"], "https://doi.org/10.21437/Interspeech.2019-1435", 5, "interspeech", 2019], ["Far-Field End-to-End Text-Dependent Speaker Verification Based on Mixed Training Data with Transfer Learning and Enrollment Data Augmentation", ["Xiaoyi Qin", "Danwei Cai", "Ming Li"], "https://doi.org/10.21437/Interspeech.2019-1542", 5, "interspeech", 2019], ["Multi-Channel Training for End-to-End Speaker Recognition Under Reverberant and Noisy Environment", ["Danwei Cai", "Xiaoyi Qin", "Ming Li"], "https://doi.org/10.21437/Interspeech.2019-1437", 5, "interspeech", 2019]], "Oleg Rybakov": [0, ["Two Tiered Distributed Training Algorithm for Acoustic Modeling", ["Pranav Ladkat", "Oleg Rybakov", "Radhika Arava", "Sree Hari Krishnan Parthasarathi", "I-Fan Chen", "Nikko Strom"], "https://doi.org/10.21437/Interspeech.2019-1859", 5, "interspeech", 2019]], "Shuai Nie": [0, ["Jointly Adversarial Enhancement Training for Robust End-to-End Speech Recognition", ["Bin Liu", "Shuai Nie", "Shan Liang", "Wenju Liu", "Meng Yu", "Lianwu Chen", "Shouye Peng", "Changliang Li"], "https://doi.org/10.21437/Interspeech.2019-1242", 5, "interspeech", 2019], ["Direction-Aware Speaker Beam for Multi-Channel Speaker Extraction", ["Guanjun Li", "Shan Liang", "Shuai Nie", "Wenju Liu", "Meng Yu", "Lianwu Chen", "Shouye Peng", "Changliang Li"], "https://doi.org/10.21437/Interspeech.2019-1474", 5, "interspeech", 2019]], "Satoshi Nakamura": [0, ["VQVAE Unsupervised Unit Discovery and Multi-Scale Code2Spec Inverter for Zerospeech Challenge 2019", ["Andros Tjandra", "Berrak Sisman", "Mingyang Zhang", "Sakriani Sakti", "Haizhou Li", "Satoshi Nakamura"], "https://doi.org/10.21437/Interspeech.2019-3232", 5, "interspeech", 2019], ["Speech Quality Evaluation of Synthesized Japanese Speech Using EEG", ["Ivan Halim Parmonangan", "Hiroki Tanaka", "Sakriani Sakti", "Shinnosuke Takamichi", "Satoshi Nakamura"], "https://doi.org/10.21437/Interspeech.2019-2059", 5, "interspeech", 2019], ["Sequence-to-Sequence Learning via Attention Transfer for Incremental Speech Recognition", ["Sashi Novitasari", "Andros Tjandra", "Sakriani Sakti", "Satoshi Nakamura"], "https://doi.org/10.21437/Interspeech.2019-2985", 5, "interspeech", 2019], ["An Incremental Turn-Taking Model for Task-Oriented Dialog Systems", ["Andrei C. Coman", "Koichiro Yoshino", "Yukitoshi Murase", "Satoshi Nakamura", "Giuseppe Riccardi"], "https://doi.org/10.21437/Interspeech.2019-1826", 5, "interspeech", 2019]], "Yun-Shao Lin": [0, ["Predicting Group Performances Using a Personality Composite-Network Architecture During Collaborative Task", ["Shun-Chang Zhong", "Yun-Shao Lin", "Chun-Min Chang", "Yi-Ching Liu", "Chi-Chun Lee"], "https://doi.org/10.21437/Interspeech.2019-2087", 5, "interspeech", 2019], ["Enforcing Semantic Consistency for Cross Corpus Valence Regression from Speech Using Adversarial Discrepancy Learning", ["Gao-Yi Chao", "Yun-Shao Lin", "Chun-Min Chang", "Chi-Chun Lee"], "https://doi.org/10.21437/Interspeech.2019-2037", 5, "interspeech", 2019]], "Bo Wang": [0.0001360086680506356, ["A Path Signature Approach for Speech Emotion Recognition", ["Bo Wang", "Maria Liakata", "Hao Ni", "Terry Lyons", "Alejo J. Nevado-Holgado", "Kate Saunders"], "https://doi.org/10.21437/Interspeech.2019-2624", 5, "interspeech", 2019]], "Jiamin Xie": [0, ["Multi-PLDA Diarization on Children's Speech", ["Jiamin Xie", "Leibny Paola Garcia-Perera", "Daniel Povey", "Sanjeev Khudanpur"], "https://doi.org/10.21437/Interspeech.2019-2961", 5, "interspeech", 2019]], "Tarik Mrech": [0, ["Employing Bottleneck and Convolutional Features for Speech-Based Physical Load Detection on Limited Data Amounts", ["Olga Egorow", "Tarik Mrech", "Norman Weisskirchen", "Andreas Wendemuth"], "https://doi.org/10.21437/Interspeech.2019-2502", 5, "interspeech", 2019]], "Razvan C. Bunescu": [0, ["Diagnosing Dysarthria with Long Short-Term Memory Networks", ["Alex Mayle", "Zhiwei Mou", "Razvan C. Bunescu", "Sadegh Mirshekarian", "Li Xu", "Chang Liu"], "https://doi.org/10.21437/Interspeech.2019-2903", 5, "interspeech", 2019]], "Kai-Cheng Wu": [3.994589405920124e-06, ["Transfer-Representation Learning for Detecting Spoofing Attacks with Converted and Synthesized Speech in Automatic Speaker Verification System", ["Su-Yu Chang", "Kai-Cheng Wu", "Chia-Ping Chen"], "https://doi.org/10.21437/Interspeech.2019-2014", 5, "interspeech", 2019]], "Tsukasa Yoshinaga": [0, ["Individual Differences of Airflow and Sound Generation in the Vocal Tract of Sibilant /s/", ["Tsukasa Yoshinaga", "Kazunori Nozaki", "Shigeo Wada"], "https://doi.org/10.21437/Interspeech.2019-1376", 5, "interspeech", 2019]], "Shahin Amiriparian": [0, ["Using Speech to Predict Sequentially Measured Cortisol Levels During a Trier Social Stress Test", ["Alice Baird", "Shahin Amiriparian", "Nicholas Cummins", "Sarah Sturmbauer", "Johanna Janson", "Eva-Maria Messner", "Harald Baumeister", "Nicolas Rohleder", "Bjorn W. Schuller"], "https://doi.org/10.21437/Interspeech.2019-1352", 5, "interspeech", 2019], ["The INTERSPEECH 2019 Computational Paralinguistics Challenge: Styrian Dialects, Continuous Sleepiness, Baby Sounds & Orca Activity", ["Bjorn W. Schuller", "Anton Batliner", "Christian Bergler", "Florian B. Pokorny", "Jarek Krajewski", "Margaret Cychosz", "Ralf Vollmann", "Sonja-Dana Roelen", "Sebastian Schnieder", "Elika Bergelson", "Alejandrina Cristia", "Amanda Seidl", "Anne S. Warlaumont", "Lisa Yankowitz", "Elmar Noth", "Shahin Amiriparian", "Simone Hantke", "Maximilian Schmitt"], "https://doi.org/10.21437/Interspeech.2019-1122", 5, "interspeech", 2019]], "Christian dHereuse": [0, ["Formant Pattern and Spectral Shape Ambiguity of Vowel Sounds, and Related Phenomena of Vowel Acoustics - Exemplary Evidence", ["Dieter Maurer", "Heidy Suter", "Christian dHereuse", "Volker Dellwo"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8017.html", 2, "interspeech", 2019]], "Hiroshi Sato": [0, ["End-to-End Automatic Speech Recognition with a Reconstruction Criterion Using Speech-to-Text and Text-to-Speech Encoder-Decoders", ["Ryo Masumura", "Hiroshi Sato", "Tomohiro Tanaka", "Takafumi Moriya", "Yusuke Ijima", "Takanobu Oba"], "https://doi.org/10.21437/Interspeech.2019-2111", 5, "interspeech", 2019], ["Neural Whispered Speech Detection with Imbalanced Learning", ["Takanori Ashihara", "Yusuke Shinohara", "Hiroshi Sato", "Takafumi Moriya", "Kiyoaki Matsui", "Takaaki Fukutomi", "Yoshikazu Yamaguchi", "Yushi Aono"], "https://doi.org/10.21437/Interspeech.2019-2161", 5, "interspeech", 2019]], "Catarina Oliveira": [0, ["On the Role of Oral Configurations in European Portuguese Nasal Vowels", ["Conceicao Cunha", "Samuel S. Silva", "Antonio J. S. Teixeira", "Catarina Oliveira", "Paula Martins", "Arun A. Joseph", "Jens Frahm"], "https://doi.org/10.21437/Interspeech.2019-2232", 5, "interspeech", 2019], ["Age-Related Changes in European Portuguese Vowel Acoustics", ["Luciana Albuquerque", "Catarina Oliveira", "Antonio J. S. Teixeira", "Pedro Sa-Couto", "Daniela Figueiredo"], "https://doi.org/10.21437/Interspeech.2019-1818", 5, "interspeech", 2019]], "Mengfei Wu": [2.038942348292494e-09, ["CNN-BLSTM Based Question Detection from Dialogs Considering Phase and Context Information", ["Yuke Si", "Longbiao Wang", "Jianwu Dang", "Mengfei Wu", "Aijun Li"], "https://doi.org/10.21437/Interspeech.2019-1701", 5, "interspeech", 2019]], "Houwei Cao": [0, ["Development of Emotion Rankers Based on Intended and Perceived Emotion Labels", ["Zhenghao Jin", "Houwei Cao"], "https://doi.org/10.21437/Interspeech.2019-1831", 5, "interspeech", 2019]], "Fernando Fernandez-Martinez": [0, ["Predicting Group-Level Skin Attention to Short Movies from Audio-Based LSTM-Mixture of Experts Models", ["Ricardo Kleinlein", "Cristina Luna Jimenez", "Juan Manuel Montero", "Zoraida Callejas", "Fernando Fernandez-Martinez"], "https://doi.org/10.21437/Interspeech.2019-2799", 5, "interspeech", 2019], ["Attention-Based Word Vector Prediction with LSTMs and its Application to the OOV Problem in ASR", ["Alejandro Coucheiro-Limeres", "Fernando Fernandez-Martinez", "Ruben San Segundo", "Javier Ferreiros Lopez"], "https://doi.org/10.21437/Interspeech.2019-2347", 5, "interspeech", 2019]], "Eugen Klein": [0, ["Assessing Acoustic and Articulatory Dimensions of Speech Motor Adaptation with Random Forests", ["Eugen Klein", "Jana Brunner", "Phil Hoole"], "https://doi.org/10.21437/Interspeech.2019-1812", 5, "interspeech", 2019]], "Hongzhi Liu": [0, ["Token-Level Ensemble Distillation for Grapheme-to-Phoneme Conversion", ["Hao Sun", "Xu Tan", "Jun-Wei Gan", "Hongzhi Liu", "Sheng Zhao", "Tao Qin", "Tie-Yan Liu"], "https://doi.org/10.21437/Interspeech.2019-1208", 5, "interspeech", 2019]], "Aleksei Romanenko": [0, ["R-Vectors: New Technique for Adaptation to Room Acoustics", ["Yuri Y. Khokhlov", "Alexander Zatvornitskiy", "Ivan Medennikov", "Ivan Sorokin", "Tatiana Prisyach", "Aleksei Romanenko", "Anton Mitrofanov", "Vladimir Bataev", "Andrei Andrusenko", "Mariya Korenevskaya", "Oleg Petrov"], "https://doi.org/10.21437/Interspeech.2019-2645", 5, "interspeech", 2019], ["The STC ASR System for the VOiCES from a Distance Challenge 2019", ["Ivan Medennikov", "Yuri Y. Khokhlov", "Aleksei Romanenko", "Ivan Sorokin", "Anton Mitrofanov", "Vladimir Bataev", "Andrei Andrusenko", "Tatiana Prisyach", "Mariya Korenevskaya", "Oleg Petrov", "Alexander Zatvornitskiy"], "https://doi.org/10.21437/Interspeech.2019-1574", 5, "interspeech", 2019], ["The STC ASR System for the VOiCES from a Distance Challenge 2019", ["Ivan Medennikov", "Yuri Y. Khokhlov", "Aleksei Romanenko", "Ivan Sorokin", "Anton Mitrofanov", "Vladimir Bataev", "Andrei Andrusenko", "Tatiana Prisyach", "Mariya Korenevskaya", "Oleg Petrov", "Alexander Zatvornitskiy"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/abs17.html", 0, "interspeech", 2019]], "Sining Sun": [0.010369112715125084, ["Unsupervised Adaptation with Adversarial Dropout Regularization for Robust Speech Recognition", ["Pengcheng Guo", "Sining Sun", "Lei Xie"], "https://doi.org/10.21437/Interspeech.2019-2544", 5, "interspeech", 2019], ["Adversarial Regularization for End-to-End Robust Speaker Verification", ["Qing Wang", "Pengcheng Guo", "Sining Sun", "Lei Xie", "John H. L. Hansen"], "https://doi.org/10.21437/Interspeech.2019-2983", 5, "interspeech", 2019]], "Thibault Viglino": [0, ["End-to-End Accented Speech Recognition", ["Thibault Viglino", "Petr Motlicek", "Milos Cernak"], "https://doi.org/10.21437/Interspeech.2019-2122", 5, "interspeech", 2019]], "Petr Mizera": [0, ["Self-Supervised Speaker Embeddings", ["Themos Stafylakis", "Johan Rohdin", "Oldrich Plchot", "Petr Mizera", "Lukas Burget"], "https://doi.org/10.21437/Interspeech.2019-2842", 5, "interspeech", 2019], ["Privacy-Preserving Speaker Recognition with Cohort Score Normalisation", ["Andreas Nautsch", "Jose Patino", "Amos Treiber", "Themos Stafylakis", "Petr Mizera", "Massimiliano Todisco", "Thomas Schneider", "Nicholas W. D. Evans"], "https://doi.org/10.21437/Interspeech.2019-2638", 5, "interspeech", 2019]], "Jack Parry": [0, ["Analysis of Deep Learning Architectures for Cross-Corpus Speech Emotion Recognition", ["Jack Parry", "Dimitri Palaz", "Georgia Clarke", "Pauline Lecomte", "Rebecca Mead", "Michael Berger", "Gregor Hofer"], "https://doi.org/10.21437/Interspeech.2019-2753", 5, "interspeech", 2019]], "Colin T. Annand": [0, ["Using Ultrasound Imaging to Create Augmented Visual Biofeedback for Articulatory Practice", ["Colin T. Annand", "Maurice Lamb", "Sarah Dugan", "Sarah R. Li", "Hannah M. Woeste", "T. Douglas Mast", "Michael A. Riley", "Jack A. Masterson", "Neeraja Mahalingam", "Kathryn J. Eary", "Caroline Spencer", "Suzanne Boyce", "Stephanie Jackson", "Anoosha Baxi", "Renee Seward"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8036.html", 2, "interspeech", 2019]], "Yiheng Jiang": [0, ["Improving Aggregation and Loss Function for Better Embedding Learning in End-to-End Speaker Verification System", ["Zhifu Gao", "Yan Song", "Ian McLoughlin", "Pengcheng Li", "Yiheng Jiang", "Li-Rong Dai"], "https://doi.org/10.21437/Interspeech.2019-1489", 5, "interspeech", 2019], ["An Effective Deep Embedding Learning Architecture for Speaker Verification", ["Yiheng Jiang", "Yan Song", "Ian McLoughlin", "Zhifu Gao", "Li-Rong Dai"], "https://doi.org/10.21437/Interspeech.2019-1606", 5, "interspeech", 2019]], "Michal Borsky": [0, ["F0 Variability Measures Based on Glottal Closure Instants", ["Yu-Ren Chien", "Michal Borsky", "Jon Gudnason"], "https://doi.org/10.21437/Interspeech.2019-1326", 4, "interspeech", 2019], ["The Althingi ASR System", ["Inga Run Helgadottir", "Anna Bjork Nikulasdottir", "Michal Borsky", "Judy Y. Fong", "Robert Kjaran", "Jon Gudnason"], "https://doi.org/10.21437/Interspeech.2019-1248", 5, "interspeech", 2019]], "Khoi-Nguyen C. Mac": [0, ["Large-Scale Mixed-Bandwidth Deep Neural Network Acoustic Modeling for Automatic Speech Recognition", ["Khoi-Nguyen C. Mac", "Xiaodong Cui", "Wei Zhang", "Michael Picheny"], "https://doi.org/10.21437/Interspeech.2019-2641", 5, "interspeech", 2019]], "Louise Ratko": [0, ["Articulation of Vowel Length Contrasts in Australian English", ["Louise Ratko", "Michael I. Proctor", "Felicity Cox"], "https://doi.org/10.21437/Interspeech.2019-2995", 5, "interspeech", 2019]], "Hussnain Ali": [0, ["A Machine Learning Based Clustering Protocol for Determining Hearing Aid Initial Configurations from Pure-Tone Audiograms", ["Chelzy Belitz", "Hussnain Ali", "John H. L. Hansen"], "https://doi.org/10.21437/Interspeech.2019-3091", 5, "interspeech", 2019]], "Farah Adeeba": [0, ["Improving Large Vocabulary Urdu Speech Recognition System Using Deep Neural Networks", ["Muhammad Umar Farooq", "Farah Adeeba", "Sahar Rauf", "Sarmad Hussain"], "https://doi.org/10.21437/Interspeech.2019-2629", 5, "interspeech", 2019]], "Kyle Williams": [0, ["Zero Shot Intent Classification Using Long-Short Term Memory Networks", ["Kyle Williams"], "https://doi.org/10.21437/Interspeech.2019-1274", 5, "interspeech", 2019]], "Jaime Hernandez-Cordero": [0, ["The 2018 NIST Speaker Recognition Evaluation", ["Seyed Omid Sadjadi", "Craig S. Greenberg", "Elliot Singer", "Douglas A. Reynolds", "Lisa P. Mason", "Jaime Hernandez-Cordero"], "https://doi.org/10.21437/Interspeech.2019-1351", 5, "interspeech", 2019]], "Sashi Novitasari": [0, ["Sequence-to-Sequence Learning via Attention Transfer for Incremental Speech Recognition", ["Sashi Novitasari", "Andros Tjandra", "Sakriani Sakti", "Satoshi Nakamura"], "https://doi.org/10.21437/Interspeech.2019-2985", 5, "interspeech", 2019]], "Alina Rakhi": [0, ["Elpis, an Accessible Speech-to-Text Tool", ["Ben Foley", "Alina Rakhi", "Nicholas Lambourne", "Nicholas Buckeridge", "Janet Wiles"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8006.html", 2, "interspeech", 2019]], "Melissa Milanovic": [0, ["Objective Assessment of Social Skills Using Automated Language Analysis for Identification of Schizophrenia and Bipolar Disorder", ["Rohit Voleti", "Stephanie Woolridge", "Julie M. Liss", "Melissa Milanovic", "Christopher R. Bowie", "Visar Berisha"], "https://doi.org/10.21437/Interspeech.2019-2960", 5, "interspeech", 2019]], "Weicheng Cai": [0, ["The DKU Replay Detection System for the ASVspoof 2019 Challenge: On Data Augmentation, Feature Representation, Classification, and Fusion", ["Weicheng Cai", "Haiwei Wu", "Danwei Cai", "Ming Li"], "https://doi.org/10.21437/Interspeech.2019-1230", 5, "interspeech", 2019], ["Survey Talk: End-to-End Deep Neural Network Based Speaker and Language Recognition", ["Ming Li", "Weicheng Cai", "Danwei Cai"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/abs10.html", 0, "interspeech", 2019], ["The DKU System for the Speaker Recognition Task of the 2019 VOiCES from a Distance Challenge", ["Danwei Cai", "Xiaoyi Qin", "Weicheng Cai", "Ming Li"], "https://doi.org/10.21437/Interspeech.2019-1435", 5, "interspeech", 2019], ["The DKU-SMIIP System for NIST 2018 Speaker Recognition Evaluation", ["Danwei Cai", "Weicheng Cai", "Ming Li"], "https://doi.org/10.21437/Interspeech.2019-1436", 5, "interspeech", 2019]], "Prashanth Gurunath Shivakumar": [0, ["Spoken Language Intent Detection Using Confusion2Vec", ["Prashanth Gurunath Shivakumar", "Mu Yang", "Panayiotis G. Georgiou"], "https://doi.org/10.21437/Interspeech.2019-2226", 5, "interspeech", 2019]], "Fang-Yu Kuo": [0, ["Selection and Training Schemes for Improving TTS Voice Built on Found Data", ["Fang-Yu Kuo", "Iris Chuoying Ouyang", "Sandesh Aryal", "Pierre Lanchantin"], "https://doi.org/10.21437/Interspeech.2019-2816", 5, "interspeech", 2019]], "Yu-Yin Hsu": [0, ["Sentence Prosody and Wh-Indeterminates in Taiwan Mandarin", ["Yu-Yin Hsu", "Anqi Xu"], "https://doi.org/10.21437/Interspeech.2019-2545", 5, "interspeech", 2019]], "Yonatan Belinkov": [0, ["Analyzing Phonetic and Graphemic Representations in End-to-End Automatic Speech Recognition", ["Yonatan Belinkov", "Ahmed Ali", "James R. Glass"], "https://doi.org/10.21437/Interspeech.2019-2599", 5, "interspeech", 2019]], "Shizhe Chen": [0, ["Speech Emotion Recognition in Dyadic Dialogues with Attentive Interaction Modeling", ["Jinming Zhao", "Shizhe Chen", "Jingjun Liang", "Qin Jin"], "https://doi.org/10.21437/Interspeech.2019-2103", 5, "interspeech", 2019]], "Haoqi Li": [0, ["Predicting Behavior in Cancer-Afflicted Patient and Spouse Interactions Using Speech and Language", ["Sandeep Nallan Chakravarthula", "Haoqi Li", "Shao-Yen Tseng", "Maija Reblin", "Panayiotis G. Georgiou"], "https://doi.org/10.21437/Interspeech.2019-1888", 5, "interspeech", 2019]], "Sari Ylinen": [0, ["Transparent Pronunciation Scoring Using Articulatorily Weighted Phoneme Edit Distance", ["Reima Karhila", "Anna-Riikka Smolander", "Sari Ylinen", "Mikko Kurimo"], "https://doi.org/10.21437/Interspeech.2019-1785", 5, "interspeech", 2019]], "Taesu Kim": [0.9277801364660263, ["Large-Scale Speaker Retrieval on Random Speaker Variability Subspace", ["Suwon Shon", "Younggun Lee", "Taesu Kim"], "https://doi.org/10.21437/Interspeech.2019-1498", 5, "interspeech", 2019]], "Qingyang Hong": [0.0002346530818613246, ["Anti-Spoofing Speaker Verification System with Multi-Feature Integration and Multi-Task Learning", ["Rongjin Li", "Miao Zhao", "Zheng Li", "Lin Li", "Qingyang Hong"], "https://doi.org/10.21437/Interspeech.2019-1698", 5, "interspeech", 2019], ["Deep Speaker Embedding Extraction with Channel-Wise Feature Responses and Additive Supervision Softmax Loss Function", ["Jianfeng Zhou", "Tao Jiang", "Zheng Li", "Lin Li", "Qingyang Hong"], "https://doi.org/10.21437/Interspeech.2019-1704", 5, "interspeech", 2019]], "Hainan Xu": [0, ["The JHU ASR System for VOiCES from a Distance Challenge 2019", ["Yiming Wang", "David Snyder", "Hainan Xu", "Vimal Manohar", "Phani Sankar Nidadavolu", "Daniel Povey", "Sanjeev Khudanpur"], "https://doi.org/10.21437/Interspeech.2019-1948", 5, "interspeech", 2019]], "Jing Chen": [0, ["Effects of Spectral and Temporal Cues to Mandarin Concurrent-Vowels Identification for Normal-Hearing and Hearing-Impaired Listeners", ["Zhen Fu", "Xihong Wu", "Jing Chen"], "https://doi.org/10.21437/Interspeech.2019-3209", 5, "interspeech", 2019]], "Pierre Andre Menard": [0, ["CRIM's Speech Transcription and Call Sign Detection System for the ATC Airbus Challenge Task", ["Vishwa Gupta", "Lise Rebout", "Gilles Boulianne", "Pierre Andre Menard", "Jahangir Alam"], "https://doi.org/10.21437/Interspeech.2019-1131", 5, "interspeech", 2019]], "Xi Wang": [3.964134066336555e-06, ["Forward-Backward Decoding for Regularizing End-to-End TTS", ["Yibin Zheng", "Xi Wang", "Lei He", "Shifeng Pan", "Frank K. Soong", "Zhengqi Wen", "Jianhua Tao"], "https://doi.org/10.21437/Interspeech.2019-2325", 5, "interspeech", 2019]], "Niccolo Sacchi": [0, ["Open-Vocabulary Keyword Spotting with Audio and Text Embeddings", ["Niccolo Sacchi", "Alexandre Nanchen", "Martin Jaggi", "Milos Cernak"], "https://doi.org/10.21437/Interspeech.2019-1846", 5, "interspeech", 2019]], "Zhong Zhou": [0, ["SANTLR: Speech Annotation Toolkit for Low Resource Languages", ["Xinjian Li", "Zhong Zhou", "Siddharth Dalmia", "Alan W. Black", "Florian Metze"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8040.html", 2, "interspeech", 2019]], "Kyubyong Park": [0.9501790404319763, ["CSS10: A Collection of Single Speaker Speech Datasets for 10 Languages", ["Kyubyong Park", "Thomas Mulc"], "https://doi.org/10.21437/Interspeech.2019-1500", 5, "interspeech", 2019]], "Peter Wu": [3.579678886644899e-09, ["Ordinal Triplet Loss: Investigating Sleepiness Detection from Speech", ["Peter Wu", "Sai Krishna Rallabandi", "Alan W. Black", "Eric Nyberg"], "https://doi.org/10.21437/Interspeech.2019-2278", 5, "interspeech", 2019]], "K. Sreenivasa Rao": [0, ["Glottal Closure Instants Detection from Speech Signal by Deep Features Extracted from Raw Speech and Linear Prediction Residual", ["Gurunath Reddy M.", "K. Sreenivasa Rao", "Partha Pratim Das"], "https://doi.org/10.21437/Interspeech.2019-1981", 5, "interspeech", 2019]], "Kwangyoun Kim": [0.999999463558197, ["Multi-Task Multi-Resolution Char-to-BPE Cross-Attention Decoder for End-to-End Speech Recognition", ["Dhananjaya Gowda", "Abhinav Garg", "Kwangyoun Kim", "Mehul Kumar", "Chanwoo Kim"], "https://doi.org/10.21437/Interspeech.2019-3216", 5, "interspeech", 2019]], "Shouji Harada": [0, ["End-to-End Monaural Speech Separation with Multi-Scale Dynamic Weighted Gated Dilated Convolutional Pyramid Network", ["Ziqiang Shi", "Huibin Lin", "Liu Liu", "Rujie Liu", "Shoji Hayakawa", "Shouji Harada", "Jiqing Han"], "https://doi.org/10.21437/Interspeech.2019-1292", 5, "interspeech", 2019]], "Eoin Mahon": [0, ["Unified Verbalization for Speech Recognition & Synthesis Across Languages", ["Sandy Ritchie", "Richard Sproat", "Kyle Gorman", "Daan van Esch", "Christian Schallhart", "Nikos Bampounis", "Benoit Brard", "Jonas Fromseier Mortensen", "Millie Holt", "Eoin Mahon"], "https://doi.org/10.21437/Interspeech.2019-2807", 5, "interspeech", 2019]], "Melissa Nollstadt": [0, ["Personalizing ASR for Dysarthric and Accented Speech with Limited Data", ["Joel Shor", "Dotan Emanuel", "Oran Lang", "Omry Tuval", "Michael Brenner", "Julie Cattiau", "Fernando Vieira", "Maeve McNally", "Taylor Charbonneau", "Melissa Nollstadt", "Avinatan Hassidim", "Yossi Matias"], "https://doi.org/10.21437/Interspeech.2019-1427", 5, "interspeech", 2019]], "Elliot Singer": [0, ["The 2018 NIST Speaker Recognition Evaluation", ["Seyed Omid Sadjadi", "Craig S. Greenberg", "Elliot Singer", "Douglas A. Reynolds", "Lisa P. Mason", "Jaime Hernandez-Cordero"], "https://doi.org/10.21437/Interspeech.2019-1351", 5, "interspeech", 2019]], "Galina Lavrentyeva": [0, ["STC Antispoofing Systems for the ASVspoof2019 Challenge", ["Galina Lavrentyeva", "Sergey Novoselov", "Andzhukaev Tseren", "Marina Volkova", "Artem Gorlanov", "Alexandr Kozlov"], "https://doi.org/10.21437/Interspeech.2019-1768", 5, "interspeech", 2019], ["STC Speaker Recognition Systems for the VOiCES from a Distance Challenge", ["Sergey Novoselov", "Aleksei Gusev", "Artem Ivanov", "Timur Pekhovsky", "Andrey Shulipa", "Galina Lavrentyeva", "Vladimir Volokhov", "Alexandr Kozlov"], "https://doi.org/10.21437/Interspeech.2019-2783", 5, "interspeech", 2019], ["STC Speaker Recognition Systems for the VOiCES from a Distance Challenge", ["Sergey Novoselov", "Aleksei Gusev", "Artem Ivanov", "Timur Pekhovsky", "Andrey Shulipa", "Galina Lavrentyeva", "Vladimir Volokhov", "Alexandr Kozlov"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/abs15.html", 0, "interspeech", 2019]], "Nando de Freitas": [0, ["Large-Scale Visual Speech Recognition", ["Brendan Shillingford", "Yannis M. Assael", "Matthew W. Hoffman", "Thomas Paine", "Cian Hughes", "Utsav Prabhu", "Hank Liao", "Hasim Sak", "Kanishka Rao", "Lorrayne Bennett", "Marie Mulville", "Misha Denil", "Ben Coppin", "Ben Laurie", "Andrew W. Senior", "Nando de Freitas"], "https://doi.org/10.21437/Interspeech.2019-1669", 5, "interspeech", 2019]], "Tomoki Hayashi": [0, ["Quasi-Periodic WaveNet Vocoder: A Pitch Dependent Dilated Convolution Model for Parametric Speech Generation", ["Yi-Chiao Wu", "Tomoki Hayashi", "Patrick Lumban Tobing", "Kazuhiro Kobayashi", "Tomoki Toda"], "https://doi.org/10.21437/Interspeech.2019-1232", 5, "interspeech", 2019], ["Non-Parallel Voice Conversion with Cyclic Variational Autoencoder", ["Patrick Lumban Tobing", "Yi-Chiao Wu", "Tomoki Hayashi", "Kazuhiro Kobayashi", "Tomoki Toda"], "https://doi.org/10.21437/Interspeech.2019-2307", 5, "interspeech", 2019], ["Investigation of F0 Conditioning and Fully Convolutional Networks in Variational Autoencoder Based Voice Conversion", ["Wen-Chin Huang", "Yi-Chiao Wu", "Chen-Chou Lo", "Patrick Lumban Tobing", "Tomoki Hayashi", "Kazuhiro Kobayashi", "Tomoki Toda", "Yu Tsao", "Hsin-Min Wang"], "https://doi.org/10.21437/Interspeech.2019-1774", 5, "interspeech", 2019], ["Pre-Trained Text Embeddings for Enhanced Text-to-Speech Synthesis", ["Tomoki Hayashi", "Shinji Watanabe", "Tomoki Toda", "Kazuya Takeda", "Shubham Toshniwal", "Karen Livescu"], "https://doi.org/10.21437/Interspeech.2019-3177", 5, "interspeech", 2019]], "Weicong Zhou": [0, ["Framewise Supervised Training Towards End-to-End Speech Recognition Models: First Results", ["Mohan Li", "Yuanjiang Cao", "Weicong Zhou", "Min Liu"], "https://doi.org/10.21437/Interspeech.2019-1117", 5, "interspeech", 2019]], "Marc Tommasi": [0, ["Privacy-Preserving Adversarial Representation Learning in ASR: Reality or Illusion?", ["Brij Mohan Lal Srivastava", "Aurelien Bellet", "Marc Tommasi", "Emmanuel Vincent"], "https://doi.org/10.21437/Interspeech.2019-2415", 5, "interspeech", 2019]], "Andrei C. Coman": [0, ["An Incremental Turn-Taking Model for Task-Oriented Dialog Systems", ["Andrei C. Coman", "Koichiro Yoshino", "Yukitoshi Murase", "Satoshi Nakamura", "Giuseppe Riccardi"], "https://doi.org/10.21437/Interspeech.2019-1826", 5, "interspeech", 2019]], "Astik Biswas": [0, ["Improved Low-Resource Somali Speech Recognition by Semi-Supervised Acoustic and Language Model Training", ["Astik Biswas", "Raghav Menon", "Ewald van der Westhuizen", "Thomas Niesler"], "https://doi.org/10.21437/Interspeech.2019-1328", 5, "interspeech", 2019], ["Semi-Supervised Acoustic Model Training for Five-Lingual Code-Switched ASR", ["Astik Biswas", "Emre Yilmaz", "Febe de Wet", "Ewald van der Westhuizen", "Thomas Niesler"], "https://doi.org/10.21437/Interspeech.2019-1325", 5, "interspeech", 2019]], "Stefan Langer": [0, ["Deep Neural Baselines for Computational Paralinguistics", ["Daniel Elsner", "Stefan Langer", "Fabian Ritz", "Robert Muller", "Steffen Illium"], "https://doi.org/10.21437/Interspeech.2019-2478", 5, "interspeech", 2019]], "Xu Tan": [0, ["Token-Level Ensemble Distillation for Grapheme-to-Phoneme Conversion", ["Hao Sun", "Xu Tan", "Jun-Wei Gan", "Hongzhi Liu", "Sheng Zhao", "Tao Qin", "Tie-Yan Liu"], "https://doi.org/10.21437/Interspeech.2019-1208", 5, "interspeech", 2019]], "Raquel Norel": [0, ["A New Approach for Automating Analysis of Responses on Verbal Fluency Tests from Subjects At-Risk for Schizophrenia", ["Mary Pietrowicz", "Carla Agurto", "Raquel Norel", "Elif Eyigoz", "Guillermo A. Cecchi", "Zarina R. Bilgrami", "Cheryl Corcoran"], "https://doi.org/10.21437/Interspeech.2019-2987", 5, "interspeech", 2019]], "Janek Ebbers": [0, ["Privacy-Preserving Variational Information Feature Extraction for Domestic Activity Monitoring versus Speaker Identification", ["Alexandru Nelus", "Janek Ebbers", "Reinhold Haeb-Umbach", "Rainer Martin"], "https://doi.org/10.21437/Interspeech.2019-1703", 5, "interspeech", 2019]], "Aparna Srinivasan": [0, ["SPIRE-fluent: A Self-Learning App for Tutoring Oral Fluency to Second Language English Learners", ["Chiranjeevi Yarra", "Aparna Srinivasan", "Sravani Gottimukkala", "Prasanta Kumar Ghosh"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8008.html", 2, "interspeech", 2019]], "Yu-Ren Chien": [0, ["F0 Variability Measures Based on Glottal Closure Instants", ["Yu-Ren Chien", "Michal Borsky", "Jon Gudnason"], "https://doi.org/10.21437/Interspeech.2019-1326", 4, "interspeech", 2019]], "Jonas Beskow": [0, ["Off the Cuff: Exploring Extemporaneous Speech Delivery with TTS", ["Eva Szekely", "Gustav Eje Henter", "Jonas Beskow", "Joakim Gustafson"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8026.html", 2, "interspeech", 2019], ["Spontaneous Conversational Speech Synthesis from Found Data", ["Eva Szekely", "Gustav Eje Henter", "Jonas Beskow", "Joakim Gustafson"], "https://doi.org/10.21437/Interspeech.2019-2836", 5, "interspeech", 2019]], "Riyaz Ahmad Bhat": [0, ["Neural Transition Systems for Modeling Hierarchical Semantic Representations", ["Riyaz Ahmad Bhat", "John Chen", "Rashmi Prasad", "Srinivas Bangalore"], "https://doi.org/10.21437/Interspeech.2019-3075", 5, "interspeech", 2019]], "Xavier Bost": [0, ["M2H-GAN: A GAN-Based Mapping from Machine to Human Transcripts for Speech Understanding", ["Titouan Parcollet", "Mohamed Morchid", "Xavier Bost", "Georges Linares"], "https://doi.org/10.21437/Interspeech.2019-2662", 5, "interspeech", 2019]], "Murat Saraclar": [0, ["Temporally-Aware Acoustic Unit Discovery for Zerospeech 2019 Challenge", ["Bolaji Yusuf", "Alican Gok", "Batuhan Gundogdu", "Oyku Deniz Kose", "Murat Saraclar"], "https://doi.org/10.21437/Interspeech.2019-1430", 5, "interspeech", 2019], ["An Empirical Evaluation of DTW Subsampling Methods for Keyword Search", ["Bolaji Yusuf", "Murat Saraclar"], "https://doi.org/10.21437/Interspeech.2019-2413", 5, "interspeech", 2019]], "Joao Paulo Neto": [0, ["Recognition of Latin American Spanish Using Multi-Task Learning", ["Carlos Mendes", "Alberto Abad", "Joao Paulo Neto", "Isabel Trancoso"], "https://doi.org/10.21437/Interspeech.2019-2772", 5, "interspeech", 2019]], "Anderson R. Avila": [0, ["Blind Channel Response Estimation for Replay Attack Detection", ["Anderson R. Avila", "Md. Jahangir Alam", "Douglas D. OShaughnessy", "Tiago H. Falk"], "https://doi.org/10.21437/Interspeech.2019-2956", 5, "interspeech", 2019]], "Jan Svec": [0, ["Multimodal Dialog with the MALACH Audiovisual Archive", ["Adam Chylek", "Lubos Smidl", "Jan Svec"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8011.html", 2, "interspeech", 2019]], "Yuchen Liu": [0, ["End-to-End Speech Translation with Knowledge Distillation", ["Yuchen Liu", "Hao Xiong", "Jiajun Zhang", "Zhongjun He", "Hua Wu", "Haifeng Wang", "Chengqing Zong"], "https://doi.org/10.21437/Interspeech.2019-2582", 5, "interspeech", 2019]], "Yan Deng": [0, ["Robust Sequence-to-Sequence Acoustic Modeling with Stepwise Monotonic Attention for Neural TTS", ["Mutian He", "Yan Deng", "Lei He"], "https://doi.org/10.21437/Interspeech.2019-1972", 5, "interspeech", 2019]], "Zelin Wu": [3.6378605727804825e-05, ["Improving Performance of End-to-End ASR on Numeric Sequences", ["Cal Peyser", "Hao Zhang", "Tara N. Sainath", "Zelin Wu"], "https://doi.org/10.21437/Interspeech.2019-1345", 5, "interspeech", 2019], ["VoiceFilter: Targeted Voice Separation by Speaker-Conditioned Spectrogram Masking", ["Quan Wang", "Hannah Muckenhirn", "Kevin W. Wilson", "Prashant Sridhar", "Zelin Wu", "John R. Hershey", "Rif A. Saurous", "Ron J. Weiss", "Ye Jia", "Ignacio Lopez-Moreno"], "https://doi.org/10.21437/Interspeech.2019-1101", 5, "interspeech", 2019]], "Charmaine Ng": [0, ["Building the Singapore English National Speech Corpus", ["Jia Xin Koh", "Aqilah Mislan", "Kevin Khoo", "Brian Ang", "Wilson Ang", "Charmaine Ng", "Ying-Ying Tan"], "https://doi.org/10.21437/Interspeech.2019-1525", 5, "interspeech", 2019]], "Marton Bartok": [0, ["V-to-V Coarticulation Induced Acoustic and Articulatory Variability of Vowels: The Effect of Pitch-Accent", ["Andrea Deme", "Marton Bartok", "Tekla Etelka Graczi", "Tamas Gabor Csapo", "Alexandra Marko"], "https://doi.org/10.21437/Interspeech.2019-2890", 5, "interspeech", 2019], ["Articulatory Analysis of Transparent Vowel /i\u02d0/ in Harmonic and Antiharmonic Hungarian Stems: Is There a Difference?", ["Alexandra Marko", "Marton Bartok", "Tamas Gabor Csapo", "Tekla Etelka Graczi", "Andrea Deme"], "https://doi.org/10.21437/Interspeech.2019-2352", 5, "interspeech", 2019]], "Kah Kuan Teh": [0, ["The I2R's ASR System for the VOiCES from a Distance Challenge 2019", ["Tze Yuang Chong", "Kye Min Tan", "Kah Kuan Teh", "Chang Huai You", "Hanwu Sun", "Tran Huy Dat"], "https://doi.org/10.21437/Interspeech.2019-2130", 5, "interspeech", 2019], ["The I2R's ASR System for the VOiCES from a Distance Challenge 2019", ["Tze Yuang Chong", "Kye Min Tan", "Kah Kuan Teh", "Chang Huai You", "Hanwu Sun", "Tran Huy Dat"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/abs18.html", 0, "interspeech", 2019], ["The I2R's Submission to VOiCES Distance Speaker Recognition Challenge 2019", ["Hanwu Sun", "Kah Kuan Teh", "Ivan Kukanov", "Tran Huy Dat"], "https://doi.org/10.21437/Interspeech.2019-1997", 5, "interspeech", 2019], ["Semi-Supervised Audio Classification with Consistency-Based Regularization", ["Kangkang Lu", "Chuan-Sheng Foo", "Kah Kuan Teh", "Huy Dat Tran", "Vijay Ramaseshan Chandrasekhar"], "https://doi.org/10.21437/Interspeech.2019-1231", 5, "interspeech", 2019]], "Yi Liu": [0, ["Large Margin Softmax Loss for Speaker Verification", ["Yi Liu", "Liang He", "Jia Liu"], "https://doi.org/10.21437/Interspeech.2019-2357", 5, "interspeech", 2019]], "Wenhuan Lu": [0, ["Individual Difference of Relative Tongue Size and its Acoustic Effects", ["Xiaohan Zhang", "Chongke Bi", "Kiyoshi Honda", "Wenhuan Lu", "Jianguo Wei"], "https://doi.org/10.21437/Interspeech.2019-2452", 5, "interspeech", 2019], ["Acoustic and Articulatory Study of Ewe Vowels: A Comparative Study of Male and Female", ["Kowovi Comivi Alowonou", "Jianguo Wei", "Wenhuan Lu", "Zhicheng Liu", "Kiyoshi Honda", "Jianwu Dang"], "https://doi.org/10.21437/Interspeech.2019-2196", 5, "interspeech", 2019]], "Pablo Perez Zarazaga": [0, ["Sound Privacy: A Conversational Speech Corpus for Quantifying the Experience of Privacy", ["Pablo Perez Zarazaga", "Sneha Das", "Tom Backstrom", "Vishnu Vidyadhara Raju Vegesna", "Anil Kumar Vuppala"], "https://doi.org/10.21437/Interspeech.2019-1172", 5, "interspeech", 2019]], "Mengzhe Geng": [0, ["The CUHK Dysarthric Speech Recognition Systems for English and Cantonese", ["Shoukang Hu", "Shansong Liu", "Heng Fai Chang", "Mengzhe Geng", "Jiani Chen", "Lau Wing Chung", "To Ka Hei", "Jianwei Yu", "Ka Ho Wong", "Xunying Liu", "Helen Meng"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8047.html", 2, "interspeech", 2019]], "Ramon Fernandez Astudillo": [0, ["Semi-Supervised Sequence-to-Sequence ASR Using Unpaired Speech and Text", ["Murali Karthick Baskar", "Shinji Watanabe", "Ramon Fernandez Astudillo", "Takaaki Hori", "Lukas Burget", "Jan Cernocky"], "https://doi.org/10.21437/Interspeech.2019-3167", 5, "interspeech", 2019]], "McKenzie Braley": [0, ["Analyzing Verbal and Nonverbal Features for Predicting Group Performance", ["Uliyana Kubasova", "Gabriel Murray", "McKenzie Braley"], "https://doi.org/10.21437/Interspeech.2019-3062", 5, "interspeech", 2019]], "Hiyon Yoo": [0.17531684786081314, ["Phonological Awareness of French Rising Contours in Japanese Learners", ["Rachel Albar", "Hiyon Yoo"], "https://doi.org/10.21437/Interspeech.2019-2856", 5, "interspeech", 2019]], "Elisabetta Farella": [0, ["Neural Network Distillation on IoT Platforms for Sound Event Detection", ["Gianmarco Cerutti", "Rahul Prasad", "Alessio Brutti", "Elisabetta Farella"], "https://doi.org/10.21437/Interspeech.2019-2394", 5, "interspeech", 2019]], "Lucie Miskic": [0, ["The Zero Resource Speech Challenge 2019: TTS Without T", ["Ewan Dunbar", "Robin Algayres", "Julien Karadayi", "Mathieu Bernard", "Juan Benjumea", "Xuan-Nga Cao", "Lucie Miskic", "Charlotte Dugrain", "Lucas Ondel", "Alan W. Black", "Laurent Besacier", "Sakriani Sakti", "Emmanuel Dupoux"], "https://doi.org/10.21437/Interspeech.2019-2904", 5, "interspeech", 2019]], "Margaret Cychosz": [0, ["The INTERSPEECH 2019 Computational Paralinguistics Challenge: Styrian Dialects, Continuous Sleepiness, Baby Sounds & Orca Activity", ["Bjorn W. Schuller", "Anton Batliner", "Christian Bergler", "Florian B. Pokorny", "Jarek Krajewski", "Margaret Cychosz", "Ralf Vollmann", "Sonja-Dana Roelen", "Sebastian Schnieder", "Elika Bergelson", "Alejandrina Cristia", "Amanda Seidl", "Anne S. Warlaumont", "Lisa Yankowitz", "Elmar Noth", "Shahin Amiriparian", "Simone Hantke", "Maximilian Schmitt"], "https://doi.org/10.21437/Interspeech.2019-1122", 5, "interspeech", 2019]], "Mirco Ravanelli": [0, ["Learning Problem-Agnostic Speech Representations from Multiple Self-Supervised Tasks", ["Santiago Pascual", "Mirco Ravanelli", "Joan Serra", "Antonio Bonafonte", "Yoshua Bengio"], "https://doi.org/10.21437/Interspeech.2019-2605", 5, "interspeech", 2019], ["Speech Model Pre-Training for End-to-End Spoken Language Understanding", ["Loren Lugosch", "Mirco Ravanelli", "Patrick Ignoto", "Vikrant Singh Tomar", "Yoshua Bengio"], "https://doi.org/10.21437/Interspeech.2019-2396", 5, "interspeech", 2019], ["Learning Speaker Representations with Mutual Information", ["Mirco Ravanelli", "Yoshua Bengio"], "https://doi.org/10.21437/Interspeech.2019-2380", 5, "interspeech", 2019]], "Michael Pucher": [0, ["Sound Tools eXtended (STx) 5.0 - A Powerful Sound Analysis Tool Optimized for Speech", ["Anton Noll", "Jonathan Stuefer", "Nicola Klingler", "Hannah Leykum", "Carina Lozo", "Jan Luttenberger", "Michael Pucher", "Carolin Schmid"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8022.html", 2, "interspeech", 2019]], "Louis Boves": [0, ["Phase Synchronization Between EEG Signals as a Function of Differences Between Stimuli Characteristics", ["Louis ten Bosch", "Kimberley Mulder", "Louis Boves"], "https://doi.org/10.21437/Interspeech.2019-2443", 5, "interspeech", 2019]], "Barbara Hinger": [0, ["The Influence of Distraction on Speech Processing: How Selective is Selective Attention?", ["Sandra I. Parhammer", "Miriam Ebersberg", "Jenny Tippmann", "Katja Stark", "Andreas Opitz", "Barbara Hinger", "Sonja Rossi"], "https://doi.org/10.21437/Interspeech.2019-2699", 5, "interspeech", 2019]], "Mousmita Sarma": [0, ["Improving Emotion Identification Using Phone Posteriors in Raw Speech Waveform Based DNN", ["Mousmita Sarma", "Pegah Ghahremani", "Daniel Povey", "Nagendra Kumar Goel", "Kandarpa Kumar Sarma", "Najim Dehak"], "https://doi.org/10.21437/Interspeech.2019-2093", 5, "interspeech", 2019], ["CaptionAI: A Real-Time Multilingual Captioning Application", ["Nagendra Kumar Goel", "Mousmita Sarma", "Saikiran Valluri", "Dharmeshkumar Agrawal", "Steve Braich", "Tejendra Singh Kuswah", "Zikra Iqbal", "Surbhi Chauhan", "Raj Karbar"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8039.html", 2, "interspeech", 2019]], "Shizuka Nakamura": [0, ["Analysis of Effect and Timing of Fillers in Natural Turn-Taking", ["Divesh Lala", "Shizuka Nakamura", "Tatsuya Kawahara"], "https://doi.org/10.21437/Interspeech.2019-1527", 5, "interspeech", 2019]], "Katherine M. Tucker": [0, ["R2SPIN: Re-Recording the Revised Speech Perception in Noise Test", ["Lauren Ward", "Catherine Robinson", "Matthew Paradis", "Katherine M. Tucker", "Ben G. Shirley"], "https://doi.org/10.21437/Interspeech.2019-1281", 5, "interspeech", 2019]], "Pasha Kamyshev": [0, ["Speech-Based Web Navigation for Limited Mobility Users", ["Vasiliy Radostev", "Serge Berger", "Justin Tabrizi", "Pasha Kamyshev", "Hisami Suzuki"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8042.html", 2, "interspeech", 2019]], "Qinyi Wang": [1.6792620627370525e-08, ["Code-Switching Detection Using ASR-Generated Language Posteriors", ["Qinyi Wang", "Emre Yilmaz", "Adem Derinel", "Haizhou Li"], "https://doi.org/10.21437/Interspeech.2019-1161", 5, "interspeech", 2019]], "Tobias Menne": [0, ["Analysis of Deep Clustering as Preprocessing for Automatic Speech Recognition of Sparsely Overlapping Speech", ["Tobias Menne", "Ilya Sklyar", "Ralf Schluter", "Hermann Ney"], "https://doi.org/10.21437/Interspeech.2019-1728", 5, "interspeech", 2019]], "Manoj Kumar": [0, ["The Second DIHARD Challenge: System Description for USC-SAIL Team", ["Tae Jin Park", "Manoj Kumar", "Nikolaos Flemotomos", "Monisankha Pal", "Raghuveer Peri", "Rimita Lahiri", "Panayiotis G. Georgiou", "Shrikanth Narayanan"], "https://doi.org/10.21437/Interspeech.2019-1903", 5, "interspeech", 2019]], "Emre Yilmaz": [0, ["Large-Scale Speaker Diarization of Radio Broadcast Archives", ["Emre Yilmaz", "Adem Derinel", "Kun Zhou", "Henk van den Heuvel", "Niko Brummer", "Haizhou Li", "David A. van Leeuwen"], "https://doi.org/10.21437/Interspeech.2019-1399", 5, "interspeech", 2019], ["Acoustic Modeling for Automatic Lyrics-to-Audio Alignment", ["Chitralekha Gupta", "Emre Yilmaz", "Haizhou Li"], "https://doi.org/10.21437/Interspeech.2019-1520", 5, "interspeech", 2019], ["Code-Switching Detection Using ASR-Generated Language Posteriors", ["Qinyi Wang", "Emre Yilmaz", "Adem Derinel", "Haizhou Li"], "https://doi.org/10.21437/Interspeech.2019-1161", 5, "interspeech", 2019], ["Semi-Supervised Acoustic Model Training for Five-Lingual Code-Switched ASR", ["Astik Biswas", "Emre Yilmaz", "Febe de Wet", "Ewald van der Westhuizen", "Thomas Niesler"], "https://doi.org/10.21437/Interspeech.2019-1325", 5, "interspeech", 2019], ["Multi-Graph Decoding for Code-Switching ASR", ["Emre Yilmaz", "Samuel Cohen", "Xianghu Yue", "David A. van Leeuwen", "Haizhou Li"], "https://doi.org/10.21437/Interspeech.2019-1125", 5, "interspeech", 2019]], "Jia Jia": [0, ["One-Shot Voice Conversion with Global Speaker Embeddings", ["Hui Lu", "Zhiyong Wu", "Dongyang Dai", "Runnan Li", "Shiyin Kang", "Jia Jia", "Helen Meng"], "https://doi.org/10.21437/Interspeech.2019-2365", 5, "interspeech", 2019], ["Disambiguation of Chinese Polyphones in an End-to-End Framework with Semantic Features Extracted by Pre-Trained BERT", ["Dongyang Dai", "Zhiyong Wu", "Shiyin Kang", "Xixin Wu", "Jia Jia", "Dan Su", "Dong Yu", "Helen Meng"], "https://doi.org/10.21437/Interspeech.2019-2292", 5, "interspeech", 2019], ["An Online Attention-Based Model for Speech Recognition", ["Ruchao Fan", "Pan Zhou", "Wei Chen", "Jia Jia", "Gang Liu"], "https://doi.org/10.21437/Interspeech.2019-2218", 5, "interspeech", 2019]], "Habib Benali": [0, ["Comparison of Telephone Recordings and Professional Microphone Recordings for Early Detection of Parkinson's Disease, Using Mel-Frequency Cepstral Coefficients with Gaussian Mixture Models", ["Laetitia Jeancolas", "Graziella Mangone", "Jean-Christophe Corvol", "Marie Vidailhet", "Stephane Lehericy", "Badr-Eddine Benkelfat", "Habib Benali", "Dijana Petrovska-Delacretaz"], "https://doi.org/10.21437/Interspeech.2019-2825", 5, "interspeech", 2019]], "Robert Fuchs": [0, ["The Monophthongs of Formal Nigerian English: An Acoustic Analysis", ["Nisad Jamakovic", "Robert Fuchs"], "https://doi.org/10.21437/Interspeech.2019-2866", 5, "interspeech", 2019]], "Kazunori Nozaki": [0, ["Individual Differences of Airflow and Sound Generation in the Vocal Tract of Sibilant /s/", ["Tsukasa Yoshinaga", "Kazunori Nozaki", "Shigeo Wada"], "https://doi.org/10.21437/Interspeech.2019-1376", 5, "interspeech", 2019]], "Harishchandra Dubey": [0, ["Toeplitz Inverse Covariance Based Robust Speaker Clustering for Naturalistic Audio Streams", ["Harishchandra Dubey", "Abhijeet Sangwan", "John H. L. Hansen"], "https://doi.org/10.21437/Interspeech.2019-1102", 5, "interspeech", 2019]], "Lan Wang": [0.0072339854668825865, ["Fast DNN Acoustic Model Speaker Adaptation by Learning Hidden Unit Contribution Features", ["Xurong Xie", "Xunying Liu", "Tan Lee", "Lan Wang"], "https://doi.org/10.21437/Interspeech.2019-2050", 5, "interspeech", 2019], ["Towards the Speech Features of Mild Cognitive Impairment: Universal Evidence from Structured and Unstructured Connected Speech of Chinese", ["Tianqi Wang", "Chongyuan Lian", "Jingshen Pan", "Quanlei Yan", "Feiqi Zhu", "Manwa L. Ng", "Lan Wang", "Nan Yan"], "https://doi.org/10.21437/Interspeech.2019-2414", 5, "interspeech", 2019], ["Towards the Speech Features of Early-Stage Dementia: Design and Application of the Mandarin Elderly Cognitive Speech Database", ["Tianqi Wang", "Quanlei Yan", "Jingshen Pan", "Feiqi Zhu", "Rongfeng Su", "Yi Guo", "Lan Wang", "Nan Yan"], "https://doi.org/10.21437/Interspeech.2019-2453", 5, "interspeech", 2019]], "Anthony Larcher": [0, ["I4U Submission to NIST SRE 2018: Leveraging from a Decade of Shared Experiences", ["Kong Aik Lee", "Ville Hautamaki", "Tomi H. Kinnunen", "Hitoshi Yamamoto", "Koji Okabe", "Ville Vestman", "Jing Huang", "Guohong Ding", "Hanwu Sun", "Anthony Larcher", "Rohan Kumar Das", "Haizhou Li", "Mickael Rouvier", "Pierre-Michel Bousquet", "Wei Rao", "Qing Wang", "Chunlei Zhang", "Fahimeh Bahmaninezhad", "Hector Delgado", "Massimiliano Todisco"], "https://doi.org/10.21437/Interspeech.2019-1533", 5, "interspeech", 2019]], "R. J. Skerry-Ryan": [0, ["Learning to Speak Fluently in a Foreign Language: Multilingual Speech Synthesis and Cross-Language Voice Cloning", ["Yu Zhang", "Ron J. Weiss", "Heiga Zen", "Yonghui Wu", "Zhifeng Chen", "R. J. Skerry-Ryan", "Ye Jia", "Andrew Rosenberg", "Bhuvana Ramabhadran"], "https://doi.org/10.21437/Interspeech.2019-2668", 5, "interspeech", 2019]], "Christopher Klein": [0, ["Active Learning for Domain Classification in a Commercial Spoken Personal Assistant", ["Xi C. Chen", "Adithya Sagar", "Justine T. Kao", "Tony Y. Li", "Christopher Klein", "Stephen Pulman", "Ashish Garg", "Jason D. Williams"], "https://doi.org/10.21437/Interspeech.2019-1315", 5, "interspeech", 2019]], "Khe Chai Sim": [1.1623309546848759e-05, ["An Investigation into On-Device Personalization of End-to-End Automatic Speech Recognition Models", ["Khe Chai Sim", "Petr Zadrazil", "Francoise Beaufays"], "https://doi.org/10.21437/Interspeech.2019-1752", 5, "interspeech", 2019]], "Lukasz Wojciak": [0, ["Avaya Conversational Intelligence: A Real-Time System for Spoken Language Understanding in Human-Human Call Center Conversations", ["Jan Mizgajski", "Adrian Szymczak", "Robert Glowski", "Piotr Szymanski", "Piotr Zelasko", "Lukasz Augustyniak", "Mikolaj Morzy", "Yishay Carmiel", "Jeff Hodson", "Lukasz Wojciak", "Daniel Smoczyk", "Adam Wrobel", "Bartosz Borowik", "Adam Artajew", "Marcin Baran", "Cezary Kwiatkowski", "Marzena Zyla-Hoppe"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8002.html", 2, "interspeech", 2019]], "Md. Jahangir Alam": [0, ["Deep Speaker Recognition: Modular or Monolithic?", ["Gautam Bhattacharya", "Md. Jahangir Alam", "Patrick Kenny"], "https://doi.org/10.21437/Interspeech.2019-3146", 5, "interspeech", 2019], ["Blind Channel Response Estimation for Replay Attack Detection", ["Anderson R. Avila", "Md. Jahangir Alam", "Douglas D. OShaughnessy", "Tiago H. Falk"], "https://doi.org/10.21437/Interspeech.2019-2956", 5, "interspeech", 2019], ["Combining Speaker Recognition and Metric Learning for Speaker-Dependent Representation Learning", ["Joao Monteiro", "Md. Jahangir Alam", "Tiago H. Falk"], "https://doi.org/10.21437/Interspeech.2019-2974", 5, "interspeech", 2019]], "Yu Zhang": [0, ["LibriTTS: A Corpus Derived from LibriSpeech for Text-to-Speech", ["Heiga Zen", "Viet Dang", "Rob Clark", "Yu Zhang", "Ron J. Weiss", "Ye Jia", "Zhifeng Chen", "Yonghui Wu"], "https://doi.org/10.21437/Interspeech.2019-2441", 5, "interspeech", 2019], ["Learning to Speak Fluently in a Foreign Language: Multilingual Speech Synthesis and Cross-Language Voice Cloning", ["Yu Zhang", "Ron J. Weiss", "Heiga Zen", "Yonghui Wu", "Zhifeng Chen", "R. J. Skerry-Ryan", "Ye Jia", "Andrew Rosenberg", "Bhuvana Ramabhadran"], "https://doi.org/10.21437/Interspeech.2019-2668", 5, "interspeech", 2019], ["SpecAugment: A Simple Data Augmentation Method for Automatic Speech Recognition", ["Daniel S. Park", "William Chan", "Yu Zhang", "Chung-Cheng Chiu", "Barret Zoph", "Ekin D. Cubuk", "Quoc V. Le"], "https://doi.org/10.21437/Interspeech.2019-2680", 5, "interspeech", 2019]], "Michael I. Proctor": [0, ["Articulation of Vowel Length Contrasts in Australian English", ["Louise Ratko", "Michael I. Proctor", "Felicity Cox"], "https://doi.org/10.21437/Interspeech.2019-2995", 5, "interspeech", 2019]], "Gustav Eje Henter": [0, ["Off the Cuff: Exploring Extemporaneous Speech Delivery with TTS", ["Eva Szekely", "Gustav Eje Henter", "Jonas Beskow", "Joakim Gustafson"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8026.html", 2, "interspeech", 2019], ["Spontaneous Conversational Speech Synthesis from Found Data", ["Eva Szekely", "Gustav Eje Henter", "Jonas Beskow", "Joakim Gustafson"], "https://doi.org/10.21437/Interspeech.2019-2836", 5, "interspeech", 2019]], "Changliang Li": [0, ["Jointly Adversarial Enhancement Training for Robust End-to-End Speech Recognition", ["Bin Liu", "Shuai Nie", "Shan Liang", "Wenju Liu", "Meng Yu", "Lianwu Chen", "Shouye Peng", "Changliang Li"], "https://doi.org/10.21437/Interspeech.2019-1242", 5, "interspeech", 2019], ["Direction-Aware Speaker Beam for Multi-Channel Speaker Extraction", ["Guanjun Li", "Shan Liang", "Shuai Nie", "Wenju Liu", "Meng Yu", "Lianwu Chen", "Shouye Peng", "Changliang Li"], "https://doi.org/10.21437/Interspeech.2019-1474", 5, "interspeech", 2019]], "Zhongtian Bao": [0, ["Attention-Enhanced Connectionist Temporal Classification for Discrete Speech Emotion Recognition", ["Ziping Zhao", "Zhongtian Bao", "Zixing Zhang", "Nicholas Cummins", "Haishuai Wang", "Bjorn W. Schuller"], "https://doi.org/10.21437/Interspeech.2019-1649", 5, "interspeech", 2019]], "Natalia Tomashenko": [0, ["Investigating Adaptation and Transfer Learning for End-to-End Spoken Language Understanding from Speech", ["Natalia Tomashenko", "Antoine Caubriere", "Yannick Esteve"], "https://doi.org/10.21437/Interspeech.2019-2158", 5, "interspeech", 2019]], "Hiroki Mori": [0, ["Conversational and Social Laughter Synthesis with WaveNet", ["Hiroki Mori", "Tomohiro Nagata", "Yoshiko Arimoto"], "https://doi.org/10.21437/Interspeech.2019-2131", 4, "interspeech", 2019]], "Felix Putze": [0, ["Comparative Analysis of Think-Aloud Methods for Everyday Activities in the Context of Cognitive Robotics", ["Moritz Meier", "Celeste Mason", "Felix Putze", "Tanja Schultz"], "https://doi.org/10.21437/Interspeech.2019-3072", 5, "interspeech", 2019]], "Jeesun Kim": [0.9742622375488281, ["Perceiving Older Adults Producing Clear and Lombard Speech", ["Chris Davis", "Jeesun Kim"], "https://doi.org/10.21437/Interspeech.2019-2210", 5, "interspeech", 2019]], "Nikko Strom": [0, ["Two Tiered Distributed Training Algorithm for Acoustic Modeling", ["Pranav Ladkat", "Oleg Rybakov", "Radhika Arava", "Sree Hari Krishnan Parthasarathi", "I-Fan Chen", "Nikko Strom"], "https://doi.org/10.21437/Interspeech.2019-1859", 5, "interspeech", 2019]], "Harish Arsikere": [0, ["Multi-Dialect Acoustic Modeling Using Phone Mapping and Online i-Vectors", ["Harish Arsikere", "Ashtosh Sapru", "Sri Garimella"], "https://doi.org/10.21437/Interspeech.2019-2881", 5, "interspeech", 2019]], "Adam Artajew": [0, ["Avaya Conversational Intelligence: A Real-Time System for Spoken Language Understanding in Human-Human Call Center Conversations", ["Jan Mizgajski", "Adrian Szymczak", "Robert Glowski", "Piotr Szymanski", "Piotr Zelasko", "Lukasz Augustyniak", "Mikolaj Morzy", "Yishay Carmiel", "Jeff Hodson", "Lukasz Wojciak", "Daniel Smoczyk", "Adam Wrobel", "Bartosz Borowik", "Adam Artajew", "Marcin Baran", "Cezary Kwiatkowski", "Marzena Zyla-Hoppe"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8002.html", 2, "interspeech", 2019]], "Kaila L. Stipancic": [0, ["Reduced Task Adaptation in Alternating Motion Rate Tasks as an Early Marker of Bulbar Involvement in Amyotrophic Lateral Sclerosis", ["Marziye Eshghi", "Panying Rong", "Antje S. Mefferd", "Kaila L. Stipancic", "Yana Yunusova", "Jordan R. Green"], "https://doi.org/10.21437/Interspeech.2019-2546", 5, "interspeech", 2019]], "Raghav Menon": [0, ["Improved Low-Resource Somali Speech Recognition by Semi-Supervised Acoustic and Language Model Training", ["Astik Biswas", "Raghav Menon", "Ewald van der Westhuizen", "Thomas Niesler"], "https://doi.org/10.21437/Interspeech.2019-1328", 5, "interspeech", 2019], ["Feature Exploration for Almost Zero-Resource ASR-Free Keyword Spotting Using a Multilingual Bottleneck Extractor and Correspondence Autoencoders", ["Raghav Menon", "Herman Kamper", "Ewald van der Westhuizen", "John Quinn", "Thomas Niesler"], "https://doi.org/10.21437/Interspeech.2019-1665", 5, "interspeech", 2019]], "Oleksii Kuchaiev": [0, ["Jasper: An End-to-End Convolutional Neural Acoustic Model", ["Jason Li", "Vitaly Lavrukhin", "Boris Ginsburg", "Ryan Leary", "Oleksii Kuchaiev", "Jonathan M. Cohen", "Huyen Nguyen", "Ravi Teja Gadde"], "https://doi.org/10.21437/Interspeech.2019-1819", 5, "interspeech", 2019]], "Bo Xu": [0, ["Boosting Character-Based Chinese Speech Synthesis via Multi-Task Learning and Dictionary Tutoring", ["Yuxiang Zou", "Linhao Dong", "Bo Xu"], "https://doi.org/10.21437/Interspeech.2019-3233", 5, "interspeech", 2019], ["Ectc-Docd: An End-to-End Structure with CTC Encoder and OCD Decoder for Speech Recognition", ["Cheng Yi", "Feng Wang", "Bo Xu"], "https://doi.org/10.21437/Interspeech.2019-1212", 5, "interspeech", 2019], ["Which Ones Are Speaking? Speaker-Inferred Model for Multi-Talker Speech Separation", ["Jing Shi", "Jiaming Xu", "Bo Xu"], "https://doi.org/10.21437/Interspeech.2019-1591", 5, "interspeech", 2019]], "Yoshiki Tanaka": [0, ["GPU-Based WFST Decoding with Extra Large Language Model", ["Daisuke Fukunaga", "Yoshiki Tanaka", "Yuichi Kageyama"], "https://doi.org/10.21437/Interspeech.2019-2101", 5, "interspeech", 2019]], "Huang-Cheng Chou": [0, ["Acoustic Indicators of Deception in Mandarin Daily Conversations Recorded from an Interactive Game", ["Chih-Hsiang Huang", "Huang-Cheng Chou", "Yi-Tong Wu", "Chi-Chun Lee", "Yi-Wen Liu"], "https://doi.org/10.21437/Interspeech.2019-2216", 5, "interspeech", 2019]], "Vinay Kothapally": [0, ["The 2019 Inaugural Fearless Steps Challenge: A Giant Leap for Naturalistic Audio", ["John H. L. Hansen", "Aditya Joglekar", "Meena Chandra Shekhar", "Vinay Kothapally", "Chengzhu Yu", "Lakshmish Kaushik", "Abhijeet Sangwan"], "https://doi.org/10.21437/Interspeech.2019-2301", 5, "interspeech", 2019]], "Kandarpa Kumar Sarma": [0, ["Improving Emotion Identification Using Phone Posteriors in Raw Speech Waveform Based DNN", ["Mousmita Sarma", "Pegah Ghahremani", "Daniel Povey", "Nagendra Kumar Goel", "Kandarpa Kumar Sarma", "Najim Dehak"], "https://doi.org/10.21437/Interspeech.2019-2093", 5, "interspeech", 2019]], "Kerstin Fischer": [0, ["Do not Hesitate! - Unless You Do it Shortly or Nasally: How the Phonetics of Filled Pauses Determine Their Subjective Frequency and Perceived Speaker Performance", ["Oliver Niebuhr", "Kerstin Fischer"], "https://doi.org/10.21437/Interspeech.2019-1194", 5, "interspeech", 2019]], "Yun Liu": [0, ["Investigation of Cost Function for Supervised Monaural Speech Separation", ["Yun Liu", "Hui Zhang", "Xueliang Zhang", "Yuhang Cao"], "https://doi.org/10.21437/Interspeech.2019-1897", 5, "interspeech", 2019]], "Chao-I Tuan": [0, ["Improved Speech Separation with Time-and-Frequency Cross-Domain Joint Embedding and Clustering", ["Gene-Ping Yang", "Chao-I Tuan", "Hung-yi Lee", "Lin-Shan Lee"], "https://doi.org/10.21437/Interspeech.2019-2181", 5, "interspeech", 2019]], "Zixiaofan Yang": [1.3875621835380487e-18, ["Predicting Humor by Learning from Time-Aligned Comments", ["Zixiaofan Yang", "Bingyan Hu", "Julia Hirschberg"], "https://doi.org/10.21437/Interspeech.2019-3113", 5, "interspeech", 2019], ["Linguistically-Informed Training of Acoustic Word Embeddings for Low-Resource Languages", ["Zixiaofan Yang", "Julia Hirschberg"], "https://doi.org/10.21437/Interspeech.2019-3119", 5, "interspeech", 2019]], "William A. Sethares": [0, ["Multi-Modal Sentiment Analysis Using Deep Canonical Correlation Analysis", ["Zhongkai Sun", "Prathusha Kameswara Sarma", "William A. Sethares", "Erik P. Bucy"], "https://doi.org/10.21437/Interspeech.2019-2482", 5, "interspeech", 2019]], "Sebastien Marcel": [0, ["Understanding and Visualizing Raw Waveform-Based CNNs", ["Hannah Muckenhirn", "Vinayak Abrol", "Mathew Magimai-Doss", "Sebastien Marcel"], "https://doi.org/10.21437/Interspeech.2019-2341", 5, "interspeech", 2019]], "Pooyan Safari": [0, ["Self Multi-Head Attention for Speaker Recognition", ["Miquel India", "Pooyan Safari", "Javier Hernando"], "https://doi.org/10.21437/Interspeech.2019-2616", 5, "interspeech", 2019]], "Hermann Ney": [0, ["RWTH ASR Systems for LibriSpeech: Hybrid vs Attention", ["Christoph Luscher", "Eugen Beck", "Kazuki Irie", "Markus Kitza", "Wilfried Michel", "Albert Zeyer", "Ralf Schluter", "Hermann Ney"], "https://doi.org/10.21437/Interspeech.2019-1780", 5, "interspeech", 2019], ["Cumulative Adaptation for BLSTM Acoustic Models", ["Markus Kitza", "Pavel Golik", "Ralf Schluter", "Hermann Ney"], "https://doi.org/10.21437/Interspeech.2019-2162", 5, "interspeech", 2019], ["An Analysis of Local Monotonic Attention Variants", ["Andre Merboldt", "Albert Zeyer", "Ralf Schluter", "Hermann Ney"], "https://doi.org/10.21437/Interspeech.2019-2879", 5, "interspeech", 2019], ["Comparison of Lattice-Free and Lattice-Based Sequence Discriminative Training Criteria for LVCSR", ["Wilfried Michel", "Ralf Schluter", "Hermann Ney"], "https://doi.org/10.21437/Interspeech.2019-2254", 5, "interspeech", 2019], ["Analysis of Deep Clustering as Preprocessing for Automatic Speech Recognition of Sparsely Overlapping Speech", ["Tobias Menne", "Ilya Sklyar", "Ralf Schluter", "Hermann Ney"], "https://doi.org/10.21437/Interspeech.2019-1728", 5, "interspeech", 2019], ["Language Modeling with Deep Transformers", ["Kazuki Irie", "Albert Zeyer", "Ralf Schluter", "Hermann Ney"], "https://doi.org/10.21437/Interspeech.2019-2225", 5, "interspeech", 2019], ["Rescoring Keyword Search Confidence Estimates with Graph-Based Re-Ranking Using Acoustic Word Embeddings", ["Anna Piunova", "Eugen Beck", "Ralf Schluter", "Hermann Ney"], "https://doi.org/10.21437/Interspeech.2019-1817", 5, "interspeech", 2019]], "Debadatta Dash": [0, ["Towards a Speaker Independent Speech-BCI Using Speaker Adaptation", ["Debadatta Dash", "Alan Wisler", "Paul Ferrari", "Jun Wang"], "https://doi.org/10.21437/Interspeech.2019-3109", 5, "interspeech", 2019], ["Spatial and Spectral Fingerprint in the Brain: Speaker Identification from Single Trial MEG Signals", ["Debadatta Dash", "Paul Ferrari", "Jun Wang"], "https://doi.org/10.21437/Interspeech.2019-3105", 5, "interspeech", 2019]], "Nizar Habash": [0, ["Towards Variability Resistant Dialectal Speech Evaluation", ["Ahmed Ali", "Salam Khalifa", "Nizar Habash"], "https://doi.org/10.21437/Interspeech.2019-2692", 5, "interspeech", 2019]], "Daniel Blackburn": [0, ["Automatic Hierarchical Attention Neural Network for Detecting AD", ["Yilin Pan", "Bahman Mirheidari", "Markus Reuber", "Annalena Venneri", "Daniel Blackburn", "Heidi Christensen"], "https://doi.org/10.21437/Interspeech.2019-1799", 5, "interspeech", 2019]], "Marianne Pouplier": [0, ["Zooming in on Spatiotemporal V-to-C Coarticulation with Functional PCA", ["Michele Gubian", "Manfred Pastatter", "Marianne Pouplier"], "https://doi.org/10.21437/Interspeech.2019-2143", 5, "interspeech", 2019]], "Pieter Appeltans": [0, ["Practical Applicability of Deep Neural Networks for Overlapping Speaker Separation", ["Pieter Appeltans", "Jeroen Zegers", "Hugo Van hamme"], "https://doi.org/10.21437/Interspeech.2019-1807", 5, "interspeech", 2019]], "Gerardo Roa Dabike": [0, ["Automatic Lyric Transcription from Karaoke Vocal Tracks: Resources and a Baseline System", ["Gerardo Roa Dabike", "Jon Barker"], "https://doi.org/10.21437/Interspeech.2019-2378", 5, "interspeech", 2019]], "Ralf Vollmann": [0, ["The INTERSPEECH 2019 Computational Paralinguistics Challenge: Styrian Dialects, Continuous Sleepiness, Baby Sounds & Orca Activity", ["Bjorn W. Schuller", "Anton Batliner", "Christian Bergler", "Florian B. Pokorny", "Jarek Krajewski", "Margaret Cychosz", "Ralf Vollmann", "Sonja-Dana Roelen", "Sebastian Schnieder", "Elika Bergelson", "Alejandrina Cristia", "Amanda Seidl", "Anne S. Warlaumont", "Lisa Yankowitz", "Elmar Noth", "Shahin Amiriparian", "Simone Hantke", "Maximilian Schmitt"], "https://doi.org/10.21437/Interspeech.2019-1122", 5, "interspeech", 2019]], "Andreas Opitz": [0, ["The Influence of Distraction on Speech Processing: How Selective is Selective Attention?", ["Sandra I. Parhammer", "Miriam Ebersberg", "Jenny Tippmann", "Katja Stark", "Andreas Opitz", "Barbara Hinger", "Sonja Rossi"], "https://doi.org/10.21437/Interspeech.2019-2699", 5, "interspeech", 2019]], "Gerben J. Westerhof": [0, ["An Acoustic and Lexical Analysis of Emotional Valence in Spontaneous Speech: Autobiographical Memory Recall in Older Adults", ["Deniece S. Nazareth", "Ellen Tournier", "Sarah Leimkotter", "Esther Janse", "Dirk Heylen", "Gerben J. Westerhof", "Khiet P. Truong"], "https://doi.org/10.21437/Interspeech.2019-1823", 5, "interspeech", 2019]], "Cibu Johny": [0, ["Cross-Lingual Consistency of Phonological Features: An Empirical Study", ["Cibu Johny", "Alexander Gutkin", "Martin Jansche"], "https://doi.org/10.21437/Interspeech.2019-2184", 5, "interspeech", 2019]], "Nicolas Audibert": [0, ["\" Gra[f] e!\" Word-Final Devoicing of Obstruents in Standard French: An Acoustic Study Based on Large Corpora", ["Adele Jatteau", "Ioana Vasilescu", "Lori Lamel", "Martine Adda-Decker", "Nicolas Audibert"], "https://doi.org/10.21437/Interspeech.2019-2329", 5, "interspeech", 2019]], "Gregory Ciccarelli": [0, ["Vocal Biomarker Assessment Following Pediatric Traumatic Brain Injury: A Retrospective Cohort Study", ["Camille Noufi", "Adam C. Lammert", "Daryush D. Mehta", "James R. Williamson", "Gregory Ciccarelli", "Douglas E. Sturim", "Jordan R. Green", "Thomas F. Campbell", "Thomas F. Quatieri"], "https://doi.org/10.21437/Interspeech.2019-1200", 5, "interspeech", 2019]], "Tharshini Gunendradasan": [0, ["An Adaptive-Q Cochlear Model for Replay Spoofing Detection", ["Tharshini Gunendradasan", "Eliathamby Ambikairajah", "Julien Epps", "Haizhou Li"], "https://doi.org/10.21437/Interspeech.2019-2361", 5, "interspeech", 2019]], "Gil Keren": [0, ["Towards Robust Speech Emotion Recognition Using Deep Residual Networks for Speech Enhancement", ["Andreas Triantafyllopoulos", "Gil Keren", "Johannes Wagner", "Ingmar Steiner", "Bjorn W. Schuller"], "https://doi.org/10.21437/Interspeech.2019-1811", 5, "interspeech", 2019]], "Yuan Liu": [0, ["Towards Language-Universal Mandarin-English Speech Recognition", ["Shiliang Zhang", "Yuan Liu", "Ming Lei", "Bin Ma", "Lei Xie"], "https://doi.org/10.21437/Interspeech.2019-1365", 5, "interspeech", 2019]], "Shachi Paul": [0, ["Towards Universal Dialogue Act Tagging for Task-Oriented Dialogues", ["Shachi Paul", "Rahul Goel", "Dilek Hakkani-Tur"], "https://doi.org/10.21437/Interspeech.2019-1866", 5, "interspeech", 2019], ["HyST: A Hybrid Approach for Flexible and Accurate Dialogue State Tracking", ["Rahul Goel", "Shachi Paul", "Dilek Hakkani-Tur"], "https://doi.org/10.21437/Interspeech.2019-1863", 5, "interspeech", 2019]], "Nicholas Cummins": [0, ["Attention-Enhanced Connectionist Temporal Classification for Discrete Speech Emotion Recognition", ["Ziping Zhao", "Zhongtian Bao", "Zixing Zhang", "Nicholas Cummins", "Haishuai Wang", "Bjorn W. Schuller"], "https://doi.org/10.21437/Interspeech.2019-1649", 5, "interspeech", 2019], ["A Hierarchical Attention Network-Based Approach for Depression Detection from Transcribed Clinical Interviews", ["Adria Mallol-Ragolta", "Ziping Zhao", "Lukas Stappen", "Nicholas Cummins", "Bjorn W. Schuller"], "https://doi.org/10.21437/Interspeech.2019-2036", 5, "interspeech", 2019], ["Using Speech to Predict Sequentially Measured Cortisol Levels During a Trier Social Stress Test", ["Alice Baird", "Shahin Amiriparian", "Nicholas Cummins", "Sarah Sturmbauer", "Johanna Janson", "Eva-Maria Messner", "Harald Baumeister", "Nicolas Rohleder", "Bjorn W. Schuller"], "https://doi.org/10.21437/Interspeech.2019-1352", 5, "interspeech", 2019], ["Autonomous Emotion Learning in Speech: A View of Zero-Shot Speech Emotion Recognition", ["Xinzhou Xu", "Jun Deng", "Nicholas Cummins", "Zixing Zhang", "Li Zhao", "Bjorn W. Schuller"], "https://doi.org/10.21437/Interspeech.2019-2406", 5, "interspeech", 2019], ["Continuous Emotion Recognition in Speech - Do We Need Recurrence?", ["Maximilian Schmitt", "Nicholas Cummins", "Bjorn W. Schuller"], "https://doi.org/10.21437/Interspeech.2019-2710", 5, "interspeech", 2019]], "Marcin Baran": [0, ["Avaya Conversational Intelligence: A Real-Time System for Spoken Language Understanding in Human-Human Call Center Conversations", ["Jan Mizgajski", "Adrian Szymczak", "Robert Glowski", "Piotr Szymanski", "Piotr Zelasko", "Lukasz Augustyniak", "Mikolaj Morzy", "Yishay Carmiel", "Jeff Hodson", "Lukasz Wojciak", "Daniel Smoczyk", "Adam Wrobel", "Bartosz Borowik", "Adam Artajew", "Marcin Baran", "Cezary Kwiatkowski", "Marzena Zyla-Hoppe"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8002.html", 2, "interspeech", 2019]], "Janet Wiles": [0, ["Elpis, an Accessible Speech-to-Text Tool", ["Ben Foley", "Alina Rakhi", "Nicholas Lambourne", "Nicholas Buckeridge", "Janet Wiles"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8006.html", 2, "interspeech", 2019]], "Nicolas Charon": [0, ["Automated Emotion Morphing in Speech Based on Diffeomorphic Curve Registration and Highway Networks", ["Ravi Shankar", "Hsi-Wei Hsieh", "Nicolas Charon", "Archana Venkataraman"], "https://doi.org/10.21437/Interspeech.2019-2386", 5, "interspeech", 2019]], "Anton Mitrofanov": [0, ["R-Vectors: New Technique for Adaptation to Room Acoustics", ["Yuri Y. Khokhlov", "Alexander Zatvornitskiy", "Ivan Medennikov", "Ivan Sorokin", "Tatiana Prisyach", "Aleksei Romanenko", "Anton Mitrofanov", "Vladimir Bataev", "Andrei Andrusenko", "Mariya Korenevskaya", "Oleg Petrov"], "https://doi.org/10.21437/Interspeech.2019-2645", 5, "interspeech", 2019], ["The STC ASR System for the VOiCES from a Distance Challenge 2019", ["Ivan Medennikov", "Yuri Y. Khokhlov", "Aleksei Romanenko", "Ivan Sorokin", "Anton Mitrofanov", "Vladimir Bataev", "Andrei Andrusenko", "Tatiana Prisyach", "Mariya Korenevskaya", "Oleg Petrov", "Alexander Zatvornitskiy"], "https://doi.org/10.21437/Interspeech.2019-1574", 5, "interspeech", 2019], ["The STC ASR System for the VOiCES from a Distance Challenge 2019", ["Ivan Medennikov", "Yuri Y. Khokhlov", "Aleksei Romanenko", "Ivan Sorokin", "Anton Mitrofanov", "Vladimir Bataev", "Andrei Andrusenko", "Tatiana Prisyach", "Mariya Korenevskaya", "Oleg Petrov", "Alexander Zatvornitskiy"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/abs17.html", 0, "interspeech", 2019]], "Chin-Hui Lee": [0.5, ["Acoustic Model Ensembling Using Effective Data Augmentation for CHiME-5 Challenge", ["Feng Ma", "Li Chai", "Jun Du", "Diyuan Liu", "Zhongfu Ye", "Chin-Hui Lee"], "https://doi.org/10.21437/Interspeech.2019-2601", 5, "interspeech", 2019], ["KL-Divergence Regularized Deep Neural Network Adaptation for Low-Resource Speaker-Dependent Speech Enhancement", ["Li Chai", "Jun Du", "Chin-Hui Lee"], "https://doi.org/10.21437/Interspeech.2019-2426", 5, "interspeech", 2019], ["A Cross-Entropy-Guided (CEG) Measure for Speech Enhancement Front-End Assessing Performances of Back-End Automatic Speech Recognition", ["Li Chai", "Jun Du", "Chin-Hui Lee"], "https://doi.org/10.21437/Interspeech.2019-2511", 5, "interspeech", 2019], ["A Hybrid Approach to Acoustic Scene Classification Based on Universal Acoustic Models", ["Xue Bai", "Jun Du", "Zi-Rui Wang", "Chin-Hui Lee"], "https://doi.org/10.21437/Interspeech.2019-2171", 5, "interspeech", 2019]], "Juan Camilo Vasquez-Correa": [0, ["Phonet: A Tool Based on Gated Recurrent Neural Networks to Extract Phonological Posteriors from Speech", ["Juan Camilo Vasquez-Correa", "Philipp Klumpp", "Juan Rafael Orozco-Arroyave", "Elmar Noth"], "https://doi.org/10.21437/Interspeech.2019-1405", 5, "interspeech", 2019], ["Apkinson: A Mobile Solution for Multimodal Assessment of Patients with Parkinson's Disease", ["Juan Camilo Vasquez-Correa", "Tomas Arias-Vergara", "Philipp Klumpp", "M. Strauss", "Arne Kuderle", "Nils Roth", "S. Bayerl", "Nicanor Garcia-Ospina", "Paula Andrea Perez-Toro", "L. Felipe Parra-Gallego", "Cristian David Rios-Urrego", "D. Escobar-Grisales", "Juan Rafael Orozco-Arroyave", "Bjorn Eskofier", "Elmar Noth"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8003.html", 2, "interspeech", 2019], ["Feature Representation of Pathophysiology of Parkinsonian Dysarthria", ["Alice Rueda", "Juan Camilo Vasquez-Correa", "Cristian David Rios-Urrego", "Juan Rafael Orozco-Arroyave", "Sridhar Krishnan", "Elmar Noth"], "https://doi.org/10.21437/Interspeech.2019-2490", 5, "interspeech", 2019], ["Feature Space Visualization with Spatial Similarity Maps for Pathological Speech Data", ["Philipp Klumpp", "Juan Camilo Vasquez-Correa", "Tino Haderlein", "Elmar Noth"], "https://doi.org/10.21437/Interspeech.2019-2080", 5, "interspeech", 2019]], "Zexin Cai": [0, ["Polyphone Disambiguation for Mandarin Chinese Using Conditional Neural Network with Multi-Level Embedding Features", ["Zexin Cai", "Yaogen Yang", "Chuxiong Zhang", "Xiaoyi Qin", "Ming Li"], "https://doi.org/10.21437/Interspeech.2019-1235", 5, "interspeech", 2019]], "Jan P. H. van Santen": [0, ["Improving ASR Systems for Children with Autism and Language Impairment Using Domain-Focused DNN Transfer Techniques", ["Robert Gale", "Liu Chen", "Jill Dolata", "Jan P. H. van Santen", "Meysam Asgari"], "https://doi.org/10.21437/Interspeech.2019-3161", 5, "interspeech", 2019]], "Hosung Park": [0.7784550338983536, ["Shortcut Connections Based Deep Speaker Embeddings for End-to-End Speaker Verification System", ["Soonshin Seo", "Daniel Jun Rim", "Minkyu Lim", "Donghyun Lee", "Hosung Park", "Junseok Oh", "Changmin Kim", "Ji-Hwan Kim"], "https://doi.org/10.21437/Interspeech.2019-2195", 5, "interspeech", 2019]], "Herman Kamper": [0, ["Unsupervised Acoustic Unit Discovery for Speech Synthesis Using Discrete Latent-Variable Neural Networks", ["Ryan Eloff", "Andre Nortje", "Benjamin van Niekerk", "Avashna Govender", "Leanne Nortje", "Arnu Pretorius", "Elan Van Biljon", "Ewald van der Westhuizen", "Lisa van Staden", "Herman Kamper"], "https://doi.org/10.21437/Interspeech.2019-1518", 5, "interspeech", 2019], ["Feature Exploration for Almost Zero-Resource ASR-Free Keyword Spotting Using a Multilingual Bottleneck Extractor and Correspondence Autoencoders", ["Raghav Menon", "Herman Kamper", "Ewald van der Westhuizen", "John Quinn", "Thomas Niesler"], "https://doi.org/10.21437/Interspeech.2019-1665", 5, "interspeech", 2019], ["On the Contributions of Visual and Textual Supervision in Low-Resource Semantic Speech Retrieval", ["Ankita Pasad", "Bowen Shi", "Herman Kamper", "Karen Livescu"], "https://doi.org/10.21437/Interspeech.2019-3051", 5, "interspeech", 2019]], "Jianwei Yu": [1.7882772346267117e-10, ["LF-MMI Training of Bayesian and Gaussian Process Time Delay Neural Networks for Speech Recognition", ["Shoukang Hu", "Xurong Xie", "Shansong Liu", "Max W. Y. Lam", "Jianwei Yu", "Xixin Wu", "Xunying Liu", "Helen Meng"], "https://doi.org/10.21437/Interspeech.2019-2379", 5, "interspeech", 2019], ["Comparative Study of Parametric and Representation Uncertainty Modeling for Recurrent Neural Network Language Models", ["Jianwei Yu", "Max W. Y. Lam", "Shoukang Hu", "Xixin Wu", "Xu Li", "Yuewen Cao", "Xunying Liu", "Helen Meng"], "https://doi.org/10.21437/Interspeech.2019-1927", 5, "interspeech", 2019], ["The CUHK Dysarthric Speech Recognition Systems for English and Cantonese", ["Shoukang Hu", "Shansong Liu", "Heng Fai Chang", "Mengzhe Geng", "Jiani Chen", "Lau Wing Chung", "To Ka Hei", "Jianwei Yu", "Ka Ho Wong", "Xunying Liu", "Helen Meng"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8047.html", 2, "interspeech", 2019], ["Exploiting Visual Features Using Bayesian Gated Neural Networks for Disordered Speech Recognition", ["Shansong Liu", "Shoukang Hu", "Yi Wang", "Jianwei Yu", "Rongfeng Su", "Xunying Liu", "Helen Meng"], "https://doi.org/10.21437/Interspeech.2019-1536", 5, "interspeech", 2019]], "Sudarsanam Parthasaarathy": [0, ["Recursive Speech Separation for Unknown Number of Speakers", ["Naoya Takahashi", "Sudarsanam Parthasaarathy", "Nabarun Goswami", "Yuki Mitsufuji"], "https://doi.org/10.21437/Interspeech.2019-1550", 5, "interspeech", 2019]], "Daan Wissing": [0, ["Online Speech Processing and Analysis Suite", ["Wikus Pienaar", "Daan Wissing"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8007.html", 2, "interspeech", 2019]], "Stephen Pulman": [0, ["Active Learning for Domain Classification in a Commercial Spoken Personal Assistant", ["Xi C. Chen", "Adithya Sagar", "Justine T. Kao", "Tony Y. Li", "Christopher Klein", "Stephen Pulman", "Ashish Garg", "Jason D. Williams"], "https://doi.org/10.21437/Interspeech.2019-1315", 5, "interspeech", 2019]], "Anna V. Runarsdottir": [0, ["Lattice Re-Scoring During Manual Editing for Automatic Error Correction of ASR Transcripts", ["Anna V. Runarsdottir", "Inga Run Helgadottir", "Jon Gudnason"], "https://doi.org/10.21437/Interspeech.2019-1790", 5, "interspeech", 2019]], "Pedro A. Torres-Carrasquillo": [0, ["State-of-the-Art Speaker Recognition for Telephone and Video Speech: The JHU-MIT Submission for NIST SRE18", ["Jesus Villalba", "Nanxin Chen", "David Snyder", "Daniel Garcia-Romero", "Alan McCree", "Gregory Sell", "Jonas Borgstrom", "Fred Richardson", "Suwon Shon", "Francois Grondin", "Reda Dehak", "Leibny Paola Garcia-Perera", "Daniel Povey", "Pedro A. Torres-Carrasquillo", "Sanjeev Khudanpur", "Najim Dehak"], "https://doi.org/10.21437/Interspeech.2019-2713", 5, "interspeech", 2019]], "Hiroshi Shimodaira": [0, ["Direct F0 Estimation with Neural-Network-Based Regression", ["Shuzhuang Xu", "Hiroshi Shimodaira"], "https://doi.org/10.21437/Interspeech.2019-3267", 5, "interspeech", 2019]], "Christopher Cieri": [0, ["The Second DIHARD Diarization Challenge: Dataset, Task, and Baselines", ["Neville Ryant", "Kenneth Church", "Christopher Cieri", "Alejandrina Cristia", "Jun Du", "Sriram Ganapathy", "Mark Liberman"], "https://doi.org/10.21437/Interspeech.2019-1268", 5, "interspeech", 2019]], "Trung Bui": [0, ["Exploiting Semi-Supervised Training Through a Dropout Regularization in End-to-End Speech Recognition", ["Subhadeep Dey", "Petr Motlicek", "Trung Bui", "Franck Dernoncourt"], "https://doi.org/10.21437/Interspeech.2019-3246", 5, "interspeech", 2019]], "Mickael Rouvier": [0, ["I4U Submission to NIST SRE 2018: Leveraging from a Decade of Shared Experiences", ["Kong Aik Lee", "Ville Hautamaki", "Tomi H. Kinnunen", "Hitoshi Yamamoto", "Koji Okabe", "Ville Vestman", "Jing Huang", "Guohong Ding", "Hanwu Sun", "Anthony Larcher", "Rohan Kumar Das", "Haizhou Li", "Mickael Rouvier", "Pierre-Michel Bousquet", "Wei Rao", "Qing Wang", "Chunlei Zhang", "Fahimeh Bahmaninezhad", "Hector Delgado", "Massimiliano Todisco"], "https://doi.org/10.21437/Interspeech.2019-1533", 5, "interspeech", 2019], ["On Robustness of Unsupervised Domain Adaptation for Speaker Recognition", ["Pierre-Michel Bousquet", "Mickael Rouvier"], "https://doi.org/10.21437/Interspeech.2019-1524", 5, "interspeech", 2019]], "Mittul Singh": [0, ["Subword RNNLM Approximations for Out-Of-Vocabulary Keyword Search", ["Mittul Singh", "Sami Virpioja", "Peter Smit", "Mikko Kurimo"], "https://doi.org/10.21437/Interspeech.2019-1329", 5, "interspeech", 2019]], "Maeve McNally": [0, ["Personalizing ASR for Dysarthric and Accented Speech with Limited Data", ["Joel Shor", "Dotan Emanuel", "Oran Lang", "Omry Tuval", "Michael Brenner", "Julie Cattiau", "Fernando Vieira", "Maeve McNally", "Taylor Charbonneau", "Melissa Nollstadt", "Avinatan Hassidim", "Yossi Matias"], "https://doi.org/10.21437/Interspeech.2019-1427", 5, "interspeech", 2019]], "Cal Peyser": [0, ["Improving Performance of End-to-End ASR on Numeric Sequences", ["Cal Peyser", "Hao Zhang", "Tara N. Sainath", "Zelin Wu"], "https://doi.org/10.21437/Interspeech.2019-1345", 5, "interspeech", 2019]], "Yi-Lin Tuan": [0, ["Personalized Dialogue Response Generation Learned from Monologues", ["Feng-Guang Su", "Aliyah R. Hsu", "Yi-Lin Tuan", "Hung-yi Lee"], "https://doi.org/10.21437/Interspeech.2019-1696", 5, "interspeech", 2019]], "Ian Lane": [0, ["BERT-DST: Scalable End-to-End Dialogue State Tracking with Bidirectional Encoder Representations from Transformer", ["Guan-Lin Chao", "Ian Lane"], "https://doi.org/10.21437/Interspeech.2019-1355", 5, "interspeech", 2019]], "Margaret Zellers": [0, ["Prosodic Effects on Plosive Duration in German and Austrian German", ["Barbara Schuppler", "Margaret Zellers"], "https://doi.org/10.21437/Interspeech.2019-2197", 5, "interspeech", 2019], ["A Preliminary Study of Charismatic Speech on YouTube: Correlating Prosodic Variation with Counts of Subscribers, Views and Likes", ["Stephanie Berger", "Oliver Niebuhr", "Margaret Zellers"], "https://doi.org/10.21437/Interspeech.2019-1664", 5, "interspeech", 2019]], "Li-Rong Dai": [0, ["Improving Aggregation and Loss Function for Better Embedding Learning in End-to-End Speaker Verification System", ["Zhifu Gao", "Yan Song", "Ian McLoughlin", "Pengcheng Li", "Yiheng Jiang", "Li-Rong Dai"], "https://doi.org/10.21437/Interspeech.2019-1489", 5, "interspeech", 2019], ["Multi-Task Learning with High-Order Statistics for x-Vector Based Text-Independent Speaker Verification", ["Lanhua You", "Wu Guo", "Li-Rong Dai", "Jun Du"], "https://doi.org/10.21437/Interspeech.2019-2264", 5, "interspeech", 2019], ["Deep Neural Network Embeddings with Gating Mechanisms for Text-Independent Speaker Verification", ["Lanhua You", "Wu Guo", "Li-Rong Dai", "Jun Du"], "https://doi.org/10.21437/Interspeech.2019-1746", 5, "interspeech", 2019], ["A Chinese Dataset for Identifying Speakers in Novels", ["Jia-Xiang Chen", "Zhen-Hua Ling", "Li-Rong Dai"], "https://doi.org/10.21437/Interspeech.2019-1614", 5, "interspeech", 2019], ["Singing Voice Synthesis Using Deep Autoregressive Neural Networks for Acoustic Modeling", ["Yuan-Hao Yi", "Yang Ai", "Zhen-Hua Ling", "Li-Rong Dai"], "https://doi.org/10.21437/Interspeech.2019-1563", 5, "interspeech", 2019], ["An Effective Deep Embedding Learning Architecture for Speaker Verification", ["Yiheng Jiang", "Yan Song", "Ian McLoughlin", "Zhifu Gao", "Li-Rong Dai"], "https://doi.org/10.21437/Interspeech.2019-1606", 5, "interspeech", 2019], ["Neural Text Clustering with Document-Level Attention Based on Dynamic Soft Labels", ["Zhi Chen", "Wu Guo", "Li-Rong Dai", "Zhen-Hua Ling", "Jun Du"], "https://doi.org/10.21437/Interspeech.2019-1417", 5, "interspeech", 2019]], "Diane J. Litman": [0, ["Identifying Personality Traits Using Overlap Dynamics in Multiparty Dialogue", ["Mingzhi Yu", "Emer Gilmartin", "Diane J. Litman"], "https://doi.org/10.21437/Interspeech.2019-1886", 5, "interspeech", 2019]], "Ross Cutler": [0, ["A Scalable Noisy Speech Dataset and Online Subjective Test Framework", ["Chandan K. A. Reddy", "Ebrahim Beyrami", "Jamie Pool", "Ross Cutler", "Sriram Srinivasan", "Johannes Gehrke"], "https://doi.org/10.21437/Interspeech.2019-3087", 5, "interspeech", 2019], ["Supervised Classifiers for Audio Impairments with Noisy Labels", ["Chandan K. A. Reddy", "Ross Cutler", "Johannes Gehrke"], "https://doi.org/10.21437/Interspeech.2019-3074", 5, "interspeech", 2019]], "Alexander Kain": [0, ["Using a Manifold Vocoder for Spectral Voice and Style Conversion", ["Tuan Dinh", "Alexander Kain", "Kris Tjaden"], "https://doi.org/10.21437/Interspeech.2019-1176", 5, "interspeech", 2019]], "Anssi Kanervisto": [0, ["Towards Debugging Deep Neural Networks by Generating Speech Utterances", ["Bilal Soomro", "Anssi Kanervisto", "Trung Ngo Trong", "Ville Hautamaki"], "https://doi.org/10.21437/Interspeech.2019-2339", 5, "interspeech", 2019]], "Emmanuel Vincent": [0, ["A Statistically Principled and Computationally Efficient Approach to Speech Enhancement Using Variational Autoencoders", ["Manuel Pariente", "Antoine Deleforge", "Emmanuel Vincent"], "https://doi.org/10.21437/Interspeech.2019-1398", 5, "interspeech", 2019], ["Privacy-Preserving Adversarial Representation Learning in ASR: Reality or Illusion?", ["Brij Mohan Lal Srivastava", "Aurelien Bellet", "Marc Tommasi", "Emmanuel Vincent"], "https://doi.org/10.21437/Interspeech.2019-2415", 5, "interspeech", 2019]], "Rohith Chandrashekar Aralikatti": [0, ["Real Time Online Visual End Point Detection Using Unidirectional LSTM", ["Tanay Sharma", "Rohith Chandrashekar Aralikatti", "Dilip Kumar Margam", "Abhinav Thanda", "Sharad Roy", "Pujitha Appan Kandala", "Shankar M. Venkatesan"], "https://doi.org/10.21437/Interspeech.2019-3253", 5, "interspeech", 2019], ["Speaker Adaptation for Lip-Reading Using Visual Identity Vectors", ["Pujitha Appan Kandala", "Abhinav Thanda", "Dilip Kumar Margam", "Rohith Chandrashekar Aralikatti", "Tanay Sharma", "Sharad Roy", "Shankar M. Venkatesan"], "https://doi.org/10.21437/Interspeech.2019-3237", 5, "interspeech", 2019]], "Jon Barker": [0, ["Automatic Lyric Transcription from Karaoke Vocal Tracks: Resources and a Baseline System", ["Gerardo Roa Dabike", "Jon Barker"], "https://doi.org/10.21437/Interspeech.2019-2378", 5, "interspeech", 2019]], "Jintao Kang": [4.612372777046403e-07, ["Multi-Scale Time-Frequency Attention for Acoustic Event Detection", ["Jingyang Zhang", "Wenhao Ding", "Jintao Kang", "Liang He"], "https://doi.org/10.21437/Interspeech.2019-1587", 5, "interspeech", 2019]], "Ivan Halim Parmonangan": [0, ["Speech Quality Evaluation of Synthesized Japanese Speech Using EEG", ["Ivan Halim Parmonangan", "Hiroki Tanaka", "Sakriani Sakti", "Shinnosuke Takamichi", "Satoshi Nakamura"], "https://doi.org/10.21437/Interspeech.2019-2059", 5, "interspeech", 2019]], "J. Gibson": [0, ["Splash: Speech and Language Assessment in Schools and Homes", ["A. Miwardelli", "I. Gallagher", "J. Gibson", "Napoleon Katsos", "Kate M. Knill", "H. Wood"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8027.html", 2, "interspeech", 2019]], "Antonio Bonafonte": [0, ["Learning Problem-Agnostic Speech Representations from Multiple Self-Supervised Tasks", ["Santiago Pascual", "Mirco Ravanelli", "Joan Serra", "Antonio Bonafonte", "Yoshua Bengio"], "https://doi.org/10.21437/Interspeech.2019-2605", 5, "interspeech", 2019], ["Towards Generalized Speech Enhancement with Generative Adversarial Networks", ["Santiago Pascual", "Joan Serra", "Antonio Bonafonte"], "https://doi.org/10.21437/Interspeech.2019-2688", 5, "interspeech", 2019], ["Prosodic Phrase Alignment for Machine Dubbing", ["Alp Oktem", "Mireia Farrus", "Antonio Bonafonte"], "https://doi.org/10.21437/Interspeech.2019-1621", 5, "interspeech", 2019]], "Aurobinda Routray": [0, ["Automatic Detection of Breath Using Voice Activity Detection and SVM Classifier with Application on News Reports", ["Mohamed Ismail Yasar Arafath K", "Aurobinda Routray"], "https://doi.org/10.21437/Interspeech.2019-2434", 5, "interspeech", 2019]], "Julia Parish-Morris": [0, ["Automatic Detection of Autism Spectrum Disorder in Children Using Acoustic and Text Features from Brief Natural Conversations", ["Sunghye Cho", "Mark Liberman", "Neville Ryant", "Meredith Cola", "Robert T. Schultz", "Julia Parish-Morris"], "https://doi.org/10.21437/Interspeech.2019-1452", 5, "interspeech", 2019]], "Lukas Stappen": [0, ["A Hierarchical Attention Network-Based Approach for Depression Detection from Transcribed Clinical Interviews", ["Adria Mallol-Ragolta", "Ziping Zhao", "Lukas Stappen", "Nicholas Cummins", "Bjorn W. Schuller"], "https://doi.org/10.21437/Interspeech.2019-2036", 5, "interspeech", 2019]], "Wei Song": [0.00018742437532637268, ["Building a Mixed-Lingual Neural TTS System with Only Monolingual Data", ["Liumeng Xue", "Wei Song", "Guanghui Xu", "Lei Xie", "Zhizheng Wu"], "https://doi.org/10.21437/Interspeech.2019-3191", 5, "interspeech", 2019]], "Yoshiki Masuyama": [0, ["Multichannel Loss Function for Supervised Speech Source Separation by Mask-Based Beamforming", ["Yoshiki Masuyama", "Masahito Togami", "Tatsuya Komatsu"], "https://doi.org/10.21437/Interspeech.2019-1289", 5, "interspeech", 2019]], "Shiri Lev-Ari": [0, ["The Different Roles of Expectations in Phonetic and Lexical Processing", ["Shiri Lev-Ari", "Robin Dodsworth", "Jeff Mielke", "Sharon Peperkamp"], "https://doi.org/10.21437/Interspeech.2019-1795", 5, "interspeech", 2019]], "Fu-Kai Chuang": [0, ["Speaker-Aware Deep Denoising Autoencoder with Embedded Speaker Identity for Speech Enhancement", ["Fu-Kai Chuang", "Syu-Siang Wang", "Jeih-weih Hung", "Yu Tsao", "Shih-Hau Fang"], "https://doi.org/10.21437/Interspeech.2019-2108", 5, "interspeech", 2019]], "Sanjeev Khudanpur": [0, ["Advances in Automatic Speech Recognition for Child Speech Using Factored Time Delay Neural Network", ["Fei Wu", "Leibny Paola Garcia-Perera", "Daniel Povey", "Sanjeev Khudanpur"], "https://doi.org/10.21437/Interspeech.2019-2980", 5, "interspeech", 2019], ["Multi-PLDA Diarization on Children's Speech", ["Jiamin Xie", "Leibny Paola Garcia-Perera", "Daniel Povey", "Sanjeev Khudanpur"], "https://doi.org/10.21437/Interspeech.2019-2961", 5, "interspeech", 2019], ["State-of-the-Art Speaker Recognition for Telephone and Video Speech: The JHU-MIT Submission for NIST SRE18", ["Jesus Villalba", "Nanxin Chen", "David Snyder", "Daniel Garcia-Romero", "Alan McCree", "Gregory Sell", "Jonas Borgstrom", "Fred Richardson", "Suwon Shon", "Francois Grondin", "Reda Dehak", "Leibny Paola Garcia-Perera", "Daniel Povey", "Pedro A. Torres-Carrasquillo", "Sanjeev Khudanpur", "Najim Dehak"], "https://doi.org/10.21437/Interspeech.2019-2713", 5, "interspeech", 2019], ["x-Vector DNN Refinement with Full-Length Recordings for Speaker Recognition", ["Daniel Garcia-Romero", "David Snyder", "Gregory Sell", "Alan McCree", "Daniel Povey", "Sanjeev Khudanpur"], "https://doi.org/10.21437/Interspeech.2019-2205", 4, "interspeech", 2019], ["Speaker Recognition Benchmark Using the CHiME-5 Corpus", ["Daniel Garcia-Romero", "David Snyder", "Shinji Watanabe", "Gregory Sell", "Alan McCree", "Daniel Povey", "Sanjeev Khudanpur"], "https://doi.org/10.21437/Interspeech.2019-2174", 5, "interspeech", 2019], ["The JHU Speaker Recognition System for the VOiCES 2019 Challenge", ["David Snyder", "Jesus Villalba", "Nanxin Chen", "Daniel Povey", "Gregory Sell", "Najim Dehak", "Sanjeev Khudanpur"], "https://doi.org/10.21437/Interspeech.2019-2979", 5, "interspeech", 2019], ["The JHU ASR System for VOiCES from a Distance Challenge 2019", ["Yiming Wang", "David Snyder", "Hainan Xu", "Vimal Manohar", "Phani Sankar Nidadavolu", "Daniel Povey", "Sanjeev Khudanpur"], "https://doi.org/10.21437/Interspeech.2019-1948", 5, "interspeech", 2019], ["Pretraining by Backtranslation for End-to-End ASR in Low-Resource Settings", ["Matthew Wiesner", "Adithya Renduchintala", "Shinji Watanabe", "Chunxi Liu", "Najim Dehak", "Sanjeev Khudanpur"], "https://doi.org/10.21437/Interspeech.2019-3254", 5, "interspeech", 2019]], "John H. L. Hansen": [0, ["Toeplitz Inverse Covariance Based Robust Speaker Clustering for Naturalistic Audio Streams", ["Harishchandra Dubey", "Abhijeet Sangwan", "John H. L. Hansen"], "https://doi.org/10.21437/Interspeech.2019-1102", 5, "interspeech", 2019], ["The 2019 Inaugural Fearless Steps Challenge: A Giant Leap for Naturalistic Audio", ["John H. L. Hansen", "Aditya Joglekar", "Meena Chandra Shekhar", "Vinay Kothapally", "Chengzhu Yu", "Lakshmish Kaushik", "Abhijeet Sangwan"], "https://doi.org/10.21437/Interspeech.2019-2301", 5, "interspeech", 2019], ["A Machine Learning Based Clustering Protocol for Determining Hearing Aid Initial Configurations from Pure-Tone Audiograms", ["Chelzy Belitz", "Hussnain Ali", "John H. L. Hansen"], "https://doi.org/10.21437/Interspeech.2019-3091", 5, "interspeech", 2019], ["Quantifying Cochlear Implant Users' Ability for Speaker Identification Using CI Auditory Stimuli", ["Nursadul Mamun", "Ria Ghosh", "John H. L. Hansen"], "https://doi.org/10.21437/Interspeech.2019-1852", 5, "interspeech", 2019], ["Adversarial Regularization for End-to-End Robust Speaker Verification", ["Qing Wang", "Pengcheng Guo", "Sining Sun", "Lei Xie", "John H. L. Hansen"], "https://doi.org/10.21437/Interspeech.2019-2983", 5, "interspeech", 2019], ["Convolutional Neural Network-Based Speech Enhancement for Cochlear Implant Recipients", ["Nursadul Mamun", "Soheil Khorram", "John H. L. Hansen"], "https://doi.org/10.21437/Interspeech.2019-1850", 5, "interspeech", 2019], ["Probabilistic Permutation Invariant Training for Speech Separation", ["Midia Yousefi", "Soheil Khorram", "John H. L. Hansen"], "https://doi.org/10.21437/Interspeech.2019-1827", 5, "interspeech", 2019]], "Shun-Chang Zhong": [0, ["Predicting Group Performances Using a Personality Composite-Network Architecture During Collaborative Task", ["Shun-Chang Zhong", "Yun-Shao Lin", "Chun-Min Chang", "Yi-Ching Liu", "Chi-Chun Lee"], "https://doi.org/10.21437/Interspeech.2019-2087", 5, "interspeech", 2019]], "Ellen Marklund": [0, ["No Distributional Learning in Adults from Attended Listening to Non-Speech", ["Ellen Marklund", "Johan Sjons", "Lisa Gustavsson", "Elisabet Eir Cortes"], "https://doi.org/10.21437/Interspeech.2019-1674", 5, "interspeech", 2019]], "Manasa Prasad": [0, ["Building Large-Vocabulary ASR Systems for Languages Without Any Audio Training Data", ["Manasa Prasad", "Daan van Esch", "Sandy Ritchie", "Jonas Fromseier Mortensen"], "https://doi.org/10.21437/Interspeech.2019-1775", 5, "interspeech", 2019]], "Richard Brutti": [0, ["Gender De-Biasing in Speech Emotion Recognition", ["Cristina Gorrostieta", "Reza Lotfian", "Kye Taylor", "Richard Brutti", "John Kane"], "https://doi.org/10.21437/Interspeech.2019-1708", 5, "interspeech", 2019]], "Junseok Oh": [0.9901176691055298, ["Shortcut Connections Based Deep Speaker Embeddings for End-to-End Speaker Verification System", ["Soonshin Seo", "Daniel Jun Rim", "Minkyu Lim", "Donghyun Lee", "Hosung Park", "Junseok Oh", "Changmin Kim", "Ji-Hwan Kim"], "https://doi.org/10.21437/Interspeech.2019-2195", 5, "interspeech", 2019]], "Aqilah Mislan": [0, ["Building the Singapore English National Speech Corpus", ["Jia Xin Koh", "Aqilah Mislan", "Kevin Khoo", "Brian Ang", "Wilson Ang", "Charmaine Ng", "Ying-Ying Tan"], "https://doi.org/10.21437/Interspeech.2019-1525", 5, "interspeech", 2019]], "Douglas A. Reynolds": [0, ["MCE 2018: The 1st Multi-Target Speaker Detection and Identification Challenge Evaluation", ["Suwon Shon", "Najim Dehak", "Douglas A. Reynolds", "James R. Glass"], "https://doi.org/10.21437/Interspeech.2019-1572", 5, "interspeech", 2019], ["The 2018 NIST Speaker Recognition Evaluation", ["Seyed Omid Sadjadi", "Craig S. Greenberg", "Elliot Singer", "Douglas A. Reynolds", "Lisa P. Mason", "Jaime Hernandez-Cordero"], "https://doi.org/10.21437/Interspeech.2019-1351", 5, "interspeech", 2019]], "Licheng Richard Zhu": [0, ["WHAM!: Extending Speech Separation to Noisy Environments", ["Gordon Wichern", "Joe Antognini", "Michael Flynn", "Licheng Richard Zhu", "Emmett McQuinn", "Dwight Crow", "Ethan Manilow", "Jonathan Le Roux"], "https://doi.org/10.21437/Interspeech.2019-2821", 5, "interspeech", 2019]], "Haizhou Li": [0, ["A Speaker-Dependent WaveNet for Voice Conversion with Non-Parallel Data", ["Xiaohai Tian", "Eng Siong Chng", "Haizhou Li"], "https://doi.org/10.21437/Interspeech.2019-1514", 5, "interspeech", 2019], ["Large-Scale Speaker Diarization of Radio Broadcast Archives", ["Emre Yilmaz", "Adem Derinel", "Kun Zhou", "Henk van den Heuvel", "Niko Brummer", "Haizhou Li", "David A. van Leeuwen"], "https://doi.org/10.21437/Interspeech.2019-1399", 5, "interspeech", 2019], ["A Combination of Model-Based and Feature-Based Strategy for Speech-to-Singing Alignment", ["Bidisha Sharma", "Haizhou Li"], "https://doi.org/10.21437/Interspeech.2019-1942", 5, "interspeech", 2019], ["Long Range Acoustic Features for Spoofed Speech Detection", ["Rohan Kumar Das", "Jichen Yang", "Haizhou Li"], "https://doi.org/10.21437/Interspeech.2019-1887", 5, "interspeech", 2019], ["VQVAE Unsupervised Unit Discovery and Multi-Scale Code2Spec Inverter for Zerospeech Challenge 2019", ["Andros Tjandra", "Berrak Sisman", "Mingyang Zhang", "Sakriani Sakti", "Haizhou Li", "Satoshi Nakamura"], "https://doi.org/10.21437/Interspeech.2019-3232", 5, "interspeech", 2019], ["Target Speaker Extraction for Multi-Talker Speaker Verification", ["Wei Rao", "Chenglin Xu", "Eng Siong Chng", "Haizhou Li"], "https://doi.org/10.21437/Interspeech.2019-1410", 5, "interspeech", 2019], ["Joint Training Framework for Text-to-Speech and Voice Conversion Using Multi-Source Tacotron and WaveNet", ["Mingyang Zhang", "Xin Wang", "Fuming Fang", "Haizhou Li", "Junichi Yamagishi"], "https://doi.org/10.21437/Interspeech.2019-1357", 5, "interspeech", 2019], ["I4U Submission to NIST SRE 2018: Leveraging from a Decade of Shared Experiences", ["Kong Aik Lee", "Ville Hautamaki", "Tomi H. Kinnunen", "Hitoshi Yamamoto", "Koji Okabe", "Ville Vestman", "Jing Huang", "Guohong Ding", "Hanwu Sun", "Anthony Larcher", "Rohan Kumar Das", "Haizhou Li", "Mickael Rouvier", "Pierre-Michel Bousquet", "Wei Rao", "Qing Wang", "Chunlei Zhang", "Fahimeh Bahmaninezhad", "Hector Delgado", "Massimiliano Todisco"], "https://doi.org/10.21437/Interspeech.2019-1533", 5, "interspeech", 2019], ["Multi-Level Adaptive Speech Activity Detector for Speech in Naturalistic Environments", ["Bidisha Sharma", "Rohan Kumar Das", "Haizhou Li"], "https://doi.org/10.21437/Interspeech.2019-1928", 5, "interspeech", 2019], ["On the Importance of Audio-Source Separation for Singer Identification in Polyphonic Music", ["Bidisha Sharma", "Rohan Kumar Das", "Haizhou Li"], "https://doi.org/10.21437/Interspeech.2019-1925", 5, "interspeech", 2019], ["Acoustic Modeling for Automatic Lyrics-to-Audio Alignment", ["Chitralekha Gupta", "Emre Yilmaz", "Haizhou Li"], "https://doi.org/10.21437/Interspeech.2019-1520", 5, "interspeech", 2019], ["On the End-to-End Solution to Mandarin-English Code-Switching Speech Recognition", ["Zhiping Zeng", "Yerbolat Khassanov", "Van Tung Pham", "Haihua Xu", "Eng Siong Chng", "Haizhou Li"], "https://doi.org/10.21437/Interspeech.2019-1429", 5, "interspeech", 2019], ["NUS Speak-to-Sing: A Web Platform for Personalized Speech-to-Singing Conversion", ["Chitralekha Gupta", "Karthika Vijayan", "Bidisha Sharma", "Xiaoxue Gao", "Haizhou Li"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8041.html", 2, "interspeech", 2019], ["Instantaneous Phase and Long-Term Acoustic Cues for Orca Activity Detection", ["Rohan Kumar Das", "Haizhou Li"], "https://doi.org/10.21437/Interspeech.2019-1894", 5, "interspeech", 2019], ["An Adaptive-Q Cochlear Model for Replay Spoofing Detection", ["Tharshini Gunendradasan", "Eliathamby Ambikairajah", "Julien Epps", "Haizhou Li"], "https://doi.org/10.21437/Interspeech.2019-2361", 5, "interspeech", 2019], ["Robust Sound Recognition: A Neuromorphic Approach", ["Jibin Wu", "Zihan Pan", "Malu Zhang", "Rohan Kumar Das", "Yansong Chua", "Haizhou Li"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8032.html", 2, "interspeech", 2019], ["Linguistically Motivated Parallel Data Augmentation for Code-Switch Language Modeling", ["Grandee Lee", "Xianghu Yue", "Haizhou Li"], "https://doi.org/10.21437/Interspeech.2019-1382", 5, "interspeech", 2019], ["Code-Switching Detection Using ASR-Generated Language Posteriors", ["Qinyi Wang", "Emre Yilmaz", "Adem Derinel", "Haizhou Li"], "https://doi.org/10.21437/Interspeech.2019-1161", 5, "interspeech", 2019], ["Multi-Graph Decoding for Code-Switching ASR", ["Emre Yilmaz", "Samuel Cohen", "Xianghu Yue", "David A. van Leeuwen", "Haizhou Li"], "https://doi.org/10.21437/Interspeech.2019-1125", 5, "interspeech", 2019], ["A Unified Framework for Speaker and Utterance Verification", ["Tianchi Liu", "Maulik C. Madhavi", "Rohan Kumar Das", "Haizhou Li"], "https://doi.org/10.21437/Interspeech.2019-1994", 5, "interspeech", 2019]], "Hironori Takemoto": [0, ["Speech Organ Contour Extraction Using Real-Time MRI and Machine Learning Method", ["Hironori Takemoto", "Tsubasa Goto", "Yuya Hagihara", "Sayaka Hamanaka", "Tatsuya Kitamura", "Yukiko Nota", "Kikuo Maekawa"], "https://doi.org/10.21437/Interspeech.2019-1593", 5, "interspeech", 2019]], "Jose Vicente Egas Lopez": [0, ["Assessing Parkinson's Disease from Speech Using Fisher Vectors", ["Jose Vicente Egas Lopez", "Juan Rafael Orozco-Arroyave", "Gabor Gosztolya"], "https://doi.org/10.21437/Interspeech.2019-2217", 5, "interspeech", 2019]], "Harinath Garudadri": [0, ["On Mitigating Acoustic Feedback in Hearing Aids with Frequency Warping by All-Pass Networks", ["Ching Hua Lee", "Kuan-Lin Chen", "Fredric J. Harris", "Bhaskar D. Rao", "Harinath Garudadri"], "https://doi.org/10.21437/Interspeech.2019-3195", 5, "interspeech", 2019]], "Aciel Eshky": [0, ["Ultrasound Tongue Imaging for Diarization and Alignment of Child Speech Therapy Sessions", ["Manuel Sam Ribeiro", "Aciel Eshky", "Korin Richmond", "Steve Renals"], "https://doi.org/10.21437/Interspeech.2019-2612", 5, "interspeech", 2019], ["Synchronising Audio and Ultrasound by Learning Cross-Modal Embeddings", ["Aciel Eshky", "Manuel Sam Ribeiro", "Korin Richmond", "Steve Renals"], "https://doi.org/10.21437/Interspeech.2019-1804", 5, "interspeech", 2019]], "Yukitoshi Murase": [0, ["An Incremental Turn-Taking Model for Task-Oriented Dialog Systems", ["Andrei C. Coman", "Koichiro Yoshino", "Yukitoshi Murase", "Satoshi Nakamura", "Giuseppe Riccardi"], "https://doi.org/10.21437/Interspeech.2019-1826", 5, "interspeech", 2019]], "Salima Mdhaffar": [0, ["Qualitative Evaluation of ASR Adaptation in a Lecture Context: Application to the PASTEL Corpus", ["Salima Mdhaffar", "Yannick Esteve", "Nicolas Hernandez", "Antoine Laurent", "Richard Dufour", "Solen Quiniou"], "https://doi.org/10.21437/Interspeech.2019-2661", 5, "interspeech", 2019]], "Jungwon Lee": [0.9839506894350052, ["Deep Multitask Acoustic Echo Cancellation", ["Amin Fazel", "Mostafa El-Khamy", "Jungwon Lee"], "https://doi.org/10.21437/Interspeech.2019-2908", 5, "interspeech", 2019]], "Heng Fai Chang": [3.663107252423192e-12, ["The CUHK Dysarthric Speech Recognition Systems for English and Cantonese", ["Shoukang Hu", "Shansong Liu", "Heng Fai Chang", "Mengzhe Geng", "Jiani Chen", "Lau Wing Chung", "To Ka Hei", "Jianwei Yu", "Ka Ho Wong", "Xunying Liu", "Helen Meng"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8047.html", 2, "interspeech", 2019]], "Mohamed Morchid": [0, ["M2H-GAN: A GAN-Based Mapping from Machine to Human Transcripts for Speech Understanding", ["Titouan Parcollet", "Mohamed Morchid", "Xavier Bost", "Georges Linares"], "https://doi.org/10.21437/Interspeech.2019-2662", 5, "interspeech", 2019], ["Real to H-Space Encoder for Speech Recognition", ["Titouan Parcollet", "Mohamed Morchid", "Georges Linares", "Renato De Mori"], "https://doi.org/10.21437/Interspeech.2019-1539", 5, "interspeech", 2019]], "Sonja Rossi": [0, ["The Influence of Distraction on Speech Processing: How Selective is Selective Attention?", ["Sandra I. Parhammer", "Miriam Ebersberg", "Jenny Tippmann", "Katja Stark", "Andreas Opitz", "Barbara Hinger", "Sonja Rossi"], "https://doi.org/10.21437/Interspeech.2019-2699", 5, "interspeech", 2019]], "Anjuli Kannan": [0, ["Large-Scale Multilingual Speech Recognition with a Streaming End-to-End Model", ["Anjuli Kannan", "Arindrima Datta", "Tara N. Sainath", "Eugene Weinstein", "Bhuvana Ramabhadran", "Yonghui Wu", "Ankur Bapna", "Zhifeng Chen", "Seungji Lee"], "https://doi.org/10.21437/Interspeech.2019-2858", 5, "interspeech", 2019], ["On the Choice of Modeling Unit for Sequence-to-Sequence Speech Recognition", ["Kazuki Irie", "Rohit Prabhavalkar", "Anjuli Kannan", "Antoine Bruguier", "David Rybach", "Patrick Nguyen"], "https://doi.org/10.21437/Interspeech.2019-2277", 5, "interspeech", 2019]], "Anne S. Warlaumont": [0, ["The INTERSPEECH 2019 Computational Paralinguistics Challenge: Styrian Dialects, Continuous Sleepiness, Baby Sounds & Orca Activity", ["Bjorn W. Schuller", "Anton Batliner", "Christian Bergler", "Florian B. Pokorny", "Jarek Krajewski", "Margaret Cychosz", "Ralf Vollmann", "Sonja-Dana Roelen", "Sebastian Schnieder", "Elika Bergelson", "Alejandrina Cristia", "Amanda Seidl", "Anne S. Warlaumont", "Lisa Yankowitz", "Elmar Noth", "Shahin Amiriparian", "Simone Hantke", "Maximilian Schmitt"], "https://doi.org/10.21437/Interspeech.2019-1122", 5, "interspeech", 2019], ["Towards Detection of Canonical Babbling by Citizen Scientists: Performance as a Function of Clip Length", ["Amanda Seidl", "Anne S. Warlaumont", "Alejandrina Cristia"], "https://doi.org/10.21437/Interspeech.2019-1773", 5, "interspeech", 2019]], "Changchun Bao": [0, ["Masking Estimation with Phase Restoration of Clean Speech for Monaural Speech Enhancement", ["Xianyun Wang", "Changchun Bao"], "https://doi.org/10.21437/Interspeech.2019-1141", 5, "interspeech", 2019]], "Markus Kitza": [0, ["RWTH ASR Systems for LibriSpeech: Hybrid vs Attention", ["Christoph Luscher", "Eugen Beck", "Kazuki Irie", "Markus Kitza", "Wilfried Michel", "Albert Zeyer", "Ralf Schluter", "Hermann Ney"], "https://doi.org/10.21437/Interspeech.2019-1780", 5, "interspeech", 2019], ["Cumulative Adaptation for BLSTM Acoustic Models", ["Markus Kitza", "Pavel Golik", "Ralf Schluter", "Hermann Ney"], "https://doi.org/10.21437/Interspeech.2019-2162", 5, "interspeech", 2019]], "Deyi Tuo": [0, ["Multimedia Simultaneous Translation System for Minority Language Communication with Mandarin", ["Shen Huang", "Bojie Hu", "Shan Huang", "Pengfei Hu", "Jian Kang", "Zhiqiang Lv", "Jinghao Yan", "Qi Ju", "Shiyin Kang", "Deyi Tuo", "Guangzhi Li", "Nurmemet Yolwas"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8020.html", 2, "interspeech", 2019]], "Garrett Weinberg": [0, ["Mirroring to Build Trust in Digital Assistants", ["Katherine Metcalf", "Barry-John Theobald", "Garrett Weinberg", "Robert Lee", "Ing-Marie Jonsson", "Russ Webb", "Nicholas Apostoloff"], "https://doi.org/10.21437/Interspeech.2019-1829", 5, "interspeech", 2019]], "Craig S. Greenberg": [0, ["The 2018 NIST Speaker Recognition Evaluation", ["Seyed Omid Sadjadi", "Craig S. Greenberg", "Elliot Singer", "Douglas A. Reynolds", "Lisa P. Mason", "Jaime Hernandez-Cordero"], "https://doi.org/10.21437/Interspeech.2019-1351", 5, "interspeech", 2019]], "Viyazonuo Terhiija": [0, ["Vowel-Tone Interaction in Two Tibeto-Burman Languages", ["Wendy Lalhminghlui", "Viyazonuo Terhiija", "Priyankoo Sarmah"], "https://doi.org/10.21437/Interspeech.2019-2808", 5, "interspeech", 2019]], "Xiangdong Su": [0, ["UNetGAN: A Robust Speech Enhancement Approach in Time Domain for Extremely Low Signal-to-Noise Ratio Condition", ["Xiang Hao", "Xiangdong Su", "Zhiyu Wang", "Hui Zhang", "Batushiren"], "https://doi.org/10.21437/Interspeech.2019-1567", 5, "interspeech", 2019]], "Wenju Liu": [0, ["Jointly Adversarial Enhancement Training for Robust End-to-End Speech Recognition", ["Bin Liu", "Shuai Nie", "Shan Liang", "Wenju Liu", "Meng Yu", "Lianwu Chen", "Shouye Peng", "Changliang Li"], "https://doi.org/10.21437/Interspeech.2019-1242", 5, "interspeech", 2019], ["Direction-Aware Speaker Beam for Multi-Channel Speaker Extraction", ["Guanjun Li", "Shan Liang", "Shuai Nie", "Wenju Liu", "Meng Yu", "Lianwu Chen", "Shouye Peng", "Changliang Li"], "https://doi.org/10.21437/Interspeech.2019-1474", 5, "interspeech", 2019]], "Haiyang Xu": [0, ["Learning Alignment for Multimodal Emotion Recognition from Speech", ["Haiyang Xu", "Hui Zhang", "Kun Han", "Yun Wang", "Yiping Peng", "Xiangang Li"], "https://doi.org/10.21437/Interspeech.2019-3247", 5, "interspeech", 2019]], "Cornelius Weber": [0, ["Predictive Auxiliary Variational Autoencoder for Representation Learning of Global Speech Characteristics", ["Sebastian Springenberg", "Egor Lakomkin", "Cornelius Weber", "Stefan Wermter"], "https://doi.org/10.21437/Interspeech.2019-2845", 5, "interspeech", 2019], ["LipSound: Neural Mel-Spectrogram Reconstruction for Lip Reading", ["Leyuan Qu", "Cornelius Weber", "Stefan Wermter"], "https://doi.org/10.21437/Interspeech.2019-1393", 5, "interspeech", 2019]], "Vishwas Mruthyunjaya": [0, ["Optimizing Voice Activity Detection for Noisy Conditions", ["Ruixi Lin", "Charles Costello", "Charles Jankowski", "Vishwas Mruthyunjaya"], "https://doi.org/10.21437/Interspeech.2019-1776", 5, "interspeech", 2019]], "Johanna Janson": [0, ["Using Speech to Predict Sequentially Measured Cortisol Levels During a Trier Social Stress Test", ["Alice Baird", "Shahin Amiriparian", "Nicholas Cummins", "Sarah Sturmbauer", "Johanna Janson", "Eva-Maria Messner", "Harald Baumeister", "Nicolas Rohleder", "Bjorn W. Schuller"], "https://doi.org/10.21437/Interspeech.2019-1352", 5, "interspeech", 2019]], "Tan Lee": [0.0017472112085670233, ["Improving Unsupervised Subword Modeling via Disentangled Speech Representation Learning and Transformation", ["Siyuan Feng", "Tan Lee"], "https://doi.org/10.21437/Interspeech.2019-1338", 5, "interspeech", 2019], ["Fast DNN Acoustic Model Speaker Adaptation by Learning Hidden Unit Contribution Features", ["Xurong Xie", "Xunying Liu", "Tan Lee", "Lan Wang"], "https://doi.org/10.21437/Interspeech.2019-2050", 5, "interspeech", 2019], ["Combining Adversarial Training and Disentangled Speech Representation for Robust Zero-Resource Subword Modeling", ["Siyuan Feng", "Tan Lee", "Zhiyuan Peng"], "https://doi.org/10.21437/Interspeech.2019-1337", 5, "interspeech", 2019], ["Deep Learning of Segment-Level Feature Representation with Multiple Instance Learning for Utterance-Level Speech Emotion Recognition", ["Shuiyang Mao", "P. C. Ching", "Tan Lee"], "https://doi.org/10.21437/Interspeech.2019-1968", 5, "interspeech", 2019], ["Automatic Assessment of Language Impairment Based on Raw ASR Output", ["Ying Qin", "Tan Lee", "Anthony Pak-Hin Kong"], "https://doi.org/10.21437/Interspeech.2019-1688", 5, "interspeech", 2019], ["Child Speech Disorder Detection with Siamese Recurrent Network Using Speech Attribute Features", ["Jiarui Wang", "Ying Qin", "Zhiyuan Peng", "Tan Lee"], "https://doi.org/10.21437/Interspeech.2019-2320", 5, "interspeech", 2019]], "Hao Xiong": [0, ["End-to-End Speech Translation with Knowledge Distillation", ["Yuchen Liu", "Hao Xiong", "Jiajun Zhang", "Zhongjun He", "Hua Wu", "Haifeng Wang", "Chengqing Zong"], "https://doi.org/10.21437/Interspeech.2019-2582", 5, "interspeech", 2019]], "Hannah P. Rowe": [0, ["Profiling Speech Motor Impairments in Persons with Amyotrophic Lateral Sclerosis: An Acoustic-Based Approach", ["Hannah P. Rowe", "Jordan R. Green"], "https://doi.org/10.21437/Interspeech.2019-2911", 5, "interspeech", 2019]], "Vitaly Lavrukhin": [0, ["Jasper: An End-to-End Convolutional Neural Acoustic Model", ["Jason Li", "Vitaly Lavrukhin", "Boris Ginsburg", "Ryan Leary", "Oleksii Kuchaiev", "Jonathan M. Cohen", "Huyen Nguyen", "Ravi Teja Gadde"], "https://doi.org/10.21437/Interspeech.2019-1819", 5, "interspeech", 2019]], "Lei Fan": [0, ["Deep Hashing for Speaker Identification and Retrieval", ["Lei Fan", "Qing-Yuan Jiang", "Ya-Qi Yu", "Wu-Jun Li"], "https://doi.org/10.21437/Interspeech.2019-2457", 5, "interspeech", 2019]], "Oliver Y. Chen": [0, ["Spatio-Temporal Attention Pooling for Audio Scene Classification", ["Huy Phan", "Oliver Y. Chen", "Lam Pham", "Philipp Koch", "Maarten De Vos", "Ian Vince McLoughlin", "Alfred Mertins"], "https://doi.org/10.21437/Interspeech.2019-3040", 5, "interspeech", 2019]], "Tatsuya Kawahara": [0, ["End-to-End Articulatory Attribute Modeling for Low-Resource Multilingual Speech Recognition", ["Sheng Li", "Chenchen Ding", "Xugang Lu", "Peng Shen", "Tatsuya Kawahara", "Hisashi Kawai"], "https://doi.org/10.21437/Interspeech.2019-2092", 5, "interspeech", 2019], ["Investigating Radical-Based End-to-End Speech Recognition Systems for Chinese Dialects and Japanese", ["Sheng Li", "Xugang Lu", "Chenchen Ding", "Peng Shen", "Tatsuya Kawahara", "Hisashi Kawai"], "https://doi.org/10.21437/Interspeech.2019-2104", 5, "interspeech", 2019], ["Improved End-to-End Speech Emotion Recognition Using Self Attention Mechanism and Multitask Learning", ["Yuanchao Li", "Tianyu Zhao", "Tatsuya Kawahara"], "https://doi.org/10.21437/Interspeech.2019-2594", 5, "interspeech", 2019], ["Turn-Taking Prediction Based on Detection of Transition Relevance Place", ["Kohei Hara", "Koji Inoue", "Katsuya Takanashi", "Tatsuya Kawahara"], "https://doi.org/10.21437/Interspeech.2019-1537", 5, "interspeech", 2019], ["Analysis of Effect and Timing of Fillers in Natural Turn-Taking", ["Divesh Lala", "Shizuka Nakamura", "Tatsuya Kawahara"], "https://doi.org/10.21437/Interspeech.2019-1527", 5, "interspeech", 2019], ["Improving Transformer-Based Speech Recognition Systems with Compressed Structure and Speech Attributes Augmentation", ["Sheng Li", "Dabre Raj", "Xugang Lu", "Peng Shen", "Tatsuya Kawahara", "Hisashi Kawai"], "https://doi.org/10.21437/Interspeech.2019-2112", 5, "interspeech", 2019]], "Mark J. F. Gales": [0, ["A Deep Learning Approach to Automatic Characterisation of Rhythm in Non-Native English Speech", ["Konstantinos Kyriakopoulos", "Kate M. Knill", "Mark J. F. Gales"], "https://doi.org/10.21437/Interspeech.2019-3186", 5, "interspeech", 2019], ["Impact of ASR Performance on Spoken Grammatical Error Detection", ["Yiting Lu", "Mark J. F. Gales", "Kate M. Knill", "P. P. Manakul", "Linlin Wang", "Y. Wang"], "https://doi.org/10.21437/Interspeech.2019-1706", 5, "interspeech", 2019]], "Dominik Schiller": [0, ["Relevance-Based Feature Masking: Improving Neural Network Based Whale Classification Through Explainable Artificial Intelligence", ["Dominik Schiller", "Tobias Huber", "Florian Lingenfelser", "Michael Dietz", "Andreas Seiderer", "Elisabeth Andre"], "https://doi.org/10.21437/Interspeech.2019-2707", 5, "interspeech", 2019]], "Kartik Audhkhasi": [0, ["Challenging the Boundaries of Speech Recognition: The MALACH Corpus", ["Michael Picheny", "Zoltan Tuske", "Brian Kingsbury", "Kartik Audhkhasi", "Xiaodong Cui", "George Saon"], "https://doi.org/10.21437/Interspeech.2019-1907", 5, "interspeech", 2019], ["Guiding CTC Posterior Spike Timings for Improved Posterior Fusion and Knowledge Distillation", ["Gakuto Kurata", "Kartik Audhkhasi"], "https://doi.org/10.21437/Interspeech.2019-1952", 5, "interspeech", 2019], ["Multi-Task CTC Training with Auxiliary Feature Reconstruction for End-to-End Speech Recognition", ["Gakuto Kurata", "Kartik Audhkhasi"], "https://doi.org/10.21437/Interspeech.2019-1710", 5, "interspeech", 2019], ["Forget a Bit to Learn Better: Soft Forgetting for CTC-Based Automatic Speech Recognition", ["Kartik Audhkhasi", "George Saon", "Zoltan Tuske", "Brian Kingsbury", "Michael Picheny"], "https://doi.org/10.21437/Interspeech.2019-2841", 5, "interspeech", 2019], ["Detection and Recovery of OOVs for Improved English Broadcast News Captioning", ["Samuel Thomas", "Kartik Audhkhasi", "Zoltan Tuske", "Yinghui Huang", "Michael Picheny"], "https://doi.org/10.21437/Interspeech.2019-2793", 5, "interspeech", 2019], ["Advancing Sequence-to-Sequence Based Speech Recognition", ["Zoltan Tuske", "Kartik Audhkhasi", "George Saon"], "https://doi.org/10.21437/Interspeech.2019-3018", 5, "interspeech", 2019]], "Ethan Manilow": [0, ["WHAM!: Extending Speech Separation to Noisy Environments", ["Gordon Wichern", "Joe Antognini", "Michael Flynn", "Licheng Richard Zhu", "Emmett McQuinn", "Dwight Crow", "Ethan Manilow", "Jonathan Le Roux"], "https://doi.org/10.21437/Interspeech.2019-2821", 5, "interspeech", 2019]], "Borislav Dzodzo": [0, ["Unsupervised Methods for Audio Classification from Lecture Discussion Recordings", ["Hang Su", "Borislav Dzodzo", "Xixin Wu", "Xunying Liu", "Helen Meng"], "https://doi.org/10.21437/Interspeech.2019-2384", 5, "interspeech", 2019]], "Yucel Yemez": [0, ["Speech Driven Backchannel Generation Using Deep Q-Network for Enhancing Engagement in Human-Robot Interaction", ["Nusrah Hussain", "Engin Erzin", "T. Metin Sezgin", "Yucel Yemez"], "https://doi.org/10.21437/Interspeech.2019-2521", 5, "interspeech", 2019]], "Yusuke Fujita": [0, ["Auxiliary Interference Speaker Loss for Target-Speaker Speech Recognition", ["Naoyuki Kanda", "Shota Horiguchi", "Ryoichi Takashima", "Yusuke Fujita", "Kenji Nagamatsu", "Shinji Watanabe"], "https://doi.org/10.21437/Interspeech.2019-1126", 5, "interspeech", 2019], ["Guided Source Separation Meets a Strong ASR Backend: Hitachi/Paderborn University Joint Investigation for Dinner Party ASR", ["Naoyuki Kanda", "Christoph Boddeker", "Jens Heitkaemper", "Yusuke Fujita", "Shota Horiguchi", "Kenji Nagamatsu", "Reinhold Haeb-Umbach"], "https://doi.org/10.21437/Interspeech.2019-1167", 5, "interspeech", 2019], ["End-to-End Neural Speaker Diarization with Permutation-Free Objectives", ["Yusuke Fujita", "Naoyuki Kanda", "Shota Horiguchi", "Kenji Nagamatsu", "Shinji Watanabe"], "https://doi.org/10.21437/Interspeech.2019-2899", 5, "interspeech", 2019]], "Marin Schroer": [0, ["Pitch Accent Trajectories Across Different Conditions of Visibility and Information Structure - Evidence from Spontaneous Dyadic Interaction", ["Petra Wagner", "Nataliya Bryhadyr", "Marin Schroer"], "https://doi.org/10.21437/Interspeech.2019-1619", 5, "interspeech", 2019]], "Daniela Figueiredo": [0, ["Age-Related Changes in European Portuguese Vowel Acoustics", ["Luciana Albuquerque", "Catarina Oliveira", "Antonio J. S. Teixeira", "Pedro Sa-Couto", "Daniela Figueiredo"], "https://doi.org/10.21437/Interspeech.2019-1818", 5, "interspeech", 2019]], "Shutao Sun": [3.0930749628232945e-10, ["ToneNet: A CNN Model of Tone Classification of Mandarin Chinese", ["Qiang Gao", "Shutao Sun", "Yaping Yang"], "https://doi.org/10.21437/Interspeech.2019-1483", 5, "interspeech", 2019]], "Ngoc-Quan Pham": [0, ["Very Deep Self-Attention Networks for End-to-End Speech Recognition", ["Ngoc-Quan Pham", "Thai-Son Nguyen", "Jan Niehues", "Markus Muller", "Alex Waibel"], "https://doi.org/10.21437/Interspeech.2019-2702", 5, "interspeech", 2019]], "Basil Abraham": [0, ["Exploiting Monolingual Speech Corpora for Code-Mixed Speech Recognition", ["Karan Taneja", "Satarupa Guha", "Preethi Jyothi", "Basil Abraham"], "https://doi.org/10.21437/Interspeech.2019-1959", 5, "interspeech", 2019]], "Alex Brouwer": [0, ["All Together Now: The Living Audio Dataset", ["David A. Braude", "Matthew P. Aylett", "Caoimhin Laoide-Kemp", "Simone Ashby", "Kristen M. Scott", "Brian O Raghallaigh", "Anna Braudo", "Alex Brouwer", "Adriana Stan"], "https://doi.org/10.21437/Interspeech.2019-2448", 5, "interspeech", 2019]], "Yongbin You": [0, ["Joint Decoding of CTC Based Systems for Speech Recognition", ["Jiaqi Guo", "Yongbin You", "Yanmin Qian", "Kai Yu"], "https://doi.org/10.21437/Interspeech.2019-2026", 5, "interspeech", 2019]], "Karan Taneja": [0, ["Exploiting Monolingual Speech Corpora for Code-Mixed Speech Recognition", ["Karan Taneja", "Satarupa Guha", "Preethi Jyothi", "Basil Abraham"], "https://doi.org/10.21437/Interspeech.2019-1959", 5, "interspeech", 2019]], "Chuxiong Zhang": [0, ["Polyphone Disambiguation for Mandarin Chinese Using Conditional Neural Network with Multi-Level Embedding Features", ["Zexin Cai", "Yaogen Yang", "Chuxiong Zhang", "Xiaoyi Qin", "Ming Li"], "https://doi.org/10.21437/Interspeech.2019-1235", 5, "interspeech", 2019]], "L. Felipe Parra-Gallego": [0, ["Apkinson: A Mobile Solution for Multimodal Assessment of Patients with Parkinson's Disease", ["Juan Camilo Vasquez-Correa", "Tomas Arias-Vergara", "Philipp Klumpp", "M. Strauss", "Arne Kuderle", "Nils Roth", "S. Bayerl", "Nicanor Garcia-Ospina", "Paula Andrea Perez-Toro", "L. Felipe Parra-Gallego", "Cristian David Rios-Urrego", "D. Escobar-Grisales", "Juan Rafael Orozco-Arroyave", "Bjorn Eskofier", "Elmar Noth"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8003.html", 2, "interspeech", 2019]], "Quoc V. Le": [0, ["SpecAugment: A Simple Data Augmentation Method for Automatic Speech Recognition", ["Daniel S. Park", "William Chan", "Yu Zhang", "Chung-Cheng Chiu", "Barret Zoph", "Ekin D. Cubuk", "Quoc V. Le"], "https://doi.org/10.21437/Interspeech.2019-2680", 5, "interspeech", 2019]], "Feng-Guang Su": [0, ["Personalized Dialogue Response Generation Learned from Monologues", ["Feng-Guang Su", "Aliyah R. Hsu", "Yi-Lin Tuan", "Hung-yi Lee"], "https://doi.org/10.21437/Interspeech.2019-1696", 5, "interspeech", 2019]], "Yi-Tong Wu": [1.8219005141872913e-05, ["Acoustic Indicators of Deception in Mandarin Daily Conversations Recorded from an Interactive Game", ["Chih-Hsiang Huang", "Huang-Cheng Chou", "Yi-Tong Wu", "Chi-Chun Lee", "Yi-Wen Liu"], "https://doi.org/10.21437/Interspeech.2019-2216", 5, "interspeech", 2019]], "Min Tang": [0, ["Hybrid Arbitration Using Raw ASR String and NLU Information - Taking the Best of Both Embedded World and Cloud World", ["Min Tang"], "https://doi.org/10.21437/Interspeech.2019-2586", 5, "interspeech", 2019]], "Huyen Nguyen": [0, ["Jasper: An End-to-End Convolutional Neural Acoustic Model", ["Jason Li", "Vitaly Lavrukhin", "Boris Ginsburg", "Ryan Leary", "Oleksii Kuchaiev", "Jonathan M. Cohen", "Huyen Nguyen", "Ravi Teja Gadde"], "https://doi.org/10.21437/Interspeech.2019-1819", 5, "interspeech", 2019]], "Meng Jian": [0, ["Prosodic Characteristics of Mandarin Declarative and Interrogative Utterances in Parkinson's Disease", ["Lei Liu", "Meng Jian", "Wentao Gu"], "https://doi.org/10.21437/Interspeech.2019-3276", 5, "interspeech", 2019]], "Zvi Kons": [0, ["High Quality, Lightweight and Adaptable TTS Using LPCNet", ["Zvi Kons", "Slava Shechtman", "Alexander Sorin", "Carmel Rabinovitz", "Ron Hoory"], "https://doi.org/10.21437/Interspeech.2019-1705", 5, "interspeech", 2019]], "Ivan Sorokin": [0, ["R-Vectors: New Technique for Adaptation to Room Acoustics", ["Yuri Y. Khokhlov", "Alexander Zatvornitskiy", "Ivan Medennikov", "Ivan Sorokin", "Tatiana Prisyach", "Aleksei Romanenko", "Anton Mitrofanov", "Vladimir Bataev", "Andrei Andrusenko", "Mariya Korenevskaya", "Oleg Petrov"], "https://doi.org/10.21437/Interspeech.2019-2645", 5, "interspeech", 2019], ["The STC ASR System for the VOiCES from a Distance Challenge 2019", ["Ivan Medennikov", "Yuri Y. Khokhlov", "Aleksei Romanenko", "Ivan Sorokin", "Anton Mitrofanov", "Vladimir Bataev", "Andrei Andrusenko", "Tatiana Prisyach", "Mariya Korenevskaya", "Oleg Petrov", "Alexander Zatvornitskiy"], "https://doi.org/10.21437/Interspeech.2019-1574", 5, "interspeech", 2019], ["The STC ASR System for the VOiCES from a Distance Challenge 2019", ["Ivan Medennikov", "Yuri Y. Khokhlov", "Aleksei Romanenko", "Ivan Sorokin", "Anton Mitrofanov", "Vladimir Bataev", "Andrei Andrusenko", "Tatiana Prisyach", "Mariya Korenevskaya", "Oleg Petrov", "Alexander Zatvornitskiy"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/abs17.html", 0, "interspeech", 2019]], "Yulong Liang": [0, ["The LeVoice Far-Field Speech Recognition System for VOiCES from a Distance Challenge 2019", ["Yulong Liang", "Lin Yang", "Xuyang Wang", "Yingjie Li", "Chen Jia", "Junjie Wang"], "https://doi.org/10.21437/Interspeech.2019-1944", 5, "interspeech", 2019]], "Ying Tong": [0, ["Direct-Path Signal Cross-Correlation Estimation for Sound Source Localization in Reverberation", ["Wei Xue", "Ying Tong", "Guohong Ding", "Chao Zhang", "Tao Ma", "Xiaodong He", "Bowen Zhou"], "https://doi.org/10.21437/Interspeech.2019-1488", 5, "interspeech", 2019]], "Takashi Fukuda": [0, ["Direct Neuron-Wise Fusion of Cognate Neural Networks", ["Takashi Fukuda", "Masayuki Suzuki", "Gakuto Kurata"], "https://doi.org/10.21437/Interspeech.2019-1930", 5, "interspeech", 2019]], "Bogdan Ludusan": [0, ["Laughter Dynamics in Dyadic Conversations", ["Bogdan Ludusan", "Petra Wagner"], "https://doi.org/10.21437/Interspeech.2019-1733", 5, "interspeech", 2019], ["Nasal Consonant Discrimination in Infant- and Adult-Directed Speech", ["Bogdan Ludusan", "Annett Jorschick", "Reiko Mazuka"], "https://doi.org/10.21437/Interspeech.2019-1737", 5, "interspeech", 2019]], "Piero Pierucci": [0, ["Fusion Techniques for Utterance-Level Emotion Recognition Combining Speech and Transcripts", ["Jilt Sebastian", "Piero Pierucci"], "https://doi.org/10.21437/Interspeech.2019-3201", 5, "interspeech", 2019]], "Youngsoo Kim": [0.9997629821300507, ["Robust Keyword Spotting via Recycle-Pooling for Mobile Game", ["Shounan An", "Youngsoo Kim", "Hu Xu", "Jinwoo Lee", "Myungwoo Lee", "Insoo Oh"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8010.html", 2, "interspeech", 2019]], "Geon Woo Lee": [0.9999426007270813, ["Directional Audio Rendering Using a Neural Network Based Personalized HRTF", ["Geon Woo Lee", "Jung Hyuk Lee", "Seong Ju Kim", "Hong Kook Kim"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8005.html", 2, "interspeech", 2019]], "Pengcheng Li": [0, ["Improving Aggregation and Loss Function for Better Embedding Learning in End-to-End Speaker Verification System", ["Zhifu Gao", "Yan Song", "Ian McLoughlin", "Pengcheng Li", "Yiheng Jiang", "Li-Rong Dai"], "https://doi.org/10.21437/Interspeech.2019-1489", 5, "interspeech", 2019]], "Alexandros Koumparoulis": [0, ["MobiLipNet: Resource-Efficient Deep Learning Based Lipreading", ["Alexandros Koumparoulis", "Gerasimos Potamianos"], "https://doi.org/10.21437/Interspeech.2019-2618", 5, "interspeech", 2019]], "Daniel R. Turner": [0, ["Perception of Pitch Contours in Speech and Nonspeech", ["Daniel R. Turner", "Ann R. Bradlow", "Jennifer S. Cole"], "https://doi.org/10.21437/Interspeech.2019-2619", 5, "interspeech", 2019]], "Hiroaki Takatsu": [0, ["Recognition of Intentions of Users' Short Responses for Conversational News Delivery System", ["Hiroaki Takatsu", "Katsuya Yokoyama", "Yoichi Matsuyama", "Hiroshi Honda", "Shinya Fujie", "Tetsunori Kobayashi"], "https://doi.org/10.21437/Interspeech.2019-2121", 5, "interspeech", 2019]], "Aurelien Bellet": [0, ["Privacy-Preserving Adversarial Representation Learning in ASR: Reality or Illusion?", ["Brij Mohan Lal Srivastava", "Aurelien Bellet", "Marc Tommasi", "Emmanuel Vincent"], "https://doi.org/10.21437/Interspeech.2019-2415", 5, "interspeech", 2019]], "Adele Aubin": [0, ["Improving Speech Synthesis with Discourse Relations", ["Adele Aubin", "Alessandra Cervone", "Oliver Watts", "Simon King"], "https://doi.org/10.21437/Interspeech.2019-1945", 5, "interspeech", 2019]], "Jaejin Cho": [0.962470218539238, ["Study of the Performance of Automatic Speech Recognition Systems in Speakers with Parkinson's Disease", ["Laureano Moro-Velazquez", "Jaejin Cho", "Shinji Watanabe", "Mark A. Hasegawa-Johnson", "Odette Scharenborg", "Heejin Kim", "Najim Dehak"], "https://doi.org/10.21437/Interspeech.2019-2993", 5, "interspeech", 2019]], "Koji Inoue": [0, ["Turn-Taking Prediction Based on Detection of Transition Relevance Place", ["Kohei Hara", "Koji Inoue", "Katsuya Takanashi", "Tatsuya Kawahara"], "https://doi.org/10.21437/Interspeech.2019-1537", 5, "interspeech", 2019]], "Adam Wrobel": [0, ["Avaya Conversational Intelligence: A Real-Time System for Spoken Language Understanding in Human-Human Call Center Conversations", ["Jan Mizgajski", "Adrian Szymczak", "Robert Glowski", "Piotr Szymanski", "Piotr Zelasko", "Lukasz Augustyniak", "Mikolaj Morzy", "Yishay Carmiel", "Jeff Hodson", "Lukasz Wojciak", "Daniel Smoczyk", "Adam Wrobel", "Bartosz Borowik", "Adam Artajew", "Marcin Baran", "Cezary Kwiatkowski", "Marzena Zyla-Hoppe"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8002.html", 2, "interspeech", 2019]], "Dravyansh Sharma": [0, ["Better Morphology Prediction for Better Speech Systems", ["Dravyansh Sharma", "Melissa Wilson", "Antoine Bruguier"], "https://doi.org/10.21437/Interspeech.2019-3207", 5, "interspeech", 2019]], "Ian McLoughlin": [0, ["Improving Aggregation and Loss Function for Better Embedding Learning in End-to-End Speaker Verification System", ["Zhifu Gao", "Yan Song", "Ian McLoughlin", "Pengcheng Li", "Yiheng Jiang", "Li-Rong Dai"], "https://doi.org/10.21437/Interspeech.2019-1489", 5, "interspeech", 2019], ["An Effective Deep Embedding Learning Architecture for Speaker Verification", ["Yiheng Jiang", "Yan Song", "Ian McLoughlin", "Zhifu Gao", "Li-Rong Dai"], "https://doi.org/10.21437/Interspeech.2019-1606", 5, "interspeech", 2019], ["A New Time-Frequency Attention Mechanism for TDNN and CNN-LSTM-TDNN, with Application to Language Identification", ["Xiaoxiao Miao", "Ian McLoughlin", "Yonghong Yan"], "https://doi.org/10.21437/Interspeech.2019-1256", 5, "interspeech", 2019]], "Alice Rueda": [0, ["Feature Representation of Pathophysiology of Parkinsonian Dysarthria", ["Alice Rueda", "Juan Camilo Vasquez-Correa", "Cristian David Rios-Urrego", "Juan Rafael Orozco-Arroyave", "Sridhar Krishnan", "Elmar Noth"], "https://doi.org/10.21437/Interspeech.2019-2490", 5, "interspeech", 2019]], "Per Fallgren": [0, ["How to Annotate 100 Hours in 45 Minutes", ["Per Fallgren", "Zofia Malisz", "Jens Edlund"], "https://doi.org/10.21437/Interspeech.2019-1648", 5, "interspeech", 2019], ["Spot the Pleasant People! Navigating the Cocktail Party Buzz", ["Christina Tannander", "Per Fallgren", "Jens Edlund", "Joakim Gusafsson"], "https://doi.org/10.21437/Interspeech.2019-1553", 5, "interspeech", 2019]], "Jill Dolata": [0, ["Improving ASR Systems for Children with Autism and Language Impairment Using Domain-Focused DNN Transfer Techniques", ["Robert Gale", "Liu Chen", "Jill Dolata", "Jan P. H. van Santen", "Meysam Asgari"], "https://doi.org/10.21437/Interspeech.2019-3161", 5, "interspeech", 2019]], "Cyril Allauzen": [0, ["Contextual Recovery of Out-of-Lattice Named Entities in Automatic Speech Recognition", ["Jack Serrino", "Leonid Velikovich", "Petar S. Aleksic", "Cyril Allauzen"], "https://doi.org/10.21437/Interspeech.2019-2962", 5, "interspeech", 2019]], "Chang Liu": [0, ["Character-Aware Sub-Word Level Language Modeling for Uyghur and Turkish ASR", ["Chang Liu", "Zhen Zhang", "Pengyuan Zhang", "Yonghong Yan"], "https://doi.org/10.21437/Interspeech.2019-1484", 5, "interspeech", 2019], ["Diagnosing Dysarthria with Long Short-Term Memory Networks", ["Alex Mayle", "Zhiwei Mou", "Razvan C. Bunescu", "Sadegh Mirshekarian", "Li Xu", "Chang Liu"], "https://doi.org/10.21437/Interspeech.2019-2903", 5, "interspeech", 2019]], "Sean U. N. Wood": [0, ["Maximum a posteriori Speech Enhancement Based on Double Spectrum", ["Pejman Mowlaee", "Daniel Scheran", "Johannes Stahl", "Sean U. N. Wood", "W. Bastiaan Kleijn"], "https://doi.org/10.21437/Interspeech.2019-1197", 5, "interspeech", 2019]], "Andreas Wendemuth": [0, ["Employing Bottleneck and Convolutional Features for Speech-Based Physical Load Detection on Limited Data Amounts", ["Olga Egorow", "Tarik Mrech", "Norman Weisskirchen", "Andreas Wendemuth"], "https://doi.org/10.21437/Interspeech.2019-2502", 5, "interspeech", 2019]], "Moustafa Alzantot": [0, ["Deep Residual Neural Networks for Audio Spoofing Detection", ["Moustafa Alzantot", "Ziqi Wang", "Mani B. Srivastava"], "https://doi.org/10.21437/Interspeech.2019-3174", 5, "interspeech", 2019]], "Prakhar Swarup": [0, ["Improving ASR Confidence Scores for Alexa Using Acoustic and Hypothesis Embeddings", ["Prakhar Swarup", "Roland Maas", "Sri Garimella", "Sri Harish Mallidi", "Bjorn Hoffmeister"], "https://doi.org/10.21437/Interspeech.2019-1241", 5, "interspeech", 2019]], "Mahaveer Jain": [0, ["Joint Grapheme and Phoneme Embeddings for Contextual End-to-End ASR", ["Zhehuai Chen", "Mahaveer Jain", "Yongqiang Wang", "Michael L. Seltzer", "Christian Fuegen"], "https://doi.org/10.21437/Interspeech.2019-1434", 5, "interspeech", 2019]], "Herve Bredin": [0, ["LSTM Based Similarity Measurement with Spectral Clustering for Speaker Diarization", ["Qingjian Lin", "Ruiqing Yin", "Ming Li", "Herve Bredin", "Claude Barras"], "https://doi.org/10.21437/Interspeech.2019-1388", 5, "interspeech", 2019]], "Zheng-Hua Tan": [0, ["Keyword Spotting for Hearing Assistive Devices Robust to External Speakers", ["Ivan Lopez-Espejo", "Zheng-Hua Tan", "Jesper Jensen"], "https://doi.org/10.21437/Interspeech.2019-2010", 5, "interspeech", 2019]], "Koji Okabe": [0, ["Speaker Augmentation and Bandwidth Extension for Deep Speaker Embedding", ["Hitoshi Yamamoto", "Kong Aik Lee", "Koji Okabe", "Takafumi Koshinaka"], "https://doi.org/10.21437/Interspeech.2019-1508", 5, "interspeech", 2019], ["I4U Submission to NIST SRE 2018: Leveraging from a Decade of Shared Experiences", ["Kong Aik Lee", "Ville Hautamaki", "Tomi H. Kinnunen", "Hitoshi Yamamoto", "Koji Okabe", "Ville Vestman", "Jing Huang", "Guohong Ding", "Hanwu Sun", "Anthony Larcher", "Rohan Kumar Das", "Haizhou Li", "Mickael Rouvier", "Pierre-Michel Bousquet", "Wei Rao", "Qing Wang", "Chunlei Zhang", "Fahimeh Bahmaninezhad", "Hector Delgado", "Massimiliano Todisco"], "https://doi.org/10.21437/Interspeech.2019-1533", 5, "interspeech", 2019], ["The NEC-TT 2018 Speaker Verification System", ["Kong Aik Lee", "Hitoshi Yamamoto", "Koji Okabe", "Qiongqiong Wang", "Ling Guo", "Takafumi Koshinaka", "Jiacen Zhang", "Koichi Shinoda"], "https://doi.org/10.21437/Interspeech.2019-1517", 5, "interspeech", 2019]], "Yanzhang He": [0, ["Two-Pass End-to-End Speech Recognition", ["Tara N. Sainath", "Ruoming Pang", "David Rybach", "Yanzhang He", "Rohit Prabhavalkar", "Wei Li", "Mirko Visontai", "Qiao Liang", "Trevor Strohman", "Yonghui Wu", "Ian McGraw", "Chung-Cheng Chiu"], "https://doi.org/10.21437/Interspeech.2019-1341", 5, "interspeech", 2019]], "Harry Bleyan": [0, ["Developing Pronunciation Models in New Languages Faster by Exploiting Common Grapheme-to-Phoneme Correspondences Across Languages", ["Harry Bleyan", "Sandy Ritchie", "Jonas Fromseier Mortensen", "Daan van Esch"], "https://doi.org/10.21437/Interspeech.2019-1781", 5, "interspeech", 2019]], "Theo Biasutto-Lervat": [0, ["Modeling Labial Coarticulation with Bidirectional Gated Recurrent Networks and Transfer Learning", ["Theo Biasutto-Lervat", "Sara Dahmani", "Slim Ouni"], "https://doi.org/10.21437/Interspeech.2019-2097", 5, "interspeech", 2019]], "Ji-Hwan Kim": [0.9722291678190231, ["Shortcut Connections Based Deep Speaker Embeddings for End-to-End Speaker Verification System", ["Soonshin Seo", "Daniel Jun Rim", "Minkyu Lim", "Donghyun Lee", "Hosung Park", "Junseok Oh", "Changmin Kim", "Ji-Hwan Kim"], "https://doi.org/10.21437/Interspeech.2019-2195", 5, "interspeech", 2019]], "Rimita Lahiri": [0, ["The Second DIHARD Challenge: System Description for USC-SAIL Team", ["Tae Jin Park", "Manoj Kumar", "Nikolaos Flemotomos", "Monisankha Pal", "Raghuveer Peri", "Rimita Lahiri", "Panayiotis G. Georgiou", "Shrikanth Narayanan"], "https://doi.org/10.21437/Interspeech.2019-1903", 5, "interspeech", 2019]], "Aijun Li": [0, ["CNN-BLSTM Based Question Detection from Dialogs Considering Phase and Context Information", ["Yuke Si", "Longbiao Wang", "Jianwu Dang", "Mengfei Wu", "Aijun Li"], "https://doi.org/10.21437/Interspeech.2019-1701", 5, "interspeech", 2019]], "Hema A. Murthy": [0, ["Zero Resource Speech Synthesis Using Transcripts Derived from Perceptual Acoustic Units", ["Karthik Pandia D. S", "Hema A. Murthy"], "https://doi.org/10.21437/Interspeech.2019-2336", 5, "interspeech", 2019]], "Jan Luttenberger": [0, ["Sound Tools eXtended (STx) 5.0 - A Powerful Sound Analysis Tool Optimized for Speech", ["Anton Noll", "Jonathan Stuefer", "Nicola Klingler", "Hannah Leykum", "Carina Lozo", "Jan Luttenberger", "Michael Pucher", "Carolin Schmid"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8022.html", 2, "interspeech", 2019]], "Alexander Gruenstein": [0, ["Multi-Microphone Adaptive Noise Cancellation for Robust Hotword Detection", ["Yiteng Huang", "Turaj Zakizadeh Shabestary", "Alexander Gruenstein", "Li Wan"], "https://doi.org/10.21437/Interspeech.2019-3006", 5, "interspeech", 2019]], "Md. Mahbubur Rahman": [0, ["DeepLung: Smartphone Convolutional Neural Network-Based Inference of Lung Anomalies for Pulmonary Patients", ["Mohsin Y. Ahmed", "Md. Mahbubur Rahman", "Jilong Kuang"], "https://doi.org/10.21437/Interspeech.2019-2953", 5, "interspeech", 2019]], "Nagaraj Adiga": [0, ["On the Suitability of the Riesz Spectro-Temporal Envelope for WaveNet Based Speech Synthesis", ["Jitendra Kumar Dhiman", "Nagaraj Adiga", "Chandra Sekhar Seelamantula"], "https://doi.org/10.21437/Interspeech.2019-2626", 5, "interspeech", 2019], ["Speech Enhancement for Noise-Robust Speech Synthesis Using Wasserstein GAN", ["Nagaraj Adiga", "Yannis Pantazis", "Vassilis Tsiaras", "Yannis Stylianou"], "https://doi.org/10.21437/Interspeech.2019-2648", 5, "interspeech", 2019], ["A Non-Causal FFTNet Architecture for Speech Enhancement", ["P. V. Muhammed Shifas", "Nagaraj Adiga", "Vassilis Tsiaras", "Yannis Stylianou"], "https://doi.org/10.21437/Interspeech.2019-2622", 5, "interspeech", 2019]], "Zhicheng Liu": [0, ["Acoustic and Articulatory Study of Ewe Vowels: A Comparative Study of Male and Female", ["Kowovi Comivi Alowonou", "Jianguo Wei", "Wenhuan Lu", "Zhicheng Liu", "Kiyoshi Honda", "Jianwu Dang"], "https://doi.org/10.21437/Interspeech.2019-2196", 5, "interspeech", 2019]], "Outi Tuomainen": [0, ["Subjective Evaluation of Communicative Effort for Younger and Older Adults in Interactive Tasks with Energetic and Informational Masking", ["Valerie Hazan", "Outi Tuomainen", "Linda Taschenberger"], "https://doi.org/10.21437/Interspeech.2019-2215", 5, "interspeech", 2019]], "Moritz Meier": [0, ["Comparative Analysis of Think-Aloud Methods for Everyday Activities in the Context of Cognitive Robotics", ["Moritz Meier", "Celeste Mason", "Felix Putze", "Tanja Schultz"], "https://doi.org/10.21437/Interspeech.2019-3072", 5, "interspeech", 2019]], "Samuel Thomas": [0, ["Learning Speaker Aware Offsets for Speaker Adaptation of Neural Networks", ["Leda Sari", "Samuel Thomas", "Mark A. Hasegawa-Johnson"], "https://doi.org/10.21437/Interspeech.2019-1788", 5, "interspeech", 2019], ["Detection and Recovery of OOVs for Improved English Broadcast News Captioning", ["Samuel Thomas", "Kartik Audhkhasi", "Zoltan Tuske", "Yinghui Huang", "Michael Picheny"], "https://doi.org/10.21437/Interspeech.2019-2793", 5, "interspeech", 2019]], "Liming Wang": [7.770433512632735e-06, ["Multimodal Word Discovery and Retrieval with Phone Sequence and Image Concepts", ["Liming Wang", "Mark A. Hasegawa-Johnson"], "https://doi.org/10.21437/Interspeech.2019-1487", 5, "interspeech", 2019]], "Matthew P. Aylett": [0, ["All Together Now: The Living Audio Dataset", ["David A. Braude", "Matthew P. Aylett", "Caoimhin Laoide-Kemp", "Simone Ashby", "Kristen M. Scott", "Brian O Raghallaigh", "Anna Braudo", "Alex Brouwer", "Adriana Stan"], "https://doi.org/10.21437/Interspeech.2019-2448", 5, "interspeech", 2019]], "Mi Suk Lee": [0.9834838956594467, ["Cascaded Cross-Module Residual Learning Towards Lightweight End-to-End Speech Coding", ["Kai Zhen", "Jongmo Sung", "Mi Suk Lee", "Seungkwon Beack", "Minje Kim"], "https://doi.org/10.21437/Interspeech.2019-1816", 5, "interspeech", 2019]], "Tino Haderlein": [0, ["Feature Space Visualization with Spatial Similarity Maps for Pathological Speech Data", ["Philipp Klumpp", "Juan Camilo Vasquez-Correa", "Tino Haderlein", "Elmar Noth"], "https://doi.org/10.21437/Interspeech.2019-2080", 5, "interspeech", 2019]], "Maximilian Schmitt": [0, ["The INTERSPEECH 2019 Computational Paralinguistics Challenge: Styrian Dialects, Continuous Sleepiness, Baby Sounds & Orca Activity", ["Bjorn W. Schuller", "Anton Batliner", "Christian Bergler", "Florian B. Pokorny", "Jarek Krajewski", "Margaret Cychosz", "Ralf Vollmann", "Sonja-Dana Roelen", "Sebastian Schnieder", "Elika Bergelson", "Alejandrina Cristia", "Amanda Seidl", "Anne S. Warlaumont", "Lisa Yankowitz", "Elmar Noth", "Shahin Amiriparian", "Simone Hantke", "Maximilian Schmitt"], "https://doi.org/10.21437/Interspeech.2019-1122", 5, "interspeech", 2019], ["Continuous Emotion Recognition in Speech - Do We Need Recurrence?", ["Maximilian Schmitt", "Nicholas Cummins", "Bjorn W. Schuller"], "https://doi.org/10.21437/Interspeech.2019-2710", 5, "interspeech", 2019]], "Michael Chinen": [0, ["Salient Speech Representations Based on Cloned Networks", ["W. Bastiaan Kleijn", "Felicia S. C. Lim", "Michael Chinen", "Jan Skoglund"], "https://doi.org/10.21437/Interspeech.2019-1861", 5, "interspeech", 2019]], "Vasiliy Radostev": [0, ["Speech-Based Web Navigation for Limited Mobility Users", ["Vasiliy Radostev", "Serge Berger", "Justin Tabrizi", "Pasha Kamyshev", "Hisami Suzuki"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8042.html", 2, "interspeech", 2019]], "Brian Vaughan": [0, ["An Investigation of Therapeutic Rapport Through Prosody in Brief Psychodynamic Psychotherapy", ["Carolina De Pasquale", "Charlie Cullen", "Brian Vaughan"], "https://doi.org/10.21437/Interspeech.2019-2551", 5, "interspeech", 2019]], "Xinwei Li": [0, ["Listen, Attend, Spell and Adapt: Speaker Adapted Sequence-to-Sequence ASR", ["Felix Weninger", "Jesus Andres-Ferrer", "Xinwei Li", "Puming Zhan"], "https://doi.org/10.21437/Interspeech.2019-2719", 5, "interspeech", 2019]], "Wei-Ning Hsu": [0, ["An Unsupervised Autoregressive Model for Speech Representation Learning", ["Yu-An Chung", "Wei-Ning Hsu", "Hao Tang", "James R. Glass"], "https://doi.org/10.21437/Interspeech.2019-1473", 5, "interspeech", 2019], ["Transfer Learning from Audio-Visual Grounding to Speech Recognition", ["Wei-Ning Hsu", "David Harwath", "James R. Glass"], "https://doi.org/10.21437/Interspeech.2019-1227", 5, "interspeech", 2019]], "Jiqing Han": [5.275537318993884e-06, ["Deep Attention Gated Dilated Temporal Convolutional Networks with Intra-Parallel Convolutional Modules for End-to-End Monaural Speech Separation", ["Ziqiang Shi", "Huibin Lin", "Liu Liu", "Rujie Liu", "Jiqing Han", "Anyan Shi"], "https://doi.org/10.21437/Interspeech.2019-1373", 5, "interspeech", 2019], ["Cross-Corpus Speech Emotion Recognition Using Semi-Supervised Transfer Non-Negative Matrix Factorization with Adaptation Regularization", ["Hui Luo", "Jiqing Han"], "https://doi.org/10.21437/Interspeech.2019-2041", 5, "interspeech", 2019], ["Subspace Pooling Based Temporal Features Extraction for Audio Event Recognition", ["Qiuying Shi", "Hui Luo", "Jiqing Han"], "https://doi.org/10.21437/Interspeech.2019-2047", 5, "interspeech", 2019], ["Acoustic Scene Classification by Implicitly Identifying Distinct Sound Events", ["Hongwei Song", "Jiqing Han", "Shiwen Deng", "Zhihao Du"], "https://doi.org/10.21437/Interspeech.2019-2231", 5, "interspeech", 2019], ["End-to-End Monaural Speech Separation with Multi-Scale Dynamic Weighted Gated Dilated Convolutional Pyramid Network", ["Ziqiang Shi", "Huibin Lin", "Liu Liu", "Rujie Liu", "Shoji Hayakawa", "Shouji Harada", "Jiqing Han"], "https://doi.org/10.21437/Interspeech.2019-1292", 5, "interspeech", 2019]], "Hagen Soltau": [0, ["Joint Speech Recognition and Speaker Diarization via Sequence Transduction", ["Laurent El Shafey", "Hagen Soltau", "Izhak Shafran"], "https://doi.org/10.21437/Interspeech.2019-1943", 5, "interspeech", 2019]], "Adithya Renduchintala": [0, ["Pretraining by Backtranslation for End-to-End ASR in Low-Resource Settings", ["Matthew Wiesner", "Adithya Renduchintala", "Shinji Watanabe", "Chunxi Liu", "Najim Dehak", "Sanjeev Khudanpur"], "https://doi.org/10.21437/Interspeech.2019-3254", 5, "interspeech", 2019]], "Ladislav Mosner": [0, ["Analysis of BUT Submission in Far-Field Scenarios of VOiCES 2019 Challenge", ["Pavel Matejka", "Oldrich Plchot", "Hossein Zeinali", "Ladislav Mosner", "Anna Silnova", "Lukas Burget", "Ondrej Novotny", "Ondrej Glembek"], "https://doi.org/10.21437/Interspeech.2019-2471", 5, "interspeech", 2019], ["Analysis of BUT Submission in Far-Field Scenarios of VOiCES 2019 Challenge", ["Pavel Matejka", "Oldrich Plchot", "Hossein Zeinali", "Ladislav Mosner", "Anna Silnova", "Lukas Burget", "Ondrej Novotny", "Ondrej Glembek"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/abs16.html", 0, "interspeech", 2019]], "Su-Youn Yoon": [0.9995113462209702, ["Development of Robust Automated Scoring Models Using Adversarial Input for Oral Proficiency Assessment", ["Su-Youn Yoon", "Chong Min Lee", "Klaus Zechner", "Keelan Evanini"], "https://doi.org/10.21437/Interspeech.2019-1711", 5, "interspeech", 2019], ["Automatic Detection of Off-Topic Spoken Responses Using Very Deep Convolutional Neural Networks", ["Xinhao Wang", "Su-Youn Yoon", "Keelan Evanini", "Klaus Zechner", "Yao Qian"], "https://doi.org/10.21437/Interspeech.2019-1848", 5, "interspeech", 2019]], "Matthew Purver": [0, ["Detecting Depression with Word-Level Multimodal Fusion", ["Morteza Rohanian", "Julian Hough", "Matthew Purver"], "https://doi.org/10.21437/Interspeech.2019-2283", 5, "interspeech", 2019]], "Ju-Chieh Chou": [0, ["One-Shot Voice Conversion by Separating Speaker and Content Representations with Instance Normalization", ["Ju-Chieh Chou", "Hung-yi Lee"], "https://doi.org/10.21437/Interspeech.2019-2663", 5, "interspeech", 2019]], "Fei Huang": [0, ["Noisy BiLSTM-Based Models for Disfluency Detection", ["Nguyen Bach", "Fei Huang"], "https://doi.org/10.21437/Interspeech.2019-1336", 5, "interspeech", 2019]], "David Sztaho": [0, ["Depression State Assessment: Application for Detection of Depression by Speech", ["Gabor Kiss", "David Sztaho", "Klara Vicsi"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8004.html", 2, "interspeech", 2019]], "Jeunghun Kim": [0.999439999461174, ["End-to-End Multi-Channel Speech Enhancement Using Inter-Channel Time-Restricted Attention on Raw Waveform", ["Hyeon Seung Lee", "Hyung Yong Kim", "Woo Hyun Kang", "Jeunghun Kim", "Nam Soo Kim"], "https://doi.org/10.21437/Interspeech.2019-2397", 5, "interspeech", 2019]], "Jan Cernocky": [0, ["Bayesian Subspace Hidden Markov Model for Acoustic Unit Discovery", ["Lucas Ondel", "Hari Krishna Vydana", "Lukas Burget", "Jan Cernocky"], "https://doi.org/10.21437/Interspeech.2019-2224", 5, "interspeech", 2019], ["Bayesian HMM Based x-Vector Clustering for Speaker Diarization", ["Mireia Diez", "Lukas Burget", "Shuai Wang", "Johan Rohdin", "Jan Cernocky"], "https://doi.org/10.21437/Interspeech.2019-2813", 5, "interspeech", 2019], ["Detecting Spoofing Attacks Using VGG and SincNet: BUT-Omilia Submission to ASVspoof 2019 Challenge", ["Hossein Zeinali", "Themos Stafylakis", "Georgia Athanasopoulou", "Johan Rohdin", "Ioannis Gkinis", "Lukas Burget", "Jan Cernocky"], "https://doi.org/10.21437/Interspeech.2019-2892", 5, "interspeech", 2019], ["On the Usage of Phonetic Information for Text-Independent Speaker Embedding Extraction", ["Shuai Wang", "Johan Rohdin", "Lukas Burget", "Oldrich Plchot", "Yanmin Qian", "Kai Yu", "Jan Cernocky"], "https://doi.org/10.21437/Interspeech.2019-3036", 5, "interspeech", 2019], ["Analysis of Multilingual Sequence-to-Sequence Speech Recognition Systems", ["Martin Karafiat", "Murali Karthick Baskar", "Shinji Watanabe", "Takaaki Hori", "Matthew Wiesner", "Jan Cernocky"], "https://doi.org/10.21437/Interspeech.2019-2355", 5, "interspeech", 2019], ["Semi-Supervised Sequence-to-Sequence ASR Using Unpaired Speech and Text", ["Murali Karthick Baskar", "Shinji Watanabe", "Ramon Fernandez Astudillo", "Takaaki Hori", "Lukas Burget", "Jan Cernocky"], "https://doi.org/10.21437/Interspeech.2019-3167", 5, "interspeech", 2019]], "Salam Khalifa": [0, ["Towards Variability Resistant Dialectal Speech Evaluation", ["Ahmed Ali", "Salam Khalifa", "Nizar Habash"], "https://doi.org/10.21437/Interspeech.2019-2692", 5, "interspeech", 2019]], "Qiang Huo": [0, ["Compression of CTC-Trained Acoustic Models by Dynamic Frame-Wise Distillation or Segment-Wise N-Best Hypotheses Imitation", ["Haisong Ding", "Kai Chen", "Qiang Huo"], "https://doi.org/10.21437/Interspeech.2019-2182", 5, "interspeech", 2019]], "Oksana Rasskazova": [0, ["Temporal Coordination of Articulatory and Respiratory Events Prior to Speech Initiation", ["Oksana Rasskazova", "Christine Mooshammer", "Susanne Fuchs"], "https://doi.org/10.21437/Interspeech.2019-2876", 5, "interspeech", 2019]], "Iris Chuoying Ouyang": [0, ["Selection and Training Schemes for Improving TTS Voice Built on Found Data", ["Fang-Yu Kuo", "Iris Chuoying Ouyang", "Sandesh Aryal", "Pierre Lanchantin"], "https://doi.org/10.21437/Interspeech.2019-2816", 5, "interspeech", 2019]], "David A. van Leeuwen": [0, ["Large-Scale Speaker Diarization of Radio Broadcast Archives", ["Emre Yilmaz", "Adem Derinel", "Kun Zhou", "Henk van den Heuvel", "Niko Brummer", "Haizhou Li", "David A. van Leeuwen"], "https://doi.org/10.21437/Interspeech.2019-1399", 5, "interspeech", 2019], ["Multi-Graph Decoding for Code-Switching ASR", ["Emre Yilmaz", "Samuel Cohen", "Xianghu Yue", "David A. van Leeuwen", "Haizhou Li"], "https://doi.org/10.21437/Interspeech.2019-1125", 5, "interspeech", 2019]], "Jean-Christophe Corvol": [0, ["Comparison of Telephone Recordings and Professional Microphone Recordings for Early Detection of Parkinson's Disease, Using Mel-Frequency Cepstral Coefficients with Gaussian Mixture Models", ["Laetitia Jeancolas", "Graziella Mangone", "Jean-Christophe Corvol", "Marie Vidailhet", "Stephane Lehericy", "Badr-Eddine Benkelfat", "Habib Benali", "Dijana Petrovska-Delacretaz"], "https://doi.org/10.21437/Interspeech.2019-2825", 5, "interspeech", 2019]], "Mattia Antonino Di Gangi": [0, ["Adapting Transformer to End-to-End Spoken Language Translation", ["Mattia Antonino Di Gangi", "Matteo Negri", "Marco Turchi"], "https://doi.org/10.21437/Interspeech.2019-3045", 5, "interspeech", 2019]], "Nathalie Camelin": [0, ["Curriculum-Based Transfer Learning for an Effective End-to-End Spoken Language Understanding and Domain Portability", ["Antoine Caubriere", "Natalia A. Tomashenko", "Antoine Laurent", "Emmanuel Morin", "Nathalie Camelin", "Yannick Esteve"], "https://doi.org/10.21437/Interspeech.2019-1832", 5, "interspeech", 2019]], "D. Escobar-Grisales": [0, ["Apkinson: A Mobile Solution for Multimodal Assessment of Patients with Parkinson's Disease", ["Juan Camilo Vasquez-Correa", "Tomas Arias-Vergara", "Philipp Klumpp", "M. Strauss", "Arne Kuderle", "Nils Roth", "S. Bayerl", "Nicanor Garcia-Ospina", "Paula Andrea Perez-Toro", "L. Felipe Parra-Gallego", "Cristian David Rios-Urrego", "D. Escobar-Grisales", "Juan Rafael Orozco-Arroyave", "Bjorn Eskofier", "Elmar Noth"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8003.html", 2, "interspeech", 2019]], "Tatsuro Hori": [0, ["Detecting Topic-Oriented Speaker Stance in Conversational Speech", ["Catherine Lai", "Beatrice Alex", "Johanna D. Moore", "Leimin Tian", "Tatsuro Hori", "Gianpiero Francesca"], "https://doi.org/10.21437/Interspeech.2019-2632", 5, "interspeech", 2019]], "Aki Harma": [0, ["Deep Sensing of Breathing Signal During Conversational Speech", ["Venkata Srikanth Nallanthighal", "Aki Harma", "Helmer Strik"], "https://doi.org/10.21437/Interspeech.2019-1796", 5, "interspeech", 2019]], "Trung Ngo Trong": [0, ["Towards Debugging Deep Neural Networks by Generating Speech Utterances", ["Bilal Soomro", "Anssi Kanervisto", "Trung Ngo Trong", "Ville Hautamaki"], "https://doi.org/10.21437/Interspeech.2019-2339", 5, "interspeech", 2019]], "Max W. Y. Lam": [0, ["Extract, Adapt and Recognize: An End-to-End Neural Network for Corrupted Monaural Speech Recognition", ["Max W. Y. Lam", "Jun Wang", "Xunying Liu", "Helen Meng", "Dan Su", "Dong Yu"], "https://doi.org/10.21437/Interspeech.2019-1626", 5, "interspeech", 2019], ["LF-MMI Training of Bayesian and Gaussian Process Time Delay Neural Networks for Speech Recognition", ["Shoukang Hu", "Xurong Xie", "Shansong Liu", "Max W. Y. Lam", "Jianwei Yu", "Xixin Wu", "Xunying Liu", "Helen Meng"], "https://doi.org/10.21437/Interspeech.2019-2379", 5, "interspeech", 2019], ["Comparative Study of Parametric and Representation Uncertainty Modeling for Recurrent Neural Network Language Models", ["Jianwei Yu", "Max W. Y. Lam", "Shoukang Hu", "Xixin Wu", "Xu Li", "Yuewen Cao", "Xunying Liu", "Helen Meng"], "https://doi.org/10.21437/Interspeech.2019-1927", 5, "interspeech", 2019]], "Soo Jin Park": [0.9360999912023544, ["Voice Quality and Between-Frame Entropy for Sleepiness Estimation", ["Vijay Ravi", "Soo Jin Park", "Amber Afshan", "Abeer Alwan"], "https://doi.org/10.21437/Interspeech.2019-2988", 5, "interspeech", 2019]], "Sonja-Dana Roelen": [0, ["The INTERSPEECH 2019 Computational Paralinguistics Challenge: Styrian Dialects, Continuous Sleepiness, Baby Sounds & Orca Activity", ["Bjorn W. Schuller", "Anton Batliner", "Christian Bergler", "Florian B. Pokorny", "Jarek Krajewski", "Margaret Cychosz", "Ralf Vollmann", "Sonja-Dana Roelen", "Sebastian Schnieder", "Elika Bergelson", "Alejandrina Cristia", "Amanda Seidl", "Anne S. Warlaumont", "Lisa Yankowitz", "Elmar Noth", "Shahin Amiriparian", "Simone Hantke", "Maximilian Schmitt"], "https://doi.org/10.21437/Interspeech.2019-1122", 5, "interspeech", 2019]], "Niko Moritz": [0, ["Unidirectional Neural Network Architectures for End-to-End Automatic Speech Recognition", ["Niko Moritz", "Takaaki Hori", "Jonathan Le Roux"], "https://doi.org/10.21437/Interspeech.2019-2837", 5, "interspeech", 2019], ["Vectorized Beam Search for CTC-Attention-Based Speech Recognition", ["Hiroshi Seki", "Takaaki Hori", "Shinji Watanabe", "Niko Moritz", "Jonathan Le Roux"], "https://doi.org/10.21437/Interspeech.2019-2860", 5, "interspeech", 2019]], "Ricardo Kleinlein": [0, ["Predicting Group-Level Skin Attention to Short Movies from Audio-Based LSTM-Mixture of Experts Models", ["Ricardo Kleinlein", "Cristina Luna Jimenez", "Juan Manuel Montero", "Zoraida Callejas", "Fernando Fernandez-Martinez"], "https://doi.org/10.21437/Interspeech.2019-2799", 5, "interspeech", 2019]], "Georgios Paraskevopoulos": [0, ["Data Augmentation Using GANs for Speech Emotion Recognition", ["Aggelina Chatziagapi", "Georgios Paraskevopoulos", "Dimitris Sgouropoulos", "Georgios Pantazopoulos", "Malvina Nikandrou", "Theodoros Giannakopoulos", "Athanasios Katsamanis", "Alexandros Potamianos", "Shrikanth Narayanan"], "https://doi.org/10.21437/Interspeech.2019-2561", 5, "interspeech", 2019], ["Unsupervised Low-Rank Representations for Speech Emotion Recognition", ["Georgios Paraskevopoulos", "Efthymios Tzinis", "Nikolaos Ellinas", "Theodoros Giannakopoulos", "Alexandros Potamianos"], "https://doi.org/10.21437/Interspeech.2019-2769", 5, "interspeech", 2019]], "Yuanfeng Song": [4.1360019575886753e-10, ["Topic-Aware Dialogue Speech Recognition with Transfer Learning", ["Yuanfeng Song", "Di Jiang", "Xueyang Wu", "Qian Xu", "Raymond Chi-Wing Wong", "Qiang Yang"], "https://doi.org/10.21437/Interspeech.2019-1694", 5, "interspeech", 2019]], "Szu-Wei Fu": [0, ["MOSNet: Deep Learning-Based Objective Assessment for Voice Conversion", ["Chen-Chou Lo", "Szu-Wei Fu", "Wen-Chin Huang", "Xin Wang", "Junichi Yamagishi", "Yu Tsao", "Hsin-Min Wang"], "https://doi.org/10.21437/Interspeech.2019-2003", 5, "interspeech", 2019], ["IA-NET: Acceleration and Compression of Speech Enhancement Using Integer-Adder Deep Neural Network", ["Yu-Chen Lin", "Yi-Te Hsu", "Szu-Wei Fu", "Yu Tsao", "Tei-Wei Kuo"], "https://doi.org/10.21437/Interspeech.2019-1207", 5, "interspeech", 2019], ["Specialized Speech Enhancement Model Selection Based on Learned Non-Intrusive Quality Assessment Metric", ["Ryandhimas E. Zezario", "Szu-Wei Fu", "Xugang Lu", "Hsin-Min Wang", "Yu Tsao"], "https://doi.org/10.21437/Interspeech.2019-2425", 5, "interspeech", 2019]], "Ryan Eloff": [0, ["Unsupervised Acoustic Unit Discovery for Speech Synthesis Using Discrete Latent-Variable Neural Networks", ["Ryan Eloff", "Andre Nortje", "Benjamin van Niekerk", "Avashna Govender", "Leanne Nortje", "Arnu Pretorius", "Elan Van Biljon", "Ewald van der Westhuizen", "Lisa van Staden", "Herman Kamper"], "https://doi.org/10.21437/Interspeech.2019-1518", 5, "interspeech", 2019]], "Javier Jorge": [0, ["Real-Time One-Pass Decoder for Speech Recognition Using LSTM Language Models", ["Javier Jorge", "Adria Gimenez", "Javier Iranzo-Sanchez", "Jorge Civera", "Albert Sanchis", "Alfons Juan"], "https://doi.org/10.21437/Interspeech.2019-2798", 5, "interspeech", 2019]], "Myungwoo Lee": [0.9866698682308197, ["Robust Keyword Spotting via Recycle-Pooling for Mobile Game", ["Shounan An", "Youngsoo Kim", "Hu Xu", "Jinwoo Lee", "Myungwoo Lee", "Insoo Oh"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8010.html", 2, "interspeech", 2019]], "Sarmad Hussain": [0, ["Improving Large Vocabulary Urdu Speech Recognition System Using Deep Neural Networks", ["Muhammad Umar Farooq", "Farah Adeeba", "Sahar Rauf", "Sarmad Hussain"], "https://doi.org/10.21437/Interspeech.2019-2629", 5, "interspeech", 2019]], "Pranav Ladkat": [0, ["Two Tiered Distributed Training Algorithm for Acoustic Modeling", ["Pranav Ladkat", "Oleg Rybakov", "Radhika Arava", "Sree Hari Krishnan Parthasarathi", "I-Fan Chen", "Nikko Strom"], "https://doi.org/10.21437/Interspeech.2019-1859", 5, "interspeech", 2019]], "Manluolan Xu": [0, ["The Processing of Prosodic Cues to Rhetorical Question Interpretation: Psycholinguistic and Neurolinguistics Evidence", ["Mariya Kharaman", "Manluolan Xu", "Carsten Eulitz", "Bettina Braun"], "https://doi.org/10.21437/Interspeech.2019-2528", 5, "interspeech", 2019]], "Naoya Takahashi": [0, ["Recursive Speech Separation for Unknown Number of Speakers", ["Naoya Takahashi", "Sudarsanam Parthasaarathy", "Nabarun Goswami", "Yuki Mitsufuji"], "https://doi.org/10.21437/Interspeech.2019-1550", 5, "interspeech", 2019]], "Raghuveer Peri": [0, ["The Second DIHARD Challenge: System Description for USC-SAIL Team", ["Tae Jin Park", "Manoj Kumar", "Nikolaos Flemotomos", "Monisankha Pal", "Raghuveer Peri", "Rimita Lahiri", "Panayiotis G. Georgiou", "Shrikanth Narayanan"], "https://doi.org/10.21437/Interspeech.2019-1903", 5, "interspeech", 2019], ["Multi-Task Discriminative Training of Hybrid DNN-TVM Model for Speaker Verification with Noisy and Far-Field Speech", ["Arindam Jati", "Raghuveer Peri", "Monisankha Pal", "Tae Jin Park", "Naveen Kumar", "Ruchir Travadi", "Panayiotis G. Georgiou", "Shrikanth Narayanan"], "https://doi.org/10.21437/Interspeech.2019-3010", 5, "interspeech", 2019]], "Xiao-Ping Steven Zhang": [0, ["Automatic Detection of the Temporal Segmentation of Hand Movements in British English Cued Speech", ["Li Liu", "Jianze Li", "Gang Feng", "Xiao-Ping Steven Zhang"], "https://doi.org/10.21437/Interspeech.2019-2353", 5, "interspeech", 2019]], "Hanumant Singh Shekhawat": [0, ["Artificial Bandwidth Extension Using H\u221e Optimization", ["Deepika Gupta", "Hanumant Singh Shekhawat"], "https://doi.org/10.21437/Interspeech.2019-1580", 5, "interspeech", 2019]], "Melvin G. McInnis": [0, ["Into the Wild: Transitioning from Recognizing Mood in Clinical Interactions to Personal Conversations for Individuals with Bipolar Disorder", ["Katie Matton", "Melvin G. McInnis", "Emily Mower Provost"], "https://doi.org/10.21437/Interspeech.2019-2698", 5, "interspeech", 2019], ["Identifying Mood Episodes Using Dialogue Features from Clinical Interviews", ["Zakaria Aldeneh", "Mimansa Jaiswal", "Michael Picheny", "Melvin G. McInnis", "Emily Mower Provost"], "https://doi.org/10.21437/Interspeech.2019-1878", 5, "interspeech", 2019], ["Emotion Recognition from Natural Phone Conversations in Individuals with and without Recent Suicidal Ideation", ["John Gideon", "Heather T. Schatten", "Melvin G. McInnis", "Emily Mower Provost"], "https://doi.org/10.21437/Interspeech.2019-1830", 5, "interspeech", 2019]], "Jingyang Li": [0, ["Towards Discriminative Representations and Unbiased Predictions: Class-Specific Angular Softmax for Speech Emotion Recognition", ["Zhixuan Li", "Liang He", "Jingyang Li", "Li Wang", "Wei-Qiang Zhang"], "https://doi.org/10.21437/Interspeech.2019-1683", 5, "interspeech", 2019]], "Yong Ma": [0, ["Code-Switching Sentence Generation by Bert and Generative Adversarial Networks", ["Yingying Gao", "Junlan Feng", "Ying Liu", "Leijing Hou", "Xin Pan", "Yong Ma"], "https://doi.org/10.21437/Interspeech.2019-2501", 5, "interspeech", 2019]], "Jurgen Riedler": [0, ["The SAIL LABS Media Mining Indexer and the CAVA Framework", ["Erinc Dikici", "Gerhard Backfried", "Jurgen Riedler"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8029.html", 2, "interspeech", 2019]], "Zoe Liu": [0, ["A Comparison of Deep Learning Methods for Language Understanding", ["Mandy Korpusik", "Zoe Liu", "James R. Glass"], "https://doi.org/10.21437/Interspeech.2019-1262", 5, "interspeech", 2019]], "Preeti Kaur": [0, ["MobiVSR : Efficient and Light-Weight Neural Network for Visual Speech Recognition on Mobile Devices", ["Nilay Shrivastava", "Astitwa Saxena", "Yaman Kumar", "Rajiv Ratn Shah", "Amanda Stent", "Debanjan Mahata", "Preeti Kaur", "Roger Zimmermann"], "https://doi.org/10.21437/Interspeech.2019-3273", 5, "interspeech", 2019]], "Jacob Huber": [0, ["ReMASC: Realistic Replay Attack Corpus for Voice Controlled Systems", ["Yuan Gong", "Jian Yang", "Jacob Huber", "Mitchell MacKnight", "Christian Poellabauer"], "https://doi.org/10.21437/Interspeech.2019-1541", 5, "interspeech", 2019]], "Yi-Te Hsu": [0, ["IA-NET: Acceleration and Compression of Speech Enhancement Using Integer-Adder Deep Neural Network", ["Yu-Chen Lin", "Yi-Te Hsu", "Szu-Wei Fu", "Yu Tsao", "Tei-Wei Kuo"], "https://doi.org/10.21437/Interspeech.2019-1207", 5, "interspeech", 2019]], "James R. Williamson": [0, ["Vocal Biomarker Assessment Following Pediatric Traumatic Brain Injury: A Retrospective Cohort Study", ["Camille Noufi", "Adam C. Lammert", "Daryush D. Mehta", "James R. Williamson", "Gregory Ciccarelli", "Douglas E. Sturim", "Jordan R. Green", "Thomas F. Campbell", "Thomas F. Quatieri"], "https://doi.org/10.21437/Interspeech.2019-1200", 5, "interspeech", 2019]], "Jacob Sager": [0, ["VESUS: A Crowd-Annotated Database to Study Emotion Production and Perception in Spoken English", ["Jacob Sager", "Ravi Shankar", "Jacob Reinhold", "Archana Venkataraman"], "https://doi.org/10.21437/Interspeech.2019-1413", 5, "interspeech", 2019], ["A Multi-Speaker Emotion Morphing Model Using Highway Networks and Maximum Likelihood Objective", ["Ravi Shankar", "Jacob Sager", "Archana Venkataraman"], "https://doi.org/10.21437/Interspeech.2019-2512", 5, "interspeech", 2019]], "Ravichander Vipperla": [0, ["ShrinkML: End-to-End ASR Model Compression Using Reinforcement Learning", ["Lukasz Dudziak", "Mohamed S. Abdelfattah", "Ravichander Vipperla", "Stefanos Laskaridis", "Nicholas D. Lane"], "https://doi.org/10.21437/Interspeech.2019-2811", 5, "interspeech", 2019]], "Ryuichi Yamamoto": [0, ["Probability Density Distillation with Generative Adversarial Networks for High-Quality Parallel Waveform Generation", ["Ryuichi Yamamoto", "Eunwoo Song", "Jae-Min Kim"], "https://doi.org/10.21437/Interspeech.2019-1965", 5, "interspeech", 2019]], "Bjorn W. Schuller": [0, ["Attention-Enhanced Connectionist Temporal Classification for Discrete Speech Emotion Recognition", ["Ziping Zhao", "Zhongtian Bao", "Zixing Zhang", "Nicholas Cummins", "Haishuai Wang", "Bjorn W. Schuller"], "https://doi.org/10.21437/Interspeech.2019-1649", 5, "interspeech", 2019], ["A Hierarchical Attention Network-Based Approach for Depression Detection from Transcribed Clinical Interviews", ["Adria Mallol-Ragolta", "Ziping Zhao", "Lukas Stappen", "Nicholas Cummins", "Bjorn W. Schuller"], "https://doi.org/10.21437/Interspeech.2019-2036", 5, "interspeech", 2019], ["Using Speech to Predict Sequentially Measured Cortisol Levels During a Trier Social Stress Test", ["Alice Baird", "Shahin Amiriparian", "Nicholas Cummins", "Sarah Sturmbauer", "Johanna Janson", "Eva-Maria Messner", "Harald Baumeister", "Nicolas Rohleder", "Bjorn W. Schuller"], "https://doi.org/10.21437/Interspeech.2019-1352", 5, "interspeech", 2019], ["Sincerity in Acted Speech: Presenting the Sincere Apology Corpus and Results", ["Alice Baird", "Eduardo Coutinho", "Julia Hirschberg", "Bjorn W. Schuller"], "https://doi.org/10.21437/Interspeech.2019-1349", 5, "interspeech", 2019], ["Autonomous Emotion Learning in Speech: A View of Zero-Shot Speech Emotion Recognition", ["Xinzhou Xu", "Jun Deng", "Nicholas Cummins", "Zixing Zhang", "Li Zhao", "Bjorn W. Schuller"], "https://doi.org/10.21437/Interspeech.2019-2406", 5, "interspeech", 2019], ["Towards Robust Speech Emotion Recognition Using Deep Residual Networks for Speech Enhancement", ["Andreas Triantafyllopoulos", "Gil Keren", "Johannes Wagner", "Ingmar Steiner", "Bjorn W. Schuller"], "https://doi.org/10.21437/Interspeech.2019-1811", 5, "interspeech", 2019], ["Speech Augmentation via Speaker-Specific Noise in Unseen Environment", ["Yanan Guo", "Ziping Zhao", "Yide Ma", "Bjorn W. Schuller"], "https://doi.org/10.21437/Interspeech.2019-2712", 5, "interspeech", 2019], ["The INTERSPEECH 2019 Computational Paralinguistics Challenge: Styrian Dialects, Continuous Sleepiness, Baby Sounds & Orca Activity", ["Bjorn W. Schuller", "Anton Batliner", "Christian Bergler", "Florian B. Pokorny", "Jarek Krajewski", "Margaret Cychosz", "Ralf Vollmann", "Sonja-Dana Roelen", "Sebastian Schnieder", "Elika Bergelson", "Alejandrina Cristia", "Amanda Seidl", "Anne S. Warlaumont", "Lisa Yankowitz", "Elmar Noth", "Shahin Amiriparian", "Simone Hantke", "Maximilian Schmitt"], "https://doi.org/10.21437/Interspeech.2019-1122", 5, "interspeech", 2019], ["Continuous Emotion Recognition in Speech - Do We Need Recurrence?", ["Maximilian Schmitt", "Nicholas Cummins", "Bjorn W. Schuller"], "https://doi.org/10.21437/Interspeech.2019-2710", 5, "interspeech", 2019], ["Robust Speech Emotion Recognition Under Different Encoding Conditions", ["Christopher Oates", "Andreas Triantafyllopoulos", "Ingmar Steiner", "Bjorn W. Schuller"], "https://doi.org/10.21437/Interspeech.2019-1658", 5, "interspeech", 2019]], "Xinhao Wang": [5.575397210577648e-07, ["Automatic Detection of Off-Topic Spoken Responses Using Very Deep Convolutional Neural Networks", ["Xinhao Wang", "Su-Youn Yoon", "Keelan Evanini", "Klaus Zechner", "Yao Qian"], "https://doi.org/10.21437/Interspeech.2019-1848", 5, "interspeech", 2019]], "Jen-Tzung Chien": [0, ["Meta Learning for Hyperparameter Optimization in Dialogue System", ["Jen-Tzung Chien", "Wei Xiang Lieow"], "https://doi.org/10.21437/Interspeech.2019-1383", 5, "interspeech", 2019], ["Self Attention in Variational Sequential Learning for Summarization", ["Jen-Tzung Chien", "Chun-Wei Wang"], "https://doi.org/10.21437/Interspeech.2019-1548", 5, "interspeech", 2019], ["Variational Domain Adversarial Learning for Speaker Verification", ["Youzhi Tu", "Man-Wai Mak", "Jen-Tzung Chien"], "https://doi.org/10.21437/Interspeech.2019-2168", 5, "interspeech", 2019]], "Hisami Suzuki": [0, ["Speech-Based Web Navigation for Limited Mobility Users", ["Vasiliy Radostev", "Serge Berger", "Justin Tabrizi", "Pasha Kamyshev", "Hisami Suzuki"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8042.html", 2, "interspeech", 2019]], "Ben Coppin": [0, ["Large-Scale Visual Speech Recognition", ["Brendan Shillingford", "Yannis M. Assael", "Matthew W. Hoffman", "Thomas Paine", "Cian Hughes", "Utsav Prabhu", "Hank Liao", "Hasim Sak", "Kanishka Rao", "Lorrayne Bennett", "Marie Mulville", "Misha Denil", "Ben Coppin", "Ben Laurie", "Andrew W. Senior", "Nando de Freitas"], "https://doi.org/10.21437/Interspeech.2019-1669", 5, "interspeech", 2019]], "Charlotte Sorensen": [0, ["Harmonic Beamformers for Non-Intrusive Speech Intelligibility Prediction", ["Charlotte Sorensen", "Jesper Bunsow Boldt", "Mads Graesboll Christensen"], "https://doi.org/10.21437/Interspeech.2019-2929", 5, "interspeech", 2019], ["Validation of the Non-Intrusive Codebook-Based Short Time Objective Intelligibility Metric for Processed Speech", ["Charlotte Sorensen", "Jesper B. Boldt", "Mads G. Christensen"], "https://doi.org/10.21437/Interspeech.2019-1625", 5, "interspeech", 2019]], "Pavel Matejka": [0, ["Analysis of BUT Submission in Far-Field Scenarios of VOiCES 2019 Challenge", ["Pavel Matejka", "Oldrich Plchot", "Hossein Zeinali", "Ladislav Mosner", "Anna Silnova", "Lukas Burget", "Ondrej Novotny", "Ondrej Glembek"], "https://doi.org/10.21437/Interspeech.2019-2471", 5, "interspeech", 2019], ["Analysis of BUT Submission in Far-Field Scenarios of VOiCES 2019 Challenge", ["Pavel Matejka", "Oldrich Plchot", "Hossein Zeinali", "Ladislav Mosner", "Anna Silnova", "Lukas Burget", "Ondrej Novotny", "Ondrej Glembek"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/abs16.html", 0, "interspeech", 2019]], "Javier Hernando": [0, ["Auto-Encoding Nearest Neighbor i-Vectors for Speaker Verification", ["Umair Khan", "Miquel India", "Javier Hernando"], "https://doi.org/10.21437/Interspeech.2019-1444", 5, "interspeech", 2019], ["Self Multi-Head Attention for Speaker Recognition", ["Miquel India", "Pooyan Safari", "Javier Hernando"], "https://doi.org/10.21437/Interspeech.2019-2616", 5, "interspeech", 2019]], "Hao Tang": [0, ["An Unsupervised Autoregressive Model for Speech Representation Learning", ["Yu-An Chung", "Wei-Ning Hsu", "Hao Tang", "James R. Glass"], "https://doi.org/10.21437/Interspeech.2019-1473", 5, "interspeech", 2019], ["A Deep Residual Network for Large-Scale Acoustic Scene Analysis", ["Logan Ford", "Hao Tang", "Francois Grondin", "James R. Glass"], "https://doi.org/10.21437/Interspeech.2019-2731", 5, "interspeech", 2019], ["VoiceID Loss: Speech Enhancement for Speaker Verification", ["Suwon Shon", "Hao Tang", "James R. Glass"], "https://doi.org/10.21437/Interspeech.2019-1496", 5, "interspeech", 2019]], "Joan Serra": [0, ["Learning Problem-Agnostic Speech Representations from Multiple Self-Supervised Tasks", ["Santiago Pascual", "Mirco Ravanelli", "Joan Serra", "Antonio Bonafonte", "Yoshua Bengio"], "https://doi.org/10.21437/Interspeech.2019-2605", 5, "interspeech", 2019], ["Towards Generalized Speech Enhancement with Generative Adversarial Networks", ["Santiago Pascual", "Joan Serra", "Antonio Bonafonte"], "https://doi.org/10.21437/Interspeech.2019-2688", 5, "interspeech", 2019]], "Amir Harati": [0, ["Optimizing Speech-Input Length for Speaker-Independent Depression Classification", ["Tomasz Rutowski", "Amir Harati", "Yang Lu", "Elizabeth Shriberg"], "https://doi.org/10.21437/Interspeech.2019-3095", 5, "interspeech", 2019]], "Oliver Niebuhr": [0, ["God as Interlocutor - Real or Imaginary? Prosodic Markers of Dialogue Speech and Expected Efficacy in Spoken Prayer", ["Oliver Niebuhr", "Uffe Schjoedt"], "https://doi.org/10.21437/Interspeech.2019-1193", 5, "interspeech", 2019], ["PASCAL and DPA: A Pilot Study on Using Prosodic Competence Scores to Predict Communicative Skills for Team Working and Public Speaking", ["Oliver Niebuhr", "Jan Michalsky"], "https://doi.org/10.21437/Interspeech.2019-3034", 5, "interspeech", 2019], ["Do not Hesitate! - Unless You Do it Shortly or Nasally: How the Phonetics of Filled Pauses Determine Their Subjective Frequency and Perceived Speaker Performance", ["Oliver Niebuhr", "Kerstin Fischer"], "https://doi.org/10.21437/Interspeech.2019-1194", 5, "interspeech", 2019], ["A Preliminary Study of Charismatic Speech on YouTube: Correlating Prosodic Variation with Counts of Subscribers, Views and Likes", ["Stephanie Berger", "Oliver Niebuhr", "Margaret Zellers"], "https://doi.org/10.21437/Interspeech.2019-1664", 5, "interspeech", 2019]], "Anna Bjork Nikulasdottir": [0, ["The Althingi ASR System", ["Inga Run Helgadottir", "Anna Bjork Nikulasdottir", "Michal Borsky", "Judy Y. Fong", "Robert Kjaran", "Jon Gudnason"], "https://doi.org/10.21437/Interspeech.2019-1248", 5, "interspeech", 2019], ["Bootstrapping a Text Normalization System for an Inflected Language. Numbers as a Test Case", ["Anna Bjork Nikulasdottir", "Jon Gudnason"], "https://doi.org/10.21437/Interspeech.2019-2367", 5, "interspeech", 2019]], "Gianmarco Cerutti": [0, ["Neural Network Distillation on IoT Platforms for Sound Event Detection", ["Gianmarco Cerutti", "Rahul Prasad", "Alessio Brutti", "Elisabetta Farella"], "https://doi.org/10.21437/Interspeech.2019-2394", 5, "interspeech", 2019]], "Saturnino Luz": [0, ["A System for Real-Time Privacy Preserving Data Collection for Ambient Assisted Living", ["Fasih Haider", "Saturnino Luz"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8037.html", 2, "interspeech", 2019]], "Dharmeshkumar Agrawal": [0, ["CaptionAI: A Real-Time Multilingual Captioning Application", ["Nagendra Kumar Goel", "Mousmita Sarma", "Saikiran Valluri", "Dharmeshkumar Agrawal", "Steve Braich", "Tejendra Singh Kuswah", "Zikra Iqbal", "Surbhi Chauhan", "Raj Karbar"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8039.html", 2, "interspeech", 2019]], "Robert T. Schultz": [0, ["Automatic Detection of Autism Spectrum Disorder in Children Using Acoustic and Text Features from Brief Natural Conversations", ["Sunghye Cho", "Mark Liberman", "Neville Ryant", "Meredith Cola", "Robert T. Schultz", "Julia Parish-Morris"], "https://doi.org/10.21437/Interspeech.2019-1452", 5, "interspeech", 2019]], "Yiming Wang": [5.499646135831426e-06, ["The JHU ASR System for VOiCES from a Distance Challenge 2019", ["Yiming Wang", "David Snyder", "Hainan Xu", "Vimal Manohar", "Phani Sankar Nidadavolu", "Daniel Povey", "Sanjeev Khudanpur"], "https://doi.org/10.21437/Interspeech.2019-1948", 5, "interspeech", 2019]], "Malvina Nikandrou": [0, ["Data Augmentation Using GANs for Speech Emotion Recognition", ["Aggelina Chatziagapi", "Georgios Paraskevopoulos", "Dimitris Sgouropoulos", "Georgios Pantazopoulos", "Malvina Nikandrou", "Theodoros Giannakopoulos", "Athanasios Katsamanis", "Alexandros Potamianos", "Shrikanth Narayanan"], "https://doi.org/10.21437/Interspeech.2019-2561", 5, "interspeech", 2019]], "Gakuto Kurata": [0, ["Guiding CTC Posterior Spike Timings for Improved Posterior Fusion and Knowledge Distillation", ["Gakuto Kurata", "Kartik Audhkhasi"], "https://doi.org/10.21437/Interspeech.2019-1952", 5, "interspeech", 2019], ["Direct Neuron-Wise Fusion of Cognate Neural Networks", ["Takashi Fukuda", "Masayuki Suzuki", "Gakuto Kurata"], "https://doi.org/10.21437/Interspeech.2019-1930", 5, "interspeech", 2019], ["Multi-Task CTC Training with Auxiliary Feature Reconstruction for End-to-End Speech Recognition", ["Gakuto Kurata", "Kartik Audhkhasi"], "https://doi.org/10.21437/Interspeech.2019-1710", 5, "interspeech", 2019]], "Meredith Moore": [0, ["Say What? A Dataset for Exploring the Error Patterns That Two ASR Engines Make", ["Meredith Moore", "Michael Saxon", "Hemanth Venkateswara", "Visar Berisha", "Sethuraman Panchanathan"], "https://doi.org/10.21437/Interspeech.2019-3096", 5, "interspeech", 2019]], "Antonio M. Peinado": [0, ["Multi-Channel Block-Online Source Extraction Based on Utterance Adaptation", ["Juan M. Martin-Donas", "Jens Heitkaemper", "Reinhold Haeb-Umbach", "Angel M. Gomez", "Antonio M. Peinado"], "https://doi.org/10.21437/Interspeech.2019-2244", 5, "interspeech", 2019], ["A Light Convolutional GRU-RNN Deep Feature Extractor for ASV Spoofing Detection", ["Alejandro Gomez Alanis", "Antonio M. Peinado", "Jose A. Gonzalez", "Angel M. Gomez"], "https://doi.org/10.21437/Interspeech.2019-2212", 5, "interspeech", 2019]], "Stefan L. Frank": [0, ["Language Learning Using Speech to Image Retrieval", ["Danny Merkx", "Stefan L. Frank", "Mirjam Ernestus"], "https://doi.org/10.21437/Interspeech.2019-3067", 5, "interspeech", 2019]], "Kuang-Ching Wang": [7.571926232685655e-07, ["Speech Enhancement Using Forked Generative Adversarial Networks with Spectral Subtraction", ["Ju Lin", "Sufeng Niu", "Zice Wei", "Xiang Lan", "Adriaan J. van Wijngaarden", "Melissa C. Smith", "Kuang-Ching Wang"], "https://doi.org/10.21437/Interspeech.2019-2954", 5, "interspeech", 2019]], "Katerina Papadimitriou": [0, ["End-to-End Convolutional Sequence Learning for ASL Fingerspelling Recognition", ["Katerina Papadimitriou", "Gerasimos Potamianos"], "https://doi.org/10.21437/Interspeech.2019-2422", 5, "interspeech", 2019]], "Misha Denil": [0, ["Large-Scale Visual Speech Recognition", ["Brendan Shillingford", "Yannis M. Assael", "Matthew W. Hoffman", "Thomas Paine", "Cian Hughes", "Utsav Prabhu", "Hank Liao", "Hasim Sak", "Kanishka Rao", "Lorrayne Bennett", "Marie Mulville", "Misha Denil", "Ben Coppin", "Ben Laurie", "Andrew W. Senior", "Nando de Freitas"], "https://doi.org/10.21437/Interspeech.2019-1669", 5, "interspeech", 2019]], "Robert Muller": [0, ["Deep Neural Baselines for Computational Paralinguistics", ["Daniel Elsner", "Stefan Langer", "Fabian Ritz", "Robert Muller", "Steffen Illium"], "https://doi.org/10.21437/Interspeech.2019-2478", 5, "interspeech", 2019]], "Harsha Vardhan": [0, ["LEAP Diarization System for the Second DIHARD Challenge", ["Prachi Singh", "Harsha Vardhan", "Sriram Ganapathy", "A. Kanagasundaram"], "https://doi.org/10.21437/Interspeech.2019-2716", 5, "interspeech", 2019]], "Xin Wang": [0.0001022029246087186, ["ASVspoof 2019: Future Horizons in Spoofed and Fake Audio Detection", ["Massimiliano Todisco", "Xin Wang", "Ville Vestman", "Md. Sahidullah", "Hector Delgado", "Andreas Nautsch", "Junichi Yamagishi", "Nicholas W. D. Evans", "Tomi H. Kinnunen", "Kong Aik Lee"], "https://doi.org/10.21437/Interspeech.2019-2249", 5, "interspeech", 2019], ["Joint Training Framework for Text-to-Speech and Voice Conversion Using Multi-Source Tacotron and WaveNet", ["Mingyang Zhang", "Xin Wang", "Fuming Fang", "Haizhou Li", "Junichi Yamagishi"], "https://doi.org/10.21437/Interspeech.2019-1357", 5, "interspeech", 2019], ["Training Multi-Speaker Neural Text-to-Speech Systems Using Speaker-Imbalanced Speech Corpora", ["Hieu-Thi Luong", "Xin Wang", "Junichi Yamagishi", "Nobuyuki Nishizawa"], "https://doi.org/10.21437/Interspeech.2019-1311", 5, "interspeech", 2019], ["MOSNet: Deep Learning-Based Objective Assessment for Voice Conversion", ["Chen-Chou Lo", "Szu-Wei Fu", "Wen-Chin Huang", "Xin Wang", "Junichi Yamagishi", "Yu Tsao", "Hsin-Min Wang"], "https://doi.org/10.21437/Interspeech.2019-2003", 5, "interspeech", 2019]], "Wei Rao": [0, ["Target Speaker Extraction for Multi-Talker Speaker Verification", ["Wei Rao", "Chenglin Xu", "Eng Siong Chng", "Haizhou Li"], "https://doi.org/10.21437/Interspeech.2019-1410", 5, "interspeech", 2019], ["I4U Submission to NIST SRE 2018: Leveraging from a Decade of Shared Experiences", ["Kong Aik Lee", "Ville Hautamaki", "Tomi H. Kinnunen", "Hitoshi Yamamoto", "Koji Okabe", "Ville Vestman", "Jing Huang", "Guohong Ding", "Hanwu Sun", "Anthony Larcher", "Rohan Kumar Das", "Haizhou Li", "Mickael Rouvier", "Pierre-Michel Bousquet", "Wei Rao", "Qing Wang", "Chunlei Zhang", "Fahimeh Bahmaninezhad", "Hector Delgado", "Massimiliano Todisco"], "https://doi.org/10.21437/Interspeech.2019-1533", 5, "interspeech", 2019]], "Pawel Korus": [0, ["Adversarial Optimization for Dictionary Attacks on Speaker Verification", ["Mirko Marras", "Pawel Korus", "Nasir D. Memon", "Gianni Fenu"], "https://doi.org/10.21437/Interspeech.2019-2430", 5, "interspeech", 2019]], "Yi-Chiao Wu": [6.146273167338418e-14, ["Quasi-Periodic WaveNet Vocoder: A Pitch Dependent Dilated Convolution Model for Parametric Speech Generation", ["Yi-Chiao Wu", "Tomoki Hayashi", "Patrick Lumban Tobing", "Kazuhiro Kobayashi", "Tomoki Toda"], "https://doi.org/10.21437/Interspeech.2019-1232", 5, "interspeech", 2019], ["Non-Parallel Voice Conversion with Cyclic Variational Autoencoder", ["Patrick Lumban Tobing", "Yi-Chiao Wu", "Tomoki Hayashi", "Kazuhiro Kobayashi", "Tomoki Toda"], "https://doi.org/10.21437/Interspeech.2019-2307", 5, "interspeech", 2019], ["Investigation of F0 Conditioning and Fully Convolutional Networks in Variational Autoencoder Based Voice Conversion", ["Wen-Chin Huang", "Yi-Chiao Wu", "Chen-Chou Lo", "Patrick Lumban Tobing", "Tomoki Hayashi", "Kazuhiro Kobayashi", "Tomoki Toda", "Yu Tsao", "Hsin-Min Wang"], "https://doi.org/10.21437/Interspeech.2019-1774", 5, "interspeech", 2019]], "Nusrah Hussain": [0, ["Speech Driven Backchannel Generation Using Deep Q-Network for Enhancing Engagement in Human-Robot Interaction", ["Nusrah Hussain", "Engin Erzin", "T. Metin Sezgin", "Yucel Yemez"], "https://doi.org/10.21437/Interspeech.2019-2521", 5, "interspeech", 2019]], "Gao-Yi Chao": [0, ["Enforcing Semantic Consistency for Cross Corpus Valence Regression from Speech Using Adversarial Discrepancy Learning", ["Gao-Yi Chao", "Yun-Shao Lin", "Chun-Min Chang", "Chi-Chun Lee"], "https://doi.org/10.21437/Interspeech.2019-2037", 5, "interspeech", 2019], ["Using Attention Networks and Adversarial Augmentation for Styrian Dialect Continuous Sleepiness and Baby Sound Recognition", ["Sung-Lin Yeh", "Gao-Yi Chao", "Bo-Hao Su", "Yu-Lin Huang", "Meng-Han Lin", "Yin-Chun Tsai", "Yu-Wen Tai", "Zheng-Chi Lu", "Chieh-Yu Chen", "Tsung-Ming Tai", "Chiu-Wang Tseng", "Cheng-Kuang Lee", "Chi-Chun Lee"], "https://doi.org/10.21437/Interspeech.2019-2110", 5, "interspeech", 2019]], "Qingjian Lin": [0, ["LSTM Based Similarity Measurement with Spectral Clustering for Speaker Diarization", ["Qingjian Lin", "Ruiqing Yin", "Ming Li", "Herve Bredin", "Claude Barras"], "https://doi.org/10.21437/Interspeech.2019-1388", 5, "interspeech", 2019]], "Roger K. Moore": [0, ["Learning Temporal Clusters Using Capsule Routing for Speech Emotion Recognition", ["Md Asif Jalal", "Erfan Loweimi", "Roger K. Moore", "Thomas Hain"], "https://doi.org/10.21437/Interspeech.2019-3068", 5, "interspeech", 2019], ["Using Alexa for Flashcard-Based Learning", ["Lucy Skidmore", "Roger K. Moore"], "https://doi.org/10.21437/Interspeech.2019-2893", 5, "interspeech", 2019], ["On the Use/Misuse of the Term 'Phoneme'", ["Roger K. Moore", "Lucy Skidmore"], "https://doi.org/10.21437/Interspeech.2019-2711", 5, "interspeech", 2019]], "Cristina Luna Jimenez": [0, ["Predicting Group-Level Skin Attention to Short Movies from Audio-Based LSTM-Mixture of Experts Models", ["Ricardo Kleinlein", "Cristina Luna Jimenez", "Juan Manuel Montero", "Zoraida Callejas", "Fernando Fernandez-Martinez"], "https://doi.org/10.21437/Interspeech.2019-2799", 5, "interspeech", 2019]], "Alessio Brutti": [0, ["Neural Network Distillation on IoT Platforms for Sound Event Detection", ["Gianmarco Cerutti", "Rahul Prasad", "Alessio Brutti", "Elisabetta Farella"], "https://doi.org/10.21437/Interspeech.2019-2394", 5, "interspeech", 2019]], "Torbjorn Svendsen": [0, ["A Phonetic-Level Analysis of Different Input Features for Articulatory Inversion", ["Abdolreza Sabzi Shahrebabaki", "Negar Olfati", "Ali Shariq Imran", "Sabato Marco Siniscalchi", "Torbjorn Svendsen"], "https://doi.org/10.21437/Interspeech.2019-2526", 5, "interspeech", 2019]], "Meng Li": [0, ["A Convolutional Neural Network with Non-Local Module for Speech Enhancement", ["Xiaoqi Li", "Yaxing Li", "Meng Li", "Shan Xu", "Yuanjie Dong", "Xinrong Sun", "Shengwu Xiong"], "https://doi.org/10.21437/Interspeech.2019-2472", 5, "interspeech", 2019]], "Alejandrina Cristia": [0, ["The Second DIHARD Diarization Challenge: Dataset, Task, and Baselines", ["Neville Ryant", "Kenneth Church", "Christopher Cieri", "Alejandrina Cristia", "Jun Du", "Sriram Ganapathy", "Mark Liberman"], "https://doi.org/10.21437/Interspeech.2019-1268", 5, "interspeech", 2019], ["The INTERSPEECH 2019 Computational Paralinguistics Challenge: Styrian Dialects, Continuous Sleepiness, Baby Sounds & Orca Activity", ["Bjorn W. Schuller", "Anton Batliner", "Christian Bergler", "Florian B. Pokorny", "Jarek Krajewski", "Margaret Cychosz", "Ralf Vollmann", "Sonja-Dana Roelen", "Sebastian Schnieder", "Elika Bergelson", "Alejandrina Cristia", "Amanda Seidl", "Anne S. Warlaumont", "Lisa Yankowitz", "Elmar Noth", "Shahin Amiriparian", "Simone Hantke", "Maximilian Schmitt"], "https://doi.org/10.21437/Interspeech.2019-1122", 5, "interspeech", 2019], ["Towards Detection of Canonical Babbling by Citizen Scientists: Performance as a Function of Clip Length", ["Amanda Seidl", "Anne S. Warlaumont", "Alejandrina Cristia"], "https://doi.org/10.21437/Interspeech.2019-1773", 5, "interspeech", 2019]], "Erik Marchi": [0, ["Leveraging Acoustic Cues and Paralinguistic Embeddings to Detect Expression from Voice", ["Vikramjit Mitra", "Sue Booker", "Erik Marchi", "David Scott Farrar", "Ute Dorothea Peitz", "Bridget Cheng", "Ermine Teves", "Anuj Mehta", "Devang Naik"], "https://doi.org/10.21437/Interspeech.2019-2998", 5, "interspeech", 2019]], "Yuanchao Li": [0, ["Improved End-to-End Speech Emotion Recognition Using Self Attention Mechanism and Multitask Learning", ["Yuanchao Li", "Tianyu Zhao", "Tatsuya Kawahara"], "https://doi.org/10.21437/Interspeech.2019-2594", 5, "interspeech", 2019]], "Michael Zeng": [0, ["Meeting Transcription Using Asynchronous Distant Microphones", ["Takuya Yoshioka", "Dimitrios Dimitriadis", "Andreas Stolcke", "William Hinthorn", "Zhuo Chen", "Michael Zeng", "Xuedong Huang"], "https://doi.org/10.21437/Interspeech.2019-3088", 5, "interspeech", 2019]], "Qian Qian": [0, ["Acoustic Characteristics of Lexical Tone Disruption in Mandarin Speakers After Brain Damage", ["Wenjun Chen", "Jeroen van de Weijer", "Shuangshuang Zhu", "Qian Qian", "Manna Wang"], "https://doi.org/10.21437/Interspeech.2019-2432", 5, "interspeech", 2019]], "Yao Qian": [0, ["Automated Estimation of Oral Reading Fluency During Summer Camp e-Book Reading with MyTurnToRead", ["Anastassia Loukina", "Beata Beigman Klebanov", "Patrick L. Lange", "Yao Qian", "Binod Gyawali", "Nitin Madnani", "Abhinav Misra", "Klaus Zechner", "Zuowei Wang", "John Sabatini"], "https://doi.org/10.21437/Interspeech.2019-2889", 5, "interspeech", 2019], ["Automatic Detection of Off-Topic Spoken Responses Using Very Deep Convolutional Neural Networks", ["Xinhao Wang", "Su-Youn Yoon", "Keelan Evanini", "Klaus Zechner", "Yao Qian"], "https://doi.org/10.21437/Interspeech.2019-1848", 5, "interspeech", 2019]], "Tianqi Wang": [4.794821872877719e-09, ["Towards the Speech Features of Mild Cognitive Impairment: Universal Evidence from Structured and Unstructured Connected Speech of Chinese", ["Tianqi Wang", "Chongyuan Lian", "Jingshen Pan", "Quanlei Yan", "Feiqi Zhu", "Manwa L. Ng", "Lan Wang", "Nan Yan"], "https://doi.org/10.21437/Interspeech.2019-2414", 5, "interspeech", 2019], ["Towards the Speech Features of Early-Stage Dementia: Design and Application of the Mandarin Elderly Cognitive Speech Database", ["Tianqi Wang", "Quanlei Yan", "Jingshen Pan", "Feiqi Zhu", "Rongfeng Su", "Yi Guo", "Lan Wang", "Nan Yan"], "https://doi.org/10.21437/Interspeech.2019-2453", 5, "interspeech", 2019]], "Roger Zimmermann": [0, ["MobiVSR : Efficient and Light-Weight Neural Network for Visual Speech Recognition on Mobile Devices", ["Nilay Shrivastava", "Astitwa Saxena", "Yaman Kumar", "Rajiv Ratn Shah", "Amanda Stent", "Debanjan Mahata", "Preeti Kaur", "Roger Zimmermann"], "https://doi.org/10.21437/Interspeech.2019-3273", 5, "interspeech", 2019]], "Shan Liu": [0, ["Pre-Trained Text Representations for Improving Front-End Text Processing in Mandarin Text-to-Speech Synthesis", ["Bing Yang", "Jiaqi Zhong", "Shan Liu"], "https://doi.org/10.21437/Interspeech.2019-1418", 5, "interspeech", 2019]], "Omry Tuval": [0, ["Personalizing ASR for Dysarthric and Accented Speech with Limited Data", ["Joel Shor", "Dotan Emanuel", "Oran Lang", "Omry Tuval", "Michael Brenner", "Julie Cattiau", "Fernando Vieira", "Maeve McNally", "Taylor Charbonneau", "Melissa Nollstadt", "Avinatan Hassidim", "Yossi Matias"], "https://doi.org/10.21437/Interspeech.2019-1427", 5, "interspeech", 2019]], "Andrew Vaughan": [0, ["Pindrop Labs' Submission to the First Multi-Target Speaker Detection and Identification Challenge", ["Elie Khoury", "Khaled Lakhdhar", "Andrew Vaughan", "Ganesh Sivaraman", "Parav Nagarsheth"], "https://doi.org/10.21437/Interspeech.2019-3179", 4, "interspeech", 2019]], "Carmel Rabinovitz": [0, ["High Quality, Lightweight and Adaptable TTS Using LPCNet", ["Zvi Kons", "Slava Shechtman", "Alexander Sorin", "Carmel Rabinovitz", "Ron Hoory"], "https://doi.org/10.21437/Interspeech.2019-1705", 5, "interspeech", 2019]], "Pablo Arantes": [0, ["Quantifying Fundamental Frequency Modulation as a Function of Language, Speaking Style and Speaker", ["Pablo Arantes", "Anders Eriksson"], "https://doi.org/10.21437/Interspeech.2019-2857", 5, "interspeech", 2019]], "Simon B. Goldberg": [0, ["Identifying Therapist and Client Personae for Therapeutic Alliance Estimation", ["Victor R. Martinez", "Nikolaos Flemotomos", "Victor Ardulov", "Krishna Somandepalli", "Simon B. Goldberg", "Zac E. Imel", "David C. Atkins", "Shrikanth Narayanan"], "https://doi.org/10.21437/Interspeech.2019-2829", 5, "interspeech", 2019]], "Antoine Bruguier": [0, ["Phoneme-Based Contextualization for Cross-Lingual Speech Recognition in End-to-End Models", ["Ke Hu", "Antoine Bruguier", "Tara N. Sainath", "Rohit Prabhavalkar", "Golan Pundak"], "https://doi.org/10.21437/Interspeech.2019-1868", 5, "interspeech", 2019], ["Better Morphology Prediction for Better Speech Systems", ["Dravyansh Sharma", "Melissa Wilson", "Antoine Bruguier"], "https://doi.org/10.21437/Interspeech.2019-3207", 5, "interspeech", 2019], ["On the Choice of Modeling Unit for Sequence-to-Sequence Speech Recognition", ["Kazuki Irie", "Rohit Prabhavalkar", "Anjuli Kannan", "Antoine Bruguier", "David Rybach", "Patrick Nguyen"], "https://doi.org/10.21437/Interspeech.2019-2277", 5, "interspeech", 2019]], "Miao Cao": [0, ["Pyramid Memory Block and Timestep Attention for Speech Emotion Recognition", ["Miao Cao", "Chun Yang", "Fang Zhou", "Xu-Cheng Yin"], "https://doi.org/10.21437/Interspeech.2019-3140", 5, "interspeech", 2019]], "Heather T. Schatten": [0, ["Emotion Recognition from Natural Phone Conversations in Individuals with and without Recent Suicidal Ideation", ["John Gideon", "Heather T. Schatten", "Melvin G. McInnis", "Emily Mower Provost"], "https://doi.org/10.21437/Interspeech.2019-1830", 5, "interspeech", 2019]], "Xiang Lan": [0, ["Speech Enhancement Using Forked Generative Adversarial Networks with Spectral Subtraction", ["Ju Lin", "Sufeng Niu", "Zice Wei", "Xiang Lan", "Adriaan J. van Wijngaarden", "Melissa C. Smith", "Kuang-Ching Wang"], "https://doi.org/10.21437/Interspeech.2019-2954", 5, "interspeech", 2019]], "Alp Oktem": [0, ["Prosodic Phrase Alignment for Machine Dubbing", ["Alp Oktem", "Mireia Farrus", "Antonio Bonafonte"], "https://doi.org/10.21437/Interspeech.2019-1621", 5, "interspeech", 2019]], "J. Hui": [0, ["Effects of Base-Frequency and Spectral Envelope on Deep-Learning Speech Separation and Recognition Models", ["J. Hui", "Y. Wei", "S. T. Chen", "R. H. Y. So"], "https://doi.org/10.21437/Interspeech.2019-1715", 5, "interspeech", 2019]], "Tatiana Kachkovskaia": [0, ["Prosodic Factors Influencing Vowel Reduction in Russian", ["Daniil Kocharov", "Tatiana Kachkovskaia", "Pavel A. Skrelin"], "https://doi.org/10.21437/Interspeech.2019-2918", 5, "interspeech", 2019]], "Dieter Maurer": [0, ["Formant Pattern and Spectral Shape Ambiguity of Vowel Sounds, and Related Phenomena of Vowel Acoustics - Exemplary Evidence", ["Dieter Maurer", "Heidy Suter", "Christian dHereuse", "Volker Dellwo"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8017.html", 2, "interspeech", 2019]], "Grandee Lee": [3.118355152764707e-06, ["Linguistically Motivated Parallel Data Augmentation for Code-Switch Language Modeling", ["Grandee Lee", "Xianghu Yue", "Haizhou Li"], "https://doi.org/10.21437/Interspeech.2019-1382", 5, "interspeech", 2019]], "Zhifu Gao": [0, ["Improving Aggregation and Loss Function for Better Embedding Learning in End-to-End Speaker Verification System", ["Zhifu Gao", "Yan Song", "Ian McLoughlin", "Pengcheng Li", "Yiheng Jiang", "Li-Rong Dai"], "https://doi.org/10.21437/Interspeech.2019-1489", 5, "interspeech", 2019], ["An Effective Deep Embedding Learning Architecture for Speaker Verification", ["Yiheng Jiang", "Yan Song", "Ian McLoughlin", "Zhifu Gao", "Li-Rong Dai"], "https://doi.org/10.21437/Interspeech.2019-1606", 5, "interspeech", 2019]], "Rachael Xi Cheng": [0, ["Deep Learning for Orca Call Type Identification - A Fully Unsupervised Approach", ["Christian Bergler", "Manuel Schmitt", "Rachael Xi Cheng", "Andreas K. Maier", "Volker Barth", "Elmar Noth"], "https://doi.org/10.21437/Interspeech.2019-1857", 5, "interspeech", 2019]], "Behnam Hedayatnia": [0, ["Topical-Chat: Towards Knowledge-Grounded Open-Domain Conversations", ["Karthik Gopalakrishnan", "Behnam Hedayatnia", "Qinglang Chen", "Anna Gottardi", "Sanjeev Kwatra", "Anu Venkatesh", "Raefer Gabriel", "Dilek Hakkani-Tur"], "https://doi.org/10.21437/Interspeech.2019-3079", 5, "interspeech", 2019]], "Lisa Yankowitz": [0, ["The INTERSPEECH 2019 Computational Paralinguistics Challenge: Styrian Dialects, Continuous Sleepiness, Baby Sounds & Orca Activity", ["Bjorn W. Schuller", "Anton Batliner", "Christian Bergler", "Florian B. Pokorny", "Jarek Krajewski", "Margaret Cychosz", "Ralf Vollmann", "Sonja-Dana Roelen", "Sebastian Schnieder", "Elika Bergelson", "Alejandrina Cristia", "Amanda Seidl", "Anne S. Warlaumont", "Lisa Yankowitz", "Elmar Noth", "Shahin Amiriparian", "Simone Hantke", "Maximilian Schmitt"], "https://doi.org/10.21437/Interspeech.2019-1122", 5, "interspeech", 2019]], "Anna Gottardi": [0, ["Topical-Chat: Towards Knowledge-Grounded Open-Domain Conversations", ["Karthik Gopalakrishnan", "Behnam Hedayatnia", "Qinglang Chen", "Anna Gottardi", "Sanjeev Kwatra", "Anu Venkatesh", "Raefer Gabriel", "Dilek Hakkani-Tur"], "https://doi.org/10.21437/Interspeech.2019-3079", 5, "interspeech", 2019]], "Kazuhiro Kobayashi": [0, ["Quasi-Periodic WaveNet Vocoder: A Pitch Dependent Dilated Convolution Model for Parametric Speech Generation", ["Yi-Chiao Wu", "Tomoki Hayashi", "Patrick Lumban Tobing", "Kazuhiro Kobayashi", "Tomoki Toda"], "https://doi.org/10.21437/Interspeech.2019-1232", 5, "interspeech", 2019], ["Non-Parallel Voice Conversion with Cyclic Variational Autoencoder", ["Patrick Lumban Tobing", "Yi-Chiao Wu", "Tomoki Hayashi", "Kazuhiro Kobayashi", "Tomoki Toda"], "https://doi.org/10.21437/Interspeech.2019-2307", 5, "interspeech", 2019], ["Robustness of Statistical Voice Conversion Based on Direct Waveform Modification Against Background Sounds", ["Yusuke Kurita", "Kazuhiro Kobayashi", "Kazuya Takeda", "Tomoki Toda"], "https://doi.org/10.21437/Interspeech.2019-2206", 5, "interspeech", 2019], ["Investigation of F0 Conditioning and Fully Convolutional Networks in Variational Autoencoder Based Voice Conversion", ["Wen-Chin Huang", "Yi-Chiao Wu", "Chen-Chou Lo", "Patrick Lumban Tobing", "Tomoki Hayashi", "Kazuhiro Kobayashi", "Tomoki Toda", "Yu Tsao", "Hsin-Min Wang"], "https://doi.org/10.21437/Interspeech.2019-1774", 5, "interspeech", 2019]], "Oran Lang": [0, ["Personalizing ASR for Dysarthric and Accented Speech with Limited Data", ["Joel Shor", "Dotan Emanuel", "Oran Lang", "Omry Tuval", "Michael Brenner", "Julie Cattiau", "Fernando Vieira", "Maeve McNally", "Taylor Charbonneau", "Melissa Nollstadt", "Avinatan Hassidim", "Yossi Matias"], "https://doi.org/10.21437/Interspeech.2019-1427", 5, "interspeech", 2019]], "Georgia Clarke": [0, ["Analysis of Deep Learning Architectures for Cross-Corpus Speech Emotion Recognition", ["Jack Parry", "Dimitri Palaz", "Georgia Clarke", "Pauline Lecomte", "Rebecca Mead", "Michael Berger", "Gregor Hofer"], "https://doi.org/10.21437/Interspeech.2019-2753", 5, "interspeech", 2019]], "Rachid Ridouane": [0, ["A Perceptual Study of CV Syllables in Both Spoken and Whistled Speech: A Tashlhiyt Berber Perspective", ["Julien Meyer", "Laure Dentel", "Silvain Gerber", "Rachid Ridouane"], "https://doi.org/10.21437/Interspeech.2019-2251", 5, "interspeech", 2019]], "Yan Song": [0.0022822055616416037, ["Improving Aggregation and Loss Function for Better Embedding Learning in End-to-End Speaker Verification System", ["Zhifu Gao", "Yan Song", "Ian McLoughlin", "Pengcheng Li", "Yiheng Jiang", "Li-Rong Dai"], "https://doi.org/10.21437/Interspeech.2019-1489", 5, "interspeech", 2019], ["An Effective Deep Embedding Learning Architecture for Speaker Verification", ["Yiheng Jiang", "Yan Song", "Ian McLoughlin", "Zhifu Gao", "Li-Rong Dai"], "https://doi.org/10.21437/Interspeech.2019-1606", 5, "interspeech", 2019]], "Omri Allouche": [0, ["GECKO - A Tool for Effective Annotation of Human Conversations", ["Golan Levy", "Raquel Sitman", "Ido Amir", "Eduard Golshtein", "Ran Mochary", "Eilon Reshef", "Roi Reichart", "Omri Allouche"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8025.html", 2, "interspeech", 2019]], "Wen-Chin Huang": [0, ["Investigation of F0 Conditioning and Fully Convolutional Networks in Variational Autoencoder Based Voice Conversion", ["Wen-Chin Huang", "Yi-Chiao Wu", "Chen-Chou Lo", "Patrick Lumban Tobing", "Tomoki Hayashi", "Kazuhiro Kobayashi", "Tomoki Toda", "Yu Tsao", "Hsin-Min Wang"], "https://doi.org/10.21437/Interspeech.2019-1774", 5, "interspeech", 2019], ["MOSNet: Deep Learning-Based Objective Assessment for Voice Conversion", ["Chen-Chou Lo", "Szu-Wei Fu", "Wen-Chin Huang", "Xin Wang", "Junichi Yamagishi", "Yu Tsao", "Hsin-Min Wang"], "https://doi.org/10.21437/Interspeech.2019-2003", 5, "interspeech", 2019]], "Karthik Gopalakrishnan": [0, ["Topical-Chat: Towards Knowledge-Grounded Open-Domain Conversations", ["Karthik Gopalakrishnan", "Behnam Hedayatnia", "Qinglang Chen", "Anna Gottardi", "Sanjeev Kwatra", "Anu Venkatesh", "Raefer Gabriel", "Dilek Hakkani-Tur"], "https://doi.org/10.21437/Interspeech.2019-3079", 5, "interspeech", 2019]], "Atreyee Saha": [0, ["Low Resource Automatic Intonation Classification Using Gated Recurrent Unit (GRU) Networks Pre-Trained with Synthesized Pitch Patterns", ["Atreyee Saha", "Chiranjeevi Yarra", "Prasanta Kumar Ghosh"], "https://doi.org/10.21437/Interspeech.2019-2351", 5, "interspeech", 2019]], "Junghyun Koo": [0.997415691614151, ["Adversarially Trained End-to-End Korean Singing Voice Synthesis System", ["Juheon Lee", "Hyeong-Seok Choi", "Chang-Bin Jeon", "Junghyun Koo", "Kyogu Lee"], "https://doi.org/10.21437/Interspeech.2019-1722", 5, "interspeech", 2019]], "Junlan Feng": [0, ["Code-Switching Sentence Generation by Bert and Generative Adversarial Networks", ["Yingying Gao", "Junlan Feng", "Ying Liu", "Leijing Hou", "Xin Pan", "Yong Ma"], "https://doi.org/10.21437/Interspeech.2019-2501", 5, "interspeech", 2019]], "Zhenyu Tang": [0, ["Regression and Classification for Direction-of-Arrival Estimation with Convolutional Recurrent Neural Networks", ["Zhenyu Tang", "John D. Kanu", "Kevin Hogan", "Dinesh Manocha"], "https://doi.org/10.21437/Interspeech.2019-1111", 5, "interspeech", 2019]], "Eleanor Chodroff": [0, ["Testing the Distinctiveness of Intonational Tunes: Evidence from Imitative Productions in American English", ["Eleanor Chodroff", "Jennifer S. Cole"], "https://doi.org/10.21437/Interspeech.2019-2684", 5, "interspeech", 2019]], "Charlie Cullen": [0, ["An Investigation of Therapeutic Rapport Through Prosody in Brief Psychodynamic Psychotherapy", ["Carolina De Pasquale", "Charlie Cullen", "Brian Vaughan"], "https://doi.org/10.21437/Interspeech.2019-2551", 5, "interspeech", 2019]], "Daniel Willett": [0, ["Deep Learning Based Mandarin Accent Identification for Accent Robust ASR", ["Felix Weninger", "Yang Sun", "Junho Park", "Daniel Willett", "Puming Zhan"], "https://doi.org/10.21437/Interspeech.2019-2737", 5, "interspeech", 2019]], "Manuel Pariente": [0, ["A Statistically Principled and Computationally Efficient Approach to Speech Enhancement Using Variational Autoencoders", ["Manuel Pariente", "Antoine Deleforge", "Emmanuel Vincent"], "https://doi.org/10.21437/Interspeech.2019-1398", 5, "interspeech", 2019]], "Valerie Hazan": [0, ["Subjective Evaluation of Communicative Effort for Younger and Older Adults in Interactive Tasks with Energetic and Informational Masking", ["Valerie Hazan", "Outi Tuomainen", "Linda Taschenberger"], "https://doi.org/10.21437/Interspeech.2019-2215", 5, "interspeech", 2019], ["Talker Intelligibility and Listening Effort with Temporally Modified Speech", ["Maximillian Paulus", "Valerie Hazan", "Patti Adank"], "https://doi.org/10.21437/Interspeech.2019-1402", 5, "interspeech", 2019]], "Pravin Bhaskar Ramteke": [0, ["NITK Kids' Speech Corpus", ["Pravin Bhaskar Ramteke", "Sujata Supanekar", "Pradyoth Hegde", "Hanna Nelson", "Venkataraja Aithal", "Shashidhar G. Koolagudi"], "https://doi.org/10.21437/Interspeech.2019-2061", 5, "interspeech", 2019]], "Bo Li": [0, ["Shallow-Fusion End-to-End Contextual Biasing", ["Ding Zhao", "Tara N. Sainath", "David Rybach", "Pat Rondon", "Deepti Bhatia", "Bo Li", "Ruoming Pang"], "https://doi.org/10.21437/Interspeech.2019-1209", 5, "interspeech", 2019]], "Sofoklis Kakouros": [0, ["Prosodic Representations of Prominence Classification Neural Networks and Autoencoders Using Bottleneck Features", ["Sofoklis Kakouros", "Antti Suni", "Juraj Simko", "Martti Vainio"], "https://doi.org/10.21437/Interspeech.2019-2984", 5, "interspeech", 2019]], "Trang Tran": [0, ["Disfluencies and Human Speech Transcription Errors", ["Vicky Zayats", "Trang Tran", "Richard A. Wright", "Courtney Mansfield", "Mari Ostendorf"], "https://doi.org/10.21437/Interspeech.2019-3134", 5, "interspeech", 2019], ["On the Role of Style in Parsing Speech with Neural Models", ["Trang Tran", "Jiahong Yuan", "Yang Liu", "Mari Ostendorf"], "https://doi.org/10.21437/Interspeech.2019-3122", 5, "interspeech", 2019]], "Saeed Bagheri": [0, ["Exploiting Multi-Channel Speech Presence Probability in Parametric Multi-Channel Wiener Filter", ["Saeed Bagheri", "Daniele Giacobello"], "https://doi.org/10.21437/Interspeech.2019-2665", 5, "interspeech", 2019]], "Nabarun Goswami": [0, ["Recursive Speech Separation for Unknown Number of Speakers", ["Naoya Takahashi", "Sudarsanam Parthasaarathy", "Nabarun Goswami", "Yuki Mitsufuji"], "https://doi.org/10.21437/Interspeech.2019-1550", 5, "interspeech", 2019]], "Joachim Fainberg": [0, ["Lattice-Based Lightly-Supervised Acoustic Model Training", ["Joachim Fainberg", "Ondrej Klejch", "Steve Renals", "Peter Bell"], "https://doi.org/10.21437/Interspeech.2019-2533", 5, "interspeech", 2019]], "Katrin Kirchhoff": [0, ["Speech Audio Super-Resolution for Speech Recognition", ["Xinyu Li", "Venkata Chebiyyam", "Katrin Kirchhoff"], "https://doi.org/10.21437/Interspeech.2019-3043", 5, "interspeech", 2019], ["Multi-Stream Network with Temporal Attention for Environmental Sound Classification", ["Xinyu Li", "Venkata Chebiyyam", "Katrin Kirchhoff"], "https://doi.org/10.21437/Interspeech.2019-3019", 5, "interspeech", 2019]], "Nigel Cannings": [0, ["Explaining Sentiment Classification", ["Marvin Rajwadi", "Cornelius Glackin", "Julie A. Wall", "Gerard Chollet", "Nigel Cannings"], "https://doi.org/10.21437/Interspeech.2019-2743", 5, "interspeech", 2019]], "Alfonso Ortega Gimenez": [0, ["ViVoLAB Speaker Diarization System for the DIHARD 2019 Challenge", ["Ignacio Vinals", "Pablo Gimeno", "Alfonso Ortega Gimenez", "Antonio Miguel", "Eduardo Lleida"], "https://doi.org/10.21437/Interspeech.2019-2462", 5, "interspeech", 2019], ["Speech Enhancement with Wide Residual Networks in Reverberant Environments", ["Jorge Llombart", "Dayana Ribas", "Antonio Miguel", "Luis Vicente", "Alfonso Ortega Gimenez", "Eduardo Lleida"], "https://doi.org/10.21437/Interspeech.2019-1745", 5, "interspeech", 2019], ["Optimization of False Acceptance/Rejection Rates and Decision Threshold for End-to-End Text-Dependent Speaker Verification Systems", ["Victoria Mingote", "Antonio Miguel", "Dayana Ribas", "Alfonso Ortega Gimenez", "Eduardo Lleida"], "https://doi.org/10.21437/Interspeech.2019-2550", 5, "interspeech", 2019], ["Progressive Speech Enhancement with Residual Connections", ["Jorge Llombart", "Dayana Ribas", "Antonio Miguel", "Luis Vicente", "Alfonso Ortega Gimenez", "Eduardo Lleida"], "https://doi.org/10.21437/Interspeech.2019-1748", 5, "interspeech", 2019], ["Language Recognition Using Triplet Neural Networks", ["Victoria Mingote", "Diego Castan", "Mitchell McLaren", "Mahesh Kumar Nandwana", "Alfonso Ortega Gimenez", "Eduardo Lleida", "Antonio Miguel"], "https://doi.org/10.21437/Interspeech.2019-2437", 5, "interspeech", 2019], ["Phonetically-Aware Embeddings, Wide Residual Networks with Time-Delay Neural Networks and Self Attention Models for the 2018 NIST Speaker Recognition Evaluation", ["Ignacio Vinals", "Dayana Ribas", "Victoria Mingote", "Jorge Llombart", "Pablo Gimeno", "Antonio Miguel", "Alfonso Ortega Gimenez", "Eduardo Lleida"], "https://doi.org/10.21437/Interspeech.2019-2417", 5, "interspeech", 2019]], "Sabrina Jenne": [0, ["Multimodal Articulation-Based Pronunciation Error Detection with Spectrogram and Acoustic Features", ["Sabrina Jenne", "Ngoc Thang Vu"], "https://doi.org/10.21437/Interspeech.2019-1677", 5, "interspeech", 2019]], "Takafumi Koshinaka": [0, ["Unleashing the Unused Potential of i-Vectors Enabled by GPU Acceleration", ["Ville Vestman", "Kong Aik Lee", "Tomi H. Kinnunen", "Takafumi Koshinaka"], "https://doi.org/10.21437/Interspeech.2019-1955", 5, "interspeech", 2019], ["Speaker Augmentation and Bandwidth Extension for Deep Speaker Embedding", ["Hitoshi Yamamoto", "Kong Aik Lee", "Koji Okabe", "Takafumi Koshinaka"], "https://doi.org/10.21437/Interspeech.2019-1508", 5, "interspeech", 2019], ["The NEC-TT 2018 Speaker Verification System", ["Kong Aik Lee", "Hitoshi Yamamoto", "Koji Okabe", "Qiongqiong Wang", "Ling Guo", "Takafumi Koshinaka", "Jiacen Zhang", "Koichi Shinoda"], "https://doi.org/10.21437/Interspeech.2019-1517", 5, "interspeech", 2019]], "Mimansa Jaiswal": [0, ["Identifying Mood Episodes Using Dialogue Features from Clinical Interviews", ["Zakaria Aldeneh", "Mimansa Jaiswal", "Michael Picheny", "Melvin G. McInnis", "Emily Mower Provost"], "https://doi.org/10.21437/Interspeech.2019-1878", 5, "interspeech", 2019]], "Jan Volin": [0, ["Perceptual Evaluation of Early versus Late F0 Peaks in the Intonation Structure of Czech Question-Word Questions", ["Pavel Sturm", "Jan Volin"], "https://doi.org/10.21437/Interspeech.2019-2082", 5, "interspeech", 2019]], "S. T. Chen": [0, ["Effects of Base-Frequency and Spectral Envelope on Deep-Learning Speech Separation and Recognition Models", ["J. Hui", "Y. Wei", "S. T. Chen", "R. H. Y. So"], "https://doi.org/10.21437/Interspeech.2019-1715", 5, "interspeech", 2019]], "Nagendra Kumar Goel": [0, ["Improving Emotion Identification Using Phone Posteriors in Raw Speech Waveform Based DNN", ["Mousmita Sarma", "Pegah Ghahremani", "Daniel Povey", "Nagendra Kumar Goel", "Kandarpa Kumar Sarma", "Najim Dehak"], "https://doi.org/10.21437/Interspeech.2019-2093", 5, "interspeech", 2019], ["CaptionAI: A Real-Time Multilingual Captioning Application", ["Nagendra Kumar Goel", "Mousmita Sarma", "Saikiran Valluri", "Dharmeshkumar Agrawal", "Steve Braich", "Tejendra Singh Kuswah", "Zikra Iqbal", "Surbhi Chauhan", "Raj Karbar"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8039.html", 2, "interspeech", 2019]], "Surbhi Chauhan": [0, ["CaptionAI: A Real-Time Multilingual Captioning Application", ["Nagendra Kumar Goel", "Mousmita Sarma", "Saikiran Valluri", "Dharmeshkumar Agrawal", "Steve Braich", "Tejendra Singh Kuswah", "Zikra Iqbal", "Surbhi Chauhan", "Raj Karbar"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8039.html", 2, "interspeech", 2019]], "Antoine Laurent": [0, ["Qualitative Evaluation of ASR Adaptation in a Lecture Context: Application to the PASTEL Corpus", ["Salima Mdhaffar", "Yannick Esteve", "Nicolas Hernandez", "Antoine Laurent", "Richard Dufour", "Solen Quiniou"], "https://doi.org/10.21437/Interspeech.2019-2661", 5, "interspeech", 2019], ["Curriculum-Based Transfer Learning for an Effective End-to-End Spoken Language Understanding and Domain Portability", ["Antoine Caubriere", "Natalia A. Tomashenko", "Antoine Laurent", "Emmanuel Morin", "Nathalie Camelin", "Yannick Esteve"], "https://doi.org/10.21437/Interspeech.2019-1832", 5, "interspeech", 2019]], "Hui Zhang": [0, ["UNetGAN: A Robust Speech Enhancement Approach in Time Domain for Extremely Low Signal-to-Noise Ratio Condition", ["Xiang Hao", "Xiangdong Su", "Zhiyu Wang", "Hui Zhang", "Batushiren"], "https://doi.org/10.21437/Interspeech.2019-1567", 5, "interspeech", 2019], ["Investigation of Cost Function for Supervised Monaural Speech Separation", ["Yun Liu", "Hui Zhang", "Xueliang Zhang", "Yuhang Cao"], "https://doi.org/10.21437/Interspeech.2019-1897", 5, "interspeech", 2019], ["Learning Alignment for Multimodal Emotion Recognition from Speech", ["Haiyang Xu", "Hui Zhang", "Kun Han", "Yun Wang", "Yiping Peng", "Xiangang Li"], "https://doi.org/10.21437/Interspeech.2019-3247", 5, "interspeech", 2019]], "Cheryl Corcoran": [0, ["A New Approach for Automating Analysis of Responses on Verbal Fluency Tests from Subjects At-Risk for Schizophrenia", ["Mary Pietrowicz", "Carla Agurto", "Raquel Norel", "Elif Eyigoz", "Guillermo A. Cecchi", "Zarina R. Bilgrami", "Cheryl Corcoran"], "https://doi.org/10.21437/Interspeech.2019-2987", 5, "interspeech", 2019]], "Marcely Zanon Boito": [0, ["Empirical Evaluation of Sequence-to-Sequence Models for Word Discovery in Low-Resource Settings", ["Marcely Zanon Boito", "Aline Villavicencio", "Laurent Besacier"], "https://doi.org/10.21437/Interspeech.2019-2029", 5, "interspeech", 2019]], "Bjorn Hoffmeister": [0, ["Improving ASR Confidence Scores for Alexa Using Acoustic and Hypothesis Embeddings", ["Prakhar Swarup", "Roland Maas", "Sri Garimella", "Sri Harish Mallidi", "Bjorn Hoffmeister"], "https://doi.org/10.21437/Interspeech.2019-1241", 5, "interspeech", 2019], ["A Study for Improving Device-Directed Speech Detection Toward Frictionless Human-Machine Interaction", ["Che-Wei Huang", "Roland Maas", "Sri Harish Mallidi", "Bjorn Hoffmeister"], "https://doi.org/10.21437/Interspeech.2019-2840", 5, "interspeech", 2019]], "Chamran Ashour": [0, ["Super-Wideband Spectral Envelope Modeling for Speech Coding", ["Guillaume Fuchs", "Chamran Ashour", "Tom Backstrom"], "https://doi.org/10.21437/Interspeech.2019-1620", 5, "interspeech", 2019]], "Shigeo Wada": [0, ["Individual Differences of Airflow and Sound Generation in the Vocal Tract of Sibilant /s/", ["Tsukasa Yoshinaga", "Kazunori Nozaki", "Shigeo Wada"], "https://doi.org/10.21437/Interspeech.2019-1376", 5, "interspeech", 2019]], "Evgeny A. Stepanov": [0, ["Active Annotation: Bootstrapping Annotation Lexicon and Guidelines for Supervised NLU Learning", ["Federico Marinelli", "Alessandra Cervone", "Giuliano Tortoreto", "Evgeny A. Stepanov", "Giuseppe Di Fabbrizio", "Giuseppe Riccardi"], "https://doi.org/10.21437/Interspeech.2019-2537", 5, "interspeech", 2019]], "Priyankoo Sarmah": [0, ["Vowel-Tone Interaction in Two Tibeto-Burman Languages", ["Wendy Lalhminghlui", "Viyazonuo Terhiija", "Priyankoo Sarmah"], "https://doi.org/10.21437/Interspeech.2019-2808", 5, "interspeech", 2019]], "Ziqi Wang": [1.543913796808738e-08, ["Deep Residual Neural Networks for Audio Spoofing Detection", ["Moustafa Alzantot", "Ziqi Wang", "Mani B. Srivastava"], "https://doi.org/10.21437/Interspeech.2019-3174", 5, "interspeech", 2019]], "Philipp Koch": [0, ["Spatio-Temporal Attention Pooling for Audio Scene Classification", ["Huy Phan", "Oliver Y. Chen", "Lam Pham", "Philipp Koch", "Maarten De Vos", "Ian Vince McLoughlin", "Alfred Mertins"], "https://doi.org/10.21437/Interspeech.2019-3040", 5, "interspeech", 2019]], "Hiromitsu Nishizaki": [0, ["Audio Classification of Bit-Representation Waveform", ["Masaki Okawa", "Takuya Saito", "Naoki Sawada", "Hiromitsu Nishizaki"], "https://doi.org/10.21437/Interspeech.2019-1855", 5, "interspeech", 2019]], "Matthew W. Hoffman": [0, ["Large-Scale Visual Speech Recognition", ["Brendan Shillingford", "Yannis M. Assael", "Matthew W. Hoffman", "Thomas Paine", "Cian Hughes", "Utsav Prabhu", "Hank Liao", "Hasim Sak", "Kanishka Rao", "Lorrayne Bennett", "Marie Mulville", "Misha Denil", "Ben Coppin", "Ben Laurie", "Andrew W. Senior", "Nando de Freitas"], "https://doi.org/10.21437/Interspeech.2019-1669", 5, "interspeech", 2019]], "Sami Virpioja": [0, ["Subword RNNLM Approximations for Out-Of-Vocabulary Keyword Search", ["Mittul Singh", "Sami Virpioja", "Peter Smit", "Mikko Kurimo"], "https://doi.org/10.21437/Interspeech.2019-1329", 5, "interspeech", 2019]], "Balint Gyires-Toth": [0, ["Transformer Based Grapheme-to-Phoneme Conversion", ["Sevinj Yolchuyeva", "Geza Nemeth", "Balint Gyires-Toth"], "https://doi.org/10.21437/Interspeech.2019-1954", 5, "interspeech", 2019]], "Yoichi Matsuyama": [0, ["Recognition of Intentions of Users' Short Responses for Conversational News Delivery System", ["Hiroaki Takatsu", "Katsuya Yokoyama", "Yoichi Matsuyama", "Hiroshi Honda", "Shinya Fujie", "Tetsunori Kobayashi"], "https://doi.org/10.21437/Interspeech.2019-2121", 5, "interspeech", 2019]], "Brian R. W. Baucom": [0, ["Modeling Interpersonal Linguistic Coordination in Conversations Using Word Mover's Distance", ["Md. Nasir", "Sandeep Nallan Chakravarthula", "Brian R. W. Baucom", "David C. Atkins", "Panayiotis G. Georgiou", "Shrikanth Narayanan"], "https://doi.org/10.21437/Interspeech.2019-1900", 5, "interspeech", 2019]], "Rivka Levitan": [0, ["Mitigating Gender and L1 Differences to Improve State and Trait Recognition", ["Guozhen An", "Rivka Levitan"], "https://doi.org/10.21437/Interspeech.2019-2868", 4, "interspeech", 2019]], "Wei Xia": [0, ["Sound Event Detection in Multichannel Audio Using Convolutional Time-Frequency-Channel Squeeze and Excitation", ["Wei Xia", "Kazuhito Koishida"], "https://doi.org/10.21437/Interspeech.2019-1860", 5, "interspeech", 2019]], "Itshak Lapidot": [0, ["Identifying Distinctive Acoustic and Spectral Features in Parkinson's Disease", ["Yermiyahu Hauptman", "Ruth Aloni-Lavi", "Itshak Lapidot", "Tanya Gurevich", "Yael Manor", "Stav Naor", "Noa Diamant", "Irit Opher"], "https://doi.org/10.21437/Interspeech.2019-2465", 5, "interspeech", 2019], ["Effects of Waveform PMF on Anti-Spoofing Detection", ["Itshak Lapidot", "Jean-Francois Bonastre"], "https://doi.org/10.21437/Interspeech.2019-2607", 5, "interspeech", 2019]], "Anneliese Kelterer": [0, ["Acoustic Correlates of Phonation Type in Chichimec", ["Anneliese Kelterer", "Barbara Schuppler"], "https://doi.org/10.21437/Interspeech.2019-2066", 5, "interspeech", 2019]], "Brian Ang": [0, ["Building the Singapore English National Speech Corpus", ["Jia Xin Koh", "Aqilah Mislan", "Kevin Khoo", "Brian Ang", "Wilson Ang", "Charmaine Ng", "Ying-Ying Tan"], "https://doi.org/10.21437/Interspeech.2019-1525", 5, "interspeech", 2019]], "Thomas F. Campbell": [0, ["Vocal Biomarker Assessment Following Pediatric Traumatic Brain Injury: A Retrospective Cohort Study", ["Camille Noufi", "Adam C. Lammert", "Daryush D. Mehta", "James R. Williamson", "Gregory Ciccarelli", "Douglas E. Sturim", "Jordan R. Green", "Thomas F. Campbell", "Thomas F. Quatieri"], "https://doi.org/10.21437/Interspeech.2019-1200", 5, "interspeech", 2019]], "Harli Weber": [0, ["Use of Beiwe Smartphone App to Identify and Track Speech Decline in Amyotrophic Lateral Sclerosis (ALS)", ["Kathryn P. Connaghan", "Jordan R. Green", "Sabrina Paganoni", "James Chan", "Harli Weber", "Ella Collins", "Brian Richburg", "Marziye Eshghi", "Jukka-Pekka Onnela", "James D. Berry"], "https://doi.org/10.21437/Interspeech.2019-3126", 5, "interspeech", 2019]], "Lin-Shan Lee": [3.882123622567235e-09, ["Improved Speech Separation with Time-and-Frequency Cross-Domain Joint Embedding and Clustering", ["Gene-Ping Yang", "Chao-I Tuan", "Hung-yi Lee", "Lin-Shan Lee"], "https://doi.org/10.21437/Interspeech.2019-2181", 5, "interspeech", 2019], ["Completely Unsupervised Phoneme Recognition by a Generative Adversarial Network Harmonized with Iteratively Refined Hidden Markov Models", ["Kuan-Yu Chen", "Che-Ping Tsai", "Da-Rong Liu", "Hung-yi Lee", "Lin-Shan Lee"], "https://doi.org/10.21437/Interspeech.2019-2068", 5, "interspeech", 2019]], "Ju Lin": [0, ["Speech Enhancement Using Forked Generative Adversarial Networks with Spectral Subtraction", ["Ju Lin", "Sufeng Niu", "Zice Wei", "Xiang Lan", "Adriaan J. van Wijngaarden", "Melissa C. Smith", "Kuang-Ching Wang"], "https://doi.org/10.21437/Interspeech.2019-2954", 5, "interspeech", 2019]], "James D. Berry": [0, ["Use of Beiwe Smartphone App to Identify and Track Speech Decline in Amyotrophic Lateral Sclerosis (ALS)", ["Kathryn P. Connaghan", "Jordan R. Green", "Sabrina Paganoni", "James Chan", "Harli Weber", "Ella Collins", "Brian Richburg", "Marziye Eshghi", "Jukka-Pekka Onnela", "James D. Berry"], "https://doi.org/10.21437/Interspeech.2019-3126", 5, "interspeech", 2019]], "Nicolas Rohleder": [0, ["Using Speech to Predict Sequentially Measured Cortisol Levels During a Trier Social Stress Test", ["Alice Baird", "Shahin Amiriparian", "Nicholas Cummins", "Sarah Sturmbauer", "Johanna Janson", "Eva-Maria Messner", "Harald Baumeister", "Nicolas Rohleder", "Bjorn W. Schuller"], "https://doi.org/10.21437/Interspeech.2019-1352", 5, "interspeech", 2019]], "Aditya Joglekar": [0, ["The 2019 Inaugural Fearless Steps Challenge: A Giant Leap for Naturalistic Audio", ["John H. L. Hansen", "Aditya Joglekar", "Meena Chandra Shekhar", "Vinay Kothapally", "Chengzhu Yu", "Lakshmish Kaushik", "Abhijeet Sangwan"], "https://doi.org/10.21437/Interspeech.2019-2301", 5, "interspeech", 2019]], "Shounan An": [9.443089766136836e-06, ["Robust Keyword Spotting via Recycle-Pooling for Mobile Game", ["Shounan An", "Youngsoo Kim", "Hu Xu", "Jinwoo Lee", "Myungwoo Lee", "Insoo Oh"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8010.html", 2, "interspeech", 2019]], "Sungjoo Ha": [0.9988091886043549, ["Temporal Convolution for Real-Time Keyword Spotting on Mobile Devices", ["Seungwoo Choi", "Seokjun Seo", "Beomjun Shin", "Hyeongmin Byun", "Martin Kersner", "Beomsu Kim", "Dongyoung Kim", "Sungjoo Ha"], "https://doi.org/10.21437/Interspeech.2019-1363", 5, "interspeech", 2019]], "Spyros Matsoukas": [0, ["Compression of Acoustic Event Detection Models with Quantized Distillation", ["Bowen Shi", "Ming Sun", "Chieh-Chi Kao", "Viktor Rozgic", "Spyros Matsoukas", "Chao Wang"], "https://doi.org/10.21437/Interspeech.2019-1747", 5, "interspeech", 2019]], "Felicia S. C. Lim": [4.2337791605895347e-10, ["Salient Speech Representations Based on Cloned Networks", ["W. Bastiaan Kleijn", "Felicia S. C. Lim", "Michael Chinen", "Jan Skoglund"], "https://doi.org/10.21437/Interspeech.2019-1861", 5, "interspeech", 2019]], "Longbiao Wang": [1.2193843957025545e-15, ["Environment-Dependent Attention-Driven Recurrent Convolutional Neural Network for Robust Speech Enhancement", ["Meng Ge", "Longbiao Wang", "Nan Li", "Hao Shi", "Jianwu Dang", "Xiangang Li"], "https://doi.org/10.21437/Interspeech.2019-1477", 5, "interspeech", 2019], ["CNN-BLSTM Based Question Detection from Dialogs Considering Phase and Context Information", ["Yuke Si", "Longbiao Wang", "Jianwu Dang", "Mengfei Wu", "Aijun Li"], "https://doi.org/10.21437/Interspeech.2019-1701", 5, "interspeech", 2019]], "Ines Nolasco": [0, ["Towards Joint Sound Scene and Polyphonic Sound Event Recognition", ["Helen L. Bear", "Ines Nolasco", "Emmanouil Benetos"], "https://doi.org/10.21437/Interspeech.2019-2169", 5, "interspeech", 2019]], "Wei Chen": [0, ["An Online Attention-Based Model for Speech Recognition", ["Ruchao Fan", "Pan Zhou", "Wei Chen", "Jia Jia", "Gang Liu"], "https://doi.org/10.21437/Interspeech.2019-2218", 5, "interspeech", 2019]], "Dan Du": [0, ["The Production of Chinese Affricates /ts/ and /tsh/ by Native Urdu Speakers", ["Dan Du", "Jinsong Zhang"], "https://doi.org/10.21437/Interspeech.2019-1638", 5, "interspeech", 2019]], "Helena Peic Tukuljac": [0, ["Evaluating Audiovisual Source Separation in the Context of Video Conferencing", ["Berkay Inan", "Milos Cernak", "Helmut Grabner", "Helena Peic Tukuljac", "Rodrigo C. G. Pena", "Benjamin Ricaud"], "https://doi.org/10.21437/Interspeech.2019-2671", 5, "interspeech", 2019]], "Rongzhi Gu": [2.6207646053322264e-09, ["Neural Spatial Filter: Target Speaker Speech Separation Assisted with Directional Information", ["Rongzhi Gu", "Lianwu Chen", "Shi-Xiong Zhang", "Jimeng Zheng", "Yong Xu", "Meng Yu", "Dan Su", "Yuexian Zou", "Dong Yu"], "https://doi.org/10.21437/Interspeech.2019-2266", 5, "interspeech", 2019], ["A Comprehensive Study of Speech Separation: Spectrogram vs Waveform Separation", ["Fahimeh Bahmaninezhad", "Jian Wu", "Rongzhi Gu", "Shi-Xiong Zhang", "Yong Xu", "Meng Yu", "Dong Yu"], "https://doi.org/10.21437/Interspeech.2019-3181", 5, "interspeech", 2019]], "Sujata Supanekar": [0, ["NITK Kids' Speech Corpus", ["Pravin Bhaskar Ramteke", "Sujata Supanekar", "Pradyoth Hegde", "Hanna Nelson", "Venkataraja Aithal", "Shashidhar G. Koolagudi"], "https://doi.org/10.21437/Interspeech.2019-2061", 5, "interspeech", 2019]], "Feng Ma": [0, ["Acoustic Model Ensembling Using Effective Data Augmentation for CHiME-5 Challenge", ["Feng Ma", "Li Chai", "Jun Du", "Diyuan Liu", "Zhongfu Ye", "Chin-Hui Lee"], "https://doi.org/10.21437/Interspeech.2019-2601", 5, "interspeech", 2019]], "Nursadul Mamun": [0, ["Quantifying Cochlear Implant Users' Ability for Speaker Identification Using CI Auditory Stimuli", ["Nursadul Mamun", "Ria Ghosh", "John H. L. Hansen"], "https://doi.org/10.21437/Interspeech.2019-1852", 5, "interspeech", 2019], ["Convolutional Neural Network-Based Speech Enhancement for Cochlear Implant Recipients", ["Nursadul Mamun", "Soheil Khorram", "John H. L. Hansen"], "https://doi.org/10.21437/Interspeech.2019-1850", 5, "interspeech", 2019]], "Zhengyang Chen": [0, ["The SJTU Robust Anti-Spoofing System for the ASVspoof 2019 Challenge", ["Yexin Yang", "Hongji Wang", "Heinrich Dinkel", "Zhengyang Chen", "Shuai Wang", "Yanmin Qian", "Kai Yu"], "https://doi.org/10.21437/Interspeech.2019-2170", 5, "interspeech", 2019]], "Yi Wang": [0.0003460402149357833, ["Exploiting Visual Features Using Bayesian Gated Neural Networks for Disordered Speech Recognition", ["Shansong Liu", "Shoukang Hu", "Yi Wang", "Jianwei Yu", "Rongfeng Su", "Xunying Liu", "Helen Meng"], "https://doi.org/10.21437/Interspeech.2019-1536", 5, "interspeech", 2019]], "Kai Zhen": [0, ["Cascaded Cross-Module Residual Learning Towards Lightweight End-to-End Speech Coding", ["Kai Zhen", "Jongmo Sung", "Mi Suk Lee", "Seungkwon Beack", "Minje Kim"], "https://doi.org/10.21437/Interspeech.2019-1816", 5, "interspeech", 2019]], "Elisabeth Andre": [0, ["Relevance-Based Feature Masking: Improving Neural Network Based Whale Classification Through Explainable Artificial Intelligence", ["Dominik Schiller", "Tobias Huber", "Florian Lingenfelser", "Michael Dietz", "Andreas Seiderer", "Elisabeth Andre"], "https://doi.org/10.21437/Interspeech.2019-2707", 5, "interspeech", 2019]], "Xinzhou Xu": [0, ["Autonomous Emotion Learning in Speech: A View of Zero-Shot Speech Emotion Recognition", ["Xinzhou Xu", "Jun Deng", "Nicholas Cummins", "Zixing Zhang", "Li Zhao", "Bjorn W. Schuller"], "https://doi.org/10.21437/Interspeech.2019-2406", 5, "interspeech", 2019]], "Anastasios Vafeiadis": [0, ["Two-Dimensional Convolutional Recurrent Neural Networks for Speech Activity Detection", ["Anastasios Vafeiadis", "Eleftherios Fanioudakis", "Ilyas Potamitis", "Konstantinos Votis", "Dimitrios Giakoumis", "Dimitrios Tzovaras", "Liming Chen", "Raouf Hamzaoui"], "https://doi.org/10.21437/Interspeech.2019-1354", 5, "interspeech", 2019]], "Kye Taylor": [0, ["Gender De-Biasing in Speech Emotion Recognition", ["Cristina Gorrostieta", "Reza Lotfian", "Kye Taylor", "Richard Brutti", "John Kane"], "https://doi.org/10.21437/Interspeech.2019-1708", 5, "interspeech", 2019]], "Laureano Moro-Velazquez": [0, ["Study of the Performance of Automatic Speech Recognition Systems in Speakers with Parkinson's Disease", ["Laureano Moro-Velazquez", "Jaejin Cho", "Shinji Watanabe", "Mark A. Hasegawa-Johnson", "Odette Scharenborg", "Heejin Kim", "Najim Dehak"], "https://doi.org/10.21437/Interspeech.2019-2993", 5, "interspeech", 2019]], "Silke Hamann": [0, ["Vietnamese Learners Tackling the German /\u0283t/ in Perception", ["Anke Sennema", "Silke Hamann"], "https://doi.org/10.21437/Interspeech.2019-2832", 4, "interspeech", 2019]], "Reza Lotfian": [0, ["Gender De-Biasing in Speech Emotion Recognition", ["Cristina Gorrostieta", "Reza Lotfian", "Kye Taylor", "Richard Brutti", "John Kane"], "https://doi.org/10.21437/Interspeech.2019-1708", 5, "interspeech", 2019]], "Daniel Smoczyk": [0, ["Avaya Conversational Intelligence: A Real-Time System for Spoken Language Understanding in Human-Human Call Center Conversations", ["Jan Mizgajski", "Adrian Szymczak", "Robert Glowski", "Piotr Szymanski", "Piotr Zelasko", "Lukasz Augustyniak", "Mikolaj Morzy", "Yishay Carmiel", "Jeff Hodson", "Lukasz Wojciak", "Daniel Smoczyk", "Adam Wrobel", "Bartosz Borowik", "Adam Artajew", "Marcin Baran", "Cezary Kwiatkowski", "Marzena Zyla-Hoppe"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8002.html", 2, "interspeech", 2019]], "Jahangir Alam": [0, ["CRIM's Speech Transcription and Call Sign Detection System for the ATC Airbus Challenge Task", ["Vishwa Gupta", "Lise Rebout", "Gilles Boulianne", "Pierre Andre Menard", "Jahangir Alam"], "https://doi.org/10.21437/Interspeech.2019-1131", 5, "interspeech", 2019]], "Tony Y. Li": [0, ["Active Learning for Domain Classification in a Commercial Spoken Personal Assistant", ["Xi C. Chen", "Adithya Sagar", "Justine T. Kao", "Tony Y. Li", "Christopher Klein", "Stephen Pulman", "Ashish Garg", "Jason D. Williams"], "https://doi.org/10.21437/Interspeech.2019-1315", 5, "interspeech", 2019]], "Miriam Ebersberg": [0, ["The Influence of Distraction on Speech Processing: How Selective is Selective Attention?", ["Sandra I. Parhammer", "Miriam Ebersberg", "Jenny Tippmann", "Katja Stark", "Andreas Opitz", "Barbara Hinger", "Sonja Rossi"], "https://doi.org/10.21437/Interspeech.2019-2699", 5, "interspeech", 2019]], "Junichi Yamagishi": [0, ["GELP: GAN-Excited Linear Prediction for Speech Synthesis from Mel-Spectrogram", ["Lauri Juvela", "Bajibabu Bollepalli", "Junichi Yamagishi", "Paavo Alku"], "https://doi.org/10.21437/Interspeech.2019-2008", 5, "interspeech", 2019], ["ASVspoof 2019: Future Horizons in Spoofed and Fake Audio Detection", ["Massimiliano Todisco", "Xin Wang", "Ville Vestman", "Md. Sahidullah", "Hector Delgado", "Andreas Nautsch", "Junichi Yamagishi", "Nicholas W. D. Evans", "Tomi H. Kinnunen", "Kong Aik Lee"], "https://doi.org/10.21437/Interspeech.2019-2249", 5, "interspeech", 2019], ["Joint Training Framework for Text-to-Speech and Voice Conversion Using Multi-Source Tacotron and WaveNet", ["Mingyang Zhang", "Xin Wang", "Fuming Fang", "Haizhou Li", "Junichi Yamagishi"], "https://doi.org/10.21437/Interspeech.2019-1357", 5, "interspeech", 2019], ["Training Multi-Speaker Neural Text-to-Speech Systems Using Speaker-Imbalanced Speech Corpora", ["Hieu-Thi Luong", "Xin Wang", "Junichi Yamagishi", "Nobuyuki Nishizawa"], "https://doi.org/10.21437/Interspeech.2019-1311", 5, "interspeech", 2019], ["MOSNet: Deep Learning-Based Objective Assessment for Voice Conversion", ["Chen-Chou Lo", "Szu-Wei Fu", "Wen-Chin Huang", "Xin Wang", "Junichi Yamagishi", "Yu Tsao", "Hsin-Min Wang"], "https://doi.org/10.21437/Interspeech.2019-2003", 5, "interspeech", 2019], ["Does the Lombard Effect Improve Emotional Communication in Noise? - Analysis of Emotional Speech Acted in Noise", ["Yi Zhao", "Atsushi Ando", "Shinji Takaki", "Junichi Yamagishi", "Satoshi Kobashikawa"], "https://doi.org/10.21437/Interspeech.2019-1605", 5, "interspeech", 2019]], "Takafumi Moriya": [0, ["End-to-End Automatic Speech Recognition with a Reconstruction Criterion Using Speech-to-Text and Text-to-Speech Encoder-Decoders", ["Ryo Masumura", "Hiroshi Sato", "Tomohiro Tanaka", "Takafumi Moriya", "Yusuke Ijima", "Takanobu Oba"], "https://doi.org/10.21437/Interspeech.2019-2111", 5, "interspeech", 2019], ["A Joint End-to-End and DNN-HMM Hybrid Automatic Speech Recognition System with Transferring Sharable Knowledge", ["Tomohiro Tanaka", "Ryo Masumura", "Takafumi Moriya", "Takanobu Oba", "Yushi Aono"], "https://doi.org/10.21437/Interspeech.2019-2263", 5, "interspeech", 2019], ["Neural Whispered Speech Detection with Imbalanced Learning", ["Takanori Ashihara", "Yusuke Shinohara", "Hiroshi Sato", "Takafumi Moriya", "Kiyoaki Matsui", "Takaaki Fukutomi", "Yoshikazu Yamaguchi", "Yushi Aono"], "https://doi.org/10.21437/Interspeech.2019-2161", 5, "interspeech", 2019], ["Joint Maximization Decoder with Neural Converters for Fully Neural Network-Based Japanese Speech Recognition", ["Takafumi Moriya", "Jian Wang", "Tomohiro Tanaka", "Ryo Masumura", "Yusuke Shinohara", "Yoshikazu Yamaguchi", "Yushi Aono"], "https://doi.org/10.21437/Interspeech.2019-1558", 5, "interspeech", 2019]], "Alexandr Kozlov": [0, ["Speaker Diarization with Deep Speaker Embeddings for DIHARD Challenge II", ["Sergey Novoselov", "Aleksei Gusev", "Artem Ivanov", "Timur Pekhovsky", "Andrey Shulipa", "Anastasia Avdeeva", "Artem Gorlanov", "Alexandr Kozlov"], "https://doi.org/10.21437/Interspeech.2019-2757", 5, "interspeech", 2019], ["STC Antispoofing Systems for the ASVspoof2019 Challenge", ["Galina Lavrentyeva", "Sergey Novoselov", "Andzhukaev Tseren", "Marina Volkova", "Artem Gorlanov", "Alexandr Kozlov"], "https://doi.org/10.21437/Interspeech.2019-1768", 5, "interspeech", 2019], ["STC Speaker Recognition Systems for the VOiCES from a Distance Challenge", ["Sergey Novoselov", "Aleksei Gusev", "Artem Ivanov", "Timur Pekhovsky", "Andrey Shulipa", "Galina Lavrentyeva", "Vladimir Volokhov", "Alexandr Kozlov"], "https://doi.org/10.21437/Interspeech.2019-2783", 5, "interspeech", 2019], ["STC Speaker Recognition Systems for the VOiCES from a Distance Challenge", ["Sergey Novoselov", "Aleksei Gusev", "Artem Ivanov", "Timur Pekhovsky", "Andrey Shulipa", "Galina Lavrentyeva", "Vladimir Volokhov", "Alexandr Kozlov"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/abs15.html", 0, "interspeech", 2019]], "Monica Dominguez": [0, ["PyToBI: A Toolkit for ToBI Labeling Under Python", ["Monica Dominguez", "Patrick Louis Rohrer", "Juan Soler Company"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8021.html", 2, "interspeech", 2019]], "Annalena Venneri": [0, ["Automatic Hierarchical Attention Neural Network for Detecting AD", ["Yilin Pan", "Bahman Mirheidari", "Markus Reuber", "Annalena Venneri", "Daniel Blackburn", "Heidi Christensen"], "https://doi.org/10.21437/Interspeech.2019-1799", 5, "interspeech", 2019]], "Shawn L. Nissen": [0, ["Listeners' Ability to Identify the Gender of Preadolescent Children in Different Linguistic Contexts", ["Shawn L. Nissen", "Sharalee Blunck", "Anita Dromey", "Christopher Dromey"], "https://doi.org/10.21437/Interspeech.2019-1865", 5, "interspeech", 2019], ["Using Real-Time Visual Biofeedback for Second Language Instruction", ["Shawn L. Nissen", "Rebecca Nissen"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8016.html", 2, "interspeech", 2019]], "Tanja Schultz": [0, ["Comparative Analysis of Think-Aloud Methods for Everyday Activities in the Context of Cognitive Robotics", ["Moritz Meier", "Celeste Mason", "Felix Putze", "Tanja Schultz"], "https://doi.org/10.21437/Interspeech.2019-3072", 5, "interspeech", 2019], ["Biosignal Processing for Human-Machine Interaction", ["Tanja Schultz"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/abs6.html", 0, "interspeech", 2019]], "Arijit Biswas": [0, ["Analysis by Adversarial Synthesis - A Novel Approach for Speech Vocoding", ["Ahmed Mustafa", "Arijit Biswas", "Christian Bergler", "Julia Schottenhamml", "Andreas K. Maier"], "https://doi.org/10.21437/Interspeech.2019-1195", 5, "interspeech", 2019]], "Jenifer Vega Rodriguez": [0, ["The Vowel System of Korebaju", ["Jenifer Vega Rodriguez"], "https://doi.org/10.21437/Interspeech.2019-3210", 5, "interspeech", 2019]], "Cezary Kwiatkowski": [0, ["Avaya Conversational Intelligence: A Real-Time System for Spoken Language Understanding in Human-Human Call Center Conversations", ["Jan Mizgajski", "Adrian Szymczak", "Robert Glowski", "Piotr Szymanski", "Piotr Zelasko", "Lukasz Augustyniak", "Mikolaj Morzy", "Yishay Carmiel", "Jeff Hodson", "Lukasz Wojciak", "Daniel Smoczyk", "Adam Wrobel", "Bartosz Borowik", "Adam Artajew", "Marcin Baran", "Cezary Kwiatkowski", "Marzena Zyla-Hoppe"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8002.html", 2, "interspeech", 2019]], "Adrian Szymczak": [0, ["Avaya Conversational Intelligence: A Real-Time System for Spoken Language Understanding in Human-Human Call Center Conversations", ["Jan Mizgajski", "Adrian Szymczak", "Robert Glowski", "Piotr Szymanski", "Piotr Zelasko", "Lukasz Augustyniak", "Mikolaj Morzy", "Yishay Carmiel", "Jeff Hodson", "Lukasz Wojciak", "Daniel Smoczyk", "Adam Wrobel", "Bartosz Borowik", "Adam Artajew", "Marcin Baran", "Cezary Kwiatkowski", "Marzena Zyla-Hoppe"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8002.html", 2, "interspeech", 2019]], "Yansong Chua": [0, ["Robust Sound Recognition: A Neuromorphic Approach", ["Jibin Wu", "Zihan Pan", "Malu Zhang", "Rohan Kumar Das", "Yansong Chua", "Haizhou Li"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8032.html", 2, "interspeech", 2019]], "Xi C. Chen": [0, ["Active Learning for Domain Classification in a Commercial Spoken Personal Assistant", ["Xi C. Chen", "Adithya Sagar", "Justine T. Kao", "Tony Y. Li", "Christopher Klein", "Stephen Pulman", "Ashish Garg", "Jason D. Williams"], "https://doi.org/10.21437/Interspeech.2019-1315", 5, "interspeech", 2019]], "Haohan Guo": [0, ["A New GAN-Based End-to-End TTS Training Algorithm", ["Haohan Guo", "Frank K. Soong", "Lei He", "Lei Xie"], "https://doi.org/10.21437/Interspeech.2019-2176", 5, "interspeech", 2019], ["Exploiting Syntactic Features in a Parsed Tree to Improve End-to-End TTS", ["Haohan Guo", "Frank K. Soong", "Lei He", "Lei Xie"], "https://doi.org/10.21437/Interspeech.2019-2167", 5, "interspeech", 2019]], "Donghyun Lee": [0.9940284192562103, ["Shortcut Connections Based Deep Speaker Embeddings for End-to-End Speaker Verification System", ["Soonshin Seo", "Daniel Jun Rim", "Minkyu Lim", "Donghyun Lee", "Hosung Park", "Junseok Oh", "Changmin Kim", "Ji-Hwan Kim"], "https://doi.org/10.21437/Interspeech.2019-2195", 5, "interspeech", 2019]], "Stephen Jannetts": [0, ["Reliability of Clinical Voice Parameters Captured with Smartphones - Measurements of Added Noise and Spectral Tilt", ["Felix Schaeffler", "Stephen Jannetts", "Janet Beck"], "https://doi.org/10.21437/Interspeech.2019-2910", 5, "interspeech", 2019]], "Alexei Baevski": [0, ["wav2vec: Unsupervised Pre-Training for Speech Recognition", ["Steffen Schneider", "Alexei Baevski", "Ronan Collobert", "Michael Auli"], "https://doi.org/10.21437/Interspeech.2019-1873", 5, "interspeech", 2019]], "Yumo Xu": [0, ["Trainable Dynamic Subsampling for End-to-End Speech Recognition", ["Shucong Zhang", "Erfan Loweimi", "Yumo Xu", "Peter Bell", "Steve Renals"], "https://doi.org/10.21437/Interspeech.2019-2778", 5, "interspeech", 2019]], "Joon-Hyuk Chang": [0.999975860118866, ["Joint Optimization of Neural Acoustic Beamforming and Dereverberation with x-Vectors for Robust Speaker Verification", ["Joon-Young Yang", "Joon-Hyuk Chang"], "https://doi.org/10.21437/Interspeech.2019-1356", 5, "interspeech", 2019]], "Thomas Schultze": [0, ["Towards the Prosody of Persuasion in Competitive Negotiation. The Relationship Between f0 and Negotiation Success in Same Sex Sales Tasks", ["Jan Michalsky", "Heike Schoormann", "Thomas Schultze"], "https://doi.org/10.21437/Interspeech.2019-3031", 5, "interspeech", 2019]], "W. Bastiaan Kleijn": [0, ["Salient Speech Representations Based on Cloned Networks", ["W. Bastiaan Kleijn", "Felicia S. C. Lim", "Michael Chinen", "Jan Skoglund"], "https://doi.org/10.21437/Interspeech.2019-1861", 5, "interspeech", 2019], ["Speech Enhancement with Variance Constrained Autoencoders", ["Daniel T. Braithwaite", "W. Bastiaan Kleijn"], "https://doi.org/10.21437/Interspeech.2019-1809", 5, "interspeech", 2019], ["Maximum a posteriori Speech Enhancement Based on Double Spectrum", ["Pejman Mowlaee", "Daniel Scheran", "Johannes Stahl", "Sean U. N. Wood", "W. Bastiaan Kleijn"], "https://doi.org/10.21437/Interspeech.2019-1197", 5, "interspeech", 2019]], "Ewan Dunbar": [0, ["The Zero Resource Speech Challenge 2019: TTS Without T", ["Ewan Dunbar", "Robin Algayres", "Julien Karadayi", "Mathieu Bernard", "Juan Benjumea", "Xuan-Nga Cao", "Lucie Miskic", "Charlotte Dugrain", "Lucas Ondel", "Alan W. Black", "Laurent Besacier", "Sakriani Sakti", "Emmanuel Dupoux"], "https://doi.org/10.21437/Interspeech.2019-2904", 5, "interspeech", 2019]], "Tejendra Singh Kuswah": [0, ["CaptionAI: A Real-Time Multilingual Captioning Application", ["Nagendra Kumar Goel", "Mousmita Sarma", "Saikiran Valluri", "Dharmeshkumar Agrawal", "Steve Braich", "Tejendra Singh Kuswah", "Zikra Iqbal", "Surbhi Chauhan", "Raj Karbar"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8039.html", 2, "interspeech", 2019]], "Nan Yan": [0, ["Towards the Speech Features of Mild Cognitive Impairment: Universal Evidence from Structured and Unstructured Connected Speech of Chinese", ["Tianqi Wang", "Chongyuan Lian", "Jingshen Pan", "Quanlei Yan", "Feiqi Zhu", "Manwa L. Ng", "Lan Wang", "Nan Yan"], "https://doi.org/10.21437/Interspeech.2019-2414", 5, "interspeech", 2019], ["Towards the Speech Features of Early-Stage Dementia: Design and Application of the Mandarin Elderly Cognitive Speech Database", ["Tianqi Wang", "Quanlei Yan", "Jingshen Pan", "Feiqi Zhu", "Rongfeng Su", "Yi Guo", "Lan Wang", "Nan Yan"], "https://doi.org/10.21437/Interspeech.2019-2453", 5, "interspeech", 2019]], "Liu Chen": [0, ["Improving ASR Systems for Children with Autism and Language Impairment Using Domain-Focused DNN Transfer Techniques", ["Robert Gale", "Liu Chen", "Jill Dolata", "Jan P. H. van Santen", "Meysam Asgari"], "https://doi.org/10.21437/Interspeech.2019-3161", 5, "interspeech", 2019]], "Gary Yeung": [0, ["A Frequency Normalization Technique for Kindergarten Speech Recognition Inspired by the Role of fo in Vowel Perception", ["Gary Yeung", "Abeer Alwan"], "https://doi.org/10.21437/Interspeech.2019-1847", 5, "interspeech", 2019]], "Anyan Shi": [0, ["Deep Attention Gated Dilated Temporal Convolutional Networks with Intra-Parallel Convolutional Modules for End-to-End Monaural Speech Separation", ["Ziqiang Shi", "Huibin Lin", "Liu Liu", "Rujie Liu", "Jiqing Han", "Anyan Shi"], "https://doi.org/10.21437/Interspeech.2019-1373", 5, "interspeech", 2019]], "Lukasz Augustyniak": [0, ["Avaya Conversational Intelligence: A Real-Time System for Spoken Language Understanding in Human-Human Call Center Conversations", ["Jan Mizgajski", "Adrian Szymczak", "Robert Glowski", "Piotr Szymanski", "Piotr Zelasko", "Lukasz Augustyniak", "Mikolaj Morzy", "Yishay Carmiel", "Jeff Hodson", "Lukasz Wojciak", "Daniel Smoczyk", "Adam Wrobel", "Bartosz Borowik", "Adam Artajew", "Marcin Baran", "Cezary Kwiatkowski", "Marzena Zyla-Hoppe"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8002.html", 2, "interspeech", 2019]], "Juan Rafael Orozco-Arroyave": [0, ["Phonet: A Tool Based on Gated Recurrent Neural Networks to Extract Phonological Posteriors from Speech", ["Juan Camilo Vasquez-Correa", "Philipp Klumpp", "Juan Rafael Orozco-Arroyave", "Elmar Noth"], "https://doi.org/10.21437/Interspeech.2019-1405", 5, "interspeech", 2019], ["Apkinson: A Mobile Solution for Multimodal Assessment of Patients with Parkinson's Disease", ["Juan Camilo Vasquez-Correa", "Tomas Arias-Vergara", "Philipp Klumpp", "M. Strauss", "Arne Kuderle", "Nils Roth", "S. Bayerl", "Nicanor Garcia-Ospina", "Paula Andrea Perez-Toro", "L. Felipe Parra-Gallego", "Cristian David Rios-Urrego", "D. Escobar-Grisales", "Juan Rafael Orozco-Arroyave", "Bjorn Eskofier", "Elmar Noth"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8003.html", 2, "interspeech", 2019], ["Feature Representation of Pathophysiology of Parkinsonian Dysarthria", ["Alice Rueda", "Juan Camilo Vasquez-Correa", "Cristian David Rios-Urrego", "Juan Rafael Orozco-Arroyave", "Sridhar Krishnan", "Elmar Noth"], "https://doi.org/10.21437/Interspeech.2019-2490", 5, "interspeech", 2019], ["Assessing Parkinson's Disease from Speech Using Fisher Vectors", ["Jose Vicente Egas Lopez", "Juan Rafael Orozco-Arroyave", "Gabor Gosztolya"], "https://doi.org/10.21437/Interspeech.2019-2217", 5, "interspeech", 2019], ["Phone-Attribute Posteriors to Evaluate the Speech of Cochlear Implant Users", ["Tomas Arias-Vergara", "Juan Rafael Orozco-Arroyave", "Milos Cernak", "Sandra Gollwitzer", "Maria Schuster", "Elmar Noth"], "https://doi.org/10.21437/Interspeech.2019-2144", 5, "interspeech", 2019]], "Lauri Tavi": [0, ["Recognition of Creaky Voice from Emergency Calls", ["Lauri Tavi", "Tanel Alumae", "Stefan Werner"], "https://doi.org/10.21437/Interspeech.2019-1253", 5, "interspeech", 2019]], "Avashna Govender": [0, ["Unsupervised Acoustic Unit Discovery for Speech Synthesis Using Discrete Latent-Variable Neural Networks", ["Ryan Eloff", "Andre Nortje", "Benjamin van Niekerk", "Avashna Govender", "Leanne Nortje", "Arnu Pretorius", "Elan Van Biljon", "Ewald van der Westhuizen", "Lisa van Staden", "Herman Kamper"], "https://doi.org/10.21437/Interspeech.2019-1518", 5, "interspeech", 2019], ["Using Pupil Dilation to Measure Cognitive Load When Listening to Text-to-Speech in Quiet and in Noise", ["Avashna Govender", "Anita E. Wagner", "Simon King"], "https://doi.org/10.21437/Interspeech.2019-1783", 5, "interspeech", 2019]], "Jean Schoentgen": [0, ["Analysis and Synthesis of Vocal Flutter and Vocal Jitter", ["Jean Schoentgen", "Philipp Aichinger"], "https://doi.org/10.21437/Interspeech.2019-1998", 5, "interspeech", 2019]], "Sandesh Aryal": [0, ["Selection and Training Schemes for Improving TTS Voice Built on Found Data", ["Fang-Yu Kuo", "Iris Chuoying Ouyang", "Sandesh Aryal", "Pierre Lanchantin"], "https://doi.org/10.21437/Interspeech.2019-2816", 5, "interspeech", 2019]], "Klaus Zechner": [0, ["Automated Estimation of Oral Reading Fluency During Summer Camp e-Book Reading with MyTurnToRead", ["Anastassia Loukina", "Beata Beigman Klebanov", "Patrick L. Lange", "Yao Qian", "Binod Gyawali", "Nitin Madnani", "Abhinav Misra", "Klaus Zechner", "Zuowei Wang", "John Sabatini"], "https://doi.org/10.21437/Interspeech.2019-2889", 5, "interspeech", 2019], ["Development of Robust Automated Scoring Models Using Adversarial Input for Oral Proficiency Assessment", ["Su-Youn Yoon", "Chong Min Lee", "Klaus Zechner", "Keelan Evanini"], "https://doi.org/10.21437/Interspeech.2019-1711", 5, "interspeech", 2019], ["Automatic Detection of Off-Topic Spoken Responses Using Very Deep Convolutional Neural Networks", ["Xinhao Wang", "Su-Youn Yoon", "Keelan Evanini", "Klaus Zechner", "Yao Qian"], "https://doi.org/10.21437/Interspeech.2019-1848", 5, "interspeech", 2019]], "Yuya Hagihara": [0, ["Speech Organ Contour Extraction Using Real-Time MRI and Machine Learning Method", ["Hironori Takemoto", "Tsubasa Goto", "Yuya Hagihara", "Sayaka Hamanaka", "Tatsuya Kitamura", "Yukiko Nota", "Kikuo Maekawa"], "https://doi.org/10.21437/Interspeech.2019-1593", 5, "interspeech", 2019]], "Ramaswamy Palaniappan": [0, ["A Robust Framework for Acoustic Scene Classification", ["Lam Dang Pham", "Ian Vince McLoughlin", "Huy Phan", "Ramaswamy Palaniappan"], "https://doi.org/10.21437/Interspeech.2019-1841", 5, "interspeech", 2019]], "Claude Barras": [0, ["LSTM Based Similarity Measurement with Spectral Clustering for Speaker Diarization", ["Qingjian Lin", "Ruiqing Yin", "Ming Li", "Herve Bredin", "Claude Barras"], "https://doi.org/10.21437/Interspeech.2019-1388", 5, "interspeech", 2019]], "Xianghu Yue": [0, ["Linguistically Motivated Parallel Data Augmentation for Code-Switch Language Modeling", ["Grandee Lee", "Xianghu Yue", "Haizhou Li"], "https://doi.org/10.21437/Interspeech.2019-1382", 5, "interspeech", 2019], ["Multi-Graph Decoding for Code-Switching ASR", ["Emre Yilmaz", "Samuel Cohen", "Xianghu Yue", "David A. van Leeuwen", "Haizhou Li"], "https://doi.org/10.21437/Interspeech.2019-1125", 5, "interspeech", 2019]], "Xin Pan": [0, ["Code-Switching Sentence Generation by Bert and Generative Adversarial Networks", ["Yingying Gao", "Junlan Feng", "Ying Liu", "Leijing Hou", "Xin Pan", "Yong Ma"], "https://doi.org/10.21437/Interspeech.2019-2501", 5, "interspeech", 2019]], "Oguz H. Elibol": [0, ["Semi-Supervised Voice Conversion with Amortized Variational Inference", ["Cory Stephenson", "Gokce Keskin", "Anil Thomas", "Oguz H. Elibol"], "https://doi.org/10.21437/Interspeech.2019-1840", 5, "interspeech", 2019]], "Yannis Pantazis": [0, ["Non-Parallel Voice Conversion Using Weighted Generative Adversarial Networks", ["Dipjyoti Paul", "Yannis Pantazis", "Yannis Stylianou"], "https://doi.org/10.21437/Interspeech.2019-2869", 5, "interspeech", 2019], ["Speech Enhancement for Noise-Robust Speech Synthesis Using Wasserstein GAN", ["Nagaraj Adiga", "Yannis Pantazis", "Vassilis Tsiaras", "Yannis Stylianou"], "https://doi.org/10.21437/Interspeech.2019-2648", 5, "interspeech", 2019]], "Jiarui Wang": [9.11693223315524e-05, ["Child Speech Disorder Detection with Siamese Recurrent Network Using Speech Attribute Features", ["Jiarui Wang", "Ying Qin", "Zhiyuan Peng", "Tan Lee"], "https://doi.org/10.21437/Interspeech.2019-2320", 5, "interspeech", 2019]], "Jung Hyuk Lee": [0.9823252260684967, ["Directional Audio Rendering Using a Neural Network Based Personalized HRTF", ["Geon Woo Lee", "Jung Hyuk Lee", "Seong Ju Kim", "Hong Kook Kim"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8005.html", 2, "interspeech", 2019]], "Alexander Rakowski": [0, ["Robust Bayesian and Light Neural Networks for Voice Spoofing Detection", ["Radoslaw Bialobrzeski", "Michal Kosmider", "Mateusz Matuszewski", "Marcin Plata", "Alexander Rakowski"], "https://doi.org/10.21437/Interspeech.2019-2676", 5, "interspeech", 2019]], "Slim Ouni": [0, ["Conditional Variational Auto-Encoder for Text-Driven Expressive AudioVisual Speech Synthesis", ["Sara Dahmani", "Vincent Colotte", "Valerian Girard", "Slim Ouni"], "https://doi.org/10.21437/Interspeech.2019-2848", 5, "interspeech", 2019], ["Modeling Labial Coarticulation with Bidirectional Gated Recurrent Networks and Transfer Learning", ["Theo Biasutto-Lervat", "Sara Dahmani", "Slim Ouni"], "https://doi.org/10.21437/Interspeech.2019-2097", 5, "interspeech", 2019]], "Aliyah R. Hsu": [0, ["Personalized Dialogue Response Generation Learned from Monologues", ["Feng-Guang Su", "Aliyah R. Hsu", "Yi-Lin Tuan", "Hung-yi Lee"], "https://doi.org/10.21437/Interspeech.2019-1696", 5, "interspeech", 2019]], "Naveen Kumar": [0, ["Multiview Shared Subspace Learning Across Speakers and Speech Commands", ["Krishna Somandepalli", "Naveen Kumar", "Arindam Jati", "Panayiotis G. Georgiou", "Shrikanth Narayanan"], "https://doi.org/10.21437/Interspeech.2019-3130", 5, "interspeech", 2019], ["Multi-Task Discriminative Training of Hybrid DNN-TVM Model for Speaker Verification with Noisy and Far-Field Speech", ["Arindam Jati", "Raghuveer Peri", "Monisankha Pal", "Tae Jin Park", "Naveen Kumar", "Ruchir Travadi", "Panayiotis G. Georgiou", "Shrikanth Narayanan"], "https://doi.org/10.21437/Interspeech.2019-3010", 5, "interspeech", 2019]], "Zhongkai Sun": [4.6527646847620806e-14, ["Multi-Modal Sentiment Analysis Using Deep Canonical Correlation Analysis", ["Zhongkai Sun", "Prathusha Kameswara Sarma", "William A. Sethares", "Erik P. Bucy"], "https://doi.org/10.21437/Interspeech.2019-2482", 5, "interspeech", 2019]], "Don McAllaster": [0, ["Bandwidth Embeddings for Mixed-Bandwidth Speech Recognition", ["Gautam Mantena", "Ozlem Kalinli", "Ossama Abdel-Hamid", "Don McAllaster"], "https://doi.org/10.21437/Interspeech.2019-2589", 5, "interspeech", 2019]], "Emmanuel Azuh": [0, ["Towards Bilingual Lexicon Discovery From Visually Grounded Speech Audio", ["Emmanuel Azuh", "David Harwath", "James R. Glass"], "https://doi.org/10.21437/Interspeech.2019-1718", 5, "interspeech", 2019]], "Hieu-Thi Luong": [0, ["Training Multi-Speaker Neural Text-to-Speech Systems Using Speaker-Imbalanced Speech Corpora", ["Hieu-Thi Luong", "Xin Wang", "Junichi Yamagishi", "Nobuyuki Nishizawa"], "https://doi.org/10.21437/Interspeech.2019-1311", 5, "interspeech", 2019]], "Yun Wang": [0.0668149832636118, ["Learning Alignment for Multimodal Emotion Recognition from Speech", ["Haiyang Xu", "Hui Zhang", "Kun Han", "Yun Wang", "Yiping Peng", "Xiangang Li"], "https://doi.org/10.21437/Interspeech.2019-3247", 5, "interspeech", 2019]], "Alejandro Gomez Alanis": [0, ["A Light Convolutional GRU-RNN Deep Feature Extractor for ASV Spoofing Detection", ["Alejandro Gomez Alanis", "Antonio M. Peinado", "Jose A. Gonzalez", "Angel M. Gomez"], "https://doi.org/10.21437/Interspeech.2019-2212", 5, "interspeech", 2019]], "Alberto Abad": [0, ["Recognition of Latin American Spanish Using Multi-Task Learning", ["Carlos Mendes", "Alberto Abad", "Joao Paulo Neto", "Isabel Trancoso"], "https://doi.org/10.21437/Interspeech.2019-2772", 5, "interspeech", 2019]], "Sahar Rauf": [0, ["Improving Large Vocabulary Urdu Speech Recognition System Using Deep Neural Networks", ["Muhammad Umar Farooq", "Farah Adeeba", "Sahar Rauf", "Sarmad Hussain"], "https://doi.org/10.21437/Interspeech.2019-2629", 5, "interspeech", 2019]], "Egor Lakomkin": [0, ["Predictive Auxiliary Variational Autoencoder for Representation Learning of Global Speech Characteristics", ["Sebastian Springenberg", "Egor Lakomkin", "Cornelius Weber", "Stefan Wermter"], "https://doi.org/10.21437/Interspeech.2019-2845", 5, "interspeech", 2019]], "Yang Zhang": [0, ["VAE-Based Regularization for Deep Speaker Embedding", ["Yang Zhang", "Lantian Li", "Dong Wang"], "https://doi.org/10.21437/Interspeech.2019-2486", 5, "interspeech", 2019]], "Heejin Kim": [0.9188794493675232, ["Study of the Performance of Automatic Speech Recognition Systems in Speakers with Parkinson's Disease", ["Laureano Moro-Velazquez", "Jaejin Cho", "Shinji Watanabe", "Mark A. Hasegawa-Johnson", "Odette Scharenborg", "Heejin Kim", "Najim Dehak"], "https://doi.org/10.21437/Interspeech.2019-2993", 5, "interspeech", 2019]], "Yingjie Li": [0, ["The LeVoice Far-Field Speech Recognition System for VOiCES from a Distance Challenge 2019", ["Yulong Liang", "Lin Yang", "Xuyang Wang", "Yingjie Li", "Chen Jia", "Junjie Wang"], "https://doi.org/10.21437/Interspeech.2019-1944", 5, "interspeech", 2019]], "Emiru Tsunoo": [0, ["End-to-End Adaptation with Backpropagation Through WFST for On-Device Speech Recognition System", ["Emiru Tsunoo", "Yosuke Kashiwagi", "Satoshi Asakawa", "Toshiyuki Kumakura"], "https://doi.org/10.21437/Interspeech.2019-1880", 5, "interspeech", 2019]], "Sho Tomita": [0, ["Lyrics Recognition from Singing Voice Focused on Correspondence Between Voice and Notes", ["Motoyuki Suzuki", "Sho Tomita", "Tomoki Morita"], "https://doi.org/10.21437/Interspeech.2019-1318", 4, "interspeech", 2019]], "Yong Qin": [0, ["Few-Shot Audio Classification with Attentional Graph Neural Networks", ["Shilei Zhang", "Yong Qin", "Kewei Sun", "Yonghua Lin"], "https://doi.org/10.21437/Interspeech.2019-1532", 5, "interspeech", 2019]], "Mathieu Giquel": [0, ["Unbabel Talk - Human Verified Translations for Voice Instant Messaging", ["Luis Bernardo", "Mathieu Giquel", "Sebastiao Quintas", "Paulo Dimas", "Helena Moniz", "Isabel Trancoso"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8034.html", 2, "interspeech", 2019]], "Alexis Moinet": [0, ["Towards Achieving Robust Universal Neural Vocoding", ["Jaime Lorenzo-Trueba", "Thomas Drugman", "Javier Latorre", "Thomas Merritt", "Bartosz Putrycz", "Roberto Barra-Chicote", "Alexis Moinet", "Vatsal Aggarwal"], "https://doi.org/10.21437/Interspeech.2019-1424", 5, "interspeech", 2019]], "Soo-Young Lee": [0.9948376417160034, ["Adjusting Pleasure-Arousal-Dominance for Continuous Emotional Text-to-Speech Synthesizer", ["Azam Rabiee", "Tae-Ho Kim", "Soo-Young Lee"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8045.html", 2, "interspeech", 2019]], "Pavel Kral": [0, ["Multi-Lingual Dialogue Act Recognition with Deep Learning Methods", ["Jiri Martinek", "Pavel Kral", "Ladislav Lenc", "Christophe Cerisara"], "https://doi.org/10.21437/Interspeech.2019-1691", 5, "interspeech", 2019]], "Yu Tsao": [0, ["Investigation of F0 Conditioning and Fully Convolutional Networks in Variational Autoencoder Based Voice Conversion", ["Wen-Chin Huang", "Yi-Chiao Wu", "Chen-Chou Lo", "Patrick Lumban Tobing", "Tomoki Hayashi", "Kazuhiro Kobayashi", "Tomoki Toda", "Yu Tsao", "Hsin-Min Wang"], "https://doi.org/10.21437/Interspeech.2019-1774", 5, "interspeech", 2019], ["Generative Adversarial Networks for Unpaired Voice Transformation on Impaired Speech", ["Li-Wei Chen", "Hung-yi Lee", "Yu Tsao"], "https://doi.org/10.21437/Interspeech.2019-1265", 5, "interspeech", 2019], ["MOSNet: Deep Learning-Based Objective Assessment for Voice Conversion", ["Chen-Chou Lo", "Szu-Wei Fu", "Wen-Chin Huang", "Xin Wang", "Junichi Yamagishi", "Yu Tsao", "Hsin-Min Wang"], "https://doi.org/10.21437/Interspeech.2019-2003", 5, "interspeech", 2019], ["Exploring the Encoder Layers of Discriminative Autoencoders for LVCSR", ["Pin-Tuan Huang", "Hung-Shin Lee", "Syu-Siang Wang", "Kuan-Yu Chen", "Yu Tsao", "Hsin-Min Wang"], "https://doi.org/10.21437/Interspeech.2019-1717", 5, "interspeech", 2019], ["IA-NET: Acceleration and Compression of Speech Enhancement Using Integer-Adder Deep Neural Network", ["Yu-Chen Lin", "Yi-Te Hsu", "Szu-Wei Fu", "Yu Tsao", "Tei-Wei Kuo"], "https://doi.org/10.21437/Interspeech.2019-1207", 5, "interspeech", 2019], ["Incorporating Symbolic Sequential Modeling for Speech Enhancement", ["Chien-Feng Liao", "Yu Tsao", "Xugang Lu", "Hisashi Kawai"], "https://doi.org/10.21437/Interspeech.2019-1777", 5, "interspeech", 2019], ["Noise Adaptive Speech Enhancement Using Domain Adversarial Training", ["Chien-Feng Liao", "Yu Tsao", "Hung-yi Lee", "Hsin-Min Wang"], "https://doi.org/10.21437/Interspeech.2019-1519", 5, "interspeech", 2019], ["Specialized Speech Enhancement Model Selection Based on Learned Non-Intrusive Quality Assessment Metric", ["Ryandhimas E. Zezario", "Szu-Wei Fu", "Xugang Lu", "Hsin-Min Wang", "Yu Tsao"], "https://doi.org/10.21437/Interspeech.2019-2425", 5, "interspeech", 2019], ["Speaker-Aware Deep Denoising Autoencoder with Embedded Speaker Identity for Speech Enhancement", ["Fu-Kai Chuang", "Syu-Siang Wang", "Jeih-weih Hung", "Yu Tsao", "Shih-Hau Fang"], "https://doi.org/10.21437/Interspeech.2019-2108", 5, "interspeech", 2019], ["Class-Wise Centroid Distance Metric Learning for Acoustic Event Detection", ["Xugang Lu", "Peng Shen", "Sheng Li", "Yu Tsao", "Hisashi Kawai"], "https://doi.org/10.21437/Interspeech.2019-2271", 5, "interspeech", 2019]], "Taiki Yamamoto": [0, ["Small-Footprint Magic Word Detection Method Using Convolutional LSTM Neural Network", ["Taiki Yamamoto", "Ryota Nishimura", "Masayuki Misaki", "Norihide Kitaoka"], "https://doi.org/10.21437/Interspeech.2019-1662", 5, "interspeech", 2019]], "Martti Vainio": [0, ["Prosodic Representations of Prominence Classification Neural Networks and Autoencoders Using Bottleneck Features", ["Sofoklis Kakouros", "Antti Suni", "Juraj Simko", "Martti Vainio"], "https://doi.org/10.21437/Interspeech.2019-2984", 5, "interspeech", 2019], ["Comparative Analysis of Prosodic Characteristics Using WaveNet Embeddings", ["Antti Suni", "Marcin Wlodarczak", "Martti Vainio", "Juraj Simko"], "https://doi.org/10.21437/Interspeech.2019-2373", 5, "interspeech", 2019]], "Paulo Dimas": [0, ["Unbabel Talk - Human Verified Translations for Voice Instant Messaging", ["Luis Bernardo", "Mathieu Giquel", "Sebastiao Quintas", "Paulo Dimas", "Helena Moniz", "Isabel Trancoso"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8034.html", 2, "interspeech", 2019]], "Yuan-Jui Chen": [0, ["End-to-End Text-to-Speech for Low-Resource Languages by Cross-Lingual Transfer Learning", ["Yuan-Jui Chen", "Tao Tu", "Cheng-chieh Yeh", "Hung-yi Lee"], "https://doi.org/10.21437/Interspeech.2019-2730", 5, "interspeech", 2019]], "Jose A. Gonzalez": [0, ["A Light Convolutional GRU-RNN Deep Feature Extractor for ASV Spoofing Detection", ["Alejandro Gomez Alanis", "Antonio M. Peinado", "Jose A. Gonzalez", "Angel M. Gomez"], "https://doi.org/10.21437/Interspeech.2019-2212", 5, "interspeech", 2019]], "Ingmar Steiner": [0, ["Phonetic Accommodation in a Wizard-of-Oz Experiment: Intonation and Segments", ["Iona Gessinger", "Bernd Mobius", "Bistra Andreeva", "Eran Raveh", "Ingmar Steiner"], "https://doi.org/10.21437/Interspeech.2019-2445", 5, "interspeech", 2019], ["Towards Robust Speech Emotion Recognition Using Deep Residual Networks for Speech Enhancement", ["Andreas Triantafyllopoulos", "Gil Keren", "Johannes Wagner", "Ingmar Steiner", "Bjorn W. Schuller"], "https://doi.org/10.21437/Interspeech.2019-1811", 5, "interspeech", 2019], ["Robust Speech Emotion Recognition Under Different Encoding Conditions", ["Christopher Oates", "Andreas Triantafyllopoulos", "Ingmar Steiner", "Bjorn W. Schuller"], "https://doi.org/10.21437/Interspeech.2019-1658", 5, "interspeech", 2019], ["Three's a Crowd? Effects of a Second Human on Vocal Accommodation with a Voice Assistant", ["Eran Raveh", "Ingo Siegert", "Ingmar Steiner", "Iona Gessinger", "Bernd Mobius"], "https://doi.org/10.21437/Interspeech.2019-1825", 5, "interspeech", 2019]], "Masaki Okawa": [0, ["Audio Classification of Bit-Representation Waveform", ["Masaki Okawa", "Takuya Saito", "Naoki Sawada", "Hiromitsu Nishizaki"], "https://doi.org/10.21437/Interspeech.2019-1855", 5, "interspeech", 2019]], "Ching Hua Lee": [9.075021983884213e-11, ["On Mitigating Acoustic Feedback in Hearing Aids with Frequency Warping by All-Pass Networks", ["Ching Hua Lee", "Kuan-Lin Chen", "Fredric J. Harris", "Bhaskar D. Rao", "Harinath Garudadri"], "https://doi.org/10.21437/Interspeech.2019-3195", 5, "interspeech", 2019]], "Dirk Heylen": [0, ["An Acoustic and Lexical Analysis of Emotional Valence in Spontaneous Speech: Autobiographical Memory Recall in Older Adults", ["Deniece S. Nazareth", "Ellen Tournier", "Sarah Leimkotter", "Esther Janse", "Dirk Heylen", "Gerben J. Westerhof", "Khiet P. Truong"], "https://doi.org/10.21437/Interspeech.2019-1823", 5, "interspeech", 2019]], "Bartosz Kostka": [0, ["Towards Using Context-Dependent Symbols in CTC Without State-Tying Decision Trees", ["Jan Chorowski", "Adrian Lancucki", "Bartosz Kostka", "Michal Zapotoczny"], "https://doi.org/10.21437/Interspeech.2019-2720", 5, "interspeech", 2019]], "Rami Botros": [0, ["Connecting and Comparing Language Model Interpolation Techniques", ["Ernest Pusateri", "Christophe Van Gysel", "Rami Botros", "Sameer Badaskar", "Mirko Hannemann", "Youssef Oualil", "Ilya Oparin"], "https://doi.org/10.21437/Interspeech.2019-1822", 5, "interspeech", 2019]], "Elie Khoury": [0, ["Pindrop Labs' Submission to the First Multi-Target Speaker Detection and Identification Challenge", ["Elie Khoury", "Khaled Lakhdhar", "Andrew Vaughan", "Ganesh Sivaraman", "Parav Nagarsheth"], "https://doi.org/10.21437/Interspeech.2019-3179", 4, "interspeech", 2019]], "Roland Maas": [0, ["Improving ASR Confidence Scores for Alexa Using Acoustic and Hypothesis Embeddings", ["Prakhar Swarup", "Roland Maas", "Sri Garimella", "Sri Harish Mallidi", "Bjorn Hoffmeister"], "https://doi.org/10.21437/Interspeech.2019-1241", 5, "interspeech", 2019], ["A Study for Improving Device-Directed Speech Detection Toward Frictionless Human-Machine Interaction", ["Che-Wei Huang", "Roland Maas", "Sri Harish Mallidi", "Bjorn Hoffmeister"], "https://doi.org/10.21437/Interspeech.2019-2840", 5, "interspeech", 2019]], "Jeroen Zegers": [0, ["Practical Applicability of Deep Neural Networks for Overlapping Speaker Separation", ["Pieter Appeltans", "Jeroen Zegers", "Hugo Van hamme"], "https://doi.org/10.21437/Interspeech.2019-1807", 5, "interspeech", 2019], ["CNN-LSTM Models for Multi-Speaker Source Separation Using Bayesian Hyper Parameter Optimization", ["Jeroen Zegers", "Hugo Van hamme"], "https://doi.org/10.21437/Interspeech.2019-2423", 5, "interspeech", 2019]], "Nils Roth": [0, ["Apkinson: A Mobile Solution for Multimodal Assessment of Patients with Parkinson's Disease", ["Juan Camilo Vasquez-Correa", "Tomas Arias-Vergara", "Philipp Klumpp", "M. Strauss", "Arne Kuderle", "Nils Roth", "S. Bayerl", "Nicanor Garcia-Ospina", "Paula Andrea Perez-Toro", "L. Felipe Parra-Gallego", "Cristian David Rios-Urrego", "D. Escobar-Grisales", "Juan Rafael Orozco-Arroyave", "Bjorn Eskofier", "Elmar Noth"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8003.html", 2, "interspeech", 2019]], "Marziye Eshghi": [0, ["Use of Beiwe Smartphone App to Identify and Track Speech Decline in Amyotrophic Lateral Sclerosis (ALS)", ["Kathryn P. Connaghan", "Jordan R. Green", "Sabrina Paganoni", "James Chan", "Harli Weber", "Ella Collins", "Brian Richburg", "Marziye Eshghi", "Jukka-Pekka Onnela", "James D. Berry"], "https://doi.org/10.21437/Interspeech.2019-3126", 5, "interspeech", 2019], ["Reduced Task Adaptation in Alternating Motion Rate Tasks as an Early Marker of Bulbar Involvement in Amyotrophic Lateral Sclerosis", ["Marziye Eshghi", "Panying Rong", "Antje S. Mefferd", "Kaila L. Stipancic", "Yana Yunusova", "Jordan R. Green"], "https://doi.org/10.21437/Interspeech.2019-2546", 5, "interspeech", 2019]], "Jhansi Mallela": [0, ["Acoustic and Articulatory Feature Based Speech Rate Estimation Using a Convolutional Dense Neural Network", ["Renuka Mannem", "Jhansi Mallela", "Aravind Illa", "Prasanta Kumar Ghosh"], "https://doi.org/10.21437/Interspeech.2019-2295", 5, "interspeech", 2019]], "Sayaka Shiota": [0, ["Investigation on Blind Bandwidth Extension with a Non-Linear Function and its Evaluation of x-Vector-Based Speaker Verification", ["Ryota Kaminishi", "Haruna Miyamoto", "Sayaka Shiota", "Hitoshi Kiya"], "https://doi.org/10.21437/Interspeech.2019-1510", 5, "interspeech", 2019]], "Lei Liu": [0, ["Prosodic Characteristics of Mandarin Declarative and Interrogative Utterances in Parkinson's Disease", ["Lei Liu", "Meng Jian", "Wentao Gu"], "https://doi.org/10.21437/Interspeech.2019-3276", 5, "interspeech", 2019]], "Cian Hughes": [0, ["Large-Scale Visual Speech Recognition", ["Brendan Shillingford", "Yannis M. Assael", "Matthew W. Hoffman", "Thomas Paine", "Cian Hughes", "Utsav Prabhu", "Hank Liao", "Hasim Sak", "Kanishka Rao", "Lorrayne Bennett", "Marie Mulville", "Misha Denil", "Ben Coppin", "Ben Laurie", "Andrew W. Senior", "Nando de Freitas"], "https://doi.org/10.21437/Interspeech.2019-1669", 5, "interspeech", 2019]], "Yeunju Choi": [0.9971908330917358, ["Spatial Pyramid Encoding with Convex Length Normalization for Text-Independent Speaker Verification", ["Youngmoon Jung", "Younggwan Kim", "Hyungjun Lim", "Yeunju Choi", "Hoirin Kim"], "https://doi.org/10.21437/Interspeech.2019-2177", 5, "interspeech", 2019]], "Lior Wolf": [0, ["Unsupervised Singing Voice Conversion", ["Eliya Nachmani", "Lior Wolf"], "https://doi.org/10.21437/Interspeech.2019-1761", 5, "interspeech", 2019]], "Yves Laprie": [0, ["Towards a Method of Dynamic Vocal Tract Shapes Generation by Combining Static 3D and Dynamic 2D MRI Speech Data", ["Ioannis K. Douros", "Anastasiia Tsukanova", "Karyna Isaieva", "Pierre-Andre Vuissoz", "Yves Laprie"], "https://doi.org/10.21437/Interspeech.2019-2880", 5, "interspeech", 2019], ["A Multimodal Real-Time MRI Articulatory Corpus of French for Speech Research", ["Ioannis K. Douros", "Jacques Felblinger", "Jens Frahm", "Karyna Isaieva", "Arun A. Joseph", "Yves Laprie", "Freddy Odille", "Anastasiia Tsukanova", "Dirk Voit", "Pierre-Andre Vuissoz"], "https://doi.org/10.21437/Interspeech.2019-1700", 5, "interspeech", 2019]], "Chenglin Xu": [0, ["Target Speaker Extraction for Multi-Talker Speaker Verification", ["Wei Rao", "Chenglin Xu", "Eng Siong Chng", "Haizhou Li"], "https://doi.org/10.21437/Interspeech.2019-1410", 5, "interspeech", 2019]], "Pavel Sturm": [0, ["Perceptual Evaluation of Early versus Late F0 Peaks in the Intonation Structure of Czech Question-Word Questions", ["Pavel Sturm", "Jan Volin"], "https://doi.org/10.21437/Interspeech.2019-2082", 5, "interspeech", 2019]], "Che-Wei Huang": [0, ["A Study for Improving Device-Directed Speech Detection Toward Frictionless Human-Machine Interaction", ["Che-Wei Huang", "Roland Maas", "Sri Harish Mallidi", "Bjorn Hoffmeister"], "https://doi.org/10.21437/Interspeech.2019-2840", 5, "interspeech", 2019]], "Inga Holube": [0, ["\"Computer, Test My Hearing\": Accurate Speech Audiometry with Smart Speakers", ["Jasper Ooster", "Pia Nancy Porysek Moreta", "Jorg-Hendrik Bach", "Inga Holube", "Bernd T. Meyer"], "https://doi.org/10.21437/Interspeech.2019-2118", 5, "interspeech", 2019]], "Chenchen Ding": [0, ["End-to-End Articulatory Attribute Modeling for Low-Resource Multilingual Speech Recognition", ["Sheng Li", "Chenchen Ding", "Xugang Lu", "Peng Shen", "Tatsuya Kawahara", "Hisashi Kawai"], "https://doi.org/10.21437/Interspeech.2019-2092", 5, "interspeech", 2019], ["Investigating Radical-Based End-to-End Speech Recognition Systems for Chinese Dialects and Japanese", ["Sheng Li", "Xugang Lu", "Chenchen Ding", "Peng Shen", "Tatsuya Kawahara", "Hisashi Kawai"], "https://doi.org/10.21437/Interspeech.2019-2104", 5, "interspeech", 2019]], "Ann R. Bradlow": [0, ["Perception of Pitch Contours in Speech and Nonspeech", ["Daniel R. Turner", "Ann R. Bradlow", "Jennifer S. Cole"], "https://doi.org/10.21437/Interspeech.2019-2619", 5, "interspeech", 2019], ["Survey Talk: Recognition of Foreign-Accented Speech: Challenges and Opportunities for Human and Computer Speech Communication", ["Ann R. Bradlow"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/abs21.html", 0, "interspeech", 2019], ["Speaking Rate, Information Density, and Information Rate in First-Language and Second-Language Speech", ["Ann R. Bradlow"], "https://doi.org/10.21437/Interspeech.2019-1150", 5, "interspeech", 2019]], "Mate Akos Tundik": [0, ["Assessing the Semantic Space Bias Caused by ASR Error Propagation and its Effect on Spoken Document Summarization", ["Mate Akos Tundik", "Valer Kaszas", "Gyorgy Szaszak"], "https://doi.org/10.21437/Interspeech.2019-2154", 5, "interspeech", 2019], ["Leveraging a Character, Word and Prosody Triplet for an ASR Error Robust and Agglutination Friendly Punctuation Approach", ["Gyorgy Szaszak", "Mate Akos Tundik"], "https://doi.org/10.21437/Interspeech.2019-2132", 5, "interspeech", 2019]], "Qi Ju": [1.1267271020187763e-05, ["Multimedia Simultaneous Translation System for Minority Language Communication with Mandarin", ["Shen Huang", "Bojie Hu", "Shan Huang", "Pengfei Hu", "Jian Kang", "Zhiqiang Lv", "Jinghao Yan", "Qi Ju", "Shiyin Kang", "Deyi Tuo", "Guangzhi Li", "Nurmemet Yolwas"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8020.html", 2, "interspeech", 2019]], "Hyungjun Lim": [0.9916885048151016, ["Spatial Pyramid Encoding with Convex Length Normalization for Text-Independent Speaker Verification", ["Youngmoon Jung", "Younggwan Kim", "Hyungjun Lim", "Yeunju Choi", "Hoirin Kim"], "https://doi.org/10.21437/Interspeech.2019-2177", 5, "interspeech", 2019]], "Yi Shen": [0, ["Listener Preference on the Local Criterion for Ideal Binary-Masked Speech", ["Zhuohuang Zhang", "Yi Shen"], "https://doi.org/10.21437/Interspeech.2019-1369", 5, "interspeech", 2019]], "Peng Shen": [0, ["End-to-End Articulatory Attribute Modeling for Low-Resource Multilingual Speech Recognition", ["Sheng Li", "Chenchen Ding", "Xugang Lu", "Peng Shen", "Tatsuya Kawahara", "Hisashi Kawai"], "https://doi.org/10.21437/Interspeech.2019-2092", 5, "interspeech", 2019], ["Investigating Radical-Based End-to-End Speech Recognition Systems for Chinese Dialects and Japanese", ["Sheng Li", "Xugang Lu", "Chenchen Ding", "Peng Shen", "Tatsuya Kawahara", "Hisashi Kawai"], "https://doi.org/10.21437/Interspeech.2019-2104", 5, "interspeech", 2019], ["Class-Wise Centroid Distance Metric Learning for Acoustic Event Detection", ["Xugang Lu", "Peng Shen", "Sheng Li", "Yu Tsao", "Hisashi Kawai"], "https://doi.org/10.21437/Interspeech.2019-2271", 5, "interspeech", 2019], ["Improving Transformer-Based Speech Recognition Systems with Compressed Structure and Speech Attributes Augmentation", ["Sheng Li", "Dabre Raj", "Xugang Lu", "Peng Shen", "Tatsuya Kawahara", "Hisashi Kawai"], "https://doi.org/10.21437/Interspeech.2019-2112", 5, "interspeech", 2019]], "Victoria Mingote": [0, ["Optimization of False Acceptance/Rejection Rates and Decision Threshold for End-to-End Text-Dependent Speaker Verification Systems", ["Victoria Mingote", "Antonio Miguel", "Dayana Ribas", "Alfonso Ortega Gimenez", "Eduardo Lleida"], "https://doi.org/10.21437/Interspeech.2019-2550", 5, "interspeech", 2019], ["Language Recognition Using Triplet Neural Networks", ["Victoria Mingote", "Diego Castan", "Mitchell McLaren", "Mahesh Kumar Nandwana", "Alfonso Ortega Gimenez", "Eduardo Lleida", "Antonio Miguel"], "https://doi.org/10.21437/Interspeech.2019-2437", 5, "interspeech", 2019], ["Phonetically-Aware Embeddings, Wide Residual Networks with Time-Delay Neural Networks and Self Attention Models for the 2018 NIST Speaker Recognition Evaluation", ["Ignacio Vinals", "Dayana Ribas", "Victoria Mingote", "Jorge Llombart", "Pablo Gimeno", "Antonio Miguel", "Alfonso Ortega Gimenez", "Eduardo Lleida"], "https://doi.org/10.21437/Interspeech.2019-2417", 5, "interspeech", 2019]], "Victor Zappi": [0, ["An Extended Two-Dimensional Vocal Tract Model for Fast Acoustic Simulation of Single-Axis Symmetric Three-Dimensional Tubes", ["Debasish Ray Mohapatra", "Victor Zappi", "Sidney S. Fels"], "https://doi.org/10.21437/Interspeech.2019-1764", 5, "interspeech", 2019]], "Thierry Dutoit": [0, ["Visualization and Interpretation of Latent Spaces for Controlling Expressive Speech Synthesis Through Audio Analysis", ["Noe Tits", "Fengna Wang", "Kevin El Haddad", "Vincent Pagel", "Thierry Dutoit"], "https://doi.org/10.21437/Interspeech.2019-1426", 5, "interspeech", 2019]], "Venkata Chebiyyam": [0, ["Speech Audio Super-Resolution for Speech Recognition", ["Xinyu Li", "Venkata Chebiyyam", "Katrin Kirchhoff"], "https://doi.org/10.21437/Interspeech.2019-3043", 5, "interspeech", 2019], ["Multi-Stream Network with Temporal Attention for Environmental Sound Classification", ["Xinyu Li", "Venkata Chebiyyam", "Katrin Kirchhoff"], "https://doi.org/10.21437/Interspeech.2019-3019", 5, "interspeech", 2019]], "Barbara Schuppler": [0, ["Prosodic Effects on Plosive Duration in German and Austrian German", ["Barbara Schuppler", "Margaret Zellers"], "https://doi.org/10.21437/Interspeech.2019-2197", 5, "interspeech", 2019], ["Acoustic Cues to Topic and Narrow Focus in Egyptian Arabic", ["Dina El Zarka", "Barbara Schuppler", "Francesco Cangemi"], "https://doi.org/10.21437/Interspeech.2019-1189", 5, "interspeech", 2019], ["Acoustic Correlates of Phonation Type in Chichimec", ["Anneliese Kelterer", "Barbara Schuppler"], "https://doi.org/10.21437/Interspeech.2019-2066", 5, "interspeech", 2019]], "David Snyder": [0, ["State-of-the-Art Speaker Recognition for Telephone and Video Speech: The JHU-MIT Submission for NIST SRE18", ["Jesus Villalba", "Nanxin Chen", "David Snyder", "Daniel Garcia-Romero", "Alan McCree", "Gregory Sell", "Jonas Borgstrom", "Fred Richardson", "Suwon Shon", "Francois Grondin", "Reda Dehak", "Leibny Paola Garcia-Perera", "Daniel Povey", "Pedro A. Torres-Carrasquillo", "Sanjeev Khudanpur", "Najim Dehak"], "https://doi.org/10.21437/Interspeech.2019-2713", 5, "interspeech", 2019], ["x-Vector DNN Refinement with Full-Length Recordings for Speaker Recognition", ["Daniel Garcia-Romero", "David Snyder", "Gregory Sell", "Alan McCree", "Daniel Povey", "Sanjeev Khudanpur"], "https://doi.org/10.21437/Interspeech.2019-2205", 4, "interspeech", 2019], ["Speaker Recognition Benchmark Using the CHiME-5 Corpus", ["Daniel Garcia-Romero", "David Snyder", "Shinji Watanabe", "Gregory Sell", "Alan McCree", "Daniel Povey", "Sanjeev Khudanpur"], "https://doi.org/10.21437/Interspeech.2019-2174", 5, "interspeech", 2019], ["The JHU Speaker Recognition System for the VOiCES 2019 Challenge", ["David Snyder", "Jesus Villalba", "Nanxin Chen", "Daniel Povey", "Gregory Sell", "Najim Dehak", "Sanjeev Khudanpur"], "https://doi.org/10.21437/Interspeech.2019-2979", 5, "interspeech", 2019], ["The JHU ASR System for VOiCES from a Distance Challenge 2019", ["Yiming Wang", "David Snyder", "Hainan Xu", "Vimal Manohar", "Phani Sankar Nidadavolu", "Daniel Povey", "Sanjeev Khudanpur"], "https://doi.org/10.21437/Interspeech.2019-1948", 5, "interspeech", 2019]], "Jingbei Li": [0, ["Knowledge-Based Linguistic Encoding for End-to-End Mandarin Text-to-Speech Synthesis", ["Jingbei Li", "Zhiyong Wu", "Runnan Li", "Pengpeng Zhi", "Song Yang", "Helen Meng"], "https://doi.org/10.21437/Interspeech.2019-1118", 5, "interspeech", 2019]], "Ioana Vasilescu": [0, ["\" Gra[f] e!\" Word-Final Devoicing of Obstruents in Standard French: An Acoustic Study Based on Large Corpora", ["Adele Jatteau", "Ioana Vasilescu", "Lori Lamel", "Martine Adda-Decker", "Nicolas Audibert"], "https://doi.org/10.21437/Interspeech.2019-2329", 5, "interspeech", 2019]], "Hiroshi Seki": [0, ["End-to-End Multilingual Multi-Speaker Speech Recognition", ["Hiroshi Seki", "Takaaki Hori", "Shinji Watanabe", "Jonathan Le Roux", "John R. Hershey"], "https://doi.org/10.21437/Interspeech.2019-3038", 5, "interspeech", 2019], ["Vectorized Beam Search for CTC-Attention-Based Speech Recognition", ["Hiroshi Seki", "Takaaki Hori", "Shinji Watanabe", "Niko Moritz", "Jonathan Le Roux"], "https://doi.org/10.21437/Interspeech.2019-2860", 5, "interspeech", 2019]], "Zhiping Zeng": [0, ["Constrained Output Embeddings for End-to-End Code-Switching Speech Recognition with Only Monolingual Data", ["Yerbolat Khassanov", "Haihua Xu", "Van Tung Pham", "Zhiping Zeng", "Eng Siong Chng", "Chongjia Ni", "Bin Ma"], "https://doi.org/10.21437/Interspeech.2019-1867", 5, "interspeech", 2019], ["On the End-to-End Solution to Mandarin-English Code-Switching Speech Recognition", ["Zhiping Zeng", "Yerbolat Khassanov", "Van Tung Pham", "Haihua Xu", "Eng Siong Chng", "Haizhou Li"], "https://doi.org/10.21437/Interspeech.2019-1429", 5, "interspeech", 2019], ["Enriching Rare Word Representations in Neural Language Models by Embedding Matrix Augmentation", ["Yerbolat Khassanov", "Zhiping Zeng", "Van Tung Pham", "Haihua Xu", "Eng Siong Chng"], "https://doi.org/10.21437/Interspeech.2019-1858", 5, "interspeech", 2019]], "Mitra Mohtarami": [0, ["Integrating Video Retrieval and Moment Detection in a Unified Corpus for Video Question Answering", ["Hongyin Luo", "Mitra Mohtarami", "James R. Glass", "Karthik Krishnamurthy", "Brigitte Richardson"], "https://doi.org/10.21437/Interspeech.2019-1736", 5, "interspeech", 2019]], "Turaj Zakizadeh Shabestary": [0, ["Multi-Microphone Adaptive Noise Cancellation for Robust Hotword Detection", ["Yiteng Huang", "Turaj Zakizadeh Shabestary", "Alexander Gruenstein", "Li Wan"], "https://doi.org/10.21437/Interspeech.2019-3006", 5, "interspeech", 2019]], "Bernd Mobius": [0, ["Phonetic Accommodation in a Wizard-of-Oz Experiment: Intonation and Segments", ["Iona Gessinger", "Bernd Mobius", "Bistra Andreeva", "Eran Raveh", "Ingmar Steiner"], "https://doi.org/10.21437/Interspeech.2019-2445", 5, "interspeech", 2019], ["Three's a Crowd? Effects of a Second Human on Vocal Accommodation with a Voice Assistant", ["Eran Raveh", "Ingo Siegert", "Ingmar Steiner", "Iona Gessinger", "Bernd Mobius"], "https://doi.org/10.21437/Interspeech.2019-1825", 5, "interspeech", 2019]], "S. R. Mahadeva Prasanna": [0, ["SpeechMarker: A Voice Based Multi-Level Attendance Application", ["Sarfaraz Jelil", "Abhishek Shrivastava", "Rohan Kumar Das", "S. R. Mahadeva Prasanna", "Rohit Sinha"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8014.html", 2, "interspeech", 2019], ["Modification of Devoicing Error in Cleft Lip and Palate Speech", ["Protima Nomo Sudro", "S. R. Mahadeva Prasanna"], "https://doi.org/10.21437/Interspeech.2019-2604", 5, "interspeech", 2019], ["Nasal Air Emission in Sibilant Fricatives of Cleft Lip and Palate Speech", ["Sishir Kalita", "Protima Nomo Sudro", "S. R. Mahadeva Prasanna", "Samarendra Dandapat"], "https://doi.org/10.21437/Interspeech.2019-2345", 5, "interspeech", 2019], ["Hypernasality Severity Detection Using Constant Q Cepstral Coefficients", ["Akhilesh Kumar Dubey", "S. R. Mahadeva Prasanna", "S. Dandapat"], "https://doi.org/10.21437/Interspeech.2019-2151", 5, "interspeech", 2019]], "Adithya Sagar": [0, ["Active Learning for Domain Classification in a Commercial Spoken Personal Assistant", ["Xi C. Chen", "Adithya Sagar", "Justine T. Kao", "Tony Y. Li", "Christopher Klein", "Stephen Pulman", "Ashish Garg", "Jason D. Williams"], "https://doi.org/10.21437/Interspeech.2019-1315", 5, "interspeech", 2019]], "Chen Jia": [0, ["The LeVoice Far-Field Speech Recognition System for VOiCES from a Distance Challenge 2019", ["Yulong Liang", "Lin Yang", "Xuyang Wang", "Yingjie Li", "Chen Jia", "Junjie Wang"], "https://doi.org/10.21437/Interspeech.2019-1944", 5, "interspeech", 2019]], "Buddhi Wickramasinghe": [0, ["Biologically Inspired Adaptive-Q Filterbanks for Replay Spoofing Attack Detection", ["Buddhi Wickramasinghe", "Eliathamby Ambikairajah", "Julien Epps"], "https://doi.org/10.21437/Interspeech.2019-1535", 5, "interspeech", 2019]], "Gerald Penn": [0, ["Extracting Mel-Frequency and Bark-Frequency Cepstral Coefficients from Encrypted Signals", ["Patricia Thaine", "Gerald Penn"], "https://doi.org/10.21437/Interspeech.2019-1136", 5, "interspeech", 2019]], "Joakim Gustafson": [0, ["Off the Cuff: Exploring Extemporaneous Speech Delivery with TTS", ["Eva Szekely", "Gustav Eje Henter", "Jonas Beskow", "Joakim Gustafson"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8026.html", 2, "interspeech", 2019], ["Spontaneous Conversational Speech Synthesis from Found Data", ["Eva Szekely", "Gustav Eje Henter", "Jonas Beskow", "Joakim Gustafson"], "https://doi.org/10.21437/Interspeech.2019-2836", 5, "interspeech", 2019]], "Ella Collins": [0, ["Use of Beiwe Smartphone App to Identify and Track Speech Decline in Amyotrophic Lateral Sclerosis (ALS)", ["Kathryn P. Connaghan", "Jordan R. Green", "Sabrina Paganoni", "James Chan", "Harli Weber", "Ella Collins", "Brian Richburg", "Marziye Eshghi", "Jukka-Pekka Onnela", "James D. Berry"], "https://doi.org/10.21437/Interspeech.2019-3126", 5, "interspeech", 2019]], "Yingke Zhu": [0, ["Mixup Learning Strategies for Text-Independent Speaker Verification", ["Yingke Zhu", "Tom Ko", "Brian Mak"], "https://doi.org/10.21437/Interspeech.2019-2250", 5, "interspeech", 2019]], "Keisuke Kinoshita": [0, ["Simultaneous Denoising and Dereverberation for Low-Latency Applications Using Frame-by-Frame Online Unified Convolutional Beamformer", ["Tomohiro Nakatani", "Keisuke Kinoshita"], "https://doi.org/10.21437/Interspeech.2019-1286", 5, "interspeech", 2019], ["End-to-End SpeakerBeam for Single Channel Target Speech Recognition", ["Marc Delcroix", "Shinji Watanabe", "Tsubasa Ochiai", "Keisuke Kinoshita", "Shigeki Karita", "Atsunori Ogawa", "Tomohiro Nakatani"], "https://doi.org/10.21437/Interspeech.2019-1856", 5, "interspeech", 2019], ["Multimodal SpeakerBeam: Single Channel Target Speech Extraction with Audio-Visual Speaker Clues", ["Tsubasa Ochiai", "Marc Delcroix", "Keisuke Kinoshita", "Atsunori Ogawa", "Tomohiro Nakatani"], "https://doi.org/10.21437/Interspeech.2019-1513", 5, "interspeech", 2019], ["Predicting Speech Intelligibility of Enhanced Speech Using Phone Accuracy of DNN-Based ASR System", ["Kenichi Arai", "Shoko Araki", "Atsunori Ogawa", "Keisuke Kinoshita", "Tomohiro Nakatani", "Katsuhiko Yamamoto", "Toshio Irino"], "https://doi.org/10.21437/Interspeech.2019-1381", 5, "interspeech", 2019]], "Abhinav Thanda": [0, ["Real Time Online Visual End Point Detection Using Unidirectional LSTM", ["Tanay Sharma", "Rohith Chandrashekar Aralikatti", "Dilip Kumar Margam", "Abhinav Thanda", "Sharad Roy", "Pujitha Appan Kandala", "Shankar M. Venkatesan"], "https://doi.org/10.21437/Interspeech.2019-3253", 5, "interspeech", 2019], ["Speaker Adaptation for Lip-Reading Using Visual Identity Vectors", ["Pujitha Appan Kandala", "Abhinav Thanda", "Dilip Kumar Margam", "Rohith Chandrashekar Aralikatti", "Tanay Sharma", "Sharad Roy", "Shankar M. Venkatesan"], "https://doi.org/10.21437/Interspeech.2019-3237", 5, "interspeech", 2019]], "Lenhart K. Schubert": [0, ["Investigating Linguistic and Semantic Features for Turn-Taking Prediction in Open-Domain Human-Computer Conversation", ["Seyedeh Zahra Razavi", "Benjamin Kane", "Lenhart K. Schubert"], "https://doi.org/10.21437/Interspeech.2019-3152", 5, "interspeech", 2019]], "Shao-Yen Tseng": [0, ["Predicting Behavior in Cancer-Afflicted Patient and Spouse Interactions Using Speech and Language", ["Sandeep Nallan Chakravarthula", "Haoqi Li", "Shao-Yen Tseng", "Maija Reblin", "Panayiotis G. Georgiou"], "https://doi.org/10.21437/Interspeech.2019-1888", 5, "interspeech", 2019]], "Song Yang": [0.020217030309140682, ["Knowledge-Based Linguistic Encoding for End-to-End Mandarin Text-to-Speech Synthesis", ["Jingbei Li", "Zhiyong Wu", "Runnan Li", "Pengpeng Zhi", "Song Yang", "Helen Meng"], "https://doi.org/10.21437/Interspeech.2019-1118", 5, "interspeech", 2019]], "Yingying Gao": [0, ["Code-Switching Sentence Generation by Bert and Generative Adversarial Networks", ["Yingying Gao", "Junlan Feng", "Ying Liu", "Leijing Hou", "Xin Pan", "Yong Ma"], "https://doi.org/10.21437/Interspeech.2019-2501", 5, "interspeech", 2019]], "Bing Yang": [0.0030677259201183915, ["Pre-Trained Text Representations for Improving Front-End Text Processing in Mandarin Text-to-Speech Synthesis", ["Bing Yang", "Jiaqi Zhong", "Shan Liu"], "https://doi.org/10.21437/Interspeech.2019-1418", 5, "interspeech", 2019]], "Qifeng Chen": [0, ["Speech Denoising with Deep Feature Losses", ["Francois G. Germain", "Qifeng Chen", "Vladlen Koltun"], "https://doi.org/10.21437/Interspeech.2019-1924", 5, "interspeech", 2019]], "Dongxiao Wang": [2.388601116502332e-18, ["A Modified Algorithm for Multiple Input Spectrogram Inversion", ["Dongxiao Wang", "Hirokazu Kameoka", "Koichi Shinoda"], "https://doi.org/10.21437/Interspeech.2019-3242", 5, "interspeech", 2019]], "Hosana Kamiyama": [0, ["Improving Conversation-Context Language Models with Multiple Spoken Language Understanding Models", ["Ryo Masumura", "Tomohiro Tanaka", "Atsushi Ando", "Hosana Kamiyama", "Takanobu Oba", "Satoshi Kobashikawa", "Yushi Aono"], "https://doi.org/10.21437/Interspeech.2019-1534", 5, "interspeech", 2019], ["Speech Emotion Recognition Based on Multi-Label Emotion Existence Model", ["Atsushi Ando", "Ryo Masumura", "Hosana Kamiyama", "Satoshi Kobashikawa", "Yushi Aono"], "https://doi.org/10.21437/Interspeech.2019-2524", 5, "interspeech", 2019]], "Kathleen Currie Hall": [0, ["SLP-AA: Tools for Sign Language Phonetic and Phonological Research", ["Roger Yu-Hsiang Lo", "Kathleen Currie Hall"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8028.html", 2, "interspeech", 2019]], "Abhinav Jain": [0, ["A Multi-Accent Acoustic Model Using Mixture of Experts for Speech Recognition", ["Abhinav Jain", "Vishwanath P. Singh", "Shakti P. Rath"], "https://doi.org/10.21437/Interspeech.2019-1667", 5, "interspeech", 2019]], "Jaime Lorenzo-Trueba": [0, ["Towards Achieving Robust Universal Neural Vocoding", ["Jaime Lorenzo-Trueba", "Thomas Drugman", "Javier Latorre", "Thomas Merritt", "Bartosz Putrycz", "Roberto Barra-Chicote", "Alexis Moinet", "Vatsal Aggarwal"], "https://doi.org/10.21437/Interspeech.2019-1424", 5, "interspeech", 2019]], "Louis-Philippe Morency": [0, ["Bag-of-Acoustic-Words for Mental Health Assessment: A Deep Autoencoding Approach", ["Wenchao Du", "Louis-Philippe Morency", "Jeffrey F. Cohn", "Alan W. Black"], "https://doi.org/10.21437/Interspeech.2019-3059", 5, "interspeech", 2019]], "Shubham Toshniwal": [0, ["Pre-Trained Text Embeddings for Enhanced Text-to-Speech Synthesis", ["Tomoki Hayashi", "Shinji Watanabe", "Tomoki Toda", "Kazuya Takeda", "Shubham Toshniwal", "Karen Livescu"], "https://doi.org/10.21437/Interspeech.2019-3177", 5, "interspeech", 2019]], "Lisa P. Mason": [0, ["The 2018 NIST Speaker Recognition Evaluation", ["Seyed Omid Sadjadi", "Craig S. Greenberg", "Elliot Singer", "Douglas A. Reynolds", "Lisa P. Mason", "Jaime Hernandez-Cordero"], "https://doi.org/10.21437/Interspeech.2019-1351", 5, "interspeech", 2019]], "Laura Spinu": [0, ["Articulatory Characteristics of Secondary Palatalization in Romanian Fricatives", ["Laura Spinu", "Maida Percival", "Alexei Kochetov"], "https://doi.org/10.21437/Interspeech.2019-3039", 5, "interspeech", 2019]], "Srinivas Bangalore": [0, ["Neural Transition Systems for Modeling Hierarchical Semantic Representations", ["Riyaz Ahmad Bhat", "John Chen", "Rashmi Prasad", "Srinivas Bangalore"], "https://doi.org/10.21437/Interspeech.2019-3075", 5, "interspeech", 2019]], "Shekhar Nayak": [0, ["Unsupervised Acoustic Segmentation and Clustering Using Siamese Network Embeddings", ["Saurabhchand Bhati", "Shekhar Nayak", "K. Sri Rama Murty", "Najim Dehak"], "https://doi.org/10.21437/Interspeech.2019-2981", 5, "interspeech", 2019]], "Sri Harish Mallidi": [0, ["Improving ASR Confidence Scores for Alexa Using Acoustic and Hypothesis Embeddings", ["Prakhar Swarup", "Roland Maas", "Sri Garimella", "Sri Harish Mallidi", "Bjorn Hoffmeister"], "https://doi.org/10.21437/Interspeech.2019-1241", 5, "interspeech", 2019], ["A Study for Improving Device-Directed Speech Detection Toward Frictionless Human-Machine Interaction", ["Che-Wei Huang", "Roland Maas", "Sri Harish Mallidi", "Bjorn Hoffmeister"], "https://doi.org/10.21437/Interspeech.2019-2840", 5, "interspeech", 2019]], "Raphael Winkelmann": [0, ["Styrian Dialect Classification: Comparing and Fusing Classifiers Based on a Feature Selection Using a Genetic Algorithm", ["Thomas Kisler", "Raphael Winkelmann", "Florian Schiel"], "https://doi.org/10.21437/Interspeech.2019-2540", 5, "interspeech", 2019]], "Xiaoke Qi": [0, ["Parameter-Transfer Learning for Low-Resource Individualization of Head-Related Transfer Functions", ["Xiaoke Qi", "Lu Wang"], "https://doi.org/10.21437/Interspeech.2019-2558", 5, "interspeech", 2019]], "Li Xu": [0, ["Diagnosing Dysarthria with Long Short-Term Memory Networks", ["Alex Mayle", "Zhiwei Mou", "Razvan C. Bunescu", "Sadegh Mirshekarian", "Li Xu", "Chang Liu"], "https://doi.org/10.21437/Interspeech.2019-2903", 5, "interspeech", 2019]], "Fernando Vieira": [0, ["Personalizing ASR for Dysarthric and Accented Speech with Limited Data", ["Joel Shor", "Dotan Emanuel", "Oran Lang", "Omry Tuval", "Michael Brenner", "Julie Cattiau", "Fernando Vieira", "Maeve McNally", "Taylor Charbonneau", "Melissa Nollstadt", "Avinatan Hassidim", "Yossi Matias"], "https://doi.org/10.21437/Interspeech.2019-1427", 5, "interspeech", 2019]], "Patrick L. Lange": [0, ["Automated Estimation of Oral Reading Fluency During Summer Camp e-Book Reading with MyTurnToRead", ["Anastassia Loukina", "Beata Beigman Klebanov", "Patrick L. Lange", "Yao Qian", "Binod Gyawali", "Nitin Madnani", "Abhinav Misra", "Klaus Zechner", "Zuowei Wang", "John Sabatini"], "https://doi.org/10.21437/Interspeech.2019-2889", 5, "interspeech", 2019]], "Kanishka Rao": [0, ["Large-Scale Visual Speech Recognition", ["Brendan Shillingford", "Yannis M. Assael", "Matthew W. Hoffman", "Thomas Paine", "Cian Hughes", "Utsav Prabhu", "Hank Liao", "Hasim Sak", "Kanishka Rao", "Lorrayne Bennett", "Marie Mulville", "Misha Denil", "Ben Coppin", "Ben Laurie", "Andrew W. Senior", "Nando de Freitas"], "https://doi.org/10.21437/Interspeech.2019-1669", 5, "interspeech", 2019]], "Eilon Reshef": [0, ["GECKO - A Tool for Effective Annotation of Human Conversations", ["Golan Levy", "Raquel Sitman", "Ido Amir", "Eduard Golshtein", "Ran Mochary", "Eilon Reshef", "Roi Reichart", "Omri Allouche"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8025.html", 2, "interspeech", 2019]], "Jason Fong": [0, ["Investigating the Robustness of Sequence-to-Sequence Text-to-Speech Models to Imperfectly-Transcribed Training Data", ["Jason Fong", "Pilar Oplustil Gallegos", "Zack Hodari", "Simon King"], "https://doi.org/10.21437/Interspeech.2019-1824", 5, "interspeech", 2019]], "Badr-Eddine Benkelfat": [0, ["Comparison of Telephone Recordings and Professional Microphone Recordings for Early Detection of Parkinson's Disease, Using Mel-Frequency Cepstral Coefficients with Gaussian Mixture Models", ["Laetitia Jeancolas", "Graziella Mangone", "Jean-Christophe Corvol", "Marie Vidailhet", "Stephane Lehericy", "Badr-Eddine Benkelfat", "Habib Benali", "Dijana Petrovska-Delacretaz"], "https://doi.org/10.21437/Interspeech.2019-2825", 5, "interspeech", 2019]], "Francesc Lluis": [0, ["End-to-End Music Source Separation: Is it Possible in the Waveform Domain?", ["Francesc Lluis", "Jordi Pons", "Xavier Serra"], "https://doi.org/10.21437/Interspeech.2019-1177", 5, "interspeech", 2019]], "Nao Hodoshima": [0, ["Effects of Urgent Speech and Congruent/Incongruent Text on Speech Intelligibility in Noise and Reverberation", ["Nao Hodoshima"], "https://doi.org/10.21437/Interspeech.2019-1902", 5, "interspeech", 2019]], "Yilin Pan": [0, ["Automatic Hierarchical Attention Neural Network for Detecting AD", ["Yilin Pan", "Bahman Mirheidari", "Markus Reuber", "Annalena Venneri", "Daniel Blackburn", "Heidi Christensen"], "https://doi.org/10.21437/Interspeech.2019-1799", 5, "interspeech", 2019]], "Sofia Cavaco": [0, ["Sustained Vowel Game: A Computer Therapy Game for Children with Dysphonia", ["Vanessa Lopes", "Joao Magalhaes", "Sofia Cavaco"], "https://doi.org/10.21437/Interspeech.2019-3017", 5, "interspeech", 2019]], "Yu-Han Shen": [0, ["Learning How to Listen: A Temporal-Frequential Attention Model for Sound Event Detection", ["Yu-Han Shen", "Ke-Xin He", "Wei-Qiang Zhang"], "https://doi.org/10.21437/Interspeech.2019-2045", 5, "interspeech", 2019], ["Hierarchical Pooling Structure for Weakly Labeled Sound Event Detection", ["Ke-Xin He", "Yu-Han Shen", "Wei-Qiang Zhang"], "https://doi.org/10.21437/Interspeech.2019-2049", 5, "interspeech", 2019]], "Anouschka Foltz": [0, ["Using Prosody to Discover Word Order Alternations in a Novel Language", ["Anouschka Foltz", "Sarah Cooper", "Tamsin M. McKelvey"], "https://doi.org/10.21437/Interspeech.2019-1183", 5, "interspeech", 2019]], "Charilaos Papaioannou": [0, ["Deep Hierarchical Fusion with Application in Sentiment Analysis", ["Efthymios Georgiou", "Charilaos Papaioannou", "Alexandros Potamianos"], "https://doi.org/10.21437/Interspeech.2019-3243", 5, "interspeech", 2019]], "Lei Xie": [0, ["Improved Speaker-Dependent Separation for CHiME-5 Challenge", ["Jian Wu", "Yong Xu", "Shi-Xiong Zhang", "Lianwu Chen", "Meng Yu", "Lei Xie", "Dong Yu"], "https://doi.org/10.21437/Interspeech.2019-1569", 5, "interspeech", 2019], ["Unsupervised Adaptation with Adversarial Dropout Regularization for Robust Speech Recognition", ["Pengcheng Guo", "Sining Sun", "Lei Xie"], "https://doi.org/10.21437/Interspeech.2019-2544", 5, "interspeech", 2019], ["A New GAN-Based End-to-End TTS Training Algorithm", ["Haohan Guo", "Frank K. Soong", "Lei He", "Lei Xie"], "https://doi.org/10.21437/Interspeech.2019-2176", 5, "interspeech", 2019], ["Building a Mixed-Lingual Neural TTS System with Only Monolingual Data", ["Liumeng Xue", "Wei Song", "Guanghui Xu", "Lei Xie", "Zhizheng Wu"], "https://doi.org/10.21437/Interspeech.2019-3191", 5, "interspeech", 2019], ["Towards Language-Universal Mandarin-English Speech Recognition", ["Shiliang Zhang", "Yuan Liu", "Ming Lei", "Bin Ma", "Lei Xie"], "https://doi.org/10.21437/Interspeech.2019-1365", 5, "interspeech", 2019], ["Adversarial Regularization for End-to-End Robust Speaker Verification", ["Qing Wang", "Pengcheng Guo", "Sining Sun", "Lei Xie", "John H. L. Hansen"], "https://doi.org/10.21437/Interspeech.2019-2983", 5, "interspeech", 2019], ["Exploiting Syntactic Features in a Parsed Tree to Improve End-to-End TTS", ["Haohan Guo", "Frank K. Soong", "Lei He", "Lei Xie"], "https://doi.org/10.21437/Interspeech.2019-2167", 5, "interspeech", 2019]], "Piotr Zelasko": [0, ["Avaya Conversational Intelligence: A Real-Time System for Spoken Language Understanding in Human-Human Call Center Conversations", ["Jan Mizgajski", "Adrian Szymczak", "Robert Glowski", "Piotr Szymanski", "Piotr Zelasko", "Lukasz Augustyniak", "Mikolaj Morzy", "Yishay Carmiel", "Jeff Hodson", "Lukasz Wojciak", "Daniel Smoczyk", "Adam Wrobel", "Bartosz Borowik", "Adam Artajew", "Marcin Baran", "Cezary Kwiatkowski", "Marzena Zyla-Hoppe"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8002.html", 2, "interspeech", 2019]], "Benjamin Ricaud": [0, ["Evaluating Audiovisual Source Separation in the Context of Video Conferencing", ["Berkay Inan", "Milos Cernak", "Helmut Grabner", "Helena Peic Tukuljac", "Rodrigo C. G. Pena", "Benjamin Ricaud"], "https://doi.org/10.21437/Interspeech.2019-2671", 5, "interspeech", 2019]], "Thomas Hain": [0, ["Detecting Mismatch Between Speech and Transcription Using Cross-Modal Attention", ["Qiang Huang", "Thomas Hain"], "https://doi.org/10.21437/Interspeech.2019-2125", 5, "interspeech", 2019], ["Learning Temporal Clusters Using Capsule Routing for Speech Emotion Recognition", ["Md Asif Jalal", "Erfan Loweimi", "Roger K. Moore", "Thomas Hain"], "https://doi.org/10.21437/Interspeech.2019-3068", 5, "interspeech", 2019], ["Latent Dirichlet Allocation Based Acoustic Data Selection for Automatic Speech Recognition", ["Mortaza Doulaty", "Thomas Hain"], "https://doi.org/10.21437/Interspeech.2019-1797", 5, "interspeech", 2019]], "Zhenghao Jin": [1.939148223505799e-12, ["Development of Emotion Rankers Based on Intended and Perceived Emotion Labels", ["Zhenghao Jin", "Houwei Cao"], "https://doi.org/10.21437/Interspeech.2019-1831", 5, "interspeech", 2019]], "Haritha U. G.": [0, ["Design and Development of a Multi-Lingual Speech Corpora (TaMaR-EmoDB) for Emotion Analysis", ["Rajeev Rajan", "Haritha U. G.", "Sujitha A. C.", "Rejisha T. M."], "https://doi.org/10.21437/Interspeech.2019-2034", 5, "interspeech", 2019]], "Carsten Eulitz": [0, ["The Processing of Prosodic Cues to Rhetorical Question Interpretation: Psycholinguistic and Neurolinguistics Evidence", ["Mariya Kharaman", "Manluolan Xu", "Carsten Eulitz", "Bettina Braun"], "https://doi.org/10.21437/Interspeech.2019-2528", 5, "interspeech", 2019]], "Tatsuya Komatsu": [0, ["Variational Bayesian Multi-Channel Speech Dereverberation Under Noisy Environments with Probabilistic Convolutive Transfer Function", ["Masahito Togami", "Tatsuya Komatsu"], "https://doi.org/10.21437/Interspeech.2019-1220", 5, "interspeech", 2019], ["Multichannel Loss Function for Supervised Speech Source Separation by Mask-Based Beamforming", ["Yoshiki Masuyama", "Masahito Togami", "Tatsuya Komatsu"], "https://doi.org/10.21437/Interspeech.2019-1289", 5, "interspeech", 2019]], "Wilfried Michel": [0, ["RWTH ASR Systems for LibriSpeech: Hybrid vs Attention", ["Christoph Luscher", "Eugen Beck", "Kazuki Irie", "Markus Kitza", "Wilfried Michel", "Albert Zeyer", "Ralf Schluter", "Hermann Ney"], "https://doi.org/10.21437/Interspeech.2019-1780", 5, "interspeech", 2019], ["Comparison of Lattice-Free and Lattice-Based Sequence Discriminative Training Criteria for LVCSR", ["Wilfried Michel", "Ralf Schluter", "Hermann Ney"], "https://doi.org/10.21437/Interspeech.2019-2254", 5, "interspeech", 2019]], "Anoosha Baxi": [0, ["Using Ultrasound Imaging to Create Augmented Visual Biofeedback for Articulatory Practice", ["Colin T. Annand", "Maurice Lamb", "Sarah Dugan", "Sarah R. Li", "Hannah M. Woeste", "T. Douglas Mast", "Michael A. Riley", "Jack A. Masterson", "Neeraja Mahalingam", "Kathryn J. Eary", "Caroline Spencer", "Suzanne Boyce", "Stephanie Jackson", "Anoosha Baxi", "Renee Seward"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8036.html", 2, "interspeech", 2019]], "Manjunath Mulimani": [0, ["Locality-Constrained Linear Coding Based Fused Visual Features for Robust Acoustic Event Classification", ["Manjunath Mulimani", "Shashidhar G. Koolagudi"], "https://doi.org/10.21437/Interspeech.2019-1421", 5, "interspeech", 2019]], "Michel-Pierre Jansen": [0, ["Towards an Annotation Scheme for Complex Laughter in Speech Corpora", ["Khiet P. Truong", "Jurgen Trouvain", "Michel-Pierre Jansen"], "https://doi.org/10.21437/Interspeech.2019-1557", 5, "interspeech", 2019]], "Leonid Velikovich": [0, ["Contextual Recovery of Out-of-Lattice Named Entities in Automatic Speech Recognition", ["Jack Serrino", "Leonid Velikovich", "Petar S. Aleksic", "Cyril Allauzen"], "https://doi.org/10.21437/Interspeech.2019-2962", 5, "interspeech", 2019]], "Leibny Paola Garcia-Perera": [0, ["Advances in Automatic Speech Recognition for Child Speech Using Factored Time Delay Neural Network", ["Fei Wu", "Leibny Paola Garcia-Perera", "Daniel Povey", "Sanjeev Khudanpur"], "https://doi.org/10.21437/Interspeech.2019-2980", 5, "interspeech", 2019], ["Multi-PLDA Diarization on Children's Speech", ["Jiamin Xie", "Leibny Paola Garcia-Perera", "Daniel Povey", "Sanjeev Khudanpur"], "https://doi.org/10.21437/Interspeech.2019-2961", 5, "interspeech", 2019], ["State-of-the-Art Speaker Recognition for Telephone and Video Speech: The JHU-MIT Submission for NIST SRE18", ["Jesus Villalba", "Nanxin Chen", "David Snyder", "Daniel Garcia-Romero", "Alan McCree", "Gregory Sell", "Jonas Borgstrom", "Fred Richardson", "Suwon Shon", "Francois Grondin", "Reda Dehak", "Leibny Paola Garcia-Perera", "Daniel Povey", "Pedro A. Torres-Carrasquillo", "Sanjeev Khudanpur", "Najim Dehak"], "https://doi.org/10.21437/Interspeech.2019-2713", 5, "interspeech", 2019]], "Serge Berger": [0, ["Speech-Based Web Navigation for Limited Mobility Users", ["Vasiliy Radostev", "Serge Berger", "Justin Tabrizi", "Pasha Kamyshev", "Hisami Suzuki"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8042.html", 2, "interspeech", 2019]], "Sriram Ganapathy": [0, ["The Second DIHARD Diarization Challenge: Dataset, Task, and Baselines", ["Neville Ryant", "Kenneth Church", "Christopher Cieri", "Alejandrina Cristia", "Jun Du", "Sriram Ganapathy", "Mark Liberman"], "https://doi.org/10.21437/Interspeech.2019-1268", 5, "interspeech", 2019], ["LEAP Diarization System for the Second DIHARD Challenge", ["Prachi Singh", "Harsha Vardhan", "Sriram Ganapathy", "A. Kanagasundaram"], "https://doi.org/10.21437/Interspeech.2019-2716", 5, "interspeech", 2019], ["Attention Based Hybrid i-Vector BLSTM Model for Language Recognition", ["Bharat Padi", "Anand Mohan", "Sriram Ganapathy"], "https://doi.org/10.21437/Interspeech.2019-2371", 5, "interspeech", 2019], ["Active Learning Methods for Low Resource End-to-End Speech Recognition", ["Karan Malhotra", "Shubham Bansal", "Sriram Ganapathy"], "https://doi.org/10.21437/Interspeech.2019-2316", 5, "interspeech", 2019], ["Unsupervised Raw Waveform Representation Learning for ASR", ["Purvi Agrawal", "Sriram Ganapathy"], "https://doi.org/10.21437/Interspeech.2019-2652", 5, "interspeech", 2019]], "Francois G. Germain": [0, ["Speech Denoising with Deep Feature Losses", ["Francois G. Germain", "Qifeng Chen", "Vladlen Koltun"], "https://doi.org/10.21437/Interspeech.2019-1924", 5, "interspeech", 2019]], "Dimitri Kanvesky": [0, ["Parrotron: An End-to-End Speech-to-Speech Conversion Model and its Applications to Hearing-Impaired Speech and Speech Separation", ["Fadi Biadsy", "Ron J. Weiss", "Pedro J. Moreno", "Dimitri Kanvesky", "Ye Jia"], "https://doi.org/10.21437/Interspeech.2019-1789", 5, "interspeech", 2019]], "Dotan Emanuel": [0, ["Personalizing ASR for Dysarthric and Accented Speech with Limited Data", ["Joel Shor", "Dotan Emanuel", "Oran Lang", "Omry Tuval", "Michael Brenner", "Julie Cattiau", "Fernando Vieira", "Maeve McNally", "Taylor Charbonneau", "Melissa Nollstadt", "Avinatan Hassidim", "Yossi Matias"], "https://doi.org/10.21437/Interspeech.2019-1427", 5, "interspeech", 2019]], "Anton Noll": [0, ["Sound Tools eXtended (STx) 5.0 - A Powerful Sound Analysis Tool Optimized for Speech", ["Anton Noll", "Jonathan Stuefer", "Nicola Klingler", "Hannah Leykum", "Carina Lozo", "Jan Luttenberger", "Michael Pucher", "Carolin Schmid"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8022.html", 2, "interspeech", 2019]], "Ivan Kraljevski": [0, ["Cross-Lingual Transfer Learning for Affective Spoken Dialogue Systems", ["Kristijan Gjoreski", "Aleksandar Gjoreski", "Ivan Kraljevski", "Diane Hirschfeld"], "https://doi.org/10.21437/Interspeech.2019-2163", 5, "interspeech", 2019]], "Sharad Roy": [0, ["Real Time Online Visual End Point Detection Using Unidirectional LSTM", ["Tanay Sharma", "Rohith Chandrashekar Aralikatti", "Dilip Kumar Margam", "Abhinav Thanda", "Sharad Roy", "Pujitha Appan Kandala", "Shankar M. Venkatesan"], "https://doi.org/10.21437/Interspeech.2019-3253", 5, "interspeech", 2019], ["Speaker Adaptation for Lip-Reading Using Visual Identity Vectors", ["Pujitha Appan Kandala", "Abhinav Thanda", "Dilip Kumar Margam", "Rohith Chandrashekar Aralikatti", "Tanay Sharma", "Sharad Roy", "Shankar M. Venkatesan"], "https://doi.org/10.21437/Interspeech.2019-3237", 5, "interspeech", 2019]], "Peter Birkholz": [0, ["Perceptual Optimization of an Enhanced Geometric Vocal Fold Model for Articulatory Speech Synthesis", ["Peter Birkholz", "Susanne Drechsel", "Simon Stone"], "https://doi.org/10.21437/Interspeech.2019-2410", 5, "interspeech", 2019], ["Articulatory Copy Synthesis Based on a Genetic Algorithm", ["Yingming Gao", "Simon Stone", "Peter Birkholz"], "https://doi.org/10.21437/Interspeech.2019-1334", 5, "interspeech", 2019]], "Kazuhito Koishida": [0, ["Sound Event Detection in Multichannel Audio Using Convolutional Time-Frequency-Channel Squeeze and Excitation", ["Wei Xia", "Kazuhito Koishida"], "https://doi.org/10.21437/Interspeech.2019-1860", 5, "interspeech", 2019]], "Patti Adank": [0, ["Talker Intelligibility and Listening Effort with Temporally Modified Speech", ["Maximillian Paulus", "Valerie Hazan", "Patti Adank"], "https://doi.org/10.21437/Interspeech.2019-1402", 5, "interspeech", 2019]], "Mostafa El-Khamy": [0, ["Deep Multitask Acoustic Echo Cancellation", ["Amin Fazel", "Mostafa El-Khamy", "Jungwon Lee"], "https://doi.org/10.21437/Interspeech.2019-2908", 5, "interspeech", 2019]], "Lukasz Dudziak": [0, ["ShrinkML: End-to-End ASR Model Compression Using Reinforcement Learning", ["Lukasz Dudziak", "Mohamed S. Abdelfattah", "Ravichander Vipperla", "Stefanos Laskaridis", "Nicholas D. Lane"], "https://doi.org/10.21437/Interspeech.2019-2811", 5, "interspeech", 2019]], "Aravind Illa": [0, ["An Investigation on Speaker Specific Articulatory Synthesis with Speaker Independent Articulatory Inversion", ["Aravind Illa", "Prasanta Kumar Ghosh"], "https://doi.org/10.21437/Interspeech.2019-2664", 5, "interspeech", 2019], ["Acoustic and Articulatory Feature Based Speech Rate Estimation Using a Convolutional Dense Neural Network", ["Renuka Mannem", "Jhansi Mallela", "Aravind Illa", "Prasanta Kumar Ghosh"], "https://doi.org/10.21437/Interspeech.2019-2295", 5, "interspeech", 2019]], "Adam Chylek": [0, ["Multimodal Dialog with the MALACH Audiovisual Archive", ["Adam Chylek", "Lubos Smidl", "Jan Svec"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8011.html", 2, "interspeech", 2019], ["Framework for Conducting Tasks Requiring Human Assessment", ["Martin Gruber", "Adam Chylek", "Jindrich Matousek"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8009.html", 2, "interspeech", 2019]], "Shigeki Karita": [0, ["End-to-End SpeakerBeam for Single Channel Target Speech Recognition", ["Marc Delcroix", "Shinji Watanabe", "Tsubasa Ochiai", "Keisuke Kinoshita", "Shigeki Karita", "Atsunori Ogawa", "Tomohiro Nakatani"], "https://doi.org/10.21437/Interspeech.2019-1856", 5, "interspeech", 2019], ["Improving Transformer-Based End-to-End Speech Recognition with Connectionist Temporal Classification and Language Model Integration", ["Shigeki Karita", "Nelson Enrique Yalta Soplin", "Shinji Watanabe", "Marc Delcroix", "Atsunori Ogawa", "Tomohiro Nakatani"], "https://doi.org/10.21437/Interspeech.2019-1938", 5, "interspeech", 2019], ["Improved Deep Duel Model for Rescoring N-Best Speech Recognition List Using Backward LSTMLM and Ensemble Encoders", ["Atsunori Ogawa", "Marc Delcroix", "Shigeki Karita", "Tomohiro Nakatani"], "https://doi.org/10.21437/Interspeech.2019-1949", 5, "interspeech", 2019]]}