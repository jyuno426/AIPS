{"Corentin Dancette": [0, ["Sampling Strategies in Siamese Networks for Unsupervised Speech Representation Learning", ["Rachid Riad", "Corentin Dancette", "Julien Karadayi", "Neil Zeghidour", "Thomas Schatz", "Emmanuel Dupoux"], "https://doi.org/10.21437/Interspeech.2018-2384", 5, "interspeech", 2018]], "Jing Han": [0.0677884966135025, ["Evolving Learning for Analysing Mood-Related Infant Vocalisation", ["Zixing Zhang", "Jing Han", "Kun Qian", "Bjorn W. Schuller"], "https://doi.org/10.21437/Interspeech.2018-1914", 5, "interspeech", 2018], ["Bags in Bag: Generating Context-Aware Bags for Tracking Emotions from Speech", ["Jing Han", "Zixing Zhang", "Maximilian Schmitt", "Zhao Ren", "Fabien Ringeval", "Bjorn W. Schuller"], "https://doi.org/10.21437/Interspeech.2018-996", 5, "interspeech", 2018]], "Ganesh Ramakrishnan": [0, ["Time Aggregation Operators for Multi-label Audio Event Detection", ["Pankaj Joshi", "Digvijaysingh Gautam", "Ganesh Ramakrishnan", "Preethi Jyothi"], "https://doi.org/10.21437/Interspeech.2018-1637", 5, "interspeech", 2018]], "Sei Ueno": [0, ["Multi-task Learning with Augmentation Strategy for Acoustic-to-word Attention-based Encoder-decoder Speech Recognition", ["Takafumi Moriya", "Sei Ueno", "Yusuke Shinohara", "Marc Delcroix", "Yoshikazu Yamaguchi", "Yushi Aono"], "https://doi.org/10.21437/Interspeech.2018-1866", 5, "interspeech", 2018], ["Encoder Transfer for Attention-based Acoustic-to-word Speech Recognition", ["Sei Ueno", "Takafumi Moriya", "Masato Mimura", "Shinsuke Sakai", "Yusuke Shinohara", "Yoshikazu Yamaguchi", "Yushi Aono", "Tatsuya Kawahara"], "https://doi.org/10.21437/Interspeech.2018-1424", 5, "interspeech", 2018]], "Mugdha Pandya": [0, ["A Study of Lexical and Prosodic Cues to Segmentation in a Hindi-English Code-switched Discourse", ["Preeti Rao", "Mugdha Pandya", "Kamini Sabu", "Kanhaiya Kumar", "Nandini Bondale"], "https://doi.org/10.21437/Interspeech.2018-1600", 5, "interspeech", 2018]], "Jordi Luque": [0, ["Lightly Supervised vs. Semi-supervised Training of Acoustic Model on Luxembourgish for Low-resource Automatic Speech Recognition", ["Karel Vesely", "Carlos Segura", "Igor Szoke", "Jordi Luque", "Jan Cernocky"], "https://doi.org/10.21437/Interspeech.2018-2361", 5, "interspeech", 2018]], "Sandeep Nallan Chakravarthula": [0, ["Modeling Interpersonal Influence of Verbal Behavior in Couples Therapy Dyadic Interactions", ["Sandeep Nallan Chakravarthula", "Brian R. Baucom", "Panayiotis G. Georgiou"], "https://doi.org/10.21437/Interspeech.2018-1562", 5, "interspeech", 2018]], "Victor R. Martinez": [0, ["Language Features for Automated Evaluation of Cognitive Behavior Psychotherapy Sessions", ["Nikolaos Flemotomos", "Victor R. Martinez", "James Gibson", "David C. Atkins", "Torrey Creed", "Shrikanth Narayanan"], "https://doi.org/10.21437/Interspeech.2018-1518", 5, "interspeech", 2018]], "Nattanun Chanchaochai": [0, ["GlobalTIMIT: Acoustic-Phonetic Datasets for the World's Languages", ["Nattanun Chanchaochai", "Christopher Cieri", "Japhet Debrah", "Hongwei Ding", "Yue Jiang", "Sishi Liao", "Mark Liberman", "Jonathan Wright", "Jiahong Yuan", "Juhong Zhan", "Yuqing Zhan"], "https://doi.org/10.21437/Interspeech.2018-1185", 5, "interspeech", 2018]], "Alessandro DAusilio": [0, ["Analyzing Vocal Tract Movements During Speech Accommodation", ["Sankar Mukherjee", "Thierry Legou", "Leonardo Lancia", "Pauline Hilt", "Alice Tomassini", "Luciano Fadiga", "Alessandro DAusilio", "Leonardo Badino", "Noel Nguyen"], "https://doi.org/10.21437/Interspeech.2018-2084", 5, "interspeech", 2018]], "Julien Karadayi": [0, ["The ACLEW DiViMe: An Easy-to-use Diarization Tool", ["Adrien Le Franc", "Eric Riebling", "Julien Karadayi", "Yun Wang", "Camila Scaff", "Florian Metze", "Alejandrina Cristia"], "https://doi.org/10.21437/Interspeech.2018-2324", 5, "interspeech", 2018], ["Sampling Strategies in Siamese Networks for Unsupervised Speech Representation Learning", ["Rachid Riad", "Corentin Dancette", "Julien Karadayi", "Neil Zeghidour", "Thomas Schatz", "Emmanuel Dupoux"], "https://doi.org/10.21437/Interspeech.2018-2384", 5, "interspeech", 2018], ["Learning Word Embeddings: Unsupervised Methods for Fixed-size Representations of Variable-length Speech Segments", ["Nils Holzenberger", "Mingxing Du", "Julien Karadayi", "Rachid Riad", "Emmanuel Dupoux"], "https://doi.org/10.21437/Interspeech.2018-2364", 5, "interspeech", 2018]], "Adrian E. G. Huber": [0, ["Speaker Activity Detection and Minimum Variance Beamforming for Source Separation", ["Enea Ceolini", "Jithendar Anumula", "Adrian E. G. Huber", "Ilya Kiselev", "Shih-Chii Liu"], "https://doi.org/10.21437/Interspeech.2018-1606", 5, "interspeech", 2018]], "Bo Xu": [0, ["Syllable-Based Sequence-to-Sequence Speech Recognition with the Transformer in Mandarin Chinese", ["Shiyu Zhou", "Linhao Dong", "Shuang Xu", "Bo Xu"], "https://doi.org/10.21437/Interspeech.2018-1107", 5, "interspeech", 2018], ["Extending Recurrent Neural Aligner for Streaming End-to-End Speech Recognition in Mandarin", ["Linhao Dong", "Shiyu Zhou", "Wei Chen", "Bo Xu"], "https://doi.org/10.21437/Interspeech.2018-1086", 5, "interspeech", 2018], ["Single-channel Speech Dereverberation via Generative Adversarial Training", ["Chenxing Li", "Tieqiang Wang", "Shuang Xu", "Bo Xu"], "https://doi.org/10.21437/Interspeech.2018-1234", 5, "interspeech", 2018]], "Yunxin Zhao": [0, ["A Probability Weighted Beamformer for Noise Robust ASR", ["Suliang Bu", "Yunxin Zhao", "Mei-Yuh Hwang", "Sining Sun"], "https://doi.org/10.21437/Interspeech.2018-2427", 5, "interspeech", 2018]], "Thanh-Le Ha": [1.1013351297606278e-06, ["Low-Latency Neural Speech Translation", ["Jan Niehues", "Ngoc-Quan Pham", "Thanh-Le Ha", "Matthias Sperber", "Alex Waibel"], "https://doi.org/10.21437/Interspeech.2018-1055", 5, "interspeech", 2018]], "Sukhyun Cho": [0.7975555807352066, ["Training Utterance-level Embedding Networks for Speaker Identification and Verification", ["Heewoong Park", "Sukhyun Cho", "Kyubyong Park", "Namju Kim", "Jonghun Park"], "https://doi.org/10.21437/Interspeech.2018-1044", 5, "interspeech", 2018]], "Rui Zhao": [0, ["Improved Training for Online End-to-end Speech Recognition Systems", ["Suyoun Kim", "Michael L. Seltzer", "Jinyu Li", "Rui Zhao"], "https://doi.org/10.21437/Interspeech.2018-2517", 5, "interspeech", 2018]], "Alyssa Alcorn": [0, ["Recognition of Echolalic Autistic Child Vocalisations Utilising Convolutional Recurrent Neural Networks", ["Shahin Amiriparian", "Alice Baird", "Sahib Julka", "Alyssa Alcorn", "Sandra Ottl", "Suncica Petrovic", "Eloise Ainger", "Nicholas Cummins", "Bjorn W. Schuller"], "https://doi.org/10.21437/Interspeech.2018-1772", 5, "interspeech", 2018]], "Muhammad Bilal Saleem": [0, ["Rapid Collection of Spontaneous Speech Corpora Using Telephonic Community Forums", ["Agha Ali Raza", "Awais Athar", "Shan Randhawa", "Zain Tariq", "Muhammad Bilal Saleem", "Haris Bin Zia", "Umar Saif", "Roni Rosenfeld"], "https://doi.org/10.21437/Interspeech.2018-1139", 5, "interspeech", 2018]], "Hao Zhang": [0, ["Cross-Corpora Convolutional Deep Neural Network Dereverberation Preprocessing for Speaker Verification and Speech Enhancement", ["Peter Guzewich", "Stephen A. Zahorian", "Xiao Chen", "Hao Zhang"], "https://doi.org/10.21437/Interspeech.2018-2238", 5, "interspeech", 2018], ["Deep Learning for Acoustic Echo Cancellation in Noisy and Double-Talk Scenarios", ["Hao Zhang", "DeLiang Wang"], "https://doi.org/10.21437/Interspeech.2018-1484", 5, "interspeech", 2018]], "Yong Liu": [0, ["Compact Feedforward Sequential Memory Networks for Small-footprint Keyword Spotting", ["Mengzhe Chen", "Shiliang Zhang", "Ming Lei", "Yong Liu", "Haitao Yao", "Jie Gao"], "https://doi.org/10.21437/Interspeech.2018-1204", 5, "interspeech", 2018]], "Adam Coates": [0, ["Cold Fusion: Training Seq2Seq Models Together with Language Models", ["Anuroop Sriram", "Heewoo Jun", "Sanjeev Satheesh", "Adam Coates"], "https://doi.org/10.21437/Interspeech.2018-1392", 5, "interspeech", 2018]], "Djegdjiga Amazouz": [0, ["Studying Vowel Variation in French-Algerian Arabic Code-switched Speech", ["Jane Wottawa", "Djegdjiga Amazouz", "Martine Adda-Decker", "Lori Lamel"], "https://doi.org/10.21437/Interspeech.2018-2381", 5, "interspeech", 2018]], "Pengcheng Li": [0, ["An Attention Pooling Based Representation Learning Method for Speech Emotion Recognition", ["Pengcheng Li", "Yan Song", "Ian Vince McLoughlin", "Wu Guo", "Lirong Dai"], "https://doi.org/10.21437/Interspeech.2018-1242", 5, "interspeech", 2018]], "Hong Ye": [0.004149170592427254, ["Active Learning for LF-MMI Trained Neural Networks in ASR", ["Yanhua Long", "Hong Ye", "Yijie Li", "Jiaen Liang"], "https://doi.org/10.21437/Interspeech.2018-1162", 5, "interspeech", 2018]], "Yi Gao": [0, ["Text-Dependent Speech Enhancement for Small-Footprint Robust Keyword Detection", ["Meng Yu", "Xuan Ji", "Yi Gao", "Lianwu Chen", "Jie Chen", "Jimeng Zheng", "Dan Su", "Dong Yu"], "https://doi.org/10.21437/Interspeech.2018-1668", 5, "interspeech", 2018]], "Abeer Alwan": [0, ["Using Voice Quality Supervectors for Affect Identification", ["Soo Jin Park", "Amber Afshan", "Zhi Ming Chua", "Abeer Alwan"], "https://doi.org/10.21437/Interspeech.2018-1401", 5, "interspeech", 2018], ["On the Difficulties of Automatic Speech Recognition for Kindergarten-Aged Children", ["Gary Yeung", "Abeer Alwan"], "https://doi.org/10.21437/Interspeech.2018-2297", 5, "interspeech", 2018], ["Effectiveness of Voice Quality Features in Detecting Depression", ["Amber Afshan", "Jinxi Guo", "Soo Jin Park", "Vijay Ravi", "Jonathan Flint", "Abeer Alwan"], "https://doi.org/10.21437/Interspeech.2018-1399", 5, "interspeech", 2018], ["Filter Sampling and Combination CNN (FSC-CNN): A Compact CNN Model for Small-footprint ASR Acoustic Modeling Using Raw Waveforms", ["Jinxi Guo", "Ning Xu", "Xin Chen", "Yang Shi", "Kaiyuan Xu", "Abeer Alwan"], "https://doi.org/10.21437/Interspeech.2018-1370", 5, "interspeech", 2018]], "Yishay Carmiel": [0, ["Deep Neural Networks for Emotion Recognition Combining Audio and Transcripts", ["Jaejin Cho", "Raghavendra Pappagari", "Purva Kulkarni", "Jesus Villalba", "Yishay Carmiel", "Najim Dehak"], "https://doi.org/10.21437/Interspeech.2018-2466", 5, "interspeech", 2018], ["Punctuation Prediction Model for Conversational Speech", ["Piotr Zelasko", "Piotr Szymanski", "Jan Mizgajski", "Adrian Szymczak", "Yishay Carmiel", "Najim Dehak"], "https://doi.org/10.21437/Interspeech.2018-1096", 5, "interspeech", 2018]], "Gaoyan Zhang": [0, ["Revealing Spatiotemporal Brain Dynamics of Speech Production Based on EEG and Eye Movement", ["Bin Zhao", "Jinfeng Huang", "Gaoyan Zhang", "Jianwu Dang", "Minbo Chen", "YingjianFu", "Longbiao Wang"], "https://doi.org/10.21437/Interspeech.2018-1908", 5, "interspeech", 2018]], "Pramit Saha": [0, ["Towards Automatic Speech Identification from Vocal Tract Shape Dynamics in Real-time MRI", ["Pramit Saha", "Praneeth Srungarapu", "Sidney Fels"], "https://doi.org/10.21437/Interspeech.2018-2537", 5, "interspeech", 2018]], "Diego Augusto Silva": [0, ["Joint Discriminative Embedding Learning, Speech Activity and Overlap Detection for the DIHARD Speaker Diarization Challenge", ["Valter Akira Miasato Filho", "Diego Augusto Silva", "Luis Gustavo Depra Cuozzo"], "https://doi.org/10.21437/Interspeech.2018-2304", 5, "interspeech", 2018]], "Alan Wrench": [0, ["UltraSuite: A Repository of Ultrasound and Acoustic Data from Child Speech Therapy Sessions", ["Aciel Eshky", "Manuel Sam Ribeiro", "Joanne Cleland", "Korin Richmond", "Zoe Roxburgh", "James M. Scobbie", "Alan Wrench"], "https://doi.org/10.21437/Interspeech.2018-1736", 5, "interspeech", 2018]], "Huai-Hung Huang": [0, ["Follow-up Question Generation Using Pattern-based Seq2seq with a Small Corpus for Interview Coaching", ["Ming-Hsiang Su", "Chung-Hsien Wu", "Kun-Yi Huang", "Qian-Bei Hong", "Huai-Hung Huang"], "https://doi.org/10.21437/Interspeech.2018-1007", 5, "interspeech", 2018]], "Doris Mucke": [0, ["Structural Effects on Properties of Consonantal Gestures in Tashlhiyt", ["Anne Hermes", "Doris Mucke", "Bastian Auris", "Rachid Ridouane"], "https://doi.org/10.21437/Interspeech.2018-1074", 5, "interspeech", 2018], ["Age-related Effects on Sensorimotor Control of Speech Production", ["Anne Hermes", "Jane Mertens", "Doris Mucke"], "https://doi.org/10.21437/Interspeech.2018-1233", 5, "interspeech", 2018]], "Mark Liberman": [0, ["GlobalTIMIT: Acoustic-Phonetic Datasets for the World's Languages", ["Nattanun Chanchaochai", "Christopher Cieri", "Japhet Debrah", "Hongwei Ding", "Yue Jiang", "Sishi Liao", "Mark Liberman", "Jonathan Wright", "Jiahong Yuan", "Juhong Zhan", "Yuqing Zhan"], "https://doi.org/10.21437/Interspeech.2018-1185", 5, "interspeech", 2018]], "Yu Gu": [0.002284156798850745, ["Multi-task WaveNet: A Multi-task Generative Model for Statistical Parametric Speech Synthesis without Fundamental Frequency Conditions", ["Yu Gu", "Yongguo Kang"], "https://doi.org/10.21437/Interspeech.2018-1506", 5, "interspeech", 2018]], "Ashutosh Pandey": [0, ["A New Framework for Supervised Speech Enhancement in the Time Domain", ["Ashutosh Pandey", "DeLiang Wang"], "https://doi.org/10.21437/Interspeech.2018-1223", 5, "interspeech", 2018]], "Julien Tardieu": [0, ["Perceptual and Automatic Evaluations of the Intelligibility of Speech Degraded by Noise Induced Hearing Loss Simulation", ["Imed Laaridh", "Julien Tardieu", "Cynthia Magnen", "Pascal Gaillard", "Jerome Farinas", "Julien Pinquier"], "https://doi.org/10.21437/Interspeech.2018-1264", 5, "interspeech", 2018]], "Thierry Legou": [0, ["Analyzing Vocal Tract Movements During Speech Accommodation", ["Sankar Mukherjee", "Thierry Legou", "Leonardo Lancia", "Pauline Hilt", "Alice Tomassini", "Luciano Fadiga", "Alessandro DAusilio", "Leonardo Badino", "Noel Nguyen"], "https://doi.org/10.21437/Interspeech.2018-2084", 5, "interspeech", 2018]], "Qian-Bei Hong": [8.622959013493414e-10, ["Follow-up Question Generation Using Pattern-based Seq2seq with a Small Corpus for Interview Coaching", ["Ming-Hsiang Su", "Chung-Hsien Wu", "Kun-Yi Huang", "Qian-Bei Hong", "Huai-Hung Huang"], "https://doi.org/10.21437/Interspeech.2018-1007", 5, "interspeech", 2018]], "Prasad Tapkir": [0, ["Novel Empirical Mode Decomposition Cepstral Features for Replay Spoof Detection", ["Prasad Tapkir", "Hemant A. Patil"], "https://doi.org/10.21437/Interspeech.2018-1661", 5, "interspeech", 2018]], "Peter Smit": [0, ["Captaina: Integrated Pronunciation Practice and Data Collection Portal", ["Aku Rouhe", "Reima Karhila", "Aija Elg", "Minnaleena Toivola", "Peter Smit", "Anna-Riikka Smolander", "Mikko Kurimo"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3015.html", 2, "interspeech", 2018]], "Saudah Namyalo": [0, ["A First Investigation of the Timing of Turn-taking in Ruuli", ["Tuarik Buanzur", "Margaret Zellers", "Saudah Namyalo", "Alena Witzlack-Makarevich"], "https://doi.org/10.21437/Interspeech.2018-1254", 5, "interspeech", 2018]], "Soman K. P": [0, ["Improved Epoch Extraction from Telephonic Speech Using Chebfun and Zero Frequency Filtering", ["B. Ganga Gowri", "Soman K. P", "D. Govind"], "https://doi.org/10.21437/Interspeech.2018-1173", 5, "interspeech", 2018]], "Loren Lugosch": [0, ["Tone Recognition Using Lifters and CTC", ["Loren Lugosch", "Vikrant Singh Tomar"], "https://doi.org/10.21437/Interspeech.2018-2293", 5, "interspeech", 2018]], "Vishnu Vidyadhara Raju Vegesna": [0, ["An Exploration towards Joint Acoustic Modeling for Indian Languages: IIIT-H Submission for Low Resource Speech Recognition Challenge for Indian Languages, INTERSPEECH 2018", ["Hari Krishna Vydana", "Krishna Gurugubelli", "Vishnu Vidyadhara Raju Vegesna", "Anil Kumar Vuppala"], "https://doi.org/10.21437/Interspeech.2018-1584", 5, "interspeech", 2018]], "Jane Wottawa": [0, ["Studying Vowel Variation in French-Algerian Arabic Code-switched Speech", ["Jane Wottawa", "Djegdjiga Amazouz", "Martine Adda-Decker", "Lori Lamel"], "https://doi.org/10.21437/Interspeech.2018-2381", 5, "interspeech", 2018]], "Alan McCree": [0, ["Diarization is Hard: Some Experiences and Lessons Learned for the JHU Team in the Inaugural DIHARD Challenge", ["Gregory Sell", "David Snyder", "Alan McCree", "Daniel Garcia-Romero", "Jesus Villalba", "Matthew Maciejewski", "Vimal Manohar", "Najim Dehak", "Daniel Povey", "Shinji Watanabe", "Sanjeev Khudanpur"], "https://doi.org/10.21437/Interspeech.2018-1893", 5, "interspeech", 2018]], "Laxmi Pandey": [0, ["LSTM Based Attentive Fusion of Spectral and Prosodic Information for Keyword Spotting in Hindi Language", ["Laxmi Pandey", "Karan Nathwani"], "https://doi.org/10.21437/Interspeech.2018-1016", 5, "interspeech", 2018], ["Monoaural Audio Source Separation Using Variational Autoencoders", ["Laxmi Pandey", "Anurendra Kumar", "Vinay Namboodiri"], "https://doi.org/10.21437/Interspeech.2018-1140", 5, "interspeech", 2018]], "John Bridle": [0, ["Efficient Voice Trigger Detection for Low Resource Hardware", ["Siddharth Sigtia", "Rob Haynes", "Hywel Richards", "Erik Marchi", "John Bridle"], "https://doi.org/10.21437/Interspeech.2018-2204", 5, "interspeech", 2018]], "Minghui Zhang": [0, ["Pitch or Phonation: on the Glottalization in Tone Productions in the Ruokeng Hui Chinese Dialect", ["Minghui Zhang", "Fang Hu"], "https://doi.org/10.21437/Interspeech.2018-1638", 5, "interspeech", 2018]], "Hang Lv": [0, ["Acoustic Modeling from Frequency Domain Representations of Speech", ["Pegah Ghahremani", "Hossein Hadian", "Hang Lv", "Daniel Povey", "Sanjeev Khudanpur"], "https://doi.org/10.21437/Interspeech.2018-1453", 5, "interspeech", 2018]], "Hideki Banno": [0, ["Frequency Domain Variants of Velvet Noise and Their Application to Speech Processing and Synthesis", ["Hideki Kawahara", "Ken-Ichi Sakakibara", "Masanori Morise", "Hideki Banno", "Tomoki Toda", "Toshio Irino"], "https://doi.org/10.21437/Interspeech.2018-43", 5, "interspeech", 2018]], "Jorge Ribeiro": [0, ["Machine Learning Powered Data Platform for High-Quality Speech and NLP Workflows", ["Joao Freitas", "Jorge Ribeiro", "Daan Baldewijns", "Sara Oliveira", "Daniela Braga"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3033.html", 2, "interspeech", 2018]], "Manabu Ikeda": [0, ["Detection of Dementia from Responses to Atypical Questions Asked by Embodied Conversational Agents", ["Tsuyoki Ujiro", "Hiroki Tanaka", "Hiroyoshi Adachi", "Hiroaki Kazui", "Manabu Ikeda", "Takashi Kudo", "Satoshi Nakamura"], "https://doi.org/10.21437/Interspeech.2018-1514", 5, "interspeech", 2018]], "Gang Feng": [0, ["Visual Recognition of Continuous Cued Speech Using a Tandem CNN-HMM Approach", ["Li Liu", "Thomas Hueber", "Gang Feng", "Denis Beautemps"], "https://doi.org/10.21437/Interspeech.2018-2434", 5, "interspeech", 2018]], "Dale Joachim": [0, ["Depression Detection from Short Utterances via Diverse Smartphones in Natural Environmental Conditions", ["Zhaocheng Huang", "Julien Epps", "Dale Joachim", "Michael Chen"], "https://doi.org/10.21437/Interspeech.2018-1743", 5, "interspeech", 2018]], "Angela Roberts": [0, ["Classification of Huntington Disease Using Acoustic and Lexical Features", ["Matthew Perez", "Wenyu Jin", "Duc Le", "Noelle Carlozzi", "Praveen Dayalu", "Angela Roberts", "Emily Mower Provost"], "https://doi.org/10.21437/Interspeech.2018-2029", 5, "interspeech", 2018]], "Linhao Dong": [2.5628809453337453e-05, ["Syllable-Based Sequence-to-Sequence Speech Recognition with the Transformer in Mandarin Chinese", ["Shiyu Zhou", "Linhao Dong", "Shuang Xu", "Bo Xu"], "https://doi.org/10.21437/Interspeech.2018-1107", 5, "interspeech", 2018], ["Extending Recurrent Neural Aligner for Streaming End-to-End Speech Recognition in Mandarin", ["Linhao Dong", "Shiyu Zhou", "Wei Chen", "Bo Xu"], "https://doi.org/10.21437/Interspeech.2018-1086", 5, "interspeech", 2018]], "Adam Lopez": [0, ["Low-Resource Speech-to-Text Translation", ["Sameer Bansal", "Herman Kamper", "Karen Livescu", "Adam Lopez", "Sharon Goldwater"], "https://doi.org/10.21437/Interspeech.2018-1326", 5, "interspeech", 2018]], "Ramon Sanabria": [0, ["Subword and Crossword Units for CTC Acoustic Models", ["Thomas Zenkel", "Ramon Sanabria", "Florian Metze", "Alex Waibel"], "https://doi.org/10.21437/Interspeech.2018-2057", 5, "interspeech", 2018]], "Ruibo Fu": [0, ["Transfer Learning Based Progressive Neural Networks for Acoustic Modeling in Statistical Parametric Speech Synthesis", ["Ruibo Fu", "Jianhua Tao", "Yibin Zheng", "Zhengqi Wen"], "https://doi.org/10.21437/Interspeech.2018-1265", 5, "interspeech", 2018], ["On the Application and Compression of Deep Time Delay Neural Network for Embedded Statistical Parametric Speech Synthesis", ["Yibin Zheng", "Jianhua Tao", "Zhengqi Wen", "Ruibo Fu"], "https://doi.org/10.21437/Interspeech.2018-1970", 5, "interspeech", 2018], ["Deep Metric Learning for the Target Cost in Unit-Selection Speech Synthesizer", ["Ruibo Fu", "Jianhua Tao", "Yibin Zheng", "Zhengqi Wen"], "https://doi.org/10.21437/Interspeech.2018-1305", 5, "interspeech", 2018]], "Samarendra Dandapat": [0, ["Self-similarity Matrix Based Intelligibility Assessment of Cleft Lip and Palate Speech", ["Sishir Kalita", "S. R. Mahadeva Prasanna", "Samarendra Dandapat"], "https://doi.org/10.21437/Interspeech.2018-1125", 5, "interspeech", 2018], ["Pitch-Adaptive Front-end Feature for Hypernasality Detection", ["Akhilesh Kumar Dubey", "S. R. Mahadeva Prasanna", "Samarendra Dandapat"], "https://doi.org/10.21437/Interspeech.2018-1251", 5, "interspeech", 2018]], "Deepak Kumar": [0, ["Development of Large Vocabulary Speech Recognition System with Keyword Search for Manipuri", ["Tanvina Patel", "Krishna D. N", "Noor Fathima", "Nisar Shah", "Mahima C", "Deepak Kumar", "Anuroop Iyengar"], "https://doi.org/10.21437/Interspeech.2018-2133", 5, "interspeech", 2018], ["An Automatic Speech Transcription System for Manipuri Language", ["Tanvina Patel", "Krishna D. N", "Noor Fathima", "Nisar Shah", "Mahima C", "Deepak Kumar", "Anuroop Iyengar"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3043.html", 2, "interspeech", 2018]], "Naomi Sakai": [0, ["Automatic Evaluation of Soft Articulatory Contact for Stuttering Treatment", ["Keiko Ochi", "Koichi Mori", "Naomi Sakai"], "https://doi.org/10.21437/Interspeech.2018-2544", 5, "interspeech", 2018]], "Julien Epps": [0, ["Transfer Learning for Improving Speech Emotion Classification Accuracy", ["Siddique Latif", "Rajib Rana", "Shahzad Younis", "Junaid Qadir", "Julien Epps"], "https://doi.org/10.21437/Interspeech.2018-1625", 5, "interspeech", 2018], ["Detection of Replay-Spoofing Attacks Using Frequency Modulation Features", ["Tharshini Gunendradasan", "Buddhi Wickramasinghe", "Phu Ngoc Le", "Eliathamby Ambikairajah", "Julien Epps"], "https://doi.org/10.21437/Interspeech.2018-1473", 5, "interspeech", 2018], ["Frequency Domain Linear Prediction Features for Replay Spoofing Attack Detection", ["Buddhi Wickramasinghe", "Saad Irtza", "Eliathamby Ambikairajah", "Julien Epps"], "https://doi.org/10.21437/Interspeech.2018-1574", 5, "interspeech", 2018], ["Variational Autoencoders for Learning Latent Representations of Speech Emotion: A Preliminary Study", ["Siddique Latif", "Rajib Rana", "Junaid Qadir", "Julien Epps"], "https://doi.org/10.21437/Interspeech.2018-1568", 5, "interspeech", 2018], ["Depression Detection from Short Utterances via Diverse Smartphones in Natural Environmental Conditions", ["Zhaocheng Huang", "Julien Epps", "Dale Joachim", "Michael Chen"], "https://doi.org/10.21437/Interspeech.2018-1743", 5, "interspeech", 2018], ["Demonstrating and Modelling Systematic Time-varying Annotator Disagreement in Continuous Emotion Annotation", ["Mia Atcheson", "Vidhyasaharan Sethu", "Julien Epps"], "https://doi.org/10.21437/Interspeech.2018-1933", 5, "interspeech", 2018]], "K. S. Nataraj": [0, ["Detection of Glottal Excitation Epochs in Speech Signal Using Hilbert Envelope", ["Hirak Dasgupta", "Prem C. Pandey", "K. S. Nataraj"], "https://doi.org/10.21437/Interspeech.2018-2014", 5, "interspeech", 2018]], "Prabha Ramanathan": [0, ["Early Vocabulary Development Through Picture-based Software Solutions", ["G. R. Kasthuri", "Prabha Ramanathan", "Hema A. Murthy", "Namita Jacob", "Anil Prabhakar"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3022.html", 2, "interspeech", 2018]], "Yufan Du": [0, ["Measuring the Band Importance Function for Mandarin Chinese with a Bayesian Adaptive Procedure", ["Yufan Du", "Yi Shen", "Hongying Yang", "Xihong Wu", "Jing Chen"], "https://doi.org/10.21437/Interspeech.2018-1825", 5, "interspeech", 2018]], "Szu-Jui Chen": [0, ["Building State-of-the-art Distant Speech Recognition Using the CHiME-4 Challenge with a Setup of Speech Enhancement Baseline", ["Szu-Jui Chen", "Aswin Shanmugam Subramanian", "Hainan Xu", "Shinji Watanabe"], "https://doi.org/10.21437/Interspeech.2018-1262", 5, "interspeech", 2018], ["Student-Teacher Learning for BLSTM Mask-based Speech Enhancement", ["Aswin Shanmugam Subramanian", "Szu-Jui Chen", "Shinji Watanabe"], "https://doi.org/10.21437/Interspeech.2018-2440", 5, "interspeech", 2018]], "Matthias Sperber": [0, ["Low-Latency Neural Speech Translation", ["Jan Niehues", "Ngoc-Quan Pham", "Thanh-Le Ha", "Matthias Sperber", "Alex Waibel"], "https://doi.org/10.21437/Interspeech.2018-1055", 5, "interspeech", 2018], ["Self-Attentional Acoustic Models", ["Matthias Sperber", "Jan Niehues", "Graham Neubig", "Sebastian Stuker", "Alex Waibel"], "https://doi.org/10.21437/Interspeech.2018-1910", 5, "interspeech", 2018]], "Adamantios I. Gafos": [0, ["Speaker-specific Structure in German Voiceless Stop Voice Onset Times", ["Marc Antony Hullebus", "Stephen J. Tobin", "Adamantios I. Gafos"], "https://doi.org/10.21437/Interspeech.2018-2288", 5, "interspeech", 2018], ["Perceptual Sensitivity to Spectral Change in Australian English Close Front Vowels: An Electroencephalographic Investigation", ["Daniel Williams", "Paola Escudero", "Adamantios I. Gafos"], "https://doi.org/10.21437/Interspeech.2018-2505", 5, "interspeech", 2018]], "Jean-Marc Odobez": [0, ["Joint Localization and Classification of Multiple Sound Sources Using a Multi-task Neural Network", ["Weipeng He", "Petr Motlicek", "Jean-Marc Odobez"], "https://doi.org/10.21437/Interspeech.2018-1269", 5, "interspeech", 2018], ["Robust and Discriminative Speaker Embedding via Intra-Class Distance Variance Regularization", ["Nam Le", "Jean-Marc Odobez"], "https://doi.org/10.21437/Interspeech.2018-1685", 5, "interspeech", 2018]], "Nabarun Goswami": [0, ["PhaseNet: Discretized Phase Modeling with Deep Neural Networks for Audio Source Separation", ["Naoya Takahashi", "Purvi Agrawal", "Nabarun Goswami", "Yuki Mitsufuji"], "https://doi.org/10.21437/Interspeech.2018-1773", 5, "interspeech", 2018]], "Hoirin Kim": [0.12472110986709595, ["Joint Learning Using Denoising Variational Autoencoders for Voice Activity Detection", ["Youngmoon Jung", "Younggwan Kim", "Yeunju Choi", "Hoirin Kim"], "https://doi.org/10.21437/Interspeech.2018-1151", 5, "interspeech", 2018]], "Oldrich Plchot": [0, ["Dereverberation and Beamforming in Robust Far-Field Speaker Recognition", ["Ladislav Mosner", "Oldrich Plchot", "Pavel Matejka", "Ondrej Novotny", "Jan Cernocky"], "https://doi.org/10.21437/Interspeech.2018-2306", 5, "interspeech", 2018], ["BUT System for DIHARD Speech Diarization Challenge 2018", ["Mireia Diez", "Federico Landini", "Lukas Burget", "Johan Rohdin", "Anna Silnova", "Katerina Zmolikova", "Ondrej Novotny", "Karel Vesely", "Ondrej Glembek", "Oldrich Plchot", "Ladislav Mosner", "Pavel Matejka"], "https://doi.org/10.21437/Interspeech.2018-1749", 5, "interspeech", 2018]], "Rajat Hebbar": [0, ["Improving Gender Identification in Movie Audio Using Cross-Domain Data", ["Rajat Hebbar", "Krishna Somandepalli", "Shrikanth Narayanan"], "https://doi.org/10.21437/Interspeech.2018-1462", 5, "interspeech", 2018]], "Jin-Seob Kim": [0.9992894381284714, ["A Unified Framework for the Generation of Glottal Signals in Deep Learning-based Parametric Speech Synthesis Systems", ["Min-Jae Hwang", "Eunwoo Song", "Jin-Seob Kim", "Hong-Goo Kang"], "https://doi.org/10.21437/Interspeech.2018-1590", 5, "interspeech", 2018]], "Camila Scaff": [0, ["The ACLEW DiViMe: An Easy-to-use Diarization Tool", ["Adrien Le Franc", "Eric Riebling", "Julien Karadayi", "Yun Wang", "Camila Scaff", "Florian Metze", "Alejandrina Cristia"], "https://doi.org/10.21437/Interspeech.2018-2324", 5, "interspeech", 2018]], "Minali Upreti": [0, ["Improved Accented Speech Recognition Using Accent Embeddings and Multi-task Learning", ["Abhinav Jain", "Minali Upreti", "Preethi Jyothi"], "https://doi.org/10.21437/Interspeech.2018-1864", 5, "interspeech", 2018]], "Chung-Hsien Wu": [2.071165852157719e-06, ["Follow-up Question Generation Using Pattern-based Seq2seq with a Small Corpus for Interview Coaching", ["Ming-Hsiang Su", "Chung-Hsien Wu", "Kun-Yi Huang", "Qian-Bei Hong", "Huai-Hung Huang"], "https://doi.org/10.21437/Interspeech.2018-1007", 5, "interspeech", 2018]], "Rohith Aralikatti": [0, ["Global SNR Estimation of Speech Signals Using Entropy and Uncertainty Estimates from Dropout Networks", ["Rohith Aralikatti", "Dilip Kumar Margam", "Tanay Sharma", "Abhinav Thanda", "Shankar M. Venkatesan"], "https://doi.org/10.21437/Interspeech.2018-1884", 5, "interspeech", 2018]], "John H. L. Hansen": [0, ["Speaker Recognition with Nonlinear Distortion: Clipping Analysis and Impact", ["Wei Xia", "John H. L. Hansen"], "https://doi.org/10.21437/Interspeech.2018-2430", 5, "interspeech", 2018], ["Compensation for Domain Mismatch in Text-independent Speaker Recognition", ["Fahimeh Bahmaninezhad", "John H. L. Hansen"], "https://doi.org/10.21437/Interspeech.2018-1446", 5, "interspeech", 2018], ["Fusing Text-dependent Word-level i-Vector Models to Screen 'at Risk' Child Speech", ["Prasanna V. Kothalkar", "Johanna Rudolph", "Christine Dollaghan", "Jennifer McGlothlin", "Thomas F. Campbell", "John H. L. Hansen"], "https://doi.org/10.21437/Interspeech.2018-1465", 5, "interspeech", 2018], ["Testing Paradigms for Assistive Hearing Devices in Diverse Acoustic Environments", ["Ram Charan Chandra Shekar", "Hussnain Ali", "John H. L. Hansen"], "https://doi.org/10.21437/Interspeech.2018-1471", 5, "interspeech", 2018], ["Assessing Speaker Engagement in 2-Person Debates: Overlap Detection in United States Presidential Debates", ["Midia Yousefi", "Navid Shokouhi", "John H. L. Hansen"], "https://doi.org/10.21437/Interspeech.2018-1463", 5, "interspeech", 2018], ["Leveraging Native Language Information for Improved Accented Speech Recognition", ["Shahram Ghorbani", "John H. L. Hansen"], "https://doi.org/10.21437/Interspeech.2018-1378", 5, "interspeech", 2018], ["Fearless Steps: Apollo-11 Corpus Advancements for Speech Technologies from Earth to the Moon", ["John H. L. Hansen", "Abhijeet Sangwan", "Aditya Joglekar", "Ahmet Emin Bulut", "Lakshmish Kaushik", "Chengzhu Yu"], "https://doi.org/10.21437/Interspeech.2018-1942", 5, "interspeech", 2018], ["Robust Speaker Clustering using Mixtures of von Mises-Fisher Distributions for Naturalistic Audio Streams", ["Harishchandra Dubey", "Abhijeet Sangwan", "John H. L. Hansen"], "https://doi.org/10.21437/Interspeech.2018-50", 5, "interspeech", 2018]], "Li Chai": [0, ["Error Modeling via Asymmetric Laplace Distribution for Deep Neural Network Based Single-Channel Speech Enhancement", ["Li Chai", "Jun Du", "Chin-Hui Lee"], "https://doi.org/10.21437/Interspeech.2018-1439", 5, "interspeech", 2018]], "Pascal Perrier": [0, ["Picture Naming or Word Reading: Does the Modality Affect Speech Motor Adaptation and Its Transfer?", ["Tiphaine Caudrelier", "Pascal Perrier", "Jean-Luc Schwartz", "Amelie Rochet-Capellan"], "https://doi.org/10.21437/Interspeech.2018-1760", 5, "interspeech", 2018]], "Preeti Rao": [0, ["Acoustic-Prosodic Features of Tabla Bol Recitation and Correspondence with the Tabla Imitation", ["Rohit M. A", "Preeti Rao"], "https://doi.org/10.21437/Interspeech.2018-1692", 5, "interspeech", 2018], ["A Non-convolutive NMF Model for Speech Dereverberation", ["Nikhil Mohanan", "Rajbabu Velmurugan", "Preeti Rao"], "https://doi.org/10.21437/Interspeech.2018-1834", 5, "interspeech", 2018], ["Automatic Detection of Expressiveness in Oral Reading", ["Kamini Sabu", "Kanhaiya Kumar", "Preeti Rao"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3026.html", 2, "interspeech", 2018], ["A Study of Lexical and Prosodic Cues to Segmentation in a Hindi-English Code-switched Discourse", ["Preeti Rao", "Mugdha Pandya", "Kamini Sabu", "Kanhaiya Kumar", "Nandini Bondale"], "https://doi.org/10.21437/Interspeech.2018-1600", 5, "interspeech", 2018]], "Colleen Richey": [0, ["Robust Speaker Recognition from Distant Speech under Real Reverberant Environments Using Speaker Embeddings", ["Mahesh Kumar Nandwana", "Julien van Hout", "Mitchell McLaren", "Allen R. Stauffer", "Colleen Richey", "Aaron Lawson", "Martin Graciarena"], "https://doi.org/10.21437/Interspeech.2018-2221", 5, "interspeech", 2018], ["Voices Obscured in Complex Environmental Settings (VOiCES) Corpus", ["Colleen Richey", "Maria Auxiliadora Barrios", "Zeb Armstrong", "Chris Bartels", "Horacio Franco", "Martin Graciarena", "Aaron Lawson", "Mahesh Kumar Nandwana", "Allen R. Stauffer", "Julien van Hout", "Paul Gamble", "Jeffrey Hetherly", "Cory Stephenson", "Karl Ni"], "https://doi.org/10.21437/Interspeech.2018-1454", 5, "interspeech", 2018]], "Jose Patino": [0, ["The EURECOM Submission to the First DIHARD Challenge", ["Jose Patino", "Hector Delgado", "Nicholas W. D. Evans"], "https://doi.org/10.21437/Interspeech.2018-2172", 5, "interspeech", 2018]], "Muralishankar R": [0, ["Robust Voice Activity Detection Using Frequency Domain Long-Term Differential Entropy", ["Debayan Ghosh", "Muralishankar R", "Sanjeev Gurugopinath"], "https://doi.org/10.21437/Interspeech.2018-1431", 5, "interspeech", 2018]], "Stephanie A. Borrie": [0, ["A Discriminative Acoustic-Prosodic Approach for Measuring Local Entrainment", ["Megan M. Willi", "Stephanie A. Borrie", "Tyson S. Barrett", "Ming Tu", "Visar Berisha"], "https://doi.org/10.21437/Interspeech.2018-1419", 5, "interspeech", 2018]], "Chandra Khatri": [0, ["Contextual Language Model Adaptation for Conversational Agents", ["Anirudh Raju", "Behnam Hedayatnia", "Linda Liu", "Ankur Gandhe", "Chandra Khatri", "Angeliki Metallinou", "Anu Venkatesh", "Ariya Rastrow"], "https://doi.org/10.21437/Interspeech.2018-1122", 5, "interspeech", 2018]], "Srinivas Parthasarathy": [0, ["Preference-Learning with Qualitative Agreement for Sentence Level Emotional Annotations", ["Srinivas Parthasarathy", "Carlos Busso"], "https://doi.org/10.21437/Interspeech.2018-2478", 5, "interspeech", 2018], ["Role of Regularization in the Prediction of Valence from Speech", ["Kusha Sridhar", "Srinivas Parthasarathy", "Carlos Busso"], "https://doi.org/10.21437/Interspeech.2018-2508", 5, "interspeech", 2018], ["Ladder Networks for Emotion Recognition: Using Unsupervised Auxiliary Tasks to Improve Predictions of Emotional Attributes", ["Srinivas Parthasarathy", "Carlos Busso"], "https://doi.org/10.21437/Interspeech.2018-1391", 5, "interspeech", 2018]], "Dae-Shik Kim": [3.6867969583909144e-06, ["End-to-End Speech Command Recognition with Capsule Network", ["Jaesung Bae", "Dae-Shik Kim"], "https://doi.org/10.21437/Interspeech.2018-1888", 5, "interspeech", 2018]], "Jane Mertens": [0, ["Age-related Effects on Sensorimotor Control of Speech Production", ["Anne Hermes", "Jane Mertens", "Doris Mucke"], "https://doi.org/10.21437/Interspeech.2018-1233", 5, "interspeech", 2018]], "Raquel Norel": [0, ["Detection of Amyotrophic Lateral Sclerosis (ALS) via Acoustic Analysis", ["Raquel Norel", "Mary Pietrowicz", "Carla Agurto", "Shay Rishoni", "Guillermo A. Cecchi"], "https://doi.org/10.21437/Interspeech.2018-2389", 5, "interspeech", 2018]], "Shahin Amiriparian": [0, ["The INTERSPEECH 2018 Computational Paralinguistics Challenge: Atypical & Self-Assessed Affect, Crying & Heart Beats", ["Bjorn W. Schuller", "Stefan Steidl", "Anton Batliner", "Peter B. Marschik", "Harald Baumeister", "Fengquan Dong", "Simone Hantke", "Florian B. Pokorny", "Eva-Maria Rathner", "Katrin D. Bartl-Pokorny", "Christa Einspieler", "Dajie Zhang", "Alice Baird", "Shahin Amiriparian", "Kun Qian", "Zhao Ren", "Maximilian Schmitt", "Panagiotis Tzirakis", "Stefanos Zafeiriou"], "https://doi.org/10.21437/Interspeech.2018-51", 5, "interspeech", 2018], ["Recognition of Echolalic Autistic Child Vocalisations Utilising Convolutional Recurrent Neural Networks", ["Shahin Amiriparian", "Alice Baird", "Sahib Julka", "Alyssa Alcorn", "Sandra Ottl", "Suncica Petrovic", "Eloise Ainger", "Nicholas Cummins", "Bjorn W. Schuller"], "https://doi.org/10.21437/Interspeech.2018-1772", 5, "interspeech", 2018]], "Ying Zhang": [0, ["Quaternion Convolutional Neural Networks for End-to-End Automatic Speech Recognition", ["Titouan Parcollet", "Ying Zhang", "Mohamed Morchid", "Chiheb Trabelsi", "Georges Linares", "Renato de Mori", "Yoshua Bengio"], "https://doi.org/10.21437/Interspeech.2018-1898", 5, "interspeech", 2018]], "Minnaleena Toivola": [0, ["Captaina: Integrated Pronunciation Practice and Data Collection Portal", ["Aku Rouhe", "Reima Karhila", "Aija Elg", "Minnaleena Toivola", "Peter Smit", "Anna-Riikka Smolander", "Mikko Kurimo"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3015.html", 2, "interspeech", 2018]], "Wendy Lalhminghlui": [0, ["Robust Mizo Continuous Speech Recognition", ["Abhishek Dey", "Biswajit Dev Sarma", "Wendy Lalhminghlui", "Lalnunsiami Ngente", "Parismita Gogoi", "Priyankoo Sarmah", "S. R. Mahadeva Prasanna", "Rohit Sinha", "S. R. Nirmala"], "https://doi.org/10.21437/Interspeech.2018-2125", 5, "interspeech", 2018]], "Dieter Studer-Joho": [0, ["Regional Variation of /r/ in Swiss German Dialects", ["Adrian Leemann", "Stephan Schmid", "Dieter Studer-Joho", "Marie-Jose Kolly"], "https://doi.org/10.21437/Interspeech.2018-1065", 5, "interspeech", 2018]], "Yiwen Shao": [0, ["A Novel Normalization Method for Autocorrelation Function for Pitch Detection and for Speech Activity Detection", ["Qiguang Lin", "Yiwen Shao"], "https://doi.org/10.21437/Interspeech.2018-45", 5, "interspeech", 2018]], "Tomas Arias-Vergara": [0, ["A Multitask Learning Approach to Assess the Dysarthria Severity in Patients with Parkinson's Disease", ["Juan Camilo Vasquez-Correa", "Tomas Arias-Vergara", "Juan Rafael Orozco-Arroyave", "Elmar Noth"], "https://doi.org/10.21437/Interspeech.2018-1988", 5, "interspeech", 2018]], "Lou Boves": [0, ["Analyzing Reaction Time Sequences from Human Participants in Auditory Experiments", ["Louis ten Bosch", "Mirjam Ernestus", "Lou Boves"], "https://doi.org/10.21437/Interspeech.2018-1728", 5, "interspeech", 2018], ["Analyzing EEG Signals in Auditory Speech Comprehension Using Temporal Response Functions and Generalized Additive Models", ["Kimberley Mulder", "Louis ten Bosch", "Lou Boves"], "https://doi.org/10.21437/Interspeech.2018-1676", 5, "interspeech", 2018], ["Information Encoding by Deep Neural Networks: What Can We Learn?", ["Louis ten Bosch", "Lou Boves"], "https://doi.org/10.21437/Interspeech.2018-1896", 5, "interspeech", 2018]], "Marek Hruz": [0, ["ZCU-NTIS Speaker Diarization System for the DIHARD 2018 Challenge", ["Zbynek Zajic", "Marie Kunesova", "Jan Zelinka", "Marek Hruz"], "https://doi.org/10.21437/Interspeech.2018-1252", 5, "interspeech", 2018], ["Multimodal Name Recognition in Live TV Subtitling", ["Marek Hruz", "Ales Prazak", "Michal Busta"], "https://doi.org/10.21437/Interspeech.2018-1748", 4, "interspeech", 2018]], "Teun F. Krikke": [0, ["Who Said That? a Comparative Study of Non-negative Matrix Factorization Techniques", ["Teun F. Krikke", "Frank Broz", "David Lane"], "https://doi.org/10.21437/Interspeech.2018-1807", 5, "interspeech", 2018]], "J. V. Satyanarayana": [0, ["Determining Speaker Location from Speech in a Practical Environment", ["B. H. V. S. Narayanamurthy", "J. V. Satyanarayana", "Bayya Yegnanarayana"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3042.html", 2, "interspeech", 2018]], "Maxine Eskenazi": [0, ["Multimodal Polynomial Fusion for Detecting Driver Distraction", ["Yulun Du", "Alan W. Black", "Louis-Philippe Morency", "Maxine Eskenazi"], "https://doi.org/10.21437/Interspeech.2018-2011", 5, "interspeech", 2018]], "Haipeng Lan": [0, ["Multiple Concurrent Sound Source Tracking Based on Observation-Guided Adaptive Particle Filter", ["Hong Liu", "Haipeng Lan", "Bing Yang", "Cheng Pang"], "https://doi.org/10.21437/Interspeech.2018-1248", 5, "interspeech", 2018]], "Vikrant Singh Tomar": [0, ["Efficient Keyword Spotting Using Time Delay Neural Networks", ["Samuel Myer", "Vikrant Singh Tomar"], "https://doi.org/10.21437/Interspeech.2018-1979", 5, "interspeech", 2018], ["Tone Recognition Using Lifters and CTC", ["Loren Lugosch", "Vikrant Singh Tomar"], "https://doi.org/10.21437/Interspeech.2018-2293", 5, "interspeech", 2018]], "Vadim Shchemelinin": [0, ["Triplet Loss Based Cosine Similarity Metric Learning for Text-independent Speaker Recognition", ["Sergey Novoselov", "Vadim Shchemelinin", "Andrey Shulipa", "Alexander Kozlov", "Ivan Kremnev"], "https://doi.org/10.21437/Interspeech.2018-1209", 5, "interspeech", 2018]], "Ram Charan Chandra Shekar": [0, ["Testing Paradigms for Assistive Hearing Devices in Diverse Acoustic Environments", ["Ram Charan Chandra Shekar", "Hussnain Ali", "John H. L. Hansen"], "https://doi.org/10.21437/Interspeech.2018-1471", 5, "interspeech", 2018]], "Elliot Singer": [0, ["Performance Analysis of the 2017 NIST Language Recognition Evaluation", ["Seyed Omid Sadjadi", "Timothee Kheyrkhah", "Craig S. Greenberg", "Elliot Singer", "Douglas A. Reynolds", "Lisa P. Mason", "Jaime Hernandez-Cordero"], "https://doi.org/10.21437/Interspeech.2018-69", 5, "interspeech", 2018]], "Jacinta Dan Luo": [0, ["Weighting Pitch Contour and Loudness Contour in Mandarin Tone Perception in Cochlear Implant Listeners", ["Qinglin Meng", "Nengheng Zheng", "Ambika Prasad Mishra", "Jacinta Dan Luo", "Jan W. H. Schnupp"], "https://doi.org/10.21437/Interspeech.2018-1245", 4, "interspeech", 2018]], "Shogo Yonekura": [0, ["Implementation of Respiration in Articulatory Synthesis Using a Pressure-Volume Lung Model", ["Keisuke Tanihara", "Shogo Yonekura", "Yasuo Kuniyoshi"], "https://doi.org/10.21437/Interspeech.2018-1080", 5, "interspeech", 2018]], "Panayiotis G. Georgiou": [0, ["An Unsupervised Neural Prediction Framework for Learning Speaker Embeddings Using Recurrent Neural Networks", ["Arindam Jati", "Panayiotis G. Georgiou"], "https://doi.org/10.21437/Interspeech.2018-1363", 5, "interspeech", 2018], ["Multimodal Speaker Segmentation and Diarization Using Lexical and Acoustic Cues via Sequence to Sequence Neural Networks", ["Tae Jin Park", "Panayiotis G. Georgiou"], "https://doi.org/10.21437/Interspeech.2018-1364", 5, "interspeech", 2018], ["Modeling Interpersonal Influence of Verbal Behavior in Couples Therapy Dyadic Interactions", ["Sandeep Nallan Chakravarthula", "Brian R. Baucom", "Panayiotis G. Georgiou"], "https://doi.org/10.21437/Interspeech.2018-1562", 5, "interspeech", 2018], ["Towards an Unsupervised Entrainment Distance in Conversational Speech Using Deep Neural Networks", ["Md. Nasir", "Brian R. Baucom", "Shrikanth Narayanan", "Panayiotis G. Georgiou"], "https://doi.org/10.21437/Interspeech.2018-1395", 5, "interspeech", 2018]], "Junlin Zeng": [0, ["An End-to-End Deep Learning Framework for Speech Emotion Recognition of Atypical Individuals", ["Dengke Tang", "Junlin Zeng", "Ming Li"], "https://doi.org/10.21437/Interspeech.2018-2581", 5, "interspeech", 2018]], "Margarita Kotti": [0, ["A Case Study on the Importance of Belief State Representation for Dialogue Policy Management", ["Margarita Kotti", "Vassilios Diakoloukas", "Alexandros Papangelis", "Michail Lagoudakis", "Yannis Stylianou"], "https://doi.org/10.21437/Interspeech.2018-1293", 5, "interspeech", 2018]], "Markus Reuber": [0, ["Detecting Signs of Dementia Using Word Vector Representations", ["Bahman Mirheidari", "Daniel Blackburn", "Traci Walker", "Annalena Venneri", "Markus Reuber", "Heidi Christensen"], "https://doi.org/10.21437/Interspeech.2018-1764", 5, "interspeech", 2018]], "Yu Tsao": [0, ["Exemplar-Based Spectral Detail Compensation for Voice Conversion", ["Yu-Huai Peng", "Hsin-Te Hwang", "Yi-Chiao Wu", "Yu Tsao", "Hsin-Min Wang"], "https://doi.org/10.21437/Interspeech.2018-1662", 5, "interspeech", 2018], ["Temporal Attentive Pooling for Acoustic Event Detection", ["Xugang Lu", "Peng Shen", "Sheng Li", "Yu Tsao", "Hisashi Kawai"], "https://doi.org/10.21437/Interspeech.2018-1552", 4, "interspeech", 2018], ["Quality-Net: An End-to-End Non-intrusive Speech Quality Assessment Model Based on BLSTM", ["Szu-Wei Fu", "Yu Tsao", "Hsin-Te Hwang", "Hsin-Min Wang"], "https://doi.org/10.21437/Interspeech.2018-1802", 5, "interspeech", 2018]], "Pengyuan Zhang": [0, ["Investigation on the Combination of Batch Normalization and Dropout in BLSTM-based Acoustic Modeling for ASR", ["Wenjie Li", "Gaofeng Cheng", "Fengpei Ge", "Pengyuan Zhang", "Yonghong Yan"], "https://doi.org/10.21437/Interspeech.2018-1597", 5, "interspeech", 2018], ["Deep Convolutional Neural Network with Scalogram for Audio Scene Modeling", ["Hangting Chen", "Pengyuan Zhang", "Haichuan Bai", "Qingsheng Yuan", "Xiuguo Bao", "Yonghong Yan"], "https://doi.org/10.21437/Interspeech.2018-1524", 5, "interspeech", 2018], ["Improving Language Modeling with an Adversarial Critic for Automatic Speech Recognition", ["Yike Zhang", "Pengyuan Zhang", "Yonghong Yan"], "https://doi.org/10.21437/Interspeech.2018-1111", 5, "interspeech", 2018]], "Shuang Xu": [0, ["Syllable-Based Sequence-to-Sequence Speech Recognition with the Transformer in Mandarin Chinese", ["Shiyu Zhou", "Linhao Dong", "Shuang Xu", "Bo Xu"], "https://doi.org/10.21437/Interspeech.2018-1107", 5, "interspeech", 2018], ["Single-channel Speech Dereverberation via Generative Adversarial Training", ["Chenxing Li", "Tieqiang Wang", "Shuang Xu", "Bo Xu"], "https://doi.org/10.21437/Interspeech.2018-1234", 5, "interspeech", 2018]], "Zhihong Lei": [0, ["Investigation on Estimation of Sentence Probability by Combining Forward, Backward and Bi-directional LSTM-RNNs", ["Kazuki Irie", "Zhihong Lei", "Liuhui Deng", "Ralf Schluter", "Hermann Ney"], "https://doi.org/10.21437/Interspeech.2018-1766", 4, "interspeech", 2018]], "Seyed Hamidreza Mohammadi": [0, ["Investigation of Using Disentangled and Interpretable Representations for One-shot Cross-lingual Voice Conversion", ["Seyed Hamidreza Mohammadi", "Taehwan Kim"], "https://doi.org/10.21437/Interspeech.2018-2525", 5, "interspeech", 2018]], "Francois Grondin": [0, ["A Study of Enhancement, Augmentation and Autoencoder Methods for Domain Adaptation in Distant Speech Recognition", ["Hao Tang", "Wei-Ning Hsu", "Francois Grondin", "James R. Glass"], "https://doi.org/10.21437/Interspeech.2018-2030", 5, "interspeech", 2018]], "Adithya Renduchintala": [0, ["ESPnet: End-to-End Speech Processing Toolkit", ["Shinji Watanabe", "Takaaki Hori", "Shigeki Karita", "Tomoki Hayashi", "Jiro Nishitoba", "Yuya Unno", "Nelson Enrique Yalta Soplin", "Jahn Heymann", "Matthew Wiesner", "Nanxin Chen", "Adithya Renduchintala", "Tsubasa Ochiai"], "https://doi.org/10.21437/Interspeech.2018-1456", 5, "interspeech", 2018], ["Multi-Modal Data Augmentation for End-to-end ASR", ["Adithya Renduchintala", "Shuoyang Ding", "Matthew Wiesner", "Shinji Watanabe"], "https://doi.org/10.21437/Interspeech.2018-2456", 5, "interspeech", 2018]], "Pei-Hung Chung": [6.687654240522534e-05, ["Joint Learning of Interactive Spoken Content Retrieval and Trainable User Simulator", ["Pei-Hung Chung", "Kuan Tung", "Ching-Lun Tai", "Hung-yi Lee"], "https://doi.org/10.21437/Interspeech.2018-1346", 5, "interspeech", 2018]], "Franck Dernoncourt": [0, ["A Framework for Speech Recognition Benchmarking", ["Franck Dernoncourt", "Trung Bui", "Walter Chang"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3003.html", 2, "interspeech", 2018]], "Karttikeya Mangalam": [0, ["Learning Spontaneity to Improve Emotion Recognition in Speech", ["Karttikeya Mangalam", "Tanaya Guha"], "https://doi.org/10.21437/Interspeech.2018-1872", 5, "interspeech", 2018]], "David C. Atkins": [0, ["Language Features for Automated Evaluation of Cognitive Behavior Psychotherapy Sessions", ["Nikolaos Flemotomos", "Victor R. Martinez", "James Gibson", "David C. Atkins", "Torrey Creed", "Shrikanth Narayanan"], "https://doi.org/10.21437/Interspeech.2018-1518", 5, "interspeech", 2018], ["Computational Modeling of Conversational Humor in Psychotherapy", ["Anil Ramakrishna", "Timothy Greer", "David C. Atkins", "Shrikanth Narayanan"], "https://doi.org/10.21437/Interspeech.2018-1583", 5, "interspeech", 2018], ["Using Prosodic and Lexical Information for Learning Utterance-level Behaviors in Psychotherapy", ["Karan Singla", "Zhuohao Chen", "Nikolaos Flemotomos", "James Gibson", "Dogan Can", "David C. Atkins", "Shrikanth Narayanan"], "https://doi.org/10.21437/Interspeech.2018-2551", 5, "interspeech", 2018]], "Lei Xie": [0, ["Learning Acoustic Word Embeddings with Temporal Context for Query-by-Example Speech Search", ["Yougen Yuan", "Cheung-Chi Leung", "Lei Xie", "Hongjie Chen", "Bin Ma", "Haizhou Li"], "https://doi.org/10.21437/Interspeech.2018-1010", 5, "interspeech", 2018], ["Investigating Generative Adversarial Networks Based Speech Dereverberation for Robust Speech Recognition", ["Ke Wang", "Junbo Zhang", "Sining Sun", "Yujun Wang", "Fei Xiang", "Lei Xie"], "https://doi.org/10.21437/Interspeech.2018-1780", 5, "interspeech", 2018], ["Study of Semi-supervised Approaches to Improving English-Mandarin Code-Switching Speech Recognition", ["Pengcheng Guo", "Haihua Xu", "Lei Xie", "Eng Siong Chng"], "https://doi.org/10.21437/Interspeech.2018-1974", 5, "interspeech", 2018], ["Attention-based End-to-End Models for Small-Footprint Keyword Spotting", ["Changhao Shan", "Junbo Zhang", "Yujun Wang", "Lei Xie"], "https://doi.org/10.21437/Interspeech.2018-1777", 5, "interspeech", 2018], ["Training Augmentation with Adversarial Examples for Robust Speech Recognition", ["Sining Sun", "Ching-Feng Yeh", "Mari Ostendorf", "Mei-Yuh Hwang", "Lei Xie"], "https://doi.org/10.21437/Interspeech.2018-1247", 5, "interspeech", 2018], ["Empirical Evaluation of Speaker Adaptation on DNN Based Acoustic Model", ["Ke Wang", "Junbo Zhang", "Yujun Wang", "Lei Xie"], "https://doi.org/10.21437/Interspeech.2018-1897", 5, "interspeech", 2018]], "Tamas Gabor Csapo": [0, ["Multi-Task Learning of Speech Recognition and Speech Synthesis Parameters for Ultrasound-based Silent Speech Interfaces", ["Laszlo Toth", "Gabor Gosztolya", "Tamas Grosz", "Alexandra Marko", "Tamas Gabor Csapo"], "https://doi.org/10.21437/Interspeech.2018-1078", 5, "interspeech", 2018]], "John F. Houde": [0, ["FACTS: A Hierarchical Task-based Control Model of Speech Incorporating Sensory Feedback", ["Benjamin Parrell", "Vikram Ramanarayanan", "Srikantan S. Nagarajan", "John F. Houde"], "https://doi.org/10.21437/Interspeech.2018-2087", 5, "interspeech", 2018]], "Yuexian Zou": [0, ["Investigation on Joint Representation Learning for Robust Feature Extraction in Speech Emotion Recognition", ["Danqing Luo", "Yuexian Zou", "Dongyan Huang"], "https://doi.org/10.21437/Interspeech.2018-1832", 5, "interspeech", 2018], ["Joint Noise and Reverberation Adaptive Learning for Robust Speaker DOA Estimation with an Acoustic Vector Sensor", ["Disong Wang", "Yuexian Zou"], "https://doi.org/10.21437/Interspeech.2018-1135", 5, "interspeech", 2018]], "Nishmar Cestero": [0, ["The Role of Cognate Words, POS Tags and Entrainment in Code-Switching", ["Victor Soto", "Nishmar Cestero", "Julia Hirschberg"], "https://doi.org/10.21437/Interspeech.2018-1099", 5, "interspeech", 2018]], "Kazuyo Tanaka": [0, ["Empirical Analysis of Score Fusion Application to Combined Neural Networks for Open Vocabulary Spoken Term Detection", ["Shi-wook Lee", "Kazuyo Tanaka", "Yoshiaki Itoh"], "https://doi.org/10.21437/Interspeech.2018-1776", 5, "interspeech", 2018]], "Awais Athar": [0, ["Rapid Collection of Spontaneous Speech Corpora Using Telephonic Community Forums", ["Agha Ali Raza", "Awais Athar", "Shan Randhawa", "Zain Tariq", "Muhammad Bilal Saleem", "Haris Bin Zia", "Umar Saif", "Roni Rosenfeld"], "https://doi.org/10.21437/Interspeech.2018-1139", 5, "interspeech", 2018]], "Ivan Kraljevski": [0, ["Classification of Correction Turns in Multilingual Dialogue Corpus", ["Ivan Kraljevski", "Diane Hirschfeld"], "https://doi.org/10.21437/Interspeech.2018-1348", 5, "interspeech", 2018]], "Wolfgang Mack": [0, ["Single-Channel Dereverberation Using Direct MMSE Optimization and Bidirectional LSTM Networks", ["Wolfgang Mack", "Soumitro Chakrabarty", "Fabian-Robert Stoter", "Sebastian Braun", "Bernd Edler", "Emanuel A. P. Habets"], "https://doi.org/10.21437/Interspeech.2018-1296", 5, "interspeech", 2018]], "Chieh-Chi Kao": [0, ["A Simple Model for Detection of Rare Sound Events", ["Weiran Wang", "Chieh-Chi Kao", "Chao Wang"], "https://doi.org/10.21437/Interspeech.2018-2338", 5, "interspeech", 2018], ["R-CRNN: Region-based Convolutional Recurrent Neural Network for Audio Event Detection", ["Chieh-Chi Kao", "Weiran Wang", "Ming Sun", "Chao Wang"], "https://doi.org/10.21437/Interspeech.2018-2323", 5, "interspeech", 2018]], "Dilek Hakkani-Tur": [0, ["Deep Learning based Situated Goal-oriented Dialogue Systems", ["Dilek Hakkani-Tur"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/4005.html", 1, "interspeech", 2018], ["An Efficient Approach to Encoding Context for Spoken Language Understanding", ["Raghav Gupta", "Abhinav Rastogi", "Dilek Hakkani-Tur"], "https://doi.org/10.21437/Interspeech.2018-2403", 5, "interspeech", 2018]], "Ekaterina Egorova": [0, ["BUT System for Low Resource Indian Language ASR", ["Bhargav Pulugundla", "Murali Karthick Baskar", "Santosh Kesiraju", "Ekaterina Egorova", "Martin Karafiat", "Lukas Burget", "Jan Cernocky"], "https://doi.org/10.21437/Interspeech.2018-1302", 5, "interspeech", 2018]], "Srinivasa Raghavan K. M.": [0, ["Semi-supervised and Active-learning Scenarios: Efficient Acoustic Model Refinement for a Low Resource Indian Language", ["Maharajan Chellapriyadharshini", "Anoop Toffy", "Srinivasa Raghavan K. M.", "V. Ramasubramanian"], "https://doi.org/10.21437/Interspeech.2018-2486", 5, "interspeech", 2018]], "Joey Ching": [0, ["Large Vocabulary Concatenative Resynthesis", ["Soumi Maiti", "Joey Ching", "Michael I. Mandel"], "https://doi.org/10.21437/Interspeech.2018-2383", 5, "interspeech", 2018]], "Jian Hu": [0, ["The Trajectory of Voice Onset Time with Vocal Aging", ["Xuanda Chen", "Ziyu Xiong", "Jian Hu"], "https://doi.org/10.21437/Interspeech.2018-60", 5, "interspeech", 2018]], "Julie Liss": [0, ["Investigating the Role of L1 in Automatic Pronunciation Evaluation of L2 Speech", ["Ming Tu", "Anna Grabek", "Julie Liss", "Visar Berisha"], "https://doi.org/10.21437/Interspeech.2018-1350", 5, "interspeech", 2018]], "Marie-Lou Barnaud": [0, ["COSMO SylPhon: A Bayesian Perceptuo-motor Model to Assess Phonological Learning", ["Marie-Lou Barnaud", "Julien Diard", "Pierre Bessiere", "Jean-Luc Schwartz"], "https://doi.org/10.21437/Interspeech.2018-73", 5, "interspeech", 2018]], "M. S. Saranya": [0, ["Decision-level Feature Switching as a Paradigm for Replay Attack Detection", ["M. S. Saranya", "Hema A. Murthy"], "https://doi.org/10.21437/Interspeech.2018-1494", 5, "interspeech", 2018]], "Younggwan Kim": [0.9961809366941452, ["Joint Learning Using Denoising Variational Autoencoders for Voice Activity Detection", ["Youngmoon Jung", "Younggwan Kim", "Yeunju Choi", "Hoirin Kim"], "https://doi.org/10.21437/Interspeech.2018-1151", 5, "interspeech", 2018]], "Thayabaran Kathiresan": [0, ["The Zurich Corpus of Vowel and Voice Quality, Version 1.0", ["Dieter Maurer", "Christian dHeureuse", "Heidy Suter", "Volker Dellwo", "Daniel Friedrichs", "Thayabaran Kathiresan"], "https://doi.org/10.21437/Interspeech.2018-1542", 5, "interspeech", 2018], ["Influences of Fundamental Oscillation on Speaker Identification in Vocalic Utterances by Humans and Computers", ["Volker Dellwo", "Thayabaran Kathiresan", "Elisa Pellegrino", "Lei He", "Sandra Schwab", "Dieter Maurer"], "https://doi.org/10.21437/Interspeech.2018-2331", 5, "interspeech", 2018]], "Shigeki Karita": [0, ["Semi-Supervised End-to-End Speech Recognition", ["Shigeki Karita", "Shinji Watanabe", "Tomoharu Iwata", "Atsunori Ogawa", "Marc Delcroix"], "https://doi.org/10.21437/Interspeech.2018-1746", 5, "interspeech", 2018], ["ESPnet: End-to-End Speech Processing Toolkit", ["Shinji Watanabe", "Takaaki Hori", "Shigeki Karita", "Tomoki Hayashi", "Jiro Nishitoba", "Yuya Unno", "Nelson Enrique Yalta Soplin", "Jahn Heymann", "Matthew Wiesner", "Nanxin Chen", "Adithya Renduchintala", "Tsubasa Ochiai"], "https://doi.org/10.21437/Interspeech.2018-1456", 5, "interspeech", 2018], ["Auxiliary Feature Based Adaptation of End-to-end ASR Systems", ["Marc Delcroix", "Shinji Watanabe", "Atsunori Ogawa", "Shigeki Karita", "Tomohiro Nakatani"], "https://doi.org/10.21437/Interspeech.2018-1438", 5, "interspeech", 2018]], "Mikko Kurimo": [0, ["Captaina: Integrated Pronunciation Practice and Data Collection Portal", ["Aku Rouhe", "Reima Karhila", "Aija Elg", "Minnaleena Toivola", "Peter Smit", "Anna-Riikka Smolander", "Mikko Kurimo"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3015.html", 2, "interspeech", 2018]], "Lukas Burget": [0, ["Fast Variational Bayes for Heavy-tailed PLDA Applied to i-vectors and x-vectors", ["Anna Silnova", "Niko Brummer", "Daniel Garcia-Romero", "David Snyder", "Lukas Burget"], "https://doi.org/10.21437/Interspeech.2018-2128", 5, "interspeech", 2018], ["BUT OpenSAT 2017 Speech Recognition System", ["Martin Karafiat", "Murali Karthick Baskar", "Igor Szoke", "Vladimir Malenovsky", "Karel Vesely", "Frantisek Grezl", "Lukas Burget", "Jan Cernocky"], "https://doi.org/10.21437/Interspeech.2018-2457", 5, "interspeech", 2018], ["BUT System for DIHARD Speech Diarization Challenge 2018", ["Mireia Diez", "Federico Landini", "Lukas Burget", "Johan Rohdin", "Anna Silnova", "Katerina Zmolikova", "Ondrej Novotny", "Karel Vesely", "Ondrej Glembek", "Oldrich Plchot", "Ladislav Mosner", "Pavel Matejka"], "https://doi.org/10.21437/Interspeech.2018-1749", 5, "interspeech", 2018], ["BUT System for Low Resource Indian Language ASR", ["Bhargav Pulugundla", "Murali Karthick Baskar", "Santosh Kesiraju", "Ekaterina Egorova", "Martin Karafiat", "Lukas Burget", "Jan Cernocky"], "https://doi.org/10.21437/Interspeech.2018-1302", 5, "interspeech", 2018], ["i-Vectors in Language Modeling: An Efficient Way of Domain Adaptation for Feed-Forward Models", ["Karel Benes", "Santosh Kesiraju", "Lukas Burget"], "https://doi.org/10.21437/Interspeech.2018-1070", 5, "interspeech", 2018]], "Dongbo Li": [0, ["Multiple Phase Information Combination for Replay Attacks Detection", ["Dongbo Li", "Longbiao Wang", "Jianwu Dang", "Meng Liu", "Zeyan Oo", "Seiichi Nakagawa", "Haotian Guan", "Xiangang Li"], "https://doi.org/10.21437/Interspeech.2018-2001", 5, "interspeech", 2018]], "Nithya Ravi": [0, ["Articulatory and Stacked Bottleneck Features for Low Resource Speech Recognition", ["Vishwas M. Shetty", "Rini A. Sharon", "Basil Abraham", "Tejaswi Seeram", "Anusha Prakash", "Nithya Ravi", "Srinivasan Umesh"], "https://doi.org/10.21437/Interspeech.2018-2226", 5, "interspeech", 2018]], "Kanthashree Mysore Sathyendra": [0, ["Statistical Model Compression for Small-Footprint Natural Language Understanding", ["Grant P. Strimel", "Kanthashree Mysore Sathyendra", "Stanislav Peshterliev"], "https://doi.org/10.21437/Interspeech.2018-1333", 5, "interspeech", 2018]], "Natalie Boll-Avetisyan": [0, ["Neural Response Development During Distributional Learning", ["Natalie Boll-Avetisyan", "Jessie S. Nixon", "Tomas O. Lentz", "Liquan Liu", "Sandrien van Ommen", "Cagri Coltekin", "Jacolien van Rij"], "https://doi.org/10.21437/Interspeech.2018-2072", 5, "interspeech", 2018]], "Sourish Chaudhuri": [0, ["AVA-Speech: A Densely Labeled Dataset of Speech Activity in Movies", ["Sourish Chaudhuri", "Joseph Roth", "Daniel P. W. Ellis", "Andrew C. Gallagher", "Liat Kaver", "Radhika Marvin", "Caroline Pantofaru", "Nathan Reale", "Loretta Guarino Reid", "Kevin W. Wilson", "Zhonghua Xi"], "https://doi.org/10.21437/Interspeech.2018-2028", 5, "interspeech", 2018]], "Sanjeevan Devnath": [0, ["Glotto Vibrato Graph: A Device and Method for Recording, Analysis and Visualization of Glottal Activity", ["Kishalay Chakraborty", "Senjam Shantirani Devi", "Sanjeevan Devnath", "S. R. Mahadeva Prasanna", "Priyankoo Sarmah"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3046.html", 2, "interspeech", 2018]], "Hemlata Tak": [0, ["Effectiveness of Speech Demodulation-Based Features for Replay Detection", ["Madhu R. Kamble", "Hemlata Tak", "Hemant A. Patil"], "https://doi.org/10.21437/Interspeech.2018-1675", 5, "interspeech", 2018], ["Novel Linear Frequency Residual Cepstral Features for Replay Attack Detection", ["Hemlata Tak", "Hemant A. Patil"], "https://doi.org/10.21437/Interspeech.2018-1702", 5, "interspeech", 2018]], "Xuesong Yang": [0.00023196971596917138, ["Improved ASR for Under-resourced Languages through Multi-task Learning with Acoustic Landmarks", ["Di He", "Boon Pang Lim", "Xuesong Yang", "Mark Hasegawa-Johnson", "Deming Chen"], "https://doi.org/10.21437/Interspeech.2018-1124", 5, "interspeech", 2018]], "Xinyuan Cai": [0, ["An End-to-End Text-Independent Speaker Identification System on Short Utterances", ["Ruifang Ji", "Xinyuan Cai", "Xu Bo"], "https://doi.org/10.21437/Interspeech.2018-1058", 5, "interspeech", 2018]], "Arijit Biswas": [0, ["Temporal Noise Shaping with Companding", ["Arijit Biswas", "Per Hedelin", "Lars F. Villemoes", "Vinay Melkote"], "https://doi.org/10.21437/Interspeech.2018-2096", 5, "interspeech", 2018]], "Weiran Wang": [0.0030166752403602004, ["A Simple Model for Detection of Rare Sound Events", ["Weiran Wang", "Chieh-Chi Kao", "Chao Wang"], "https://doi.org/10.21437/Interspeech.2018-2338", 5, "interspeech", 2018], ["R-CRNN: Region-based Convolutional Recurrent Neural Network for Audio Event Detection", ["Chieh-Chi Kao", "Weiran Wang", "Ming Sun", "Chao Wang"], "https://doi.org/10.21437/Interspeech.2018-2323", 5, "interspeech", 2018]], "Georgina Dorca": [0, ["Spanish Statistical Parametric Speech Synthesis Using a Neural Vocoder", ["Antonio Bonafonte", "Santiago Pascual", "Georgina Dorca"], "https://doi.org/10.21437/Interspeech.2018-2417", 4, "interspeech", 2018]], "Ratree Wayland": [0, ["Analysis of Breathiness in Contextual Vowel of Voiceless Nasals in Mizo", ["Pamir Gogoi", "Sishir Kalita", "Parismita Gogoi", "Ratree Wayland", "Priyankoo Sarmah", "S. R. Mahadeva Prasanna"], "https://doi.org/10.21437/Interspeech.2018-1899", 5, "interspeech", 2018]], "Bo Xiao": [0, ["Play Duration Based User-Entity Affinity Modeling in Spoken Dialog System", ["Bo Xiao", "Nicholas Monath", "Shankar Ananthakrishnan", "Abishek Ravi"], "https://doi.org/10.21437/Interspeech.2018-1100", 5, "interspeech", 2018]], "Erica Gold": [0, ["Articulation Rate as a Speaker Discriminant in British English", ["Erica Gold"], "https://doi.org/10.21437/Interspeech.2018-1384", 5, "interspeech", 2018], ["Variation in the FACE Vowel across West Yorkshire: Implications for Forensic Speaker Comparisons", ["Kate Earnshaw", "Erica Gold"], "https://doi.org/10.21437/Interspeech.2018-1944", 5, "interspeech", 2018], ["The 'West Yorkshire Regional English Database': Investigations into the Generalizability of Reference Populations for Forensic Speaker Comparison Casework", ["Erica Gold", "Sula Ross", "Kate Earnshaw"], "https://doi.org/10.21437/Interspeech.2018-65", 5, "interspeech", 2018]], "Kaiyuan Xu": [0, ["Filter Sampling and Combination CNN (FSC-CNN): A Compact CNN Model for Small-footprint ASR Acoustic Modeling Using Raw Waveforms", ["Jinxi Guo", "Ning Xu", "Xin Chen", "Yang Shi", "Kaiyuan Xu", "Abeer Alwan"], "https://doi.org/10.21437/Interspeech.2018-1370", 5, "interspeech", 2018]], "Nathalie Camelin": [0, ["Task Specific Sentence Embeddings for ASR Error Detection", ["Sahar Ghannay", "Yannick Esteve", "Nathalie Camelin"], "https://doi.org/10.21437/Interspeech.2018-2211", 5, "interspeech", 2018]], "Quy-Thao Truong": [0, ["Automatic Assessment of L2 English Word Prosody Using Weighted Distances of F0 and Intensity Contours", ["Quy-Thao Truong", "Tsuneo Kato", "Seiichi Yamamoto"], "https://doi.org/10.21437/Interspeech.2018-1386", 5, "interspeech", 2018]], "Okko Rasanen": [0, ["Time-regularized Linear Prediction for Noise-robust Extraction of the Spectral Envelope of Speech", ["Manu Airaksinen", "Lauri Juvela", "Okko Rasanen", "Paavo Alku"], "https://doi.org/10.21437/Interspeech.2018-1230", 5, "interspeech", 2018], ["Comparison of Syllabification Algorithms and Training Strategies for Robust Word Count Estimation across Different Languages and Recording Conditions", ["Okko Rasanen", "Shreyas Seshadri", "Marisa Casillas"], "https://doi.org/10.21437/Interspeech.2018-1047", 5, "interspeech", 2018]], "Jianwu Dang": [0, ["Multiple Phase Information Combination for Replay Attacks Detection", ["Dongbo Li", "Longbiao Wang", "Jianwu Dang", "Meng Liu", "Zeyan Oo", "Seiichi Nakagawa", "Haotian Guan", "Xiangang Li"], "https://doi.org/10.21437/Interspeech.2018-2001", 5, "interspeech", 2018], ["Revealing Spatiotemporal Brain Dynamics of Speech Production Based on EEG and Eye Movement", ["Bin Zhao", "Jinfeng Huang", "Gaoyan Zhang", "Jianwu Dang", "Minbo Chen", "YingjianFu", "Longbiao Wang"], "https://doi.org/10.21437/Interspeech.2018-1908", 5, "interspeech", 2018], ["Speech Emotion Recognition by Combining Amplitude and Phase Information Using Convolutional Neural Network", ["Lili Guo", "Longbiao Wang", "Jianwu Dang", "Linjuan Zhang", "Haotian Guan", "Xiangang Li"], "https://doi.org/10.21437/Interspeech.2018-2156", 5, "interspeech", 2018]], "Vincent Aubanel": [0, ["Investigating the Role of Familiar Face and Voice Cues in Speech Processing in Noise", ["Jeesun Kim", "Sonya Karisma", "Vincent Aubanel", "Chris Davis"], "https://doi.org/10.21437/Interspeech.2018-1812", 4, "interspeech", 2018]], "Constantinos Papayiannis": [0, ["Detecting Media Sound Presence in Acoustic Scenes", ["Constantinos Papayiannis", "Justice Amoh", "Viktor Rozgic", "Shiva Sundaram", "Chao Wang"], "https://doi.org/10.21437/Interspeech.2018-2559", 5, "interspeech", 2018]], "Carla Agurto": [0, ["Detection of Amyotrophic Lateral Sclerosis (ALS) via Acoustic Analysis", ["Raquel Norel", "Mary Pietrowicz", "Carla Agurto", "Shay Rishoni", "Guillermo A. Cecchi"], "https://doi.org/10.21437/Interspeech.2018-2389", 5, "interspeech", 2018]], "Pierre Godard": [0, ["Unsupervised Word Segmentation from Speech with Attention", ["Pierre Godard", "Marcely Zanon Boito", "Lucas Ondel", "Alexandre Berard", "Francois Yvon", "Aline Villavicencio", "Laurent Besacier"], "https://doi.org/10.21437/Interspeech.2018-1308", 5, "interspeech", 2018]], "Mohammad Sadegh Rasooli": [0, ["Entity-Aware Language Model as an Unsupervised Reranker", ["Mohammad Sadegh Rasooli", "Sarangarajan Parthasarathy"], "https://doi.org/10.21437/Interspeech.2018-62", 5, "interspeech", 2018]], "Hector Delgado": [0, ["Integrated Presentation Attack Detection and Automatic Speaker Verification: Common Features and Gaussian Back-end Fusion", ["Massimiliano Todisco", "Hector Delgado", "Kong-Aik Lee", "Md. Sahidullah", "Nicholas W. D. Evans", "Tomi Kinnunen", "Junichi Yamagishi"], "https://doi.org/10.21437/Interspeech.2018-2289", 5, "interspeech", 2018], ["Speech Database and Protocol Validation Using Waveform Entropy", ["Itshak Lapidot", "Hector Delgado", "Massimiliano Todisco", "Nicholas W. D. Evans", "Jean-Francois Bonastre"], "https://doi.org/10.21437/Interspeech.2018-2330", 5, "interspeech", 2018], ["The EURECOM Submission to the First DIHARD Challenge", ["Jose Patino", "Hector Delgado", "Nicholas W. D. Evans"], "https://doi.org/10.21437/Interspeech.2018-2172", 5, "interspeech", 2018]], "Sunil Rudresh": [0, ["An Optimization Framework for Recovery of Speech from Phase-Encoded Spectrograms", ["Abhilash Sainathan", "Sunil Rudresh", "Chandra Sekhar Seelamantula"], "https://doi.org/10.21437/Interspeech.2018-1987", 5, "interspeech", 2018]], "Zhihua Su": [0, ["Tongue Segmentation with Geometrically Constrained Snake Model", ["Zhihua Su", "Jianguo Wei", "Qiang Fang", "Jianrong Wang", "Kiyoshi Honda"], "https://doi.org/10.21437/Interspeech.2018-1108", 5, "interspeech", 2018]], "Lianhong Cai": [0, ["Siamese Recurrent Auto-Encoder Representation for Query-by-Example Spoken Term Detection", ["Ziwei Zhu", "Zhiyong Wu", "Runnan Li", "Helen Meng", "Lianhong Cai"], "https://doi.org/10.21437/Interspeech.2018-1788", 5, "interspeech", 2018], ["Emotion Recognition from Variable-Length Speech Segments Using Deep Learning on Spectrograms", ["Xi Ma", "Zhiyong Wu", "Jia Jia", "Mingxing Xu", "Helen Meng", "Lianhong Cai"], "https://doi.org/10.21437/Interspeech.2018-2228", 5, "interspeech", 2018]], "Mate Akos Tundik": [0, ["User-centric Evaluation of Automatic Punctuation in ASR Closed Captioning", ["Mate Akos Tundik", "Gyorgy Szaszak", "Gabor Gosztolya", "Andras Beke"], "https://doi.org/10.21437/Interspeech.2018-1352", 5, "interspeech", 2018]], "Giuseppina Turco": [0, ["Length Contrast and Covarying Features: Whistled Speech as a Case Study", ["Rachid Ridouane", "Giuseppina Turco", "Julien Meyer"], "https://doi.org/10.21437/Interspeech.2018-1060", 5, "interspeech", 2018]], "Hemanth Venkateswara": [0, ["Whistle-blowing ASRs: Evaluating the Need for More Inclusive Speech Recognition Systems", ["Meredith Moore", "Hemanth Venkateswara", "Sethuraman Panchanathan"], "https://doi.org/10.21437/Interspeech.2018-2391", 5, "interspeech", 2018]], "Andrew Rosenberg": [0, ["Data Augmentation Improves Recognition of Foreign Accented Speech", ["Takashi Fukuda", "Raul Fernandez", "Andrew Rosenberg", "Samuel Thomas", "Bhuvana Ramabhadran", "Alexander Sorin", "Gakuto Kurata"], "https://doi.org/10.21437/Interspeech.2018-1211", 5, "interspeech", 2018]], "Ana Isabel Mata": [0, ["Acoustic-prosodic Entrainment in Structural Metadata Events", ["Vera Cabarrao", "Fernando Batista", "Helena Moniz", "Isabel Trancoso", "Ana Isabel Mata"], "https://doi.org/10.21437/Interspeech.2018-2366", 5, "interspeech", 2018]], "Andrei A. Shlykov": [0, ["LOCUST - Longitudinal Corpus and Toolset for Speaker Verification", ["Evgeny Dmitriev", "Yulia Kim", "Anastasia Matveeva", "Claude Montacie", "Yannick Boulard", "Yadviga Sinyavskaya", "Yulia Zhukova", "Adam Zarazinski", "Egor Akhanov", "Ilya I. Viksnin", "Andrei A. Shlykov", "Maria Usova"], "https://doi.org/10.21437/Interspeech.2018-2412", 5, "interspeech", 2018]], "Petr Cerva": [0, ["Using Deep Neural Networks for Identification of Slavic Languages from Acoustic Signal", ["Lukas Mateju", "Petr Cerva", "Jindrich Zdansky", "Radek Safarik"], "https://doi.org/10.21437/Interspeech.2018-1165", 5, "interspeech", 2018]], "Erfan Loweimi": [0, ["On the Usefulness of the Speech Phase Spectrum for Pitch Extraction", ["Erfan Loweimi", "Jon Barker", "Thomas Hain"], "https://doi.org/10.21437/Interspeech.2018-1062", 5, "interspeech", 2018]], "Chenxing Li": [0, ["Single-channel Speech Dereverberation via Generative Adversarial Training", ["Chenxing Li", "Tieqiang Wang", "Shuang Xu", "Bo Xu"], "https://doi.org/10.21437/Interspeech.2018-1234", 5, "interspeech", 2018]], "Gaetano Di Caterina": [0, ["A Deep Learning Method for Pathological Voice Detection Using Convolutional Deep Belief Networks", ["Huiyi Wu", "John J. Soraghan", "Anja Lowit", "Gaetano Di Caterina"], "https://doi.org/10.21437/Interspeech.2018-1351", 5, "interspeech", 2018]], "Hieu-Thi Luong": [0, ["Investigating Accuracy of Pitch-accent Annotations in Neural Network-based Speech Synthesis and Denoising Effects", ["Hieu-Thi Luong", "Xin Wang", "Junichi Yamagishi", "Nobuyuki Nishizawa"], "https://doi.org/10.21437/Interspeech.2018-1227", 5, "interspeech", 2018], ["Multimodal Speech Synthesis Architecture for Unsupervised Speaker Adaptation", ["Hieu-Thi Luong", "Junichi Yamagishi"], "https://doi.org/10.21437/Interspeech.2018-1791", 5, "interspeech", 2018]], "Ananya Misra": [0, ["Domain Adaptation Using Factorized Hidden Layer for Robust Automatic Speech Recognition", ["Khe Chai Sim", "Arun Narayanan", "Ananya Misra", "Anshuman Tripathi", "Golan Pundak", "Tara N. Sainath", "Parisa Haghani", "Bo Li", "Michiel Bacchiani"], "https://doi.org/10.21437/Interspeech.2018-2246", 5, "interspeech", 2018]], "Mark Huckvale": [0, ["Neural Network Architecture That Combines Temporal and Summative Features for Infant Cry Classification in the Interspeech 2018 Computational Paralinguistics Challenge", ["Mark Huckvale"], "https://doi.org/10.21437/Interspeech.2018-1959", 5, "interspeech", 2018]], "Vimal Manohar": [0, ["Automatic Speech Recognition and Topic Identification from Speech for Almost-Zero-Resource Languages", ["Matthew Wiesner", "Chunxi Liu", "Lucas Ondel", "Craig Harman", "Vimal Manohar", "Jan Trmal", "Zhongqiang Huang", "Najim Dehak", "Sanjeev Khudanpur"], "https://doi.org/10.21437/Interspeech.2018-1836", 5, "interspeech", 2018], ["Diarization is Hard: Some Experiences and Lessons Learned for the JHU Team in the Inaugural DIHARD Challenge", ["Gregory Sell", "David Snyder", "Alan McCree", "Daniel Garcia-Romero", "Jesus Villalba", "Matthew Maciejewski", "Vimal Manohar", "Najim Dehak", "Daniel Povey", "Shinji Watanabe", "Sanjeev Khudanpur"], "https://doi.org/10.21437/Interspeech.2018-1893", 5, "interspeech", 2018]], "Tomohiro Tanaka": [0, ["Neural Error Corrective Language Models for Automatic Speech Recognition", ["Tomohiro Tanaka", "Ryo Masumura", "Hirokazu Masataki", "Yushi Aono"], "https://doi.org/10.21437/Interspeech.2018-1430", 5, "interspeech", 2018], ["Role Play Dialogue Aware Language Models Based on Conditional Hierarchical Recurrent Encoder-Decoder", ["Ryo Masumura", "Tomohiro Tanaka", "Atsushi Ando", "Hirokazu Masataki", "Yushi Aono"], "https://doi.org/10.21437/Interspeech.2018-2185", 5, "interspeech", 2018]], "Ka Ho Wong": [0, ["Development of the CUHK Dysarthric Speech Recognition System for the UA Speech Corpus", ["Jianwei Yu", "Xurong Xie", "Shansong Liu", "Shoukang Hu", "Max W. Y. Lam", "Xixin Wu", "Ka Ho Wong", "Xunying Liu", "Helen Meng"], "https://doi.org/10.21437/Interspeech.2018-1541", 5, "interspeech", 2018]], "Nassima Fezza": [0, ["The Role of Temporal Variation in Narrative Organization", ["Nassima Fezza"], "https://doi.org/10.21437/Interspeech.2018-1725", 5, "interspeech", 2018]], "Eleanor Chodroff": [0, ["Information Structure, Affect and Prenuclear Prominence in American English", ["Eleanor Chodroff", "Jennifer Cole"], "https://doi.org/10.21437/Interspeech.2018-1529", 5, "interspeech", 2018]], "Dan Darcy": [0, ["Voice Conversion with Conditional SampleRNN", ["Cong Zhou", "Michael Horgan", "Vivek Kumar", "Cristina Vasco", "Dan Darcy"], "https://doi.org/10.21437/Interspeech.2018-1121", 5, "interspeech", 2018]], "Korin Richmond": [0, ["UltraSuite: A Repository of Ultrasound and Acoustic Data from Child Speech Therapy Sessions", ["Aciel Eshky", "Manuel Sam Ribeiro", "Joanne Cleland", "Korin Richmond", "Zoe Roxburgh", "James M. Scobbie", "Alan Wrench"], "https://doi.org/10.21437/Interspeech.2018-1736", 5, "interspeech", 2018]], "Gahgene Gweon": [0.0009573765273671597, ["Automatic Miscue Detection Using RNN Based Models with Data Augmentation", ["Yoon Seok Hong", "Kyung Seo Ki", "Gahgene Gweon"], "https://doi.org/10.21437/Interspeech.2018-1644", 5, "interspeech", 2018]], "Daisuke Saito": [0, ["A Comparative Study of Statistical Conversion of Face to Voice Based on Their Subjective Impressions", ["Yasuhito Ohsugi", "Daisuke Saito", "Nobuaki Minematsu"], "https://doi.org/10.21437/Interspeech.2018-2005", 5, "interspeech", 2018], ["A Study of Objective Measurement of Comprehensibility through Native Speakers' Shadowing of Learners' Utterances", ["Yusuke Inoue", "Suguru Kabashima", "Daisuke Saito", "Nobuaki Minematsu", "Kumi Kanamura", "Yutaka Yamauchi"], "https://doi.org/10.21437/Interspeech.2018-1860", 5, "interspeech", 2018]], "Michael Towsey": [0, ["Deep Learning Techniques for Koala Activity Detection", ["Ivan Himawan", "Michael Towsey", "Bradley Law", "Paul Roe"], "https://doi.org/10.21437/Interspeech.2018-1143", 5, "interspeech", 2018]], "Angeliki Metallinou": [0, ["Contextual Language Model Adaptation for Conversational Agents", ["Anirudh Raju", "Behnam Hedayatnia", "Linda Liu", "Ankur Gandhe", "Chandra Khatri", "Angeliki Metallinou", "Anu Venkatesh", "Ariya Rastrow"], "https://doi.org/10.21437/Interspeech.2018-1122", 5, "interspeech", 2018]], "Zhongxin Bai": [1.279472527926373e-08, ["Cosine Metric Learning for Speaker Verification in the I-vector Space", ["Zhongxin Bai", "Xiao-Lei Zhang", "Jingdong Chen"], "https://doi.org/10.21437/Interspeech.2018-1593", 5, "interspeech", 2018]], "Shelagh Brumfitt": [0, ["A Lightly Supervised Approach to Detect Stuttering in Children's Speech", ["Sadeen Alharbi", "Madina Hasan", "Anthony J. H. Simons", "Shelagh Brumfitt", "Phil D. Green"], "https://doi.org/10.21437/Interspeech.2018-2155", 5, "interspeech", 2018]], "Bianca Vieru": [0, ["Exploring Temporal Reduction in Dialectal Spanish: A Large-scale Study of Lenition of Voiced Stops and Coda-s", ["Ioana Vasilescu", "Nidia Hernandez", "Bianca Vieru", "Lori Lamel"], "https://doi.org/10.21437/Interspeech.2018-1256", 5, "interspeech", 2018]], "Marija Tabain": [0, ["Formant Measures of Vowels Adjacent to Alveolar and Retroflex Consonants in Arrernte: Stressed and Unstressed Position", ["Marija Tabain", "Richard Beare", "Andrew Butcher"], "https://doi.org/10.21437/Interspeech.2018-1126", 5, "interspeech", 2018]], "Xixin Wu": [1.2604690624584691e-08, ["Voice Conversion Across Arbitrary Speakers Based on a Single Target-Speaker Utterance", ["Songxiang Liu", "Jinghua Zhong", "Lifa Sun", "Xixin Wu", "Xunying Liu", "Helen Meng"], "https://doi.org/10.21437/Interspeech.2018-1504", 5, "interspeech", 2018], ["Unsupervised Discovery of Non-native Phonetic Patterns in L2 English Speech for Mispronunciation Detection and Diagnosis", ["Xu Li", "Shaoguang Mao", "Xixin Wu", "Kun Li", "Xunying Liu", "Helen Meng"], "https://doi.org/10.21437/Interspeech.2018-2027", 5, "interspeech", 2018], ["Development of the CUHK Dysarthric Speech Recognition System for the UA Speech Corpus", ["Jianwei Yu", "Xurong Xie", "Shansong Liu", "Shoukang Hu", "Max W. Y. Lam", "Xixin Wu", "Ka Ho Wong", "Xunying Liu", "Helen Meng"], "https://doi.org/10.21437/Interspeech.2018-1541", 5, "interspeech", 2018], ["Rapid Style Adaptation Using Residual Error Embedding for Expressive Speech Synthesis", ["Xixin Wu", "Yuewen Cao", "Mu Wang", "Songxiang Liu", "Shiyin Kang", "Zhiyong Wu", "Xunying Liu", "Dan Su", "Dong Yu", "Helen Meng"], "https://doi.org/10.21437/Interspeech.2018-1991", 5, "interspeech", 2018]], "Digvijaysingh Gautam": [0, ["Time Aggregation Operators for Multi-label Audio Event Detection", ["Pankaj Joshi", "Digvijaysingh Gautam", "Ganesh Ramakrishnan", "Preethi Jyothi"], "https://doi.org/10.21437/Interspeech.2018-1637", 5, "interspeech", 2018]], "Reinhold Haeb-Umbach": [0, ["Full Bayesian Hidden Markov Model Variational Autoencoder for Acoustic Unit Discovery", ["Thomas Glarner", "Patrick Hanebrink", "Janek Ebbers", "Reinhold Haeb-Umbach"], "https://doi.org/10.21437/Interspeech.2018-2148", 5, "interspeech", 2018], ["Integrating Neural Network Based Beamforming and Weighted Prediction Error Dereverberation", ["Lukas Drude", "Christoph Boddeker", "Jahn Heymann", "Reinhold Haeb-Umbach", "Keisuke Kinoshita", "Marc Delcroix", "Tomohiro Nakatani"], "https://doi.org/10.21437/Interspeech.2018-2196", 5, "interspeech", 2018]], "Lu Yin": [0, ["Multi-talker Speech Separation Based on Permutation Invariant Training and Beamforming", ["Lu Yin", "Ziteng Wang", "Risheng Xia", "Junfeng Li", "Yonghong Yan"], "https://doi.org/10.21437/Interspeech.2018-1739", 5, "interspeech", 2018]], "Mireia Farrus": [0, ["Visualizing Punctuation Restoration in Speech Transcripts with Prosograph", ["Alp Oktem", "Mireia Farrus", "Antonio Bonafonte"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3028.html", 2, "interspeech", 2018]], "Michal Busta": [0, ["Multimodal Name Recognition in Live TV Subtitling", ["Marek Hruz", "Ales Prazak", "Michal Busta"], "https://doi.org/10.21437/Interspeech.2018-1748", 4, "interspeech", 2018]], "Nicolas Usunier": [0, ["End-to-End Speech Recognition from the Raw Waveform", ["Neil Zeghidour", "Nicolas Usunier", "Gabriel Synnaeve", "Ronan Collobert", "Emmanuel Dupoux"], "https://doi.org/10.21437/Interspeech.2018-2414", 5, "interspeech", 2018]], "Robert A. Pugh": [0, ["Improvements to an Automated Content Scoring System for Spoken CALL Responses: the ETS Submission to the Second Spoken CALL Shared Task", ["Keelan Evanini", "Matthew Mulholland", "Rutuja Ubale", "Yao Qian", "Robert A. Pugh", "Vikram Ramanarayanan", "Aoife Cahill"], "https://doi.org/10.21437/Interspeech.2018-2362", 5, "interspeech", 2018]], "Peter French": [0, ["The Individual and the System: Assessing the Stability of the Output of a Semi-automatic Forensic Voice Comparison System", ["Vincent Hughes", "Philip Harrison", "Paul Foulkes", "Peter French", "Colleen Kavanagh", "Eugenia San Segundo Fernandez"], "https://doi.org/10.21437/Interspeech.2018-1649", 5, "interspeech", 2018]], "Raghavendra Pappagari": [0, ["Deep Neural Networks for Emotion Recognition Combining Audio and Transcripts", ["Jaejin Cho", "Raghavendra Pappagari", "Purva Kulkarni", "Jesus Villalba", "Yishay Carmiel", "Najim Dehak"], "https://doi.org/10.21437/Interspeech.2018-2466", 5, "interspeech", 2018]], "Richard Beare": [0, ["Formant Measures of Vowels Adjacent to Alveolar and Retroflex Consonants in Arrernte: Stressed and Unstressed Position", ["Marija Tabain", "Richard Beare", "Andrew Butcher"], "https://doi.org/10.21437/Interspeech.2018-1126", 5, "interspeech", 2018]], "Tianqi Wang": [4.794821872877719e-09, ["Acoustic Features Associated with Sustained Vowel and Continuous Speech Productions by Chinese Children with Functional Articulation Disorders", ["Wang Zhang", "Xiangquan Gui", "Tianqi Wang", "Manwa L. Ng", "Feng Yang", "Lan Wang", "Nan Yan"], "https://doi.org/10.21437/Interspeech.2018-1521", 5, "interspeech", 2018]], "Yuya Chiba": [0, ["Analyzing Effect of Physical Expression on English Proficiency for Multimodal Computer-Assisted Language Learning", ["Haoran Wu", "Yuya Chiba", "Takashi Nose", "Akinori Ito"], "https://doi.org/10.21437/Interspeech.2018-1425", 5, "interspeech", 2018]], "Rajbabu Velmurugan": [0, ["A Non-convolutive NMF Model for Speech Dereverberation", ["Nikhil Mohanan", "Rajbabu Velmurugan", "Preeti Rao"], "https://doi.org/10.21437/Interspeech.2018-1834", 5, "interspeech", 2018]], "Reima Karhila": [0, ["Captaina: Integrated Pronunciation Practice and Data Collection Portal", ["Aku Rouhe", "Reima Karhila", "Aija Elg", "Minnaleena Toivola", "Peter Smit", "Anna-Riikka Smolander", "Mikko Kurimo"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3015.html", 2, "interspeech", 2018]], "Yulun Du": [0, ["Multimodal Polynomial Fusion for Detecting Driver Distraction", ["Yulun Du", "Alan W. Black", "Louis-Philippe Morency", "Maxine Eskenazi"], "https://doi.org/10.21437/Interspeech.2018-2011", 5, "interspeech", 2018]], "Heewoong Park": [0.9999277591705322, ["Training Utterance-level Embedding Networks for Speaker Identification and Verification", ["Heewoong Park", "Sukhyun Cho", "Kyubyong Park", "Namju Kim", "Jonghun Park"], "https://doi.org/10.21437/Interspeech.2018-1044", 5, "interspeech", 2018]], "Joao Freitas": [0, ["Machine Learning Powered Data Platform for High-Quality Speech and NLP Workflows", ["Joao Freitas", "Jorge Ribeiro", "Daan Baldewijns", "Sara Oliveira", "Daniela Braga"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3033.html", 2, "interspeech", 2018]], "Jingdong Chen": [0, ["Cosine Metric Learning for Speaker Verification in the I-vector Space", ["Zhongxin Bai", "Xiao-Lei Zhang", "Jingdong Chen"], "https://doi.org/10.21437/Interspeech.2018-1593", 5, "interspeech", 2018]], "Yu Zheng": [0, ["Exploring Spatio-Temporal Representations by Integrating Attention-based Bidirectional-LSTM-RNNs and FCNs for Speech Emotion Recognition", ["Ziping Zhao", "Yu Zheng", "Zixing Zhang", "Haishuai Wang", "Yiqin Zhao", "Chao Li"], "https://doi.org/10.21437/Interspeech.2018-1477", 5, "interspeech", 2018]], "Hsin-Min Wang": [0.0006203114317031577, ["Exemplar-Based Spectral Detail Compensation for Voice Conversion", ["Yu-Huai Peng", "Hsin-Te Hwang", "Yi-Chiao Wu", "Yu Tsao", "Hsin-Min Wang"], "https://doi.org/10.21437/Interspeech.2018-1662", 5, "interspeech", 2018], ["Quality-Net: An End-to-End Non-intrusive Speech Quality Assessment Model Based on BLSTM", ["Szu-Wei Fu", "Yu Tsao", "Hsin-Te Hwang", "Hsin-Min Wang"], "https://doi.org/10.21437/Interspeech.2018-1802", 5, "interspeech", 2018]], "Gerard Bailly": [0, ["A Weighted Superposition of Functional Contours Model for Modelling Contextual Prominence of Elementary Prosodic Contours", ["Branislav Gerazov", "Gerard Bailly", "Yi Xu"], "https://doi.org/10.21437/Interspeech.2018-1286", 5, "interspeech", 2018]], "Alexander Kozlov": [0, ["Triplet Loss Based Cosine Similarity Metric Learning for Text-independent Speaker Recognition", ["Sergey Novoselov", "Vadim Shchemelinin", "Andrey Shulipa", "Alexander Kozlov", "Ivan Kremnev"], "https://doi.org/10.21437/Interspeech.2018-1209", 5, "interspeech", 2018]], "Michael I. Mandel": [0, ["Large Vocabulary Concatenative Resynthesis", ["Soumi Maiti", "Joey Ching", "Michael I. Mandel"], "https://doi.org/10.21437/Interspeech.2018-2383", 5, "interspeech", 2018], ["Concatenative Resynthesis with Improved Training Signals for Speech Enhancement", ["Ali Raza Syed", "Viet Anh Trinh", "Michael I. Mandel"], "https://doi.org/10.21437/Interspeech.2018-2439", 5, "interspeech", 2018], ["Bubble Cooperative Networks for Identifying Important Speech Cues", ["Viet Anh Trinh", "Brian McFee", "Michael I. Mandel"], "https://doi.org/10.21437/Interspeech.2018-2377", 5, "interspeech", 2018]], "Jonathan Wright": [0, ["GlobalTIMIT: Acoustic-Phonetic Datasets for the World's Languages", ["Nattanun Chanchaochai", "Christopher Cieri", "Japhet Debrah", "Hongwei Ding", "Yue Jiang", "Sishi Liao", "Mark Liberman", "Jonathan Wright", "Jiahong Yuan", "Juhong Zhan", "Yuqing Zhan"], "https://doi.org/10.21437/Interspeech.2018-1185", 5, "interspeech", 2018]], "Olympia Simantiraki": [0, ["Impact of Different Speech Types on Listening Effort", ["Olympia Simantiraki", "Martin Cooke", "Simon King"], "https://doi.org/10.21437/Interspeech.2018-1358", 5, "interspeech", 2018]], "Anand P. A": [0, ["Intonation tutor by SPIRE (In-SPIRE): An Online Tool for an Automatic Feedback to the Second Language Learners in Learning Intonation", ["Anand P. A", "Chiranjeevi Yarra", "N. K. Kausthubha", "Prasanta Kumar Ghosh"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3008.html", 2, "interspeech", 2018], ["SPIRE-SST: An Automatic Web-based Self-learning Tool for Syllable Stress Tutoring (SST) to the Second Language Learners", ["Chiranjeevi Yarra", "Anand P. A", "N. K. Kausthubha", "Prasanta Kumar Ghosh"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3009.html", 2, "interspeech", 2018]], "Abhijeet Sangwan": [0, ["Fearless Steps: Apollo-11 Corpus Advancements for Speech Technologies from Earth to the Moon", ["John H. L. Hansen", "Abhijeet Sangwan", "Aditya Joglekar", "Ahmet Emin Bulut", "Lakshmish Kaushik", "Chengzhu Yu"], "https://doi.org/10.21437/Interspeech.2018-1942", 5, "interspeech", 2018], ["Robust Speaker Clustering using Mixtures of von Mises-Fisher Distributions for Naturalistic Audio Streams", ["Harishchandra Dubey", "Abhijeet Sangwan", "John H. L. Hansen"], "https://doi.org/10.21437/Interspeech.2018-50", 5, "interspeech", 2018]], "Zhong-Qiu Wang": [1.0870333767235701e-12, ["Robust TDOA Estimation Based on Time-Frequency Masking and Deep Neural Networks", ["Zhong-Qiu Wang", "Xueliang Zhang", "DeLiang Wang"], "https://doi.org/10.21437/Interspeech.2018-1652", 5, "interspeech", 2018], ["End-to-End Speech Separation with Unfolded Iterative Phase Reconstruction", ["Zhong-Qiu Wang", "Jonathan Le Roux", "DeLiang Wang", "John R. Hershey"], "https://doi.org/10.21437/Interspeech.2018-1629", 5, "interspeech", 2018], ["Integrating Spectral and Spatial Features for Multi-Channel Speaker Separation", ["Zhong-Qiu Wang", "DeLiang Wang"], "https://doi.org/10.21437/Interspeech.2018-1940", 5, "interspeech", 2018], ["All-Neural Multi-Channel Speech Enhancement", ["Zhong-Qiu Wang", "DeLiang Wang"], "https://doi.org/10.21437/Interspeech.2018-1664", 5, "interspeech", 2018]], "Shereen Oraby": [0, ["Neural MultiVoice Models for Expressing Novel Personalities in Dialog", ["Shereen Oraby", "Lena Reed", "Sharath T. S.", "Shubhangi Tandon", "Marilyn A. Walker"], "https://doi.org/10.21437/Interspeech.2018-2174", 5, "interspeech", 2018]], "Miguel Angrick": [0, ["Investigating the Effect of Audio Duration on Dementia Detection Using Acoustic Features", ["Jochen Weiner", "Miguel Angrick", "Srinivasan Umesh", "Tanja Schultz"], "https://doi.org/10.21437/Interspeech.2018-57", 5, "interspeech", 2018]], "Anton Batliner": [0, ["The INTERSPEECH 2018 Computational Paralinguistics Challenge: Atypical & Self-Assessed Affect, Crying & Heart Beats", ["Bjorn W. Schuller", "Stefan Steidl", "Anton Batliner", "Peter B. Marschik", "Harald Baumeister", "Fengquan Dong", "Simone Hantke", "Florian B. Pokorny", "Eva-Maria Rathner", "Katrin D. Bartl-Pokorny", "Christa Einspieler", "Dajie Zhang", "Alice Baird", "Shahin Amiriparian", "Kun Qian", "Zhao Ren", "Maximilian Schmitt", "Panagiotis Tzirakis", "Stefanos Zafeiriou"], "https://doi.org/10.21437/Interspeech.2018-51", 5, "interspeech", 2018], ["Categorical vs Dimensional Perception of Italian Emotional Speech", ["Emilia Parada-Cabaleiro", "Giovanni Costantini", "Anton Batliner", "Alice Baird", "Bjorn W. Schuller"], "https://doi.org/10.21437/Interspeech.2018-47", 5, "interspeech", 2018]], "Xin Wang": [0.0001022029246087186, ["Investigating Accuracy of Pitch-accent Annotations in Neural Network-based Speech Synthesis and Denoising Effects", ["Hieu-Thi Luong", "Xin Wang", "Junichi Yamagishi", "Nobuyuki Nishizawa"], "https://doi.org/10.21437/Interspeech.2018-1227", 5, "interspeech", 2018]], "Daksh Thapar": [0, ["All-Conv Net for Bird Activity Detection: Significance of Learned Pooling", ["Arjun Pankajakshan", "Anshul Thakur", "Daksh Thapar", "Padmanabhan Rajan", "Aditya Nigam"], "https://doi.org/10.21437/Interspeech.2018-1522", 5, "interspeech", 2018]], "Yiming Wang": [5.499646135831426e-06, ["A GPU-based WFST Decoder with Exact Lattice Generation", ["Zhehuai Chen", "Justin Luitjens", "Hainan Xu", "Yiming Wang", "Daniel Povey", "Sanjeev Khudanpur"], "https://doi.org/10.21437/Interspeech.2018-1339", 5, "interspeech", 2018], ["Recurrent Neural Network Language Model Adaptation for Conversational Speech Recognition", ["Ke Li", "Hainan Xu", "Yiming Wang", "Daniel Povey", "Sanjeev Khudanpur"], "https://doi.org/10.21437/Interspeech.2018-1413", 5, "interspeech", 2018], ["Semi-Orthogonal Low-Rank Matrix Factorization for Deep Neural Networks", ["Daniel Povey", "Gaofeng Cheng", "Yiming Wang", "Ke Li", "Hainan Xu", "Mahsa Yarmohammadi", "Sanjeev Khudanpur"], "https://doi.org/10.21437/Interspeech.2018-1417", 5, "interspeech", 2018]], "Etienne Gaudrain": [0, ["Who Are You Listening to? Towards a Dynamic Measure of Auditory Attention to Speech-on-speech", ["Moira-Phoebe Huet", "Christophe Micheyl", "Etienne Gaudrain", "Etienne Parizet"], "https://doi.org/10.21437/Interspeech.2018-2053", 4, "interspeech", 2018]], "G. R. Kasthuri": [0, ["Early Vocabulary Development Through Picture-based Software Solutions", ["G. R. Kasthuri", "Prabha Ramanathan", "Hema A. Murthy", "Namita Jacob", "Anil Prabhakar"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3022.html", 2, "interspeech", 2018]], "Liang He": [0, ["Speaker Embedding Extraction with Phonetic Information", ["Yi Liu", "Liang He", "Jia Liu", "Michael T. Johnson"], "https://doi.org/10.21437/Interspeech.2018-1226", 5, "interspeech", 2018], ["MTGAN: Speaker Verification through Multitasking Triplet Generative Adversarial Networks", ["Wenhao Ding", "Liang He"], "https://doi.org/10.21437/Interspeech.2018-1023", 5, "interspeech", 2018]], "Koji Inoue": [0, ["Engagement Recognition in Spoken Dialogue via Neural Network by Aggregating Different Annotators' Models", ["Koji Inoue", "Divesh Lala", "Katsuya Takanashi", "Tatsuya Kawahara"], "https://doi.org/10.21437/Interspeech.2018-2067", 5, "interspeech", 2018], ["Prediction of Turn-taking Using Multitask Learning with Prediction of Backchannels and Fillers", ["Kohei Hara", "Koji Inoue", "Katsuya Takanashi", "Tatsuya Kawahara"], "https://doi.org/10.21437/Interspeech.2018-1442", 5, "interspeech", 2018]], "Shreyas Seshadri": [0, ["Comparison of Syllabification Algorithms and Training Strategies for Robust Word Count Estimation across Different Languages and Recording Conditions", ["Okko Rasanen", "Shreyas Seshadri", "Marisa Casillas"], "https://doi.org/10.21437/Interspeech.2018-1047", 5, "interspeech", 2018]], "Helena Moniz": [0, ["Acoustic-prosodic Entrainment in Structural Metadata Events", ["Vera Cabarrao", "Fernando Batista", "Helena Moniz", "Isabel Trancoso", "Ana Isabel Mata"], "https://doi.org/10.21437/Interspeech.2018-2366", 5, "interspeech", 2018]], "David Pautler": [0, ["Toward Scalable Dialog Technology for Conversational Language Learning: Case Study of the TOEFL\u00ae MOOC", ["Vikram Ramanarayanan", "David Pautler", "Patrick L. Lange", "Eugene Tsuprun", "Rutuja Ubale", "Keelan Evanini", "David Suendermann-Oeft"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3032.html", 2, "interspeech", 2018]], "Michelle Guo": [0, ["Conditional End-to-End Audio Transforms", ["Albert Haque", "Michelle Guo", "Prateek Verma"], "https://doi.org/10.21437/Interspeech.2018-38", 5, "interspeech", 2018]], "Keisuke Tanihara": [0, ["Implementation of Respiration in Articulatory Synthesis Using a Pressure-Volume Lung Model", ["Keisuke Tanihara", "Shogo Yonekura", "Yasuo Kuniyoshi"], "https://doi.org/10.21437/Interspeech.2018-1080", 5, "interspeech", 2018]], "Yueming Ding": [0, ["Multi-frame Coding of LSF Parameters Using Block-Constrained Trellis Coded Vector Quantization", ["Yaxing Li", "Shan Xu", "Shengwu Xiong", "Anna Zhu", "Pengfei Duan", "Yueming Ding"], "https://doi.org/10.21437/Interspeech.2018-2578", 5, "interspeech", 2018]], "Antti Suni": [0, ["Prominence-based Evaluation of L2 Prosody", ["Heini Kallio", "Antti Suni", "Paivi Virkkunen", "Juraj Simko"], "https://doi.org/10.21437/Interspeech.2018-1873", 5, "interspeech", 2018]], "Martine Adda-Decker": [0, ["Studying Vowel Variation in French-Algerian Arabic Code-switched Speech", ["Jane Wottawa", "Djegdjiga Amazouz", "Martine Adda-Decker", "Lori Lamel"], "https://doi.org/10.21437/Interspeech.2018-2381", 5, "interspeech", 2018]], "Yoshiaki Itoh": [0, ["Empirical Analysis of Score Fusion Application to Combined Neural Networks for Open Vocabulary Spoken Term Detection", ["Shi-wook Lee", "Kazuyo Tanaka", "Yoshiaki Itoh"], "https://doi.org/10.21437/Interspeech.2018-1776", 5, "interspeech", 2018]], "Jerome Farinas": [0, ["Perceptual and Automatic Evaluations of the Intelligibility of Speech Degraded by Noise Induced Hearing Loss Simulation", ["Imed Laaridh", "Julien Tardieu", "Cynthia Magnen", "Pascal Gaillard", "Jerome Farinas", "Julien Pinquier"], "https://doi.org/10.21437/Interspeech.2018-1264", 5, "interspeech", 2018]], "Haoran Wu": [0.02372580673545599, ["Analyzing Effect of Physical Expression on English Proficiency for Multimodal Computer-Assisted Language Learning", ["Haoran Wu", "Yuya Chiba", "Takashi Nose", "Akinori Ito"], "https://doi.org/10.21437/Interspeech.2018-1425", 5, "interspeech", 2018]], "Bhaskar D. Rao": [0, ["Bone-Conduction Sensor Assisted Noise Estimation for Improved Speech Enhancement", ["Ching Hua Lee", "Bhaskar D. Rao", "Harinath Garudadri"], "https://doi.org/10.21437/Interspeech.2018-1046", 5, "interspeech", 2018]], "Mathew Magimai-Doss": [0, ["On Learning to Identify Genders from Raw Speech Signal Using CNNs", ["Selen Hande Kabil", "Hannah Muckenhirn", "Mathew Magimai-Doss"], "https://doi.org/10.21437/Interspeech.2018-1240", 5, "interspeech", 2018], ["Denoising and Raw-waveform Networks for Weakly-Supervised Gender Identification on Noisy Speech", ["Jilt Sebastian", "Manoj Kumar", "Pavan Kumar D. S.", "Mathew Magimai-Doss", "Hema A. Murthy", "Shrikanth Narayanan"], "https://doi.org/10.21437/Interspeech.2018-2321", 5, "interspeech", 2018], ["Implementing Fusion Techniques for the Classification of Paralinguistic Information", ["Bogdan Vlasenko", "Jilt Sebastian", "Pavan Kumar D. S.", "Mathew Magimai-Doss"], "https://doi.org/10.21437/Interspeech.2018-2360", 5, "interspeech", 2018], ["On Learning Vocal Tract System Related Speaker Discriminative Information from Raw Signal Using CNNs", ["Hannah Muckenhirn", "Mathew Magimai-Doss", "Sebastien Marcel"], "https://doi.org/10.21437/Interspeech.2018-1696", 5, "interspeech", 2018]], "Zhengqi Wen": [0, ["BLSTM-CRF Based End-to-End Prosodic Boundary Prediction with Context Sensitive Embeddings in a Text-to-Speech Front-End", ["Yibin Zheng", "Jianhua Tao", "Zhengqi Wen", "Ya Li"], "https://doi.org/10.21437/Interspeech.2018-1472", 5, "interspeech", 2018], ["Transfer Learning Based Progressive Neural Networks for Acoustic Modeling in Statistical Parametric Speech Synthesis", ["Ruibo Fu", "Jianhua Tao", "Yibin Zheng", "Zhengqi Wen"], "https://doi.org/10.21437/Interspeech.2018-1265", 5, "interspeech", 2018], ["On the Application and Compression of Deep Time Delay Neural Network for Embedded Statistical Parametric Speech Synthesis", ["Yibin Zheng", "Jianhua Tao", "Zhengqi Wen", "Ruibo Fu"], "https://doi.org/10.21437/Interspeech.2018-1970", 5, "interspeech", 2018], ["Deep Metric Learning for the Target Cost in Unit-Selection Speech Synthesizer", ["Ruibo Fu", "Jianhua Tao", "Yibin Zheng", "Zhengqi Wen"], "https://doi.org/10.21437/Interspeech.2018-1305", 5, "interspeech", 2018]], "Isabel Trancoso": [0, ["Acoustic-prosodic Entrainment in Structural Metadata Events", ["Vera Cabarrao", "Fernando Batista", "Helena Moniz", "Isabel Trancoso", "Ana Isabel Mata"], "https://doi.org/10.21437/Interspeech.2018-2366", 5, "interspeech", 2018], ["Mining Multimodal Repositories for Speech Affecting Diseases", ["M. Joana Correia", "Bhiksha Raj", "Isabel Trancoso", "Francisco Teixeira"], "https://doi.org/10.21437/Interspeech.2018-1806", 5, "interspeech", 2018], ["Patient Privacy in Paralinguistic Tasks", ["Francisco Teixeira", "Alberto Abad", "Isabel Trancoso"], "https://doi.org/10.21437/Interspeech.2018-2186", 5, "interspeech", 2018]], "Catherine Lord": [0, ["A Knowledge Driven Structural Segmentation Approach for Play-Talk Classification During Autism Assessment", ["Manoj Kumar", "Pooja Chebolu", "So Hyun Kim", "Kassandra Martinez", "Catherine Lord", "Shrikanth Narayanan"], "https://doi.org/10.21437/Interspeech.2018-1516", 5, "interspeech", 2018]], "Myriam Piccaluga": [0, ["Towards a Better Characterization of Parkinsonian Speech: A Multidimensional Acoustic Study", ["Veronique Delvaux", "Kathy Huet", "Myriam Piccaluga", "Sophie van Malderen", "Bernard Harmegnies"], "https://doi.org/10.21437/Interspeech.2018-1054", 5, "interspeech", 2018]], "Hartmut Helmke": [0, ["Iterative Learning of Speech Recognition Models for Air Traffic Control", ["Ajay Srinivasamurthy", "Petr Motlicek", "Mittul Singh", "Youssef Oualil", "Matthias Kleinert", "Heiko Ehr", "Hartmut Helmke"], "https://doi.org/10.21437/Interspeech.2018-1447", 5, "interspeech", 2018]], "Abishek Ravi": [0, ["Play Duration Based User-Entity Affinity Modeling in Spoken Dialog System", ["Bo Xiao", "Nicholas Monath", "Shankar Ananthakrishnan", "Abishek Ravi"], "https://doi.org/10.21437/Interspeech.2018-1100", 5, "interspeech", 2018]], "Antonios Anastasopoulos": [0, ["Leveraging Translations for Speech Transcription in Low-resource Settings", ["Antonios Anastasopoulos", "David Chiang"], "https://doi.org/10.21437/Interspeech.2018-2162", 5, "interspeech", 2018]], "Pavel Matejka": [0, ["Dereverberation and Beamforming in Robust Far-Field Speaker Recognition", ["Ladislav Mosner", "Oldrich Plchot", "Pavel Matejka", "Ondrej Novotny", "Jan Cernocky"], "https://doi.org/10.21437/Interspeech.2018-2306", 5, "interspeech", 2018], ["BUT System for DIHARD Speech Diarization Challenge 2018", ["Mireia Diez", "Federico Landini", "Lukas Burget", "Johan Rohdin", "Anna Silnova", "Katerina Zmolikova", "Ondrej Novotny", "Karel Vesely", "Ondrej Glembek", "Oldrich Plchot", "Ladislav Mosner", "Pavel Matejka"], "https://doi.org/10.21437/Interspeech.2018-1749", 5, "interspeech", 2018]], "Michael Pucher": [0, ["UltraFit: A Speaker-friendly Headset for Ultrasound Recordings in Speech Science", ["Lorenzo Spreafico", "Michael Pucher", "Anna Matosova"], "https://doi.org/10.21437/Interspeech.2018-995", 4, "interspeech", 2018]], "Abhinav Jain": [0, ["Improved Accented Speech Recognition Using Accent Embeddings and Multi-task Learning", ["Abhinav Jain", "Minali Upreti", "Preethi Jyothi"], "https://doi.org/10.21437/Interspeech.2018-1864", 5, "interspeech", 2018]], "Elinor Payne": [0, ["Homogeneity vs Heterogeneity in Indian English: Investigating Influences of L1 on f0 Range", ["Olga Maxwell", "Elinor Payne", "Rosey Billington"], "https://doi.org/10.21437/Interspeech.2018-1476", 5, "interspeech", 2018]], "Krishna D. N": [0, ["Development of Large Vocabulary Speech Recognition System with Keyword Search for Manipuri", ["Tanvina Patel", "Krishna D. N", "Noor Fathima", "Nisar Shah", "Mahima C", "Deepak Kumar", "Anuroop Iyengar"], "https://doi.org/10.21437/Interspeech.2018-2133", 5, "interspeech", 2018], ["An Automatic Speech Transcription System for Manipuri Language", ["Tanvina Patel", "Krishna D. N", "Noor Fathima", "Nisar Shah", "Mahima C", "Deepak Kumar", "Anuroop Iyengar"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3043.html", 2, "interspeech", 2018]], "Yifan Gong": [0.0002331648356630467, ["Cycle-Consistent Speech Enhancement", ["Zhong Meng", "Jinyu Li", "Yifan Gong", "Biing-Hwang Fred Juang"], "https://doi.org/10.21437/Interspeech.2018-2409", 5, "interspeech", 2018], ["Layer Trajectory LSTM", ["Jinyu Li", "Changliang Liu", "Yifan Gong"], "https://doi.org/10.21437/Interspeech.2018-1485", 5, "interspeech", 2018], ["Adversarial Feature-Mapping for Speech Enhancement", ["Zhong Meng", "Jinyu Li", "Yifan Gong", "Biing-Hwang Fred Juang"], "https://doi.org/10.21437/Interspeech.2018-2461", 5, "interspeech", 2018]], "Chi-Liang Liu": [0, ["Spoken SQuAD: A Study of Mitigating the Impact of Speech Recognition Errors on Listening Comprehension", ["Chia-Hsuan Lee", "Szu-Lin Wu", "Chi-Liang Liu", "Hung-yi Lee"], "https://doi.org/10.21437/Interspeech.2018-1714", 5, "interspeech", 2018]], "Guangjian Tian": [0, ["Long Distance Voice Channel Diagnosis Using Deep Neural Networks", ["Zhen Qin", "Tom Ko", "Guangjian Tian"], "https://doi.org/10.21437/Interspeech.2018-1428", 4, "interspeech", 2018]], "Bing Yang": [0.0030677259201183915, ["Multiple Concurrent Sound Source Tracking Based on Observation-Guided Adaptive Particle Filter", ["Hong Liu", "Haipeng Lan", "Bing Yang", "Cheng Pang"], "https://doi.org/10.21437/Interspeech.2018-1248", 5, "interspeech", 2018]], "Zeb Armstrong": [0, ["Voices Obscured in Complex Environmental Settings (VOiCES) Corpus", ["Colleen Richey", "Maria Auxiliadora Barrios", "Zeb Armstrong", "Chris Bartels", "Horacio Franco", "Martin Graciarena", "Aaron Lawson", "Mahesh Kumar Nandwana", "Allen R. Stauffer", "Julien van Hout", "Paul Gamble", "Jeffrey Hetherly", "Cory Stephenson", "Karl Ni"], "https://doi.org/10.21437/Interspeech.2018-1454", 5, "interspeech", 2018]], "Yixin Zhang": [0, ["Emotional Prosody Perception in Mandarin-speaking Congenital Amusics", ["Yixin Zhang", "Tianzhu Geng", "Jinsong Zhang"], "https://doi.org/10.21437/Interspeech.2018-91", 5, "interspeech", 2018]], "Zhen Yang": [9.011094164179667e-07, ["Co-whitening of I-vectors for Short and Long Duration Speaker Verification", ["Longting Xu", "Kong-Aik Lee", "Haizhou Li", "Zhen Yang"], "https://doi.org/10.21437/Interspeech.2018-1246", 5, "interspeech", 2018]], "Midia Yousefi": [0, ["Assessing Speaker Engagement in 2-Person Debates: Overlap Detection in United States Presidential Debates", ["Midia Yousefi", "Navid Shokouhi", "John H. L. Hansen"], "https://doi.org/10.21437/Interspeech.2018-1463", 5, "interspeech", 2018]], "Guangsen Wang": [6.21803675215915e-08, ["Improving Attention Based Sequence-to-Sequence Models for End-to-End English Conversational Speech Recognition", ["Chao Weng", "Jia Cui", "Guangsen Wang", "Jun Wang", "Chengzhu Yu", "Dan Su", "Dong Yu"], "https://doi.org/10.21437/Interspeech.2018-1030", 5, "interspeech", 2018]], "Md. Jahangir Alam": [0, ["Deeply Fused Speaker Embeddings for Text-Independent Speaker Verification", ["Gautam Bhattacharya", "Md. Jahangir Alam", "Vishwa Gupta", "Patrick Kenny"], "https://doi.org/10.21437/Interspeech.2018-1688", 5, "interspeech", 2018], ["Investigating Speech Enhancement and Perceptual Quality for Speech Emotion Recognition", ["Anderson R. Avila", "Md. Jahangir Alam", "Douglas D. OShaughnessy", "Tiago H. Falk"], "https://doi.org/10.21437/Interspeech.2018-2350", 5, "interspeech", 2018]], "Marc Antony Hullebus": [0, ["Speaker-specific Structure in German Voiceless Stop Voice Onset Times", ["Marc Antony Hullebus", "Stephen J. Tobin", "Adamantios I. Gafos"], "https://doi.org/10.21437/Interspeech.2018-2288", 5, "interspeech", 2018]], "Xin Chen": [0, ["Filter Sampling and Combination CNN (FSC-CNN): A Compact CNN Model for Small-footprint ASR Acoustic Modeling Using Raw Waveforms", ["Jinxi Guo", "Ning Xu", "Xin Chen", "Yang Shi", "Kaiyuan Xu", "Abeer Alwan"], "https://doi.org/10.21437/Interspeech.2018-1370", 5, "interspeech", 2018]], "Fil Alleva": [0, ["Recognizing Overlapped Speech in Meetings: A Multichannel Separation Approach Using Neural Networks", ["Takuya Yoshioka", "Hakan Erdogan", "Zhuo Chen", "Xiong Xiao", "Fil Alleva"], "https://doi.org/10.21437/Interspeech.2018-2284", 5, "interspeech", 2018]], "Ying Qin": [0, ["Automatic Speech Assessment for People with Aphasia Using TDNN-BLSTM with Multi-Task Learning", ["Ying Qin", "Tan Lee", "Siyuan Feng", "Anthony Pak-Hin Kong"], "https://doi.org/10.21437/Interspeech.2018-1630", 5, "interspeech", 2018]], "Byoung Jin Choi": [0.9996498823165894, ["Acoustic Modeling Using Adversarially Trained Variational Recurrent Neural Network for Speech Synthesis", ["Joun Yeop Lee", "Sung Jun Cheon", "Byoung Jin Choi", "Nam Soo Kim", "Eunwoo Song"], "https://doi.org/10.21437/Interspeech.2018-1598", 5, "interspeech", 2018]], "Vidhyasaharan Sethu": [0, ["Deep Siamese Architecture Based Replay Detection for Secure Voice Biometric", ["Kaavya Sriskandaraja", "Vidhyasaharan Sethu", "Eliathamby Ambikairajah"], "https://doi.org/10.21437/Interspeech.2018-1819", 5, "interspeech", 2018], ["Modulation Dynamic Features for the Detection of Replay Attacks", ["Gajan Suthokumar", "Vidhyasaharan Sethu", "Chamith Wijenayake", "Eliathamby Ambikairajah"], "https://doi.org/10.21437/Interspeech.2018-1846", 5, "interspeech", 2018], ["Sub-band Envelope Features Using Frequency Domain Linear Prediction for Short Duration Language Identification", ["Sarith Fernando", "Vidhyasaharan Sethu", "Eliathamby Ambikairajah"], "https://doi.org/10.21437/Interspeech.2018-1805", 5, "interspeech", 2018], ["Demonstrating and Modelling Systematic Time-varying Annotator Disagreement in Continuous Emotion Annotation", ["Mia Atcheson", "Vidhyasaharan Sethu", "Julien Epps"], "https://doi.org/10.21437/Interspeech.2018-1933", 5, "interspeech", 2018]], "Brij Mohan Lal Srivastava": [0, ["Homophone Identification and Merging for Code-switched Speech Recognition", ["Brij Mohan Lal Srivastava", "Sunayana Sitaram"], "https://doi.org/10.21437/Interspeech.2018-1171", 5, "interspeech", 2018]], "Reine Asakawa": [0, ["Automatic Question Detection from Acoustic and Phonetic Features Using Feature-wise Pre-training", ["Atsushi Ando", "Reine Asakawa", "Ryo Masumura", "Hosana Kamiyama", "Satoshi Kobashikawa", "Yushi Aono"], "https://doi.org/10.21437/Interspeech.2018-1755", 5, "interspeech", 2018]], "Zhifu Gao": [0, ["An Improved Deep Embedding Learning Method for Short Duration Speaker Verification", ["Zhifu Gao", "Yan Song", "Ian Vince McLoughlin", "Wu Guo", "Lirong Dai"], "https://doi.org/10.21437/Interspeech.2018-1515", 5, "interspeech", 2018]], "Francisco Teixeira": [0, ["Mining Multimodal Repositories for Speech Affecting Diseases", ["M. Joana Correia", "Bhiksha Raj", "Isabel Trancoso", "Francisco Teixeira"], "https://doi.org/10.21437/Interspeech.2018-1806", 5, "interspeech", 2018], ["Patient Privacy in Paralinguistic Tasks", ["Francisco Teixeira", "Alberto Abad", "Isabel Trancoso"], "https://doi.org/10.21437/Interspeech.2018-2186", 5, "interspeech", 2018]], "Alif Silpachai": [0, ["L2-ARCTIC: A Non-native English Speech Corpus", ["Guanlong Zhao", "Sinem Sonsaat", "Alif Silpachai", "Ivana Lucic", "Evgeny Chukharev-Hudilainen", "John Levis", "Ricardo Gutierrez-Osuna"], "https://doi.org/10.21437/Interspeech.2018-1110", 5, "interspeech", 2018]], "Savitha Murthy": [0, ["Effect of TTS Generated Audio on OOV Detection and Word Error Rate in ASR for Low-resource Languages", ["Savitha Murthy", "Dinkar Sitaram", "Sunayana Sitaram"], "https://doi.org/10.21437/Interspeech.2018-1555", 5, "interspeech", 2018]], "Manwa L. Ng": [0, ["Acoustic Features Associated with Sustained Vowel and Continuous Speech Productions by Chinese Children with Functional Articulation Disorders", ["Wang Zhang", "Xiangquan Gui", "Tianqi Wang", "Manwa L. Ng", "Feng Yang", "Lan Wang", "Nan Yan"], "https://doi.org/10.21437/Interspeech.2018-1521", 5, "interspeech", 2018]], "Bjorn W. Schuller": [0, ["The INTERSPEECH 2018 Computational Paralinguistics Challenge: Atypical & Self-Assessed Affect, Crying & Heart Beats", ["Bjorn W. Schuller", "Stefan Steidl", "Anton Batliner", "Peter B. Marschik", "Harald Baumeister", "Fengquan Dong", "Simone Hantke", "Florian B. Pokorny", "Eva-Maria Rathner", "Katrin D. Bartl-Pokorny", "Christa Einspieler", "Dajie Zhang", "Alice Baird", "Shahin Amiriparian", "Kun Qian", "Zhao Ren", "Maximilian Schmitt", "Panagiotis Tzirakis", "Stefanos Zafeiriou"], "https://doi.org/10.21437/Interspeech.2018-51", 5, "interspeech", 2018], ["Evolving Learning for Analysing Mood-Related Infant Vocalisation", ["Zixing Zhang", "Jing Han", "Kun Qian", "Bjorn W. Schuller"], "https://doi.org/10.21437/Interspeech.2018-1914", 5, "interspeech", 2018], ["State of Mind: Classification through Self-reported Affect and Word Use in Speech", ["Eva-Maria Rathner", "Yannik Terhorst", "Nicholas Cummins", "Bjorn W. Schuller", "Harald Baumeister"], "https://doi.org/10.21437/Interspeech.2018-2043", 5, "interspeech", 2018], ["Towards Temporal Modelling of Categorical Speech Emotion Recognition", ["Wenjing Han", "Huabin Ruan", "Xiaomin Chen", "Zhixiang Wang", "Haifeng Li", "Bjorn W. Schuller"], "https://doi.org/10.21437/Interspeech.2018-1858", 5, "interspeech", 2018], ["Recognition of Echolalic Autistic Child Vocalisations Utilising Convolutional Recurrent Neural Networks", ["Shahin Amiriparian", "Alice Baird", "Sahib Julka", "Alyssa Alcorn", "Sandra Ottl", "Suncica Petrovic", "Eloise Ainger", "Nicholas Cummins", "Bjorn W. Schuller"], "https://doi.org/10.21437/Interspeech.2018-1772", 5, "interspeech", 2018], ["Automated Classification of Children's Linguistic versus Non-Linguistic Vocalisations", ["Zixing Zhang", "Alejandrina Cristia", "Anne A. Warlaumont", "Bjorn W. Schuller"], "https://doi.org/10.21437/Interspeech.2018-2523", 5, "interspeech", 2018], ["The Perception and Analysis of the Likeability and Human Likeness of Synthesized Speech", ["Alice Baird", "Emilia Parada-Cabaleiro", "Simone Hantke", "Felix Burkhardt", "Nicholas Cummins", "Bjorn W. Schuller"], "https://doi.org/10.21437/Interspeech.2018-1093", 5, "interspeech", 2018], ["Bags in Bag: Generating Context-Aware Bags for Tracking Emotions from Speech", ["Jing Han", "Zixing Zhang", "Maximilian Schmitt", "Zhao Ren", "Fabien Ringeval", "Bjorn W. Schuller"], "https://doi.org/10.21437/Interspeech.2018-996", 5, "interspeech", 2018], ["How Did You like 2017? Detection of Language Markers of Depression and Narcissism in Personal Narratives", ["Eva-Maria Rathner", "Julia Djamali", "Yannik Terhorst", "Bjorn W. Schuller", "Nicholas Cummins", "Gudrun Salamon", "Christina Hunger-Schoppe", "Harald Baumeister"], "https://doi.org/10.21437/Interspeech.2018-2040", 5, "interspeech", 2018], ["Annotator Trustability-based Cooperative Learning Solutions for Intelligent Audio Analysis", ["Simone Hantke", "Christoph Stemp", "Bjorn W. Schuller"], "https://doi.org/10.21437/Interspeech.2018-1019", 5, "interspeech", 2018], ["Categorical vs Dimensional Perception of Italian Emotional Speech", ["Emilia Parada-Cabaleiro", "Giovanni Costantini", "Anton Batliner", "Alice Baird", "Bjorn W. Schuller"], "https://doi.org/10.21437/Interspeech.2018-47", 5, "interspeech", 2018]], "Brian DeRenzi": [0, ["Cross-language Phoneme Mapping for Low-resource Languages: An Exploration of Benefits and Trade-offs", ["Nick K. Chibuye", "Todd Rosenstock", "Brian DeRenzi"], "https://doi.org/10.21437/Interspeech.2018-2454", 5, "interspeech", 2018]], "Jean Carrive": [0, ["S4D: Speaker Diarization Toolkit in Python", ["Pierre-Alexandre Broux", "Florent Desnous", "Anthony Larcher", "Simon Petitrenaud", "Jean Carrive", "Sylvain Meignier"], "https://doi.org/10.21437/Interspeech.2018-1232", 5, "interspeech", 2018]], "Ehsan Hosseini-Asl": [0, ["A Multi-Discriminator CycleGAN for Unsupervised Non-Parallel Speech Domain Adaptation", ["Ehsan Hosseini-Asl", "Yingbo Zhou", "Caiming Xiong", "Richard Socher"], "https://doi.org/10.21437/Interspeech.2018-1535", 5, "interspeech", 2018]], "Filip Nenadic": [0, ["Implementing DIANA to Model Isolated Auditory Word Recognition in English", ["Filip Nenadic", "Louis ten Bosch", "Benjamin V. Tucker"], "https://doi.org/10.21437/Interspeech.2018-2081", 5, "interspeech", 2018]], "Evgeny Chukharev-Hudilainen": [0, ["L2-ARCTIC: A Non-native English Speech Corpus", ["Guanlong Zhao", "Sinem Sonsaat", "Alif Silpachai", "Ivana Lucic", "Evgeny Chukharev-Hudilainen", "John Levis", "Ricardo Gutierrez-Osuna"], "https://doi.org/10.21437/Interspeech.2018-1110", 5, "interspeech", 2018]], "Namju Kim": [0.9953907132148743, ["Training Utterance-level Embedding Networks for Speaker Identification and Verification", ["Heewoong Park", "Sukhyun Cho", "Kyubyong Park", "Namju Kim", "Jonghun Park"], "https://doi.org/10.21437/Interspeech.2018-1044", 5, "interspeech", 2018]], "Evgeny A. Stepanov": [0, ["Coherence Models for Dialogue", ["Alessandra Cervone", "Evgeny A. Stepanov", "Giuseppe Riccardi"], "https://doi.org/10.21437/Interspeech.2018-2446", 5, "interspeech", 2018]], "Cheng Pang": [0, ["Multiple Concurrent Sound Source Tracking Based on Observation-Guided Adaptive Particle Filter", ["Hong Liu", "Haipeng Lan", "Bing Yang", "Cheng Pang"], "https://doi.org/10.21437/Interspeech.2018-1248", 5, "interspeech", 2018]], "Madhu R. Kamble": [0, ["Effectiveness of Speech Demodulation-Based Features for Replay Detection", ["Madhu R. Kamble", "Hemlata Tak", "Hemant A. Patil"], "https://doi.org/10.21437/Interspeech.2018-1675", 5, "interspeech", 2018], ["Novel Variable Length Energy Separation Algorithm Using Instantaneous Amplitude Features for Replay Detection", ["Madhu R. Kamble", "Hemant A. Patil"], "https://doi.org/10.21437/Interspeech.2018-1687", 5, "interspeech", 2018], ["Auditory Filterbank Learning for Temporal Modulation Features in Replay Spoof Speech Detection", ["Hardik B. Sailor", "Madhu R. Kamble", "Hemant A. Patil"], "https://doi.org/10.21437/Interspeech.2018-1651", 5, "interspeech", 2018], ["DA-IICT/IIITV System for Low Resource Speech Recognition Challenge 2018", ["Hardik B. Sailor", "Maddala Venkata Siva Krishna", "Diksha Chhabra", "Ankur T. Patil", "Madhu R. Kamble", "Hemant A. Patil"], "https://doi.org/10.21437/Interspeech.2018-1553", 5, "interspeech", 2018]], "Emre Yilmaz": [0, ["Building a Unified Code-Switching ASR System for South African Languages", ["Emre Yilmaz", "Astik Biswas", "Ewald van der Westhuizen", "Febe de Wet", "Thomas Niesler"], "https://doi.org/10.21437/Interspeech.2018-1966", 5, "interspeech", 2018], ["Acoustic and Textual Data Augmentation for Improved ASR of Code-Switching Speech", ["Emre Yilmaz", "Henk van den Heuvel", "David A. van Leeuwen"], "https://doi.org/10.21437/Interspeech.2018-52", 5, "interspeech", 2018], ["Multilingual Neural Network Acoustic Modelling for ASR of Under-Resourced English-isiZulu Code-Switched Speech", ["Astik Biswas", "Febe de Wet", "Ewald van der Westhuizen", "Emre Yilmaz", "Thomas Niesler"], "https://doi.org/10.21437/Interspeech.2018-1711", 5, "interspeech", 2018], ["Articulatory Features for ASR of Pathological Speech", ["Emre Yilmaz", "Vikramjit Mitra", "Chris Bartels", "Horacio Franco"], "https://doi.org/10.21437/Interspeech.2018-67", 5, "interspeech", 2018]], "Wentao Gu": [1.1605677252557456e-09, ["Acoustic and Perceptual Characteristics of Mandarin Speech in Homosexual and Heterosexual Male Speakers", ["Puyang Geng", "Wentao Gu", "Hiroya Fujisaki"], "https://doi.org/10.21437/Interspeech.2018-2225", 5, "interspeech", 2018]], "Alexandra Marko": [0, ["Multi-Task Learning of Speech Recognition and Speech Synthesis Parameters for Ultrasound-based Silent Speech Interfaces", ["Laszlo Toth", "Gabor Gosztolya", "Tamas Grosz", "Alexandra Marko", "Tamas Gabor Csapo"], "https://doi.org/10.21437/Interspeech.2018-1078", 5, "interspeech", 2018]], "Ziyu Xiong": [0, ["The Trajectory of Voice Onset Time with Vocal Aging", ["Xuanda Chen", "Ziyu Xiong", "Jian Hu"], "https://doi.org/10.21437/Interspeech.2018-60", 5, "interspeech", 2018]], "Umesh Sachdev": [0, ["auMina\u2122 - Enterprise Speech Analytics", ["Umesh Sachdev", "Rajagopal Jayaraman", "Zainab Millwala"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3016.html", 2, "interspeech", 2018], ["akeira\u2122 - Virtual Assistant", ["Umesh Sachdev", "Rajagopal Jayaraman", "Zainab Millwala"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3018.html", 2, "interspeech", 2018]], "Haitao Yao": [0, ["Compact Feedforward Sequential Memory Networks for Small-footprint Keyword Spotting", ["Mengzhe Chen", "Shiliang Zhang", "Ming Lei", "Yong Liu", "Haitao Yao", "Jie Gao"], "https://doi.org/10.21437/Interspeech.2018-1204", 5, "interspeech", 2018]], "Suncica Petrovic": [0, ["Recognition of Echolalic Autistic Child Vocalisations Utilising Convolutional Recurrent Neural Networks", ["Shahin Amiriparian", "Alice Baird", "Sahib Julka", "Alyssa Alcorn", "Sandra Ottl", "Suncica Petrovic", "Eloise Ainger", "Nicholas Cummins", "Bjorn W. Schuller"], "https://doi.org/10.21437/Interspeech.2018-1772", 5, "interspeech", 2018]], "Xiangquan Gui": [0, ["Acoustic Features Associated with Sustained Vowel and Continuous Speech Productions by Chinese Children with Functional Articulation Disorders", ["Wang Zhang", "Xiangquan Gui", "Tianqi Wang", "Manwa L. Ng", "Feng Yang", "Lan Wang", "Nan Yan"], "https://doi.org/10.21437/Interspeech.2018-1521", 5, "interspeech", 2018]], "Dominique Fohr": [0, ["Keyword Based Speaker Localization: Localizing a Target Speaker in a Multi-speaker Environment", ["Sunit Sivasankaran", "Emmanuel Vincent", "Dominique Fohr"], "https://doi.org/10.21437/Interspeech.2018-1526", 5, "interspeech", 2018]], "Lanhua You": [0, ["Improved Supervised Locality Preserving Projection for I-vector Based Speaker Verification", ["Lanhua You", "Wu Guo", "Yan Song", "Sheng Zhang"], "https://doi.org/10.21437/Interspeech.2018-41", 5, "interspeech", 2018], ["Gated Convolutional Neural Network for Sentence Matching", ["Peixin Chen", "Wu Guo", "Zhi Chen", "Jian Sun", "Lanhua You"], "https://doi.org/10.21437/Interspeech.2018-70", 5, "interspeech", 2018]], "Chuan Wang": [0.10538369044661522, ["Liulishuo's System for the Spoken CALL Shared Task 2018", ["Huy Nguyen", "Lei Chen", "Ramon Prieto", "Chuan Wang", "Yang Liu"], "https://doi.org/10.21437/Interspeech.2018-1309", 5, "interspeech", 2018]], "Tohru Nagano": [0, ["Inference-Invariant Transformation of Batch Normalization for Domain Adaptation of Acoustic Models", ["Masayuki Suzuki", "Tohru Nagano", "Gakuto Kurata", "Samuel Thomas"], "https://doi.org/10.21437/Interspeech.2018-1563", 5, "interspeech", 2018]], "Akshay Soni": [0, ["Towards Automated Single Channel Source Separation Using Neural Networks", ["Arpita Gang", "Pravesh Biyani", "Akshay Soni"], "https://doi.org/10.21437/Interspeech.2018-2065", 5, "interspeech", 2018]], "Zhiyong Wu": [4.808835365111008e-05, ["Siamese Recurrent Auto-Encoder Representation for Query-by-Example Spoken Term Detection", ["Ziwei Zhu", "Zhiyong Wu", "Runnan Li", "Helen Meng", "Lianhong Cai"], "https://doi.org/10.21437/Interspeech.2018-1788", 5, "interspeech", 2018], ["Detection of Glottal Closure Instants from Speech Signals: A Convolutional Neural Network Based Method", ["Shuai Yang", "Zhiyong Wu", "Binbin Shen", "Helen Meng"], "https://doi.org/10.21437/Interspeech.2018-1281", 5, "interspeech", 2018], ["Rapid Style Adaptation Using Residual Error Embedding for Expressive Speech Synthesis", ["Xixin Wu", "Yuewen Cao", "Mu Wang", "Songxiang Liu", "Shiyin Kang", "Zhiyong Wu", "Xunying Liu", "Dan Su", "Dong Yu", "Helen Meng"], "https://doi.org/10.21437/Interspeech.2018-1991", 5, "interspeech", 2018], ["Emotion Recognition from Variable-Length Speech Segments Using Deep Learning on Spectrograms", ["Xi Ma", "Zhiyong Wu", "Jia Jia", "Mingxing Xu", "Helen Meng", "Lianhong Cai"], "https://doi.org/10.21437/Interspeech.2018-2228", 5, "interspeech", 2018]], "Amanda Robinson": [0, ["An Automated Assistant for Medical Scribes", ["Gregory P. Finley", "Erik Edwards", "Amanda Robinson", "Najmeh Sadoughi", "James Fone", "Mark Miller", "David Suendermann-Oeft", "Michael Brenndoerfer", "Nico Axtmann"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3047.html", 2, "interspeech", 2018]], "Yih-Ru Wang": [0.0003858963609673083, ["An Exploration of Local Speaking Rate Variations in Mandarin Read Speech", ["Guan-Ting Liou", "Chen-Yu Chiang", "Yih-Ru Wang", "Sin-Horng Chen"], "https://doi.org/10.21437/Interspeech.2018-1214", 5, "interspeech", 2018]], "Eloise Ainger": [0, ["Recognition of Echolalic Autistic Child Vocalisations Utilising Convolutional Recurrent Neural Networks", ["Shahin Amiriparian", "Alice Baird", "Sahib Julka", "Alyssa Alcorn", "Sandra Ottl", "Suncica Petrovic", "Eloise Ainger", "Nicholas Cummins", "Bjorn W. Schuller"], "https://doi.org/10.21437/Interspeech.2018-1772", 5, "interspeech", 2018]], "Claudia Baur": [0, ["Overview of the 2018 Spoken CALL Shared Task", ["Claudia Baur", "Andrew Caines", "Cathy Chua", "Johanna Gerlach", "Mengjie Qian", "Manny Rayner", "Martin J. Russell", "Helmer Strik", "Xizi Wei"], "https://doi.org/10.21437/Interspeech.2018-97", 5, "interspeech", 2018]], "Jan Cernocky": [0, ["Dereverberation and Beamforming in Robust Far-Field Speaker Recognition", ["Ladislav Mosner", "Oldrich Plchot", "Pavel Matejka", "Ondrej Novotny", "Jan Cernocky"], "https://doi.org/10.21437/Interspeech.2018-2306", 5, "interspeech", 2018], ["BUT OpenSAT 2017 Speech Recognition System", ["Martin Karafiat", "Murali Karthick Baskar", "Igor Szoke", "Vladimir Malenovsky", "Karel Vesely", "Frantisek Grezl", "Lukas Burget", "Jan Cernocky"], "https://doi.org/10.21437/Interspeech.2018-2457", 5, "interspeech", 2018], ["Lightly Supervised vs. Semi-supervised Training of Acoustic Model on Luxembourgish for Low-resource Automatic Speech Recognition", ["Karel Vesely", "Carlos Segura", "Igor Szoke", "Jordi Luque", "Jan Cernocky"], "https://doi.org/10.21437/Interspeech.2018-2361", 5, "interspeech", 2018], ["BUT System for Low Resource Indian Language ASR", ["Bhargav Pulugundla", "Murali Karthick Baskar", "Santosh Kesiraju", "Ekaterina Egorova", "Martin Karafiat", "Lukas Burget", "Jan Cernocky"], "https://doi.org/10.21437/Interspeech.2018-1302", 5, "interspeech", 2018]], "Andrew Butcher": [0, ["Formant Measures of Vowels Adjacent to Alveolar and Retroflex Consonants in Arrernte: Stressed and Unstressed Position", ["Marija Tabain", "Richard Beare", "Andrew Butcher"], "https://doi.org/10.21437/Interspeech.2018-1126", 5, "interspeech", 2018]], "Robert Kenefick": [0, ["The Effect of Exposure to High Altitude and Heat on Speech Articulatory Coordination", ["James R. Williamson", "Thomas F. Quatieri", "Adam C. Lammert", "Katherine Mitchell", "Katherine Finkelstein", "Nicole Ekon", "Caitlin Dillon", "Robert Kenefick", "Kristin Heaton"], "https://doi.org/10.21437/Interspeech.2018-2372", 5, "interspeech", 2018]], "Changhao Shan": [0, ["Attention-based End-to-End Models for Small-Footprint Keyword Spotting", ["Changhao Shan", "Junbo Zhang", "Yujun Wang", "Lei Xie"], "https://doi.org/10.21437/Interspeech.2018-1777", 5, "interspeech", 2018]], "Shuai Wang": [2.6364129013245474e-07, ["Angular Softmax for Short-Duration Text-independent Speaker Verification", ["Zili Huang", "Shuai Wang", "Kai Yu"], "https://doi.org/10.21437/Interspeech.2018-1545", 5, "interspeech", 2018]], "Jianhua Tao": [0, ["BLSTM-CRF Based End-to-End Prosodic Boundary Prediction with Context Sensitive Embeddings in a Text-to-Speech Front-End", ["Yibin Zheng", "Jianhua Tao", "Zhengqi Wen", "Ya Li"], "https://doi.org/10.21437/Interspeech.2018-1472", 5, "interspeech", 2018], ["Sparsity-Constrained Weight Mapping for Head-Related Transfer Functions Individualization from Anthropometric Features", ["Xiaoke Qi", "Jianhua Tao"], "https://doi.org/10.21437/Interspeech.2018-1615", 5, "interspeech", 2018], ["Transfer Learning Based Progressive Neural Networks for Acoustic Modeling in Statistical Parametric Speech Synthesis", ["Ruibo Fu", "Jianhua Tao", "Yibin Zheng", "Zhengqi Wen"], "https://doi.org/10.21437/Interspeech.2018-1265", 5, "interspeech", 2018], ["On the Application and Compression of Deep Time Delay Neural Network for Embedded Statistical Parametric Speech Synthesis", ["Yibin Zheng", "Jianhua Tao", "Zhengqi Wen", "Ruibo Fu"], "https://doi.org/10.21437/Interspeech.2018-1970", 5, "interspeech", 2018], ["Deep Metric Learning for the Target Cost in Unit-Selection Speech Synthesizer", ["Ruibo Fu", "Jianhua Tao", "Yibin Zheng", "Zhengqi Wen"], "https://doi.org/10.21437/Interspeech.2018-1305", 5, "interspeech", 2018], ["Deep Noise Tracking Network: A Hybrid Signal Processing/Deep Learning Approach to Speech Enhancement", ["Shuai Nie", "Shan Liang", "Bin Liu", "Yaping Zhang", "Wenju Liu", "Jianhua Tao"], "https://doi.org/10.21437/Interspeech.2018-1020", 5, "interspeech", 2018], ["Speech Emotion Recognition from Variable-Length Inputs with Triplet Loss Function", ["Jian Huang", "Ya Li", "Jianhua Tao", "Zhen Lian"], "https://doi.org/10.21437/Interspeech.2018-1432", 5, "interspeech", 2018]], "Tan Lee": [0.0017472112085670233, ["Cross-cultural (A)symmetries in Audio-visual Attitude Perception", ["Hansjorg Mixdorff", "Albert Rilliard", "Tan Lee", "Matthew K. H. Ma", "Angelika Honemann"], "https://doi.org/10.21437/Interspeech.2018-1373", 5, "interspeech", 2018], ["Improving Cross-Lingual Knowledge Transferability Using Multilingual TDNN-BLSTM with Language-Dependent Pre-Final Layer", ["Siyuan Feng", "Tan Lee"], "https://doi.org/10.21437/Interspeech.2018-1182", 5, "interspeech", 2018], ["Exploiting Speaker and Phonetic Diversity of Mismatched Language Resources for Unsupervised Subword Modeling", ["Siyuan Feng", "Tan Lee"], "https://doi.org/10.21437/Interspeech.2018-1081", 5, "interspeech", 2018], ["Automatic Speech Assessment for People with Aphasia Using TDNN-BLSTM with Multi-Task Learning", ["Ying Qin", "Tan Lee", "Siyuan Feng", "Anthony Pak-Hin Kong"], "https://doi.org/10.21437/Interspeech.2018-1630", 5, "interspeech", 2018]], "Radhika Pal": [0, ["Mobile Application for Learning Languages for the Unlettered", ["Gayathri G", "N. Mohana", "Radhika Pal", "Hema A. Murthy"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3012.html", 2, "interspeech", 2018]], "Jing Chen": [0, ["Measuring the Band Importance Function for Mandarin Chinese with a Bayesian Adaptive Procedure", ["Yufan Du", "Yi Shen", "Hongying Yang", "Xihong Wu", "Jing Chen"], "https://doi.org/10.21437/Interspeech.2018-1825", 5, "interspeech", 2018]], "Padmasundari": [0, ["Intent Discovery Through Unsupervised Semantic Text Clustering", ["Padmasundari", "Srinivas Bangalore"], "https://doi.org/10.21437/Interspeech.2018-2436", 5, "interspeech", 2018]], "Haotian Guan": [0, ["Multiple Phase Information Combination for Replay Attacks Detection", ["Dongbo Li", "Longbiao Wang", "Jianwu Dang", "Meng Liu", "Zeyan Oo", "Seiichi Nakagawa", "Haotian Guan", "Xiangang Li"], "https://doi.org/10.21437/Interspeech.2018-2001", 5, "interspeech", 2018], ["Speech Emotion Recognition by Combining Amplitude and Phase Information Using Convolutional Neural Network", ["Lili Guo", "Longbiao Wang", "Jianwu Dang", "Linjuan Zhang", "Haotian Guan", "Xiangang Li"], "https://doi.org/10.21437/Interspeech.2018-2156", 5, "interspeech", 2018]], "Young-Bum Kim": [0.9703183174133301, ["Joint Learning of Domain Classification and Out-of-Domain Detection with Dynamic Class Weighting for Satisficing False Acceptance Rates", ["Joo-Kyung Kim", "Young-Bum Kim"], "https://doi.org/10.21437/Interspeech.2018-1581", 5, "interspeech", 2018]], "Burkhard Meyer-Sickendiek": [0, ["Analysing the Focus of a Hierarchical Attention Network: the Importance of Enjambments When Classifying Post-modern Poetry", ["Timo Baumann", "Hussein Hussein", "Burkhard Meyer-Sickendiek"], "https://doi.org/10.21437/Interspeech.2018-2533", 5, "interspeech", 2018]], "Masanobu Abe": [0, ["Naturalness Improvement Algorithm for Reconstructed Glossectomy Patient's Speech Using Spectral Differential Modification in Voice Conversion", ["Hiroki Murakami", "Sunao Hara", "Masanobu Abe", "Masaaki Sato", "Shogo Minagi"], "https://doi.org/10.21437/Interspeech.2018-1239", 5, "interspeech", 2018]], "Kate Earnshaw": [0, ["Variation in the FACE Vowel across West Yorkshire: Implications for Forensic Speaker Comparisons", ["Kate Earnshaw", "Erica Gold"], "https://doi.org/10.21437/Interspeech.2018-1944", 5, "interspeech", 2018], ["The 'West Yorkshire Regional English Database': Investigations into the Generalizability of Reference Populations for Forensic Speaker Comparison Casework", ["Erica Gold", "Sula Ross", "Kate Earnshaw"], "https://doi.org/10.21437/Interspeech.2018-65", 5, "interspeech", 2018]], "Ha-Jin Yu": [0.7287916094064713, ["Avoiding Speaker Overfitting in End-to-End DNNs Using Raw Waveform for Text-Independent Speaker Verification", ["Jee-weon Jung", "Hee-Soo Heo", "Il-Ho Yang", "Hye-jin Shim", "Ha-Jin Yu"], "https://doi.org/10.21437/Interspeech.2018-1608", 5, "interspeech", 2018]], "Huy Nguyen": [0, ["Liulishuo's System for the Spoken CALL Shared Task 2018", ["Huy Nguyen", "Lei Chen", "Ramon Prieto", "Chuan Wang", "Yang Liu"], "https://doi.org/10.21437/Interspeech.2018-1309", 5, "interspeech", 2018]], "Diana Jaunzeikare": [0, ["Semi-supervised Learning for Information Extraction from Dialogue", ["Anjuli Kannan", "Kai Chen", "Diana Jaunzeikare", "Alvin Rajkomar"], "https://doi.org/10.21437/Interspeech.2018-1318", 5, "interspeech", 2018], ["Speech Recognition for Medical Conversations", ["Chung-Cheng Chiu", "Anshuman Tripathi", "Katherine Chou", "Chris Co", "Navdeep Jaitly", "Diana Jaunzeikare", "Anjuli Kannan", "Patrick Nguyen", "Hasim Sak", "Ananth Sankar", "Justin Tansuwan", "Nathan Wan", "Yonghui Wu", "Xuedong Zhang"], "https://doi.org/10.21437/Interspeech.2018-40", 5, "interspeech", 2018]], "Veronika Timpe-Laughlin": [0, ["Game-based Spoken Dialog Language Learning Applications for Young Students", ["Keelan Evanini", "Veronika Timpe-Laughlin", "Eugene Tsuprun", "Ian Blood", "Jeremy Lee", "James V. Bruno", "Vikram Ramanarayanan", "Patrick L. Lange", "David Suendermann-Oeft"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3045.html", 2, "interspeech", 2018]], "Zoe Roxburgh": [0, ["UltraSuite: A Repository of Ultrasound and Acoustic Data from Child Speech Therapy Sessions", ["Aciel Eshky", "Manuel Sam Ribeiro", "Joanne Cleland", "Korin Richmond", "Zoe Roxburgh", "James M. Scobbie", "Alan Wrench"], "https://doi.org/10.21437/Interspeech.2018-1736", 5, "interspeech", 2018]], "Hossein Hadian": [0, ["End-to-end Speech Recognition Using Lattice-free MMI", ["Hossein Hadian", "Hossein Sameti", "Daniel Povey", "Sanjeev Khudanpur"], "https://doi.org/10.21437/Interspeech.2018-1423", 5, "interspeech", 2018], ["Acoustic Modeling from Frequency Domain Representations of Speech", ["Pegah Ghahremani", "Hossein Hadian", "Hang Lv", "Daniel Povey", "Sanjeev Khudanpur"], "https://doi.org/10.21437/Interspeech.2018-1453", 5, "interspeech", 2018]], "Florian B. Pokorny": [0, ["The INTERSPEECH 2018 Computational Paralinguistics Challenge: Atypical & Self-Assessed Affect, Crying & Heart Beats", ["Bjorn W. Schuller", "Stefan Steidl", "Anton Batliner", "Peter B. Marschik", "Harald Baumeister", "Fengquan Dong", "Simone Hantke", "Florian B. Pokorny", "Eva-Maria Rathner", "Katrin D. Bartl-Pokorny", "Christa Einspieler", "Dajie Zhang", "Alice Baird", "Shahin Amiriparian", "Kun Qian", "Zhao Ren", "Maximilian Schmitt", "Panagiotis Tzirakis", "Stefanos Zafeiriou"], "https://doi.org/10.21437/Interspeech.2018-51", 5, "interspeech", 2018]], "Adam C. Lammert": [0, ["The Effect of Exposure to High Altitude and Heat on Speech Articulatory Coordination", ["James R. Williamson", "Thomas F. Quatieri", "Adam C. Lammert", "Katherine Mitchell", "Katherine Finkelstein", "Nicole Ekon", "Caitlin Dillon", "Robert Kenefick", "Kristin Heaton"], "https://doi.org/10.21437/Interspeech.2018-2372", 5, "interspeech", 2018], ["Vocal Biomarkers for Cognitive Performance Estimation in a Working Memory Task", ["Jennifer Sloboda", "Adam C. Lammert", "James R. Williamson", "Christopher J. Smalt", "Daryush D. Mehta", "C. O. L. Ian Curry", "Kristin Heaton", "Jeff Palmer", "Thomas F. Quatieri"], "https://doi.org/10.21437/Interspeech.2018-2418", 5, "interspeech", 2018]], "Mario Kunstek": [0, ["The CSU-K Rule-Based System for the 2nd Edition Spoken CALL Shared Task", ["Dominik Julg", "Mario Kunstek", "Cem Philipp Freimoser", "Kay Berkling", "Mengjie Qian"], "https://doi.org/10.21437/Interspeech.2018-1000", 5, "interspeech", 2018]], "Jonathan Flint": [0, ["Effectiveness of Voice Quality Features in Detecting Depression", ["Amber Afshan", "Jinxi Guo", "Soo Jin Park", "Vijay Ravi", "Jonathan Flint", "Abeer Alwan"], "https://doi.org/10.21437/Interspeech.2018-1399", 5, "interspeech", 2018]], "Sandeep Reddy Kothinti": [0, ["Correlational Networks for Speaker Normalization in Automatic Speech Recognition", ["Rini A. Sharon", "Sandeep Reddy Kothinti", "Srinivasan Umesh"], "https://doi.org/10.21437/Interspeech.2018-1612", 5, "interspeech", 2018]], "Ilya Kiselev": [0, ["Speaker Activity Detection and Minimum Variance Beamforming for Source Separation", ["Enea Ceolini", "Jithendar Anumula", "Adrian E. G. Huber", "Ilya Kiselev", "Shih-Chii Liu"], "https://doi.org/10.21437/Interspeech.2018-1606", 5, "interspeech", 2018]], "Herve Bourlard": [0, ["CNN Based Query by Example Spoken Term Detection", ["Dhananjay Ram", "Lesly Miculicich Werlen", "Herve Bourlard"], "https://doi.org/10.21437/Interspeech.2018-1722", 5, "interspeech", 2018], ["Single-channel Late Reverberation Power Spectral Density Estimation Using Denoising Autoencoders", ["Ina Kodrasi", "Herve Bourlard"], "https://doi.org/10.21437/Interspeech.2018-1660", 5, "interspeech", 2018], ["Evolution of Neural Network Architectures for Speech Recognition", ["Herve Bourlard"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/4003.html", 1, "interspeech", 2018], ["Phonological Posterior Hashing for Query by Example Spoken Term Detection", ["Afsaneh Asaei", "Dhananjay Ram", "Herve Bourlard"], "https://doi.org/10.21437/Interspeech.2018-1973", 5, "interspeech", 2018], ["Fast Language Adaptation Using Phonological Information", ["Sibo Tong", "Philip N. Garner", "Herve Bourlard"], "https://doi.org/10.21437/Interspeech.2018-1990", 5, "interspeech", 2018]], "Manny Rayner": [0, ["A Robust Context-Dependent Speech-to-Speech Phraselator Toolkit for Alexa", ["Manny Rayner", "Nikos Tsourakis", "Jan Stanek"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3006.html", 2, "interspeech", 2018], ["Overview of the 2018 Spoken CALL Shared Task", ["Claudia Baur", "Andrew Caines", "Cathy Chua", "Johanna Gerlach", "Mengjie Qian", "Manny Rayner", "Martin J. Russell", "Helmer Strik", "Xizi Wei"], "https://doi.org/10.21437/Interspeech.2018-97", 5, "interspeech", 2018]], "Feilong Bao": [0, ["Improving Mongolian Phrase Break Prediction by Using Syllable and Morphological Embeddings with BiLSTM Model", ["Rui Liu", "Feilong Bao", "Guanglai Gao", "Hui Zhang", "Yonghe Wang"], "https://doi.org/10.21437/Interspeech.2018-1706", 5, "interspeech", 2018]], "Dong Yu": [0.1973298266530037, ["Permutation Invariant Training of Generative Adversarial Network for Monaural Speech Separation", ["Lianwu Chen", "Meng Yu", "Yanmin Qian", "Dan Su", "Dong Yu"], "https://doi.org/10.21437/Interspeech.2018-1603", 5, "interspeech", 2018], ["Deep Extractor Network for Target Speaker Recovery from Single Channel Speech Mixtures", ["Jun Wang", "Jie Chen", "Dan Su", "Lianwu Chen", "Meng Yu", "Yanmin Qian", "Dong Yu"], "https://doi.org/10.21437/Interspeech.2018-1205", 5, "interspeech", 2018], ["Improving Attention Based Sequence-to-Sequence Models for End-to-End English Conversational Speech Recognition", ["Chao Weng", "Jia Cui", "Guangsen Wang", "Jun Wang", "Chengzhu Yu", "Dan Su", "Dong Yu"], "https://doi.org/10.21437/Interspeech.2018-1030", 5, "interspeech", 2018], ["A Multistage Training Framework for Acoustic-to-Word Model", ["Chengzhu Yu", "Chunlei Zhang", "Chao Weng", "Jia Cui", "Dong Yu"], "https://doi.org/10.21437/Interspeech.2018-1452", 5, "interspeech", 2018], ["Monaural Multi-Talker Speech Recognition with Attention Mechanism and Gated Convolutional Networks", ["Xuankai Chang", "Yanmin Qian", "Dong Yu"], "https://doi.org/10.21437/Interspeech.2018-1547", 5, "interspeech", 2018], ["Deep Discriminative Embeddings for Duration Robust Speaker Verification", ["Na Li", "Deyi Tuo", "Dan Su", "Zhifeng Li", "Dong Yu"], "https://doi.org/10.21437/Interspeech.2018-1769", 5, "interspeech", 2018], ["Text-Dependent Speech Enhancement for Small-Footprint Robust Keyword Detection", ["Meng Yu", "Xuan Ji", "Yi Gao", "Lianwu Chen", "Jie Chen", "Jimeng Zheng", "Dan Su", "Dong Yu"], "https://doi.org/10.21437/Interspeech.2018-1668", 5, "interspeech", 2018], ["Rapid Style Adaptation Using Residual Error Embedding for Expressive Speech Synthesis", ["Xixin Wu", "Yuewen Cao", "Mu Wang", "Songxiang Liu", "Shiyin Kang", "Zhiyong Wu", "Xunying Liu", "Dan Su", "Dong Yu", "Helen Meng"], "https://doi.org/10.21437/Interspeech.2018-1991", 5, "interspeech", 2018]], "Hajime Endo": [0, ["Audio-visual Voice Conversion Using Deep Canonical Correlation Analysis for Deep Bottleneck Features", ["Satoshi Tamura", "Kento Horio", "Hajime Endo", "Satoru Hayamizu", "Tomoki Toda"], "https://doi.org/10.21437/Interspeech.2018-2286", 5, "interspeech", 2018]], "Yuan Gong": [0.18233120441436768, ["Impact of Aliasing on Deep CNN-Based End-to-End Acoustic Models", ["Yuan Gong", "Christian Poellabauer"], "https://doi.org/10.21437/Interspeech.2018-1371", 5, "interspeech", 2018]], "Alvin Rajkomar": [0, ["Semi-supervised Learning for Information Extraction from Dialogue", ["Anjuli Kannan", "Kai Chen", "Diana Jaunzeikare", "Alvin Rajkomar"], "https://doi.org/10.21437/Interspeech.2018-1318", 5, "interspeech", 2018]], "Golda Brunet Rajan": [0, ["Transcription Correction for Indian Languages Using Acoustic Signatures", ["Jeena J. Prakash", "Golda Brunet Rajan", "Hema A. Murthy"], "https://doi.org/10.21437/Interspeech.2018-1188", 5, "interspeech", 2018]], "Andras Beke": [0, ["User-centric Evaluation of Automatic Punctuation in ASR Closed Captioning", ["Mate Akos Tundik", "Gyorgy Szaszak", "Gabor Gosztolya", "Andras Beke"], "https://doi.org/10.21437/Interspeech.2018-1352", 5, "interspeech", 2018]], "Kenji Nagamatsu": [0, ["Lattice-free State-level Minimum Bayes Risk Training of Acoustic Models", ["Naoyuki Kanda", "Yusuke Fujita", "Kenji Nagamatsu"], "https://doi.org/10.21437/Interspeech.2018-79", 5, "interspeech", 2018]], "Tharshini Gunendradasan": [0, ["Detection of Replay-Spoofing Attacks Using Frequency Modulation Features", ["Tharshini Gunendradasan", "Buddhi Wickramasinghe", "Phu Ngoc Le", "Eliathamby Ambikairajah", "Julien Epps"], "https://doi.org/10.21437/Interspeech.2018-1473", 5, "interspeech", 2018]], "Xu Li": [0, ["Unsupervised Discovery of Non-native Phonetic Patterns in L2 English Speech for Mispronunciation Detection and Diagnosis", ["Xu Li", "Shaoguang Mao", "Xixin Wu", "Kun Li", "Xunying Liu", "Helen Meng"], "https://doi.org/10.21437/Interspeech.2018-2027", 5, "interspeech", 2018]], "Renuka Mannem": [0, ["Air-Tissue Boundary Segmentation in Real-Time Magnetic Resonance Imaging Video Using Semantic Segmentation with Fully Convolutional Networks", ["C. A. Valliappan", "Renuka Mannem", "Prasanta Kumar Ghosh"], "https://doi.org/10.21437/Interspeech.2018-1939", 5, "interspeech", 2018]], "Puyang Geng": [0, ["Acoustic and Perceptual Characteristics of Mandarin Speech in Homosexual and Heterosexual Male Speakers", ["Puyang Geng", "Wentao Gu", "Hiroya Fujisaki"], "https://doi.org/10.21437/Interspeech.2018-2225", 5, "interspeech", 2018]], "Huan Song": [0.09555121511220932, ["Triplet Network with Attention for Speaker Diarization", ["Huan Song", "Megan M. Willi", "Jayaraman J. Thiagarajan", "Visar Berisha", "Andreas Spanias"], "https://doi.org/10.21437/Interspeech.2018-2305", 5, "interspeech", 2018]], "Michel Hoen": [0, ["Phoneme Resistance and Phoneme Confusion in Noise: Impact of Dyslexia", ["Noelia Do Carmo Blanco", "Julien Meyer", "Michel Hoen", "Fanny Meunier"], "https://doi.org/10.21437/Interspeech.2018-1271", 5, "interspeech", 2018]], "Syed Shahnawazuddin": [0, ["Enhancement of Noisy Speech Signal by Non-Local Means Estimation of Variational Mode Functions", ["Nagapuri Srinivas", "Gayadhar Pradhan", "Syed Shahnawazuddin"], "https://doi.org/10.21437/Interspeech.2018-1928", 5, "interspeech", 2018], ["Non-Uniform Spectral Smoothing for Robust Children's Speech Recognition", ["Ishwar Chandra Yadav", "Avinash Kumar", "Syed Shahnawazuddin", "Gayadhar Pradhan"], "https://doi.org/10.21437/Interspeech.2018-1828", 5, "interspeech", 2018]], "Christian Poellabauer": [0, ["Impact of Aliasing on Deep CNN-Based End-to-End Acoustic Models", ["Yuan Gong", "Christian Poellabauer"], "https://doi.org/10.21437/Interspeech.2018-1371", 5, "interspeech", 2018]], "Sri Harsha Dumpala": [0, ["Analysis of the Effect of Speech-Laugh on Speaker Recognition System", ["Sri Harsha Dumpala", "Ashish Panda", "Sunil Kumar Kopparapu"], "https://doi.org/10.21437/Interspeech.2018-2090", 5, "interspeech", 2018]], "Girish K. S": [0, ["Detection of Glottal Activity Errors in Production of Stop Consonants in Children with Cleft Lip and Palate", ["Vikram C. M.", "S. R. Mahadeva Prasanna", "Ajish K. Abraham", "Pushpavathi M", "Girish K. S"], "https://doi.org/10.21437/Interspeech.2018-1665", 5, "interspeech", 2018]], "Alexandros Papangelis": [0, ["Comparison of an End-to-end Trainable Dialogue System with a Modular Statistical Dialogue System", ["Norbert Braunschweiler", "Alexandros Papangelis"], "https://doi.org/10.21437/Interspeech.2018-1679", 5, "interspeech", 2018], ["A Case Study on the Importance of Belief State Representation for Dialogue Policy Management", ["Margarita Kotti", "Vassilios Diakoloukas", "Alexandros Papangelis", "Michail Lagoudakis", "Yannis Stylianou"], "https://doi.org/10.21437/Interspeech.2018-1293", 5, "interspeech", 2018]], "Stephen J. Tobin": [0, ["Speaker-specific Structure in German Voiceless Stop Voice Onset Times", ["Marc Antony Hullebus", "Stephen J. Tobin", "Adamantios I. Gafos"], "https://doi.org/10.21437/Interspeech.2018-2288", 5, "interspeech", 2018]], "Satoshi Nakamura": [0, ["Compressing End-to-end ASR Networks by Tensor-Train Decomposition", ["Takuma Mori", "Andros Tjandra", "Sakriani Sakti", "Satoshi Nakamura"], "https://doi.org/10.21437/Interspeech.2018-1543", 5, "interspeech", 2018], ["Machine Speech Chain with One-shot Speaker Adaptation", ["Andros Tjandra", "Sakriani Sakti", "Satoshi Nakamura"], "https://doi.org/10.21437/Interspeech.2018-1558", 5, "interspeech", 2018], ["Incremental TTS for Japanese Language", ["Tomoya Yanagita", "Sakriani Sakti", "Satoshi Nakamura"], "https://doi.org/10.21437/Interspeech.2018-1561", 5, "interspeech", 2018], ["Detection of Dementia from Responses to Atypical Questions Asked by Embodied Conversational Agents", ["Tsuyoki Ujiro", "Hiroki Tanaka", "Hiroyoshi Adachi", "Hiroaki Kazui", "Manabu Ikeda", "Takashi Kudo", "Satoshi Nakamura"], "https://doi.org/10.21437/Interspeech.2018-1514", 5, "interspeech", 2018]], "Sandra Schwab": [0, ["Influences of Fundamental Oscillation on Speaker Identification in Vocalic Utterances by Humans and Computers", ["Volker Dellwo", "Thayabaran Kathiresan", "Elisa Pellegrino", "Lei He", "Sandra Schwab", "Dieter Maurer"], "https://doi.org/10.21437/Interspeech.2018-2331", 5, "interspeech", 2018]], "Douglas A. Reynolds": [0, ["Performance Analysis of the 2017 NIST Language Recognition Evaluation", ["Seyed Omid Sadjadi", "Timothee Kheyrkhah", "Craig S. Greenberg", "Elliot Singer", "Douglas A. Reynolds", "Lisa P. Mason", "Jaime Hernandez-Cordero"], "https://doi.org/10.21437/Interspeech.2018-69", 5, "interspeech", 2018]], "Owen Conlan": [0, ["An Active Feature Transformation Method for Attitude Recognition of Video Bloggers", ["Fasih Haider", "Fahim A. Salim", "Owen Conlan", "Saturnino Luz"], "https://doi.org/10.21437/Interspeech.2018-1222", 5, "interspeech", 2018]], "Harinath Garudadri": [0, ["Bone-Conduction Sensor Assisted Noise Estimation for Improved Speech Enhancement", ["Ching Hua Lee", "Bhaskar D. Rao", "Harinath Garudadri"], "https://doi.org/10.21437/Interspeech.2018-1046", 5, "interspeech", 2018]], "Oskar Dorfler": [0, ["An Empirical Analysis of the Correlation of Syntax and Prosody", ["Arne Kohn", "Timo Baumann", "Oskar Dorfler"], "https://doi.org/10.21437/Interspeech.2018-2530", 5, "interspeech", 2018]], "Thomas Niesler": [0, ["Building a Unified Code-Switching ASR System for South African Languages", ["Emre Yilmaz", "Astik Biswas", "Ewald van der Westhuizen", "Febe de Wet", "Thomas Niesler"], "https://doi.org/10.21437/Interspeech.2018-1966", 5, "interspeech", 2018], ["Multilingual Neural Network Acoustic Modelling for ASR of Under-Resourced English-isiZulu Code-Switched Speech", ["Astik Biswas", "Febe de Wet", "Ewald van der Westhuizen", "Emre Yilmaz", "Thomas Niesler"], "https://doi.org/10.21437/Interspeech.2018-1711", 5, "interspeech", 2018], ["Fast ASR-free and Almost Zero-resource Keyword Spotting Using DTW and CNNs for Humanitarian Monitoring", ["Raghav Menon", "Herman Kamper", "John Quinn", "Thomas Niesler"], "https://doi.org/10.21437/Interspeech.2018-1580", 5, "interspeech", 2018]], "Julien Diard": [0, ["COSMO SylPhon: A Bayesian Perceptuo-motor Model to Assess Phonological Learning", ["Marie-Lou Barnaud", "Julien Diard", "Pierre Bessiere", "Jean-Luc Schwartz"], "https://doi.org/10.21437/Interspeech.2018-73", 5, "interspeech", 2018]], "Shuai Nie": [0, ["Deep Noise Tracking Network: A Hybrid Signal Processing/Deep Learning Approach to Speech Enhancement", ["Shuai Nie", "Shan Liang", "Bin Liu", "Yaping Zhang", "Wenju Liu", "Jianhua Tao"], "https://doi.org/10.21437/Interspeech.2018-1020", 5, "interspeech", 2018]], "Jarmo Malinen": [0, ["Interaction Mechanisms between Glottal Source and Vocal Tract in Pitch Glides", ["Tiina Murtola", "Jarmo Malinen"], "https://doi.org/10.21437/Interspeech.2018-1827", 5, "interspeech", 2018]], "Rob van Son": [1.6504676292328213e-08, ["Vowel Space as a Tool to Evaluate Articulation Problems", ["Rob van Son", "Catherine Middag", "Kris Demuynck"], "https://doi.org/10.21437/Interspeech.2018-68", 5, "interspeech", 2018]], "Zin Tun Kyaw": [0, ["Mandarin-English Code-switching Speech Recognition", ["Haihua Xu", "Van Tung Pham", "Zin Tun Kyaw", "Zhi Hao Lim", "Eng Siong Chng", "Haizhou Li"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3014.html", 2, "interspeech", 2018]], "Weiqun Xu": [0, ["Cross-Lingual Multi-Task Neural Architecture for Spoken Language Understanding", ["Yujiang Li", "Xuemin Zhao", "Weiqun Xu", "Yonghong Yan"], "https://doi.org/10.21437/Interspeech.2018-1039", 5, "interspeech", 2018]], "Chandra Sekhar Seelamantula": [0, ["Multicomponent 2-D AM-FM Modeling of Speech Spectrograms", ["Jitendra Kumar Dhiman", "Neeraj Sharma", "Chandra Sekhar Seelamantula"], "https://doi.org/10.21437/Interspeech.2018-1937", 5, "interspeech", 2018], ["An Optimization Framework for Recovery of Speech from Phase-Encoded Spectrograms", ["Abhilash Sainathan", "Sunil Rudresh", "Chandra Sekhar Seelamantula"], "https://doi.org/10.21437/Interspeech.2018-1987", 5, "interspeech", 2018], ["Speech Enhancement Using the Minimum-probability-of-error Criterion", ["Jishnu Sadasivan", "Subhadip Mukherjee", "Chandra Sekhar Seelamantula"], "https://doi.org/10.21437/Interspeech.2018-1294", 5, "interspeech", 2018]], "Philippe Chabot": [0, ["Classification of Nonverbal Human Produced Audio Events: A Pilot Study", ["Rachel E. Bouserhal", "Philippe Chabot", "Milton Sarria Paja", "Patrick Cardinal", "Jeremie Voix"], "https://doi.org/10.21437/Interspeech.2018-2299", 5, "interspeech", 2018]], "Giovanni Costantini": [0, ["Categorical vs Dimensional Perception of Italian Emotional Speech", ["Emilia Parada-Cabaleiro", "Giovanni Costantini", "Anton Batliner", "Alice Baird", "Bjorn W. Schuller"], "https://doi.org/10.21437/Interspeech.2018-47", 5, "interspeech", 2018]], "Megan M. Willi": [0, ["A Discriminative Acoustic-Prosodic Approach for Measuring Local Entrainment", ["Megan M. Willi", "Stephanie A. Borrie", "Tyson S. Barrett", "Ming Tu", "Visar Berisha"], "https://doi.org/10.21437/Interspeech.2018-1419", 5, "interspeech", 2018], ["Triplet Network with Attention for Speaker Diarization", ["Huan Song", "Megan M. Willi", "Jayaraman J. Thiagarajan", "Visar Berisha", "Andreas Spanias"], "https://doi.org/10.21437/Interspeech.2018-2305", 5, "interspeech", 2018]], "Olivier Rosec": [0, ["Acoustic-dependent Phonemic Transcription for Text-to-speech Synthesis", ["Kevin Vythelingum", "Yannick Esteve", "Olivier Rosec"], "https://doi.org/10.21437/Interspeech.2018-1306", 5, "interspeech", 2018]], "Tuarik Buanzur": [0, ["A First Investigation of the Timing of Turn-taking in Ruuli", ["Tuarik Buanzur", "Margaret Zellers", "Saudah Namyalo", "Alena Witzlack-Makarevich"], "https://doi.org/10.21437/Interspeech.2018-1254", 5, "interspeech", 2018]], "Sinem Sonsaat": [0, ["L2-ARCTIC: A Non-native English Speech Corpus", ["Guanlong Zhao", "Sinem Sonsaat", "Alif Silpachai", "Ivana Lucic", "Evgeny Chukharev-Hudilainen", "John Levis", "Ricardo Gutierrez-Osuna"], "https://doi.org/10.21437/Interspeech.2018-1110", 5, "interspeech", 2018]], "Jeff Palmer": [0, ["Vocal Biomarkers for Cognitive Performance Estimation in a Working Memory Task", ["Jennifer Sloboda", "Adam C. Lammert", "James R. Williamson", "Christopher J. Smalt", "Daryush D. Mehta", "C. O. L. Ian Curry", "Kristin Heaton", "Jeff Palmer", "Thomas F. Quatieri"], "https://doi.org/10.21437/Interspeech.2018-2418", 5, "interspeech", 2018]], "Huiyi Wu": [4.652872689803189e-06, ["A Deep Learning Method for Pathological Voice Detection Using Convolutional Deep Belief Networks", ["Huiyi Wu", "John J. Soraghan", "Anja Lowit", "Gaetano Di Caterina"], "https://doi.org/10.21437/Interspeech.2018-1351", 5, "interspeech", 2018]], "Yu-Huai Peng": [0, ["Exemplar-Based Spectral Detail Compensation for Voice Conversion", ["Yu-Huai Peng", "Hsin-Te Hwang", "Yi-Chiao Wu", "Yu Tsao", "Hsin-Min Wang"], "https://doi.org/10.21437/Interspeech.2018-1662", 5, "interspeech", 2018]], "Tokihiko Kaburagi": [0, ["Articulatory-to-speech Conversion Using Bi-directional Long Short-term Memory", ["Fumiaki Taguchi", "Tokihiko Kaburagi"], "https://doi.org/10.21437/Interspeech.2018-999", 5, "interspeech", 2018]], "Sung-Lin Yeh": [0, ["Self-Assessed Affect Recognition Using Fusion of Attentional BLSTM and Static Acoustic Features", ["Bo-Hao Su", "Sung-Lin Yeh", "Ming-Ya Ko", "Huan-Yu Chen", "Shun-Chang Zhong", "Jeng-Lin Li", "Chi-Chun Lee"], "https://doi.org/10.21437/Interspeech.2018-2261", 5, "interspeech", 2018]], "Wang Zhang": [0, ["Acoustic Features Associated with Sustained Vowel and Continuous Speech Productions by Chinese Children with Functional Articulation Disorders", ["Wang Zhang", "Xiangquan Gui", "Tianqi Wang", "Manwa L. Ng", "Feng Yang", "Lan Wang", "Nan Yan"], "https://doi.org/10.21437/Interspeech.2018-1521", 5, "interspeech", 2018]], "Jonathan Le Roux": [0, ["End-to-End Speech Separation with Unfolded Iterative Phase Reconstruction", ["Zhong-Qiu Wang", "Jonathan Le Roux", "DeLiang Wang", "John R. Hershey"], "https://doi.org/10.21437/Interspeech.2018-1629", 5, "interspeech", 2018]], "Keisuke Kinoshita": [0, ["Multi-resolution Gammachirp Envelope Distortion Index for Intelligibility Prediction of Noisy Speech", ["Katsuhiko Yamamoto", "Toshio Irino", "Narumi Ohashi", "Shoko Araki", "Keisuke Kinoshita", "Tomohiro Nakatani"], "https://doi.org/10.21437/Interspeech.2018-1291", 5, "interspeech", 2018], ["Integrating Neural Network Based Beamforming and Weighted Prediction Error Dereverberation", ["Lukas Drude", "Christoph Boddeker", "Jahn Heymann", "Reinhold Haeb-Umbach", "Keisuke Kinoshita", "Marc Delcroix", "Tomohiro Nakatani"], "https://doi.org/10.21437/Interspeech.2018-2196", 5, "interspeech", 2018]], "Timo Baumann": [0, ["DialogOS: Simple and Extensible Dialogue Modeling", ["Alexander Koller", "Timo Baumann", "Arne Kohn"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3002.html", 2, "interspeech", 2018], ["An Empirical Analysis of the Correlation of Syntax and Prosody", ["Arne Kohn", "Timo Baumann", "Oskar Dorfler"], "https://doi.org/10.21437/Interspeech.2018-2530", 5, "interspeech", 2018], ["Analysing the Focus of a Hierarchical Attention Network: the Importance of Enjambments When Classifying Post-modern Poetry", ["Timo Baumann", "Hussein Hussein", "Burkhard Meyer-Sickendiek"], "https://doi.org/10.21437/Interspeech.2018-2533", 5, "interspeech", 2018]], "Ishwar Chandra Yadav": [0, ["Non-Uniform Spectral Smoothing for Robust Children's Speech Recognition", ["Ishwar Chandra Yadav", "Avinash Kumar", "Syed Shahnawazuddin", "Gayadhar Pradhan"], "https://doi.org/10.21437/Interspeech.2018-1828", 5, "interspeech", 2018]], "Pedro J. Moreno": [0, ["Semantic Lattice Processing in Contextual Automatic Speech Recognition for Google Assistant", ["Leonid Velikovich", "Ian Williams", "Justin Scheiner", "Petar S. Aleksic", "Pedro J. Moreno", "Michael Riley"], "https://doi.org/10.21437/Interspeech.2018-2453", 5, "interspeech", 2018]], "Hongjiang Yu": [7.99402251061565e-08, ["A Deep Neural Network Based Harmonic Noise Model for Speech Enhancement", ["Zhiheng Ouyang", "Hongjiang Yu", "Wei-Ping Zhu", "Benoit Champagne"], "https://doi.org/10.21437/Interspeech.2018-1114", 5, "interspeech", 2018]], "Takuma Mori": [0, ["Compressing End-to-end ASR Networks by Tensor-Train Decomposition", ["Takuma Mori", "Andros Tjandra", "Sakriani Sakti", "Satoshi Nakamura"], "https://doi.org/10.21437/Interspeech.2018-1543", 5, "interspeech", 2018]], "Vikram C. M.": [0, ["Spoken Keyword Detection Using Joint DTW-CNN", ["Ravi Shankar", "Vikram C. M.", "S. R. Mahadeva Prasanna"], "https://doi.org/10.21437/Interspeech.2018-1436", 5, "interspeech", 2018], ["Detection of Glottal Activity Errors in Production of Stop Consonants in Children with Cleft Lip and Palate", ["Vikram C. M.", "S. R. Mahadeva Prasanna", "Ajish K. Abraham", "Pushpavathi M", "Girish K. S"], "https://doi.org/10.21437/Interspeech.2018-1665", 5, "interspeech", 2018], ["Estimation of Hypernasality Scores from Cleft Lip and Palate Speech", ["Vikram C. M.", "Ayush Tripathi", "Sishir Kalita", "S. R. Mahadeva Prasanna"], "https://doi.org/10.21437/Interspeech.2018-1631", 5, "interspeech", 2018], ["Epoch Extraction from Pathological Children Speech Using Single Pole Filtering Approach", ["Vikram C. M.", "S. R. Mahadeva Prasanna"], "https://doi.org/10.21437/Interspeech.2018-1613", 5, "interspeech", 2018]], "Alp Oktem": [0, ["Visualizing Punctuation Restoration in Speech Transcripts with Prosograph", ["Alp Oktem", "Mireia Farrus", "Antonio Bonafonte"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3028.html", 2, "interspeech", 2018]], "Noelle Carlozzi": [0, ["Classification of Huntington Disease Using Acoustic and Lexical Features", ["Matthew Perez", "Wenyu Jin", "Duc Le", "Noelle Carlozzi", "Praveen Dayalu", "Angela Roberts", "Emily Mower Provost"], "https://doi.org/10.21437/Interspeech.2018-2029", 5, "interspeech", 2018]], "Annam Naresh": [0, ["HoloCompanion: An MR Friend for EveryOne", ["Annam Naresh", "Rushabh Gandhi", "Mallikarjuna Rao Bellamkonda", "Mithun Das Gupta"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3017.html", 2, "interspeech", 2018]], "Xuanda Chen": [0, ["The Trajectory of Voice Onset Time with Vocal Aging", ["Xuanda Chen", "Ziyu Xiong", "Jian Hu"], "https://doi.org/10.21437/Interspeech.2018-60", 5, "interspeech", 2018]], "Kazuya Taira": [0, ["Binaural Speech Intelligibility Estimation Using Deep Neural Networks", ["Kazuhiro Kondo", "Kazuya Taira", "Yosuke Kobayashi"], "https://doi.org/10.21437/Interspeech.2018-27", 5, "interspeech", 2018]], "Seiichi Yamamoto": [0, ["Automatic Assessment of L2 English Word Prosody Using Weighted Distances of F0 and Intensity Contours", ["Quy-Thao Truong", "Tsuneo Kato", "Seiichi Yamamoto"], "https://doi.org/10.21437/Interspeech.2018-1386", 5, "interspeech", 2018]], "Nicole Ekon": [0, ["The Effect of Exposure to High Altitude and Heat on Speech Articulatory Coordination", ["James R. Williamson", "Thomas F. Quatieri", "Adam C. Lammert", "Katherine Mitchell", "Katherine Finkelstein", "Nicole Ekon", "Caitlin Dillon", "Robert Kenefick", "Kristin Heaton"], "https://doi.org/10.21437/Interspeech.2018-2372", 5, "interspeech", 2018]], "Roberto Togneri": [0, ["Spoofing Detection Using Adaptive Weighting Framework and Clustering Analysis", ["Yuanjun Zhao", "Roberto Togneri", "Victor Sreeram"], "https://doi.org/10.21437/Interspeech.2018-1042", 5, "interspeech", 2018]], "Muriel Lalain": [0, ["Automatic Evaluation of Speech Intelligibility Based on I-vectors in the Context of Head and Neck Cancers", ["Imed Laaridh", "Corinne Fredouille", "Alain Ghio", "Muriel Lalain", "Virginie Woisard"], "https://doi.org/10.21437/Interspeech.2018-1266", 5, "interspeech", 2018]], "Alexandros Potamianos": [0, ["Integrating Recurrence Dynamics for Speech Emotion Recognition", ["Efthymios Tzinis", "Georgios Paraskevopoulos", "Christos Baziotis", "Alexandros Potamianos"], "https://doi.org/10.21437/Interspeech.2018-1377", 5, "interspeech", 2018]], "Lin-Shan Lee": [3.882123622567235e-09, ["Multi-target Voice Conversion without Parallel Data by Adversarially Learning Disentangled Audio Representations", ["Ju-Chieh Chou", "Cheng-chieh Yeh", "Hung-yi Lee", "Lin-Shan Lee"], "https://doi.org/10.21437/Interspeech.2018-1830", 5, "interspeech", 2018], ["Completely Unsupervised Phoneme Recognition by Adversarially Learning Mapping Relationships from Audio Embeddings", ["Da-Rong Liu", "Kuan-Yu Chen", "Hung-yi Lee", "Lin-Shan Lee"], "https://doi.org/10.21437/Interspeech.2018-1800", 5, "interspeech", 2018]], "Sandrien van Ommen": [0, ["Neural Response Development During Distributional Learning", ["Natalie Boll-Avetisyan", "Jessie S. Nixon", "Tomas O. Lentz", "Liquan Liu", "Sandrien van Ommen", "Cagri Coltekin", "Jacolien van Rij"], "https://doi.org/10.21437/Interspeech.2018-2072", 5, "interspeech", 2018]], "Lifa Sun": [0.008820109069347382, ["Voice Conversion Across Arbitrary Speakers Based on a Single Target-Speaker Utterance", ["Songxiang Liu", "Jinghua Zhong", "Lifa Sun", "Xixin Wu", "Xunying Liu", "Helen Meng"], "https://doi.org/10.21437/Interspeech.2018-1504", 5, "interspeech", 2018]], "Yadviga Sinyavskaya": [0, ["LOCUST - Longitudinal Corpus and Toolset for Speaker Verification", ["Evgeny Dmitriev", "Yulia Kim", "Anastasia Matveeva", "Claude Montacie", "Yannick Boulard", "Yadviga Sinyavskaya", "Yulia Zhukova", "Adam Zarazinski", "Egor Akhanov", "Ilya I. Viksnin", "Andrei A. Shlykov", "Maria Usova"], "https://doi.org/10.21437/Interspeech.2018-2412", 5, "interspeech", 2018]], "Pavlos Papadopoulos": [0, ["Exploring the Relationship between Conic Affinity of NMF Dictionaries and Speech Enhancement Metrics", ["Pavlos Papadopoulos", "Colin Vaz", "Shrikanth Narayanan"], "https://doi.org/10.21437/Interspeech.2018-1387", 5, "interspeech", 2018], ["Combined Speaker Clustering and Role Recognition in Conversational Speech", ["Nikolaos Flemotomos", "Pavlos Papadopoulos", "James Gibson", "Shrikanth Narayanan"], "https://doi.org/10.21437/Interspeech.2018-1654", 5, "interspeech", 2018]], "Antoine Bruguier": [0, ["Sequence-to-sequence Neural Network Model with 2D Attention for Learning Japanese Pitch Accents", ["Antoine Bruguier", "Heiga Zen", "Arkady Arkhangorodsky"], "https://doi.org/10.21437/Interspeech.2018-1381", 4, "interspeech", 2018], ["Dictionary Augmented Sequence-to-Sequence Neural Network for Grapheme to Phoneme Prediction", ["Antoine Bruguier", "Anton Bakhtin", "Dravyansh Sharma"], "https://doi.org/10.21437/Interspeech.2018-2061", 5, "interspeech", 2018]], "Jia Jia": [0, ["Emotion Recognition from Variable-Length Speech Segments Using Deep Learning on Spectrograms", ["Xi Ma", "Zhiyong Wu", "Jia Jia", "Mingxing Xu", "Helen Meng", "Lianhong Cai"], "https://doi.org/10.21437/Interspeech.2018-2228", 5, "interspeech", 2018]], "Jan Stanek": [0, ["A Robust Context-Dependent Speech-to-Speech Phraselator Toolkit for Alexa", ["Manny Rayner", "Nikos Tsourakis", "Jan Stanek"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3006.html", 2, "interspeech", 2018]], "Shao-Yen Tseng": [0, ["Multiple Instance Deep Learning for Weakly Supervised Small-Footprint Audio Event Detection", ["Shao-Yen Tseng", "Juncheng Li", "Yun Wang", "Florian Metze", "Joseph Szurley", "Samarjit Das"], "https://doi.org/10.21437/Interspeech.2018-1120", 5, "interspeech", 2018]], "Yijie Li": [0, ["Active Learning for LF-MMI Trained Neural Networks in ASR", ["Yanhua Long", "Hong Ye", "Yijie Li", "Jiaen Liang"], "https://doi.org/10.21437/Interspeech.2018-1162", 5, "interspeech", 2018]], "Clinton Fookes": [0, ["Employing Phonetic Information in DNN Speaker Embeddings to Improve Speaker Recognition Performance", ["Md. Hafizur Rahman", "Ivan Himawan", "Mitchell McLaren", "Clinton Fookes", "Sridha Sridharan"], "https://doi.org/10.21437/Interspeech.2018-1804", 5, "interspeech", 2018]], "Vinay Melkote": [0, ["Temporal Noise Shaping with Companding", ["Arijit Biswas", "Per Hedelin", "Lars F. Villemoes", "Vinay Melkote"], "https://doi.org/10.21437/Interspeech.2018-2096", 5, "interspeech", 2018]], "Mohamed Morchid": [0, ["Quaternion Convolutional Neural Networks for End-to-End Automatic Speech Recognition", ["Titouan Parcollet", "Ying Zhang", "Mohamed Morchid", "Chiheb Trabelsi", "Georges Linares", "Renato de Mori", "Yoshua Bengio"], "https://doi.org/10.21437/Interspeech.2018-1898", 5, "interspeech", 2018]], "Chip-Jin Ng": [0, ["Learning Conditional Acoustic Latent Representation with Gender and Age Attributes for Automatic Pain Level Recognition", ["Jeng-Lin Li", "Yi-Ming Weng", "Chip-Jin Ng", "Chi-Chun Lee"], "https://doi.org/10.21437/Interspeech.2018-1298", 5, "interspeech", 2018]], "Andrey Belyaev": [0, ["Automatic Detection of Multi-speaker Fragments with High Time Resolution", ["Evdokia Kazimirova", "Andrey Belyaev"], "https://doi.org/10.21437/Interspeech.2018-1878", 5, "interspeech", 2018]], "Lena Reed": [0, ["Neural MultiVoice Models for Expressing Novel Personalities in Dialog", ["Shereen Oraby", "Lena Reed", "Sharath T. S.", "Shubhangi Tandon", "Marilyn A. Walker"], "https://doi.org/10.21437/Interspeech.2018-2174", 5, "interspeech", 2018]], "Solange Rossato": [0, ["Voice Comparison and Rhythm: Behavioral Differences between Target and Non-target Comparisons", ["Moez Ajili", "Jean-Francois Bonastre", "Solange Rossato"], "https://doi.org/10.21437/Interspeech.2018-61", 5, "interspeech", 2018]], "Agha Ali Raza": [0, ["Rapid Collection of Spontaneous Speech Corpora Using Telephonic Community Forums", ["Agha Ali Raza", "Awais Athar", "Shan Randhawa", "Zain Tariq", "Muhammad Bilal Saleem", "Haris Bin Zia", "Umar Saif", "Roni Rosenfeld"], "https://doi.org/10.21437/Interspeech.2018-1139", 5, "interspeech", 2018]], "Sriram Ganapathy": [0, ["Supervised I-vector Modeling - Theory and Applications", ["Shreyas Ramoji", "Sriram Ganapathy"], "https://doi.org/10.21437/Interspeech.2018-2012", 5, "interspeech", 2018], ["On Convolutional LSTM Modeling for Joint Wake-Word Detection and Text Dependent Speaker Verification", ["Rajath Kumar", "Vaishnavi Yeruva", "Sriram Ganapathy"], "https://doi.org/10.21437/Interspeech.2018-1759", 5, "interspeech", 2018], ["Talker Diarization in the Wild: the Case of Child-centered Daylong Audio-recordings", ["Alejandrina Cristia", "Shobhana Ganesh", "Marisa Casillas", "Sriram Ganapathy"], "https://doi.org/10.21437/Interspeech.2018-2078", 5, "interspeech", 2018], ["Comparison of Unsupervised Modulation Filter Learning Methods for ASR", ["Purvi Agrawal", "Sriram Ganapathy"], "https://doi.org/10.21437/Interspeech.2018-1972", 5, "interspeech", 2018], ["Far-Field Speech Recognition Using Multivariate Autoregressive Models", ["Sriram Ganapathy", "Madhumita Harish"], "https://doi.org/10.21437/Interspeech.2018-2003", 5, "interspeech", 2018], ["Speaker and Language Recognition - From Laboratory Technologies to the Wild", ["Sriram Ganapathy"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/4008.html", 1, "interspeech", 2018]], "Sandra Ottl": [0, ["Recognition of Echolalic Autistic Child Vocalisations Utilising Convolutional Recurrent Neural Networks", ["Shahin Amiriparian", "Alice Baird", "Sahib Julka", "Alyssa Alcorn", "Sandra Ottl", "Suncica Petrovic", "Eloise Ainger", "Nicholas Cummins", "Bjorn W. Schuller"], "https://doi.org/10.21437/Interspeech.2018-1772", 5, "interspeech", 2018]], "Stephen A. Zahorian": [0, ["Cross-Corpora Convolutional Deep Neural Network Dereverberation Preprocessing for Speaker Verification and Speech Enhancement", ["Peter Guzewich", "Stephen A. Zahorian", "Xiao Chen", "Hao Zhang"], "https://doi.org/10.21437/Interspeech.2018-2238", 5, "interspeech", 2018]], "Jason Levy": [0, ["Fully Automatic Speaker Separation System, with Automatic Enrolling of Recurrent Speakers", ["Raphael Cohen", "Orgad Keller", "Jason Levy", "Russell Levy", "Micha Breakstone", "Amit Ashkenazi"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3034.html", 2, "interspeech", 2018]], "Hari Krishna Vydana": [0, ["An Exploration towards Joint Acoustic Modeling for Indian Languages: IIIT-H Submission for Low Resource Speech Recognition Challenge for Indian Languages, INTERSPEECH 2018", ["Hari Krishna Vydana", "Krishna Gurugubelli", "Vishnu Vidyadhara Raju Vegesna", "Anil Kumar Vuppala"], "https://doi.org/10.21437/Interspeech.2018-1584", 5, "interspeech", 2018]], "Sang-goo Lee": [1, ["Slot Filling with Delexicalized Sentence Generation", ["Youhyun Shin", "Kang Min Yoo", "Sang-goo Lee"], "https://doi.org/10.21437/Interspeech.2018-1808", 5, "interspeech", 2018]], "Gautam Bhattacharya": [0, ["Deeply Fused Speaker Embeddings for Text-Independent Speaker Verification", ["Gautam Bhattacharya", "Md. Jahangir Alam", "Vishwa Gupta", "Patrick Kenny"], "https://doi.org/10.21437/Interspeech.2018-1688", 5, "interspeech", 2018]], "Shankar M. Venkatesan": [0, ["Global SNR Estimation of Speech Signals Using Entropy and Uncertainty Estimates from Dropout Networks", ["Rohith Aralikatti", "Dilip Kumar Margam", "Tanay Sharma", "Abhinav Thanda", "Shankar M. Venkatesan"], "https://doi.org/10.21437/Interspeech.2018-1884", 5, "interspeech", 2018]], "Ching Hua Lee": [9.075021983884213e-11, ["Bone-Conduction Sensor Assisted Noise Estimation for Improved Speech Enhancement", ["Ching Hua Lee", "Bhaskar D. Rao", "Harinath Garudadri"], "https://doi.org/10.21437/Interspeech.2018-1046", 5, "interspeech", 2018]], "Mirco Ravanelli": [0, ["Twin Regularization for Online Speech Recognition", ["Mirco Ravanelli", "Dmitriy Serdyuk", "Yoshua Bengio"], "https://doi.org/10.21437/Interspeech.2018-1407", 5, "interspeech", 2018]], "Dan Aharon": [0, ["Voice-powered Solutions with Cloud AI", ["Dan Aharon"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3049.html", 1, "interspeech", 2018]], "Kiyoshi Honda": [0, ["Tongue Segmentation with Geometrically Constrained Snake Model", ["Zhihua Su", "Jianguo Wei", "Qiang Fang", "Jianrong Wang", "Kiyoshi Honda"], "https://doi.org/10.21437/Interspeech.2018-1108", 5, "interspeech", 2018]], "Wei-Ning Hsu": [0, ["Scalable Factorized Hierarchical Variational Autoencoder Training", ["Wei-Ning Hsu", "James R. Glass"], "https://doi.org/10.21437/Interspeech.2018-1034", 5, "interspeech", 2018], ["Unsupervised Adaptation with Interpretable Disentangled Representations for Distant Conversational Speech Recognition", ["Wei-Ning Hsu", "Hao Tang", "James R. Glass"], "https://doi.org/10.21437/Interspeech.2018-1097", 5, "interspeech", 2018], ["A Study of Enhancement, Augmentation and Autoencoder Methods for Domain Adaptation in Distant Speech Recognition", ["Hao Tang", "Wei-Ning Hsu", "Francois Grondin", "James R. Glass"], "https://doi.org/10.21437/Interspeech.2018-2030", 5, "interspeech", 2018]], "Sula Ross": [0, ["The 'West Yorkshire Regional English Database': Investigations into the Generalizability of Reference Populations for Forensic Speaker Comparison Casework", ["Erica Gold", "Sula Ross", "Kate Earnshaw"], "https://doi.org/10.21437/Interspeech.2018-65", 5, "interspeech", 2018]], "Lucas D. Terissi": [0, ["A French-Spanish Multimodal Speech Communication Corpus Incorporating Acoustic Data, Facial, Hands and Arms Gestures Information", ["Lucas D. Terissi", "Gonzalo D. Sad", "Mauricio Cerda", "Slim Ouni", "Rodrigo Galvez", "Juan Carlos Gomez", "Bernard Girau", "Nancy Hitschfeld-Kahler"], "https://doi.org/10.21437/Interspeech.2018-2212", 5, "interspeech", 2018]], "Petr Motlicek": [0, ["Joint Localization and Classification of Multiple Sound Sources Using a Multi-task Neural Network", ["Weipeng He", "Petr Motlicek", "Jean-Marc Odobez"], "https://doi.org/10.21437/Interspeech.2018-1269", 5, "interspeech", 2018], ["Analysis of Language Dependent Front-End for Speaker Recognition", ["Srikanth R. Madikeri", "Subhadeep Dey", "Petr Motlicek"], "https://doi.org/10.21437/Interspeech.2018-2071", 5, "interspeech", 2018], ["Iterative Learning of Speech Recognition Models for Air Traffic Control", ["Ajay Srinivasamurthy", "Petr Motlicek", "Mittul Singh", "Youssef Oualil", "Matthias Kleinert", "Heiko Ehr", "Hartmut Helmke"], "https://doi.org/10.21437/Interspeech.2018-1447", 5, "interspeech", 2018], ["End-to-end Text-dependent Speaker Verification Using Novel Distance Measures", ["Subhadeep Dey", "Srikanth R. Madikeri", "Petr Motlicek"], "https://doi.org/10.21437/Interspeech.2018-2300", 5, "interspeech", 2018]], "Christian Weinert": [0, ["VoiceGuard: Secure and Private Speech Processing", ["Ferdinand Brasser", "Tommaso Frassetto", "Korbinian Riedhammer", "Ahmad-Reza Sadeghi", "Thomas Schneider", "Christian Weinert"], "https://doi.org/10.21437/Interspeech.2018-2032", 5, "interspeech", 2018]], "Kay Berkling": [0, ["The CSU-K Rule-Based System for the 2nd Edition Spoken CALL Shared Task", ["Dominik Julg", "Mario Kunstek", "Cem Philipp Freimoser", "Kay Berkling", "Mengjie Qian"], "https://doi.org/10.21437/Interspeech.2018-1000", 5, "interspeech", 2018]], "Jan Zelinka": [0, ["ZCU-NTIS Speaker Diarization System for the DIHARD 2018 Challenge", ["Zbynek Zajic", "Marie Kunesova", "Jan Zelinka", "Marek Hruz"], "https://doi.org/10.21437/Interspeech.2018-1252", 5, "interspeech", 2018]], "Kusha Sridhar": [0, ["Role of Regularization in the Prediction of Valence from Speech", ["Kusha Sridhar", "Srinivas Parthasarathy", "Carlos Busso"], "https://doi.org/10.21437/Interspeech.2018-2508", 5, "interspeech", 2018]], "Dogan Can": [0, ["Using Prosodic and Lexical Information for Learning Utterance-level Behaviors in Psychotherapy", ["Karan Singla", "Zhuohao Chen", "Nikolaos Flemotomos", "James Gibson", "Dogan Can", "David C. Atkins", "Shrikanth Narayanan"], "https://doi.org/10.21437/Interspeech.2018-2551", 5, "interspeech", 2018]], "Kuan Tung": [0, ["Joint Learning of Interactive Spoken Content Retrieval and Trainable User Simulator", ["Pei-Hung Chung", "Kuan Tung", "Ching-Lun Tai", "Hung-yi Lee"], "https://doi.org/10.21437/Interspeech.2018-1346", 5, "interspeech", 2018]], "Arjun Pankajakshan": [0, ["All-Conv Net for Bird Activity Detection: Significance of Learned Pooling", ["Arjun Pankajakshan", "Anshul Thakur", "Daksh Thapar", "Padmanabhan Rajan", "Aditya Nigam"], "https://doi.org/10.21437/Interspeech.2018-1522", 5, "interspeech", 2018]], "Basil Abraham": [0, ["Articulatory and Stacked Bottleneck Features for Low Resource Speech Recognition", ["Vishwas M. Shetty", "Rini A. Sharon", "Basil Abraham", "Tejaswi Seeram", "Anusha Prakash", "Nithya Ravi", "Srinivasan Umesh"], "https://doi.org/10.21437/Interspeech.2018-2226", 5, "interspeech", 2018]], "Fei Wu": [0.000492751831188798, ["Pitch Characteristics of L2 English Speech by Chinese Speakers: A Large-scale Study", ["Jiahong Yuan", "Qiusi Dong", "Fei Wu", "Huan Luan", "Xiaofei Yang", "Hui Lin", "Yang Liu"], "https://doi.org/10.21437/Interspeech.2018-1556", 5, "interspeech", 2018]], "Petar S. Aleksic": [0, ["Semantic Lattice Processing in Contextual Automatic Speech Recognition for Google Assistant", ["Leonid Velikovich", "Ian Williams", "Justin Scheiner", "Petar S. Aleksic", "Pedro J. Moreno", "Michael Riley"], "https://doi.org/10.21437/Interspeech.2018-2453", 5, "interspeech", 2018], ["Contextual Speech Recognition in End-to-end Neural Network Systems Using Beam Search", ["Ian Williams", "Anjuli Kannan", "Petar S. Aleksic", "David Rybach", "Tara N. Sainath"], "https://doi.org/10.21437/Interspeech.2018-2416", 5, "interspeech", 2018]], "Rong Gong": [0.01968786818906665, ["Singing Voice Phoneme Segmentation by Hierarchically Inferring Syllable and Phoneme Onset Positions", ["Rong Gong", "Xavier Serra"], "https://doi.org/10.21437/Interspeech.2018-1224", 5, "interspeech", 2018]], "Nanxin Chen": [0, ["An Investigation of Non-linear i-vectors for Speaker Verification", ["Nanxin Chen", "Jesus Villalba", "Najim Dehak"], "https://doi.org/10.21437/Interspeech.2018-2474", 5, "interspeech", 2018], ["End-to-end Deep Neural Network Age Estimation", ["Pegah Ghahremani", "Phani Sankar Nidadavolu", "Nanxin Chen", "Jesus Villalba", "Daniel Povey", "Sanjeev Khudanpur", "Najim Dehak"], "https://doi.org/10.21437/Interspeech.2018-2015", 5, "interspeech", 2018], ["ESPnet: End-to-End Speech Processing Toolkit", ["Shinji Watanabe", "Takaaki Hori", "Shigeki Karita", "Tomoki Hayashi", "Jiro Nishitoba", "Yuya Unno", "Nelson Enrique Yalta Soplin", "Jahn Heymann", "Matthew Wiesner", "Nanxin Chen", "Adithya Renduchintala", "Tsubasa Ochiai"], "https://doi.org/10.21437/Interspeech.2018-1456", 5, "interspeech", 2018]], "Erica Cooper": [0, ["A Comparison of Speaker-based and Utterance-based Data Selection for Text-to-Speech Synthesis", ["Kai-Zhan Lee", "Erica Cooper", "Julia Hirschberg"], "https://doi.org/10.21437/Interspeech.2018-1313", 5, "interspeech", 2018]], "Juan Rafael Orozco-Arroyave": [0, ["A Multitask Learning Approach to Assess the Dysarthria Severity in Patients with Parkinson's Disease", ["Juan Camilo Vasquez-Correa", "Tomas Arias-Vergara", "Juan Rafael Orozco-Arroyave", "Elmar Noth"], "https://doi.org/10.21437/Interspeech.2018-1988", 5, "interspeech", 2018], ["Multimodal I-vectors to Detect and Evaluate Parkinson's Disease", ["Nicanor Garcia", "Juan Camilo Vasquez-Correa", "Juan Rafael Orozco-Arroyave", "Elmar Noth"], "https://doi.org/10.21437/Interspeech.2018-2295", 5, "interspeech", 2018]], "Shuoyang Ding": [0, ["Multi-Modal Data Augmentation for End-to-end ASR", ["Adithya Renduchintala", "Shuoyang Ding", "Matthew Wiesner", "Shinji Watanabe"], "https://doi.org/10.21437/Interspeech.2018-2456", 5, "interspeech", 2018]], "Atsunori Ogawa": [0, ["Semi-Supervised End-to-End Speech Recognition", ["Shigeki Karita", "Shinji Watanabe", "Tomoharu Iwata", "Atsunori Ogawa", "Marc Delcroix"], "https://doi.org/10.21437/Interspeech.2018-1746", 5, "interspeech", 2018], ["Auxiliary Feature Based Adaptation of End-to-end ASR Systems", ["Marc Delcroix", "Shinji Watanabe", "Atsunori Ogawa", "Shigeki Karita", "Tomohiro Nakatani"], "https://doi.org/10.21437/Interspeech.2018-1438", 5, "interspeech", 2018]], "Xu Bo": [0, ["An End-to-End Text-Independent Speaker Identification System on Short Utterances", ["Ruifang Ji", "Xinyuan Cai", "Xu Bo"], "https://doi.org/10.21437/Interspeech.2018-1058", 5, "interspeech", 2018]], "Karen Livescu": [0, ["Low-Resource Speech-to-Text Translation", ["Sameer Bansal", "Herman Kamper", "Karen Livescu", "Adam Lopez", "Sharon Goldwater"], "https://doi.org/10.21437/Interspeech.2018-1326", 5, "interspeech", 2018]], "Yuanyuan Zhao": [0, ["Gated Recurrent Unit Based Acoustic Modeling with Future Context", ["Jie Li", "Xiaorui Wang", "Yuanyuan Zhao", "Yan Li"], "https://doi.org/10.21437/Interspeech.2018-1544", 5, "interspeech", 2018]], "Fengpei Ge": [0, ["Investigation on the Combination of Batch Normalization and Dropout in BLSTM-based Acoustic Modeling for ASR", ["Wenjie Li", "Gaofeng Cheng", "Fengpei Ge", "Pengyuan Zhang", "Yonghong Yan"], "https://doi.org/10.21437/Interspeech.2018-1597", 5, "interspeech", 2018]], "Sanjeev Gurugopinath": [0, ["Robust Voice Activity Detection Using Frequency Domain Long-Term Differential Entropy", ["Debayan Ghosh", "Muralishankar R", "Sanjeev Gurugopinath"], "https://doi.org/10.21437/Interspeech.2018-1431", 5, "interspeech", 2018]], "Aaron Nicolson": [0, ["Bidirectional Long-Short Term Memory Network-based Estimation of Reliable Spectral Component Locations", ["Aaron Nicolson", "Kuldip K. Paliwal"], "https://doi.org/10.21437/Interspeech.2018-1134", 5, "interspeech", 2018]], "Anshuman Tripathi": [0, ["Domain Adaptation Using Factorized Hidden Layer for Robust Automatic Speech Recognition", ["Khe Chai Sim", "Arun Narayanan", "Ananya Misra", "Anshuman Tripathi", "Golan Pundak", "Tara N. Sainath", "Parisa Haghani", "Bo Li", "Michiel Bacchiani"], "https://doi.org/10.21437/Interspeech.2018-2246", 5, "interspeech", 2018], ["Speech Recognition for Medical Conversations", ["Chung-Cheng Chiu", "Anshuman Tripathi", "Katherine Chou", "Chris Co", "Navdeep Jaitly", "Diana Jaunzeikare", "Anjuli Kannan", "Patrick Nguyen", "Hasim Sak", "Ananth Sankar", "Justin Tansuwan", "Nathan Wan", "Yonghui Wu", "Xuedong Zhang"], "https://doi.org/10.21437/Interspeech.2018-40", 5, "interspeech", 2018]], "Tieqiang Wang": [2.7761829501926627e-09, ["Single-channel Speech Dereverberation via Generative Adversarial Training", ["Chenxing Li", "Tieqiang Wang", "Shuang Xu", "Bo Xu"], "https://doi.org/10.21437/Interspeech.2018-1234", 5, "interspeech", 2018]], "Yue Lang": [0, ["Early Detection of Continuous and Partial Audio Events Using CNN", ["Ian Vince McLoughlin", "Yan Song", "Lam Dang Pham", "Ramaswamy Palaniappan", "Huy Phan", "Yue Lang"], "https://doi.org/10.21437/Interspeech.2018-1821", 5, "interspeech", 2018]], "Qiguang Lin": [0, ["A Novel Normalization Method for Autocorrelation Function for Pitch Detection and for Speech Activity Detection", ["Qiguang Lin", "Yiwen Shao"], "https://doi.org/10.21437/Interspeech.2018-45", 5, "interspeech", 2018]], "Katlin Aare": [0, ["Creak in the Respiratory Cycle", ["Katlin Aare", "Partel Lippus", "Marcin Wlodarczak", "Mattias Heldner"], "https://doi.org/10.21437/Interspeech.2018-2165", 5, "interspeech", 2018]], "Hongjie Chen": [0, ["Learning Acoustic Word Embeddings with Temporal Context for Query-by-Example Speech Search", ["Yougen Yuan", "Cheung-Chi Leung", "Lei Xie", "Hongjie Chen", "Bin Ma", "Haizhou Li"], "https://doi.org/10.21437/Interspeech.2018-1010", 5, "interspeech", 2018]], "David Konopnicki": [0, ["Word Emphasis Prediction for Expressive Text to Speech", ["Yosi Mass", "Slava Shechtman", "Moran Mordechay", "Ron Hoory", "Oren Sar Shalom", "Guy Lev", "David Konopnicki"], "https://doi.org/10.21437/Interspeech.2018-1159", 5, "interspeech", 2018]], "Viktor Rozgic": [0, ["Detecting Media Sound Presence in Acoustic Scenes", ["Constantinos Papayiannis", "Justice Amoh", "Viktor Rozgic", "Shiva Sundaram", "Chao Wang"], "https://doi.org/10.21437/Interspeech.2018-2559", 5, "interspeech", 2018]], "Daniel Williams": [0, ["Perceptual Sensitivity to Spectral Change in Australian English Close Front Vowels: An Electroencephalographic Investigation", ["Daniel Williams", "Paola Escudero", "Adamantios I. Gafos"], "https://doi.org/10.21437/Interspeech.2018-2505", 5, "interspeech", 2018]], "Sheng Zhang": [0, ["Improved Supervised Locality Preserving Projection for I-vector Based Speaker Verification", ["Lanhua You", "Wu Guo", "Yan Song", "Sheng Zhang"], "https://doi.org/10.21437/Interspeech.2018-41", 5, "interspeech", 2018]], "Amelie Rochet-Capellan": [0, ["Picture Naming or Word Reading: Does the Modality Affect Speech Motor Adaptation and Its Transfer?", ["Tiphaine Caudrelier", "Pascal Perrier", "Jean-Luc Schwartz", "Amelie Rochet-Capellan"], "https://doi.org/10.21437/Interspeech.2018-1760", 5, "interspeech", 2018]], "Kris Demuynck": [0, ["Vowel Space as a Tool to Evaluate Articulation Problems", ["Rob van Son", "Catherine Middag", "Kris Demuynck"], "https://doi.org/10.21437/Interspeech.2018-68", 5, "interspeech", 2018], ["Cross-lingual Speech Emotion Recognition through Factor Analysis", ["Brecht Desplanques", "Kris Demuynck"], "https://doi.org/10.21437/Interspeech.2018-1778", 5, "interspeech", 2018]], "Yue Deng": [0, ["Training Recurrent Neural Network through Moment Matching for NLP Applications", ["Yue Deng", "Yilin Shen", "KaWai Chen", "Hongxia Jin"], "https://doi.org/10.21437/Interspeech.2018-1369", 5, "interspeech", 2018]], "Zikra Iqbal": [0, ["Extracting Speaker's Gender, Accent, Age and Emotional State from Speech", ["Nagendra Kumar Goel", "Mousmita Sarma", "Tejendra Kushwah", "Dharmesh Agarwal", "Zikra Iqbal", "Surbhi Chauhan"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3036.html", 2, "interspeech", 2018]], "Surbhi Sakshi": [0, ["Analysis of Variational Mode Functions for Robust Detection of Vowels", ["Surbhi Sakshi", "Avinash Kumar", "Gayadhar Pradhan"], "https://doi.org/10.21437/Interspeech.2018-1947", 5, "interspeech", 2018]], "Chandrakant Bothe": [0, ["Conversational Analysis Using Utterance-level Attention-based Bidirectional Recurrent Neural Networks", ["Chandrakant Bothe", "Sven Magg", "Cornelius Weber", "Stefan Wermter"], "https://doi.org/10.21437/Interspeech.2018-2527", 5, "interspeech", 2018]], "Xiao-Lei Zhang": [0, ["Cosine Metric Learning for Speaker Verification in the I-vector Space", ["Zhongxin Bai", "Xiao-Lei Zhang", "Jingdong Chen"], "https://doi.org/10.21437/Interspeech.2018-1593", 5, "interspeech", 2018]], "Janek Ebbers": [0, ["Full Bayesian Hidden Markov Model Variational Autoencoder for Acoustic Unit Discovery", ["Thomas Glarner", "Patrick Hanebrink", "Janek Ebbers", "Reinhold Haeb-Umbach"], "https://doi.org/10.21437/Interspeech.2018-2148", 5, "interspeech", 2018]], "Moquan Wan": [0, ["Waveform-Based Speaker Representations for Speech Synthesis", ["Moquan Wan", "Gilles Degottex", "Mark J. F. Gales"], "https://doi.org/10.21437/Interspeech.2018-1154", 5, "interspeech", 2018]], "Maheshkumar H. Kolekar": [0, ["Music Genre Recognition Using Deep Neural Networks and Transfer Learning", ["Deepanway Ghosal", "Maheshkumar H. Kolekar"], "https://doi.org/10.21437/Interspeech.2018-2045", 5, "interspeech", 2018]], "Vinay Namboodiri": [0, ["Monoaural Audio Source Separation Using Variational Autoencoders", ["Laxmi Pandey", "Anurendra Kumar", "Vinay Namboodiri"], "https://doi.org/10.21437/Interspeech.2018-1140", 5, "interspeech", 2018]], "Aditya Joglekar": [0, ["Fearless Steps: Apollo-11 Corpus Advancements for Speech Technologies from Earth to the Moon", ["John H. L. Hansen", "Abhijeet Sangwan", "Aditya Joglekar", "Ahmet Emin Bulut", "Lakshmish Kaushik", "Chengzhu Yu"], "https://doi.org/10.21437/Interspeech.2018-1942", 5, "interspeech", 2018]], "Bernd T. Meyer": [0, ["Prediction of Perceived Speech Quality Using Deep Machine Listening", ["Jasper Ooster", "Rainer Huber", "Bernd T. Meyer"], "https://doi.org/10.21437/Interspeech.2018-1374", 5, "interspeech", 2018], ["Prediction of Subjective Listening Effort from Acoustic Data with Non-Intrusive Deep Models", ["Paul Kranzusch", "Rainer Huber", "Melanie Kruger", "Birger Kollmeier", "Bernd T. Meyer"], "https://doi.org/10.21437/Interspeech.2018-1375", 5, "interspeech", 2018]], "Daragh Heitzman": [0, ["Automatic Early Detection of Amyotrophic Lateral Sclerosis from Intelligible Speech Using Convolutional Neural Networks", ["Kwanghoon An", "Myung Jong Kim", "Kristin Teplansky", "Jordan R. Green", "Thomas Campbell", "Yana Yunusova", "Daragh Heitzman", "Jun Wang"], "https://doi.org/10.21437/Interspeech.2018-2496", 5, "interspeech", 2018]], "Arne Kohn": [0, ["DialogOS: Simple and Extensible Dialogue Modeling", ["Alexander Koller", "Timo Baumann", "Arne Kohn"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3002.html", 2, "interspeech", 2018], ["An Empirical Analysis of the Correlation of Syntax and Prosody", ["Arne Kohn", "Timo Baumann", "Oskar Dorfler"], "https://doi.org/10.21437/Interspeech.2018-2530", 5, "interspeech", 2018]], "Zheng-Hua Tan": [0, ["Effectiveness of Single-Channel BLSTM Enhancement for Language Identification", ["Peter Sibbern Frederiksen", "Jesus Villalba", "Shinji Watanabe", "Zheng-Hua Tan", "Najim Dehak"], "https://doi.org/10.21437/Interspeech.2018-2458", 5, "interspeech", 2018]], "Zoltan Tuske": [0, ["Investigation on LSTM Recurrent N-gram Language Models for Speech Recognition", ["Zoltan Tuske", "Ralf Schluter", "Hermann Ney"], "https://doi.org/10.21437/Interspeech.2018-2476", 5, "interspeech", 2018]], "Nick Campbell": [0, ["Improving Response Time of Active Speaker Detection Using Visual Prosody Information Prior to Articulation", ["Fasih Haider", "Saturnino Luz", "Carl Vogel", "Nick Campbell"], "https://doi.org/10.21437/Interspeech.2018-2310", 5, "interspeech", 2018]], "Jean-Luc Schwartz": [0, ["Picture Naming or Word Reading: Does the Modality Affect Speech Motor Adaptation and Its Transfer?", ["Tiphaine Caudrelier", "Pascal Perrier", "Jean-Luc Schwartz", "Amelie Rochet-Capellan"], "https://doi.org/10.21437/Interspeech.2018-1760", 5, "interspeech", 2018], ["COSMO SylPhon: A Bayesian Perceptuo-motor Model to Assess Phonological Learning", ["Marie-Lou Barnaud", "Julien Diard", "Pierre Bessiere", "Jean-Luc Schwartz"], "https://doi.org/10.21437/Interspeech.2018-73", 5, "interspeech", 2018]], "Rosey Billington": [0, ["Homogeneity vs Heterogeneity in Indian English: Investigating Influences of L1 on f0 Range", ["Olga Maxwell", "Elinor Payne", "Rosey Billington"], "https://doi.org/10.21437/Interspeech.2018-1476", 5, "interspeech", 2018]], "Luciano Fadiga": [0, ["Analyzing Vocal Tract Movements During Speech Accommodation", ["Sankar Mukherjee", "Thierry Legou", "Leonardo Lancia", "Pauline Hilt", "Alice Tomassini", "Luciano Fadiga", "Alessandro DAusilio", "Leonardo Badino", "Noel Nguyen"], "https://doi.org/10.21437/Interspeech.2018-2084", 5, "interspeech", 2018]], "Jian Cheng": [0, ["Real-Time Scoring of an Oral Reading Assessment on Mobile Devices", ["Jian Cheng"], "https://doi.org/10.21437/Interspeech.2018-34", 5, "interspeech", 2018], ["Modeling Self-Reported and Observed Affect from Speech", ["Jian Cheng", "Jared Bernstein", "Elizabeth Rosenfeld", "Peter W. Foltz", "Alex S. Cohen", "Terje B. Holmlund", "Brita Elvevag"], "https://doi.org/10.21437/Interspeech.2018-2222", 5, "interspeech", 2018]], "Siddharth Sigtia": [0, ["Efficient Voice Trigger Detection for Low Resource Hardware", ["Siddharth Sigtia", "Rob Haynes", "Hywel Richards", "Erik Marchi", "John Bridle"], "https://doi.org/10.21437/Interspeech.2018-2204", 5, "interspeech", 2018]], "Kate Knill": [0, ["A Deep Learning Approach to Assessing Non-native Pronunciation of English Using Phone Distances", ["Konstantinos Kyriakopoulos", "Kate Knill", "Mark J. F. Gales"], "https://doi.org/10.21437/Interspeech.2018-1087", 5, "interspeech", 2018], ["Impact of ASR Performance on Free Speaking Language Assessment", ["Kate Knill", "Mark J. F. Gales", "Konstantinos Kyriakopoulos", "Andrey Malinin", "Anton Ragni", "Yu Wang", "Andrew Caines"], "https://doi.org/10.21437/Interspeech.2018-1312", 5, "interspeech", 2018]], "Vassilis Tsiaras": [0, ["Speech Intelligibility Enhancement Based on a Non-causal Wavenet-like Model", ["P. V. Muhammed Shifas", "Vassilis Tsiaras", "Yannis Stylianou"], "https://doi.org/10.21437/Interspeech.2018-2119", 5, "interspeech", 2018], ["Speaker-independent Raw Waveform Model for Glottal Excitation", ["Lauri Juvela", "Vassilis Tsiaras", "Bajibabu Bollepalli", "Manu Airaksinen", "Junichi Yamagishi", "Paavo Alku"], "https://doi.org/10.21437/Interspeech.2018-1635", 5, "interspeech", 2018]], "Thomas F. Quatieri": [0, ["The Effect of Exposure to High Altitude and Heat on Speech Articulatory Coordination", ["James R. Williamson", "Thomas F. Quatieri", "Adam C. Lammert", "Katherine Mitchell", "Katherine Finkelstein", "Nicole Ekon", "Caitlin Dillon", "Robert Kenefick", "Kristin Heaton"], "https://doi.org/10.21437/Interspeech.2018-2372", 5, "interspeech", 2018], ["Vocal Biomarkers for Cognitive Performance Estimation in a Working Memory Task", ["Jennifer Sloboda", "Adam C. Lammert", "James R. Williamson", "Christopher J. Smalt", "Daryush D. Mehta", "C. O. L. Ian Curry", "Kristin Heaton", "Jeff Palmer", "Thomas F. Quatieri"], "https://doi.org/10.21437/Interspeech.2018-2418", 5, "interspeech", 2018]], "Xiaomin Chen": [0, ["Towards Temporal Modelling of Categorical Speech Emotion Recognition", ["Wenjing Han", "Huabin Ruan", "Xiaomin Chen", "Zhixiang Wang", "Haifeng Li", "Bjorn W. Schuller"], "https://doi.org/10.21437/Interspeech.2018-1858", 5, "interspeech", 2018]], "Shreyas Ramoji": [0, ["Supervised I-vector Modeling - Theory and Applications", ["Shreyas Ramoji", "Sriram Ganapathy"], "https://doi.org/10.21437/Interspeech.2018-2012", 5, "interspeech", 2018]], "Yiqin Zhao": [0, ["Exploring Spatio-Temporal Representations by Integrating Attention-based Bidirectional-LSTM-RNNs and FCNs for Speech Emotion Recognition", ["Ziping Zhao", "Yu Zheng", "Zixing Zhang", "Haishuai Wang", "Yiqin Zhao", "Chao Li"], "https://doi.org/10.21437/Interspeech.2018-1477", 5, "interspeech", 2018]], "Nobuaki Minematsu": [0, ["A Comparative Study of Statistical Conversion of Face to Voice Based on Their Subjective Impressions", ["Yasuhito Ohsugi", "Daisuke Saito", "Nobuaki Minematsu"], "https://doi.org/10.21437/Interspeech.2018-2005", 5, "interspeech", 2018], ["A Study of Objective Measurement of Comprehensibility through Native Speakers' Shadowing of Learners' Utterances", ["Yusuke Inoue", "Suguru Kabashima", "Daisuke Saito", "Nobuaki Minematsu", "Kumi Kanamura", "Yutaka Yamauchi"], "https://doi.org/10.21437/Interspeech.2018-1860", 5, "interspeech", 2018]], "Hannah Muckenhirn": [0, ["On Learning to Identify Genders from Raw Speech Signal Using CNNs", ["Selen Hande Kabil", "Hannah Muckenhirn", "Mathew Magimai-Doss"], "https://doi.org/10.21437/Interspeech.2018-1240", 5, "interspeech", 2018], ["On Learning Vocal Tract System Related Speaker Discriminative Information from Raw Signal Using CNNs", ["Hannah Muckenhirn", "Mathew Magimai-Doss", "Sebastien Marcel"], "https://doi.org/10.21437/Interspeech.2018-1696", 5, "interspeech", 2018]], "Denis Beautemps": [0, ["Visual Recognition of Continuous Cued Speech Using a Tandem CNN-HMM Approach", ["Li Liu", "Thomas Hueber", "Gang Feng", "Denis Beautemps"], "https://doi.org/10.21437/Interspeech.2018-2434", 5, "interspeech", 2018]], "Linxue Bai": [2.363286899509376e-08, ["Exploring How Phone Classification Neural Networks Learn Phonetic Information by Visualising and Interpreting Bottleneck Features", ["Linxue Bai", "Philip Weber", "Peter Jancovic", "Martin J. Russell"], "https://doi.org/10.21437/Interspeech.2018-2462", 5, "interspeech", 2018], ["Phone Recognition Using a Non-Linear Manifold with Broad Phone Class Dependent DNNs", ["Mengjie Qian", "Linxue Bai", "Peter Jancovic", "Martin J. Russell"], "https://doi.org/10.21437/Interspeech.2018-1376", 5, "interspeech", 2018]], "Rohit Prabhavalkar": [0, ["Compression of End-to-End Models", ["Ruoming Pang", "Tara N. Sainath", "Rohit Prabhavalkar", "Suyog Gupta", "Yonghui Wu", "Shuyuan Zhang", "Chung-Cheng Chiu"], "https://doi.org/10.21437/Interspeech.2018-1025", 5, "interspeech", 2018]], "G. Nisha Meenakshi": [0, ["Whispered Speech to Neutral Speech Conversion Using Bidirectional LSTMs", ["G. Nisha Meenakshi", "Prasanta Kumar Ghosh"], "https://doi.org/10.21437/Interspeech.2018-1487", 5, "interspeech", 2018], ["Reconstructing Neutral Speech from Tracheoesophageal Speech", ["Abinay Reddy N", "M. V. Achuth Rao", "G. Nisha Meenakshi", "Prasanta Kumar Ghosh"], "https://doi.org/10.21437/Interspeech.2018-1907", 5, "interspeech", 2018], ["Relating Articulatory Motions in Different Speaking Rates", ["Astha Singh", "G. Nisha Meenakshi", "Prasanta Kumar Ghosh"], "https://doi.org/10.21437/Interspeech.2018-1862", 5, "interspeech", 2018]], "Hideki Kawahara": [0, ["Frequency Domain Variants of Velvet Noise and Their Application to Speech Processing and Synthesis", ["Hideki Kawahara", "Ken-Ichi Sakakibara", "Masanori Morise", "Hideki Banno", "Tomoki Toda", "Toshio Irino"], "https://doi.org/10.21437/Interspeech.2018-43", 5, "interspeech", 2018]], "Nelson Enrique Yalta Soplin": [0, ["ESPnet: End-to-End Speech Processing Toolkit", ["Shinji Watanabe", "Takaaki Hori", "Shigeki Karita", "Tomoki Hayashi", "Jiro Nishitoba", "Yuya Unno", "Nelson Enrique Yalta Soplin", "Jahn Heymann", "Matthew Wiesner", "Nanxin Chen", "Adithya Renduchintala", "Tsubasa Ochiai"], "https://doi.org/10.21437/Interspeech.2018-1456", 5, "interspeech", 2018]], "Anton Bakhtin": [0, ["Dictionary Augmented Sequence-to-Sequence Neural Network for Grapheme to Phoneme Prediction", ["Antoine Bruguier", "Anton Bakhtin", "Dravyansh Sharma"], "https://doi.org/10.21437/Interspeech.2018-2061", 5, "interspeech", 2018]], "Thomas Schatz": [0, ["Sampling Strategies in Siamese Networks for Unsupervised Speech Representation Learning", ["Rachid Riad", "Corentin Dancette", "Julien Karadayi", "Neil Zeghidour", "Thomas Schatz", "Emmanuel Dupoux"], "https://doi.org/10.21437/Interspeech.2018-2384", 5, "interspeech", 2018]], "Chirag Singh": [0, ["Speech Emotion Recognition Using Spectrogram & Phoneme Embedding", ["Promod Yenigalla", "Abhay Kumar", "Suraj Tripathi", "Chirag Singh", "Sibsambhu Kar", "Jithendra Vepa"], "https://doi.org/10.21437/Interspeech.2018-1811", 5, "interspeech", 2018]], "Mehmet Ali Tugtekin Turan": [0, ["Monitoring Infant's Emotional Cry in Domestic Environments Using the Capsule Network Architecture", ["Mehmet Ali Tugtekin Turan", "Engin Erzin"], "https://doi.org/10.21437/Interspeech.2018-2187", 5, "interspeech", 2018]], "Gurunath Reddy M.": [0, ["Harmonic-Percussive Source Separation of Polyphonic Music by Suppressing Impulsive Noise Events", ["Gurunath Reddy M.", "K. Sreenivasa Rao", "Partha Pratim Das"], "https://doi.org/10.21437/Interspeech.2018-1310", 5, "interspeech", 2018]], "Vikram Ramanarayanan": [0, ["Game-based Spoken Dialog Language Learning Applications for Young Students", ["Keelan Evanini", "Veronika Timpe-Laughlin", "Eugene Tsuprun", "Ian Blood", "Jeremy Lee", "James V. Bruno", "Vikram Ramanarayanan", "Patrick L. Lange", "David Suendermann-Oeft"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3045.html", 2, "interspeech", 2018], ["FACTS: A Hierarchical Task-based Control Model of Speech Incorporating Sensory Feedback", ["Benjamin Parrell", "Vikram Ramanarayanan", "Srikantan S. Nagarajan", "John F. Houde"], "https://doi.org/10.21437/Interspeech.2018-2087", 5, "interspeech", 2018], ["Toward Scalable Dialog Technology for Conversational Language Learning: Case Study of the TOEFL\u00ae MOOC", ["Vikram Ramanarayanan", "David Pautler", "Patrick L. Lange", "Eugene Tsuprun", "Rutuja Ubale", "Keelan Evanini", "David Suendermann-Oeft"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3032.html", 2, "interspeech", 2018], ["Improvements to an Automated Content Scoring System for Spoken CALL Responses: the ETS Submission to the Second Spoken CALL Shared Task", ["Keelan Evanini", "Matthew Mulholland", "Rutuja Ubale", "Yao Qian", "Robert A. Pugh", "Vikram Ramanarayanan", "Aoife Cahill"], "https://doi.org/10.21437/Interspeech.2018-2362", 5, "interspeech", 2018]], "Andrew Zisserman": [0, ["VoxCeleb2: Deep Speaker Recognition", ["Joon Son Chung", "Arsha Nagrani", "Andrew Zisserman"], "https://doi.org/10.21437/Interspeech.2018-1929", 5, "interspeech", 2018], ["The Conversation: Deep Audio-Visual Speech Enhancement", ["Triantafyllos Afouras", "Joon Son Chung", "Andrew Zisserman"], "https://doi.org/10.21437/Interspeech.2018-1400", 5, "interspeech", 2018], ["Deep Lip Reading: A Comparison of Models and an Online Application", ["Triantafyllos Afouras", "Joon Son Chung", "Andrew Zisserman"], "https://doi.org/10.21437/Interspeech.2018-1943", 5, "interspeech", 2018]], "Gabriel Mittag": [0, ["Detecting Packet-Loss Concealment Using Formant Features and Decision Tree Learning", ["Gabriel Mittag", "Sebastian Moller"], "https://doi.org/10.21437/Interspeech.2018-1098", 5, "interspeech", 2018]], "B. H. V. S. Narayanamurthy": [0, ["Determining Speaker Location from Speech in a Practical Environment", ["B. H. V. S. Narayanamurthy", "J. V. Satyanarayana", "Bayya Yegnanarayana"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3042.html", 2, "interspeech", 2018]], "Walter Chang": [1.2626319260966579e-11, ["A Framework for Speech Recognition Benchmarking", ["Franck Dernoncourt", "Trung Bui", "Walter Chang"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3003.html", 2, "interspeech", 2018]], "Hansjorg Mixdorff": [0, ["Cross-cultural (A)symmetries in Audio-visual Attitude Perception", ["Hansjorg Mixdorff", "Albert Rilliard", "Tan Lee", "Matthew K. H. Ma", "Angelika Honemann"], "https://doi.org/10.21437/Interspeech.2018-1373", 5, "interspeech", 2018]], "Alexandre Berard": [0, ["Unsupervised Word Segmentation from Speech with Attention", ["Pierre Godard", "Marcely Zanon Boito", "Lucas Ondel", "Alexandre Berard", "Francois Yvon", "Aline Villavicencio", "Laurent Besacier"], "https://doi.org/10.21437/Interspeech.2018-1308", 5, "interspeech", 2018]], "Ngoc-Quan Pham": [0, ["Low-Latency Neural Speech Translation", ["Jan Niehues", "Ngoc-Quan Pham", "Thanh-Le Ha", "Matthias Sperber", "Alex Waibel"], "https://doi.org/10.21437/Interspeech.2018-1055", 5, "interspeech", 2018]], "Ming-Hsiang Su": [0, ["Follow-up Question Generation Using Pattern-based Seq2seq with a Small Corpus for Interview Coaching", ["Ming-Hsiang Su", "Chung-Hsien Wu", "Kun-Yi Huang", "Qian-Bei Hong", "Huai-Hung Huang"], "https://doi.org/10.21437/Interspeech.2018-1007", 5, "interspeech", 2018]], "Moez Ajili": [0, ["Voice Comparison and Rhythm: Behavioral Differences between Target and Non-target Comparisons", ["Moez Ajili", "Jean-Francois Bonastre", "Solange Rossato"], "https://doi.org/10.21437/Interspeech.2018-61", 5, "interspeech", 2018]], "Xiao Zhou": [0, ["Learning and Modeling Unit Embeddings for Improving HMM-based Unit Selection Speech Synthesis", ["Xiao Zhou", "Zhen-Hua Ling", "Zhi-Ping Zhou", "Li-Rong Dai"], "https://doi.org/10.21437/Interspeech.2018-1198", 5, "interspeech", 2018]], "Thomas Hueber": [0, ["Visual Recognition of Continuous Cued Speech Using a Tandem CNN-HMM Approach", ["Li Liu", "Thomas Hueber", "Gang Feng", "Denis Beautemps"], "https://doi.org/10.21437/Interspeech.2018-2434", 5, "interspeech", 2018]], "Masanori Morise": [0, ["Frequency Domain Variants of Velvet Noise and Their Application to Speech Processing and Synthesis", ["Hideki Kawahara", "Ken-Ichi Sakakibara", "Masanori Morise", "Hideki Banno", "Tomoki Toda", "Toshio Irino"], "https://doi.org/10.21437/Interspeech.2018-43", 5, "interspeech", 2018]], "Qinglin Meng": [0, ["Weighting Pitch Contour and Loudness Contour in Mandarin Tone Perception in Cochlear Implant Listeners", ["Qinglin Meng", "Nengheng Zheng", "Ambika Prasad Mishra", "Jacinta Dan Luo", "Jan W. H. Schnupp"], "https://doi.org/10.21437/Interspeech.2018-1245", 4, "interspeech", 2018]], "Johannes Fischer": [0, ["Dithered Quantization for Frequency-Domain Speech and Audio Coding", ["Tom Backstrom", "Johannes Fischer", "Sneha Das"], "https://doi.org/10.21437/Interspeech.2018-46", 5, "interspeech", 2018]], "Yongbin You": [0, ["Knowledge Distillation for Sequence Model", ["Mingkun Huang", "Yongbin You", "Zhehuai Chen", "Yanmin Qian", "Kai Yu"], "https://doi.org/10.21437/Interspeech.2018-1589", 5, "interspeech", 2018]], "Nathan Bodenstab": [0, ["Efficient Language Model Adaptation with Noise Contrastive Estimation and Kullback-Leibler Regularization", ["Jesus Andres-Ferrer", "Nathan Bodenstab", "Paul Vozila"], "https://doi.org/10.21437/Interspeech.2018-1345", 5, "interspeech", 2018]], "Yujiang Li": [0, ["Cross-Lingual Multi-Task Neural Architecture for Spoken Language Understanding", ["Yujiang Li", "Xuemin Zhao", "Weiqun Xu", "Yonghong Yan"], "https://doi.org/10.21437/Interspeech.2018-1039", 5, "interspeech", 2018]], "Craig S. Greenberg": [0, ["Performance Analysis of the 2017 NIST Language Recognition Evaluation", ["Seyed Omid Sadjadi", "Timothee Kheyrkhah", "Craig S. Greenberg", "Elliot Singer", "Douglas A. Reynolds", "Lisa P. Mason", "Jaime Hernandez-Cordero"], "https://doi.org/10.21437/Interspeech.2018-69", 5, "interspeech", 2018]], "Joseph Moran": [0, ["Attention-based Sequence Classification for Affect Detection", ["Cristina Gorrostieta", "Richard Brutti", "Kye Taylor", "Avi Shapiro", "Joseph Moran", "Ali Azarbayejani", "John Kane"], "https://doi.org/10.21437/Interspeech.2018-1610", 5, "interspeech", 2018]], "Nancy McElwain": [0, ["Infant Emotional Outbursts Detection in Infant-parent Spoken Interactions", ["Yijia Xu", "Mark Hasegawa-Johnson", "Nancy McElwain"], "https://doi.org/10.21437/Interspeech.2018-2429", 5, "interspeech", 2018]], "Abhishek Dey": [0, ["Robust Mizo Continuous Speech Recognition", ["Abhishek Dey", "Biswajit Dev Sarma", "Wendy Lalhminghlui", "Lalnunsiami Ngente", "Parismita Gogoi", "Priyankoo Sarmah", "S. R. Mahadeva Prasanna", "Rohit Sinha", "S. R. Nirmala"], "https://doi.org/10.21437/Interspeech.2018-2125", 5, "interspeech", 2018], ["AGROASSAM: A Web Based Assamese Speech Recognition Application for Retrieving Agricultural Commodity Price and Weather Information", ["Abhishek Dey", "Abhash Deka", "Siddika Imani", "Barsha Deka", "Rohit Sinha", "S. R. Mahadeva Prasanna", "Priyankoo Sarmah", "K. Samudravijaya", "S. R. Nirmala"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3048.html", 2, "interspeech", 2018]], "Kun Li": [0, ["Unsupervised Discovery of Non-native Phonetic Patterns in L2 English Speech for Mispronunciation Detection and Diagnosis", ["Xu Li", "Shaoguang Mao", "Xixin Wu", "Kun Li", "Xunying Liu", "Helen Meng"], "https://doi.org/10.21437/Interspeech.2018-2027", 5, "interspeech", 2018]], "Mittul Singh": [0, ["Iterative Learning of Speech Recognition Models for Air Traffic Control", ["Ajay Srinivasamurthy", "Petr Motlicek", "Mittul Singh", "Youssef Oualil", "Matthias Kleinert", "Heiko Ehr", "Hartmut Helmke"], "https://doi.org/10.21437/Interspeech.2018-1447", 5, "interspeech", 2018]], "Diksha Chhabra": [0, ["DA-IICT/IIITV System for Low Resource Speech Recognition Challenge 2018", ["Hardik B. Sailor", "Maddala Venkata Siva Krishna", "Diksha Chhabra", "Ankur T. Patil", "Madhu R. Kamble", "Hemant A. Patil"], "https://doi.org/10.21437/Interspeech.2018-1553", 5, "interspeech", 2018]], "Stefan Steidl": [0, ["The INTERSPEECH 2018 Computational Paralinguistics Challenge: Atypical & Self-Assessed Affect, Crying & Heart Beats", ["Bjorn W. Schuller", "Stefan Steidl", "Anton Batliner", "Peter B. Marschik", "Harald Baumeister", "Fengquan Dong", "Simone Hantke", "Florian B. Pokorny", "Eva-Maria Rathner", "Katrin D. Bartl-Pokorny", "Christa Einspieler", "Dajie Zhang", "Alice Baird", "Shahin Amiriparian", "Kun Qian", "Zhao Ren", "Maximilian Schmitt", "Panagiotis Tzirakis", "Stefanos Zafeiriou"], "https://doi.org/10.21437/Interspeech.2018-51", 5, "interspeech", 2018]], "Istvan Szendi": [0, ["Identifying Schizophrenia Based on Temporal Parameters in Spontaneous Speech", ["Gabor Gosztolya", "Anita Bagi", "Szilvia Szaloki", "Istvan Szendi", "Ildiko Hoffmann"], "https://doi.org/10.21437/Interspeech.2018-1079", 5, "interspeech", 2018]], "Rajath Kumar": [0, ["Music Source Activity Detection and Separation Using Deep Attractor Network", ["Rajath Kumar", "Yi Luo", "Nima Mesgarani"], "https://doi.org/10.21437/Interspeech.2018-2326", 5, "interspeech", 2018], ["On Convolutional LSTM Modeling for Joint Wake-Word Detection and Text Dependent Speaker Verification", ["Rajath Kumar", "Vaishnavi Yeruva", "Sriram Ganapathy"], "https://doi.org/10.21437/Interspeech.2018-1759", 5, "interspeech", 2018]], "Hao-Chun Yang": [0.03243382181972265, ["Automatic Assessment of Individual Culture Attribute of Power Distance Using a Social Context-Enhanced Prosodic Network Representation", ["Fu-Sheng Tsai", "Hao-Chun Yang", "Wei-Wen Chang", "Chi-Chun Lee"], "https://doi.org/10.21437/Interspeech.2018-1523", 5, "interspeech", 2018]], "Hong-Goo Kang": [1, ["A Unified Framework for the Generation of Glottal Signals in Deep Learning-based Parametric Speech Synthesis Systems", ["Min-Jae Hwang", "Eunwoo Song", "Jin-Seob Kim", "Hong-Goo Kang"], "https://doi.org/10.21437/Interspeech.2018-1590", 5, "interspeech", 2018]], "Jordan R. Green": [0, ["Automatic Detection of Orofacial Impairment in Stroke", ["Andrea Bandini", "Jordan R. Green", "Brian Richburg", "Yana Yunusova"], "https://doi.org/10.21437/Interspeech.2018-2475", 5, "interspeech", 2018], ["Automatic Early Detection of Amyotrophic Lateral Sclerosis from Intelligible Speech Using Convolutional Neural Networks", ["Kwanghoon An", "Myung Jong Kim", "Kristin Teplansky", "Jordan R. Green", "Thomas Campbell", "Yana Yunusova", "Daragh Heitzman", "Jun Wang"], "https://doi.org/10.21437/Interspeech.2018-2496", 5, "interspeech", 2018]], "Lei Wang": [0.001596404705196619, ["Wuxi Speakers' Production and Perception of Coda Nasals in Mandarin", ["Lei Wang", "Jie Cui", "Ying Chen"], "https://doi.org/10.21437/Interspeech.2018-2224", 4, "interspeech", 2018]], "Tuka Al Hanai": [0, ["Detecting Depression with Audio/Text Sequence Modeling of Interviews", ["Tuka Al Hanai", "Mohammad M. Ghassemi", "James R. Glass"], "https://doi.org/10.21437/Interspeech.2018-2522", 5, "interspeech", 2018]], "Yosuke Kobayashi": [0, ["Binaural Speech Intelligibility Estimation Using Deep Neural Networks", ["Kazuhiro Kondo", "Kazuya Taira", "Yosuke Kobayashi"], "https://doi.org/10.21437/Interspeech.2018-27", 5, "interspeech", 2018]], "Avi Shapiro": [0, ["Attention-based Sequence Classification for Affect Detection", ["Cristina Gorrostieta", "Richard Brutti", "Kye Taylor", "Avi Shapiro", "Joseph Moran", "Ali Azarbayejani", "John Kane"], "https://doi.org/10.21437/Interspeech.2018-1610", 5, "interspeech", 2018]], "Diego Castan": [0, ["Analysis of Complementary Information Sources in the Speaker Embeddings Framework", ["Mahesh Kumar Nandwana", "Mitchell McLaren", "Diego Castan", "Julien van Hout", "Aaron Lawson"], "https://doi.org/10.21437/Interspeech.2018-1102", 5, "interspeech", 2018]], "Mandar Gogate": [0, ["DNN Driven Speaker Independent Audio-Visual Mask Estimation for Speech Separation", ["Mandar Gogate", "Ahsan Adeel", "Ricard Marxer", "Jon Barker", "Amir Hussain"], "https://doi.org/10.21437/Interspeech.2018-2516", 5, "interspeech", 2018]], "Jayaraman J. Thiagarajan": [0, ["Triplet Network with Attention for Speaker Diarization", ["Huan Song", "Megan M. Willi", "Jayaraman J. Thiagarajan", "Visar Berisha", "Andreas Spanias"], "https://doi.org/10.21437/Interspeech.2018-2305", 5, "interspeech", 2018]], "Slava Shechtman": [0, ["The IBM Virtual Voice Creator", ["Alexander Sorin", "Slava Shechtman", "Zvi Kons", "Ron Hoory", "Shay Ben-David", "Joe Pavitt", "Shai Rozenberg", "Carmel Rabinovitz", "Tal Drory"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3011.html", 2, "interspeech", 2018], ["Word Emphasis Prediction for Expressive Text to Speech", ["Yosi Mass", "Slava Shechtman", "Moran Mordechay", "Ron Hoory", "Oren Sar Shalom", "Guy Lev", "David Konopnicki"], "https://doi.org/10.21437/Interspeech.2018-1159", 5, "interspeech", 2018]], "Georg Stemmer": [0, ["Speaker Adaptive Audio-Visual Fusion for the Open-Vocabulary Section of AVICAR", ["Leda Sari", "Mark Hasegawa-Johnson", "Kumaran S", "Georg Stemmer", "Krishnakumar N. Nair"], "https://doi.org/10.21437/Interspeech.2018-2359", 5, "interspeech", 2018]], "Victor Soto": [0, ["The Role of Cognate Words, POS Tags and Entrainment in Code-Switching", ["Victor Soto", "Nishmar Cestero", "Julia Hirschberg"], "https://doi.org/10.21437/Interspeech.2018-1099", 5, "interspeech", 2018]], "Pallavi Baljekar": [0, ["An Investigation of Convolution Attention Based Models for Multilingual Speech Synthesis of Indian Languages", ["Pallavi Baljekar", "Sai Krishna Rallabandi", "Alan W. Black"], "https://doi.org/10.21437/Interspeech.2018-1869", 5, "interspeech", 2018]], "Frank K. Soong": [0, ["Paired Phone-Posteriors Approach to ESL Pronunciation Quality Assessment", ["Yujia Xiao", "Frank K. Soong", "Wenping Hu"], "https://doi.org/10.21437/Interspeech.2018-1270", 5, "interspeech", 2018], ["A New Glottal Neural Vocoder for Speech Synthesis", ["Yang Cui", "Xi Wang", "Lei He", "Frank K. Soong"], "https://doi.org/10.21437/Interspeech.2018-1757", 5, "interspeech", 2018]], "Wei-Ping Zhu": [0, ["A Deep Neural Network Based Harmonic Noise Model for Speech Enhancement", ["Zhiheng Ouyang", "Hongjiang Yu", "Wei-Ping Zhu", "Benoit Champagne"], "https://doi.org/10.21437/Interspeech.2018-1114", 5, "interspeech", 2018]], "Ina Kodrasi": [0, ["Single-channel Late Reverberation Power Spectral Density Estimation Using Denoising Autoencoders", ["Ina Kodrasi", "Herve Bourlard"], "https://doi.org/10.21437/Interspeech.2018-1660", 5, "interspeech", 2018]], "Buddhi Wickramasinghe": [0, ["Detection of Replay-Spoofing Attacks Using Frequency Modulation Features", ["Tharshini Gunendradasan", "Buddhi Wickramasinghe", "Phu Ngoc Le", "Eliathamby Ambikairajah", "Julien Epps"], "https://doi.org/10.21437/Interspeech.2018-1473", 5, "interspeech", 2018], ["Frequency Domain Linear Prediction Features for Replay Spoofing Attack Detection", ["Buddhi Wickramasinghe", "Saad Irtza", "Eliathamby Ambikairajah", "Julien Epps"], "https://doi.org/10.21437/Interspeech.2018-1574", 5, "interspeech", 2018]], "Gregory P. Finley": [0, ["An Automated Assistant for Medical Scribes", ["Gregory P. Finley", "Erik Edwards", "Amanda Robinson", "Najmeh Sadoughi", "James Fone", "Mark Miller", "David Suendermann-Oeft", "Michael Brenndoerfer", "Nico Axtmann"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3047.html", 2, "interspeech", 2018]], "Yulia Zhukova": [0, ["LOCUST - Longitudinal Corpus and Toolset for Speaker Verification", ["Evgeny Dmitriev", "Yulia Kim", "Anastasia Matveeva", "Claude Montacie", "Yannick Boulard", "Yadviga Sinyavskaya", "Yulia Zhukova", "Adam Zarazinski", "Egor Akhanov", "Ilya I. Viksnin", "Andrei A. Shlykov", "Maria Usova"], "https://doi.org/10.21437/Interspeech.2018-2412", 5, "interspeech", 2018]], "Youngmoon Jung": [0.9995688796043396, ["Joint Learning Using Denoising Variational Autoencoders for Voice Activity Detection", ["Youngmoon Jung", "Younggwan Kim", "Yeunju Choi", "Hoirin Kim"], "https://doi.org/10.21437/Interspeech.2018-1151", 5, "interspeech", 2018]], "Michael Levit": [0, ["What to Expect from Expected Kneser-Ney Smoothing", ["Michael Levit", "Sarangarajan Parthasarathy", "Shuangyu Chang"], "https://doi.org/10.21437/Interspeech.2018-84", 5, "interspeech", 2018]], "Namita Jacob": [0, ["Early Vocabulary Development Through Picture-based Software Solutions", ["G. R. Kasthuri", "Prabha Ramanathan", "Hema A. Murthy", "Namita Jacob", "Anil Prabhakar"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3022.html", 2, "interspeech", 2018]], "Daniel Blackburn": [0, ["Detecting Signs of Dementia Using Word Vector Representations", ["Bahman Mirheidari", "Daniel Blackburn", "Traci Walker", "Annalena Venneri", "Markus Reuber", "Heidi Christensen"], "https://doi.org/10.21437/Interspeech.2018-1764", 5, "interspeech", 2018]], "Rui Wang": [0.035276773385703564, ["Visual Timing Information in Audiovisual Speech Perception: Evidence from Lexical Tone Contour", ["Hui Xie", "Biao Zeng", "Rui Wang"], "https://doi.org/10.21437/Interspeech.2018-1285", 5, "interspeech", 2018]], "Gregory Sell": [0, ["Diarization is Hard: Some Experiences and Lessons Learned for the JHU Team in the Inaugural DIHARD Challenge", ["Gregory Sell", "David Snyder", "Alan McCree", "Daniel Garcia-Romero", "Jesus Villalba", "Matthew Maciejewski", "Vimal Manohar", "Najim Dehak", "Daniel Povey", "Shinji Watanabe", "Sanjeev Khudanpur"], "https://doi.org/10.21437/Interspeech.2018-1893", 5, "interspeech", 2018]], "Yi-Ming Weng": [0, ["Learning Conditional Acoustic Latent Representation with Gender and Age Attributes for Automatic Pain Level Recognition", ["Jeng-Lin Li", "Yi-Ming Weng", "Chip-Jin Ng", "Chi-Chun Lee"], "https://doi.org/10.21437/Interspeech.2018-1298", 5, "interspeech", 2018]], "Rachel E. Bouserhal": [0, ["Classification of Nonverbal Human Produced Audio Events: A Pilot Study", ["Rachel E. Bouserhal", "Philippe Chabot", "Milton Sarria Paja", "Patrick Cardinal", "Jeremie Voix"], "https://doi.org/10.21437/Interspeech.2018-2299", 5, "interspeech", 2018]], "Jennifer McGlothlin": [0, ["Fusing Text-dependent Word-level i-Vector Models to Screen 'at Risk' Child Speech", ["Prasanna V. Kothalkar", "Johanna Rudolph", "Christine Dollaghan", "Jennifer McGlothlin", "Thomas F. Campbell", "John H. L. Hansen"], "https://doi.org/10.21437/Interspeech.2018-1465", 5, "interspeech", 2018]], "R. Harald Baayen": [0, ["Wide Learning for Auditory Comprehension", ["Elnaz Shafaei-Bajestan", "R. Harald Baayen"], "https://doi.org/10.21437/Interspeech.2018-2420", 5, "interspeech", 2018]], "Jacqueline Serigos": [0, ["Should Code-switching Models Be Asymmetric?", ["Barbara E. Bullock", "Gualberto A. Guzman", "Jacqueline Serigos", "Almeida Jacqueline Toribio"], "https://doi.org/10.21437/Interspeech.2018-1284", 5, "interspeech", 2018]], "Shrikanth Narayanan": [0, ["Improving Gender Identification in Movie Audio Using Cross-Domain Data", ["Rajat Hebbar", "Krishna Somandepalli", "Shrikanth Narayanan"], "https://doi.org/10.21437/Interspeech.2018-1462", 5, "interspeech", 2018], ["Denoising and Raw-waveform Networks for Weakly-Supervised Gender Identification on Noisy Speech", ["Jilt Sebastian", "Manoj Kumar", "Pavan Kumar D. S.", "Mathew Magimai-Doss", "Hema A. Murthy", "Shrikanth Narayanan"], "https://doi.org/10.21437/Interspeech.2018-2321", 5, "interspeech", 2018], ["Exploring the Relationship between Conic Affinity of NMF Dictionaries and Speech Enhancement Metrics", ["Pavlos Papadopoulos", "Colin Vaz", "Shrikanth Narayanan"], "https://doi.org/10.21437/Interspeech.2018-1387", 5, "interspeech", 2018], ["Combined Speaker Clustering and Role Recognition in Conversational Speech", ["Nikolaos Flemotomos", "Pavlos Papadopoulos", "James Gibson", "Shrikanth Narayanan"], "https://doi.org/10.21437/Interspeech.2018-1654", 5, "interspeech", 2018], ["Language Features for Automated Evaluation of Cognitive Behavior Psychotherapy Sessions", ["Nikolaos Flemotomos", "Victor R. Martinez", "James Gibson", "David C. Atkins", "Torrey Creed", "Shrikanth Narayanan"], "https://doi.org/10.21437/Interspeech.2018-1518", 5, "interspeech", 2018], ["Computational Modeling of Conversational Humor in Psychotherapy", ["Anil Ramakrishna", "Timothy Greer", "David C. Atkins", "Shrikanth Narayanan"], "https://doi.org/10.21437/Interspeech.2018-1583", 5, "interspeech", 2018], ["A Knowledge Driven Structural Segmentation Approach for Play-Talk Classification During Autism Assessment", ["Manoj Kumar", "Pooja Chebolu", "So Hyun Kim", "Kassandra Martinez", "Catherine Lord", "Shrikanth Narayanan"], "https://doi.org/10.21437/Interspeech.2018-1516", 5, "interspeech", 2018], ["Using Prosodic and Lexical Information for Learning Utterance-level Behaviors in Psychotherapy", ["Karan Singla", "Zhuohao Chen", "Nikolaos Flemotomos", "James Gibson", "Dogan Can", "David C. Atkins", "Shrikanth Narayanan"], "https://doi.org/10.21437/Interspeech.2018-2551", 5, "interspeech", 2018], ["Towards an Unsupervised Entrainment Distance in Conversational Speech Using Deep Neural Networks", ["Md. Nasir", "Brian R. Baucom", "Shrikanth Narayanan", "Panayiotis G. Georgiou"], "https://doi.org/10.21437/Interspeech.2018-1395", 5, "interspeech", 2018], ["Stochastic Shake-Shake Regularization for Affective Learning from Speech", ["Che-Wei Huang", "Shrikanth Narayanan"], "https://doi.org/10.21437/Interspeech.2018-1327", 5, "interspeech", 2018]], "Chellu Chandra Sekhar": [0, ["Information Bottleneck Based Percussion Instrument Diarization System for Taniavartanam Segments of Carnatic Music Concerts", ["Nauman Dawalatabad", "Jom Kuriakose", "Chellu Chandra Sekhar", "Hema A. Murthy"], "https://doi.org/10.21437/Interspeech.2018-1203", 5, "interspeech", 2018]], "Junichi Yamagishi": [0, ["Investigating Accuracy of Pitch-accent Annotations in Neural Network-based Speech Synthesis and Denoising Effects", ["Hieu-Thi Luong", "Xin Wang", "Junichi Yamagishi", "Nobuyuki Nishizawa"], "https://doi.org/10.21437/Interspeech.2018-1227", 5, "interspeech", 2018], ["Integrated Presentation Attack Detection and Automatic Speaker Verification: Common Features and Gaussian Back-end Fusion", ["Massimiliano Todisco", "Hector Delgado", "Kong-Aik Lee", "Md. Sahidullah", "Nicholas W. D. Evans", "Tomi Kinnunen", "Junichi Yamagishi"], "https://doi.org/10.21437/Interspeech.2018-2289", 5, "interspeech", 2018], ["Speaker-independent Raw Waveform Model for Glottal Excitation", ["Lauri Juvela", "Vassilis Tsiaras", "Bajibabu Bollepalli", "Manu Airaksinen", "Junichi Yamagishi", "Paavo Alku"], "https://doi.org/10.21437/Interspeech.2018-1635", 5, "interspeech", 2018], ["Multimodal Speech Synthesis Architecture for Unsupervised Speaker Adaptation", ["Hieu-Thi Luong", "Junichi Yamagishi"], "https://doi.org/10.21437/Interspeech.2018-1791", 5, "interspeech", 2018], ["Expressive Speech Synthesis Using Sentiment Embeddings", ["Igor Jauk", "Jaime Lorenzo-Trueba", "Junichi Yamagishi", "Antonio Bonafonte"], "https://doi.org/10.21437/Interspeech.2018-2467", 5, "interspeech", 2018]], "Selen Hande Kabil": [0, ["On Learning to Identify Genders from Raw Speech Signal Using CNNs", ["Selen Hande Kabil", "Hannah Muckenhirn", "Mathew Magimai-Doss"], "https://doi.org/10.21437/Interspeech.2018-1240", 5, "interspeech", 2018]], "Keiko Ochi": [0, ["Automatic Evaluation of Soft Articulatory Contact for Stuttering Treatment", ["Keiko Ochi", "Koichi Mori", "Naomi Sakai"], "https://doi.org/10.21437/Interspeech.2018-2544", 5, "interspeech", 2018], ["Respiratory and Respiratory Muscular Control in JL1's and JL2's Text Reading Utilizing 4-RSTs and a Soft Respiratory Mask with a Two-Way Bulb", ["Toshiko Isei-Jaakkola", "Keiko Ochi", "Keikichi Hirose"], "https://doi.org/10.21437/Interspeech.2018-1948", 5, "interspeech", 2018]], "Wenping Hu": [0, ["Paired Phone-Posteriors Approach to ESL Pronunciation Quality Assessment", ["Yujia Xiao", "Frank K. Soong", "Wenping Hu"], "https://doi.org/10.21437/Interspeech.2018-1270", 5, "interspeech", 2018]], "Alice Tomassini": [0, ["Analyzing Vocal Tract Movements During Speech Accommodation", ["Sankar Mukherjee", "Thierry Legou", "Leonardo Lancia", "Pauline Hilt", "Alice Tomassini", "Luciano Fadiga", "Alessandro DAusilio", "Leonardo Badino", "Noel Nguyen"], "https://doi.org/10.21437/Interspeech.2018-2084", 5, "interspeech", 2018]], "Michael Brenndoerfer": [0, ["An Automated Assistant for Medical Scribes", ["Gregory P. Finley", "Erik Edwards", "Amanda Robinson", "Najmeh Sadoughi", "James Fone", "Mark Miller", "David Suendermann-Oeft", "Michael Brenndoerfer", "Nico Axtmann"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3047.html", 2, "interspeech", 2018]], "Aciel Eshky": [0, ["UltraSuite: A Repository of Ultrasound and Acoustic Data from Child Speech Therapy Sessions", ["Aciel Eshky", "Manuel Sam Ribeiro", "Joanne Cleland", "Korin Richmond", "Zoe Roxburgh", "James M. Scobbie", "Alan Wrench"], "https://doi.org/10.21437/Interspeech.2018-1736", 5, "interspeech", 2018]], "Xingfeng Li": [0, ["A Three-Layer Emotion Perception Model for Valence and Arousal-Based Detection from Multilingual Speech", ["Xingfeng Li", "Masato Akagi"], "https://doi.org/10.21437/Interspeech.2018-1820", 5, "interspeech", 2018]], "Kristin Heaton": [0, ["The Effect of Exposure to High Altitude and Heat on Speech Articulatory Coordination", ["James R. Williamson", "Thomas F. Quatieri", "Adam C. Lammert", "Katherine Mitchell", "Katherine Finkelstein", "Nicole Ekon", "Caitlin Dillon", "Robert Kenefick", "Kristin Heaton"], "https://doi.org/10.21437/Interspeech.2018-2372", 5, "interspeech", 2018], ["Vocal Biomarkers for Cognitive Performance Estimation in a Working Memory Task", ["Jennifer Sloboda", "Adam C. Lammert", "James R. Williamson", "Christopher J. Smalt", "Daryush D. Mehta", "C. O. L. Ian Curry", "Kristin Heaton", "Jeff Palmer", "Thomas F. Quatieri"], "https://doi.org/10.21437/Interspeech.2018-2418", 5, "interspeech", 2018]], "Ruhi Sarikaya": [0, ["Contextual Slot Carryover for Disparate Schemas", ["Chetan Naik", "Arpit Gupta", "Hancheng Ge", "Lambert Mathias", "Ruhi Sarikaya"], "https://doi.org/10.21437/Interspeech.2018-1035", 5, "interspeech", 2018]], "Markus Toman": [0, ["Data Requirements, Selection and Augmentation for DNN-based Speech Synthesis from Crowdsourced Data", ["Markus Toman", "Geoffrey S. Meltzner", "Rupal Patel"], "https://doi.org/10.21437/Interspeech.2018-1316", 5, "interspeech", 2018]], "Wenda Chen": [0, ["Topic and Keyword Identification for Low-resourced Speech Using Cross-Language Transfer Learning", ["Wenda Chen", "Mark Hasegawa-Johnson", "Nancy F. Chen"], "https://doi.org/10.21437/Interspeech.2018-1283", 5, "interspeech", 2018]], "Anne Hermes": [0, ["Structural Effects on Properties of Consonantal Gestures in Tashlhiyt", ["Anne Hermes", "Doris Mucke", "Bastian Auris", "Rachid Ridouane"], "https://doi.org/10.21437/Interspeech.2018-1074", 5, "interspeech", 2018], ["Age-related Effects on Sensorimotor Control of Speech Production", ["Anne Hermes", "Jane Mertens", "Doris Mucke"], "https://doi.org/10.21437/Interspeech.2018-1233", 5, "interspeech", 2018]], "Ferdinand Brasser": [0, ["VoiceGuard: Secure and Private Speech Processing", ["Ferdinand Brasser", "Tommaso Frassetto", "Korbinian Riedhammer", "Ahmad-Reza Sadeghi", "Thomas Schneider", "Christian Weinert"], "https://doi.org/10.21437/Interspeech.2018-2032", 5, "interspeech", 2018]], "Nidia Hernandez": [0, ["Exploring Temporal Reduction in Dialectal Spanish: A Large-scale Study of Lenition of Voiced Stops and Coda-s", ["Ioana Vasilescu", "Nidia Hernandez", "Bianca Vieru", "Lori Lamel"], "https://doi.org/10.21437/Interspeech.2018-1256", 5, "interspeech", 2018]], "Krishna Gurugubelli": [0, ["An Exploration towards Joint Acoustic Modeling for Indian Languages: IIIT-H Submission for Low Resource Speech Recognition Challenge for Indian Languages, INTERSPEECH 2018", ["Hari Krishna Vydana", "Krishna Gurugubelli", "Vishnu Vidyadhara Raju Vegesna", "Anil Kumar Vuppala"], "https://doi.org/10.21437/Interspeech.2018-1584", 5, "interspeech", 2018]], "Cornelius Weber": [0, ["Conversational Analysis Using Utterance-level Attention-based Bidirectional Recurrent Neural Networks", ["Chandrakant Bothe", "Sven Magg", "Cornelius Weber", "Stefan Wermter"], "https://doi.org/10.21437/Interspeech.2018-2527", 5, "interspeech", 2018]], "Hasim Sak": [0, ["Speech Recognition for Medical Conversations", ["Chung-Cheng Chiu", "Anshuman Tripathi", "Katherine Chou", "Chris Co", "Navdeep Jaitly", "Diana Jaunzeikare", "Anjuli Kannan", "Patrick Nguyen", "Hasim Sak", "Ananth Sankar", "Justin Tansuwan", "Nathan Wan", "Yonghui Wu", "Xuedong Zhang"], "https://doi.org/10.21437/Interspeech.2018-40", 5, "interspeech", 2018]], "Tomohiro Nakatani": [0, ["Multi-resolution Gammachirp Envelope Distortion Index for Intelligibility Prediction of Noisy Speech", ["Katsuhiko Yamamoto", "Toshio Irino", "Narumi Ohashi", "Shoko Araki", "Keisuke Kinoshita", "Tomohiro Nakatani"], "https://doi.org/10.21437/Interspeech.2018-1291", 5, "interspeech", 2018], ["Auxiliary Feature Based Adaptation of End-to-end ASR Systems", ["Marc Delcroix", "Shinji Watanabe", "Atsunori Ogawa", "Shigeki Karita", "Tomohiro Nakatani"], "https://doi.org/10.21437/Interspeech.2018-1438", 5, "interspeech", 2018], ["Integrating Neural Network Based Beamforming and Weighted Prediction Error Dereverberation", ["Lukas Drude", "Christoph Boddeker", "Jahn Heymann", "Reinhold Haeb-Umbach", "Keisuke Kinoshita", "Marc Delcroix", "Tomohiro Nakatani"], "https://doi.org/10.21437/Interspeech.2018-2196", 5, "interspeech", 2018]], "Biswajit Dev Sarma": [0, ["Robust Mizo Continuous Speech Recognition", ["Abhishek Dey", "Biswajit Dev Sarma", "Wendy Lalhminghlui", "Lalnunsiami Ngente", "Parismita Gogoi", "Priyankoo Sarmah", "S. R. Mahadeva Prasanna", "Rohit Sinha", "S. R. Nirmala"], "https://doi.org/10.21437/Interspeech.2018-2125", 5, "interspeech", 2018]], "Huan-Yu Chen": [0, ["Self-Assessed Affect Recognition Using Fusion of Attentional BLSTM and Static Acoustic Features", ["Bo-Hao Su", "Sung-Lin Yeh", "Ming-Ya Ko", "Huan-Yu Chen", "Shun-Chang Zhong", "Jeng-Lin Li", "Chi-Chun Lee"], "https://doi.org/10.21437/Interspeech.2018-2261", 5, "interspeech", 2018]], "Mallikarjuna Rao Bellamkonda": [0, ["HoloCompanion: An MR Friend for EveryOne", ["Annam Naresh", "Rushabh Gandhi", "Mallikarjuna Rao Bellamkonda", "Mithun Das Gupta"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3017.html", 2, "interspeech", 2018]], "Yao Qian": [0, ["Improvements to an Automated Content Scoring System for Spoken CALL Responses: the ETS Submission to the Second Spoken CALL Shared Task", ["Keelan Evanini", "Matthew Mulholland", "Rutuja Ubale", "Yao Qian", "Robert A. Pugh", "Vikram Ramanarayanan", "Aoife Cahill"], "https://doi.org/10.21437/Interspeech.2018-2362", 5, "interspeech", 2018]], "Joshua Penney": [0, ["Weighting of Coda Voicing Cues: Glottalisation and Vowel Duration", ["Joshua Penney", "Felicity Cox", "Anita Szakay"], "https://doi.org/10.21437/Interspeech.2018-1677", 5, "interspeech", 2018]], "Karan Singla": [0, ["Using Prosodic and Lexical Information for Learning Utterance-level Behaviors in Psychotherapy", ["Karan Singla", "Zhuohao Chen", "Nikolaos Flemotomos", "James Gibson", "Dogan Can", "David C. Atkins", "Shrikanth Narayanan"], "https://doi.org/10.21437/Interspeech.2018-2551", 5, "interspeech", 2018]], "Anna-Riikka Smolander": [0, ["Captaina: Integrated Pronunciation Practice and Data Collection Portal", ["Aku Rouhe", "Reima Karhila", "Aija Elg", "Minnaleena Toivola", "Peter Smit", "Anna-Riikka Smolander", "Mikko Kurimo"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3015.html", 2, "interspeech", 2018]], "Ruiqing Yin": [0, ["Neural Speech Turn Segmentation and Affinity Propagation for Speaker Diarization", ["Ruiqing Yin", "Herve Bredin", "Claude Barras"], "https://doi.org/10.21437/Interspeech.2018-1750", 5, "interspeech", 2018]], "David Suendermann-Oeft": [0, ["Game-based Spoken Dialog Language Learning Applications for Young Students", ["Keelan Evanini", "Veronika Timpe-Laughlin", "Eugene Tsuprun", "Ian Blood", "Jeremy Lee", "James V. Bruno", "Vikram Ramanarayanan", "Patrick L. Lange", "David Suendermann-Oeft"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3045.html", 2, "interspeech", 2018], ["Toward Scalable Dialog Technology for Conversational Language Learning: Case Study of the TOEFL\u00ae MOOC", ["Vikram Ramanarayanan", "David Pautler", "Patrick L. Lange", "Eugene Tsuprun", "Rutuja Ubale", "Keelan Evanini", "David Suendermann-Oeft"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3032.html", 2, "interspeech", 2018], ["An Automated Assistant for Medical Scribes", ["Gregory P. Finley", "Erik Edwards", "Amanda Robinson", "Najmeh Sadoughi", "James Fone", "Mark Miller", "David Suendermann-Oeft", "Michael Brenndoerfer", "Nico Axtmann"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3047.html", 2, "interspeech", 2018]], "Joanne Cleland": [0, ["UltraSuite: A Repository of Ultrasound and Acoustic Data from Child Speech Therapy Sessions", ["Aciel Eshky", "Manuel Sam Ribeiro", "Joanne Cleland", "Korin Richmond", "Zoe Roxburgh", "James M. Scobbie", "Alan Wrench"], "https://doi.org/10.21437/Interspeech.2018-1736", 5, "interspeech", 2018]], "Fernando Batista": [0, ["Acoustic-prosodic Entrainment in Structural Metadata Events", ["Vera Cabarrao", "Fernando Batista", "Helena Moniz", "Isabel Trancoso", "Ana Isabel Mata"], "https://doi.org/10.21437/Interspeech.2018-2366", 5, "interspeech", 2018]], "Elnaz Shafaei-Bajestan": [0, ["Wide Learning for Auditory Comprehension", ["Elnaz Shafaei-Bajestan", "R. Harald Baayen"], "https://doi.org/10.21437/Interspeech.2018-2420", 5, "interspeech", 2018]], "Philip Harrison": [0, ["The Individual and the System: Assessing the Stability of the Output of a Semi-automatic Forensic Voice Comparison System", ["Vincent Hughes", "Philip Harrison", "Paul Foulkes", "Peter French", "Colleen Kavanagh", "Eugenia San Segundo Fernandez"], "https://doi.org/10.21437/Interspeech.2018-1649", 5, "interspeech", 2018]], "Anurendra Kumar": [0, ["Monoaural Audio Source Separation Using Variational Autoencoders", ["Laxmi Pandey", "Anurendra Kumar", "Vinay Namboodiri"], "https://doi.org/10.21437/Interspeech.2018-1140", 5, "interspeech", 2018]], "Satoshi Tamura": [0, ["Audio-visual Voice Conversion Using Deep Canonical Correlation Analysis for Deep Bottleneck Features", ["Satoshi Tamura", "Kento Horio", "Hajime Endo", "Satoru Hayamizu", "Tomoki Toda"], "https://doi.org/10.21437/Interspeech.2018-2286", 5, "interspeech", 2018]], "Andreas Soeborg Kirkedal": [0, ["Multilingual Deep Neural Network Training Using Cyclical Learning Rate", ["Andreas Soeborg Kirkedal", "Yeon-Jun Kim"], "https://doi.org/10.21437/Interspeech.2018-1891", 5, "interspeech", 2018]], "K. Gopakumar": [0, ["Voice Analysis Using Acoustic and Throat Microphones for Speech Therapy", ["Lani Mathew", "K. Gopakumar"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3005.html", 2, "interspeech", 2018]], "Gabriel Synnaeve": [0, ["End-to-End Speech Recognition from the Raw Waveform", ["Neil Zeghidour", "Nicolas Usunier", "Gabriel Synnaeve", "Ronan Collobert", "Emmanuel Dupoux"], "https://doi.org/10.21437/Interspeech.2018-2414", 5, "interspeech", 2018]], "Thomas Zenkel": [0, ["Subword and Crossword Units for CTC Acoustic Models", ["Thomas Zenkel", "Ramon Sanabria", "Florian Metze", "Alex Waibel"], "https://doi.org/10.21437/Interspeech.2018-2057", 5, "interspeech", 2018], ["Term Extraction via Neural Sequence Labeling a Comparative Evaluation of Strategies Using Recurrent Neural Networks", ["Maren Kucza", "Jan Niehues", "Thomas Zenkel", "Alex Waibel", "Sebastian Stuker"], "https://doi.org/10.21437/Interspeech.2018-2017", 5, "interspeech", 2018]], "Xavier Serra": [0, ["Singing Voice Phoneme Segmentation by Hierarchically Inferring Syllable and Phoneme Onset Positions", ["Rong Gong", "Xavier Serra"], "https://doi.org/10.21437/Interspeech.2018-1224", 5, "interspeech", 2018]], "Cathy Chua": [0, ["Overview of the 2018 Spoken CALL Shared Task", ["Claudia Baur", "Andrew Caines", "Cathy Chua", "Johanna Gerlach", "Mengjie Qian", "Manny Rayner", "Martin J. Russell", "Helmer Strik", "Xizi Wei"], "https://doi.org/10.21437/Interspeech.2018-97", 5, "interspeech", 2018]], "Dajie Zhang": [0, ["The INTERSPEECH 2018 Computational Paralinguistics Challenge: Atypical & Self-Assessed Affect, Crying & Heart Beats", ["Bjorn W. Schuller", "Stefan Steidl", "Anton Batliner", "Peter B. Marschik", "Harald Baumeister", "Fengquan Dong", "Simone Hantke", "Florian B. Pokorny", "Eva-Maria Rathner", "Katrin D. Bartl-Pokorny", "Christa Einspieler", "Dajie Zhang", "Alice Baird", "Shahin Amiriparian", "Kun Qian", "Zhao Ren", "Maximilian Schmitt", "Panagiotis Tzirakis", "Stefanos Zafeiriou"], "https://doi.org/10.21437/Interspeech.2018-51", 5, "interspeech", 2018]], "Madhavaraj Ayyavu": [0, ["Online Speech Translation System for Tamil", ["Madhavaraj Ayyavu", "Shiva Kumar H. R", "Ramakrishnan A. G"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3035.html", 2, "interspeech", 2018]], "Wei Chen": [0, ["Extending Recurrent Neural Aligner for Streaming End-to-End Speech Recognition in Mandarin", ["Linhao Dong", "Shiyu Zhou", "Wei Chen", "Bo Xu"], "https://doi.org/10.21437/Interspeech.2018-1086", 5, "interspeech", 2018]], "Matthew Perez": [0, ["Classification of Huntington Disease Using Acoustic and Lexical Features", ["Matthew Perez", "Wenyu Jin", "Duc Le", "Noelle Carlozzi", "Praveen Dayalu", "Angela Roberts", "Emily Mower Provost"], "https://doi.org/10.21437/Interspeech.2018-2029", 5, "interspeech", 2018]], "Juhong Zhan": [0, ["GlobalTIMIT: Acoustic-Phonetic Datasets for the World's Languages", ["Nattanun Chanchaochai", "Christopher Cieri", "Japhet Debrah", "Hongwei Ding", "Yue Jiang", "Sishi Liao", "Mark Liberman", "Jonathan Wright", "Jiahong Yuan", "Juhong Zhan", "Yuqing Zhan"], "https://doi.org/10.21437/Interspeech.2018-1185", 5, "interspeech", 2018]], "Georges Linares": [0, ["Quaternion Convolutional Neural Networks for End-to-End Automatic Speech Recognition", ["Titouan Parcollet", "Ying Zhang", "Mohamed Morchid", "Chiheb Trabelsi", "Georges Linares", "Renato de Mori", "Yoshua Bengio"], "https://doi.org/10.21437/Interspeech.2018-1898", 5, "interspeech", 2018]], "Lirong Dai": [0, ["Acoustic Modeling with Densely Connected Residual Network for Multichannel Speech Recognition", ["Jian Tang", "Yan Song", "Lirong Dai", "Ian Vince McLoughlin"], "https://doi.org/10.21437/Interspeech.2018-1089", 5, "interspeech", 2018], ["An Attention Pooling Based Representation Learning Method for Speech Emotion Recognition", ["Pengcheng Li", "Yan Song", "Ian Vince McLoughlin", "Wu Guo", "Lirong Dai"], "https://doi.org/10.21437/Interspeech.2018-1242", 5, "interspeech", 2018], ["An Improved Deep Embedding Learning Method for Short Duration Speaker Verification", ["Zhifu Gao", "Yan Song", "Ian Vince McLoughlin", "Wu Guo", "Lirong Dai"], "https://doi.org/10.21437/Interspeech.2018-1515", 5, "interspeech", 2018]], "Meng Liu": [0, ["Multiple Phase Information Combination for Replay Attacks Detection", ["Dongbo Li", "Longbiao Wang", "Jianwu Dang", "Meng Liu", "Zeyan Oo", "Seiichi Nakagawa", "Haotian Guan", "Xiangang Li"], "https://doi.org/10.21437/Interspeech.2018-2001", 5, "interspeech", 2018]], "Sridha Sridharan": [0, ["Employing Phonetic Information in DNN Speaker Embeddings to Improve Speaker Recognition Performance", ["Md. Hafizur Rahman", "Ivan Himawan", "Mitchell McLaren", "Clinton Fookes", "Sridha Sridharan"], "https://doi.org/10.21437/Interspeech.2018-1804", 5, "interspeech", 2018]], "Ashish Panda": [0, ["Analysis of the Effect of Speech-Laugh on Speaker Recognition System", ["Sri Harsha Dumpala", "Ashish Panda", "Sunil Kumar Kopparapu"], "https://doi.org/10.21437/Interspeech.2018-2090", 5, "interspeech", 2018]], "Manuel Sam Ribeiro": [0, ["UltraSuite: A Repository of Ultrasound and Acoustic Data from Child Speech Therapy Sessions", ["Aciel Eshky", "Manuel Sam Ribeiro", "Joanne Cleland", "Korin Richmond", "Zoe Roxburgh", "James M. Scobbie", "Alan Wrench"], "https://doi.org/10.21437/Interspeech.2018-1736", 5, "interspeech", 2018]], "Chris Co": [0, ["Speech Recognition for Medical Conversations", ["Chung-Cheng Chiu", "Anshuman Tripathi", "Katherine Chou", "Chris Co", "Navdeep Jaitly", "Diana Jaunzeikare", "Anjuli Kannan", "Patrick Nguyen", "Hasim Sak", "Ananth Sankar", "Justin Tansuwan", "Nathan Wan", "Yonghui Wu", "Xuedong Zhang"], "https://doi.org/10.21437/Interspeech.2018-40", 5, "interspeech", 2018]], "Wenjing Han": [0.00020490603492362425, ["Towards Temporal Modelling of Categorical Speech Emotion Recognition", ["Wenjing Han", "Huabin Ruan", "Xiaomin Chen", "Zhixiang Wang", "Haifeng Li", "Bjorn W. Schuller"], "https://doi.org/10.21437/Interspeech.2018-1858", 5, "interspeech", 2018]], "Eunwoo Song": [0.9905647486448288, ["A Unified Framework for the Generation of Glottal Signals in Deep Learning-based Parametric Speech Synthesis Systems", ["Min-Jae Hwang", "Eunwoo Song", "Jin-Seob Kim", "Hong-Goo Kang"], "https://doi.org/10.21437/Interspeech.2018-1590", 5, "interspeech", 2018], ["Acoustic Modeling Using Adversarially Trained Variational Recurrent Neural Network for Speech Synthesis", ["Joun Yeop Lee", "Sung Jun Cheon", "Byoung Jin Choi", "Nam Soo Kim", "Eunwoo Song"], "https://doi.org/10.21437/Interspeech.2018-1598", 5, "interspeech", 2018]], "Srikanth Ronanki": [0, ["Learning Interpretable Control Dimensions for Speech Synthesis by Using External Data", ["Zack Hodari", "Oliver Watts", "Srikanth Ronanki", "Simon King"], "https://doi.org/10.21437/Interspeech.2018-2075", 5, "interspeech", 2018]], "Yana Yunusova": [0, ["Automatic Detection of Orofacial Impairment in Stroke", ["Andrea Bandini", "Jordan R. Green", "Brian Richburg", "Yana Yunusova"], "https://doi.org/10.21437/Interspeech.2018-2475", 5, "interspeech", 2018], ["Automatic Early Detection of Amyotrophic Lateral Sclerosis from Intelligible Speech Using Convolutional Neural Networks", ["Kwanghoon An", "Myung Jong Kim", "Kristin Teplansky", "Jordan R. Green", "Thomas Campbell", "Yana Yunusova", "Daragh Heitzman", "Jun Wang"], "https://doi.org/10.21437/Interspeech.2018-2496", 5, "interspeech", 2018]], "Yoon Seok Hong": [0.9519332945346832, ["Automatic Miscue Detection Using RNN Based Models with Data Augmentation", ["Yoon Seok Hong", "Kyung Seo Ki", "Gahgene Gweon"], "https://doi.org/10.21437/Interspeech.2018-1644", 5, "interspeech", 2018]], "James M. Scobbie": [0, ["UltraSuite: A Repository of Ultrasound and Acoustic Data from Child Speech Therapy Sessions", ["Aciel Eshky", "Manuel Sam Ribeiro", "Joanne Cleland", "Korin Richmond", "Zoe Roxburgh", "James M. Scobbie", "Alan Wrench"], "https://doi.org/10.21437/Interspeech.2018-1736", 5, "interspeech", 2018]], "Carlos Segura": [0, ["Lightly Supervised vs. Semi-supervised Training of Acoustic Model on Luxembourgish for Low-resource Automatic Speech Recognition", ["Karel Vesely", "Carlos Segura", "Igor Szoke", "Jordi Luque", "Jan Cernocky"], "https://doi.org/10.21437/Interspeech.2018-2361", 5, "interspeech", 2018]], "Anthony Pak-Hin Kong": [5.5142583207934415e-12, ["Automatic Speech Assessment for People with Aphasia Using TDNN-BLSTM with Multi-Task Learning", ["Ying Qin", "Tan Lee", "Siyuan Feng", "Anthony Pak-Hin Kong"], "https://doi.org/10.21437/Interspeech.2018-1630", 5, "interspeech", 2018]], "Helen Meng": [0, ["Siamese Recurrent Auto-Encoder Representation for Query-by-Example Spoken Term Detection", ["Ziwei Zhu", "Zhiyong Wu", "Runnan Li", "Helen Meng", "Lianhong Cai"], "https://doi.org/10.21437/Interspeech.2018-1788", 5, "interspeech", 2018], ["Detection of Glottal Closure Instants from Speech Signals: A Convolutional Neural Network Based Method", ["Shuai Yang", "Zhiyong Wu", "Binbin Shen", "Helen Meng"], "https://doi.org/10.21437/Interspeech.2018-1281", 5, "interspeech", 2018], ["Voice Conversion Across Arbitrary Speakers Based on a Single Target-Speaker Utterance", ["Songxiang Liu", "Jinghua Zhong", "Lifa Sun", "Xixin Wu", "Xunying Liu", "Helen Meng"], "https://doi.org/10.21437/Interspeech.2018-1504", 5, "interspeech", 2018], ["Gaussian Process Neural Networks for Speech Recognition", ["Max W. Y. Lam", "Shoukang Hu", "Xurong Xie", "Shansong Liu", "Jianwei Yu", "Rongfeng Su", "Xunying Liu", "Helen Meng"], "https://doi.org/10.21437/Interspeech.2018-1823", 5, "interspeech", 2018], ["Unsupervised Discovery of Non-native Phonetic Patterns in L2 English Speech for Mispronunciation Detection and Diagnosis", ["Xu Li", "Shaoguang Mao", "Xixin Wu", "Kun Li", "Xunying Liu", "Helen Meng"], "https://doi.org/10.21437/Interspeech.2018-2027", 5, "interspeech", 2018], ["Development of the CUHK Dysarthric Speech Recognition System for the UA Speech Corpus", ["Jianwei Yu", "Xurong Xie", "Shansong Liu", "Shoukang Hu", "Max W. Y. Lam", "Xixin Wu", "Ka Ho Wong", "Xunying Liu", "Helen Meng"], "https://doi.org/10.21437/Interspeech.2018-1541", 5, "interspeech", 2018], ["Speech and Language Processing for Learning and Wellbeing", ["Helen Meng"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/4004.html", 1, "interspeech", 2018], ["Rapid Style Adaptation Using Residual Error Embedding for Expressive Speech Synthesis", ["Xixin Wu", "Yuewen Cao", "Mu Wang", "Songxiang Liu", "Shiyin Kang", "Zhiyong Wu", "Xunying Liu", "Dan Su", "Dong Yu", "Helen Meng"], "https://doi.org/10.21437/Interspeech.2018-1991", 5, "interspeech", 2018], ["Emotion Recognition from Variable-Length Speech Segments Using Deep Learning on Spectrograms", ["Xi Ma", "Zhiyong Wu", "Jia Jia", "Mingxing Xu", "Helen Meng", "Lianhong Cai"], "https://doi.org/10.21437/Interspeech.2018-2228", 5, "interspeech", 2018]], "Che-Wei Huang": [0, ["Stochastic Shake-Shake Regularization for Affective Learning from Speech", ["Che-Wei Huang", "Shrikanth Narayanan"], "https://doi.org/10.21437/Interspeech.2018-1327", 5, "interspeech", 2018]], "Praneeth Srungarapu": [0, ["Towards Automatic Speech Identification from Vocal Tract Shape Dynamics in Real-time MRI", ["Pramit Saha", "Praneeth Srungarapu", "Sidney Fels"], "https://doi.org/10.21437/Interspeech.2018-2537", 5, "interspeech", 2018]], "Amir Hussain": [0, ["DNN Driven Speaker Independent Audio-Visual Mask Estimation for Speech Separation", ["Mandar Gogate", "Ahsan Adeel", "Ricard Marxer", "Jon Barker", "Amir Hussain"], "https://doi.org/10.21437/Interspeech.2018-2516", 5, "interspeech", 2018]], "Hardik B. Sailor": [0, ["Auditory Filterbank Learning for Temporal Modulation Features in Replay Spoof Speech Detection", ["Hardik B. Sailor", "Madhu R. Kamble", "Hemant A. Patil"], "https://doi.org/10.21437/Interspeech.2018-1651", 5, "interspeech", 2018], ["Auditory Filterbank Learning Using ConvRBM for Infant Cry Classification", ["Hardik B. Sailor", "Hemant A. Patil"], "https://doi.org/10.21437/Interspeech.2018-1536", 5, "interspeech", 2018], ["DA-IICT/IIITV System for Low Resource Speech Recognition Challenge 2018", ["Hardik B. Sailor", "Maddala Venkata Siva Krishna", "Diksha Chhabra", "Ankur T. Patil", "Madhu R. Kamble", "Hemant A. Patil"], "https://doi.org/10.21437/Interspeech.2018-1553", 5, "interspeech", 2018]], "Liquan Liu": [0, ["Neural Response Development During Distributional Learning", ["Natalie Boll-Avetisyan", "Jessie S. Nixon", "Tomas O. Lentz", "Liquan Liu", "Sandrien van Ommen", "Cagri Coltekin", "Jacolien van Rij"], "https://doi.org/10.21437/Interspeech.2018-2072", 5, "interspeech", 2018]], "Hung-yi Lee": [5.747688737756107e-05, ["Multi-target Voice Conversion without Parallel Data by Adversarially Learning Disentangled Audio Representations", ["Ju-Chieh Chou", "Cheng-chieh Yeh", "Hung-yi Lee", "Lin-Shan Lee"], "https://doi.org/10.21437/Interspeech.2018-1830", 5, "interspeech", 2018], ["Joint Learning of Interactive Spoken Content Retrieval and Trainable User Simulator", ["Pei-Hung Chung", "Kuan Tung", "Ching-Lun Tai", "Hung-yi Lee"], "https://doi.org/10.21437/Interspeech.2018-1346", 5, "interspeech", 2018], ["Spoken SQuAD: A Study of Mitigating the Impact of Speech Recognition Errors on Listening Comprehension", ["Chia-Hsuan Lee", "Szu-Lin Wu", "Chi-Liang Liu", "Hung-yi Lee"], "https://doi.org/10.21437/Interspeech.2018-1714", 5, "interspeech", 2018], ["Completely Unsupervised Phoneme Recognition by Adversarially Learning Mapping Relationships from Audio Embeddings", ["Da-Rong Liu", "Kuan-Yu Chen", "Hung-yi Lee", "Lin-Shan Lee"], "https://doi.org/10.21437/Interspeech.2018-1800", 5, "interspeech", 2018]], "Xurong Xie": [0, ["Gaussian Process Neural Networks for Speech Recognition", ["Max W. Y. Lam", "Shoukang Hu", "Xurong Xie", "Shansong Liu", "Jianwei Yu", "Rongfeng Su", "Xunying Liu", "Helen Meng"], "https://doi.org/10.21437/Interspeech.2018-1823", 5, "interspeech", 2018], ["Development of the CUHK Dysarthric Speech Recognition System for the UA Speech Corpus", ["Jianwei Yu", "Xurong Xie", "Shansong Liu", "Shoukang Hu", "Max W. Y. Lam", "Xixin Wu", "Ka Ho Wong", "Xunying Liu", "Helen Meng"], "https://doi.org/10.21437/Interspeech.2018-1541", 5, "interspeech", 2018]], "Nadee Seneviratne": [0, ["Noise Robust Acoustic to Articulatory Speech Inversion", ["Nadee Seneviratne", "Ganesh Sivaraman", "Vikramjit Mitra", "Carol Y. Espy-Wilson"], "https://doi.org/10.21437/Interspeech.2018-1509", 5, "interspeech", 2018]], "Kanhaiya Kumar": [0, ["Automatic Detection of Expressiveness in Oral Reading", ["Kamini Sabu", "Kanhaiya Kumar", "Preeti Rao"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3026.html", 2, "interspeech", 2018], ["A Study of Lexical and Prosodic Cues to Segmentation in a Hindi-English Code-switched Discourse", ["Preeti Rao", "Mugdha Pandya", "Kamini Sabu", "Kanhaiya Kumar", "Nandini Bondale"], "https://doi.org/10.21437/Interspeech.2018-1600", 5, "interspeech", 2018]], "Hainan Xu": [0, ["Building State-of-the-art Distant Speech Recognition Using the CHiME-4 Challenge with a Setup of Speech Enhancement Baseline", ["Szu-Jui Chen", "Aswin Shanmugam Subramanian", "Hainan Xu", "Shinji Watanabe"], "https://doi.org/10.21437/Interspeech.2018-1262", 5, "interspeech", 2018], ["A GPU-based WFST Decoder with Exact Lattice Generation", ["Zhehuai Chen", "Justin Luitjens", "Hainan Xu", "Yiming Wang", "Daniel Povey", "Sanjeev Khudanpur"], "https://doi.org/10.21437/Interspeech.2018-1339", 5, "interspeech", 2018], ["Recurrent Neural Network Language Model Adaptation for Conversational Speech Recognition", ["Ke Li", "Hainan Xu", "Yiming Wang", "Daniel Povey", "Sanjeev Khudanpur"], "https://doi.org/10.21437/Interspeech.2018-1413", 5, "interspeech", 2018], ["Semi-Orthogonal Low-Rank Matrix Factorization for Deep Neural Networks", ["Daniel Povey", "Gaofeng Cheng", "Yiming Wang", "Ke Li", "Hainan Xu", "Mahsa Yarmohammadi", "Sanjeev Khudanpur"], "https://doi.org/10.21437/Interspeech.2018-1417", 5, "interspeech", 2018]], "Gajan Suthokumar": [0, ["Modulation Dynamic Features for the Detection of Replay Attacks", ["Gajan Suthokumar", "Vidhyasaharan Sethu", "Chamith Wijenayake", "Eliathamby Ambikairajah"], "https://doi.org/10.21437/Interspeech.2018-1846", 5, "interspeech", 2018]], "Ruizhi Li": [0, ["Stream Attention for Distributed Multi-Microphone Speech Recognition", ["Xiaofei Wang", "Ruizhi Li", "Hynek Hermansky"], "https://doi.org/10.21437/Interspeech.2018-1037", 5, "interspeech", 2018]], "Ke Tan": [0, ["A Convolutional Recurrent Neural Network for Real-Time Speech Enhancement", ["Ke Tan", "DeLiang Wang"], "https://doi.org/10.21437/Interspeech.2018-1405", 5, "interspeech", 2018], ["A Two-Stage Approach to Noisy Cochannel Speech Separation with Gated Residual Networks", ["Ke Tan", "DeLiang Wang"], "https://doi.org/10.21437/Interspeech.2018-1406", 5, "interspeech", 2018]], "Jared Bernstein": [0, ["Modeling Self-Reported and Observed Affect from Speech", ["Jian Cheng", "Jared Bernstein", "Elizabeth Rosenfeld", "Peter W. Foltz", "Alex S. Cohen", "Terje B. Holmlund", "Brita Elvevag"], "https://doi.org/10.21437/Interspeech.2018-2222", 5, "interspeech", 2018]], "Feng Yang": [0.00021905750327277929, ["Acoustic Features Associated with Sustained Vowel and Continuous Speech Productions by Chinese Children with Functional Articulation Disorders", ["Wang Zhang", "Xiangquan Gui", "Tianqi Wang", "Manwa L. Ng", "Feng Yang", "Lan Wang", "Nan Yan"], "https://doi.org/10.21437/Interspeech.2018-1521", 5, "interspeech", 2018]], "Mark Miller": [0, ["An Automated Assistant for Medical Scribes", ["Gregory P. Finley", "Erik Edwards", "Amanda Robinson", "Najmeh Sadoughi", "James Fone", "Mark Miller", "David Suendermann-Oeft", "Michael Brenndoerfer", "Nico Axtmann"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3047.html", 2, "interspeech", 2018]], "Shinsuke Sakai": [0, ["Forward-Backward Attention Decoder", ["Masato Mimura", "Shinsuke Sakai", "Tatsuya Kawahara"], "https://doi.org/10.21437/Interspeech.2018-1160", 5, "interspeech", 2018], ["Encoder Transfer for Attention-based Acoustic-to-word Speech Recognition", ["Sei Ueno", "Takafumi Moriya", "Masato Mimura", "Shinsuke Sakai", "Yusuke Shinohara", "Yoshikazu Yamaguchi", "Yushi Aono", "Tatsuya Kawahara"], "https://doi.org/10.21437/Interspeech.2018-1424", 5, "interspeech", 2018]], "Eric Riebling": [0, ["The ACLEW DiViMe: An Easy-to-use Diarization Tool", ["Adrien Le Franc", "Eric Riebling", "Julien Karadayi", "Yun Wang", "Camila Scaff", "Florian Metze", "Alejandrina Cristia"], "https://doi.org/10.21437/Interspeech.2018-2324", 5, "interspeech", 2018]], "Chamith Wijenayake": [0, ["Modulation Dynamic Features for the Detection of Replay Attacks", ["Gajan Suthokumar", "Vidhyasaharan Sethu", "Chamith Wijenayake", "Eliathamby Ambikairajah"], "https://doi.org/10.21437/Interspeech.2018-1846", 5, "interspeech", 2018]], "Deepanway Ghosal": [0, ["Music Genre Recognition Using Deep Neural Networks and Transfer Learning", ["Deepanway Ghosal", "Maheshkumar H. Kolekar"], "https://doi.org/10.21437/Interspeech.2018-2045", 5, "interspeech", 2018]], "Chao Jiang": [0, ["Speaker Diarization with Enhancing Speech for the First DIHARD Challenge", ["Lei Sun", "Jun Du", "Chao Jiang", "Xueyang Zhang", "Shan He", "Bing Yin", "Chin-Hui Lee"], "https://doi.org/10.21437/Interspeech.2018-1742", 5, "interspeech", 2018]], "Tanaya Guha": [0, ["Learning Spontaneity to Improve Emotion Recognition in Speech", ["Karttikeya Mangalam", "Tanaya Guha"], "https://doi.org/10.21437/Interspeech.2018-1872", 5, "interspeech", 2018]], "Yike Yang": [0.00010171171015826985, ["Acoustic Analysis of Whispery Voice Disguise in Mandarin Chinese", ["Cuiling Zhang", "Bin Li", "Si Chen", "Yike Yang"], "https://doi.org/10.21437/Interspeech.2018-2598", 4, "interspeech", 2018]], "Horacio Franco": [0, ["Voices Obscured in Complex Environmental Settings (VOiCES) Corpus", ["Colleen Richey", "Maria Auxiliadora Barrios", "Zeb Armstrong", "Chris Bartels", "Horacio Franco", "Martin Graciarena", "Aaron Lawson", "Mahesh Kumar Nandwana", "Allen R. Stauffer", "Julien van Hout", "Paul Gamble", "Jeffrey Hetherly", "Cory Stephenson", "Karl Ni"], "https://doi.org/10.21437/Interspeech.2018-1454", 5, "interspeech", 2018], ["Articulatory Features for ASR of Pathological Speech", ["Emre Yilmaz", "Vikramjit Mitra", "Chris Bartels", "Horacio Franco"], "https://doi.org/10.21437/Interspeech.2018-67", 5, "interspeech", 2018]], "Siddika Imani": [0, ["AGROASSAM: A Web Based Assamese Speech Recognition Application for Retrieving Agricultural Commodity Price and Weather Information", ["Abhishek Dey", "Abhash Deka", "Siddika Imani", "Barsha Deka", "Rohit Sinha", "S. R. Mahadeva Prasanna", "Priyankoo Sarmah", "K. Samudravijaya", "S. R. Nirmala"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3048.html", 2, "interspeech", 2018]], "Yaxing Li": [0, ["Multi-frame Quantization of LSF Parameters Using a Deep Autoencoder and Pyramid Vector Quantizer", ["Yaxing Li", "Eshete Derb Emiru", "Shengwu Xiong", "Anna Zhu", "Pengfei Duan", "Yichang Li"], "https://doi.org/10.21437/Interspeech.2018-2577", 5, "interspeech", 2018], ["Multi-frame Coding of LSF Parameters Using Block-Constrained Trellis Coded Vector Quantization", ["Yaxing Li", "Shan Xu", "Shengwu Xiong", "Anna Zhu", "Pengfei Duan", "Yueming Ding"], "https://doi.org/10.21437/Interspeech.2018-2578", 5, "interspeech", 2018]], "Hangting Chen": [0, ["Deep Convolutional Neural Network with Scalogram for Audio Scene Modeling", ["Hangting Chen", "Pengyuan Zhang", "Haichuan Bai", "Qingsheng Yuan", "Xiuguo Bao", "Yonghong Yan"], "https://doi.org/10.21437/Interspeech.2018-1524", 5, "interspeech", 2018]], "Xiong Xiao": [0, ["Recognizing Overlapped Speech in Meetings: A Multichannel Separation Approach Using Neural Networks", ["Takuya Yoshioka", "Hakan Erdogan", "Zhuo Chen", "Xiong Xiao", "Fil Alleva"], "https://doi.org/10.21437/Interspeech.2018-2284", 5, "interspeech", 2018]], "Justin Luitjens": [0, ["A GPU-based WFST Decoder with Exact Lattice Generation", ["Zhehuai Chen", "Justin Luitjens", "Hainan Xu", "Yiming Wang", "Daniel Povey", "Sanjeev Khudanpur"], "https://doi.org/10.21437/Interspeech.2018-1339", 5, "interspeech", 2018]], "Eng Siong Chng": [0, ["Mandarin-English Code-switching Speech Recognition", ["Haihua Xu", "Van Tung Pham", "Zin Tun Kyaw", "Zhi Hao Lim", "Eng Siong Chng", "Haizhou Li"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3014.html", 2, "interspeech", 2018], ["Study of Semi-supervised Approaches to Improving English-Mandarin Code-Switching Speech Recognition", ["Pengcheng Guo", "Haihua Xu", "Lei Xie", "Eng Siong Chng"], "https://doi.org/10.21437/Interspeech.2018-1974", 5, "interspeech", 2018], ["Unsupervised and Efficient Vocabulary Expansion for Recurrent Neural Network Language Models in ASR", ["Yerbolat Khassanov", "Eng Siong Chng"], "https://doi.org/10.21437/Interspeech.2018-1021", 5, "interspeech", 2018], ["A Shifted Delta Coefficient Objective for Monaural Speech Separation Using Multi-task Learning", ["Chenglin Xu", "Wei Rao", "Eng Siong Chng", "Haizhou Li"], "https://doi.org/10.21437/Interspeech.2018-1150", 5, "interspeech", 2018]], "Juan Camilo Vasquez-Correa": [0, ["A Multitask Learning Approach to Assess the Dysarthria Severity in Patients with Parkinson's Disease", ["Juan Camilo Vasquez-Correa", "Tomas Arias-Vergara", "Juan Rafael Orozco-Arroyave", "Elmar Noth"], "https://doi.org/10.21437/Interspeech.2018-1988", 5, "interspeech", 2018], ["Multimodal I-vectors to Detect and Evaluate Parkinson's Disease", ["Nicanor Garcia", "Juan Camilo Vasquez-Correa", "Juan Rafael Orozco-Arroyave", "Elmar Noth"], "https://doi.org/10.21437/Interspeech.2018-2295", 5, "interspeech", 2018]], "Duc Le": [0, ["Classification of Huntington Disease Using Acoustic and Lexical Features", ["Matthew Perez", "Wenyu Jin", "Duc Le", "Noelle Carlozzi", "Praveen Dayalu", "Angela Roberts", "Emily Mower Provost"], "https://doi.org/10.21437/Interspeech.2018-2029", 5, "interspeech", 2018]], "Ales Prazak": [0, ["Multimodal Name Recognition in Live TV Subtitling", ["Marek Hruz", "Ales Prazak", "Michal Busta"], "https://doi.org/10.21437/Interspeech.2018-1748", 4, "interspeech", 2018]], "Suyog Gupta": [0, ["Compression of End-to-End Models", ["Ruoming Pang", "Tara N. Sainath", "Rohit Prabhavalkar", "Suyog Gupta", "Yonghui Wu", "Shuyuan Zhang", "Chung-Cheng Chiu"], "https://doi.org/10.21437/Interspeech.2018-1025", 5, "interspeech", 2018]], "Nam Soo Kim": [1, ["Acoustic Modeling Using Adversarially Trained Variational Recurrent Neural Network for Speech Synthesis", ["Joun Yeop Lee", "Sung Jun Cheon", "Byoung Jin Choi", "Nam Soo Kim", "Eunwoo Song"], "https://doi.org/10.21437/Interspeech.2018-1598", 5, "interspeech", 2018]], "Ch. V. Rama Rao": [0, ["Phase-locked Loop (PLL) Based Phase Estimation in Single Channel Speech Enhancement", ["Priya Pallavi", "Ch. V. Rama Rao"], "https://doi.org/10.21437/Interspeech.2018-1950", 4, "interspeech", 2018]], "Linda Liu": [0, ["Contextual Language Model Adaptation for Conversational Agents", ["Anirudh Raju", "Behnam Hedayatnia", "Linda Liu", "Ankur Gandhe", "Chandra Khatri", "Angeliki Metallinou", "Anu Venkatesh", "Ariya Rastrow"], "https://doi.org/10.21437/Interspeech.2018-1122", 5, "interspeech", 2018]], "Ildiko Hoffmann": [0, ["Identifying Schizophrenia Based on Temporal Parameters in Spontaneous Speech", ["Gabor Gosztolya", "Anita Bagi", "Szilvia Szaloki", "Istvan Szendi", "Ildiko Hoffmann"], "https://doi.org/10.21437/Interspeech.2018-1079", 5, "interspeech", 2018]], "Hossein Sameti": [0, ["End-to-end Speech Recognition Using Lattice-free MMI", ["Hossein Hadian", "Hossein Sameti", "Daniel Povey", "Sanjeev Khudanpur"], "https://doi.org/10.21437/Interspeech.2018-1423", 5, "interspeech", 2018]], "Konstantinos Drossos": [0, ["Reducing Interference with Phase Recovery in DNN-based Monaural Singing Voice Separation", ["Paul Magron", "Konstantinos Drossos", "Stylianos Ioannis Mimilakis", "Tuomas Virtanen"], "https://doi.org/10.21437/Interspeech.2018-1845", 5, "interspeech", 2018]], "David Greenwood": [0, ["Joint Learning of Facial Expression and Head Pose from Speech", ["David Greenwood", "Iain Matthews", "Stephen D. Laycock"], "https://doi.org/10.21437/Interspeech.2018-2587", 5, "interspeech", 2018]], "Catherine Inez Watson": [0, ["An Open Source Emotional Speech Corpus for Human Robot Interaction Applications", ["Jesin James", "Li Tian", "Catherine Inez Watson"], "https://doi.org/10.21437/Interspeech.2018-1349", 5, "interspeech", 2018]], "Heini Kallio": [0, ["Prominence-based Evaluation of L2 Prosody", ["Heini Kallio", "Antti Suni", "Paivi Virkkunen", "Juraj Simko"], "https://doi.org/10.21437/Interspeech.2018-1873", 5, "interspeech", 2018]], "Arun Baby": [0, ["Code-switching in Indic Speech Synthesisers", ["Anju Leela Thomas", "Anusha Prakash", "Arun Baby", "Hema A. Murthy"], "https://doi.org/10.21437/Interspeech.2018-1178", 5, "interspeech", 2018]], "Melvin G. McInnis": [0, ["The PRIORI Emotion Dataset: Linking Mood to Emotion Detected In-the-Wild", ["Soheil Khorram", "Mimansa Jaiswal", "John Gideon", "Melvin G. McInnis", "Emily Mower Provost"], "https://doi.org/10.21437/Interspeech.2018-2355", 5, "interspeech", 2018]], "Anju Leela Thomas": [0, ["Code-switching in Indic Speech Synthesisers", ["Anju Leela Thomas", "Anusha Prakash", "Arun Baby", "Hema A. Murthy"], "https://doi.org/10.21437/Interspeech.2018-1178", 5, "interspeech", 2018]], "Yang Zhang": [0, ["LSTM Based Cross-corpus and Cross-task Acoustic Emotion Recognition", ["Heysem Kaya", "Dmitrii Fedotov", "Ali Yesilkanat", "Oxana Verkholyak", "Yang Zhang", "Alexey Karpov"], "https://doi.org/10.21437/Interspeech.2018-2298", 5, "interspeech", 2018]], "Paul Vozila": [0, ["Efficient Language Model Adaptation with Noise Contrastive Estimation and Kullback-Leibler Regularization", ["Jesus Andres-Ferrer", "Nathan Bodenstab", "Paul Vozila"], "https://doi.org/10.21437/Interspeech.2018-1345", 5, "interspeech", 2018]], "Jinfeng Huang": [0, ["Revealing Spatiotemporal Brain Dynamics of Speech Production Based on EEG and Eye Movement", ["Bin Zhao", "Jinfeng Huang", "Gaoyan Zhang", "Jianwu Dang", "Minbo Chen", "YingjianFu", "Longbiao Wang"], "https://doi.org/10.21437/Interspeech.2018-1908", 5, "interspeech", 2018]], "Huan Luan": [0, ["Pitch Characteristics of L2 English Speech by Chinese Speakers: A Large-scale Study", ["Jiahong Yuan", "Qiusi Dong", "Fei Wu", "Huan Luan", "Xiaofei Yang", "Hui Lin", "Yang Liu"], "https://doi.org/10.21437/Interspeech.2018-1556", 5, "interspeech", 2018]], "Mohammad Ateeq": [0, ["An Optimization Based Approach for Solving Spoken CALL Shared Task", ["Mohammad Ateeq", "Abualsoud Hanani", "Aziz Qaroush"], "https://doi.org/10.21437/Interspeech.2018-1328", 5, "interspeech", 2018]], "Kyubyong Park": [0.9501790404319763, ["Training Utterance-level Embedding Networks for Speaker Identification and Verification", ["Heewoong Park", "Sukhyun Cho", "Kyubyong Park", "Namju Kim", "Jonghun Park"], "https://doi.org/10.21437/Interspeech.2018-1044", 5, "interspeech", 2018]], "Yichang Li": [0, ["Multi-frame Quantization of LSF Parameters Using a Deep Autoencoder and Pyramid Vector Quantizer", ["Yaxing Li", "Eshete Derb Emiru", "Shengwu Xiong", "Anna Zhu", "Pengfei Duan", "Yichang Li"], "https://doi.org/10.21437/Interspeech.2018-2577", 5, "interspeech", 2018]], "Hui Xie": [0, ["Visual Timing Information in Audiovisual Speech Perception: Evidence from Lexical Tone Contour", ["Hui Xie", "Biao Zeng", "Rui Wang"], "https://doi.org/10.21437/Interspeech.2018-1285", 5, "interspeech", 2018]], "James V. Bruno": [0, ["Game-based Spoken Dialog Language Learning Applications for Young Students", ["Keelan Evanini", "Veronika Timpe-Laughlin", "Eugene Tsuprun", "Ian Blood", "Jeremy Lee", "James V. Bruno", "Vikram Ramanarayanan", "Patrick L. Lange", "David Suendermann-Oeft"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3045.html", 2, "interspeech", 2018]], "Cem Philipp Freimoser": [0, ["The CSU-K Rule-Based System for the 2nd Edition Spoken CALL Shared Task", ["Dominik Julg", "Mario Kunstek", "Cem Philipp Freimoser", "Kay Berkling", "Mengjie Qian"], "https://doi.org/10.21437/Interspeech.2018-1000", 5, "interspeech", 2018]], "Zhonghua Xi": [0, ["AVA-Speech: A Densely Labeled Dataset of Speech Activity in Movies", ["Sourish Chaudhuri", "Joseph Roth", "Daniel P. W. Ellis", "Andrew C. Gallagher", "Liat Kaver", "Radhika Marvin", "Caroline Pantofaru", "Nathan Reale", "Loretta Guarino Reid", "Kevin W. Wilson", "Zhonghua Xi"], "https://doi.org/10.21437/Interspeech.2018-2028", 5, "interspeech", 2018]], "Toru Nakashika": [0, ["DNN-based Speech Synthesis for Small Data Sets Considering Bidirectional Speech-Text Conversion", ["Kentaro Sone", "Toru Nakashika"], "https://doi.org/10.21437/Interspeech.2018-1460", 5, "interspeech", 2018], ["LSTBM: A Novel Sequence Representation of Speech Spectra Using Restricted Boltzmann Machine with Long Short-Term Memory", ["Toru Nakashika"], "https://doi.org/10.21437/Interspeech.2018-1753", 5, "interspeech", 2018]], "Takaaki Hori": [0, ["ESPnet: End-to-End Speech Processing Toolkit", ["Shinji Watanabe", "Takaaki Hori", "Shigeki Karita", "Tomoki Hayashi", "Jiro Nishitoba", "Yuya Unno", "Nelson Enrique Yalta Soplin", "Jahn Heymann", "Matthew Wiesner", "Nanxin Chen", "Adithya Renduchintala", "Tsubasa Ochiai"], "https://doi.org/10.21437/Interspeech.2018-1456", 5, "interspeech", 2018]], "Xiaofei Yang": [3.716871946231055e-15, ["Pitch Characteristics of L2 English Speech by Chinese Speakers: A Large-scale Study", ["Jiahong Yuan", "Qiusi Dong", "Fei Wu", "Huan Luan", "Xiaofei Yang", "Hui Lin", "Yang Liu"], "https://doi.org/10.21437/Interspeech.2018-1556", 5, "interspeech", 2018]], "John Levis": [0, ["L2-ARCTIC: A Non-native English Speech Corpus", ["Guanlong Zhao", "Sinem Sonsaat", "Alif Silpachai", "Ivana Lucic", "Evgeny Chukharev-Hudilainen", "John Levis", "Ricardo Gutierrez-Osuna"], "https://doi.org/10.21437/Interspeech.2018-1110", 5, "interspeech", 2018]], "Richard Brutti": [0, ["Attention-based Sequence Classification for Affect Detection", ["Cristina Gorrostieta", "Richard Brutti", "Kye Taylor", "Avi Shapiro", "Joseph Moran", "Ali Azarbayejani", "John Kane"], "https://doi.org/10.21437/Interspeech.2018-1610", 5, "interspeech", 2018]], "Kailai Zhang": [0, ["Temporal Transformer Networks for Acoustic Scene Classification", ["Teng Zhang", "Kailai Zhang", "Ji Wu"], "https://doi.org/10.21437/Interspeech.2018-1152", 5, "interspeech", 2018], ["Data Independent Sequence Augmentation Method for Acoustic Scene Classification", ["Teng Zhang", "Kailai Zhang", "Ji Wu"], "https://doi.org/10.21437/Interspeech.2018-1250", 5, "interspeech", 2018], ["Multi-modal Attention Mechanisms in LSTM and Its Application to Acoustic Scene Classification", ["Teng Zhang", "Kailai Zhang", "Ji Wu"], "https://doi.org/10.21437/Interspeech.2018-1138", 5, "interspeech", 2018]], "Vincent Renkens": [0, ["Capsule Networks for Low Resource Spoken Language Understanding", ["Vincent Renkens", "Hugo Van hamme"], "https://doi.org/10.21437/Interspeech.2018-1013", 5, "interspeech", 2018], ["State Gradients for RNN Memory Analysis", ["Lyan Verwimp", "Hugo Van hamme", "Vincent Renkens", "Patrick Wambacq"], "https://doi.org/10.21437/Interspeech.2018-1153", 5, "interspeech", 2018]], "Craig Harman": [0, ["Automatic Speech Recognition and Topic Identification from Speech for Almost-Zero-Resource Languages", ["Matthew Wiesner", "Chunxi Liu", "Lucas Ondel", "Craig Harman", "Vimal Manohar", "Jan Trmal", "Zhongqiang Huang", "Najim Dehak", "Sanjeev Khudanpur"], "https://doi.org/10.21437/Interspeech.2018-1836", 5, "interspeech", 2018]], "Sarith Fernando": [0, ["Sub-band Envelope Features Using Frequency Domain Linear Prediction for Short Duration Language Identification", ["Sarith Fernando", "Vidhyasaharan Sethu", "Eliathamby Ambikairajah"], "https://doi.org/10.21437/Interspeech.2018-1805", 5, "interspeech", 2018]], "Navid Shokouhi": [0, ["Assessing Speaker Engagement in 2-Person Debates: Overlap Detection in United States Presidential Debates", ["Midia Yousefi", "Navid Shokouhi", "John H. L. Hansen"], "https://doi.org/10.21437/Interspeech.2018-1463", 5, "interspeech", 2018]], "Mohammad M. Ghassemi": [0, ["Detecting Depression with Audio/Text Sequence Modeling of Interviews", ["Tuka Al Hanai", "Mohammad M. Ghassemi", "James R. Glass"], "https://doi.org/10.21437/Interspeech.2018-2522", 5, "interspeech", 2018]], "Saad Irtza": [0, ["Frequency Domain Linear Prediction Features for Replay Spoofing Attack Detection", ["Buddhi Wickramasinghe", "Saad Irtza", "Eliathamby Ambikairajah", "Julien Epps"], "https://doi.org/10.21437/Interspeech.2018-1574", 5, "interspeech", 2018]], "Sung Jun Cheon": [0.9205868095159531, ["Acoustic Modeling Using Adversarially Trained Variational Recurrent Neural Network for Speech Synthesis", ["Joun Yeop Lee", "Sung Jun Cheon", "Byoung Jin Choi", "Nam Soo Kim", "Eunwoo Song"], "https://doi.org/10.21437/Interspeech.2018-1598", 5, "interspeech", 2018]], "Anirudh Raju": [0, ["Contextual Language Model Adaptation for Conversational Agents", ["Anirudh Raju", "Behnam Hedayatnia", "Linda Liu", "Ankur Gandhe", "Chandra Khatri", "Angeliki Metallinou", "Anu Venkatesh", "Ariya Rastrow"], "https://doi.org/10.21437/Interspeech.2018-1122", 5, "interspeech", 2018]], "Julien Pinquier": [0, ["Perceptual and Automatic Evaluations of the Intelligibility of Speech Degraded by Noise Induced Hearing Loss Simulation", ["Imed Laaridh", "Julien Tardieu", "Cynthia Magnen", "Pascal Gaillard", "Jerome Farinas", "Julien Pinquier"], "https://doi.org/10.21437/Interspeech.2018-1264", 5, "interspeech", 2018]], "Kimiko Tsukada": [0, ["Cross-language Perception of Mandarin Lexical Tones by Mongolian-speaking Bilinguals in the Inner Mongolia Autonomous Region, China", ["Kimiko Tsukada", "Yu Rong"], "https://doi.org/10.21437/Interspeech.2018-48", 5, "interspeech", 2018]], "Markus Kitza": [0, ["Comparison of BLSTM-Layer-Specific Affine Transformations for Speaker Adaptation", ["Markus Kitza", "Ralf Schluter", "Hermann Ney"], "https://doi.org/10.21437/Interspeech.2018-2022", 5, "interspeech", 2018]], "Sylvain Meignier": [0, ["S4D: Speaker Diarization Toolkit in Python", ["Pierre-Alexandre Broux", "Florent Desnous", "Anthony Larcher", "Simon Petitrenaud", "Jean Carrive", "Sylvain Meignier"], "https://doi.org/10.21437/Interspeech.2018-1232", 5, "interspeech", 2018]], "So Hyun Kim": [0.8991688787937164, ["A Knowledge Driven Structural Segmentation Approach for Play-Talk Classification During Autism Assessment", ["Manoj Kumar", "Pooja Chebolu", "So Hyun Kim", "Kassandra Martinez", "Catherine Lord", "Shrikanth Narayanan"], "https://doi.org/10.21437/Interspeech.2018-1516", 5, "interspeech", 2018]], "Surbhi Chauhan": [0, ["Extracting Speaker's Gender, Accent, Age and Emotional State from Speech", ["Nagendra Kumar Goel", "Mousmita Sarma", "Tejendra Kushwah", "Dharmesh Agarwal", "Zikra Iqbal", "Surbhi Chauhan"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3036.html", 2, "interspeech", 2018]], "Srihari Maruthachalam": [0, ["Brain-Computer Interface using Electroencephalogram Signatures of Eye Blinks", ["Srihari Maruthachalam", "Sidharth Aggarwal", "Mari Ganesh Kumar", "Mriganka Sur", "Hema A. Murthy"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3019.html", 2, "interspeech", 2018]], "Kyle Goehner": [0, ["Device-directed Utterance Detection", ["Sri Harish Reddy Mallidi", "Roland Maas", "Kyle Goehner", "Ariya Rastrow", "Spyros Matsoukas", "Bjorn Hoffmeister"], "https://doi.org/10.21437/Interspeech.2018-1531", 4, "interspeech", 2018]], "Chin-Hui Lee": [0.5, ["Speaker Diarization with Enhancing Speech for the First DIHARD Challenge", ["Lei Sun", "Jun Du", "Chao Jiang", "Xueyang Zhang", "Shan He", "Bing Yin", "Chin-Hui Lee"], "https://doi.org/10.21437/Interspeech.2018-1742", 5, "interspeech", 2018], ["Error Modeling via Asymmetric Laplace Distribution for Deep Neural Network Based Single-Channel Speech Enhancement", ["Li Chai", "Jun Du", "Chin-Hui Lee"], "https://doi.org/10.21437/Interspeech.2018-1439", 5, "interspeech", 2018]], "Changliang Liu": [0, ["Layer Trajectory LSTM", ["Jinyu Li", "Changliang Liu", "Yifan Gong"], "https://doi.org/10.21437/Interspeech.2018-1485", 5, "interspeech", 2018]], "Danny Websdale": [0, ["The Effect of Real-Time Constraints on Automatic Speech Animation", ["Danny Websdale", "Sarah Taylor", "Ben Milner"], "https://doi.org/10.21437/Interspeech.2018-2066", 5, "interspeech", 2018]], "Sanjeev Kumar Mittal": [0, ["Automatic Visual Augmentation for Concatenation Based Synthesized Articulatory Videos from Real-time MRI Data for Spoken Language Training", ["Chandana S", "Chiranjeevi Yarra", "Ritu Aggarwal", "Sanjeev Kumar Mittal", "N. K. Kausthubha", "Raseena K. T", "Astha Singh", "Prasanta Kumar Ghosh"], "https://doi.org/10.21437/Interspeech.2018-1570", 5, "interspeech", 2018]], "Ritu Aggarwal": [0, ["Automatic Visual Augmentation for Concatenation Based Synthesized Articulatory Videos from Real-time MRI Data for Spoken Language Training", ["Chandana S", "Chiranjeevi Yarra", "Ritu Aggarwal", "Sanjeev Kumar Mittal", "N. K. Kausthubha", "Raseena K. T", "Astha Singh", "Prasanta Kumar Ghosh"], "https://doi.org/10.21437/Interspeech.2018-1570", 5, "interspeech", 2018]], "Christine Dollaghan": [0, ["Fusing Text-dependent Word-level i-Vector Models to Screen 'at Risk' Child Speech", ["Prasanna V. Kothalkar", "Johanna Rudolph", "Christine Dollaghan", "Jennifer McGlothlin", "Thomas F. Campbell", "John H. L. Hansen"], "https://doi.org/10.21437/Interspeech.2018-1465", 5, "interspeech", 2018]], "Tanay Sharma": [0, ["Global SNR Estimation of Speech Signals Using Entropy and Uncertainty Estimates from Dropout Networks", ["Rohith Aralikatti", "Dilip Kumar Margam", "Tanay Sharma", "Abhinav Thanda", "Shankar M. Venkatesan"], "https://doi.org/10.21437/Interspeech.2018-1884", 5, "interspeech", 2018]], "Martin Graciarena": [0, ["Robust Speaker Recognition from Distant Speech under Real Reverberant Environments Using Speaker Embeddings", ["Mahesh Kumar Nandwana", "Julien van Hout", "Mitchell McLaren", "Allen R. Stauffer", "Colleen Richey", "Aaron Lawson", "Martin Graciarena"], "https://doi.org/10.21437/Interspeech.2018-2221", 5, "interspeech", 2018], ["Voices Obscured in Complex Environmental Settings (VOiCES) Corpus", ["Colleen Richey", "Maria Auxiliadora Barrios", "Zeb Armstrong", "Chris Bartels", "Horacio Franco", "Martin Graciarena", "Aaron Lawson", "Mahesh Kumar Nandwana", "Allen R. Stauffer", "Julien van Hout", "Paul Gamble", "Jeffrey Hetherly", "Cory Stephenson", "Karl Ni"], "https://doi.org/10.21437/Interspeech.2018-1454", 5, "interspeech", 2018]], "Traci Walker": [0, ["Detecting Signs of Dementia Using Word Vector Representations", ["Bahman Mirheidari", "Daniel Blackburn", "Traci Walker", "Annalena Venneri", "Markus Reuber", "Heidi Christensen"], "https://doi.org/10.21437/Interspeech.2018-1764", 5, "interspeech", 2018]], "Juncheng Li": [0, ["Comparing the Max and Noisy-Or Pooling Functions in Multiple Instance Learning for Weakly Supervised Sequence Learning Tasks", ["Yun Wang", "Juncheng Li", "Florian Metze"], "https://doi.org/10.21437/Interspeech.2018-990", 5, "interspeech", 2018], ["Multiple Instance Deep Learning for Weakly Supervised Small-Footprint Audio Event Detection", ["Shao-Yen Tseng", "Juncheng Li", "Yun Wang", "Florian Metze", "Joseph Szurley", "Samarjit Das"], "https://doi.org/10.21437/Interspeech.2018-1120", 5, "interspeech", 2018]], "Murali Karthick Baskar": [0, ["BUT OpenSAT 2017 Speech Recognition System", ["Martin Karafiat", "Murali Karthick Baskar", "Igor Szoke", "Vladimir Malenovsky", "Karel Vesely", "Frantisek Grezl", "Lukas Burget", "Jan Cernocky"], "https://doi.org/10.21437/Interspeech.2018-2457", 5, "interspeech", 2018], ["BUT System for Low Resource Indian Language ASR", ["Bhargav Pulugundla", "Murali Karthick Baskar", "Santosh Kesiraju", "Ekaterina Egorova", "Martin Karafiat", "Lukas Burget", "Jan Cernocky"], "https://doi.org/10.21437/Interspeech.2018-1302", 5, "interspeech", 2018]], "Longbiao Wang": [1.2193843957025545e-15, ["Multiple Phase Information Combination for Replay Attacks Detection", ["Dongbo Li", "Longbiao Wang", "Jianwu Dang", "Meng Liu", "Zeyan Oo", "Seiichi Nakagawa", "Haotian Guan", "Xiangang Li"], "https://doi.org/10.21437/Interspeech.2018-2001", 5, "interspeech", 2018], ["Revealing Spatiotemporal Brain Dynamics of Speech Production Based on EEG and Eye Movement", ["Bin Zhao", "Jinfeng Huang", "Gaoyan Zhang", "Jianwu Dang", "Minbo Chen", "YingjianFu", "Longbiao Wang"], "https://doi.org/10.21437/Interspeech.2018-1908", 5, "interspeech", 2018], ["Speech Emotion Recognition by Combining Amplitude and Phase Information Using Convolutional Neural Network", ["Lili Guo", "Longbiao Wang", "Jianwu Dang", "Linjuan Zhang", "Haotian Guan", "Xiangang Li"], "https://doi.org/10.21437/Interspeech.2018-2156", 5, "interspeech", 2018]], "Nan Yan": [0, ["Acoustic Features Associated with Sustained Vowel and Continuous Speech Productions by Chinese Children with Functional Articulation Disorders", ["Wang Zhang", "Xiangquan Gui", "Tianqi Wang", "Manwa L. Ng", "Feng Yang", "Lan Wang", "Nan Yan"], "https://doi.org/10.21437/Interspeech.2018-1521", 5, "interspeech", 2018]], "Santosh Kesiraju": [0, ["BUT System for Low Resource Indian Language ASR", ["Bhargav Pulugundla", "Murali Karthick Baskar", "Santosh Kesiraju", "Ekaterina Egorova", "Martin Karafiat", "Lukas Burget", "Jan Cernocky"], "https://doi.org/10.21437/Interspeech.2018-1302", 5, "interspeech", 2018], ["i-Vectors in Language Modeling: An Efficient Way of Domain Adaptation for Feed-Forward Models", ["Karel Benes", "Santosh Kesiraju", "Lukas Burget"], "https://doi.org/10.21437/Interspeech.2018-1070", 5, "interspeech", 2018]], "Claude Barras": [0, ["Neural Speech Turn Segmentation and Affinity Propagation for Speaker Diarization", ["Ruiqing Yin", "Herve Bredin", "Claude Barras"], "https://doi.org/10.21437/Interspeech.2018-1750", 5, "interspeech", 2018]], "Kanru Hua": [0, ["Nebula: F0 Estimation and Voicing Detection by Modeling the Statistical Properties of Feature Extractors", ["Kanru Hua"], "https://doi.org/10.21437/Interspeech.2018-1258", 5, "interspeech", 2018]], "Timothy Greer": [0, ["Computational Modeling of Conversational Humor in Psychotherapy", ["Anil Ramakrishna", "Timothy Greer", "David C. Atkins", "Shrikanth Narayanan"], "https://doi.org/10.21437/Interspeech.2018-1583", 5, "interspeech", 2018]], "Win Thuzar Kyaw": [0, ["Analysis of L2 Learners' Progress of Distinguishing Mandarin Tone 2 and Tone 3", ["Yue Sun", "Win Thuzar Kyaw", "Jinsong Zhang", "Yoshinori Sagisaka"], "https://doi.org/10.21437/Interspeech.2018-1983", 5, "interspeech", 2018]], "Ondrej Glembek": [0, ["BUT System for DIHARD Speech Diarization Challenge 2018", ["Mireia Diez", "Federico Landini", "Lukas Burget", "Johan Rohdin", "Anna Silnova", "Katerina Zmolikova", "Ondrej Novotny", "Karel Vesely", "Ondrej Glembek", "Oldrich Plchot", "Ladislav Mosner", "Pavel Matejka"], "https://doi.org/10.21437/Interspeech.2018-1749", 5, "interspeech", 2018]], "Evdokia Kazimirova": [0, ["Automatic Detection of Multi-speaker Fragments with High Time Resolution", ["Evdokia Kazimirova", "Andrey Belyaev"], "https://doi.org/10.21437/Interspeech.2018-1878", 5, "interspeech", 2018]], "Chetan Naik": [0, ["Contextual Slot Carryover for Disparate Schemas", ["Chetan Naik", "Arpit Gupta", "Hancheng Ge", "Lambert Mathias", "Ruhi Sarikaya"], "https://doi.org/10.21437/Interspeech.2018-1035", 5, "interspeech", 2018]], "N. P. Narendra": [0, ["Dysarthric Speech Classification Using Glottal Features Computed from Non-words, Words and Sentences", ["N. P. Narendra", "Paavo Alku"], "https://doi.org/10.21437/Interspeech.2018-1059", 5, "interspeech", 2018]], "Jon Barker": [0, ["On the Usefulness of the Speech Phase Spectrum for Pitch Extraction", ["Erfan Loweimi", "Jon Barker", "Thomas Hain"], "https://doi.org/10.21437/Interspeech.2018-1062", 5, "interspeech", 2018], ["The Fifth 'CHiME' Speech Separation and Recognition Challenge: Dataset, Task and Baselines", ["Jon Barker", "Shinji Watanabe", "Emmanuel Vincent", "Jan Trmal"], "https://doi.org/10.21437/Interspeech.2018-1768", 5, "interspeech", 2018], ["DNN Driven Speaker Independent Audio-Visual Mask Estimation for Speech Separation", ["Mandar Gogate", "Ahsan Adeel", "Ricard Marxer", "Jon Barker", "Amir Hussain"], "https://doi.org/10.21437/Interspeech.2018-2516", 5, "interspeech", 2018]], "Alexander Sorin": [0, ["The IBM Virtual Voice Creator", ["Alexander Sorin", "Slava Shechtman", "Zvi Kons", "Ron Hoory", "Shay Ben-David", "Joe Pavitt", "Shai Rozenberg", "Carmel Rabinovitz", "Tal Drory"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3011.html", 2, "interspeech", 2018], ["Data Augmentation Improves Recognition of Foreign Accented Speech", ["Takashi Fukuda", "Raul Fernandez", "Andrew Rosenberg", "Samuel Thomas", "Bhuvana Ramabhadran", "Alexander Sorin", "Gakuto Kurata"], "https://doi.org/10.21437/Interspeech.2018-1211", 5, "interspeech", 2018]], "Prasenjit Dey": [0, ["End-To-End Audio Replay Attack Detection Using Deep Convolutional Networks with Attention", ["Francis Tom", "Mohit Jain", "Prasenjit Dey"], "https://doi.org/10.21437/Interspeech.2018-2279", 5, "interspeech", 2018]], "Colleen Kavanagh": [0, ["The Individual and the System: Assessing the Stability of the Output of a Semi-automatic Forensic Voice Comparison System", ["Vincent Hughes", "Philip Harrison", "Paul Foulkes", "Peter French", "Colleen Kavanagh", "Eugenia San Segundo Fernandez"], "https://doi.org/10.21437/Interspeech.2018-1649", 5, "interspeech", 2018]], "Mostafa Ali Shahin": [0, ["Anomaly Detection Approach for Pronunciation Verification of Disordered Speech Using Speech Attribute Features", ["Mostafa Ali Shahin", "Beena Ahmed", "Jim X. Ji", "Kirrie J. Ballard"], "https://doi.org/10.21437/Interspeech.2018-1319", 5, "interspeech", 2018]], "Sara Oliveira": [0, ["Machine Learning Powered Data Platform for High-Quality Speech and NLP Workflows", ["Joao Freitas", "Jorge Ribeiro", "Daan Baldewijns", "Sara Oliveira", "Daniela Braga"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3033.html", 2, "interspeech", 2018]], "Joseph Szurley": [0, ["Multiple Instance Deep Learning for Weakly Supervised Small-Footprint Audio Event Detection", ["Shao-Yen Tseng", "Juncheng Li", "Yun Wang", "Florian Metze", "Joseph Szurley", "Samarjit Das"], "https://doi.org/10.21437/Interspeech.2018-1120", 5, "interspeech", 2018]], "Harishchandra Dubey": [0, ["Robust Speaker Clustering using Mixtures of von Mises-Fisher Distributions for Naturalistic Audio Streams", ["Harishchandra Dubey", "Abhijeet Sangwan", "John H. L. Hansen"], "https://doi.org/10.21437/Interspeech.2018-50", 5, "interspeech", 2018]], "Aoife Cahill": [0, ["Improvements to an Automated Content Scoring System for Spoken CALL Responses: the ETS Submission to the Second Spoken CALL Shared Task", ["Keelan Evanini", "Matthew Mulholland", "Rutuja Ubale", "Yao Qian", "Robert A. Pugh", "Vikram Ramanarayanan", "Aoife Cahill"], "https://doi.org/10.21437/Interspeech.2018-2362", 5, "interspeech", 2018]], "Yushi Aono": [0, ["Neural Error Corrective Language Models for Automatic Speech Recognition", ["Tomohiro Tanaka", "Ryo Masumura", "Hirokazu Masataki", "Yushi Aono"], "https://doi.org/10.21437/Interspeech.2018-1430", 5, "interspeech", 2018], ["Role Play Dialogue Aware Language Models Based on Conditional Hierarchical Recurrent Encoder-Decoder", ["Ryo Masumura", "Tomohiro Tanaka", "Atsushi Ando", "Hirokazu Masataki", "Yushi Aono"], "https://doi.org/10.21437/Interspeech.2018-2185", 5, "interspeech", 2018], ["Automatic DNN Node Pruning Using Mixture Distribution-based Group Regularization", ["Tsukasa Yoshida", "Takafumi Moriya", "Kazuho Watanabe", "Yusuke Shinohara", "Yoshikazu Yamaguchi", "Yushi Aono"], "https://doi.org/10.21437/Interspeech.2018-2062", 5, "interspeech", 2018], ["Automatic Question Detection from Acoustic and Phonetic Features Using Feature-wise Pre-training", ["Atsushi Ando", "Reine Asakawa", "Ryo Masumura", "Hosana Kamiyama", "Satoshi Kobashikawa", "Yushi Aono"], "https://doi.org/10.21437/Interspeech.2018-1755", 5, "interspeech", 2018], ["Multi-task Learning with Augmentation Strategy for Acoustic-to-word Attention-based Encoder-decoder Speech Recognition", ["Takafumi Moriya", "Sei Ueno", "Yusuke Shinohara", "Marc Delcroix", "Yoshikazu Yamaguchi", "Yushi Aono"], "https://doi.org/10.21437/Interspeech.2018-1866", 5, "interspeech", 2018], ["Encoder Transfer for Attention-based Acoustic-to-word Speech Recognition", ["Sei Ueno", "Takafumi Moriya", "Masato Mimura", "Shinsuke Sakai", "Yusuke Shinohara", "Yoshikazu Yamaguchi", "Yushi Aono", "Tatsuya Kawahara"], "https://doi.org/10.21437/Interspeech.2018-1424", 5, "interspeech", 2018]], "Mingyang Zhang": [0, ["A Voice Conversion Framework with Tandem Feature Sparse Representation and Speaker-Adapted WaveNet Vocoder", ["Berrak Sisman", "Mingyang Zhang", "Haizhou Li"], "https://doi.org/10.21437/Interspeech.2018-1131", 5, "interspeech", 2018]], "Nima Mesgarani": [0, ["Real-time Single-channel Dereverberation and Separation with Time-domain Audio Separation Network", ["Yi Luo", "Nima Mesgarani"], "https://doi.org/10.21437/Interspeech.2018-2290", 5, "interspeech", 2018], ["Music Source Activity Detection and Separation Using Deep Attractor Network", ["Rajath Kumar", "Yi Luo", "Nima Mesgarani"], "https://doi.org/10.21437/Interspeech.2018-2326", 5, "interspeech", 2018], ["Speech Processing in the Human Brain Meets Deep Learning", ["Nima Mesgarani"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/4007.html", 1, "interspeech", 2018]], "Rohit M. A": [0, ["Acoustic-Prosodic Features of Tabla Bol Recitation and Correspondence with the Tabla Imitation", ["Rohit M. A", "Preeti Rao"], "https://doi.org/10.21437/Interspeech.2018-1692", 5, "interspeech", 2018]], "Torrey Creed": [0, ["Language Features for Automated Evaluation of Cognitive Behavior Psychotherapy Sessions", ["Nikolaos Flemotomos", "Victor R. Martinez", "James Gibson", "David C. Atkins", "Torrey Creed", "Shrikanth Narayanan"], "https://doi.org/10.21437/Interspeech.2018-1518", 5, "interspeech", 2018]], "Japhet Debrah": [0, ["GlobalTIMIT: Acoustic-Phonetic Datasets for the World's Languages", ["Nattanun Chanchaochai", "Christopher Cieri", "Japhet Debrah", "Hongwei Ding", "Yue Jiang", "Sishi Liao", "Mark Liberman", "Jonathan Wright", "Jiahong Yuan", "Juhong Zhan", "Yuqing Zhan"], "https://doi.org/10.21437/Interspeech.2018-1185", 5, "interspeech", 2018]], "Imed Laaridh": [0, ["Automatic Evaluation of Speech Intelligibility Based on I-vectors in the Context of Head and Neck Cancers", ["Imed Laaridh", "Corinne Fredouille", "Alain Ghio", "Muriel Lalain", "Virginie Woisard"], "https://doi.org/10.21437/Interspeech.2018-1266", 5, "interspeech", 2018], ["Perceptual and Automatic Evaluations of the Intelligibility of Speech Degraded by Noise Induced Hearing Loss Simulation", ["Imed Laaridh", "Julien Tardieu", "Cynthia Magnen", "Pascal Gaillard", "Jerome Farinas", "Julien Pinquier"], "https://doi.org/10.21437/Interspeech.2018-1264", 5, "interspeech", 2018]], "Lauri Juvela": [0, ["Time-regularized Linear Prediction for Noise-robust Extraction of the Spectral Envelope of Speech", ["Manu Airaksinen", "Lauri Juvela", "Okko Rasanen", "Paavo Alku"], "https://doi.org/10.21437/Interspeech.2018-1230", 5, "interspeech", 2018], ["Speaker-independent Raw Waveform Model for Glottal Excitation", ["Lauri Juvela", "Vassilis Tsiaras", "Bajibabu Bollepalli", "Manu Airaksinen", "Junichi Yamagishi", "Paavo Alku"], "https://doi.org/10.21437/Interspeech.2018-1635", 5, "interspeech", 2018]], "Dominik Schiller": [0, ["Deep Learning in Paralinguistic Recognition Tasks: Are Hand-crafted Features Still Relevant?", ["Johannes Wagner", "Dominik Schiller", "Andreas Seiderer", "Elisabeth Andre"], "https://doi.org/10.21437/Interspeech.2018-1238", 5, "interspeech", 2018]], "Alejandrina Cristia": [0, ["The ACLEW DiViMe: An Easy-to-use Diarization Tool", ["Adrien Le Franc", "Eric Riebling", "Julien Karadayi", "Yun Wang", "Camila Scaff", "Florian Metze", "Alejandrina Cristia"], "https://doi.org/10.21437/Interspeech.2018-2324", 5, "interspeech", 2018], ["Talker Diarization in the Wild: the Case of Child-centered Daylong Audio-recordings", ["Alejandrina Cristia", "Shobhana Ganesh", "Marisa Casillas", "Sriram Ganapathy"], "https://doi.org/10.21437/Interspeech.2018-2078", 5, "interspeech", 2018], ["Automated Classification of Children's Linguistic versus Non-Linguistic Vocalisations", ["Zixing Zhang", "Alejandrina Cristia", "Anne A. Warlaumont", "Bjorn W. Schuller"], "https://doi.org/10.21437/Interspeech.2018-2523", 5, "interspeech", 2018]], "Wonyong Sung": [0.8276381641626358, ["Character-level Language Modeling with Gated Hierarchical Recurrent Neural Networks", ["Iksoo Choi", "Jinhwan Park", "Wonyong Sung"], "https://doi.org/10.21437/Interspeech.2018-1727", 5, "interspeech", 2018], ["Hierarchical Recurrent Neural Networks for Acoustic Modeling", ["Jinhwan Park", "Iksoo Choi", "Yoonho Boo", "Wonyong Sung"], "https://doi.org/10.21437/Interspeech.2018-1797", 5, "interspeech", 2018]], "Dongyan Huang": [0, ["Investigation on Joint Representation Learning for Robust Feature Extraction in Speech Emotion Recognition", ["Danqing Luo", "Yuexian Zou", "Dongyan Huang"], "https://doi.org/10.21437/Interspeech.2018-1832", 5, "interspeech", 2018]], "Farzaneh Ahmadi": [0, ["Designing a Pneumatic Bionic Voice Prosthesis - A Statistical Approach for Source Excitation Generation", ["Farzaneh Ahmadi", "Tomoki Toda"], "https://doi.org/10.21437/Interspeech.2018-1043", 5, "interspeech", 2018]], "Shih-Chii Liu": [0, ["Multi-channel Attention for End-to-End Speech Recognition", ["Stefan Braun", "Daniel Neil", "Jithendar Anumula", "Enea Ceolini", "Shih-Chii Liu"], "https://doi.org/10.21437/Interspeech.2018-1301", 5, "interspeech", 2018], ["Speaker Activity Detection and Minimum Variance Beamforming for Source Separation", ["Enea Ceolini", "Jithendar Anumula", "Adrian E. G. Huber", "Ilya Kiselev", "Shih-Chii Liu"], "https://doi.org/10.21437/Interspeech.2018-1606", 5, "interspeech", 2018]], "Rahul Krishnamurthy": [0, ["Automatic Glottis Localization and Segmentation in Stroboscopic Videos Using Deep Neural Network", ["M. V. Achuth Rao", "Rahul Krishnamurthy", "Pebbili Gopikishore", "Veeramani Priyadharshini", "Prasanta Kumar Ghosh"], "https://doi.org/10.21437/Interspeech.2018-2572", 5, "interspeech", 2018]], "Kuan Chen": [0, ["High-quality Voice Conversion Using Spectrogram-Based WaveNet Vocoder", ["Kuan Chen", "Bo Chen", "Jiahao Lai", "Kai Yu"], "https://doi.org/10.21437/Interspeech.2018-1528", 5, "interspeech", 2018]], "Zhuohao Chen": [0, ["Using Prosodic and Lexical Information for Learning Utterance-level Behaviors in Psychotherapy", ["Karan Singla", "Zhuohao Chen", "Nikolaos Flemotomos", "James Gibson", "Dogan Can", "David C. Atkins", "Shrikanth Narayanan"], "https://doi.org/10.21437/Interspeech.2018-2551", 5, "interspeech", 2018]], "K. Samudravijaya": [0, ["AGROASSAM: A Web Based Assamese Speech Recognition Application for Retrieving Agricultural Commodity Price and Weather Information", ["Abhishek Dey", "Abhash Deka", "Siddika Imani", "Barsha Deka", "Rohit Sinha", "S. R. Mahadeva Prasanna", "Priyankoo Sarmah", "K. Samudravijaya", "S. R. Nirmala"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3048.html", 2, "interspeech", 2018]], "Trung Bui": [0, ["A Framework for Speech Recognition Benchmarking", ["Franck Dernoncourt", "Trung Bui", "Walter Chang"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3003.html", 2, "interspeech", 2018]], "Yuki Mitsufuji": [0, ["PhaseNet: Discretized Phase Modeling with Deep Neural Networks for Audio Source Separation", ["Naoya Takahashi", "Purvi Agrawal", "Nabarun Goswami", "Yuki Mitsufuji"], "https://doi.org/10.21437/Interspeech.2018-1773", 5, "interspeech", 2018]], "Erik Marchi": [0, ["Efficient Voice Trigger Detection for Low Resource Hardware", ["Siddharth Sigtia", "Rob Haynes", "Hywel Richards", "Erik Marchi", "John Bridle"], "https://doi.org/10.21437/Interspeech.2018-2204", 5, "interspeech", 2018]], "Yue Jiang": [0, ["GlobalTIMIT: Acoustic-Phonetic Datasets for the World's Languages", ["Nattanun Chanchaochai", "Christopher Cieri", "Japhet Debrah", "Hongwei Ding", "Yue Jiang", "Sishi Liao", "Mark Liberman", "Jonathan Wright", "Jiahong Yuan", "Juhong Zhan", "Yuqing Zhan"], "https://doi.org/10.21437/Interspeech.2018-1185", 5, "interspeech", 2018]], "Sheng Li": [0, ["Temporal Attentive Pooling for Acoustic Event Detection", ["Xugang Lu", "Peng Shen", "Sheng Li", "Yu Tsao", "Hisashi Kawai"], "https://doi.org/10.21437/Interspeech.2018-1552", 4, "interspeech", 2018], ["Feature Representation of Short Utterances Based on Knowledge Distillation for Spoken Language Identification", ["Peng Shen", "Xugang Lu", "Sheng Li", "Hisashi Kawai"], "https://doi.org/10.21437/Interspeech.2018-1519", 5, "interspeech", 2018], ["Improving CTC-based Acoustic Model with Very Deep Residual Time-delay Neural Networks", ["Sheng Li", "Xugang Lu", "Ryoichi Takashima", "Peng Shen", "Tatsuya Kawahara", "Hisashi Kawai"], "https://doi.org/10.21437/Interspeech.2018-1475", 5, "interspeech", 2018]], "Kwanchiva Thangthai": [0, ["Building Large-vocabulary Speaker-independent Lipreading Systems", ["Kwanchiva Thangthai", "Richard W. Harvey"], "https://doi.org/10.21437/Interspeech.2018-2112", 5, "interspeech", 2018]], "Haizhou Li": [0, ["Wavelet Analysis of Speaker Dependent and Independent Prosody for Voice Conversion", ["Berrak Sisman", "Haizhou Li"], "https://doi.org/10.21437/Interspeech.2018-1499", 5, "interspeech", 2018], ["Learning Acoustic Word Embeddings with Temporal Context for Query-by-Example Speech Search", ["Yougen Yuan", "Cheung-Chi Leung", "Lei Xie", "Hongjie Chen", "Bin Ma", "Haizhou Li"], "https://doi.org/10.21437/Interspeech.2018-1010", 5, "interspeech", 2018], ["Mandarin-English Code-switching Speech Recognition", ["Haihua Xu", "Van Tung Pham", "Zin Tun Kyaw", "Zhi Hao Lim", "Eng Siong Chng", "Haizhou Li"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3014.html", 2, "interspeech", 2018], ["Co-whitening of I-vectors for Short and Long Duration Speaker Verification", ["Longting Xu", "Kong-Aik Lee", "Haizhou Li", "Zhen Yang"], "https://doi.org/10.21437/Interspeech.2018-1246", 5, "interspeech", 2018], ["Automatic Pronunciation Evaluation of Singing", ["Chitralekha Gupta", "Haizhou Li", "Ye Wang"], "https://doi.org/10.21437/Interspeech.2018-1267", 5, "interspeech", 2018], ["A Voice Conversion Framework with Tandem Feature Sparse Representation and Speaker-Adapted WaveNet Vocoder", ["Berrak Sisman", "Mingyang Zhang", "Haizhou Li"], "https://doi.org/10.21437/Interspeech.2018-1131", 5, "interspeech", 2018], ["A Shifted Delta Coefficient Objective for Monaural Speech Separation Using Multi-task Learning", ["Chenglin Xu", "Wei Rao", "Eng Siong Chng", "Haizhou Li"], "https://doi.org/10.21437/Interspeech.2018-1150", 5, "interspeech", 2018]], "Piotr Szymanski": [0, ["Punctuation Prediction Model for Conversational Speech", ["Piotr Zelasko", "Piotr Szymanski", "Jan Mizgajski", "Adrian Szymczak", "Yishay Carmiel", "Najim Dehak"], "https://doi.org/10.21437/Interspeech.2018-1096", 5, "interspeech", 2018]], "Sahar Ghannay": [0, ["Task Specific Sentence Embeddings for ASR Error Detection", ["Sahar Ghannay", "Yannick Esteve", "Nathalie Camelin"], "https://doi.org/10.21437/Interspeech.2018-2211", 5, "interspeech", 2018]], "Alberto Abad": [0, ["Patient Privacy in Paralinguistic Tasks", ["Francisco Teixeira", "Alberto Abad", "Isabel Trancoso"], "https://doi.org/10.21437/Interspeech.2018-2186", 5, "interspeech", 2018]], "Olga Maxwell": [0, ["Homogeneity vs Heterogeneity in Indian English: Investigating Influences of L1 on f0 Range", ["Olga Maxwell", "Elinor Payne", "Rosey Billington"], "https://doi.org/10.21437/Interspeech.2018-1476", 5, "interspeech", 2018]], "Tiago H. Falk": [0, ["Investigating Speech Enhancement and Perceptual Quality for Speech Emotion Recognition", ["Anderson R. Avila", "Md. Jahangir Alam", "Douglas D. OShaughnessy", "Tiago H. Falk"], "https://doi.org/10.21437/Interspeech.2018-2350", 5, "interspeech", 2018]], "Ondrej Klejch": [0, ["Learning to Adapt: A Meta-learning Approach for Speaker Adaptation", ["Ondrej Klejch", "Joachim Fainberg", "Peter Bell"], "https://doi.org/10.21437/Interspeech.2018-1244", 5, "interspeech", 2018]], "Toshio Irino": [0, ["Multi-resolution Gammachirp Envelope Distortion Index for Intelligibility Prediction of Noisy Speech", ["Katsuhiko Yamamoto", "Toshio Irino", "Narumi Ohashi", "Shoko Araki", "Keisuke Kinoshita", "Tomohiro Nakatani"], "https://doi.org/10.21437/Interspeech.2018-1291", 5, "interspeech", 2018], ["Frequency Domain Variants of Velvet Noise and Their Application to Speech Processing and Synthesis", ["Hideki Kawahara", "Ken-Ichi Sakakibara", "Masanori Morise", "Hideki Banno", "Tomoki Toda", "Toshio Irino"], "https://doi.org/10.21437/Interspeech.2018-43", 5, "interspeech", 2018]], "Ali Yesilkanat": [0, ["LSTM Based Cross-corpus and Cross-task Acoustic Emotion Recognition", ["Heysem Kaya", "Dmitrii Fedotov", "Ali Yesilkanat", "Oxana Verkholyak", "Yang Zhang", "Alexey Karpov"], "https://doi.org/10.21437/Interspeech.2018-2298", 5, "interspeech", 2018]], "Simon Petitrenaud": [0, ["S4D: Speaker Diarization Toolkit in Python", ["Pierre-Alexandre Broux", "Florent Desnous", "Anthony Larcher", "Simon Petitrenaud", "Jean Carrive", "Sylvain Meignier"], "https://doi.org/10.21437/Interspeech.2018-1232", 5, "interspeech", 2018]], "Nakamasa Inoue": [0, ["Detecting Alzheimer's Disease Using Gated Convolutional Neural Network from Audio Data", ["Tifani Warnita", "Nakamasa Inoue", "Koichi Shinoda"], "https://doi.org/10.21437/Interspeech.2018-1713", 5, "interspeech", 2018], ["I-vector Transformation Using Conditional Generative Adversarial Networks for Short Utterance Speaker Verification", ["Jiacen Zhang", "Nakamasa Inoue", "Koichi Shinoda"], "https://doi.org/10.21437/Interspeech.2018-1680", 5, "interspeech", 2018]], "Ian Williams": [0, ["Semantic Lattice Processing in Contextual Automatic Speech Recognition for Google Assistant", ["Leonid Velikovich", "Ian Williams", "Justin Scheiner", "Petar S. Aleksic", "Pedro J. Moreno", "Michael Riley"], "https://doi.org/10.21437/Interspeech.2018-2453", 5, "interspeech", 2018], ["Contextual Speech Recognition in End-to-end Neural Network Systems Using Beam Search", ["Ian Williams", "Anjuli Kannan", "Petar S. Aleksic", "David Rybach", "Tara N. Sainath"], "https://doi.org/10.21437/Interspeech.2018-2416", 5, "interspeech", 2018]], "Rivka Levitan": [0, ["Deep Personality Recognition for Deception Detection", ["Guozhen An", "Sarah Ita Levitan", "Julia Hirschberg", "Rivka Levitan"], "https://doi.org/10.21437/Interspeech.2018-2269", 5, "interspeech", 2018], ["Lexical and Acoustic Deep Learning Model for Personality Recognition", ["Guozhen An", "Rivka Levitan"], "https://doi.org/10.21437/Interspeech.2018-2263", 5, "interspeech", 2018]], "Kyung Seo Ki": [0, ["Automatic Miscue Detection Using RNN Based Models with Data Augmentation", ["Yoon Seok Hong", "Kyung Seo Ki", "Gahgene Gweon"], "https://doi.org/10.21437/Interspeech.2018-1644", 5, "interspeech", 2018]], "Moira-Phoebe Huet": [0, ["Who Are You Listening to? Towards a Dynamic Measure of Auditory Attention to Speech-on-speech", ["Moira-Phoebe Huet", "Christophe Micheyl", "Etienne Gaudrain", "Etienne Parizet"], "https://doi.org/10.21437/Interspeech.2018-2053", 4, "interspeech", 2018]], "Biing-Hwang Fred Juang": [0, ["Cycle-Consistent Speech Enhancement", ["Zhong Meng", "Jinyu Li", "Yifan Gong", "Biing-Hwang Fred Juang"], "https://doi.org/10.21437/Interspeech.2018-2409", 5, "interspeech", 2018], ["Adversarial Feature-Mapping for Speech Enhancement", ["Zhong Meng", "Jinyu Li", "Yifan Gong", "Biing-Hwang Fred Juang"], "https://doi.org/10.21437/Interspeech.2018-2461", 5, "interspeech", 2018]], "Rui Liu": [0, ["Improving Mongolian Phrase Break Prediction by Using Syllable and Morphological Embeddings with BiLSTM Model", ["Rui Liu", "Feilong Bao", "Guanglai Gao", "Hui Zhang", "Yonghe Wang"], "https://doi.org/10.21437/Interspeech.2018-1706", 5, "interspeech", 2018]], "Paivi Virkkunen": [0, ["Prominence-based Evaluation of L2 Prosody", ["Heini Kallio", "Antti Suni", "Paivi Virkkunen", "Juraj Simko"], "https://doi.org/10.21437/Interspeech.2018-1873", 5, "interspeech", 2018]], "Andrey Shulipa": [0, ["Triplet Loss Based Cosine Similarity Metric Learning for Text-independent Speaker Recognition", ["Sergey Novoselov", "Vadim Shchemelinin", "Andrey Shulipa", "Alexander Kozlov", "Ivan Kremnev"], "https://doi.org/10.21437/Interspeech.2018-1209", 5, "interspeech", 2018]], "Da-Rong Liu": [0, ["Completely Unsupervised Phoneme Recognition by Adversarially Learning Mapping Relationships from Audio Embeddings", ["Da-Rong Liu", "Kuan-Yu Chen", "Hung-yi Lee", "Lin-Shan Lee"], "https://doi.org/10.21437/Interspeech.2018-1800", 5, "interspeech", 2018]], "Jinhwan Park": [0.9726525098085403, ["Character-level Language Modeling with Gated Hierarchical Recurrent Neural Networks", ["Iksoo Choi", "Jinhwan Park", "Wonyong Sung"], "https://doi.org/10.21437/Interspeech.2018-1727", 5, "interspeech", 2018], ["Hierarchical Recurrent Neural Networks for Acoustic Modeling", ["Jinhwan Park", "Iksoo Choi", "Yoonho Boo", "Wonyong Sung"], "https://doi.org/10.21437/Interspeech.2018-1797", 5, "interspeech", 2018]], "Brita Elvevag": [0, ["Modeling Self-Reported and Observed Affect from Speech", ["Jian Cheng", "Jared Bernstein", "Elizabeth Rosenfeld", "Peter W. Foltz", "Alex S. Cohen", "Terje B. Holmlund", "Brita Elvevag"], "https://doi.org/10.21437/Interspeech.2018-2222", 5, "interspeech", 2018]], "Ajay Srinivasamurthy": [0, ["Iterative Learning of Speech Recognition Models for Air Traffic Control", ["Ajay Srinivasamurthy", "Petr Motlicek", "Mittul Singh", "Youssef Oualil", "Matthias Kleinert", "Heiko Ehr", "Hartmut Helmke"], "https://doi.org/10.21437/Interspeech.2018-1447", 5, "interspeech", 2018]], "Myung Jong Kim": [0.9044821113348007, ["Automatic Speech Recognition with Articulatory Information and a Unified Dictionary for Hindi, Marathi, Bengali and Oriya", ["Debadatta Dash", "Myung Jong Kim", "Kristin Teplansky", "Jun Wang"], "https://doi.org/10.21437/Interspeech.2018-2122", 5, "interspeech", 2018], ["Automatic Early Detection of Amyotrophic Lateral Sclerosis from Intelligible Speech Using Convolutional Neural Networks", ["Kwanghoon An", "Myung Jong Kim", "Kristin Teplansky", "Jordan R. Green", "Thomas Campbell", "Yana Yunusova", "Daragh Heitzman", "Jun Wang"], "https://doi.org/10.21437/Interspeech.2018-2496", 5, "interspeech", 2018], ["Dysarthric Speech Recognition Using Convolutional LSTM Neural Network", ["Myung Jong Kim", "Beiming Cao", "Kwanghoon An", "Jun Wang"], "https://doi.org/10.21437/Interspeech.2018-2250", 5, "interspeech", 2018], ["Articulation-to-Speech Synthesis Using Articulatory Flesh Point Sensors' Orientation Information", ["Beiming Cao", "Myung Jong Kim", "Jun R. Wang", "Jan P. H. van Santen", "Ted Mau", "Jun Wang"], "https://doi.org/10.21437/Interspeech.2018-2484", 5, "interspeech", 2018]], "Zhen Lian": [0, ["Speech Emotion Recognition from Variable-Length Inputs with Triplet Loss Function", ["Jian Huang", "Ya Li", "Jianhua Tao", "Zhen Lian"], "https://doi.org/10.21437/Interspeech.2018-1432", 5, "interspeech", 2018]], "Victor Ungureanu": [0, ["Experiments with Training Corpora for Statistical Text-to-speech Systems", ["Monika Podsiadlo", "Victor Ungureanu"], "https://doi.org/10.21437/Interspeech.2018-2400", 5, "interspeech", 2018]], "Pebbili Gopikishore": [0, ["Automatic Glottis Localization and Segmentation in Stroboscopic Videos Using Deep Neural Network", ["M. V. Achuth Rao", "Rahul Krishnamurthy", "Pebbili Gopikishore", "Veeramani Priyadharshini", "Prasanta Kumar Ghosh"], "https://doi.org/10.21437/Interspeech.2018-2572", 5, "interspeech", 2018]], "Girija Ramesan Karthik": [0, ["Subband Weighting for Binaural Speech Source Localization", ["Girija Ramesan Karthik", "Parth Suresh", "Prasanta Kumar Ghosh"], "https://doi.org/10.21437/Interspeech.2018-2173", 5, "interspeech", 2018]], "Abhinav Thanda": [0, ["Global SNR Estimation of Speech Signals Using Entropy and Uncertainty Estimates from Dropout Networks", ["Rohith Aralikatti", "Dilip Kumar Margam", "Tanay Sharma", "Abhinav Thanda", "Shankar M. Venkatesan"], "https://doi.org/10.21437/Interspeech.2018-1884", 5, "interspeech", 2018]], "Kai Yu": [0.007579648867249489, ["Structured Word Embedding for Low Memory Neural Network Language Model", ["Kaiyu Shi", "Kai Yu"], "https://doi.org/10.21437/Interspeech.2018-1057", 5, "interspeech", 2018], ["High-quality Voice Conversion Using Spectrogram-Based WaveNet Vocoder", ["Kuan Chen", "Bo Chen", "Jiahao Lai", "Kai Yu"], "https://doi.org/10.21437/Interspeech.2018-1528", 5, "interspeech", 2018], ["Angular Softmax for Short-Duration Text-independent Speaker Verification", ["Zili Huang", "Shuai Wang", "Kai Yu"], "https://doi.org/10.21437/Interspeech.2018-1545", 5, "interspeech", 2018], ["Knowledge Distillation for Sequence Model", ["Mingkun Huang", "Yongbin You", "Zhehuai Chen", "Yanmin Qian", "Kai Yu"], "https://doi.org/10.21437/Interspeech.2018-1589", 5, "interspeech", 2018]], "Mari Ganesh Kumar": [0, ["Brain-Computer Interface using Electroencephalogram Signatures of Eye Blinks", ["Srihari Maruthachalam", "Sidharth Aggarwal", "Mari Ganesh Kumar", "Mriganka Sur", "Hema A. Murthy"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3019.html", 2, "interspeech", 2018]], "Michail Lagoudakis": [0, ["A Case Study on the Importance of Belief State Representation for Dialogue Policy Management", ["Margarita Kotti", "Vassilios Diakoloukas", "Alexandros Papangelis", "Michail Lagoudakis", "Yannis Stylianou"], "https://doi.org/10.21437/Interspeech.2018-1293", 5, "interspeech", 2018]], "Debadatta Pati": [0, ["Linear Prediction Residual based Short-term Cepstral Features for Replay Attacks Detection", ["Madhusudan Singh", "Debadatta Pati"], "https://doi.org/10.21437/Interspeech.2018-1128", 5, "interspeech", 2018]], "Arindam Jati": [0, ["An Unsupervised Neural Prediction Framework for Learning Speaker Embeddings Using Recurrent Neural Networks", ["Arindam Jati", "Panayiotis G. Georgiou"], "https://doi.org/10.21437/Interspeech.2018-1363", 5, "interspeech", 2018]], "Yongguo Kang": [1.0158878751553857e-06, ["Multi-task WaveNet: A Multi-task Generative Model for Statistical Parametric Speech Synthesis without Fundamental Frequency Conditions", ["Yu Gu", "Yongguo Kang"], "https://doi.org/10.21437/Interspeech.2018-1506", 5, "interspeech", 2018], ["EMPHASIS: An Emotional Phoneme-based Acoustic Model for Speech Synthesis System", ["Hao Li", "Yongguo Kang", "Zhenyu Wang"], "https://doi.org/10.21437/Interspeech.2018-1511", 5, "interspeech", 2018]], "Kiranpreet Nara": [0, ["The Retroflex-dental Contrast in Punjabi Stops and Nasals: A Principal Component Analysis of Ultrasound Images", ["Alexei Kochetov", "Matthew Faytak", "Kiranpreet Nara"], "https://doi.org/10.21437/Interspeech.2018-1457", 5, "interspeech", 2018]], "Nancy Hitschfeld-Kahler": [0, ["A French-Spanish Multimodal Speech Communication Corpus Incorporating Acoustic Data, Facial, Hands and Arms Gestures Information", ["Lucas D. Terissi", "Gonzalo D. Sad", "Mauricio Cerda", "Slim Ouni", "Rodrigo Galvez", "Juan Carlos Gomez", "Bernard Girau", "Nancy Hitschfeld-Kahler"], "https://doi.org/10.21437/Interspeech.2018-2212", 5, "interspeech", 2018]], "Qingsheng Yuan": [0, ["Deep Convolutional Neural Network with Scalogram for Audio Scene Modeling", ["Hangting Chen", "Pengyuan Zhang", "Haichuan Bai", "Qingsheng Yuan", "Xiuguo Bao", "Yonghong Yan"], "https://doi.org/10.21437/Interspeech.2018-1524", 5, "interspeech", 2018]], "Wei Wei": [0, ["Interactions between Vowels and Nasal Codas in Mandarin Speakers' Perception of Nasal Finals", ["Chong Cao", "Wei Wei", "Wei Wang", "Yanlu Xie", "Jinsong Zhang"], "https://doi.org/10.21437/Interspeech.2018-2025", 5, "interspeech", 2018]], "Si Chen": [0, ["Acoustic Analysis of Whispery Voice Disguise in Mandarin Chinese", ["Cuiling Zhang", "Bin Li", "Si Chen", "Yike Yang"], "https://doi.org/10.21437/Interspeech.2018-2598", 4, "interspeech", 2018]], "Yucel Yemez": [0, ["Audio-Visual Prediction of Head-Nod and Turn-Taking Events in Dyadic Interactions", ["Bekir Berker Turker", "Engin Erzin", "Yucel Yemez", "T. Metin Sezgin"], "https://doi.org/10.21437/Interspeech.2018-2215", 5, "interspeech", 2018]], "D. Govind": [0, ["Improved Epoch Extraction from Telephonic Speech Using Chebfun and Zero Frequency Filtering", ["B. Ganga Gowri", "Soman K. P", "D. Govind"], "https://doi.org/10.21437/Interspeech.2018-1173", 5, "interspeech", 2018]], "Hiroaki Kazui": [0, ["Detection of Dementia from Responses to Atypical Questions Asked by Embodied Conversational Agents", ["Tsuyoki Ujiro", "Hiroki Tanaka", "Hiroyoshi Adachi", "Hiroaki Kazui", "Manabu Ikeda", "Takashi Kudo", "Satoshi Nakamura"], "https://doi.org/10.21437/Interspeech.2018-1514", 5, "interspeech", 2018]], "Gilles Degottex": [0, ["Waveform-Based Speaker Representations for Speech Synthesis", ["Moquan Wan", "Gilles Degottex", "Mark J. F. Gales"], "https://doi.org/10.21437/Interspeech.2018-1154", 5, "interspeech", 2018]], "Yonghui Wu": [0.6403691470623016, ["Compression of End-to-End Models", ["Ruoming Pang", "Tara N. Sainath", "Rohit Prabhavalkar", "Suyog Gupta", "Yonghui Wu", "Shuyuan Zhang", "Chung-Cheng Chiu"], "https://doi.org/10.21437/Interspeech.2018-1025", 5, "interspeech", 2018], ["Speech Recognition for Medical Conversations", ["Chung-Cheng Chiu", "Anshuman Tripathi", "Katherine Chou", "Chris Co", "Navdeep Jaitly", "Diana Jaunzeikare", "Anjuli Kannan", "Patrick Nguyen", "Hasim Sak", "Ananth Sankar", "Justin Tansuwan", "Nathan Wan", "Yonghui Wu", "Xuedong Zhang"], "https://doi.org/10.21437/Interspeech.2018-40", 5, "interspeech", 2018]], "Jian Sun": [0.40413545072078705, ["Gated Convolutional Neural Network for Sentence Matching", ["Peixin Chen", "Wu Guo", "Zhi Chen", "Jian Sun", "Lanhua You"], "https://doi.org/10.21437/Interspeech.2018-70", 5, "interspeech", 2018]], "Xiangang Li": [0, ["Multiple Phase Information Combination for Replay Attacks Detection", ["Dongbo Li", "Longbiao Wang", "Jianwu Dang", "Meng Liu", "Zeyan Oo", "Seiichi Nakagawa", "Haotian Guan", "Xiangang Li"], "https://doi.org/10.21437/Interspeech.2018-2001", 5, "interspeech", 2018], ["Speech Emotion Recognition by Combining Amplitude and Phase Information Using Convolutional Neural Network", ["Lili Guo", "Longbiao Wang", "Jianwu Dang", "Linjuan Zhang", "Haotian Guan", "Xiangang Li"], "https://doi.org/10.21437/Interspeech.2018-2156", 5, "interspeech", 2018]], "Alex Waibel": [0, ["Subword and Crossword Units for CTC Acoustic Models", ["Thomas Zenkel", "Ramon Sanabria", "Florian Metze", "Alex Waibel"], "https://doi.org/10.21437/Interspeech.2018-2057", 5, "interspeech", 2018], ["Low-Latency Neural Speech Translation", ["Jan Niehues", "Ngoc-Quan Pham", "Thanh-Le Ha", "Matthias Sperber", "Alex Waibel"], "https://doi.org/10.21437/Interspeech.2018-1055", 5, "interspeech", 2018], ["Term Extraction via Neural Sequence Labeling a Comparative Evaluation of Strategies Using Recurrent Neural Networks", ["Maren Kucza", "Jan Niehues", "Thomas Zenkel", "Alex Waibel", "Sebastian Stuker"], "https://doi.org/10.21437/Interspeech.2018-2017", 5, "interspeech", 2018], ["Neural Language Codes for Multilingual Acoustic Models", ["Markus Muller", "Sebastian Stuker", "Alex Waibel"], "https://doi.org/10.21437/Interspeech.2018-1241", 5, "interspeech", 2018], ["Self-Attentional Acoustic Models", ["Matthias Sperber", "Jan Niehues", "Graham Neubig", "Sebastian Stuker", "Alex Waibel"], "https://doi.org/10.21437/Interspeech.2018-1910", 5, "interspeech", 2018]], "Manu Airaksinen": [0, ["Time-regularized Linear Prediction for Noise-robust Extraction of the Spectral Envelope of Speech", ["Manu Airaksinen", "Lauri Juvela", "Okko Rasanen", "Paavo Alku"], "https://doi.org/10.21437/Interspeech.2018-1230", 5, "interspeech", 2018], ["Speaker-independent Raw Waveform Model for Glottal Excitation", ["Lauri Juvela", "Vassilis Tsiaras", "Bajibabu Bollepalli", "Manu Airaksinen", "Junichi Yamagishi", "Paavo Alku"], "https://doi.org/10.21437/Interspeech.2018-1635", 5, "interspeech", 2018]], "Xiao Chen": [0, ["Cross-Corpora Convolutional Deep Neural Network Dereverberation Preprocessing for Speaker Verification and Speech Enhancement", ["Peter Guzewich", "Stephen A. Zahorian", "Xiao Chen", "Hao Zhang"], "https://doi.org/10.21437/Interspeech.2018-2238", 5, "interspeech", 2018]], "Kandarpa Kumar Sarma": [0, ["Emotion Identification from Raw Speech Signals Using DNNs", ["Mousmita Sarma", "Pegah Ghahremani", "Daniel Povey", "Nagendra Kumar Goel", "Kandarpa Kumar Sarma", "Najim Dehak"], "https://doi.org/10.21437/Interspeech.2018-1353", 5, "interspeech", 2018]], "Rajib Roy": [0, ["PannoMulloKathan: Voice Enabled Mobile App for Agricultural Commodity Price Dissemination in Bengali Language", ["Madhab Pal", "Rajib Roy", "Soma Khan", "Milton Samirakshma Bepari", "Joyanta Basu"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3027.html", 2, "interspeech", 2018]], "Rachid Riad": [0, ["Sampling Strategies in Siamese Networks for Unsupervised Speech Representation Learning", ["Rachid Riad", "Corentin Dancette", "Julien Karadayi", "Neil Zeghidour", "Thomas Schatz", "Emmanuel Dupoux"], "https://doi.org/10.21437/Interspeech.2018-2384", 5, "interspeech", 2018], ["Learning Word Embeddings: Unsupervised Methods for Fixed-size Representations of Variable-length Speech Segments", ["Nils Holzenberger", "Mingxing Du", "Julien Karadayi", "Rachid Riad", "Emmanuel Dupoux"], "https://doi.org/10.21437/Interspeech.2018-2364", 5, "interspeech", 2018]], "C. A. Valliappan": [0, ["Air-Tissue Boundary Segmentation in Real-Time Magnetic Resonance Imaging Video Using Semantic Segmentation with Fully Convolutional Networks", ["C. A. Valliappan", "Renuka Mannem", "Prasanta Kumar Ghosh"], "https://doi.org/10.21437/Interspeech.2018-1939", 5, "interspeech", 2018]], "Laurent Besacier": [0, ["Unsupervised Word Segmentation from Speech with Attention", ["Pierre Godard", "Marcely Zanon Boito", "Lucas Ondel", "Alexandre Berard", "Francois Yvon", "Aline Villavicencio", "Laurent Besacier"], "https://doi.org/10.21437/Interspeech.2018-1308", 5, "interspeech", 2018]], "Gabor Gosztolya": [0, ["General Utterance-Level Feature Extraction for Classifying Crying Sounds, Atypical & Self-Assessed Affect and Heart Beats", ["Gabor Gosztolya", "Tamas Grosz", "Laszlo Toth"], "https://doi.org/10.21437/Interspeech.2018-1076", 5, "interspeech", 2018], ["User-centric Evaluation of Automatic Punctuation in ASR Closed Captioning", ["Mate Akos Tundik", "Gyorgy Szaszak", "Gabor Gosztolya", "Andras Beke"], "https://doi.org/10.21437/Interspeech.2018-1352", 5, "interspeech", 2018], ["Multi-Task Learning of Speech Recognition and Speech Synthesis Parameters for Ultrasound-based Silent Speech Interfaces", ["Laszlo Toth", "Gabor Gosztolya", "Tamas Grosz", "Alexandra Marko", "Tamas Gabor Csapo"], "https://doi.org/10.21437/Interspeech.2018-1078", 5, "interspeech", 2018], ["Identifying Schizophrenia Based on Temporal Parameters in Spontaneous Speech", ["Gabor Gosztolya", "Anita Bagi", "Szilvia Szaloki", "Istvan Szendi", "Ildiko Hoffmann"], "https://doi.org/10.21437/Interspeech.2018-1079", 5, "interspeech", 2018]], "DeLiang Wang": [0.0001271415312658064, ["Robust TDOA Estimation Based on Time-Frequency Masking and Deep Neural Networks", ["Zhong-Qiu Wang", "Xueliang Zhang", "DeLiang Wang"], "https://doi.org/10.21437/Interspeech.2018-1652", 5, "interspeech", 2018], ["A New Framework for Supervised Speech Enhancement in the Time Domain", ["Ashutosh Pandey", "DeLiang Wang"], "https://doi.org/10.21437/Interspeech.2018-1223", 5, "interspeech", 2018], ["End-to-End Speech Separation with Unfolded Iterative Phase Reconstruction", ["Zhong-Qiu Wang", "Jonathan Le Roux", "DeLiang Wang", "John R. Hershey"], "https://doi.org/10.21437/Interspeech.2018-1629", 5, "interspeech", 2018], ["Integrating Spectral and Spatial Features for Multi-Channel Speaker Separation", ["Zhong-Qiu Wang", "DeLiang Wang"], "https://doi.org/10.21437/Interspeech.2018-1940", 5, "interspeech", 2018], ["A Convolutional Recurrent Neural Network for Real-Time Speech Enhancement", ["Ke Tan", "DeLiang Wang"], "https://doi.org/10.21437/Interspeech.2018-1405", 5, "interspeech", 2018], ["All-Neural Multi-Channel Speech Enhancement", ["Zhong-Qiu Wang", "DeLiang Wang"], "https://doi.org/10.21437/Interspeech.2018-1664", 5, "interspeech", 2018], ["Deep Learning for Acoustic Echo Cancellation in Noisy and Double-Talk Scenarios", ["Hao Zhang", "DeLiang Wang"], "https://doi.org/10.21437/Interspeech.2018-1484", 5, "interspeech", 2018], ["A Two-Stage Approach to Noisy Cochannel Speech Separation with Gated Residual Networks", ["Ke Tan", "DeLiang Wang"], "https://doi.org/10.21437/Interspeech.2018-1406", 5, "interspeech", 2018]], "Bjorn Hoffmeister": [0, ["Device-directed Utterance Detection", ["Sri Harish Reddy Mallidi", "Roland Maas", "Kyle Goehner", "Ariya Rastrow", "Spyros Matsoukas", "Bjorn Hoffmeister"], "https://doi.org/10.21437/Interspeech.2018-1531", 4, "interspeech", 2018]], "Raffaele Tavarone": [0, ["Conditional-Computation-Based Recurrent Neural Networks for Computationally Efficient Acoustic Modelling", ["Raffaele Tavarone", "Leonardo Badino"], "https://doi.org/10.21437/Interspeech.2018-2195", 5, "interspeech", 2018]], "Ruifang Ji": [2.161666498068371e-05, ["An End-to-End Text-Independent Speaker Identification System on Short Utterances", ["Ruifang Ji", "Xinyuan Cai", "Xu Bo"], "https://doi.org/10.21437/Interspeech.2018-1058", 5, "interspeech", 2018]], "Shuai Yang": [2.6364129013245474e-07, ["Detection of Glottal Closure Instants from Speech Signals: A Convolutional Neural Network Based Method", ["Shuai Yang", "Zhiyong Wu", "Binbin Shen", "Helen Meng"], "https://doi.org/10.21437/Interspeech.2018-1281", 5, "interspeech", 2018]], "Satoshi Kobashikawa": [0, ["Automatic Question Detection from Acoustic and Phonetic Features Using Feature-wise Pre-training", ["Atsushi Ando", "Reine Asakawa", "Ryo Masumura", "Hosana Kamiyama", "Satoshi Kobashikawa", "Yushi Aono"], "https://doi.org/10.21437/Interspeech.2018-1755", 5, "interspeech", 2018]], "Heiko Ehr": [0, ["Iterative Learning of Speech Recognition Models for Air Traffic Control", ["Ajay Srinivasamurthy", "Petr Motlicek", "Mittul Singh", "Youssef Oualil", "Matthias Kleinert", "Heiko Ehr", "Hartmut Helmke"], "https://doi.org/10.21437/Interspeech.2018-1447", 5, "interspeech", 2018]], "Egor Akhanov": [0, ["LOCUST - Longitudinal Corpus and Toolset for Speaker Verification", ["Evgeny Dmitriev", "Yulia Kim", "Anastasia Matveeva", "Claude Montacie", "Yannick Boulard", "Yadviga Sinyavskaya", "Yulia Zhukova", "Adam Zarazinski", "Egor Akhanov", "Ilya I. Viksnin", "Andrei A. Shlykov", "Maria Usova"], "https://doi.org/10.21437/Interspeech.2018-2412", 5, "interspeech", 2018]], "Thomas Campbell": [0, ["Automatic Early Detection of Amyotrophic Lateral Sclerosis from Intelligible Speech Using Convolutional Neural Networks", ["Kwanghoon An", "Myung Jong Kim", "Kristin Teplansky", "Jordan R. Green", "Thomas Campbell", "Yana Yunusova", "Daragh Heitzman", "Jun Wang"], "https://doi.org/10.21437/Interspeech.2018-2496", 5, "interspeech", 2018]], "Vladimir Malenovsky": [0, ["BUT OpenSAT 2017 Speech Recognition System", ["Martin Karafiat", "Murali Karthick Baskar", "Igor Szoke", "Vladimir Malenovsky", "Karel Vesely", "Frantisek Grezl", "Lukas Burget", "Jan Cernocky"], "https://doi.org/10.21437/Interspeech.2018-2457", 5, "interspeech", 2018]], "Joo-Kyung Kim": [0.9997486770153046, ["Joint Learning of Domain Classification and Out-of-Domain Detection with Dynamic Class Weighting for Satisficing False Acceptance Rates", ["Joo-Kyung Kim", "Young-Bum Kim"], "https://doi.org/10.21437/Interspeech.2018-1581", 5, "interspeech", 2018]], "Ramaswamy Palaniappan": [0, ["Early Detection of Continuous and Partial Audio Events Using CNN", ["Ian Vince McLoughlin", "Yan Song", "Lam Dang Pham", "Ramaswamy Palaniappan", "Huy Phan", "Yue Lang"], "https://doi.org/10.21437/Interspeech.2018-1821", 5, "interspeech", 2018]], "Sankar Mukherjee": [0, ["Analyzing Vocal Tract Movements During Speech Accommodation", ["Sankar Mukherjee", "Thierry Legou", "Leonardo Lancia", "Pauline Hilt", "Alice Tomassini", "Luciano Fadiga", "Alessandro DAusilio", "Leonardo Badino", "Noel Nguyen"], "https://doi.org/10.21437/Interspeech.2018-2084", 5, "interspeech", 2018]], "Guan-Ting Liou": [0, ["An Exploration of Local Speaking Rate Variations in Mandarin Read Speech", ["Guan-Ting Liou", "Chen-Yu Chiang", "Yih-Ru Wang", "Sin-Horng Chen"], "https://doi.org/10.21437/Interspeech.2018-1214", 5, "interspeech", 2018]], "Jia Cui": [0, ["Improving Attention Based Sequence-to-Sequence Models for End-to-End English Conversational Speech Recognition", ["Chao Weng", "Jia Cui", "Guangsen Wang", "Jun Wang", "Chengzhu Yu", "Dan Su", "Dong Yu"], "https://doi.org/10.21437/Interspeech.2018-1030", 5, "interspeech", 2018], ["A Multistage Training Framework for Acoustic-to-Word Model", ["Chengzhu Yu", "Chunlei Zhang", "Chao Weng", "Jia Cui", "Dong Yu"], "https://doi.org/10.21437/Interspeech.2018-1452", 5, "interspeech", 2018]], "Matthew Mulholland": [0, ["Improvements to an Automated Content Scoring System for Spoken CALL Responses: the ETS Submission to the Second Spoken CALL Shared Task", ["Keelan Evanini", "Matthew Mulholland", "Rutuja Ubale", "Yao Qian", "Robert A. Pugh", "Vikram Ramanarayanan", "Aoife Cahill"], "https://doi.org/10.21437/Interspeech.2018-2362", 5, "interspeech", 2018]], "Alice Baird": [0, ["The INTERSPEECH 2018 Computational Paralinguistics Challenge: Atypical & Self-Assessed Affect, Crying & Heart Beats", ["Bjorn W. Schuller", "Stefan Steidl", "Anton Batliner", "Peter B. Marschik", "Harald Baumeister", "Fengquan Dong", "Simone Hantke", "Florian B. Pokorny", "Eva-Maria Rathner", "Katrin D. Bartl-Pokorny", "Christa Einspieler", "Dajie Zhang", "Alice Baird", "Shahin Amiriparian", "Kun Qian", "Zhao Ren", "Maximilian Schmitt", "Panagiotis Tzirakis", "Stefanos Zafeiriou"], "https://doi.org/10.21437/Interspeech.2018-51", 5, "interspeech", 2018], ["Recognition of Echolalic Autistic Child Vocalisations Utilising Convolutional Recurrent Neural Networks", ["Shahin Amiriparian", "Alice Baird", "Sahib Julka", "Alyssa Alcorn", "Sandra Ottl", "Suncica Petrovic", "Eloise Ainger", "Nicholas Cummins", "Bjorn W. Schuller"], "https://doi.org/10.21437/Interspeech.2018-1772", 5, "interspeech", 2018], ["The Perception and Analysis of the Likeability and Human Likeness of Synthesized Speech", ["Alice Baird", "Emilia Parada-Cabaleiro", "Simone Hantke", "Felix Burkhardt", "Nicholas Cummins", "Bjorn W. Schuller"], "https://doi.org/10.21437/Interspeech.2018-1093", 5, "interspeech", 2018], ["Categorical vs Dimensional Perception of Italian Emotional Speech", ["Emilia Parada-Cabaleiro", "Giovanni Costantini", "Anton Batliner", "Alice Baird", "Bjorn W. Schuller"], "https://doi.org/10.21437/Interspeech.2018-47", 5, "interspeech", 2018]], "Chia-Hsuan Lee": [6.758944295361894e-15, ["Spoken SQuAD: A Study of Mitigating the Impact of Speech Recognition Errors on Listening Comprehension", ["Chia-Hsuan Lee", "Szu-Lin Wu", "Chi-Liang Liu", "Hung-yi Lee"], "https://doi.org/10.21437/Interspeech.2018-1714", 5, "interspeech", 2018]], "Il-Ho Yang": [0.8665457963943481, ["Avoiding Speaker Overfitting in End-to-End DNNs Using Raw Waveform for Text-Independent Speaker Verification", ["Jee-weon Jung", "Hee-Soo Heo", "Il-Ho Yang", "Hye-jin Shim", "Ha-Jin Yu"], "https://doi.org/10.21437/Interspeech.2018-1608", 5, "interspeech", 2018]], "Li Tian": [0, ["An Open Source Emotional Speech Corpus for Human Robot Interaction Applications", ["Jesin James", "Li Tian", "Catherine Inez Watson"], "https://doi.org/10.21437/Interspeech.2018-1349", 5, "interspeech", 2018]], "Ying Chen": [0, ["Wuxi Speakers' Production and Perception of Coda Nasals in Mandarin", ["Lei Wang", "Jie Cui", "Ying Chen"], "https://doi.org/10.21437/Interspeech.2018-2224", 4, "interspeech", 2018]], "Ananth Sankar": [0, ["Speech Recognition for Medical Conversations", ["Chung-Cheng Chiu", "Anshuman Tripathi", "Katherine Chou", "Chris Co", "Navdeep Jaitly", "Diana Jaunzeikare", "Anjuli Kannan", "Patrick Nguyen", "Hasim Sak", "Ananth Sankar", "Justin Tansuwan", "Nathan Wan", "Yonghui Wu", "Xuedong Zhang"], "https://doi.org/10.21437/Interspeech.2018-40", 5, "interspeech", 2018]], "Alan W. Black": [0, ["Investigating Utterance Level Representations for Detecting Intent from Acoustics", ["Sai Krishna Rallabandi", "Bhavya Karki", "Carla Viegas", "Eric Nyberg", "Alan W. Black"], "https://doi.org/10.21437/Interspeech.2018-2149", 5, "interspeech", 2018], ["Multimodal Polynomial Fusion for Detecting Driver Distraction", ["Yulun Du", "Alan W. Black", "Louis-Philippe Morency", "Maxine Eskenazi"], "https://doi.org/10.21437/Interspeech.2018-2011", 5, "interspeech", 2018], ["An Investigation of Convolution Attention Based Models for Multilingual Speech Synthesis of Indian Languages", ["Pallavi Baljekar", "Sai Krishna Rallabandi", "Alan W. Black"], "https://doi.org/10.21437/Interspeech.2018-1869", 5, "interspeech", 2018]], "Moran Mordechay": [0, ["Word Emphasis Prediction for Expressive Text to Speech", ["Yosi Mass", "Slava Shechtman", "Moran Mordechay", "Ron Hoory", "Oren Sar Shalom", "Guy Lev", "David Konopnicki"], "https://doi.org/10.21437/Interspeech.2018-1159", 5, "interspeech", 2018]], "Hancheng Ge": [0, ["Contextual Slot Carryover for Disparate Schemas", ["Chetan Naik", "Arpit Gupta", "Hancheng Ge", "Lambert Mathias", "Ruhi Sarikaya"], "https://doi.org/10.21437/Interspeech.2018-1035", 5, "interspeech", 2018]], "Ralf Schluter": [0, ["Improved Training of End-to-end Attention Models for Speech Recognition", ["Albert Zeyer", "Kazuki Irie", "Ralf Schluter", "Hermann Ney"], "https://doi.org/10.21437/Interspeech.2018-1616", 5, "interspeech", 2018], ["Investigation on Estimation of Sentence Probability by Combining Forward, Backward and Bi-directional LSTM-RNNs", ["Kazuki Irie", "Zhihong Lei", "Liuhui Deng", "Ralf Schluter", "Hermann Ney"], "https://doi.org/10.21437/Interspeech.2018-1766", 4, "interspeech", 2018], ["Segmental Encoder-Decoder Models for Large Vocabulary Automatic Speech Recognition", ["Eugen Beck", "Mirko Hannemann", "Patrick Dotsch", "Ralf Schluter", "Hermann Ney"], "https://doi.org/10.21437/Interspeech.2018-1212", 5, "interspeech", 2018], ["Comparison of BLSTM-Layer-Specific Affine Transformations for Speaker Adaptation", ["Markus Kitza", "Ralf Schluter", "Hermann Ney"], "https://doi.org/10.21437/Interspeech.2018-2022", 5, "interspeech", 2018], ["Investigation on LSTM Recurrent N-gram Language Models for Speech Recognition", ["Zoltan Tuske", "Ralf Schluter", "Hermann Ney"], "https://doi.org/10.21437/Interspeech.2018-2476", 5, "interspeech", 2018]], "Julia Djamali": [0, ["How Did You like 2017? Detection of Language Markers of Depression and Narcissism in Personal Narratives", ["Eva-Maria Rathner", "Julia Djamali", "Yannik Terhorst", "Bjorn W. Schuller", "Nicholas Cummins", "Gudrun Salamon", "Christina Hunger-Schoppe", "Harald Baumeister"], "https://doi.org/10.21437/Interspeech.2018-2040", 5, "interspeech", 2018]], "Ivan Kremnev": [0, ["Triplet Loss Based Cosine Similarity Metric Learning for Text-independent Speaker Recognition", ["Sergey Novoselov", "Vadim Shchemelinin", "Andrey Shulipa", "Alexander Kozlov", "Ivan Kremnev"], "https://doi.org/10.21437/Interspeech.2018-1209", 5, "interspeech", 2018]], "Kye Taylor": [0, ["Attention-based Sequence Classification for Affect Detection", ["Cristina Gorrostieta", "Richard Brutti", "Kye Taylor", "Avi Shapiro", "Joseph Moran", "Ali Azarbayejani", "John Kane"], "https://doi.org/10.21437/Interspeech.2018-1610", 5, "interspeech", 2018]], "Stefan Wermter": [0, ["Conversational Analysis Using Utterance-level Attention-based Bidirectional Recurrent Neural Networks", ["Chandrakant Bothe", "Sven Magg", "Cornelius Weber", "Stefan Wermter"], "https://doi.org/10.21437/Interspeech.2018-2527", 5, "interspeech", 2018]], "Graham Neubig": [0, ["Self-Attentional Acoustic Models", ["Matthias Sperber", "Jan Niehues", "Graham Neubig", "Sebastian Stuker", "Alex Waibel"], "https://doi.org/10.21437/Interspeech.2018-1910", 5, "interspeech", 2018]], "Yougen Yuan": [0, ["Learning Acoustic Word Embeddings with Temporal Context for Query-by-Example Speech Search", ["Yougen Yuan", "Cheung-Chi Leung", "Lei Xie", "Hongjie Chen", "Bin Ma", "Haizhou Li"], "https://doi.org/10.21437/Interspeech.2018-1010", 5, "interspeech", 2018]], "Ehsan Variani": [0, ["Efficient Implementation of the Room Simulator for Training Deep Neural Network Acoustic Models", ["Chanwoo Kim", "Ehsan Variani", "Arun Narayanan", "Michiel Bacchiani"], "https://doi.org/10.21437/Interspeech.2018-2566", 5, "interspeech", 2018]], "Rutuja Ubale": [0, ["Toward Scalable Dialog Technology for Conversational Language Learning: Case Study of the TOEFL\u00ae MOOC", ["Vikram Ramanarayanan", "David Pautler", "Patrick L. Lange", "Eugene Tsuprun", "Rutuja Ubale", "Keelan Evanini", "David Suendermann-Oeft"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3032.html", 2, "interspeech", 2018], ["Improvements to an Automated Content Scoring System for Spoken CALL Responses: the ETS Submission to the Second Spoken CALL Shared Task", ["Keelan Evanini", "Matthew Mulholland", "Rutuja Ubale", "Yao Qian", "Robert A. Pugh", "Vikram Ramanarayanan", "Aoife Cahill"], "https://doi.org/10.21437/Interspeech.2018-2362", 5, "interspeech", 2018]], "Zbynek Zajic": [0, ["ZCU-NTIS Speaker Diarization System for the DIHARD 2018 Challenge", ["Zbynek Zajic", "Marie Kunesova", "Jan Zelinka", "Marek Hruz"], "https://doi.org/10.21437/Interspeech.2018-1252", 5, "interspeech", 2018]], "Sarah Taylor": [0, ["The Effect of Real-Time Constraints on Automatic Speech Animation", ["Danny Websdale", "Sarah Taylor", "Ben Milner"], "https://doi.org/10.21437/Interspeech.2018-2066", 5, "interspeech", 2018]], "Zhen-Hua Ling": [0, ["WaveNet Vocoder with Limited Training Data for Voice Conversion", ["Li-Juan Liu", "Zhen-Hua Ling", "Yuan Jiang", "Ming Zhou", "Li-Rong Dai"], "https://doi.org/10.21437/Interspeech.2018-1190", 5, "interspeech", 2018], ["Learning and Modeling Unit Embeddings for Improving HMM-based Unit Selection Speech Synthesis", ["Xiao Zhou", "Zhen-Hua Ling", "Zhi-Ping Zhou", "Li-Rong Dai"], "https://doi.org/10.21437/Interspeech.2018-1198", 5, "interspeech", 2018]], "Louis ten Bosch": [0, ["Analyzing Reaction Time Sequences from Human Participants in Auditory Experiments", ["Louis ten Bosch", "Mirjam Ernestus", "Lou Boves"], "https://doi.org/10.21437/Interspeech.2018-1728", 5, "interspeech", 2018], ["Analyzing EEG Signals in Auditory Speech Comprehension Using Temporal Response Functions and Generalized Additive Models", ["Kimberley Mulder", "Louis ten Bosch", "Lou Boves"], "https://doi.org/10.21437/Interspeech.2018-1676", 5, "interspeech", 2018], ["Information Encoding by Deep Neural Networks: What Can We Learn?", ["Louis ten Bosch", "Lou Boves"], "https://doi.org/10.21437/Interspeech.2018-1896", 5, "interspeech", 2018], ["Implementing DIANA to Model Isolated Auditory Word Recognition in English", ["Filip Nenadic", "Louis ten Bosch", "Benjamin V. Tucker"], "https://doi.org/10.21437/Interspeech.2018-2081", 5, "interspeech", 2018]], "Jie Gao": [0, ["Compact Feedforward Sequential Memory Networks for Small-footprint Keyword Spotting", ["Mengzhe Chen", "Shiliang Zhang", "Ming Lei", "Yong Liu", "Haitao Yao", "Jie Gao"], "https://doi.org/10.21437/Interspeech.2018-1204", 5, "interspeech", 2018]], "Cynthia Magnen": [0, ["Perceptual and Automatic Evaluations of the Intelligibility of Speech Degraded by Noise Induced Hearing Loss Simulation", ["Imed Laaridh", "Julien Tardieu", "Cynthia Magnen", "Pascal Gaillard", "Jerome Farinas", "Julien Pinquier"], "https://doi.org/10.21437/Interspeech.2018-1264", 5, "interspeech", 2018]], "Prasanna V. Kothalkar": [0, ["Fusing Text-dependent Word-level i-Vector Models to Screen 'at Risk' Child Speech", ["Prasanna V. Kothalkar", "Johanna Rudolph", "Christine Dollaghan", "Jennifer McGlothlin", "Thomas F. Campbell", "John H. L. Hansen"], "https://doi.org/10.21437/Interspeech.2018-1465", 5, "interspeech", 2018]], "Johanna Gerlach": [0, ["Overview of the 2018 Spoken CALL Shared Task", ["Claudia Baur", "Andrew Caines", "Cathy Chua", "Johanna Gerlach", "Mengjie Qian", "Manny Rayner", "Martin J. Russell", "Helmer Strik", "Xizi Wei"], "https://doi.org/10.21437/Interspeech.2018-97", 5, "interspeech", 2018]], "Dmitriy Serdyuk": [0, ["Twin Regularization for Online Speech Recognition", ["Mirco Ravanelli", "Dmitriy Serdyuk", "Yoshua Bengio"], "https://doi.org/10.21437/Interspeech.2018-1407", 5, "interspeech", 2018]], "Radhika Marvin": [0, ["AVA-Speech: A Densely Labeled Dataset of Speech Activity in Movies", ["Sourish Chaudhuri", "Joseph Roth", "Daniel P. W. Ellis", "Andrew C. Gallagher", "Liat Kaver", "Radhika Marvin", "Caroline Pantofaru", "Nathan Reale", "Loretta Guarino Reid", "Kevin W. Wilson", "Zhonghua Xi"], "https://doi.org/10.21437/Interspeech.2018-2028", 5, "interspeech", 2018]], "Tyson S. Barrett": [0, ["A Discriminative Acoustic-Prosodic Approach for Measuring Local Entrainment", ["Megan M. Willi", "Stephanie A. Borrie", "Tyson S. Barrett", "Ming Tu", "Visar Berisha"], "https://doi.org/10.21437/Interspeech.2018-1419", 5, "interspeech", 2018]], "Grant P. Strimel": [0, ["Statistical Model Compression for Small-Footprint Natural Language Understanding", ["Grant P. Strimel", "Kanthashree Mysore Sathyendra", "Stanislav Peshterliev"], "https://doi.org/10.21437/Interspeech.2018-1333", 5, "interspeech", 2018]], "Alejandro Gomez Alanis": [0, ["A Deep Identity Representation for Noise Robust Spoofing Detection", ["Alejandro Gomez Alanis", "Antonio M. Peinado", "Jose A. Gonzalez", "Angel M. Gomez"], "https://doi.org/10.21437/Interspeech.2018-1909", 5, "interspeech", 2018]], "Maria Usova": [0, ["LOCUST - Longitudinal Corpus and Toolset for Speaker Verification", ["Evgeny Dmitriev", "Yulia Kim", "Anastasia Matveeva", "Claude Montacie", "Yannick Boulard", "Yadviga Sinyavskaya", "Yulia Zhukova", "Adam Zarazinski", "Egor Akhanov", "Ilya I. Viksnin", "Andrei A. Shlykov", "Maria Usova"], "https://doi.org/10.21437/Interspeech.2018-2412", 5, "interspeech", 2018]], "Sai Krishna Rallabandi": [0, ["Investigating Utterance Level Representations for Detecting Intent from Acoustics", ["Sai Krishna Rallabandi", "Bhavya Karki", "Carla Viegas", "Eric Nyberg", "Alan W. Black"], "https://doi.org/10.21437/Interspeech.2018-2149", 5, "interspeech", 2018], ["An Investigation of Convolution Attention Based Models for Multilingual Speech Synthesis of Indian Languages", ["Pallavi Baljekar", "Sai Krishna Rallabandi", "Alan W. Black"], "https://doi.org/10.21437/Interspeech.2018-1869", 5, "interspeech", 2018]], "Ju-Chieh Chou": [0, ["Multi-target Voice Conversion without Parallel Data by Adversarially Learning Disentangled Audio Representations", ["Ju-Chieh Chou", "Cheng-chieh Yeh", "Hung-yi Lee", "Lin-Shan Lee"], "https://doi.org/10.21437/Interspeech.2018-1830", 5, "interspeech", 2018]], "Mengzhe Chen": [0, ["Compact Feedforward Sequential Memory Networks for Small-footprint Keyword Spotting", ["Mengzhe Chen", "Shiliang Zhang", "Ming Lei", "Yong Liu", "Haitao Yao", "Jie Gao"], "https://doi.org/10.21437/Interspeech.2018-1204", 5, "interspeech", 2018]], "Kevin Vythelingum": [0, ["Acoustic-dependent Phonemic Transcription for Text-to-speech Synthesis", ["Kevin Vythelingum", "Yannick Esteve", "Olivier Rosec"], "https://doi.org/10.21437/Interspeech.2018-1306", 5, "interspeech", 2018]], "Ravi Shankar": [0, ["Spoken Keyword Detection Using Joint DTW-CNN", ["Ravi Shankar", "Vikram C. M.", "S. R. Mahadeva Prasanna"], "https://doi.org/10.21437/Interspeech.2018-1436", 5, "interspeech", 2018]], "Wei-Wen Chang": [7.158355508352088e-08, ["Automatic Assessment of Individual Culture Attribute of Power Distance Using a Social Context-Enhanced Prosodic Network Representation", ["Fu-Sheng Tsai", "Hao-Chun Yang", "Wei-Wen Chang", "Chi-Chun Lee"], "https://doi.org/10.21437/Interspeech.2018-1523", 5, "interspeech", 2018]], "Luciana Ferrer": [0, ["A Generalization of PLDA for Joint Modeling of Speaker Identity and Multiple Nuisance Conditions", ["Luciana Ferrer", "Mitchell McLaren"], "https://doi.org/10.21437/Interspeech.2018-1280", 5, "interspeech", 2018]], "Rohit Sinha": [0, ["Exploration of Compressed ILPR Features for Replay Attack Detection", ["Sarfaraz Jelil", "Sishir Kalita", "S. R. Mahadeva Prasanna", "Rohit Sinha"], "https://doi.org/10.21437/Interspeech.2018-1297", 5, "interspeech", 2018], ["Robust Mizo Continuous Speech Recognition", ["Abhishek Dey", "Biswajit Dev Sarma", "Wendy Lalhminghlui", "Lalnunsiami Ngente", "Parismita Gogoi", "Priyankoo Sarmah", "S. R. Mahadeva Prasanna", "Rohit Sinha", "S. R. Nirmala"], "https://doi.org/10.21437/Interspeech.2018-2125", 5, "interspeech", 2018], ["A Novel Approach for Effective Recognition of the Code-Switched Data on Monolingual Language Model", ["Ganji Sreeram", "Rohit Sinha"], "https://doi.org/10.21437/Interspeech.2018-1259", 5, "interspeech", 2018], ["AGROASSAM: A Web Based Assamese Speech Recognition Application for Retrieving Agricultural Commodity Price and Weather Information", ["Abhishek Dey", "Abhash Deka", "Siddika Imani", "Barsha Deka", "Rohit Sinha", "S. R. Mahadeva Prasanna", "Priyankoo Sarmah", "K. Samudravijaya", "S. R. Nirmala"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3048.html", 2, "interspeech", 2018]], "Kishor K. S": [0, ["Speech Source Separation Using ICA in Constant Q Transform Domain", ["Dheeraj Sai D. V. L. N", "Kishor K. S", "Sri Rama Murty Kodukula"], "https://doi.org/10.21437/Interspeech.2018-1732", 5, "interspeech", 2018]], "Suryakanth V. Gangashetty": [0, ["Discriminating Nasals and Approximants in English Language Using Zero Time Windowing", ["RaviShankar Prasad", "Sudarsana Reddy Kadiri", "Suryakanth V. Gangashetty", "Bayya Yegnanarayana"], "https://doi.org/10.21437/Interspeech.2018-1032", 5, "interspeech", 2018]], "Russell Levy": [0, ["Fully Automatic Speaker Separation System, with Automatic Enrolling of Recurrent Speakers", ["Raphael Cohen", "Orgad Keller", "Jason Levy", "Russell Levy", "Micha Breakstone", "Amit Ashkenazi"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3034.html", 2, "interspeech", 2018]], "Cagri Coltekin": [0, ["Neural Response Development During Distributional Learning", ["Natalie Boll-Avetisyan", "Jessie S. Nixon", "Tomas O. Lentz", "Liquan Liu", "Sandrien van Ommen", "Cagri Coltekin", "Jacolien van Rij"], "https://doi.org/10.21437/Interspeech.2018-2072", 5, "interspeech", 2018]], "Philip Weber": [0, ["Exploring How Phone Classification Neural Networks Learn Phonetic Information by Visualising and Interpreting Bottleneck Features", ["Linxue Bai", "Philip Weber", "Peter Jancovic", "Martin J. Russell"], "https://doi.org/10.21437/Interspeech.2018-2462", 5, "interspeech", 2018]], "Anja Lowit": [0, ["A Deep Learning Method for Pathological Voice Detection Using Convolutional Deep Belief Networks", ["Huiyi Wu", "John J. Soraghan", "Anja Lowit", "Gaetano Di Caterina"], "https://doi.org/10.21437/Interspeech.2018-1351", 5, "interspeech", 2018]], "Jianrong Wang": [1.1226132983210846e-06, ["Tongue Segmentation with Geometrically Constrained Snake Model", ["Zhihua Su", "Jianguo Wei", "Qiang Fang", "Jianrong Wang", "Kiyoshi Honda"], "https://doi.org/10.21437/Interspeech.2018-1108", 5, "interspeech", 2018]], "Teng Zhang": [0, ["Temporal Transformer Networks for Acoustic Scene Classification", ["Teng Zhang", "Kailai Zhang", "Ji Wu"], "https://doi.org/10.21437/Interspeech.2018-1152", 5, "interspeech", 2018], ["Data Independent Sequence Augmentation Method for Acoustic Scene Classification", ["Teng Zhang", "Kailai Zhang", "Ji Wu"], "https://doi.org/10.21437/Interspeech.2018-1250", 5, "interspeech", 2018], ["Multi-modal Attention Mechanisms in LSTM and Its Application to Acoustic Scene Classification", ["Teng Zhang", "Kailai Zhang", "Ji Wu"], "https://doi.org/10.21437/Interspeech.2018-1138", 5, "interspeech", 2018]], "Ariya Rastrow": [0, ["Device-directed Utterance Detection", ["Sri Harish Reddy Mallidi", "Roland Maas", "Kyle Goehner", "Ariya Rastrow", "Spyros Matsoukas", "Bjorn Hoffmeister"], "https://doi.org/10.21437/Interspeech.2018-1531", 4, "interspeech", 2018], ["Contextual Language Model Adaptation for Conversational Agents", ["Anirudh Raju", "Behnam Hedayatnia", "Linda Liu", "Ankur Gandhe", "Chandra Khatri", "Angeliki Metallinou", "Anu Venkatesh", "Ariya Rastrow"], "https://doi.org/10.21437/Interspeech.2018-1122", 5, "interspeech", 2018]], "Daniel Friedrichs": [0, ["The Zurich Corpus of Vowel and Voice Quality, Version 1.0", ["Dieter Maurer", "Christian dHeureuse", "Heidy Suter", "Volker Dellwo", "Daniel Friedrichs", "Thayabaran Kathiresan"], "https://doi.org/10.21437/Interspeech.2018-1542", 5, "interspeech", 2018]], "Aviv Gabbay": [0, ["Visual Speech Enhancement", ["Aviv Gabbay", "Asaph Shamir", "Shmuel Peleg"], "https://doi.org/10.21437/Interspeech.2018-1955", 5, "interspeech", 2018]], "John Shen": [0, ["Online Incremental Learning for Speaker-Adaptive Language Models", ["Chih Chi Hu", "Bing Liu", "John Shen", "Ian Lane"], "https://doi.org/10.21437/Interspeech.2018-2259", 5, "interspeech", 2018]], "Haris Bin Zia": [0, ["Rapid Collection of Spontaneous Speech Corpora Using Telephonic Community Forums", ["Agha Ali Raza", "Awais Athar", "Shan Randhawa", "Zain Tariq", "Muhammad Bilal Saleem", "Haris Bin Zia", "Umar Saif", "Roni Rosenfeld"], "https://doi.org/10.21437/Interspeech.2018-1139", 5, "interspeech", 2018]], "Yosi Mass": [0, ["Word Emphasis Prediction for Expressive Text to Speech", ["Yosi Mass", "Slava Shechtman", "Moran Mordechay", "Ron Hoory", "Oren Sar Shalom", "Guy Lev", "David Konopnicki"], "https://doi.org/10.21437/Interspeech.2018-1159", 5, "interspeech", 2018]], "Yoshikazu Yamaguchi": [0, ["Automatic DNN Node Pruning Using Mixture Distribution-based Group Regularization", ["Tsukasa Yoshida", "Takafumi Moriya", "Kazuho Watanabe", "Yusuke Shinohara", "Yoshikazu Yamaguchi", "Yushi Aono"], "https://doi.org/10.21437/Interspeech.2018-2062", 5, "interspeech", 2018], ["Multi-task Learning with Augmentation Strategy for Acoustic-to-word Attention-based Encoder-decoder Speech Recognition", ["Takafumi Moriya", "Sei Ueno", "Yusuke Shinohara", "Marc Delcroix", "Yoshikazu Yamaguchi", "Yushi Aono"], "https://doi.org/10.21437/Interspeech.2018-1866", 5, "interspeech", 2018], ["Encoder Transfer for Attention-based Acoustic-to-word Speech Recognition", ["Sei Ueno", "Takafumi Moriya", "Masato Mimura", "Shinsuke Sakai", "Yusuke Shinohara", "Yoshikazu Yamaguchi", "Yushi Aono", "Tatsuya Kawahara"], "https://doi.org/10.21437/Interspeech.2018-1424", 5, "interspeech", 2018]], "Hirak Dasgupta": [0, ["Detection of Glottal Excitation Epochs in Speech Signal Using Hilbert Envelope", ["Hirak Dasgupta", "Prem C. Pandey", "K. S. Nataraj"], "https://doi.org/10.21437/Interspeech.2018-2014", 5, "interspeech", 2018]], "Kohei Hara": [0, ["Prediction of Turn-taking Using Multitask Learning with Prediction of Backchannels and Fillers", ["Kohei Hara", "Koji Inoue", "Katsuya Takanashi", "Tatsuya Kawahara"], "https://doi.org/10.21437/Interspeech.2018-1442", 5, "interspeech", 2018]], "Christophe Micheyl": [0, ["Who Are You Listening to? Towards a Dynamic Measure of Auditory Attention to Speech-on-speech", ["Moira-Phoebe Huet", "Christophe Micheyl", "Etienne Gaudrain", "Etienne Parizet"], "https://doi.org/10.21437/Interspeech.2018-2053", 4, "interspeech", 2018]], "Lucas Ondel": [0, ["Automatic Speech Recognition and Topic Identification from Speech for Almost-Zero-Resource Languages", ["Matthew Wiesner", "Chunxi Liu", "Lucas Ondel", "Craig Harman", "Vimal Manohar", "Jan Trmal", "Zhongqiang Huang", "Najim Dehak", "Sanjeev Khudanpur"], "https://doi.org/10.21437/Interspeech.2018-1836", 5, "interspeech", 2018], ["Unsupervised Word Segmentation from Speech with Attention", ["Pierre Godard", "Marcely Zanon Boito", "Lucas Ondel", "Alexandre Berard", "Francois Yvon", "Aline Villavicencio", "Laurent Besacier"], "https://doi.org/10.21437/Interspeech.2018-1308", 5, "interspeech", 2018]], "Suyoun Kim": [0.9995113462209702, ["Improved Training for Online End-to-end Speech Recognition Systems", ["Suyoun Kim", "Michael L. Seltzer", "Jinyu Li", "Rui Zhao"], "https://doi.org/10.21437/Interspeech.2018-2517", 5, "interspeech", 2018]], "Yuan Jiang": [0, ["WaveNet Vocoder with Limited Training Data for Voice Conversion", ["Li-Juan Liu", "Zhen-Hua Ling", "Yuan Jiang", "Ming Zhou", "Li-Rong Dai"], "https://doi.org/10.21437/Interspeech.2018-1190", 5, "interspeech", 2018]], "Lyan Verwimp": [0, ["State Gradients for RNN Memory Analysis", ["Lyan Verwimp", "Hugo Van hamme", "Vincent Renkens", "Patrick Wambacq"], "https://doi.org/10.21437/Interspeech.2018-1153", 5, "interspeech", 2018]], "Carla Viegas": [0, ["Investigating Utterance Level Representations for Detecting Intent from Acoustics", ["Sai Krishna Rallabandi", "Bhavya Karki", "Carla Viegas", "Eric Nyberg", "Alan W. Black"], "https://doi.org/10.21437/Interspeech.2018-2149", 5, "interspeech", 2018]], "Xuankai Chang": [1.0287378045779894e-12, ["Monaural Multi-Talker Speech Recognition with Attention Mechanism and Gated Convolutional Networks", ["Xuankai Chang", "Yanmin Qian", "Dong Yu"], "https://doi.org/10.21437/Interspeech.2018-1547", 5, "interspeech", 2018]], "Chanwoo Kim": [0.9085521399974823, ["Efficient Implementation of the Room Simulator for Training Deep Neural Network Acoustic Models", ["Chanwoo Kim", "Ehsan Variani", "Arun Narayanan", "Michiel Bacchiani"], "https://doi.org/10.21437/Interspeech.2018-2566", 5, "interspeech", 2018]], "Taufiq Hasan": [0, ["An Ensemble of Transfer, Semi-supervised and Supervised Learning Methods for Pathological Heart Sound Classification", ["Ahmed Imtiaz Humayun", "Md. Tauhiduzzaman Khan", "Shabnam Ghaffarzadegan", "Zhe Feng", "Taufiq Hasan"], "https://doi.org/10.21437/Interspeech.2018-2413", 5, "interspeech", 2018]], "Zhong Meng": [0, ["Cycle-Consistent Speech Enhancement", ["Zhong Meng", "Jinyu Li", "Yifan Gong", "Biing-Hwang Fred Juang"], "https://doi.org/10.21437/Interspeech.2018-2409", 5, "interspeech", 2018], ["Adversarial Feature-Mapping for Speech Enhancement", ["Zhong Meng", "Jinyu Li", "Yifan Gong", "Biing-Hwang Fred Juang"], "https://doi.org/10.21437/Interspeech.2018-2461", 5, "interspeech", 2018]], "Mary Pietrowicz": [0, ["Detection of Amyotrophic Lateral Sclerosis (ALS) via Acoustic Analysis", ["Raquel Norel", "Mary Pietrowicz", "Carla Agurto", "Shay Rishoni", "Guillermo A. Cecchi"], "https://doi.org/10.21437/Interspeech.2018-2389", 5, "interspeech", 2018]], "Marilyn A. Walker": [0, ["Neural MultiVoice Models for Expressing Novel Personalities in Dialog", ["Shereen Oraby", "Lena Reed", "Sharath T. S.", "Shubhangi Tandon", "Marilyn A. Walker"], "https://doi.org/10.21437/Interspeech.2018-2174", 5, "interspeech", 2018]], "Nobuyuki Nishizawa": [0, ["Investigating Accuracy of Pitch-accent Annotations in Neural Network-based Speech Synthesis and Denoising Effects", ["Hieu-Thi Luong", "Xin Wang", "Junichi Yamagishi", "Nobuyuki Nishizawa"], "https://doi.org/10.21437/Interspeech.2018-1227", 5, "interspeech", 2018]], "Dinkar Sitaram": [0, ["Effect of TTS Generated Audio on OOV Detection and Word Error Rate in ASR for Low-resource Languages", ["Savitha Murthy", "Dinkar Sitaram", "Sunayana Sitaram"], "https://doi.org/10.21437/Interspeech.2018-1555", 5, "interspeech", 2018]], "Cenk Demiroglu": [0, ["Multi-Lingual Depression-Level Assessment from Conversational Speech Using Acoustic and Text Features", ["Yasin Ozkanca", "Cenk Demiroglu", "Asli Besirli", "Selime Celik"], "https://doi.org/10.21437/Interspeech.2018-2169", 5, "interspeech", 2018]], "Lukas Drude": [0, ["Integrating Neural Network Based Beamforming and Weighted Prediction Error Dereverberation", ["Lukas Drude", "Christoph Boddeker", "Jahn Heymann", "Reinhold Haeb-Umbach", "Keisuke Kinoshita", "Marc Delcroix", "Tomohiro Nakatani"], "https://doi.org/10.21437/Interspeech.2018-2196", 5, "interspeech", 2018]], "Caroline Pantofaru": [0, ["AVA-Speech: A Densely Labeled Dataset of Speech Activity in Movies", ["Sourish Chaudhuri", "Joseph Roth", "Daniel P. W. Ellis", "Andrew C. Gallagher", "Liat Kaver", "Radhika Marvin", "Caroline Pantofaru", "Nathan Reale", "Loretta Guarino Reid", "Kevin W. Wilson", "Zhonghua Xi"], "https://doi.org/10.21437/Interspeech.2018-2028", 5, "interspeech", 2018]], "Justice Amoh": [0, ["Detecting Media Sound Presence in Acoustic Scenes", ["Constantinos Papayiannis", "Justice Amoh", "Viktor Rozgic", "Shiva Sundaram", "Chao Wang"], "https://doi.org/10.21437/Interspeech.2018-2559", 5, "interspeech", 2018]], "Hao Tang": [0, ["Unsupervised Adaptation with Interpretable Disentangled Representations for Distant Conversational Speech Recognition", ["Wei-Ning Hsu", "Hao Tang", "James R. Glass"], "https://doi.org/10.21437/Interspeech.2018-1097", 5, "interspeech", 2018], ["A Study of Enhancement, Augmentation and Autoencoder Methods for Domain Adaptation in Distant Speech Recognition", ["Hao Tang", "Wei-Ning Hsu", "Francois Grondin", "James R. Glass"], "https://doi.org/10.21437/Interspeech.2018-2030", 5, "interspeech", 2018]], "Fu-Sheng Tsai": [0, ["Automatic Assessment of Individual Culture Attribute of Power Distance Using a Social Context-Enhanced Prosodic Network Representation", ["Fu-Sheng Tsai", "Hao-Chun Yang", "Wei-Wen Chang", "Chi-Chun Lee"], "https://doi.org/10.21437/Interspeech.2018-1523", 5, "interspeech", 2018]], "Bhargav Pulugundla": [0, ["BUT System for Low Resource Indian Language ASR", ["Bhargav Pulugundla", "Murali Karthick Baskar", "Santosh Kesiraju", "Ekaterina Egorova", "Martin Karafiat", "Lukas Burget", "Jan Cernocky"], "https://doi.org/10.21437/Interspeech.2018-1302", 5, "interspeech", 2018]], "Liu Liu": [0, ["Double Joint Bayesian Modeling of DNN Local I-Vector for Text Dependent Speaker Verification with Random Digit Strings", ["Ziqiang Shi", "Huibin Lin", "Liu Liu", "Rujie Liu"], "https://doi.org/10.21437/Interspeech.2018-1103", 5, "interspeech", 2018], ["Joint Learning of J-Vector Extractor and Joint Bayesian Model for Text Dependent Speaker Verification", ["Ziqiang Shi", "Liu Liu", "Huibin Lin", "Rujie Liu"], "https://doi.org/10.21437/Interspeech.2018-1500", 5, "interspeech", 2018], ["Latent Factor Analysis of Deep Bottleneck Features for Speaker Verification with Random Digit Strings", ["Ziqiang Shi", "Huibin Lin", "Liu Liu", "Rujie Liu"], "https://doi.org/10.21437/Interspeech.2018-1422", 5, "interspeech", 2018]], "Shiyin Kang": [1.356270360020062e-06, ["Rapid Style Adaptation Using Residual Error Embedding for Expressive Speech Synthesis", ["Xixin Wu", "Yuewen Cao", "Mu Wang", "Songxiang Liu", "Shiyin Kang", "Zhiyong Wu", "Xunying Liu", "Dan Su", "Dong Yu", "Helen Meng"], "https://doi.org/10.21437/Interspeech.2018-1991", 5, "interspeech", 2018]], "Mireia Diez": [0, ["BUT System for DIHARD Speech Diarization Challenge 2018", ["Mireia Diez", "Federico Landini", "Lukas Burget", "Johan Rohdin", "Anna Silnova", "Katerina Zmolikova", "Ondrej Novotny", "Karel Vesely", "Ondrej Glembek", "Oldrich Plchot", "Ladislav Mosner", "Pavel Matejka"], "https://doi.org/10.21437/Interspeech.2018-1749", 5, "interspeech", 2018]], "Jianwei Yu": [1.7882772346267117e-10, ["Gaussian Process Neural Networks for Speech Recognition", ["Max W. Y. Lam", "Shoukang Hu", "Xurong Xie", "Shansong Liu", "Jianwei Yu", "Rongfeng Su", "Xunying Liu", "Helen Meng"], "https://doi.org/10.21437/Interspeech.2018-1823", 5, "interspeech", 2018], ["Development of the CUHK Dysarthric Speech Recognition System for the UA Speech Corpus", ["Jianwei Yu", "Xurong Xie", "Shansong Liu", "Shoukang Hu", "Max W. Y. Lam", "Xixin Wu", "Ka Ho Wong", "Xunying Liu", "Helen Meng"], "https://doi.org/10.21437/Interspeech.2018-1541", 5, "interspeech", 2018]], "Oliver Watts": [0, ["Learning Interpretable Control Dimensions for Speech Synthesis by Using External Data", ["Zack Hodari", "Oliver Watts", "Srikanth Ronanki", "Simon King"], "https://doi.org/10.21437/Interspeech.2018-2075", 5, "interspeech", 2018], ["Exemplar-based Speech Waveform Generation", ["Oliver Watts", "Cassia Valentini-Botinhao", "Felipe Espic", "Simon King"], "https://doi.org/10.21437/Interspeech.2018-1857", 5, "interspeech", 2018]], "Sunayana Sitaram": [0, ["Effect of TTS Generated Audio on OOV Detection and Word Error Rate in ASR for Low-resource Languages", ["Savitha Murthy", "Dinkar Sitaram", "Sunayana Sitaram"], "https://doi.org/10.21437/Interspeech.2018-1555", 5, "interspeech", 2018], ["Homophone Identification and Merging for Code-switched Speech Recognition", ["Brij Mohan Lal Srivastava", "Sunayana Sitaram"], "https://doi.org/10.21437/Interspeech.2018-1171", 5, "interspeech", 2018]], "Hsin-Te Hwang": [0.0003545219369698316, ["Exemplar-Based Spectral Detail Compensation for Voice Conversion", ["Yu-Huai Peng", "Hsin-Te Hwang", "Yi-Chiao Wu", "Yu Tsao", "Hsin-Min Wang"], "https://doi.org/10.21437/Interspeech.2018-1662", 5, "interspeech", 2018], ["Quality-Net: An End-to-End Non-intrusive Speech Quality Assessment Model Based on BLSTM", ["Szu-Wei Fu", "Yu Tsao", "Hsin-Te Hwang", "Hsin-Min Wang"], "https://doi.org/10.21437/Interspeech.2018-1802", 5, "interspeech", 2018]], "Lionel Fontan": [0, ["Automatically Measuring L2 Speech Fluency without the Need of ASR: A Proof-of-concept Study with Japanese Learners of French", ["Lionel Fontan", "Maxime Le Coz", "Sylvain Detey"], "https://doi.org/10.21437/Interspeech.2018-1336", 5, "interspeech", 2018]], "Karl Ni": [0, ["Voices Obscured in Complex Environmental Settings (VOiCES) Corpus", ["Colleen Richey", "Maria Auxiliadora Barrios", "Zeb Armstrong", "Chris Bartels", "Horacio Franco", "Martin Graciarena", "Aaron Lawson", "Mahesh Kumar Nandwana", "Allen R. Stauffer", "Julien van Hout", "Paul Gamble", "Jeffrey Hetherly", "Cory Stephenson", "Karl Ni"], "https://doi.org/10.21437/Interspeech.2018-1454", 5, "interspeech", 2018], ["Deep Speech Denoising with Vector Space Projections", ["Jeffrey Hetherly", "Paul Gamble", "Maria Alejandra Barrios", "Cory Stephenson", "Karl Ni"], "https://doi.org/10.21437/Interspeech.2018-83", 5, "interspeech", 2018]], "Ahmet Emin Bulut": [0, ["Fearless Steps: Apollo-11 Corpus Advancements for Speech Technologies from Earth to the Moon", ["John H. L. Hansen", "Abhijeet Sangwan", "Aditya Joglekar", "Ahmet Emin Bulut", "Lakshmish Kaushik", "Chengzhu Yu"], "https://doi.org/10.21437/Interspeech.2018-1942", 5, "interspeech", 2018]], "Tiphaine Caudrelier": [0, ["Picture Naming or Word Reading: Does the Modality Affect Speech Motor Adaptation and Its Transfer?", ["Tiphaine Caudrelier", "Pascal Perrier", "Jean-Luc Schwartz", "Amelie Rochet-Capellan"], "https://doi.org/10.21437/Interspeech.2018-1760", 5, "interspeech", 2018]], "Yannick Boulard": [0, ["LOCUST - Longitudinal Corpus and Toolset for Speaker Verification", ["Evgeny Dmitriev", "Yulia Kim", "Anastasia Matveeva", "Claude Montacie", "Yannick Boulard", "Yadviga Sinyavskaya", "Yulia Zhukova", "Adam Zarazinski", "Egor Akhanov", "Ilya I. Viksnin", "Andrei A. Shlykov", "Maria Usova"], "https://doi.org/10.21437/Interspeech.2018-2412", 5, "interspeech", 2018]], "Cory Stephenson": [0, ["Voices Obscured in Complex Environmental Settings (VOiCES) Corpus", ["Colleen Richey", "Maria Auxiliadora Barrios", "Zeb Armstrong", "Chris Bartels", "Horacio Franco", "Martin Graciarena", "Aaron Lawson", "Mahesh Kumar Nandwana", "Allen R. Stauffer", "Julien van Hout", "Paul Gamble", "Jeffrey Hetherly", "Cory Stephenson", "Karl Ni"], "https://doi.org/10.21437/Interspeech.2018-1454", 5, "interspeech", 2018], ["Deep Speech Denoising with Vector Space Projections", ["Jeffrey Hetherly", "Paul Gamble", "Maria Alejandra Barrios", "Cory Stephenson", "Karl Ni"], "https://doi.org/10.21437/Interspeech.2018-83", 5, "interspeech", 2018]], "Caitlin Dillon": [0, ["The Effect of Exposure to High Altitude and Heat on Speech Articulatory Coordination", ["James R. Williamson", "Thomas F. Quatieri", "Adam C. Lammert", "Katherine Mitchell", "Katherine Finkelstein", "Nicole Ekon", "Caitlin Dillon", "Robert Kenefick", "Kristin Heaton"], "https://doi.org/10.21437/Interspeech.2018-2372", 5, "interspeech", 2018]], "Atsushi Ando": [0, ["Role Play Dialogue Aware Language Models Based on Conditional Hierarchical Recurrent Encoder-Decoder", ["Ryo Masumura", "Tomohiro Tanaka", "Atsushi Ando", "Hirokazu Masataki", "Yushi Aono"], "https://doi.org/10.21437/Interspeech.2018-2185", 5, "interspeech", 2018], ["Automatic Question Detection from Acoustic and Phonetic Features Using Feature-wise Pre-training", ["Atsushi Ando", "Reine Asakawa", "Ryo Masumura", "Hosana Kamiyama", "Satoshi Kobashikawa", "Yushi Aono"], "https://doi.org/10.21437/Interspeech.2018-1755", 5, "interspeech", 2018]], "Bastian Auris": [0, ["Structural Effects on Properties of Consonantal Gestures in Tashlhiyt", ["Anne Hermes", "Doris Mucke", "Bastian Auris", "Rachid Ridouane"], "https://doi.org/10.21437/Interspeech.2018-1074", 5, "interspeech", 2018]], "Rachid Ridouane": [0, ["Structural Effects on Properties of Consonantal Gestures in Tashlhiyt", ["Anne Hermes", "Doris Mucke", "Bastian Auris", "Rachid Ridouane"], "https://doi.org/10.21437/Interspeech.2018-1074", 5, "interspeech", 2018], ["Length Contrast and Covarying Features: Whistled Speech as a Case Study", ["Rachid Ridouane", "Giuseppina Turco", "Julien Meyer"], "https://doi.org/10.21437/Interspeech.2018-1060", 5, "interspeech", 2018]], "Akinori Ito": [0, ["Analyzing Effect of Physical Expression on English Proficiency for Multimodal Computer-Assisted Language Learning", ["Haoran Wu", "Yuya Chiba", "Takashi Nose", "Akinori Ito"], "https://doi.org/10.21437/Interspeech.2018-1425", 5, "interspeech", 2018]], "Shuangyu Chang": [3.8453920581105194e-07, ["What to Expect from Expected Kneser-Ney Smoothing", ["Michael Levit", "Sarangarajan Parthasarathy", "Shuangyu Chang"], "https://doi.org/10.21437/Interspeech.2018-84", 5, "interspeech", 2018]], "Patrick Lumban Tobing": [0, ["Collapsed Speech Segment Detection and Suppression for WaveNet Vocoder", ["Yi-Chiao Wu", "Kazuhiro Kobayashi", "Tomoki Hayashi", "Patrick Lumban Tobing", "Tomoki Toda"], "https://doi.org/10.21437/Interspeech.2018-1210", 5, "interspeech", 2018]], "Madhumita Harish": [0, ["Far-Field Speech Recognition Using Multivariate Autoregressive Models", ["Sriram Ganapathy", "Madhumita Harish"], "https://doi.org/10.21437/Interspeech.2018-2003", 5, "interspeech", 2018]], "Melanie Kruger": [0, ["Prediction of Subjective Listening Effort from Acoustic Data with Non-Intrusive Deep Models", ["Paul Kranzusch", "Rainer Huber", "Melanie Kruger", "Birger Kollmeier", "Bernd T. Meyer"], "https://doi.org/10.21437/Interspeech.2018-1375", 5, "interspeech", 2018]], "Shoko Araki": [0, ["Multi-resolution Gammachirp Envelope Distortion Index for Intelligibility Prediction of Noisy Speech", ["Katsuhiko Yamamoto", "Toshio Irino", "Narumi Ohashi", "Shoko Araki", "Keisuke Kinoshita", "Tomohiro Nakatani"], "https://doi.org/10.21437/Interspeech.2018-1291", 5, "interspeech", 2018]], "Pravesh Biyani": [0, ["Towards Automated Single Channel Source Separation Using Neural Networks", ["Arpita Gang", "Pravesh Biyani", "Akshay Soni"], "https://doi.org/10.21437/Interspeech.2018-2065", 5, "interspeech", 2018]], "Deming Chen": [0, ["Improved ASR for Under-resourced Languages through Multi-task Learning with Acoustic Landmarks", ["Di He", "Boon Pang Lim", "Xuesong Yang", "Mark Hasegawa-Johnson", "Deming Chen"], "https://doi.org/10.21437/Interspeech.2018-1124", 5, "interspeech", 2018]], "Jesus Andres-Ferrer": [0, ["Efficient Language Model Adaptation with Noise Contrastive Estimation and Kullback-Leibler Regularization", ["Jesus Andres-Ferrer", "Nathan Bodenstab", "Paul Vozila"], "https://doi.org/10.21437/Interspeech.2018-1345", 5, "interspeech", 2018]], "Fei Tao": [0, ["Audiovisual Speech Activity Detection with Advanced Long Short-Term Memory", ["Fei Tao", "Carlos Busso"], "https://doi.org/10.21437/Interspeech.2018-2490", 5, "interspeech", 2018]], "Szu-Wei Fu": [0, ["Quality-Net: An End-to-End Non-intrusive Speech Quality Assessment Model Based on BLSTM", ["Szu-Wei Fu", "Yu Tsao", "Hsin-Te Hwang", "Hsin-Min Wang"], "https://doi.org/10.21437/Interspeech.2018-1802", 5, "interspeech", 2018]], "Sylvain Detey": [0, ["Automatically Measuring L2 Speech Fluency without the Need of ASR: A Proof-of-concept Study with Japanese Learners of French", ["Lionel Fontan", "Maxime Le Coz", "Sylvain Detey"], "https://doi.org/10.21437/Interspeech.2018-1336", 5, "interspeech", 2018]], "Mu Wang": [0.0004269026394467801, ["Rapid Style Adaptation Using Residual Error Embedding for Expressive Speech Synthesis", ["Xixin Wu", "Yuewen Cao", "Mu Wang", "Songxiang Liu", "Shiyin Kang", "Zhiyong Wu", "Xunying Liu", "Dan Su", "Dong Yu", "Helen Meng"], "https://doi.org/10.21437/Interspeech.2018-1991", 5, "interspeech", 2018]], "Debayan Ghosh": [0, ["Robust Voice Activity Detection Using Frequency Domain Long-Term Differential Entropy", ["Debayan Ghosh", "Muralishankar R", "Sanjeev Gurugopinath"], "https://doi.org/10.21437/Interspeech.2018-1431", 5, "interspeech", 2018]], "Michael L. Seltzer": [0, ["Improved Training for Online End-to-end Speech Recognition Systems", ["Suyoun Kim", "Michael L. Seltzer", "Jinyu Li", "Rui Zhao"], "https://doi.org/10.21437/Interspeech.2018-2517", 5, "interspeech", 2018]], "Lan Wang": [0.0072339854668825865, ["Acoustic Features Associated with Sustained Vowel and Continuous Speech Productions by Chinese Children with Functional Articulation Disorders", ["Wang Zhang", "Xiangquan Gui", "Tianqi Wang", "Manwa L. Ng", "Feng Yang", "Lan Wang", "Nan Yan"], "https://doi.org/10.21437/Interspeech.2018-1521", 5, "interspeech", 2018], ["Semi-supervised Cross-domain Visual Feature Learning for Audio-Visual Broadcast Speech Transcription", ["Rongfeng Su", "Xunying Liu", "Lan Wang"], "https://doi.org/10.21437/Interspeech.2018-1063", 5, "interspeech", 2018]], "Chunxiao Zhang": [0, ["Factorized Deep Neural Network Adaptation for Automatic Scoring of L2 Speech in English Speaking Tests", ["Dean Luo", "Chunxiao Zhang", "Linzhong Xia", "Lixin Wang"], "https://doi.org/10.21437/Interspeech.2018-2138", 5, "interspeech", 2018]], "Benjamin V. Tucker": [0, ["A Comparison of Input Types to a Deep Neural Network-based Forced Aligner", ["Matthew C. Kelley", "Benjamin V. Tucker"], "https://doi.org/10.21437/Interspeech.2018-1115", 5, "interspeech", 2018], ["Implementing DIANA to Model Isolated Auditory Word Recognition in English", ["Filip Nenadic", "Louis ten Bosch", "Benjamin V. Tucker"], "https://doi.org/10.21437/Interspeech.2018-2081", 5, "interspeech", 2018]], "Panagiotis Tzirakis": [0, ["The INTERSPEECH 2018 Computational Paralinguistics Challenge: Atypical & Self-Assessed Affect, Crying & Heart Beats", ["Bjorn W. Schuller", "Stefan Steidl", "Anton Batliner", "Peter B. Marschik", "Harald Baumeister", "Fengquan Dong", "Simone Hantke", "Florian B. Pokorny", "Eva-Maria Rathner", "Katrin D. Bartl-Pokorny", "Christa Einspieler", "Dajie Zhang", "Alice Baird", "Shahin Amiriparian", "Kun Qian", "Zhao Ren", "Maximilian Schmitt", "Panagiotis Tzirakis", "Stefanos Zafeiriou"], "https://doi.org/10.21437/Interspeech.2018-51", 5, "interspeech", 2018]], "Saurabh Garg": [0, ["Dual Language Models for Code Switched Speech Recognition", ["Saurabh Garg", "Tanmay Parekh", "Preethi Jyothi"], "https://doi.org/10.21437/Interspeech.2018-1343", 5, "interspeech", 2018]], "Md. Nasir": [0, ["Towards an Unsupervised Entrainment Distance in Conversational Speech Using Deep Neural Networks", ["Md. Nasir", "Brian R. Baucom", "Shrikanth Narayanan", "Panayiotis G. Georgiou"], "https://doi.org/10.21437/Interspeech.2018-1395", 5, "interspeech", 2018]], "Nikolaos Flemotomos": [0, ["Combined Speaker Clustering and Role Recognition in Conversational Speech", ["Nikolaos Flemotomos", "Pavlos Papadopoulos", "James Gibson", "Shrikanth Narayanan"], "https://doi.org/10.21437/Interspeech.2018-1654", 5, "interspeech", 2018], ["Language Features for Automated Evaluation of Cognitive Behavior Psychotherapy Sessions", ["Nikolaos Flemotomos", "Victor R. Martinez", "James Gibson", "David C. Atkins", "Torrey Creed", "Shrikanth Narayanan"], "https://doi.org/10.21437/Interspeech.2018-1518", 5, "interspeech", 2018], ["Using Prosodic and Lexical Information for Learning Utterance-level Behaviors in Psychotherapy", ["Karan Singla", "Zhuohao Chen", "Nikolaos Flemotomos", "James Gibson", "Dogan Can", "David C. Atkins", "Shrikanth Narayanan"], "https://doi.org/10.21437/Interspeech.2018-2551", 5, "interspeech", 2018]], "Afsaneh Asaei": [0, ["Phonological Posterior Hashing for Query by Example Spoken Term Detection", ["Afsaneh Asaei", "Dhananjay Ram", "Herve Bourlard"], "https://doi.org/10.21437/Interspeech.2018-1973", 5, "interspeech", 2018]], "Joe Pavitt": [0, ["The IBM Virtual Voice Creator", ["Alexander Sorin", "Slava Shechtman", "Zvi Kons", "Ron Hoory", "Shay Ben-David", "Joe Pavitt", "Shai Rozenberg", "Carmel Rabinovitz", "Tal Drory"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3011.html", 2, "interspeech", 2018]], "Samuel Thomas": [0, ["Data Augmentation Improves Recognition of Foreign Accented Speech", ["Takashi Fukuda", "Raul Fernandez", "Andrew Rosenberg", "Samuel Thomas", "Bhuvana Ramabhadran", "Alexander Sorin", "Gakuto Kurata"], "https://doi.org/10.21437/Interspeech.2018-1211", 5, "interspeech", 2018], ["Inference-Invariant Transformation of Batch Normalization for Domain Adaptation of Acoustic Models", ["Masayuki Suzuki", "Tohru Nagano", "Gakuto Kurata", "Samuel Thomas"], "https://doi.org/10.21437/Interspeech.2018-1563", 5, "interspeech", 2018]], "Preethi Jyothi": [0, ["Improved Accented Speech Recognition Using Accent Embeddings and Multi-task Learning", ["Abhinav Jain", "Minali Upreti", "Preethi Jyothi"], "https://doi.org/10.21437/Interspeech.2018-1864", 5, "interspeech", 2018], ["Dual Language Models for Code Switched Speech Recognition", ["Saurabh Garg", "Tanmay Parekh", "Preethi Jyothi"], "https://doi.org/10.21437/Interspeech.2018-1343", 5, "interspeech", 2018], ["Time Aggregation Operators for Multi-label Audio Event Detection", ["Pankaj Joshi", "Digvijaysingh Gautam", "Ganesh Ramakrishnan", "Preethi Jyothi"], "https://doi.org/10.21437/Interspeech.2018-1637", 5, "interspeech", 2018]], "Junbo Zhang": [0, ["Investigating Generative Adversarial Networks Based Speech Dereverberation for Robust Speech Recognition", ["Ke Wang", "Junbo Zhang", "Sining Sun", "Yujun Wang", "Fei Xiang", "Lei Xie"], "https://doi.org/10.21437/Interspeech.2018-1780", 5, "interspeech", 2018], ["Attention-based End-to-End Models for Small-Footprint Keyword Spotting", ["Changhao Shan", "Junbo Zhang", "Yujun Wang", "Lei Xie"], "https://doi.org/10.21437/Interspeech.2018-1777", 5, "interspeech", 2018], ["Empirical Evaluation of Speaker Adaptation on DNN Based Acoustic Model", ["Ke Wang", "Junbo Zhang", "Yujun Wang", "Lei Xie"], "https://doi.org/10.21437/Interspeech.2018-1897", 5, "interspeech", 2018]], "Jacob Goldberger": [0, ["Adding New Classes without Access to the Original Training Data with Applications to Language Identification", ["Hagai Taitelbaum", "Ehud Ben-Reuven", "Jacob Goldberger"], "https://doi.org/10.21437/Interspeech.2018-1342", 5, "interspeech", 2018]], "Martha Larson": [0, ["The Conversation Continues: the Effect of Lyrics and Music Complexity of Background Music on Spoken-Word Recognition", ["Odette Scharenborg", "Martha Larson"], "https://doi.org/10.21437/Interspeech.2018-1088", 5, "interspeech", 2018]], "Leonardo Badino": [0, ["Analyzing Vocal Tract Movements During Speech Accommodation", ["Sankar Mukherjee", "Thierry Legou", "Leonardo Lancia", "Pauline Hilt", "Alice Tomassini", "Luciano Fadiga", "Alessandro DAusilio", "Leonardo Badino", "Noel Nguyen"], "https://doi.org/10.21437/Interspeech.2018-2084", 5, "interspeech", 2018], ["Conditional-Computation-Based Recurrent Neural Networks for Computationally Efficient Acoustic Modelling", ["Raffaele Tavarone", "Leonardo Badino"], "https://doi.org/10.21437/Interspeech.2018-2195", 5, "interspeech", 2018]], "Ming Zhou": [0, ["WaveNet Vocoder with Limited Training Data for Voice Conversion", ["Li-Juan Liu", "Zhen-Hua Ling", "Yuan Jiang", "Ming Zhou", "Li-Rong Dai"], "https://doi.org/10.21437/Interspeech.2018-1190", 5, "interspeech", 2018]], "Yeunju Choi": [0.9971908330917358, ["Joint Learning Using Denoising Variational Autoencoders for Voice Activity Detection", ["Youngmoon Jung", "Younggwan Kim", "Yeunju Choi", "Hoirin Kim"], "https://doi.org/10.21437/Interspeech.2018-1151", 5, "interspeech", 2018]], "Caiming Xiong": [0, ["A Multi-Discriminator CycleGAN for Unsupervised Non-Parallel Speech Domain Adaptation", ["Ehsan Hosseini-Asl", "Yingbo Zhou", "Caiming Xiong", "Richard Socher"], "https://doi.org/10.21437/Interspeech.2018-1535", 5, "interspeech", 2018]], "Pascal Gaillard": [0, ["Perceptual and Automatic Evaluations of the Intelligibility of Speech Degraded by Noise Induced Hearing Loss Simulation", ["Imed Laaridh", "Julien Tardieu", "Cynthia Magnen", "Pascal Gaillard", "Jerome Farinas", "Julien Pinquier"], "https://doi.org/10.21437/Interspeech.2018-1264", 5, "interspeech", 2018]], "Golan Pundak": [0, ["Domain Adaptation Using Factorized Hidden Layer for Robust Automatic Speech Recognition", ["Khe Chai Sim", "Arun Narayanan", "Ananya Misra", "Anshuman Tripathi", "Golan Pundak", "Tara N. Sainath", "Parisa Haghani", "Bo Li", "Michiel Bacchiani"], "https://doi.org/10.21437/Interspeech.2018-2246", 5, "interspeech", 2018]], "Giuseppe Riccardi": [0, ["Coherence Models for Dialogue", ["Alessandra Cervone", "Evgeny A. Stepanov", "Giuseppe Riccardi"], "https://doi.org/10.21437/Interspeech.2018-2446", 5, "interspeech", 2018]], "Odette Scharenborg": [0, ["Visualizing Phoneme Category Adaptation in Deep Neural Networks", ["Odette Scharenborg", "Sebastian Tiesmeyer", "Mark Hasegawa-Johnson", "Najim Dehak"], "https://doi.org/10.21437/Interspeech.2018-1707", 5, "interspeech", 2018], ["Articulatory Feature Classification Using Convolutional Neural Networks", ["Danny Merkx", "Odette Scharenborg"], "https://doi.org/10.21437/Interspeech.2018-2275", 5, "interspeech", 2018], ["The Conversation Continues: the Effect of Lyrics and Music Complexity of Background Music on Spoken-Word Recognition", ["Odette Scharenborg", "Martha Larson"], "https://doi.org/10.21437/Interspeech.2018-1088", 5, "interspeech", 2018]], "Huy Phan": [0, ["Early Detection of Continuous and Partial Audio Events Using CNN", ["Ian Vince McLoughlin", "Yan Song", "Lam Dang Pham", "Ramaswamy Palaniappan", "Huy Phan", "Yue Lang"], "https://doi.org/10.21437/Interspeech.2018-1821", 5, "interspeech", 2018]], "Kazuki Irie": [0, ["Improved Training of End-to-end Attention Models for Speech Recognition", ["Albert Zeyer", "Kazuki Irie", "Ralf Schluter", "Hermann Ney"], "https://doi.org/10.21437/Interspeech.2018-1616", 5, "interspeech", 2018], ["Investigation on Estimation of Sentence Probability by Combining Forward, Backward and Bi-directional LSTM-RNNs", ["Kazuki Irie", "Zhihong Lei", "Liuhui Deng", "Ralf Schluter", "Hermann Ney"], "https://doi.org/10.21437/Interspeech.2018-1766", 4, "interspeech", 2018]], "Igor Jauk": [0, ["Expressive Speech Synthesis Using Sentiment Embeddings", ["Igor Jauk", "Jaime Lorenzo-Trueba", "Junichi Yamagishi", "Antonio Bonafonte"], "https://doi.org/10.21437/Interspeech.2018-2467", 5, "interspeech", 2018]], "Hee-Soo Heo": [0.996008962392807, ["Avoiding Speaker Overfitting in End-to-End DNNs Using Raw Waveform for Text-Independent Speaker Verification", ["Jee-weon Jung", "Hee-Soo Heo", "Il-Ho Yang", "Hye-jin Shim", "Ha-Jin Yu"], "https://doi.org/10.21437/Interspeech.2018-1608", 5, "interspeech", 2018]], "Hermann Ney": [0, ["Improved Training of End-to-end Attention Models for Speech Recognition", ["Albert Zeyer", "Kazuki Irie", "Ralf Schluter", "Hermann Ney"], "https://doi.org/10.21437/Interspeech.2018-1616", 5, "interspeech", 2018], ["Investigation on Estimation of Sentence Probability by Combining Forward, Backward and Bi-directional LSTM-RNNs", ["Kazuki Irie", "Zhihong Lei", "Liuhui Deng", "Ralf Schluter", "Hermann Ney"], "https://doi.org/10.21437/Interspeech.2018-1766", 4, "interspeech", 2018], ["Segmental Encoder-Decoder Models for Large Vocabulary Automatic Speech Recognition", ["Eugen Beck", "Mirko Hannemann", "Patrick Dotsch", "Ralf Schluter", "Hermann Ney"], "https://doi.org/10.21437/Interspeech.2018-1212", 5, "interspeech", 2018], ["Comparison of BLSTM-Layer-Specific Affine Transformations for Speaker Adaptation", ["Markus Kitza", "Ralf Schluter", "Hermann Ney"], "https://doi.org/10.21437/Interspeech.2018-2022", 5, "interspeech", 2018], ["Investigation on LSTM Recurrent N-gram Language Models for Speech Recognition", ["Zoltan Tuske", "Ralf Schluter", "Hermann Ney"], "https://doi.org/10.21437/Interspeech.2018-2476", 5, "interspeech", 2018]], "Patrick Kenny": [0, ["Deeply Fused Speaker Embeddings for Text-Independent Speaker Verification", ["Gautam Bhattacharya", "Md. Jahangir Alam", "Vishwa Gupta", "Patrick Kenny"], "https://doi.org/10.21437/Interspeech.2018-1688", 5, "interspeech", 2018]], "Triantafyllos Afouras": [0, ["The Conversation: Deep Audio-Visual Speech Enhancement", ["Triantafyllos Afouras", "Joon Son Chung", "Andrew Zisserman"], "https://doi.org/10.21437/Interspeech.2018-1400", 5, "interspeech", 2018], ["Deep Lip Reading: A Comparison of Models and an Online Application", ["Triantafyllos Afouras", "Joon Son Chung", "Andrew Zisserman"], "https://doi.org/10.21437/Interspeech.2018-1943", 5, "interspeech", 2018]], "Jesin James": [0, ["An Open Source Emotional Speech Corpus for Human Robot Interaction Applications", ["Jesin James", "Li Tian", "Catherine Inez Watson"], "https://doi.org/10.21437/Interspeech.2018-1349", 5, "interspeech", 2018]], "Hussnain Ali": [0, ["Testing Paradigms for Assistive Hearing Devices in Diverse Acoustic Environments", ["Ram Charan Chandra Shekar", "Hussnain Ali", "John H. L. Hansen"], "https://doi.org/10.21437/Interspeech.2018-1471", 5, "interspeech", 2018]], "Gualberto A. Guzman": [0, ["Should Code-switching Models Be Asymmetric?", ["Barbara E. Bullock", "Gualberto A. Guzman", "Jacqueline Serigos", "Almeida Jacqueline Toribio"], "https://doi.org/10.21437/Interspeech.2018-1284", 5, "interspeech", 2018]], "Eugenia San Segundo Fernandez": [0, ["The Individual and the System: Assessing the Stability of the Output of a Semi-automatic Forensic Voice Comparison System", ["Vincent Hughes", "Philip Harrison", "Paul Foulkes", "Peter French", "Colleen Kavanagh", "Eugenia San Segundo Fernandez"], "https://doi.org/10.21437/Interspeech.2018-1649", 5, "interspeech", 2018]], "Dhananjay Ram": [0, ["CNN Based Query by Example Spoken Term Detection", ["Dhananjay Ram", "Lesly Miculicich Werlen", "Herve Bourlard"], "https://doi.org/10.21437/Interspeech.2018-1722", 5, "interspeech", 2018], ["Phonological Posterior Hashing for Query by Example Spoken Term Detection", ["Afsaneh Asaei", "Dhananjay Ram", "Herve Bourlard"], "https://doi.org/10.21437/Interspeech.2018-1973", 5, "interspeech", 2018]], "Kazuho Watanabe": [0, ["Automatic DNN Node Pruning Using Mixture Distribution-based Group Regularization", ["Tsukasa Yoshida", "Takafumi Moriya", "Kazuho Watanabe", "Yusuke Shinohara", "Yoshikazu Yamaguchi", "Yushi Aono"], "https://doi.org/10.21437/Interspeech.2018-2062", 5, "interspeech", 2018]], "Yujun Wang": [0.4730056822299957, ["Investigating Generative Adversarial Networks Based Speech Dereverberation for Robust Speech Recognition", ["Ke Wang", "Junbo Zhang", "Sining Sun", "Yujun Wang", "Fei Xiang", "Lei Xie"], "https://doi.org/10.21437/Interspeech.2018-1780", 5, "interspeech", 2018], ["Attention-based End-to-End Models for Small-Footprint Keyword Spotting", ["Changhao Shan", "Junbo Zhang", "Yujun Wang", "Lei Xie"], "https://doi.org/10.21437/Interspeech.2018-1777", 5, "interspeech", 2018], ["Empirical Evaluation of Speaker Adaptation on DNN Based Acoustic Model", ["Ke Wang", "Junbo Zhang", "Yujun Wang", "Lei Xie"], "https://doi.org/10.21437/Interspeech.2018-1897", 5, "interspeech", 2018]], "Yue Sun": [0.006344831781461835, ["Analysis of L2 Learners' Progress of Distinguishing Mandarin Tone 2 and Tone 3", ["Yue Sun", "Win Thuzar Kyaw", "Jinsong Zhang", "Yoshinori Sagisaka"], "https://doi.org/10.21437/Interspeech.2018-1983", 5, "interspeech", 2018]], "Karel Benes": [0, ["i-Vectors in Language Modeling: An Efficient Way of Domain Adaptation for Feed-Forward Models", ["Karel Benes", "Santosh Kesiraju", "Lukas Burget"], "https://doi.org/10.21437/Interspeech.2018-1070", 5, "interspeech", 2018]], "Tomoki Hayashi": [0, ["Multi-Head Decoder for End-to-End Speech Recognition", ["Tomoki Hayashi", "Shinji Watanabe", "Tomoki Toda", "Kazuya Takeda"], "https://doi.org/10.21437/Interspeech.2018-1655", 5, "interspeech", 2018], ["Collapsed Speech Segment Detection and Suppression for WaveNet Vocoder", ["Yi-Chiao Wu", "Kazuhiro Kobayashi", "Tomoki Hayashi", "Patrick Lumban Tobing", "Tomoki Toda"], "https://doi.org/10.21437/Interspeech.2018-1210", 5, "interspeech", 2018], ["ESPnet: End-to-End Speech Processing Toolkit", ["Shinji Watanabe", "Takaaki Hori", "Shigeki Karita", "Tomoki Hayashi", "Jiro Nishitoba", "Yuya Unno", "Nelson Enrique Yalta Soplin", "Jahn Heymann", "Matthew Wiesner", "Nanxin Chen", "Adithya Renduchintala", "Tsubasa Ochiai"], "https://doi.org/10.21437/Interspeech.2018-1456", 5, "interspeech", 2018]], "Hiroya Fujisaki": [0, ["Acoustic and Perceptual Characteristics of Mandarin Speech in Homosexual and Heterosexual Male Speakers", ["Puyang Geng", "Wentao Gu", "Hiroya Fujisaki"], "https://doi.org/10.21437/Interspeech.2018-2225", 5, "interspeech", 2018]], "Kevin W. Wilson": [0, ["AVA-Speech: A Densely Labeled Dataset of Speech Activity in Movies", ["Sourish Chaudhuri", "Joseph Roth", "Daniel P. W. Ellis", "Andrew C. Gallagher", "Liat Kaver", "Radhika Marvin", "Caroline Pantofaru", "Nathan Reale", "Loretta Guarino Reid", "Kevin W. Wilson", "Zhonghua Xi"], "https://doi.org/10.21437/Interspeech.2018-2028", 5, "interspeech", 2018]], "Amit Das": [0, ["Improving DNNs Trained with Non-Native Transcriptions Using Knowledge Distillation and Target Interpolation", ["Amit Das", "Mark Hasegawa-Johnson"], "https://doi.org/10.21437/Interspeech.2018-1450", 5, "interspeech", 2018]], "Shan Xu": [0, ["Multi-frame Coding of LSF Parameters Using Block-Constrained Trellis Coded Vector Quantization", ["Yaxing Li", "Shan Xu", "Shengwu Xiong", "Anna Zhu", "Pengfei Duan", "Yueming Ding"], "https://doi.org/10.21437/Interspeech.2018-2578", 5, "interspeech", 2018]], "Hongwei Ding": [0, ["GlobalTIMIT: Acoustic-Phonetic Datasets for the World's Languages", ["Nattanun Chanchaochai", "Christopher Cieri", "Japhet Debrah", "Hongwei Ding", "Yue Jiang", "Sishi Liao", "Mark Liberman", "Jonathan Wright", "Jiahong Yuan", "Juhong Zhan", "Yuqing Zhan"], "https://doi.org/10.21437/Interspeech.2018-1185", 5, "interspeech", 2018]], "Shiyu Zhou": [0, ["Syllable-Based Sequence-to-Sequence Speech Recognition with the Transformer in Mandarin Chinese", ["Shiyu Zhou", "Linhao Dong", "Shuang Xu", "Bo Xu"], "https://doi.org/10.21437/Interspeech.2018-1107", 5, "interspeech", 2018], ["Extending Recurrent Neural Aligner for Streaming End-to-End Speech Recognition in Mandarin", ["Linhao Dong", "Shiyu Zhou", "Wei Chen", "Bo Xu"], "https://doi.org/10.21437/Interspeech.2018-1086", 5, "interspeech", 2018]], "Jaejin Cho": [0.962470218539238, ["Deep Neural Networks for Emotion Recognition Combining Audio and Transcripts", ["Jaejin Cho", "Raghavendra Pappagari", "Purva Kulkarni", "Jesus Villalba", "Yishay Carmiel", "Najim Dehak"], "https://doi.org/10.21437/Interspeech.2018-2466", 5, "interspeech", 2018]], "Zainab Millwala": [0, ["auMina\u2122 - Enterprise Speech Analytics", ["Umesh Sachdev", "Rajagopal Jayaraman", "Zainab Millwala"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3016.html", 2, "interspeech", 2018], ["akeira\u2122 - Virtual Assistant", ["Umesh Sachdev", "Rajagopal Jayaraman", "Zainab Millwala"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3018.html", 2, "interspeech", 2018]], "Lei Chen": [0, ["Liulishuo's System for the Spoken CALL Shared Task 2018", ["Huy Nguyen", "Lei Chen", "Ramon Prieto", "Chuan Wang", "Yang Liu"], "https://doi.org/10.21437/Interspeech.2018-1309", 5, "interspeech", 2018]], "Fumiaki Taguchi": [0, ["Articulatory-to-speech Conversion Using Bi-directional Long Short-term Memory", ["Fumiaki Taguchi", "Tokihiko Kaburagi"], "https://doi.org/10.21437/Interspeech.2018-999", 5, "interspeech", 2018]], "Selime Celik": [0, ["Multi-Lingual Depression-Level Assessment from Conversational Speech Using Acoustic and Text Features", ["Yasin Ozkanca", "Cenk Demiroglu", "Asli Besirli", "Selime Celik"], "https://doi.org/10.21437/Interspeech.2018-2169", 5, "interspeech", 2018]], "Zili Huang": [0, ["Angular Softmax for Short-Duration Text-independent Speaker Verification", ["Zili Huang", "Shuai Wang", "Kai Yu"], "https://doi.org/10.21437/Interspeech.2018-1545", 5, "interspeech", 2018]], "Peng Shen": [0, ["Temporal Attentive Pooling for Acoustic Event Detection", ["Xugang Lu", "Peng Shen", "Sheng Li", "Yu Tsao", "Hisashi Kawai"], "https://doi.org/10.21437/Interspeech.2018-1552", 4, "interspeech", 2018], ["Feature Representation of Short Utterances Based on Knowledge Distillation for Spoken Language Identification", ["Peng Shen", "Xugang Lu", "Sheng Li", "Hisashi Kawai"], "https://doi.org/10.21437/Interspeech.2018-1519", 5, "interspeech", 2018], ["Improving CTC-based Acoustic Model with Very Deep Residual Time-delay Neural Networks", ["Sheng Li", "Xugang Lu", "Ryoichi Takashima", "Peng Shen", "Tatsuya Kawahara", "Hisashi Kawai"], "https://doi.org/10.21437/Interspeech.2018-1475", 5, "interspeech", 2018]], "Kumi Kanamura": [0, ["A Study of Objective Measurement of Comprehensibility through Native Speakers' Shadowing of Learners' Utterances", ["Yusuke Inoue", "Suguru Kabashima", "Daisuke Saito", "Nobuaki Minematsu", "Kumi Kanamura", "Yutaka Yamauchi"], "https://doi.org/10.21437/Interspeech.2018-1860", 5, "interspeech", 2018]], "Ramakrishnan A. G": [0, ["Online Speech Translation System for Tamil", ["Madhavaraj Ayyavu", "Shiva Kumar H. R", "Ramakrishnan A. G"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3035.html", 2, "interspeech", 2018]], "John Gideon": [0, ["The PRIORI Emotion Dataset: Linking Mood to Emotion Detected In-the-Wild", ["Soheil Khorram", "Mimansa Jaiswal", "John Gideon", "Melvin G. McInnis", "Emily Mower Provost"], "https://doi.org/10.21437/Interspeech.2018-2355", 5, "interspeech", 2018]], "Andy Murphy": [0, ["Voice Source Contribution to Prominence Perception: Rd Implementation", ["Andy Murphy", "Irena Yanushevskaya", "Ailbhe Ni Chasaide", "Christer Gobl"], "https://doi.org/10.21437/Interspeech.2018-2352", 5, "interspeech", 2018], ["On the Relationship between Glottal Pulse Shape and Its Spectrum: Correlations of Open Quotient, Pulse Skew and Peak Flow with Source Harmonic Amplitudes", ["Christer Gobl", "Andy Murphy", "Irena Yanushevskaya", "Ailbhe Ni Chasaide"], "https://doi.org/10.21437/Interspeech.2018-2532", 5, "interspeech", 2018]], "Beiming Cao": [0, ["Dysarthric Speech Recognition Using Convolutional LSTM Neural Network", ["Myung Jong Kim", "Beiming Cao", "Kwanghoon An", "Jun Wang"], "https://doi.org/10.21437/Interspeech.2018-2250", 5, "interspeech", 2018], ["Articulation-to-Speech Synthesis Using Articulatory Flesh Point Sensors' Orientation Information", ["Beiming Cao", "Myung Jong Kim", "Jun R. Wang", "Jan P. H. van Santen", "Ted Mau", "Jun Wang"], "https://doi.org/10.21437/Interspeech.2018-2484", 5, "interspeech", 2018]], "Jimeng Zheng": [0, ["Text-Dependent Speech Enhancement for Small-Footprint Robust Keyword Detection", ["Meng Yu", "Xuan Ji", "Yi Gao", "Lianwu Chen", "Jie Chen", "Jimeng Zheng", "Dan Su", "Dong Yu"], "https://doi.org/10.21437/Interspeech.2018-1668", 5, "interspeech", 2018]], "Shogo Minagi": [0, ["Naturalness Improvement Algorithm for Reconstructed Glossectomy Patient's Speech Using Spectral Differential Modification in Voice Conversion", ["Hiroki Murakami", "Sunao Hara", "Masanobu Abe", "Masaaki Sato", "Shogo Minagi"], "https://doi.org/10.21437/Interspeech.2018-1239", 5, "interspeech", 2018]], "Andrew C. Gallagher": [0, ["AVA-Speech: A Densely Labeled Dataset of Speech Activity in Movies", ["Sourish Chaudhuri", "Joseph Roth", "Daniel P. W. Ellis", "Andrew C. Gallagher", "Liat Kaver", "Radhika Marvin", "Caroline Pantofaru", "Nathan Reale", "Loretta Guarino Reid", "Kevin W. Wilson", "Zhonghua Xi"], "https://doi.org/10.21437/Interspeech.2018-2028", 5, "interspeech", 2018]], "Shay Ben-David": [0, ["The IBM Virtual Voice Creator", ["Alexander Sorin", "Slava Shechtman", "Zvi Kons", "Ron Hoory", "Shay Ben-David", "Joe Pavitt", "Shai Rozenberg", "Carmel Rabinovitz", "Tal Drory"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3011.html", 2, "interspeech", 2018]], "Margaret Zellers": [0, ["A First Investigation of the Timing of Turn-taking in Ruuli", ["Tuarik Buanzur", "Margaret Zellers", "Saudah Namyalo", "Alena Witzlack-Makarevich"], "https://doi.org/10.21437/Interspeech.2018-1254", 5, "interspeech", 2018]], "Yerbolat Khassanov": [0, ["Unsupervised and Efficient Vocabulary Expansion for Recurrent Neural Network Language Models in ASR", ["Yerbolat Khassanov", "Eng Siong Chng"], "https://doi.org/10.21437/Interspeech.2018-1021", 5, "interspeech", 2018]], "Ji Xu": [0, ["Output-Gate Projected Gated Recurrent Unit for Speech Recognition", ["Gaofeng Cheng", "Daniel Povey", "Lu Huang", "Ji Xu", "Sanjeev Khudanpur", "Yonghong Yan"], "https://doi.org/10.21437/Interspeech.2018-1403", 5, "interspeech", 2018]], "T. Metin Sezgin": [0, ["Audio-Visual Prediction of Head-Nod and Turn-Taking Events in Dyadic Interactions", ["Bekir Berker Turker", "Engin Erzin", "Yucel Yemez", "T. Metin Sezgin"], "https://doi.org/10.21437/Interspeech.2018-2215", 5, "interspeech", 2018]], "Pegah Ghahremani": [0, ["End-to-end Deep Neural Network Age Estimation", ["Pegah Ghahremani", "Phani Sankar Nidadavolu", "Nanxin Chen", "Jesus Villalba", "Daniel Povey", "Sanjeev Khudanpur", "Najim Dehak"], "https://doi.org/10.21437/Interspeech.2018-2015", 5, "interspeech", 2018], ["Acoustic Modeling from Frequency Domain Representations of Speech", ["Pegah Ghahremani", "Hossein Hadian", "Hang Lv", "Daniel Povey", "Sanjeev Khudanpur"], "https://doi.org/10.21437/Interspeech.2018-1453", 5, "interspeech", 2018], ["Emotion Identification from Raw Speech Signals Using DNNs", ["Mousmita Sarma", "Pegah Ghahremani", "Daniel Povey", "Nagendra Kumar Goel", "Kandarpa Kumar Sarma", "Najim Dehak"], "https://doi.org/10.21437/Interspeech.2018-1353", 5, "interspeech", 2018]], "Takafumi Moriya": [0, ["Automatic DNN Node Pruning Using Mixture Distribution-based Group Regularization", ["Tsukasa Yoshida", "Takafumi Moriya", "Kazuho Watanabe", "Yusuke Shinohara", "Yoshikazu Yamaguchi", "Yushi Aono"], "https://doi.org/10.21437/Interspeech.2018-2062", 5, "interspeech", 2018], ["Multi-task Learning with Augmentation Strategy for Acoustic-to-word Attention-based Encoder-decoder Speech Recognition", ["Takafumi Moriya", "Sei Ueno", "Yusuke Shinohara", "Marc Delcroix", "Yoshikazu Yamaguchi", "Yushi Aono"], "https://doi.org/10.21437/Interspeech.2018-1866", 5, "interspeech", 2018], ["Encoder Transfer for Attention-based Acoustic-to-word Speech Recognition", ["Sei Ueno", "Takafumi Moriya", "Masato Mimura", "Shinsuke Sakai", "Yusuke Shinohara", "Yoshikazu Yamaguchi", "Yushi Aono", "Tatsuya Kawahara"], "https://doi.org/10.21437/Interspeech.2018-1424", 5, "interspeech", 2018]], "Xihong Wu": [0.0003008982093888335, ["Measuring the Band Importance Function for Mandarin Chinese with a Bayesian Adaptive Procedure", ["Yufan Du", "Yi Shen", "Hongying Yang", "Xihong Wu", "Jing Chen"], "https://doi.org/10.21437/Interspeech.2018-1825", 5, "interspeech", 2018]], "Sining Sun": [0.010369112715125084, ["Investigating Generative Adversarial Networks Based Speech Dereverberation for Robust Speech Recognition", ["Ke Wang", "Junbo Zhang", "Sining Sun", "Yujun Wang", "Fei Xiang", "Lei Xie"], "https://doi.org/10.21437/Interspeech.2018-1780", 5, "interspeech", 2018], ["Training Augmentation with Adversarial Examples for Robust Speech Recognition", ["Sining Sun", "Ching-Feng Yeh", "Mari Ostendorf", "Mei-Yuh Hwang", "Lei Xie"], "https://doi.org/10.21437/Interspeech.2018-1247", 5, "interspeech", 2018], ["A Probability Weighted Beamformer for Noise Robust ASR", ["Suliang Bu", "Yunxin Zhao", "Mei-Yuh Hwang", "Sining Sun"], "https://doi.org/10.21437/Interspeech.2018-2427", 5, "interspeech", 2018]], "Raghav Gupta": [0, ["An Efficient Approach to Encoding Context for Spoken Language Understanding", ["Raghav Gupta", "Abhinav Rastogi", "Dilek Hakkani-Tur"], "https://doi.org/10.21437/Interspeech.2018-2403", 5, "interspeech", 2018]], "Ricardo Gutierrez-Osuna": [0, ["Improving Sparse Representations in Exemplar-Based Voice Conversion with a Phoneme-Selective Objective Function", ["Shaojin Ding", "Guanlong Zhao", "Christopher Liberatore", "Ricardo Gutierrez-Osuna"], "https://doi.org/10.21437/Interspeech.2018-1272", 5, "interspeech", 2018], ["Learning Structured Dictionaries for Exemplar-based Voice Conversion", ["Shaojin Ding", "Christopher Liberatore", "Ricardo Gutierrez-Osuna"], "https://doi.org/10.21437/Interspeech.2018-1295", 5, "interspeech", 2018], ["L2-ARCTIC: A Non-native English Speech Corpus", ["Guanlong Zhao", "Sinem Sonsaat", "Alif Silpachai", "Ivana Lucic", "Evgeny Chukharev-Hudilainen", "John Levis", "Ricardo Gutierrez-Osuna"], "https://doi.org/10.21437/Interspeech.2018-1110", 5, "interspeech", 2018]], "Adrian Leemann": [0, ["Regional Variation of /r/ in Swiss German Dialects", ["Adrian Leemann", "Stephan Schmid", "Dieter Studer-Joho", "Marie-Jose Kolly"], "https://doi.org/10.21437/Interspeech.2018-1065", 5, "interspeech", 2018]], "Jindrich Zdansky": [0, ["Using Deep Neural Networks for Identification of Slavic Languages from Acoustic Signal", ["Lukas Mateju", "Petr Cerva", "Jindrich Zdansky", "Radek Safarik"], "https://doi.org/10.21437/Interspeech.2018-1165", 5, "interspeech", 2018]], "Mei-Yuh Hwang": [0.0003176184036419727, ["Training Augmentation with Adversarial Examples for Robust Speech Recognition", ["Sining Sun", "Ching-Feng Yeh", "Mari Ostendorf", "Mei-Yuh Hwang", "Lei Xie"], "https://doi.org/10.21437/Interspeech.2018-1247", 5, "interspeech", 2018], ["A Probability Weighted Beamformer for Noise Robust ASR", ["Suliang Bu", "Yunxin Zhao", "Mei-Yuh Hwang", "Sining Sun"], "https://doi.org/10.21437/Interspeech.2018-2427", 5, "interspeech", 2018]], "Minsoo Hahn": [0.989277109503746, ["Korean Singing Voice Synthesis Based on an LSTM Recurrent Neural Network", ["Juntae Kim", "Heejin Choi", "Jinuk Park", "Minsoo Hahn", "Sang-Jin Kim", "Jong-Jin Kim"], "https://doi.org/10.21437/Interspeech.2018-1575", 5, "interspeech", 2018]], "Rajib Rana": [0, ["Transfer Learning for Improving Speech Emotion Classification Accuracy", ["Siddique Latif", "Rajib Rana", "Shahzad Younis", "Junaid Qadir", "Julien Epps"], "https://doi.org/10.21437/Interspeech.2018-1625", 5, "interspeech", 2018], ["Variational Autoencoders for Learning Latent Representations of Speech Emotion: A Preliminary Study", ["Siddique Latif", "Rajib Rana", "Junaid Qadir", "Julien Epps"], "https://doi.org/10.21437/Interspeech.2018-1568", 5, "interspeech", 2018]], "Joseph Roth": [0, ["AVA-Speech: A Densely Labeled Dataset of Speech Activity in Movies", ["Sourish Chaudhuri", "Joseph Roth", "Daniel P. W. Ellis", "Andrew C. Gallagher", "Liat Kaver", "Radhika Marvin", "Caroline Pantofaru", "Nathan Reale", "Loretta Guarino Reid", "Kevin W. Wilson", "Zhonghua Xi"], "https://doi.org/10.21437/Interspeech.2018-2028", 5, "interspeech", 2018]], "Partha Pratim Das": [0, ["Harmonic-Percussive Source Separation of Polyphonic Music by Suppressing Impulsive Noise Events", ["Gurunath Reddy M.", "K. Sreenivasa Rao", "Partha Pratim Das"], "https://doi.org/10.21437/Interspeech.2018-1310", 5, "interspeech", 2018]], "Catherine Middag": [0, ["Vowel Space as a Tool to Evaluate Articulation Problems", ["Rob van Son", "Catherine Middag", "Kris Demuynck"], "https://doi.org/10.21437/Interspeech.2018-68", 5, "interspeech", 2018]], "Christoph Stemp": [0, ["Annotator Trustability-based Cooperative Learning Solutions for Intelligent Audio Analysis", ["Simone Hantke", "Christoph Stemp", "Bjorn W. Schuller"], "https://doi.org/10.21437/Interspeech.2018-1019", 5, "interspeech", 2018]], "Bhamini Sharma": [0, ["Effects of Homophone Density on Spoken Word Recognition in Mandarin Chinese", ["Bhamini Sharma"], "https://doi.org/10.21437/Interspeech.2018-2114", 4, "interspeech", 2018]], "Praveen Dayalu": [0, ["Classification of Huntington Disease Using Acoustic and Lexical Features", ["Matthew Perez", "Wenyu Jin", "Duc Le", "Noelle Carlozzi", "Praveen Dayalu", "Angela Roberts", "Emily Mower Provost"], "https://doi.org/10.21437/Interspeech.2018-2029", 5, "interspeech", 2018]], "Yonghong Yan": [0, ["Cross-Lingual Multi-Task Neural Architecture for Spoken Language Understanding", ["Yujiang Li", "Xuemin Zhao", "Weiqun Xu", "Yonghong Yan"], "https://doi.org/10.21437/Interspeech.2018-1039", 5, "interspeech", 2018], ["Multi-talker Speech Separation Based on Permutation Invariant Training and Beamforming", ["Lu Yin", "Ziteng Wang", "Risheng Xia", "Junfeng Li", "Yonghong Yan"], "https://doi.org/10.21437/Interspeech.2018-1739", 5, "interspeech", 2018], ["Output-Gate Projected Gated Recurrent Unit for Speech Recognition", ["Gaofeng Cheng", "Daniel Povey", "Lu Huang", "Ji Xu", "Sanjeev Khudanpur", "Yonghong Yan"], "https://doi.org/10.21437/Interspeech.2018-1403", 5, "interspeech", 2018], ["Investigation on the Combination of Batch Normalization and Dropout in BLSTM-based Acoustic Modeling for ASR", ["Wenjie Li", "Gaofeng Cheng", "Fengpei Ge", "Pengyuan Zhang", "Yonghong Yan"], "https://doi.org/10.21437/Interspeech.2018-1597", 5, "interspeech", 2018], ["Deep Convolutional Neural Network with Scalogram for Audio Scene Modeling", ["Hangting Chen", "Pengyuan Zhang", "Haichuan Bai", "Qingsheng Yuan", "Xiuguo Bao", "Yonghong Yan"], "https://doi.org/10.21437/Interspeech.2018-1524", 5, "interspeech", 2018], ["Improving Language Modeling with an Adversarial Critic for Automatic Speech Recognition", ["Yike Zhang", "Pengyuan Zhang", "Yonghong Yan"], "https://doi.org/10.21437/Interspeech.2018-1111", 5, "interspeech", 2018]], "Maulik C. Madhavi": [0, ["Unsupervised Vocal Tract Length Warped Posterior Features for Non-Parallel Voice Conversion", ["Nirmesh J. Shah", "Maulik C. Madhavi", "Hemant A. Patil"], "https://doi.org/10.21437/Interspeech.2018-1712", 5, "interspeech", 2018]], "Daniel Tihelka": [0, ["Glottal Closure Instant Detection from Speech Signal Using Voting Classifier and Recursive Feature Elimination", ["Jindrich Matousek", "Daniel Tihelka"], "https://doi.org/10.21437/Interspeech.2018-1147", 5, "interspeech", 2018]], "Branislav Gerazov": [0, ["A Weighted Superposition of Functional Contours Model for Modelling Contextual Prominence of Elementary Prosodic Contours", ["Branislav Gerazov", "Gerard Bailly", "Yi Xu"], "https://doi.org/10.21437/Interspeech.2018-1286", 5, "interspeech", 2018]], "Bajibabu Bollepalli": [0, ["Speaker-independent Raw Waveform Model for Glottal Excitation", ["Lauri Juvela", "Vassilis Tsiaras", "Bajibabu Bollepalli", "Manu Airaksinen", "Junichi Yamagishi", "Paavo Alku"], "https://doi.org/10.21437/Interspeech.2018-1635", 5, "interspeech", 2018]], "Ching-Lun Tai": [0, ["Joint Learning of Interactive Spoken Content Retrieval and Trainable User Simulator", ["Pei-Hung Chung", "Kuan Tung", "Ching-Lun Tai", "Hung-yi Lee"], "https://doi.org/10.21437/Interspeech.2018-1346", 5, "interspeech", 2018]], "Hui Lin": [0, ["Pitch Characteristics of L2 English Speech by Chinese Speakers: A Large-scale Study", ["Jiahong Yuan", "Qiusi Dong", "Fei Wu", "Huan Luan", "Xiaofei Yang", "Hui Lin", "Yang Liu"], "https://doi.org/10.21437/Interspeech.2018-1556", 5, "interspeech", 2018]], "Birger Kollmeier": [0, ["Prediction of Subjective Listening Effort from Acoustic Data with Non-Intrusive Deep Models", ["Paul Kranzusch", "Rainer Huber", "Melanie Kruger", "Birger Kollmeier", "Bernd T. Meyer"], "https://doi.org/10.21437/Interspeech.2018-1375", 5, "interspeech", 2018]], "Rushabh Gandhi": [0, ["HoloCompanion: An MR Friend for EveryOne", ["Annam Naresh", "Rushabh Gandhi", "Mallikarjuna Rao Bellamkonda", "Mithun Das Gupta"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3017.html", 2, "interspeech", 2018]], "Ayush Tripathi": [0, ["Estimation of Hypernasality Scores from Cleft Lip and Palate Speech", ["Vikram C. M.", "Ayush Tripathi", "Sishir Kalita", "S. R. Mahadeva Prasanna"], "https://doi.org/10.21437/Interspeech.2018-1631", 5, "interspeech", 2018]], "Andreas Spanias": [0, ["Triplet Network with Attention for Speaker Diarization", ["Huan Song", "Megan M. Willi", "Jayaraman J. Thiagarajan", "Visar Berisha", "Andreas Spanias"], "https://doi.org/10.21437/Interspeech.2018-2305", 5, "interspeech", 2018]], "Chen-Yu Chiang": [0, ["An Exploration of Local Speaking Rate Variations in Mandarin Read Speech", ["Guan-Ting Liou", "Chen-Yu Chiang", "Yih-Ru Wang", "Sin-Horng Chen"], "https://doi.org/10.21437/Interspeech.2018-1214", 5, "interspeech", 2018]], "Adrian Szymczak": [0, ["Punctuation Prediction Model for Conversational Speech", ["Piotr Zelasko", "Piotr Szymanski", "Jan Mizgajski", "Adrian Szymczak", "Yishay Carmiel", "Najim Dehak"], "https://doi.org/10.21437/Interspeech.2018-1096", 5, "interspeech", 2018]], "Anu Venkatesh": [0, ["Contextual Language Model Adaptation for Conversational Agents", ["Anirudh Raju", "Behnam Hedayatnia", "Linda Liu", "Ankur Gandhe", "Chandra Khatri", "Angeliki Metallinou", "Anu Venkatesh", "Ariya Rastrow"], "https://doi.org/10.21437/Interspeech.2018-1122", 5, "interspeech", 2018]], "Carl Vogel": [0, ["Improving Response Time of Active Speaker Detection Using Visual Prosody Information Prior to Articulation", ["Fasih Haider", "Saturnino Luz", "Carl Vogel", "Nick Campbell"], "https://doi.org/10.21437/Interspeech.2018-2310", 5, "interspeech", 2018]], "Ming Sun": [0.0060784968081861734, ["R-CRNN: Region-based Convolutional Recurrent Neural Network for Audio Event Detection", ["Chieh-Chi Kao", "Weiran Wang", "Ming Sun", "Chao Wang"], "https://doi.org/10.21437/Interspeech.2018-2323", 5, "interspeech", 2018]], "Kishalay Chakraborty": [0, ["Glotto Vibrato Graph: A Device and Method for Recording, Analysis and Visualization of Glottal Activity", ["Kishalay Chakraborty", "Senjam Shantirani Devi", "Sanjeevan Devnath", "S. R. Mahadeva Prasanna", "Priyankoo Sarmah"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3046.html", 2, "interspeech", 2018]], "Xiuguo Bao": [0, ["Deep Convolutional Neural Network with Scalogram for Audio Scene Modeling", ["Hangting Chen", "Pengyuan Zhang", "Haichuan Bai", "Qingsheng Yuan", "Xiuguo Bao", "Yonghong Yan"], "https://doi.org/10.21437/Interspeech.2018-1524", 5, "interspeech", 2018]], "Micha Breakstone": [0, ["Fully Automatic Speaker Separation System, with Automatic Enrolling of Recurrent Speakers", ["Raphael Cohen", "Orgad Keller", "Jason Levy", "Russell Levy", "Micha Breakstone", "Amit Ashkenazi"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3034.html", 2, "interspeech", 2018]], "Fabian-Robert Stoter": [0, ["Single-Channel Dereverberation Using Direct MMSE Optimization and Bidirectional LSTM Networks", ["Wolfgang Mack", "Soumitro Chakrabarty", "Fabian-Robert Stoter", "Sebastian Braun", "Bernd Edler", "Emanuel A. P. Habets"], "https://doi.org/10.21437/Interspeech.2018-1296", 5, "interspeech", 2018]], "Virginie Woisard": [0, ["Automatic Evaluation of Speech Intelligibility Based on I-vectors in the Context of Head and Neck Cancers", ["Imed Laaridh", "Corinne Fredouille", "Alain Ghio", "Muriel Lalain", "Virginie Woisard"], "https://doi.org/10.21437/Interspeech.2018-1266", 5, "interspeech", 2018]], "Jean-Luc Rouas": [0, ["Cultural Differences in Pattern Matching: Multisensory Recognition of Socio-affective Prosody", ["Takaaki Shochi", "Jean-Luc Rouas", "Marine Guerry", "Donna Erickson"], "https://doi.org/10.21437/Interspeech.2018-1795", 5, "interspeech", 2018]], "Yan Li": [0, ["Gated Recurrent Unit Based Acoustic Modeling with Future Context", ["Jie Li", "Xiaorui Wang", "Yuanyuan Zhao", "Yan Li"], "https://doi.org/10.21437/Interspeech.2018-1544", 5, "interspeech", 2018]], "Johannes Wagner": [0, ["Deep Learning in Paralinguistic Recognition Tasks: Are Hand-crafted Features Still Relevant?", ["Johannes Wagner", "Dominik Schiller", "Andreas Seiderer", "Elisabeth Andre"], "https://doi.org/10.21437/Interspeech.2018-1238", 5, "interspeech", 2018]], "Sarfaraz Jelil": [0, ["Exploration of Compressed ILPR Features for Replay Attack Detection", ["Sarfaraz Jelil", "Sishir Kalita", "S. R. Mahadeva Prasanna", "Rohit Sinha"], "https://doi.org/10.21437/Interspeech.2018-1297", 5, "interspeech", 2018]], "Karan Nathwani": [0, ["LSTM Based Attentive Fusion of Spectral and Prosodic Information for Keyword Spotting in Hindi Language", ["Laxmi Pandey", "Karan Nathwani"], "https://doi.org/10.21437/Interspeech.2018-1016", 5, "interspeech", 2018]], "Pramod B. Bachhav": [0, ["Artificial Bandwidth Extension with Memory Inclusion Using Semi-supervised Stacked Auto-encoders", ["Pramod B. Bachhav", "Massimiliano Todisco", "Nicholas W. D. Evans"], "https://doi.org/10.21437/Interspeech.2018-2213", 5, "interspeech", 2018]], "Hemant A. Patil": [0, ["Effectiveness of Speech Demodulation-Based Features for Replay Detection", ["Madhu R. Kamble", "Hemlata Tak", "Hemant A. Patil"], "https://doi.org/10.21437/Interspeech.2018-1675", 5, "interspeech", 2018], ["Novel Variable Length Energy Separation Algorithm Using Instantaneous Amplitude Features for Replay Detection", ["Madhu R. Kamble", "Hemant A. Patil"], "https://doi.org/10.21437/Interspeech.2018-1687", 5, "interspeech", 2018], ["Auditory Filterbank Learning for Temporal Modulation Features in Replay Spoof Speech Detection", ["Hardik B. Sailor", "Madhu R. Kamble", "Hemant A. Patil"], "https://doi.org/10.21437/Interspeech.2018-1651", 5, "interspeech", 2018], ["Auditory Filterbank Learning Using ConvRBM for Infant Cry Classification", ["Hardik B. Sailor", "Hemant A. Patil"], "https://doi.org/10.21437/Interspeech.2018-1536", 5, "interspeech", 2018], ["Effectiveness of Dynamic Features in INCA and Temporal Context-INCA", ["Nirmesh J. Shah", "Hemant A. Patil"], "https://doi.org/10.21437/Interspeech.2018-1538", 5, "interspeech", 2018], ["Novel Empirical Mode Decomposition Cepstral Features for Replay Spoof Detection", ["Prasad Tapkir", "Hemant A. Patil"], "https://doi.org/10.21437/Interspeech.2018-1661", 5, "interspeech", 2018], ["Novel Linear Frequency Residual Cepstral Features for Replay Attack Detection", ["Hemlata Tak", "Hemant A. Patil"], "https://doi.org/10.21437/Interspeech.2018-1702", 5, "interspeech", 2018], ["Unsupervised Vocal Tract Length Warped Posterior Features for Non-Parallel Voice Conversion", ["Nirmesh J. Shah", "Maulik C. Madhavi", "Hemant A. Patil"], "https://doi.org/10.21437/Interspeech.2018-1712", 5, "interspeech", 2018], ["Effectiveness of Generative Adversarial Network for Non-Audible Murmur-to-Whisper Speech Conversion", ["Neil Shah", "Nirmesh J. Shah", "Hemant A. Patil"], "https://doi.org/10.21437/Interspeech.2018-1565", 5, "interspeech", 2018], ["DA-IICT/IIITV System for Low Resource Speech Recognition Challenge 2018", ["Hardik B. Sailor", "Maddala Venkata Siva Krishna", "Diksha Chhabra", "Ankur T. Patil", "Madhu R. Kamble", "Hemant A. Patil"], "https://doi.org/10.21437/Interspeech.2018-1553", 5, "interspeech", 2018]], "Frederic Bechet": [0, ["Is ATIS Too Shallow to Go Deeper for Benchmarking Spoken Language Understanding Models?", ["Frederic Bechet", "Christian Raymond"], "https://doi.org/10.21437/Interspeech.2018-2256", 5, "interspeech", 2018]], "Prateek Verma": [0, ["Conditional End-to-End Audio Transforms", ["Albert Haque", "Michelle Guo", "Prateek Verma"], "https://doi.org/10.21437/Interspeech.2018-38", 5, "interspeech", 2018]], "Jonghun Park": [0.9659967869520187, ["Training Utterance-level Embedding Networks for Speaker Identification and Verification", ["Heewoong Park", "Sukhyun Cho", "Kyubyong Park", "Namju Kim", "Jonghun Park"], "https://doi.org/10.21437/Interspeech.2018-1044", 5, "interspeech", 2018]], "Jaime Hernandez-Cordero": [0, ["Performance Analysis of the 2017 NIST Language Recognition Evaluation", ["Seyed Omid Sadjadi", "Timothee Kheyrkhah", "Craig S. Greenberg", "Elliot Singer", "Douglas A. Reynolds", "Lisa P. Mason", "Jaime Hernandez-Cordero"], "https://doi.org/10.21437/Interspeech.2018-69", 5, "interspeech", 2018]], "Rainer Huber": [0, ["Prediction of Perceived Speech Quality Using Deep Machine Listening", ["Jasper Ooster", "Rainer Huber", "Bernd T. Meyer"], "https://doi.org/10.21437/Interspeech.2018-1374", 5, "interspeech", 2018], ["Prediction of Subjective Listening Effort from Acoustic Data with Non-Intrusive Deep Models", ["Paul Kranzusch", "Rainer Huber", "Melanie Kruger", "Birger Kollmeier", "Bernd T. Meyer"], "https://doi.org/10.21437/Interspeech.2018-1375", 5, "interspeech", 2018]], "Stephen D. Laycock": [0, ["Joint Learning of Facial Expression and Head Pose from Speech", ["David Greenwood", "Iain Matthews", "Stephen D. Laycock"], "https://doi.org/10.21437/Interspeech.2018-2587", 5, "interspeech", 2018]], "Mingxing Du": [0, ["Learning Word Embeddings: Unsupervised Methods for Fixed-size Representations of Variable-length Speech Segments", ["Nils Holzenberger", "Mingxing Du", "Julien Karadayi", "Rachid Riad", "Emmanuel Dupoux"], "https://doi.org/10.21437/Interspeech.2018-2364", 5, "interspeech", 2018]], "Hosana Kamiyama": [0, ["Automatic Question Detection from Acoustic and Phonetic Features Using Feature-wise Pre-training", ["Atsushi Ando", "Reine Asakawa", "Ryo Masumura", "Hosana Kamiyama", "Satoshi Kobashikawa", "Yushi Aono"], "https://doi.org/10.21437/Interspeech.2018-1755", 5, "interspeech", 2018]], "Shubhangi Tandon": [0, ["Neural MultiVoice Models for Expressing Novel Personalities in Dialog", ["Shereen Oraby", "Lena Reed", "Sharath T. S.", "Shubhangi Tandon", "Marilyn A. Walker"], "https://doi.org/10.21437/Interspeech.2018-2174", 5, "interspeech", 2018]], "S. R. Nirmala": [0, ["Robust Mizo Continuous Speech Recognition", ["Abhishek Dey", "Biswajit Dev Sarma", "Wendy Lalhminghlui", "Lalnunsiami Ngente", "Parismita Gogoi", "Priyankoo Sarmah", "S. R. Mahadeva Prasanna", "Rohit Sinha", "S. R. Nirmala"], "https://doi.org/10.21437/Interspeech.2018-2125", 5, "interspeech", 2018], ["AGROASSAM: A Web Based Assamese Speech Recognition Application for Retrieving Agricultural Commodity Price and Weather Information", ["Abhishek Dey", "Abhash Deka", "Siddika Imani", "Barsha Deka", "Rohit Sinha", "S. R. Mahadeva Prasanna", "Priyankoo Sarmah", "K. Samudravijaya", "S. R. Nirmala"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3048.html", 2, "interspeech", 2018]], "Zvi Kons": [0, ["The IBM Virtual Voice Creator", ["Alexander Sorin", "Slava Shechtman", "Zvi Kons", "Ron Hoory", "Shay Ben-David", "Joe Pavitt", "Shai Rozenberg", "Carmel Rabinovitz", "Tal Drory"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3011.html", 2, "interspeech", 2018]], "N. K. Kausthubha": [0, ["Intonation tutor by SPIRE (In-SPIRE): An Online Tool for an Automatic Feedback to the Second Language Learners in Learning Intonation", ["Anand P. A", "Chiranjeevi Yarra", "N. K. Kausthubha", "Prasanta Kumar Ghosh"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3008.html", 2, "interspeech", 2018], ["SPIRE-SST: An Automatic Web-based Self-learning Tool for Syllable Stress Tutoring (SST) to the Second Language Learners", ["Chiranjeevi Yarra", "Anand P. A", "N. K. Kausthubha", "Prasanta Kumar Ghosh"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3009.html", 2, "interspeech", 2018], ["Automatic Visual Augmentation for Concatenation Based Synthesized Articulatory Videos from Real-time MRI Data for Spoken Language Training", ["Chandana S", "Chiranjeevi Yarra", "Ritu Aggarwal", "Sanjeev Kumar Mittal", "N. K. Kausthubha", "Raseena K. T", "Astha Singh", "Prasanta Kumar Ghosh"], "https://doi.org/10.21437/Interspeech.2018-1570", 5, "interspeech", 2018]], "Albert Zeyer": [0, ["Improved Training of End-to-end Attention Models for Speech Recognition", ["Albert Zeyer", "Kazuki Irie", "Ralf Schluter", "Hermann Ney"], "https://doi.org/10.21437/Interspeech.2018-1616", 5, "interspeech", 2018]], "Satoru Hayamizu": [0, ["Audio-visual Voice Conversion Using Deep Canonical Correlation Analysis for Deep Bottleneck Features", ["Satoshi Tamura", "Kento Horio", "Hajime Endo", "Satoru Hayamizu", "Tomoki Toda"], "https://doi.org/10.21437/Interspeech.2018-2286", 5, "interspeech", 2018]], "Zhen Qin": [0, ["Long Distance Voice Channel Diagnosis Using Deep Neural Networks", ["Zhen Qin", "Tom Ko", "Guangjian Tian"], "https://doi.org/10.21437/Interspeech.2018-1428", 4, "interspeech", 2018]], "Arkady Arkhangorodsky": [0, ["Sequence-to-sequence Neural Network Model with 2D Attention for Learning Japanese Pitch Accents", ["Antoine Bruguier", "Heiga Zen", "Arkady Arkhangorodsky"], "https://doi.org/10.21437/Interspeech.2018-1381", 4, "interspeech", 2018]], "Jinsong Zhang": [0, ["Improving Mandarin Tone Recognition Using Convolutional Bidirectional Long Short-Term Memory with Attention", ["Longfei Yang", "Yanlu Xie", "Jinsong Zhang"], "https://doi.org/10.21437/Interspeech.2018-2561", 5, "interspeech", 2018], ["Emotional Prosody Perception in Mandarin-speaking Congenital Amusics", ["Yixin Zhang", "Tianzhu Geng", "Jinsong Zhang"], "https://doi.org/10.21437/Interspeech.2018-91", 5, "interspeech", 2018], ["Analysis of L2 Learners' Progress of Distinguishing Mandarin Tone 2 and Tone 3", ["Yue Sun", "Win Thuzar Kyaw", "Jinsong Zhang", "Yoshinori Sagisaka"], "https://doi.org/10.21437/Interspeech.2018-1983", 5, "interspeech", 2018], ["A Preliminary Study on Tonal Coarticulation in Continuous Speech", ["Lixia Hao", "Wei Zhang", "Yanlu Xie", "Jinsong Zhang"], "https://doi.org/10.21437/Interspeech.2018-1849", 5, "interspeech", 2018], ["Interactions between Vowels and Nasal Codas in Mandarin Speakers' Perception of Nasal Finals", ["Chong Cao", "Wei Wei", "Wei Wang", "Yanlu Xie", "Jinsong Zhang"], "https://doi.org/10.21437/Interspeech.2018-2025", 5, "interspeech", 2018]], "Takashi Fukuda": [0, ["Data Augmentation Improves Recognition of Foreign Accented Speech", ["Takashi Fukuda", "Raul Fernandez", "Andrew Rosenberg", "Samuel Thomas", "Bhuvana Ramabhadran", "Alexander Sorin", "Gakuto Kurata"], "https://doi.org/10.21437/Interspeech.2018-1211", 5, "interspeech", 2018]], "Shan Randhawa": [0, ["Rapid Collection of Spontaneous Speech Corpora Using Telephonic Community Forums", ["Agha Ali Raza", "Awais Athar", "Shan Randhawa", "Zain Tariq", "Muhammad Bilal Saleem", "Haris Bin Zia", "Umar Saif", "Roni Rosenfeld"], "https://doi.org/10.21437/Interspeech.2018-1139", 5, "interspeech", 2018]], "Keikichi Hirose": [0, ["Respiratory and Respiratory Muscular Control in JL1's and JL2's Text Reading Utilizing 4-RSTs and a Soft Respiratory Mask with a Two-Way Bulb", ["Toshiko Isei-Jaakkola", "Keiko Ochi", "Keikichi Hirose"], "https://doi.org/10.21437/Interspeech.2018-1948", 5, "interspeech", 2018]], "Jie Chen": [0, ["Deep Extractor Network for Target Speaker Recovery from Single Channel Speech Mixtures", ["Jun Wang", "Jie Chen", "Dan Su", "Lianwu Chen", "Meng Yu", "Yanmin Qian", "Dong Yu"], "https://doi.org/10.21437/Interspeech.2018-1205", 5, "interspeech", 2018], ["Text-Dependent Speech Enhancement for Small-Footprint Robust Keyword Detection", ["Meng Yu", "Xuan Ji", "Yi Gao", "Lianwu Chen", "Jie Chen", "Jimeng Zheng", "Dan Su", "Dong Yu"], "https://doi.org/10.21437/Interspeech.2018-1668", 5, "interspeech", 2018]], "Shabnam Ghaffarzadegan": [0, ["An Ensemble of Transfer, Semi-supervised and Supervised Learning Methods for Pathological Heart Sound Classification", ["Ahmed Imtiaz Humayun", "Md. Tauhiduzzaman Khan", "Shabnam Ghaffarzadegan", "Zhe Feng", "Taufiq Hasan"], "https://doi.org/10.21437/Interspeech.2018-2413", 5, "interspeech", 2018]], "KaWai Chen": [0, ["Training Recurrent Neural Network through Moment Matching for NLP Applications", ["Yue Deng", "Yilin Shen", "KaWai Chen", "Hongxia Jin"], "https://doi.org/10.21437/Interspeech.2018-1369", 5, "interspeech", 2018]], "Marcely Zanon Boito": [0, ["Unsupervised Word Segmentation from Speech with Attention", ["Pierre Godard", "Marcely Zanon Boito", "Lucas Ondel", "Alexandre Berard", "Francois Yvon", "Aline Villavicencio", "Laurent Besacier"], "https://doi.org/10.21437/Interspeech.2018-1308", 5, "interspeech", 2018]], "Zeyan Oo": [0, ["Multiple Phase Information Combination for Replay Attacks Detection", ["Dongbo Li", "Longbiao Wang", "Jianwu Dang", "Meng Liu", "Zeyan Oo", "Seiichi Nakagawa", "Haotian Guan", "Xiangang Li"], "https://doi.org/10.21437/Interspeech.2018-2001", 5, "interspeech", 2018]], "Anna Matosova": [0, ["UltraFit: A Speaker-friendly Headset for Ultrasound Recordings in Speech Science", ["Lorenzo Spreafico", "Michael Pucher", "Anna Matosova"], "https://doi.org/10.21437/Interspeech.2018-995", 4, "interspeech", 2018]], "Hussein Hussein": [0, ["Analysing the Focus of a Hierarchical Attention Network: the Importance of Enjambments When Classifying Post-modern Poetry", ["Timo Baumann", "Hussein Hussein", "Burkhard Meyer-Sickendiek"], "https://doi.org/10.21437/Interspeech.2018-2533", 5, "interspeech", 2018]], "Weicheng Cai": [0, ["Analysis of Length Normalization in End-to-End Speaker Verification System", ["Weicheng Cai", "Jinkun Chen", "Ming Li"], "https://doi.org/10.21437/Interspeech.2018-92", 5, "interspeech", 2018]], "Madhusudan Singh": [0, ["Linear Prediction Residual based Short-term Cepstral Features for Replay Attacks Detection", ["Madhusudan Singh", "Debadatta Pati"], "https://doi.org/10.21437/Interspeech.2018-1128", 5, "interspeech", 2018]], "Mahesh Kumar Nandwana": [0, ["Robust Speaker Recognition from Distant Speech under Real Reverberant Environments Using Speaker Embeddings", ["Mahesh Kumar Nandwana", "Julien van Hout", "Mitchell McLaren", "Allen R. Stauffer", "Colleen Richey", "Aaron Lawson", "Martin Graciarena"], "https://doi.org/10.21437/Interspeech.2018-2221", 5, "interspeech", 2018], ["Voices Obscured in Complex Environmental Settings (VOiCES) Corpus", ["Colleen Richey", "Maria Auxiliadora Barrios", "Zeb Armstrong", "Chris Bartels", "Horacio Franco", "Martin Graciarena", "Aaron Lawson", "Mahesh Kumar Nandwana", "Allen R. Stauffer", "Julien van Hout", "Paul Gamble", "Jeffrey Hetherly", "Cory Stephenson", "Karl Ni"], "https://doi.org/10.21437/Interspeech.2018-1454", 5, "interspeech", 2018], ["Analysis of Complementary Information Sources in the Speaker Embeddings Framework", ["Mahesh Kumar Nandwana", "Mitchell McLaren", "Diego Castan", "Julien van Hout", "Aaron Lawson"], "https://doi.org/10.21437/Interspeech.2018-1102", 5, "interspeech", 2018]], "Kamini Sabu": [0, ["Automatic Detection of Expressiveness in Oral Reading", ["Kamini Sabu", "Kanhaiya Kumar", "Preeti Rao"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3026.html", 2, "interspeech", 2018], ["A Study of Lexical and Prosodic Cues to Segmentation in a Hindi-English Code-switched Discourse", ["Preeti Rao", "Mugdha Pandya", "Kamini Sabu", "Kanhaiya Kumar", "Nandini Bondale"], "https://doi.org/10.21437/Interspeech.2018-1600", 5, "interspeech", 2018]], "Srinivasan Umesh": [0, ["Correlational Networks for Speaker Normalization in Automatic Speech Recognition", ["Rini A. Sharon", "Sandeep Reddy Kothinti", "Srinivasan Umesh"], "https://doi.org/10.21437/Interspeech.2018-1612", 5, "interspeech", 2018], ["Investigating the Effect of Audio Duration on Dementia Detection Using Acoustic Features", ["Jochen Weiner", "Miguel Angrick", "Srinivasan Umesh", "Tanja Schultz"], "https://doi.org/10.21437/Interspeech.2018-57", 5, "interspeech", 2018], ["Articulatory and Stacked Bottleneck Features for Low Resource Speech Recognition", ["Vishwas M. Shetty", "Rini A. Sharon", "Basil Abraham", "Tejaswi Seeram", "Anusha Prakash", "Nithya Ravi", "Srinivasan Umesh"], "https://doi.org/10.21437/Interspeech.2018-2226", 5, "interspeech", 2018]], "Julia Hirschberg": [0, ["Acoustic-Prosodic Indicators of Deception and Trust in Interview Dialogues", ["Sarah Ita Levitan", "Angel Maredia", "Julia Hirschberg"], "https://doi.org/10.21437/Interspeech.2018-2443", 5, "interspeech", 2018], ["Deep Personality Recognition for Deception Detection", ["Guozhen An", "Sarah Ita Levitan", "Julia Hirschberg", "Rivka Levitan"], "https://doi.org/10.21437/Interspeech.2018-2269", 5, "interspeech", 2018], ["The Role of Cognate Words, POS Tags and Entrainment in Code-Switching", ["Victor Soto", "Nishmar Cestero", "Julia Hirschberg"], "https://doi.org/10.21437/Interspeech.2018-1099", 5, "interspeech", 2018], ["A Comparison of Speaker-based and Utterance-based Data Selection for Text-to-Speech Synthesis", ["Kai-Zhan Lee", "Erica Cooper", "Julia Hirschberg"], "https://doi.org/10.21437/Interspeech.2018-1313", 5, "interspeech", 2018], ["Predicting Arousal and Valence from Waveforms and Spectrograms Using Deep Neural Networks", ["Zixiaofan Yang", "Julia Hirschberg"], "https://doi.org/10.21437/Interspeech.2018-2397", 5, "interspeech", 2018]], "Jason Lilley": [0, ["The Use of Machine Learning and Phonetic Endophenotypes to Discover Genetic Variants Associated with Speech Sound Disorder", ["Jason Lilley", "Erin Crowgey", "H. Timothy Bunnell"], "https://doi.org/10.21437/Interspeech.2018-2398", 5, "interspeech", 2018]], "Justin Scheiner": [0, ["Semantic Lattice Processing in Contextual Automatic Speech Recognition for Google Assistant", ["Leonid Velikovich", "Ian Williams", "Justin Scheiner", "Petar S. Aleksic", "Pedro J. Moreno", "Michael Riley"], "https://doi.org/10.21437/Interspeech.2018-2453", 5, "interspeech", 2018]], "Anuroop Sriram": [0, ["Cold Fusion: Training Seq2Seq Models Together with Language Models", ["Anuroop Sriram", "Heewoo Jun", "Sanjeev Satheesh", "Adam Coates"], "https://doi.org/10.21437/Interspeech.2018-1392", 5, "interspeech", 2018]], "V. Ramasubramanian": [0, ["Indian Languages ASR: A Multilingual Phone Recognition Framework with IPA Based Common Phone-set, Predicted Articulatory Features and Feature fusion", ["K. E. Manjunath", "K. Sreenivasa Rao", "Dinesh Babu Jayagopi", "V. Ramasubramanian"], "https://doi.org/10.21437/Interspeech.2018-2529", 5, "interspeech", 2018], ["Semi-supervised and Active-learning Scenarios: Efficient Acoustic Model Refinement for a Low Resource Indian Language", ["Maharajan Chellapriyadharshini", "Anoop Toffy", "Srinivasa Raghavan K. M.", "V. Ramasubramanian"], "https://doi.org/10.21437/Interspeech.2018-2486", 5, "interspeech", 2018]], "Tejaswi Seeram": [0, ["Articulatory and Stacked Bottleneck Features for Low Resource Speech Recognition", ["Vishwas M. Shetty", "Rini A. Sharon", "Basil Abraham", "Tejaswi Seeram", "Anusha Prakash", "Nithya Ravi", "Srinivasan Umesh"], "https://doi.org/10.21437/Interspeech.2018-2226", 5, "interspeech", 2018]], "Tifani Warnita": [0, ["Detecting Alzheimer's Disease Using Gated Convolutional Neural Network from Audio Data", ["Tifani Warnita", "Nakamasa Inoue", "Koichi Shinoda"], "https://doi.org/10.21437/Interspeech.2018-1713", 5, "interspeech", 2018]], "Anoop Toffy": [0, ["Semi-supervised and Active-learning Scenarios: Efficient Acoustic Model Refinement for a Low Resource Indian Language", ["Maharajan Chellapriyadharshini", "Anoop Toffy", "Srinivasa Raghavan K. M.", "V. Ramasubramanian"], "https://doi.org/10.21437/Interspeech.2018-2486", 5, "interspeech", 2018]], "Chiranjeevi Yarra": [0, ["Intonation tutor by SPIRE (In-SPIRE): An Online Tool for an Automatic Feedback to the Second Language Learners in Learning Intonation", ["Anand P. A", "Chiranjeevi Yarra", "N. K. Kausthubha", "Prasanta Kumar Ghosh"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3008.html", 2, "interspeech", 2018], ["SPIRE-SST: An Automatic Web-based Self-learning Tool for Syllable Stress Tutoring (SST) to the Second Language Learners", ["Chiranjeevi Yarra", "Anand P. A", "N. K. Kausthubha", "Prasanta Kumar Ghosh"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3009.html", 2, "interspeech", 2018], ["Automatic Visual Augmentation for Concatenation Based Synthesized Articulatory Videos from Real-time MRI Data for Spoken Language Training", ["Chandana S", "Chiranjeevi Yarra", "Ritu Aggarwal", "Sanjeev Kumar Mittal", "N. K. Kausthubha", "Raseena K. T", "Astha Singh", "Prasanta Kumar Ghosh"], "https://doi.org/10.21437/Interspeech.2018-1570", 5, "interspeech", 2018]], "Tanumay Mandal": [0, ["Classification of Disorders in Vocal Folds Using Electroglottographic Signal", ["Tanumay Mandal", "K. Sreenivasa Rao", "Sanjay Kumar Gupta"], "https://doi.org/10.21437/Interspeech.2018-1967", 5, "interspeech", 2018]], "Abhay Kumar": [0, ["Speech Emotion Recognition Using Spectrogram & Phoneme Embedding", ["Promod Yenigalla", "Abhay Kumar", "Suraj Tripathi", "Chirag Singh", "Sibsambhu Kar", "Jithendra Vepa"], "https://doi.org/10.21437/Interspeech.2018-1811", 5, "interspeech", 2018]], "Enea Ceolini": [0, ["Multi-channel Attention for End-to-End Speech Recognition", ["Stefan Braun", "Daniel Neil", "Jithendar Anumula", "Enea Ceolini", "Shih-Chii Liu"], "https://doi.org/10.21437/Interspeech.2018-1301", 5, "interspeech", 2018], ["Speaker Activity Detection and Minimum Variance Beamforming for Source Separation", ["Enea Ceolini", "Jithendar Anumula", "Adrian E. G. Huber", "Ilya Kiselev", "Shih-Chii Liu"], "https://doi.org/10.21437/Interspeech.2018-1606", 5, "interspeech", 2018]], "Zack Hodari": [0, ["Learning Interpretable Control Dimensions for Speech Synthesis by Using External Data", ["Zack Hodari", "Oliver Watts", "Srikanth Ronanki", "Simon King"], "https://doi.org/10.21437/Interspeech.2018-2075", 5, "interspeech", 2018]], "Mingxing Xu": [0, ["Imbalance Learning-based Framework for Fear Recognition in the MediaEval Emotional Impact of Movies Task", ["Xiaotong Zhang", "Xingliang Cheng", "Mingxing Xu", "Thomas Fang Zheng"], "https://doi.org/10.21437/Interspeech.2018-1744", 5, "interspeech", 2018], ["Emotion Recognition from Variable-Length Speech Segments Using Deep Learning on Spectrograms", ["Xi Ma", "Zhiyong Wu", "Jia Jia", "Mingxing Xu", "Helen Meng", "Lianhong Cai"], "https://doi.org/10.21437/Interspeech.2018-2228", 5, "interspeech", 2018]], "Patrick Reidy": [0, ["Sensorimotor Response to Tongue Displacement Imagery by Talkers with Parkinson's Disease", ["William F. Katz", "Patrick Reidy", "Divya Prabhakaran"], "https://doi.org/10.21437/Interspeech.2018-2592", 5, "interspeech", 2018]], "Wenhao Ding": [0, ["MTGAN: Speaker Verification through Multitasking Triplet Generative Adversarial Networks", ["Wenhao Ding", "Liang He"], "https://doi.org/10.21437/Interspeech.2018-1023", 5, "interspeech", 2018]], "Mariapaola DImperio": [0, ["Prosodic Focus Acquisition in French Early Cochlear Implanted Children", ["Chadi Farah", "Stephane Roman", "Mariapaola DImperio"], "https://doi.org/10.21437/Interspeech.2018-1320", 5, "interspeech", 2018]], "Rini A. Sharon": [0, ["Correlational Networks for Speaker Normalization in Automatic Speech Recognition", ["Rini A. Sharon", "Sandeep Reddy Kothinti", "Srinivasan Umesh"], "https://doi.org/10.21437/Interspeech.2018-1612", 5, "interspeech", 2018], ["Articulatory and Stacked Bottleneck Features for Low Resource Speech Recognition", ["Vishwas M. Shetty", "Rini A. Sharon", "Basil Abraham", "Tejaswi Seeram", "Anusha Prakash", "Nithya Ravi", "Srinivasan Umesh"], "https://doi.org/10.21437/Interspeech.2018-2226", 5, "interspeech", 2018]], "Richard W. Harvey": [0, ["Building Large-vocabulary Speaker-independent Lipreading Systems", ["Kwanchiva Thangthai", "Richard W. Harvey"], "https://doi.org/10.21437/Interspeech.2018-2112", 5, "interspeech", 2018]], "Shakuntala Mahanta": [0, ["A Hybrid Approach to Grapheme to Phoneme Conversion in Assamese", ["Somnath Roy", "Shakuntala Mahanta"], "https://doi.org/10.21437/Interspeech.2018-1694", 5, "interspeech", 2018]], "Xiaofei Wang": [3.716871946231055e-15, ["Stream Attention for Distributed Multi-Microphone Speech Recognition", ["Xiaofei Wang", "Ruizhi Li", "Hynek Hermansky"], "https://doi.org/10.21437/Interspeech.2018-1037", 5, "interspeech", 2018]], "Peter W. Foltz": [0, ["Modeling Self-Reported and Observed Affect from Speech", ["Jian Cheng", "Jared Bernstein", "Elizabeth Rosenfeld", "Peter W. Foltz", "Alex S. Cohen", "Terje B. Holmlund", "Brita Elvevag"], "https://doi.org/10.21437/Interspeech.2018-2222", 5, "interspeech", 2018]], "Anderson R. Avila": [0, ["Investigating Speech Enhancement and Perceptual Quality for Speech Emotion Recognition", ["Anderson R. Avila", "Md. Jahangir Alam", "Douglas D. OShaughnessy", "Tiago H. Falk"], "https://doi.org/10.21437/Interspeech.2018-2350", 5, "interspeech", 2018]], "Fang Hu": [0, ["Vowels and Diphthongs in Hangzhou Wu Chinese Dialect", ["Yang Yue", "Fang Hu"], "https://doi.org/10.21437/Interspeech.2018-1225", 5, "interspeech", 2018], ["Pitch or Phonation: on the Glottalization in Tone Productions in the Ruokeng Hui Chinese Dialect", ["Minghui Zhang", "Fang Hu"], "https://doi.org/10.21437/Interspeech.2018-1638", 5, "interspeech", 2018]], "Ehud Ben-Reuven": [0, ["Adding New Classes without Access to the Original Training Data with Applications to Language Identification", ["Hagai Taitelbaum", "Ehud Ben-Reuven", "Jacob Goldberger"], "https://doi.org/10.21437/Interspeech.2018-1342", 5, "interspeech", 2018]], "Bradley Law": [0, ["Deep Learning Techniques for Koala Activity Detection", ["Ivan Himawan", "Michael Towsey", "Bradley Law", "Paul Roe"], "https://doi.org/10.21437/Interspeech.2018-1143", 5, "interspeech", 2018]], "Marie-Jose Caraty": [0, ["Vocalic, Lexical and Prosodic Cues for the INTERSPEECH 2018 Self-Assessed Affect Challenge", ["Claude Montacie", "Marie-Jose Caraty"], "https://doi.org/10.21437/Interspeech.2018-1331", 5, "interspeech", 2018]], "Veeramani Priyadharshini": [0, ["Automatic Glottis Localization and Segmentation in Stroboscopic Videos Using Deep Neural Network", ["M. V. Achuth Rao", "Rahul Krishnamurthy", "Pebbili Gopikishore", "Veeramani Priyadharshini", "Prasanta Kumar Ghosh"], "https://doi.org/10.21437/Interspeech.2018-2572", 5, "interspeech", 2018]], "Engin Erzin": [0, ["Monitoring Infant's Emotional Cry in Domestic Environments Using the Capsule Network Architecture", ["Mehmet Ali Tugtekin Turan", "Engin Erzin"], "https://doi.org/10.21437/Interspeech.2018-2187", 5, "interspeech", 2018], ["Audio-Visual Prediction of Head-Nod and Turn-Taking Events in Dyadic Interactions", ["Bekir Berker Turker", "Engin Erzin", "Yucel Yemez", "T. Metin Sezgin"], "https://doi.org/10.21437/Interspeech.2018-2215", 5, "interspeech", 2018]], "Biao Zeng": [0, ["Visual Timing Information in Audiovisual Speech Perception: Evidence from Lexical Tone Contour", ["Hui Xie", "Biao Zeng", "Rui Wang"], "https://doi.org/10.21437/Interspeech.2018-1285", 5, "interspeech", 2018]], "Saurabh Sahu": [0, ["On Enhancing Speech Emotion Recognition Using Generative Adversarial Networks", ["Saurabh Sahu", "Rahul Gupta", "Carol Y. Espy-Wilson"], "https://doi.org/10.21437/Interspeech.2018-1883", 5, "interspeech", 2018]], "Benjamin Milde": [0, ["Unspeech: Unsupervised Speech Context Embeddings", ["Benjamin Milde", "Chris Biemann"], "https://doi.org/10.21437/Interspeech.2018-2194", 5, "interspeech", 2018]], "Keelan Evanini": [0, ["Game-based Spoken Dialog Language Learning Applications for Young Students", ["Keelan Evanini", "Veronika Timpe-Laughlin", "Eugene Tsuprun", "Ian Blood", "Jeremy Lee", "James V. Bruno", "Vikram Ramanarayanan", "Patrick L. Lange", "David Suendermann-Oeft"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3045.html", 2, "interspeech", 2018], ["Toward Scalable Dialog Technology for Conversational Language Learning: Case Study of the TOEFL\u00ae MOOC", ["Vikram Ramanarayanan", "David Pautler", "Patrick L. Lange", "Eugene Tsuprun", "Rutuja Ubale", "Keelan Evanini", "David Suendermann-Oeft"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3032.html", 2, "interspeech", 2018], ["Improvements to an Automated Content Scoring System for Spoken CALL Responses: the ETS Submission to the Second Spoken CALL Shared Task", ["Keelan Evanini", "Matthew Mulholland", "Rutuja Ubale", "Yao Qian", "Robert A. Pugh", "Vikram Ramanarayanan", "Aoife Cahill"], "https://doi.org/10.21437/Interspeech.2018-2362", 5, "interspeech", 2018]], "Aditya Nigam": [0, ["All-Conv Net for Bird Activity Detection: Significance of Learned Pooling", ["Arjun Pankajakshan", "Anshul Thakur", "Daksh Thapar", "Padmanabhan Rajan", "Aditya Nigam"], "https://doi.org/10.21437/Interspeech.2018-1522", 5, "interspeech", 2018]], "Michiel Sanders": [0, ["Improved Acoustic Modelling for Automatic Literacy Assessment of Children", ["Mauro Nicolao", "Michiel Sanders", "Thomas Hain"], "https://doi.org/10.21437/Interspeech.2018-2118", 5, "interspeech", 2018]], "Maren Kucza": [0, ["Term Extraction via Neural Sequence Labeling a Comparative Evaluation of Strategies Using Recurrent Neural Networks", ["Maren Kucza", "Jan Niehues", "Thomas Zenkel", "Alex Waibel", "Sebastian Stuker"], "https://doi.org/10.21437/Interspeech.2018-2017", 5, "interspeech", 2018]], "Anusha Prakash": [0, ["Code-switching in Indic Speech Synthesisers", ["Anju Leela Thomas", "Anusha Prakash", "Arun Baby", "Hema A. Murthy"], "https://doi.org/10.21437/Interspeech.2018-1178", 5, "interspeech", 2018], ["Articulatory and Stacked Bottleneck Features for Low Resource Speech Recognition", ["Vishwas M. Shetty", "Rini A. Sharon", "Basil Abraham", "Tejaswi Seeram", "Anusha Prakash", "Nithya Ravi", "Srinivasan Umesh"], "https://doi.org/10.21437/Interspeech.2018-2226", 5, "interspeech", 2018]], "Kazuhiro Kondo": [0, ["Binaural Speech Intelligibility Estimation Using Deep Neural Networks", ["Kazuhiro Kondo", "Kazuya Taira", "Yosuke Kobayashi"], "https://doi.org/10.21437/Interspeech.2018-27", 5, "interspeech", 2018]], "Fengquan Dong": [6.238314864681627e-10, ["The INTERSPEECH 2018 Computational Paralinguistics Challenge: Atypical & Self-Assessed Affect, Crying & Heart Beats", ["Bjorn W. Schuller", "Stefan Steidl", "Anton Batliner", "Peter B. Marschik", "Harald Baumeister", "Fengquan Dong", "Simone Hantke", "Florian B. Pokorny", "Eva-Maria Rathner", "Katrin D. Bartl-Pokorny", "Christa Einspieler", "Dajie Zhang", "Alice Baird", "Shahin Amiriparian", "Kun Qian", "Zhao Ren", "Maximilian Schmitt", "Panagiotis Tzirakis", "Stefanos Zafeiriou"], "https://doi.org/10.21437/Interspeech.2018-51", 5, "interspeech", 2018]], "Irena Yanushevskaya": [0, ["Voice Source Contribution to Prominence Perception: Rd Implementation", ["Andy Murphy", "Irena Yanushevskaya", "Ailbhe Ni Chasaide", "Christer Gobl"], "https://doi.org/10.21437/Interspeech.2018-2352", 5, "interspeech", 2018], ["On the Relationship between Glottal Pulse Shape and Its Spectrum: Correlations of Open Quotient, Pulse Skew and Peak Flow with Source Harmonic Amplitudes", ["Christer Gobl", "Andy Murphy", "Irena Yanushevskaya", "Ailbhe Ni Chasaide"], "https://doi.org/10.21437/Interspeech.2018-2532", 5, "interspeech", 2018]], "Nengheng Zheng": [0, ["Weighting Pitch Contour and Loudness Contour in Mandarin Tone Perception in Cochlear Implant Listeners", ["Qinglin Meng", "Nengheng Zheng", "Ambika Prasad Mishra", "Jacinta Dan Luo", "Jan W. H. Schnupp"], "https://doi.org/10.21437/Interspeech.2018-1245", 4, "interspeech", 2018]], "Thomas Glarner": [0, ["Full Bayesian Hidden Markov Model Variational Autoencoder for Acoustic Unit Discovery", ["Thomas Glarner", "Patrick Hanebrink", "Janek Ebbers", "Reinhold Haeb-Umbach"], "https://doi.org/10.21437/Interspeech.2018-2148", 5, "interspeech", 2018]], "Anna Silnova": [0, ["Fast Variational Bayes for Heavy-tailed PLDA Applied to i-vectors and x-vectors", ["Anna Silnova", "Niko Brummer", "Daniel Garcia-Romero", "David Snyder", "Lukas Burget"], "https://doi.org/10.21437/Interspeech.2018-2128", 5, "interspeech", 2018], ["BUT System for DIHARD Speech Diarization Challenge 2018", ["Mireia Diez", "Federico Landini", "Lukas Burget", "Johan Rohdin", "Anna Silnova", "Katerina Zmolikova", "Ondrej Novotny", "Karel Vesely", "Ondrej Glembek", "Oldrich Plchot", "Ladislav Mosner", "Pavel Matejka"], "https://doi.org/10.21437/Interspeech.2018-1749", 5, "interspeech", 2018]], "Yonghe Wang": [0.22981642931699753, ["Improving Mongolian Phrase Break Prediction by Using Syllable and Morphological Embeddings with BiLSTM Model", ["Rui Liu", "Feilong Bao", "Guanglai Gao", "Hui Zhang", "Yonghe Wang"], "https://doi.org/10.21437/Interspeech.2018-1706", 5, "interspeech", 2018]], "Vassilios Diakoloukas": [0, ["A Case Study on the Importance of Belief State Representation for Dialogue Policy Management", ["Margarita Kotti", "Vassilios Diakoloukas", "Alexandros Papangelis", "Michail Lagoudakis", "Yannis Stylianou"], "https://doi.org/10.21437/Interspeech.2018-1293", 5, "interspeech", 2018]], "Ivan Himawan": [0, ["Deep Learning Techniques for Koala Activity Detection", ["Ivan Himawan", "Michael Towsey", "Bradley Law", "Paul Roe"], "https://doi.org/10.21437/Interspeech.2018-1143", 5, "interspeech", 2018], ["Employing Phonetic Information in DNN Speaker Embeddings to Improve Speaker Recognition Performance", ["Md. Hafizur Rahman", "Ivan Himawan", "Mitchell McLaren", "Clinton Fookes", "Sridha Sridharan"], "https://doi.org/10.21437/Interspeech.2018-1804", 5, "interspeech", 2018]], "Neeraj Sharma": [0, ["Multicomponent 2-D AM-FM Modeling of Speech Spectrograms", ["Jitendra Kumar Dhiman", "Neeraj Sharma", "Chandra Sekhar Seelamantula"], "https://doi.org/10.21437/Interspeech.2018-1937", 5, "interspeech", 2018]], "Katherine Finkelstein": [0, ["The Effect of Exposure to High Altitude and Heat on Speech Articulatory Coordination", ["James R. Williamson", "Thomas F. Quatieri", "Adam C. Lammert", "Katherine Mitchell", "Katherine Finkelstein", "Nicole Ekon", "Caitlin Dillon", "Robert Kenefick", "Kristin Heaton"], "https://doi.org/10.21437/Interspeech.2018-2372", 5, "interspeech", 2018]], "Vikramjit Mitra": [0, ["Articulatory Features for ASR of Pathological Speech", ["Emre Yilmaz", "Vikramjit Mitra", "Chris Bartels", "Horacio Franco"], "https://doi.org/10.21437/Interspeech.2018-67", 5, "interspeech", 2018], ["Noise Robust Acoustic to Articulatory Speech Inversion", ["Nadee Seneviratne", "Ganesh Sivaraman", "Vikramjit Mitra", "Carol Y. Espy-Wilson"], "https://doi.org/10.21437/Interspeech.2018-1509", 5, "interspeech", 2018]], "Bogdan Vlasenko": [0, ["Implementing Fusion Techniques for the Classification of Paralinguistic Information", ["Bogdan Vlasenko", "Jilt Sebastian", "Pavan Kumar D. S.", "Mathew Magimai-Doss"], "https://doi.org/10.21437/Interspeech.2018-2360", 5, "interspeech", 2018]], "Nauman Dawalatabad": [0, ["Information Bottleneck Based Percussion Instrument Diarization System for Taniavartanam Segments of Carnatic Music Concerts", ["Nauman Dawalatabad", "Jom Kuriakose", "Chellu Chandra Sekhar", "Hema A. Murthy"], "https://doi.org/10.21437/Interspeech.2018-1203", 5, "interspeech", 2018]], "Wenqing Zong": [0, ["Learning Two Tone Languages Enhances the Brainstem Encoding of Lexical Tones", ["Akshay Raj Maggu", "Wenqing Zong", "Vina Law", "Patrick C. M. Wong"], "https://doi.org/10.21437/Interspeech.2018-2130", 5, "interspeech", 2018]], "Shan Liang": [0, ["Deep Noise Tracking Network: A Hybrid Signal Processing/Deep Learning Approach to Speech Enhancement", ["Shuai Nie", "Shan Liang", "Bin Liu", "Yaping Zhang", "Wenju Liu", "Jianhua Tao"], "https://doi.org/10.21437/Interspeech.2018-1020", 5, "interspeech", 2018]], "Shashidhar G. Koolagudi": [0, ["Robust Acoustic Event Classification Using Bag-of-Visual-Words", ["Manjunath Mulimani", "Shashidhar G. Koolagudi"], "https://doi.org/10.21437/Interspeech.2018-1905", 4, "interspeech", 2018]], "James Fone": [0, ["An Automated Assistant for Medical Scribes", ["Gregory P. Finley", "Erik Edwards", "Amanda Robinson", "Najmeh Sadoughi", "James Fone", "Mark Miller", "David Suendermann-Oeft", "Michael Brenndoerfer", "Nico Axtmann"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3047.html", 2, "interspeech", 2018]], "Deepak Baby": [0, ["Biophysically-inspired Features Improve the Generalizability of Neural Network-based Speech Enhancement Systems", ["Deepak Baby", "Sarah Verhulst"], "https://doi.org/10.21437/Interspeech.2018-1237", 5, "interspeech", 2018]], "Hui Zhang": [0, ["Improving Mongolian Phrase Break Prediction by Using Syllable and Morphological Embeddings with BiLSTM Model", ["Rui Liu", "Feilong Bao", "Guanglai Gao", "Hui Zhang", "Yonghe Wang"], "https://doi.org/10.21437/Interspeech.2018-1706", 5, "interspeech", 2018], ["Using Shifted Real Spectrum Mask as Training Target for Supervised Speech Separation", ["Yun Liu", "Hui Zhang", "Xueliang Zhang"], "https://doi.org/10.21437/Interspeech.2018-1650", 5, "interspeech", 2018]], "Sanjeev Satheesh": [0, ["Cold Fusion: Training Seq2Seq Models Together with Language Models", ["Anuroop Sriram", "Heewoo Jun", "Sanjeev Satheesh", "Adam Coates"], "https://doi.org/10.21437/Interspeech.2018-1392", 5, "interspeech", 2018]], "Guanlong Zhao": [0, ["Improving Sparse Representations in Exemplar-Based Voice Conversion with a Phoneme-Selective Objective Function", ["Shaojin Ding", "Guanlong Zhao", "Christopher Liberatore", "Ricardo Gutierrez-Osuna"], "https://doi.org/10.21437/Interspeech.2018-1272", 5, "interspeech", 2018], ["L2-ARCTIC: A Non-native English Speech Corpus", ["Guanlong Zhao", "Sinem Sonsaat", "Alif Silpachai", "Ivana Lucic", "Evgeny Chukharev-Hudilainen", "John Levis", "Ricardo Gutierrez-Osuna"], "https://doi.org/10.21437/Interspeech.2018-1110", 5, "interspeech", 2018]], "Elisabet Eir Cortes": [0, ["Articulatory Consequences of Vocal Effort Elicitation Method", ["Elisabet Eir Cortes", "Marcin Wlodarczak", "Juraj Simko"], "https://doi.org/10.21437/Interspeech.2018-1038", 5, "interspeech", 2018]], "Gyorgy Szaszak": [0, ["User-centric Evaluation of Automatic Punctuation in ASR Closed Captioning", ["Mate Akos Tundik", "Gyorgy Szaszak", "Gabor Gosztolya", "Andras Beke"], "https://doi.org/10.21437/Interspeech.2018-1352", 5, "interspeech", 2018]], "Sri Rama Murty Kodukula": [0, ["Speech Source Separation Using ICA in Constant Q Transform Domain", ["Dheeraj Sai D. V. L. N", "Kishor K. S", "Sri Rama Murty Kodukula"], "https://doi.org/10.21437/Interspeech.2018-1732", 5, "interspeech", 2018]], "Songxiang Liu": [0, ["Voice Conversion Across Arbitrary Speakers Based on a Single Target-Speaker Utterance", ["Songxiang Liu", "Jinghua Zhong", "Lifa Sun", "Xixin Wu", "Xunying Liu", "Helen Meng"], "https://doi.org/10.21437/Interspeech.2018-1504", 5, "interspeech", 2018], ["Rapid Style Adaptation Using Residual Error Embedding for Expressive Speech Synthesis", ["Xixin Wu", "Yuewen Cao", "Mu Wang", "Songxiang Liu", "Shiyin Kang", "Zhiyong Wu", "Xunying Liu", "Dan Su", "Dong Yu", "Helen Meng"], "https://doi.org/10.21437/Interspeech.2018-1991", 5, "interspeech", 2018]], "Tim Fingscheidt": [0, ["What Do Classifiers Actually Learn? a Case Study on Emotion Recognition Datasets", ["Patrick Meyer", "Eric Buschermohle", "Tim Fingscheidt"], "https://doi.org/10.21437/Interspeech.2018-1851", 5, "interspeech", 2018]], "Hanjun Liu": [0, ["Experience-dependent Influence of Music and Language on Lexical Pitch Learning Is Not Additive", ["Akshay Raj Maggu", "Patrick C. M. Wong", "Hanjun Liu", "Francis C. K. Wong"], "https://doi.org/10.21437/Interspeech.2018-2104", 4, "interspeech", 2018]], "Danqing Luo": [0, ["Investigation on Joint Representation Learning for Robust Feature Extraction in Speech Emotion Recognition", ["Danqing Luo", "Yuexian Zou", "Dongyan Huang"], "https://doi.org/10.21437/Interspeech.2018-1832", 5, "interspeech", 2018]], "Jishnu Sadasivan": [0, ["Speech Enhancement Using the Minimum-probability-of-error Criterion", ["Jishnu Sadasivan", "Subhadip Mukherjee", "Chandra Sekhar Seelamantula"], "https://doi.org/10.21437/Interspeech.2018-1294", 5, "interspeech", 2018]], "Ted Mau": [0, ["Articulation-to-Speech Synthesis Using Articulatory Flesh Point Sensors' Orientation Information", ["Beiming Cao", "Myung Jong Kim", "Jun R. Wang", "Jan P. H. van Santen", "Ted Mau", "Jun Wang"], "https://doi.org/10.21437/Interspeech.2018-2484", 5, "interspeech", 2018]], "Siddique Latif": [0, ["Transfer Learning for Improving Speech Emotion Classification Accuracy", ["Siddique Latif", "Rajib Rana", "Shahzad Younis", "Junaid Qadir", "Julien Epps"], "https://doi.org/10.21437/Interspeech.2018-1625", 5, "interspeech", 2018], ["Variational Autoencoders for Learning Latent Representations of Speech Emotion: A Preliminary Study", ["Siddique Latif", "Rajib Rana", "Junaid Qadir", "Julien Epps"], "https://doi.org/10.21437/Interspeech.2018-1568", 5, "interspeech", 2018]], "M. V. Achuth Rao": [0, ["Reconstructing Neutral Speech from Tracheoesophageal Speech", ["Abinay Reddy N", "M. V. Achuth Rao", "G. Nisha Meenakshi", "Prasanta Kumar Ghosh"], "https://doi.org/10.21437/Interspeech.2018-1907", 5, "interspeech", 2018], ["Automatic Glottis Localization and Segmentation in Stroboscopic Videos Using Deep Neural Network", ["M. V. Achuth Rao", "Rahul Krishnamurthy", "Pebbili Gopikishore", "Veeramani Priyadharshini", "Prasanta Kumar Ghosh"], "https://doi.org/10.21437/Interspeech.2018-2572", 5, "interspeech", 2018]], "RaviShankar Prasad": [0, ["Discriminating Nasals and Approximants in English Language Using Zero Time Windowing", ["RaviShankar Prasad", "Sudarsana Reddy Kadiri", "Suryakanth V. Gangashetty", "Bayya Yegnanarayana"], "https://doi.org/10.21437/Interspeech.2018-1032", 5, "interspeech", 2018], ["Identification and Classification of Fricatives in Speech Using Zero Time Windowing Method", ["RaviShankar Prasad", "Bayya Yegnanarayana"], "https://doi.org/10.21437/Interspeech.2018-1958", 5, "interspeech", 2018]], "Eva-Maria Rathner": [0, ["The INTERSPEECH 2018 Computational Paralinguistics Challenge: Atypical & Self-Assessed Affect, Crying & Heart Beats", ["Bjorn W. Schuller", "Stefan Steidl", "Anton Batliner", "Peter B. Marschik", "Harald Baumeister", "Fengquan Dong", "Simone Hantke", "Florian B. Pokorny", "Eva-Maria Rathner", "Katrin D. Bartl-Pokorny", "Christa Einspieler", "Dajie Zhang", "Alice Baird", "Shahin Amiriparian", "Kun Qian", "Zhao Ren", "Maximilian Schmitt", "Panagiotis Tzirakis", "Stefanos Zafeiriou"], "https://doi.org/10.21437/Interspeech.2018-51", 5, "interspeech", 2018], ["State of Mind: Classification through Self-reported Affect and Word Use in Speech", ["Eva-Maria Rathner", "Yannik Terhorst", "Nicholas Cummins", "Bjorn W. Schuller", "Harald Baumeister"], "https://doi.org/10.21437/Interspeech.2018-2043", 5, "interspeech", 2018], ["How Did You like 2017? Detection of Language Markers of Depression and Narcissism in Personal Narratives", ["Eva-Maria Rathner", "Julia Djamali", "Yannik Terhorst", "Bjorn W. Schuller", "Nicholas Cummins", "Gudrun Salamon", "Christina Hunger-Schoppe", "Harald Baumeister"], "https://doi.org/10.21437/Interspeech.2018-2040", 5, "interspeech", 2018]], "Marc Delcroix": [0, ["Semi-Supervised End-to-End Speech Recognition", ["Shigeki Karita", "Shinji Watanabe", "Tomoharu Iwata", "Atsunori Ogawa", "Marc Delcroix"], "https://doi.org/10.21437/Interspeech.2018-1746", 5, "interspeech", 2018], ["Multi-task Learning with Augmentation Strategy for Acoustic-to-word Attention-based Encoder-decoder Speech Recognition", ["Takafumi Moriya", "Sei Ueno", "Yusuke Shinohara", "Marc Delcroix", "Yoshikazu Yamaguchi", "Yushi Aono"], "https://doi.org/10.21437/Interspeech.2018-1866", 5, "interspeech", 2018], ["Auxiliary Feature Based Adaptation of End-to-end ASR Systems", ["Marc Delcroix", "Shinji Watanabe", "Atsunori Ogawa", "Shigeki Karita", "Tomohiro Nakatani"], "https://doi.org/10.21437/Interspeech.2018-1438", 5, "interspeech", 2018], ["Integrating Neural Network Based Beamforming and Weighted Prediction Error Dereverberation", ["Lukas Drude", "Christoph Boddeker", "Jahn Heymann", "Reinhold Haeb-Umbach", "Keisuke Kinoshita", "Marc Delcroix", "Tomohiro Nakatani"], "https://doi.org/10.21437/Interspeech.2018-2196", 5, "interspeech", 2018]], "Ganesh Sivaraman": [0, ["Noise Robust Acoustic to Articulatory Speech Inversion", ["Nadee Seneviratne", "Ganesh Sivaraman", "Vikramjit Mitra", "Carol Y. Espy-Wilson"], "https://doi.org/10.21437/Interspeech.2018-1509", 5, "interspeech", 2018], ["Speech Synthesis in the Wild", ["Ganesh Sivaraman", "Parav Nagarsheth", "Elie Khoury"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3050.html", 2, "interspeech", 2018]], "B. Ganga Gowri": [0, ["Improved Epoch Extraction from Telephonic Speech Using Chebfun and Zero Frequency Filtering", ["B. Ganga Gowri", "Soman K. P", "D. Govind"], "https://doi.org/10.21437/Interspeech.2018-1173", 5, "interspeech", 2018]], "Eugen Beck": [0, ["Segmental Encoder-Decoder Models for Large Vocabulary Automatic Speech Recognition", ["Eugen Beck", "Mirko Hannemann", "Patrick Dotsch", "Ralf Schluter", "Hermann Ney"], "https://doi.org/10.21437/Interspeech.2018-1212", 5, "interspeech", 2018]], "Florian Metze": [0, ["Subword and Crossword Units for CTC Acoustic Models", ["Thomas Zenkel", "Ramon Sanabria", "Florian Metze", "Alex Waibel"], "https://doi.org/10.21437/Interspeech.2018-2057", 5, "interspeech", 2018], ["Comparing the Max and Noisy-Or Pooling Functions in Multiple Instance Learning for Weakly Supervised Sequence Learning Tasks", ["Yun Wang", "Juncheng Li", "Florian Metze"], "https://doi.org/10.21437/Interspeech.2018-990", 5, "interspeech", 2018], ["The ACLEW DiViMe: An Easy-to-use Diarization Tool", ["Adrien Le Franc", "Eric Riebling", "Julien Karadayi", "Yun Wang", "Camila Scaff", "Florian Metze", "Alejandrina Cristia"], "https://doi.org/10.21437/Interspeech.2018-2324", 5, "interspeech", 2018], ["Multiple Instance Deep Learning for Weakly Supervised Small-Footprint Audio Event Detection", ["Shao-Yen Tseng", "Juncheng Li", "Yun Wang", "Florian Metze", "Joseph Szurley", "Samarjit Das"], "https://doi.org/10.21437/Interspeech.2018-1120", 5, "interspeech", 2018]], "Iksoo Choi": [0.9707764834165573, ["Character-level Language Modeling with Gated Hierarchical Recurrent Neural Networks", ["Iksoo Choi", "Jinhwan Park", "Wonyong Sung"], "https://doi.org/10.21437/Interspeech.2018-1727", 5, "interspeech", 2018], ["Hierarchical Recurrent Neural Networks for Acoustic Modeling", ["Jinhwan Park", "Iksoo Choi", "Yoonho Boo", "Wonyong Sung"], "https://doi.org/10.21437/Interspeech.2018-1797", 5, "interspeech", 2018]], "Huabin Ruan": [0, ["Towards Temporal Modelling of Categorical Speech Emotion Recognition", ["Wenjing Han", "Huabin Ruan", "Xiaomin Chen", "Zhixiang Wang", "Haifeng Li", "Bjorn W. Schuller"], "https://doi.org/10.21437/Interspeech.2018-1858", 5, "interspeech", 2018]], "Jinxi Guo": [0, ["Effectiveness of Voice Quality Features in Detecting Depression", ["Amber Afshan", "Jinxi Guo", "Soo Jin Park", "Vijay Ravi", "Jonathan Flint", "Abeer Alwan"], "https://doi.org/10.21437/Interspeech.2018-1399", 5, "interspeech", 2018], ["Filter Sampling and Combination CNN (FSC-CNN): A Compact CNN Model for Small-footprint ASR Acoustic Modeling Using Raw Waveforms", ["Jinxi Guo", "Ning Xu", "Xin Chen", "Yang Shi", "Kaiyuan Xu", "Abeer Alwan"], "https://doi.org/10.21437/Interspeech.2018-1370", 5, "interspeech", 2018]], "Guy Lev": [0, ["Word Emphasis Prediction for Expressive Text to Speech", ["Yosi Mass", "Slava Shechtman", "Moran Mordechay", "Ron Hoory", "Oren Sar Shalom", "Guy Lev", "David Konopnicki"], "https://doi.org/10.21437/Interspeech.2018-1159", 5, "interspeech", 2018]], "Erin Crowgey": [0, ["The Use of Machine Learning and Phonetic Endophenotypes to Discover Genetic Variants Associated with Speech Sound Disorder", ["Jason Lilley", "Erin Crowgey", "H. Timothy Bunnell"], "https://doi.org/10.21437/Interspeech.2018-2398", 5, "interspeech", 2018]], "Yuanjun Zhao": [0, ["Spoofing Detection Using Adaptive Weighting Framework and Clustering Analysis", ["Yuanjun Zhao", "Roberto Togneri", "Victor Sreeram"], "https://doi.org/10.21437/Interspeech.2018-1042", 5, "interspeech", 2018]], "YingjianFu": [0, ["Revealing Spatiotemporal Brain Dynamics of Speech Production Based on EEG and Eye Movement", ["Bin Zhao", "Jinfeng Huang", "Gaoyan Zhang", "Jianwu Dang", "Minbo Chen", "YingjianFu", "Longbiao Wang"], "https://doi.org/10.21437/Interspeech.2018-1908", 5, "interspeech", 2018]], "Norbert Braunschweiler": [0, ["Comparison of an End-to-end Trainable Dialogue System with a Modular Statistical Dialogue System", ["Norbert Braunschweiler", "Alexandros Papangelis"], "https://doi.org/10.21437/Interspeech.2018-1679", 5, "interspeech", 2018]], "Sameer Bansal": [0, ["Low-Resource Speech-to-Text Translation", ["Sameer Bansal", "Herman Kamper", "Karen Livescu", "Adam Lopez", "Sharon Goldwater"], "https://doi.org/10.21437/Interspeech.2018-1326", 5, "interspeech", 2018]], "Itshak Lapidot": [0, ["Speech Database and Protocol Validation Using Waveform Entropy", ["Itshak Lapidot", "Hector Delgado", "Massimiliano Todisco", "Nicholas W. D. Evans", "Jean-Francois Bonastre"], "https://doi.org/10.21437/Interspeech.2018-2330", 5, "interspeech", 2018]], "Andros Tjandra": [0, ["Compressing End-to-end ASR Networks by Tensor-Train Decomposition", ["Takuma Mori", "Andros Tjandra", "Sakriani Sakti", "Satoshi Nakamura"], "https://doi.org/10.21437/Interspeech.2018-1543", 5, "interspeech", 2018], ["Machine Speech Chain with One-shot Speaker Adaptation", ["Andros Tjandra", "Sakriani Sakti", "Satoshi Nakamura"], "https://doi.org/10.21437/Interspeech.2018-1558", 5, "interspeech", 2018]], "Mauro Nicolao": [0, ["Improved Acoustic Modelling for Automatic Literacy Assessment of Children", ["Mauro Nicolao", "Michiel Sanders", "Thomas Hain"], "https://doi.org/10.21437/Interspeech.2018-2118", 5, "interspeech", 2018]], "Kyu J. Han": [0.11794104427099228, ["Densely Connected Networks for Conversational Speech Recognition", ["Kyu J. Han", "Akshay Chandrashekaran", "Jungsuk Kim", "Ian Lane"], "https://doi.org/10.21437/Interspeech.2018-1486", 5, "interspeech", 2018]], "Pengcheng Guo": [0, ["Study of Semi-supervised Approaches to Improving English-Mandarin Code-Switching Speech Recognition", ["Pengcheng Guo", "Haihua Xu", "Lei Xie", "Eng Siong Chng"], "https://doi.org/10.21437/Interspeech.2018-1974", 5, "interspeech", 2018]], "Sidney Fels": [0, ["Towards Automatic Speech Identification from Vocal Tract Shape Dynamics in Real-time MRI", ["Pramit Saha", "Praneeth Srungarapu", "Sidney Fels"], "https://doi.org/10.21437/Interspeech.2018-2537", 5, "interspeech", 2018]], "David Lane": [0, ["Who Said That? a Comparative Study of Non-negative Matrix Factorization Techniques", ["Teun F. Krikke", "Frank Broz", "David Lane"], "https://doi.org/10.21437/Interspeech.2018-1807", 5, "interspeech", 2018]], "Kun-Yi Huang": [0, ["Follow-up Question Generation Using Pattern-based Seq2seq with a Small Corpus for Interview Coaching", ["Ming-Hsiang Su", "Chung-Hsien Wu", "Kun-Yi Huang", "Qian-Bei Hong", "Huai-Hung Huang"], "https://doi.org/10.21437/Interspeech.2018-1007", 5, "interspeech", 2018]], "Jiahao Lai": [0, ["High-quality Voice Conversion Using Spectrogram-Based WaveNet Vocoder", ["Kuan Chen", "Bo Chen", "Jiahao Lai", "Kai Yu"], "https://doi.org/10.21437/Interspeech.2018-1528", 5, "interspeech", 2018]], "Lori Lamel": [0, ["Exploring Temporal Reduction in Dialectal Spanish: A Large-scale Study of Lenition of Voiced Stops and Coda-s", ["Ioana Vasilescu", "Nidia Hernandez", "Bianca Vieru", "Lori Lamel"], "https://doi.org/10.21437/Interspeech.2018-1256", 5, "interspeech", 2018], ["Studying Vowel Variation in French-Algerian Arabic Code-switched Speech", ["Jane Wottawa", "Djegdjiga Amazouz", "Martine Adda-Decker", "Lori Lamel"], "https://doi.org/10.21437/Interspeech.2018-2381", 5, "interspeech", 2018]], "Yoshinori Shiga": [0, ["Multilingual Grapheme-to-Phoneme Conversion with Global Character Vectors", ["Jinfu Ni", "Yoshinori Shiga", "Hisashi Kawai"], "https://doi.org/10.21437/Interspeech.2018-1626", 5, "interspeech", 2018]], "Takafumi Koshinaka": [0, ["Attentive Statistics Pooling for Deep Speaker Embedding", ["Koji Okabe", "Takafumi Koshinaka", "Koichi Shinoda"], "https://doi.org/10.21437/Interspeech.2018-993", 5, "interspeech", 2018]], "Shahzad Younis": [0, ["Transfer Learning for Improving Speech Emotion Classification Accuracy", ["Siddique Latif", "Rajib Rana", "Shahzad Younis", "Junaid Qadir", "Julien Epps"], "https://doi.org/10.21437/Interspeech.2018-1625", 5, "interspeech", 2018]], "Minbo Chen": [0, ["Revealing Spatiotemporal Brain Dynamics of Speech Production Based on EEG and Eye Movement", ["Bin Zhao", "Jinfeng Huang", "Gaoyan Zhang", "Jianwu Dang", "Minbo Chen", "YingjianFu", "Longbiao Wang"], "https://doi.org/10.21437/Interspeech.2018-1908", 5, "interspeech", 2018]], "Yutaka Matsuo": [0, ["Expressive Speech Synthesis via Modeling Expressions with Variational Autoencoder", ["Kei Akuzawa", "Yusuke Iwasawa", "Yutaka Matsuo"], "https://doi.org/10.21437/Interspeech.2018-1113", 5, "interspeech", 2018]], "Per Hedelin": [0, ["Temporal Noise Shaping with Companding", ["Arijit Biswas", "Per Hedelin", "Lars F. Villemoes", "Vinay Melkote"], "https://doi.org/10.21437/Interspeech.2018-2096", 5, "interspeech", 2018]], "Partel Lippus": [0, ["Creak in the Respiratory Cycle", ["Katlin Aare", "Partel Lippus", "Marcin Wlodarczak", "Mattias Heldner"], "https://doi.org/10.21437/Interspeech.2018-2165", 5, "interspeech", 2018]], "Rajagopal Jayaraman": [0, ["auMina\u2122 - Enterprise Speech Analytics", ["Umesh Sachdev", "Rajagopal Jayaraman", "Zainab Millwala"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3016.html", 2, "interspeech", 2018], ["akeira\u2122 - Virtual Assistant", ["Umesh Sachdev", "Rajagopal Jayaraman", "Zainab Millwala"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3018.html", 2, "interspeech", 2018]], "Kun Qian": [0, ["The INTERSPEECH 2018 Computational Paralinguistics Challenge: Atypical & Self-Assessed Affect, Crying & Heart Beats", ["Bjorn W. Schuller", "Stefan Steidl", "Anton Batliner", "Peter B. Marschik", "Harald Baumeister", "Fengquan Dong", "Simone Hantke", "Florian B. Pokorny", "Eva-Maria Rathner", "Katrin D. Bartl-Pokorny", "Christa Einspieler", "Dajie Zhang", "Alice Baird", "Shahin Amiriparian", "Kun Qian", "Zhao Ren", "Maximilian Schmitt", "Panagiotis Tzirakis", "Stefanos Zafeiriou"], "https://doi.org/10.21437/Interspeech.2018-51", 5, "interspeech", 2018], ["Evolving Learning for Analysing Mood-Related Infant Vocalisation", ["Zixing Zhang", "Jing Han", "Kun Qian", "Bjorn W. Schuller"], "https://doi.org/10.21437/Interspeech.2018-1914", 5, "interspeech", 2018]], "Gilles Boulianne": [0, ["CRIM's System for the MGB-3 English Multi-Genre Broadcast Media Transcription", ["Vishwa Gupta", "Gilles Boulianne"], "https://doi.org/10.21437/Interspeech.2018-2079", 5, "interspeech", 2018]], "Guanglai Gao": [0, ["Improving Mongolian Phrase Break Prediction by Using Syllable and Morphological Embeddings with BiLSTM Model", ["Rui Liu", "Feilong Bao", "Guanglai Gao", "Hui Zhang", "Yonghe Wang"], "https://doi.org/10.21437/Interspeech.2018-1706", 5, "interspeech", 2018]], "Asaph Shamir": [0, ["Visual Speech Enhancement", ["Aviv Gabbay", "Asaph Shamir", "Shmuel Peleg"], "https://doi.org/10.21437/Interspeech.2018-1955", 5, "interspeech", 2018]], "Yoonjung Kang": [0.9980157017707825, ["An Ultrasound Study of Gemination in Coronal Stops in Eastern Oromo", ["Maida Percival", "Alexei Kochetov", "Yoonjung Kang"], "https://doi.org/10.21437/Interspeech.2018-2512", 5, "interspeech", 2018]], "Zhifeng Li": [0, ["Deep Discriminative Embeddings for Duration Robust Speaker Verification", ["Na Li", "Deyi Tuo", "Dan Su", "Zhifeng Li", "Dong Yu"], "https://doi.org/10.21437/Interspeech.2018-1769", 5, "interspeech", 2018]], "Louis-Philippe Morency": [0, ["Multimodal Polynomial Fusion for Detecting Driver Distraction", ["Yulun Du", "Alan W. Black", "Louis-Philippe Morency", "Maxine Eskenazi"], "https://doi.org/10.21437/Interspeech.2018-2011", 5, "interspeech", 2018]], "Ramakrishnan A. G.": [0, ["Estimation of the Vocal Tract Length of Vowel Sounds Based on the Frequency of the Significant Spectral Valley", ["T. V. Ananthapadmanabha", "Ramakrishnan A. G."], "https://doi.org/10.21437/Interspeech.2018-1105", 5, "interspeech", 2018]], "Chadi Farah": [0, ["Prosodic Focus Acquisition in French Early Cochlear Implanted Children", ["Chadi Farah", "Stephane Roman", "Mariapaola DImperio"], "https://doi.org/10.21437/Interspeech.2018-1320", 5, "interspeech", 2018]], "Yun Liu": [0, ["Using Shifted Real Spectrum Mask as Training Target for Supervised Speech Separation", ["Yun Liu", "Hui Zhang", "Xueliang Zhang"], "https://doi.org/10.21437/Interspeech.2018-1650", 5, "interspeech", 2018]], "Tsukasa Yoshida": [0, ["Automatic DNN Node Pruning Using Mixture Distribution-based Group Regularization", ["Tsukasa Yoshida", "Takafumi Moriya", "Kazuho Watanabe", "Yusuke Shinohara", "Yoshikazu Yamaguchi", "Yushi Aono"], "https://doi.org/10.21437/Interspeech.2018-2062", 5, "interspeech", 2018]], "Mahima C": [0, ["Development of Large Vocabulary Speech Recognition System with Keyword Search for Manipuri", ["Tanvina Patel", "Krishna D. N", "Noor Fathima", "Nisar Shah", "Mahima C", "Deepak Kumar", "Anuroop Iyengar"], "https://doi.org/10.21437/Interspeech.2018-2133", 5, "interspeech", 2018], ["An Automatic Speech Transcription System for Manipuri Language", ["Tanvina Patel", "Krishna D. N", "Noor Fathima", "Nisar Shah", "Mahima C", "Deepak Kumar", "Anuroop Iyengar"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3043.html", 2, "interspeech", 2018], ["TDNN-based Multilingual Speech Recognition System for Low Resource Indian Languages", ["Noor Fathima", "Tanvina Patel", "Mahima C", "Anuroop Iyengar"], "https://doi.org/10.21437/Interspeech.2018-2117", 5, "interspeech", 2018]], "Fasih Haider": [0, ["An Active Feature Transformation Method for Attitude Recognition of Video Bloggers", ["Fasih Haider", "Fahim A. Salim", "Owen Conlan", "Saturnino Luz"], "https://doi.org/10.21437/Interspeech.2018-1222", 5, "interspeech", 2018], ["Improving Response Time of Active Speaker Detection Using Visual Prosody Information Prior to Articulation", ["Fasih Haider", "Saturnino Luz", "Carl Vogel", "Nick Campbell"], "https://doi.org/10.21437/Interspeech.2018-2310", 5, "interspeech", 2018]], "Elizabeth Rosenfeld": [0, ["Modeling Self-Reported and Observed Affect from Speech", ["Jian Cheng", "Jared Bernstein", "Elizabeth Rosenfeld", "Peter W. Foltz", "Alex S. Cohen", "Terje B. Holmlund", "Brita Elvevag"], "https://doi.org/10.21437/Interspeech.2018-2222", 5, "interspeech", 2018]], "Hongxia Jin": [1.1710628397988004e-12, ["Training Recurrent Neural Network through Moment Matching for NLP Applications", ["Yue Deng", "Yilin Shen", "KaWai Chen", "Hongxia Jin"], "https://doi.org/10.21437/Interspeech.2018-1369", 5, "interspeech", 2018], ["A Deep Reinforcement Learning Based Multimodal Coaching Model (DCM) for Slot Filling in Spoken Language Understanding(SLU)", ["Yu Wang", "Abhishek Patel", "Yilin Shen", "Hongxia Jin"], "https://doi.org/10.21437/Interspeech.2018-1379", 5, "interspeech", 2018], ["Robust Spoken Language Understanding via Paraphrasing", ["Avik Ray", "Yilin Shen", "Hongxia Jin"], "https://doi.org/10.21437/Interspeech.2018-2358", 5, "interspeech", 2018], ["User Information Augmented Semantic Frame Parsing Using Progressive Neural Networks", ["Yilin Shen", "Xiangyu Zeng", "Yu Wang", "Hongxia Jin"], "https://doi.org/10.21437/Interspeech.2018-1149", 5, "interspeech", 2018]], "Jinfu Ni": [0, ["Multilingual Grapheme-to-Phoneme Conversion with Global Character Vectors", ["Jinfu Ni", "Yoshinori Shiga", "Hisashi Kawai"], "https://doi.org/10.21437/Interspeech.2018-1626", 5, "interspeech", 2018]], "Mriganka Sur": [0, ["Brain-Computer Interface using Electroencephalogram Signatures of Eye Blinks", ["Srihari Maruthachalam", "Sidharth Aggarwal", "Mari Ganesh Kumar", "Mriganka Sur", "Hema A. Murthy"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3019.html", 2, "interspeech", 2018]], "Nagendra Kumar Goel": [0, ["Extracting Speaker's Gender, Accent, Age and Emotional State from Speech", ["Nagendra Kumar Goel", "Mousmita Sarma", "Tejendra Kushwah", "Dharmesh Agarwal", "Zikra Iqbal", "Surbhi Chauhan"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3036.html", 2, "interspeech", 2018], ["Emotion Identification from Raw Speech Signals Using DNNs", ["Mousmita Sarma", "Pegah Ghahremani", "Daniel Povey", "Nagendra Kumar Goel", "Kandarpa Kumar Sarma", "Najim Dehak"], "https://doi.org/10.21437/Interspeech.2018-1353", 5, "interspeech", 2018]], "Brian R. Baucom": [0, ["Modeling Interpersonal Influence of Verbal Behavior in Couples Therapy Dyadic Interactions", ["Sandeep Nallan Chakravarthula", "Brian R. Baucom", "Panayiotis G. Georgiou"], "https://doi.org/10.21437/Interspeech.2018-1562", 5, "interspeech", 2018], ["Towards an Unsupervised Entrainment Distance in Conversational Speech Using Deep Neural Networks", ["Md. Nasir", "Brian R. Baucom", "Shrikanth Narayanan", "Panayiotis G. Georgiou"], "https://doi.org/10.21437/Interspeech.2018-1395", 5, "interspeech", 2018]], "Zixiaofan Yang": [1.3875621835380487e-18, ["Predicting Arousal and Valence from Waveforms and Spectrograms Using Deep Neural Networks", ["Zixiaofan Yang", "Julia Hirschberg"], "https://doi.org/10.21437/Interspeech.2018-2397", 5, "interspeech", 2018]], "Xi Wang": [3.964134066336555e-06, ["A New Glottal Neural Vocoder for Speech Synthesis", ["Yang Cui", "Xi Wang", "Lei He", "Frank K. Soong"], "https://doi.org/10.21437/Interspeech.2018-1757", 5, "interspeech", 2018]], "Sakriani Sakti": [0, ["Compressing End-to-end ASR Networks by Tensor-Train Decomposition", ["Takuma Mori", "Andros Tjandra", "Sakriani Sakti", "Satoshi Nakamura"], "https://doi.org/10.21437/Interspeech.2018-1543", 5, "interspeech", 2018], ["Machine Speech Chain with One-shot Speaker Adaptation", ["Andros Tjandra", "Sakriani Sakti", "Satoshi Nakamura"], "https://doi.org/10.21437/Interspeech.2018-1558", 5, "interspeech", 2018], ["Incremental TTS for Japanese Language", ["Tomoya Yanagita", "Sakriani Sakti", "Satoshi Nakamura"], "https://doi.org/10.21437/Interspeech.2018-1561", 5, "interspeech", 2018]], "Alessandra Cervone": [0, ["Coherence Models for Dialogue", ["Alessandra Cervone", "Evgeny A. Stepanov", "Giuseppe Riccardi"], "https://doi.org/10.21437/Interspeech.2018-2446", 5, "interspeech", 2018]], "Anthony J. H. Simons": [0, ["A Lightly Supervised Approach to Detect Stuttering in Children's Speech", ["Sadeen Alharbi", "Madina Hasan", "Anthony J. H. Simons", "Shelagh Brumfitt", "Phil D. Green"], "https://doi.org/10.21437/Interspeech.2018-2155", 5, "interspeech", 2018]], "Christopher Cieri": [0, ["GlobalTIMIT: Acoustic-Phonetic Datasets for the World's Languages", ["Nattanun Chanchaochai", "Christopher Cieri", "Japhet Debrah", "Hongwei Ding", "Yue Jiang", "Sishi Liao", "Mark Liberman", "Jonathan Wright", "Jiahong Yuan", "Juhong Zhan", "Yuqing Zhan"], "https://doi.org/10.21437/Interspeech.2018-1185", 5, "interspeech", 2018]], "Tsuyoki Ujiro": [0, ["Detection of Dementia from Responses to Atypical Questions Asked by Embodied Conversational Agents", ["Tsuyoki Ujiro", "Hiroki Tanaka", "Hiroyoshi Adachi", "Hiroaki Kazui", "Manabu Ikeda", "Takashi Kudo", "Satoshi Nakamura"], "https://doi.org/10.21437/Interspeech.2018-1514", 5, "interspeech", 2018]], "Loretta Guarino Reid": [0, ["AVA-Speech: A Densely Labeled Dataset of Speech Activity in Movies", ["Sourish Chaudhuri", "Joseph Roth", "Daniel P. W. Ellis", "Andrew C. Gallagher", "Liat Kaver", "Radhika Marvin", "Caroline Pantofaru", "Nathan Reale", "Loretta Guarino Reid", "Kevin W. Wilson", "Zhonghua Xi"], "https://doi.org/10.21437/Interspeech.2018-2028", 5, "interspeech", 2018]], "Noor Fathima": [0, ["Development of Large Vocabulary Speech Recognition System with Keyword Search for Manipuri", ["Tanvina Patel", "Krishna D. N", "Noor Fathima", "Nisar Shah", "Mahima C", "Deepak Kumar", "Anuroop Iyengar"], "https://doi.org/10.21437/Interspeech.2018-2133", 5, "interspeech", 2018], ["An Automatic Speech Transcription System for Manipuri Language", ["Tanvina Patel", "Krishna D. N", "Noor Fathima", "Nisar Shah", "Mahima C", "Deepak Kumar", "Anuroop Iyengar"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3043.html", 2, "interspeech", 2018], ["TDNN-based Multilingual Speech Recognition System for Low Resource Indian Languages", ["Noor Fathima", "Tanvina Patel", "Mahima C", "Anuroop Iyengar"], "https://doi.org/10.21437/Interspeech.2018-2117", 5, "interspeech", 2018]], "Eduardo Lleida": [0, ["Estimation of the Number of Speakers with Variational Bayesian PLDA in the DIHARD Diarization Challenge", ["Ignacio Vinals", "Pablo Gimeno", "Alfonso Ortega", "Antonio Miguel", "Eduardo Lleida"], "https://doi.org/10.21437/Interspeech.2018-1841", 5, "interspeech", 2018]], "Kong-Aik Lee": [2.7774383966061578e-06, ["Integrated Presentation Attack Detection and Automatic Speaker Verification: Common Features and Gaussian Back-end Fusion", ["Massimiliano Todisco", "Hector Delgado", "Kong-Aik Lee", "Md. Sahidullah", "Nicholas W. D. Evans", "Tomi Kinnunen", "Junichi Yamagishi"], "https://doi.org/10.21437/Interspeech.2018-2289", 5, "interspeech", 2018], ["Co-whitening of I-vectors for Short and Long Duration Speaker Verification", ["Longting Xu", "Kong-Aik Lee", "Haizhou Li", "Zhen Yang"], "https://doi.org/10.21437/Interspeech.2018-1246", 5, "interspeech", 2018]], "Sarangarajan Parthasarathy": [0, ["Entity-Aware Language Model as an Unsupervised Reranker", ["Mohammad Sadegh Rasooli", "Sarangarajan Parthasarathy"], "https://doi.org/10.21437/Interspeech.2018-62", 5, "interspeech", 2018], ["What to Expect from Expected Kneser-Ney Smoothing", ["Michael Levit", "Sarangarajan Parthasarathy", "Shuangyu Chang"], "https://doi.org/10.21437/Interspeech.2018-84", 5, "interspeech", 2018]], "Gayathri G": [0, ["Mobile Application for Learning Languages for the Unlettered", ["Gayathri G", "N. Mohana", "Radhika Pal", "Hema A. Murthy"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3012.html", 2, "interspeech", 2018]], "Ya Li": [0, ["BLSTM-CRF Based End-to-End Prosodic Boundary Prediction with Context Sensitive Embeddings in a Text-to-Speech Front-End", ["Yibin Zheng", "Jianhua Tao", "Zhengqi Wen", "Ya Li"], "https://doi.org/10.21437/Interspeech.2018-1472", 5, "interspeech", 2018], ["Speech Emotion Recognition from Variable-Length Inputs with Triplet Loss Function", ["Jian Huang", "Ya Li", "Jianhua Tao", "Zhen Lian"], "https://doi.org/10.21437/Interspeech.2018-1432", 5, "interspeech", 2018]], "Jeroen Zegers": [0, ["Memory Time Span in LSTMs for Multi-Speaker Source Separation", ["Jeroen Zegers", "Hugo Van hamme"], "https://doi.org/10.21437/Interspeech.2018-2082", 5, "interspeech", 2018]], "Cristina Vasco": [0, ["Voice Conversion with Conditional SampleRNN", ["Cong Zhou", "Michael Horgan", "Vivek Kumar", "Cristina Vasco", "Dan Darcy"], "https://doi.org/10.21437/Interspeech.2018-1121", 5, "interspeech", 2018]], "Claude Montacie": [0, ["Vocalic, Lexical and Prosodic Cues for the INTERSPEECH 2018 Self-Assessed Affect Challenge", ["Claude Montacie", "Marie-Jose Caraty"], "https://doi.org/10.21437/Interspeech.2018-1331", 5, "interspeech", 2018], ["LOCUST - Longitudinal Corpus and Toolset for Speaker Verification", ["Evgeny Dmitriev", "Yulia Kim", "Anastasia Matveeva", "Claude Montacie", "Yannick Boulard", "Yadviga Sinyavskaya", "Yulia Zhukova", "Adam Zarazinski", "Egor Akhanov", "Ilya I. Viksnin", "Andrei A. Shlykov", "Maria Usova"], "https://doi.org/10.21437/Interspeech.2018-2412", 5, "interspeech", 2018]], "Herman Kamper": [0, ["Low-Resource Speech-to-Text Translation", ["Sameer Bansal", "Herman Kamper", "Karen Livescu", "Adam Lopez", "Sharon Goldwater"], "https://doi.org/10.21437/Interspeech.2018-1326", 5, "interspeech", 2018], ["Fast ASR-free and Almost Zero-resource Keyword Spotting Using DTW and CNNs for Humanitarian Monitoring", ["Raghav Menon", "Herman Kamper", "John Quinn", "Thomas Niesler"], "https://doi.org/10.21437/Interspeech.2018-1580", 5, "interspeech", 2018]], "Jasper Ooster": [0, ["Prediction of Perceived Speech Quality Using Deep Machine Listening", ["Jasper Ooster", "Rainer Huber", "Bernd T. Meyer"], "https://doi.org/10.21437/Interspeech.2018-1374", 5, "interspeech", 2018]], "Roland Maas": [0, ["Device-directed Utterance Detection", ["Sri Harish Reddy Mallidi", "Roland Maas", "Kyle Goehner", "Ariya Rastrow", "Spyros Matsoukas", "Bjorn Hoffmeister"], "https://doi.org/10.21437/Interspeech.2018-1531", 4, "interspeech", 2018]], "Suraj Tripathi": [0, ["Speech Emotion Recognition Using Spectrogram & Phoneme Embedding", ["Promod Yenigalla", "Abhay Kumar", "Suraj Tripathi", "Chirag Singh", "Sibsambhu Kar", "Jithendra Vepa"], "https://doi.org/10.21437/Interspeech.2018-1811", 5, "interspeech", 2018]], "Srinivas Bangalore": [0, ["Intent Discovery Through Unsupervised Semantic Text Clustering", ["Padmasundari", "Srinivas Bangalore"], "https://doi.org/10.21437/Interspeech.2018-2436", 5, "interspeech", 2018]], "Philip N. Garner": [0, ["Fast Language Adaptation Using Phonological Information", ["Sibo Tong", "Philip N. Garner", "Herve Bourlard"], "https://doi.org/10.21437/Interspeech.2018-1990", 5, "interspeech", 2018], ["A Neural Model to Predict Parameters for a Generalized Command Response Model of Intonation", ["Bastian Schnell", "Philip N. Garner"], "https://doi.org/10.21437/Interspeech.2018-1904", 5, "interspeech", 2018]], "Vincent Hughes": [0, ["The Individual and the System: Assessing the Stability of the Output of a Semi-automatic Forensic Voice Comparison System", ["Vincent Hughes", "Philip Harrison", "Paul Foulkes", "Peter French", "Colleen Kavanagh", "Eugenia San Segundo Fernandez"], "https://doi.org/10.21437/Interspeech.2018-1649", 5, "interspeech", 2018]], "Leonid Velikovich": [0, ["Semantic Lattice Processing in Contextual Automatic Speech Recognition for Google Assistant", ["Leonid Velikovich", "Ian Williams", "Justin Scheiner", "Petar S. Aleksic", "Pedro J. Moreno", "Michael Riley"], "https://doi.org/10.21437/Interspeech.2018-2453", 5, "interspeech", 2018]], "Oscar Chen": [0, ["Active Memory Networks for Language Modeling", ["Oscar Chen", "Anton Ragni", "Mark J. F. Gales", "Xie Chen"], "https://doi.org/10.21437/Interspeech.2018-78", 5, "interspeech", 2018]], "Gary Yeung": [0, ["On the Difficulties of Automatic Speech Recognition for Kindergarten-Aged Children", ["Gary Yeung", "Abeer Alwan"], "https://doi.org/10.21437/Interspeech.2018-2297", 5, "interspeech", 2018]], "Vina Law": [0, ["Learning Two Tone Languages Enhances the Brainstem Encoding of Lexical Tones", ["Akshay Raj Maggu", "Wenqing Zong", "Vina Law", "Patrick C. M. Wong"], "https://doi.org/10.21437/Interspeech.2018-2130", 5, "interspeech", 2018]], "Masato Akagi": [0, ["A Three-Layer Emotion Perception Model for Valence and Arousal-Based Detection from Multilingual Speech", ["Xingfeng Li", "Masato Akagi"], "https://doi.org/10.21437/Interspeech.2018-1820", 5, "interspeech", 2018]], "N. Mohana": [0, ["Mobile Application for Learning Languages for the Unlettered", ["Gayathri G", "N. Mohana", "Radhika Pal", "Hema A. Murthy"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3012.html", 2, "interspeech", 2018]], "Jacqueline Vaissiere": [0, ["Universal Tendencies for Cross-Linguistic Prosodic Tendencies: A Review and Some New Proposals", ["Jacqueline Vaissiere"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/4002.html", 1, "interspeech", 2018]], "Enno Hermann": [0, ["Multilingual Bottleneck Features for Subword Modeling in Zero-resource Languages", ["Enno Hermann", "Sharon Goldwater"], "https://doi.org/10.21437/Interspeech.2018-2334", 5, "interspeech", 2018]], "Chitralekha Gupta": [0, ["Automatic Pronunciation Evaluation of Singing", ["Chitralekha Gupta", "Haizhou Li", "Ye Wang"], "https://doi.org/10.21437/Interspeech.2018-1267", 5, "interspeech", 2018]], "Gakuto Kurata": [0, ["Data Augmentation Improves Recognition of Foreign Accented Speech", ["Takashi Fukuda", "Raul Fernandez", "Andrew Rosenberg", "Samuel Thomas", "Bhuvana Ramabhadran", "Alexander Sorin", "Gakuto Kurata"], "https://doi.org/10.21437/Interspeech.2018-1211", 5, "interspeech", 2018], ["Inference-Invariant Transformation of Batch Normalization for Domain Adaptation of Acoustic Models", ["Masayuki Suzuki", "Tohru Nagano", "Gakuto Kurata", "Samuel Thomas"], "https://doi.org/10.21437/Interspeech.2018-1563", 5, "interspeech", 2018]], "Johan Rohdin": [0, ["BUT System for DIHARD Speech Diarization Challenge 2018", ["Mireia Diez", "Federico Landini", "Lukas Burget", "Johan Rohdin", "Anna Silnova", "Katerina Zmolikova", "Ondrej Novotny", "Karel Vesely", "Ondrej Glembek", "Oldrich Plchot", "Ladislav Mosner", "Pavel Matejka"], "https://doi.org/10.21437/Interspeech.2018-1749", 5, "interspeech", 2018]], "Seyed Omid Sadjadi": [0, ["Performance Analysis of the 2017 NIST Language Recognition Evaluation", ["Seyed Omid Sadjadi", "Timothee Kheyrkhah", "Craig S. Greenberg", "Elliot Singer", "Douglas A. Reynolds", "Lisa P. Mason", "Jaime Hernandez-Cordero"], "https://doi.org/10.21437/Interspeech.2018-69", 5, "interspeech", 2018]], "Anton Ragni": [0, ["Impact of ASR Performance on Free Speaking Language Assessment", ["Kate Knill", "Mark J. F. Gales", "Konstantinos Kyriakopoulos", "Andrey Malinin", "Anton Ragni", "Yu Wang", "Andrew Caines"], "https://doi.org/10.21437/Interspeech.2018-1312", 5, "interspeech", 2018], ["Automatic Speech Recognition System Development in the \"Wild\"", ["Anton Ragni", "Mark J. F. Gales"], "https://doi.org/10.21437/Interspeech.2018-1085", 5, "interspeech", 2018], ["Active Memory Networks for Language Modeling", ["Oscar Chen", "Anton Ragni", "Mark J. F. Gales", "Xie Chen"], "https://doi.org/10.21437/Interspeech.2018-78", 5, "interspeech", 2018]], "Qianhua He": [0, ["Feature with Complementarity of Statistics and Principal Information for Spoofing Detection", ["Ji-Chen Yang", "Changhuai You", "Qianhua He"], "https://doi.org/10.21437/Interspeech.2018-1693", 5, "interspeech", 2018]], "Asli Besirli": [0, ["Multi-Lingual Depression-Level Assessment from Conversational Speech Using Acoustic and Text Features", ["Yasin Ozkanca", "Cenk Demiroglu", "Asli Besirli", "Selime Celik"], "https://doi.org/10.21437/Interspeech.2018-2169", 5, "interspeech", 2018]], "Jeng-Lin Li": [0, ["Self-Assessed Affect Recognition Using Fusion of Attentional BLSTM and Static Acoustic Features", ["Bo-Hao Su", "Sung-Lin Yeh", "Ming-Ya Ko", "Huan-Yu Chen", "Shun-Chang Zhong", "Jeng-Lin Li", "Chi-Chun Lee"], "https://doi.org/10.21437/Interspeech.2018-2261", 5, "interspeech", 2018], ["Encoding Individual Acoustic Features Using Dyad-Augmented Deep Variational Representations for Dialog-level Emotion Recognition", ["Jeng-Lin Li", "Chi-Chun Lee"], "https://doi.org/10.21437/Interspeech.2018-1455", 5, "interspeech", 2018], ["Learning Conditional Acoustic Latent Representation with Gender and Age Attributes for Automatic Pain Level Recognition", ["Jeng-Lin Li", "Yi-Ming Weng", "Chip-Jin Ng", "Chi-Chun Lee"], "https://doi.org/10.21437/Interspeech.2018-1298", 5, "interspeech", 2018]], "Takuya Yoshioka": [0, ["Recognizing Overlapped Speech in Meetings: A Multichannel Separation Approach Using Neural Networks", ["Takuya Yoshioka", "Hakan Erdogan", "Zhuo Chen", "Xiong Xiao", "Fil Alleva"], "https://doi.org/10.21437/Interspeech.2018-2284", 5, "interspeech", 2018], ["Investigations on Data Augmentation and Loss Functions for Deep Learning Based Speech-Background Separation", ["Hakan Erdogan", "Takuya Yoshioka"], "https://doi.org/10.21437/Interspeech.2018-2441", 5, "interspeech", 2018]], "Kwanghoon An": [0.9998938739299774, ["Automatic Early Detection of Amyotrophic Lateral Sclerosis from Intelligible Speech Using Convolutional Neural Networks", ["Kwanghoon An", "Myung Jong Kim", "Kristin Teplansky", "Jordan R. Green", "Thomas Campbell", "Yana Yunusova", "Daragh Heitzman", "Jun Wang"], "https://doi.org/10.21437/Interspeech.2018-2496", 5, "interspeech", 2018], ["Dysarthric Speech Recognition Using Convolutional LSTM Neural Network", ["Myung Jong Kim", "Beiming Cao", "Kwanghoon An", "Jun Wang"], "https://doi.org/10.21437/Interspeech.2018-2250", 5, "interspeech", 2018]], "Ben Milner": [0, ["The Effect of Real-Time Constraints on Automatic Speech Animation", ["Danny Websdale", "Sarah Taylor", "Ben Milner"], "https://doi.org/10.21437/Interspeech.2018-2066", 5, "interspeech", 2018]], "Lixia Hao": [0, ["A Preliminary Study on Tonal Coarticulation in Continuous Speech", ["Lixia Hao", "Wei Zhang", "Yanlu Xie", "Jinsong Zhang"], "https://doi.org/10.21437/Interspeech.2018-1849", 5, "interspeech", 2018]], "Yulia Kim": [0.00017717339505907148, ["LOCUST - Longitudinal Corpus and Toolset for Speaker Verification", ["Evgeny Dmitriev", "Yulia Kim", "Anastasia Matveeva", "Claude Montacie", "Yannick Boulard", "Yadviga Sinyavskaya", "Yulia Zhukova", "Adam Zarazinski", "Egor Akhanov", "Ilya I. Viksnin", "Andrei A. Shlykov", "Maria Usova"], "https://doi.org/10.21437/Interspeech.2018-2412", 5, "interspeech", 2018]], "Yasin Ozkanca": [0, ["Multi-Lingual Depression-Level Assessment from Conversational Speech Using Acoustic and Text Features", ["Yasin Ozkanca", "Cenk Demiroglu", "Asli Besirli", "Selime Celik"], "https://doi.org/10.21437/Interspeech.2018-2169", 5, "interspeech", 2018]], "Rongfeng Su": [0, ["Gaussian Process Neural Networks for Speech Recognition", ["Max W. Y. Lam", "Shoukang Hu", "Xurong Xie", "Shansong Liu", "Jianwei Yu", "Rongfeng Su", "Xunying Liu", "Helen Meng"], "https://doi.org/10.21437/Interspeech.2018-1823", 5, "interspeech", 2018], ["Semi-supervised Cross-domain Visual Feature Learning for Audio-Visual Broadcast Speech Transcription", ["Rongfeng Su", "Xunying Liu", "Lan Wang"], "https://doi.org/10.21437/Interspeech.2018-1063", 5, "interspeech", 2018]], "Szilvia Szaloki": [0, ["Identifying Schizophrenia Based on Temporal Parameters in Spontaneous Speech", ["Gabor Gosztolya", "Anita Bagi", "Szilvia Szaloki", "Istvan Szendi", "Ildiko Hoffmann"], "https://doi.org/10.21437/Interspeech.2018-1079", 5, "interspeech", 2018]], "Sebastian Tiesmeyer": [0, ["Visualizing Phoneme Category Adaptation in Deep Neural Networks", ["Odette Scharenborg", "Sebastian Tiesmeyer", "Mark Hasegawa-Johnson", "Najim Dehak"], "https://doi.org/10.21437/Interspeech.2018-1707", 5, "interspeech", 2018]], "Tanja Schultz": [0, ["Investigating the Effect of Audio Duration on Dementia Detection Using Acoustic Features", ["Jochen Weiner", "Miguel Angrick", "Srinivasan Umesh", "Tanja Schultz"], "https://doi.org/10.21437/Interspeech.2018-57", 5, "interspeech", 2018], ["Investigating Objective Intelligibility in Real-Time EMG-to-Speech Conversion", ["Lorenz Diener", "Tanja Schultz"], "https://doi.org/10.21437/Interspeech.2018-2080", 5, "interspeech", 2018], ["Domain-Adversarial Training for Session Independent EMG-based Speech Recognition", ["Michael Wand", "Tanja Schultz", "Jurgen Schmidhuber"], "https://doi.org/10.21437/Interspeech.2018-2318", 5, "interspeech", 2018]], "Bing Liu": [0, ["Online Incremental Learning for Speaker-Adaptive Language Models", ["Chih Chi Hu", "Bing Liu", "John Shen", "Ian Lane"], "https://doi.org/10.21437/Interspeech.2018-2259", 5, "interspeech", 2018]], "Zhenyu Wang": [3.19647428526082e-08, ["EMPHASIS: An Emotional Phoneme-based Acoustic Model for Speech Synthesis System", ["Hao Li", "Yongguo Kang", "Zhenyu Wang"], "https://doi.org/10.21437/Interspeech.2018-1511", 5, "interspeech", 2018]], "Prem C. Pandey": [0, ["Implementation of Digital Hearing Aid as a Smartphone Application", ["Saketh Sharma", "Nitya Tiwari", "Prem C. Pandey"], "https://doi.org/10.21437/Interspeech.2018-2031", 5, "interspeech", 2018], ["Detection of Glottal Excitation Epochs in Speech Signal Using Hilbert Envelope", ["Hirak Dasgupta", "Prem C. Pandey", "K. S. Nataraj"], "https://doi.org/10.21437/Interspeech.2018-2014", 5, "interspeech", 2018]], "Wenjie Li": [0, ["Investigation on the Combination of Batch Normalization and Dropout in BLSTM-based Acoustic Modeling for ASR", ["Wenjie Li", "Gaofeng Cheng", "Fengpei Ge", "Pengyuan Zhang", "Yonghong Yan"], "https://doi.org/10.21437/Interspeech.2018-1597", 5, "interspeech", 2018]], "Benjamin Parrell": [0, ["FACTS: A Hierarchical Task-based Control Model of Speech Incorporating Sensory Feedback", ["Benjamin Parrell", "Vikram Ramanarayanan", "Srikantan S. Nagarajan", "John F. Houde"], "https://doi.org/10.21437/Interspeech.2018-2087", 5, "interspeech", 2018]], "Joun Yeop Lee": [0.9999985694885254, ["Acoustic Modeling Using Adversarially Trained Variational Recurrent Neural Network for Speech Synthesis", ["Joun Yeop Lee", "Sung Jun Cheon", "Byoung Jin Choi", "Nam Soo Kim", "Eunwoo Song"], "https://doi.org/10.21437/Interspeech.2018-1598", 5, "interspeech", 2018]], "Hakan Erdogan": [0, ["Recognizing Overlapped Speech in Meetings: A Multichannel Separation Approach Using Neural Networks", ["Takuya Yoshioka", "Hakan Erdogan", "Zhuo Chen", "Xiong Xiao", "Fil Alleva"], "https://doi.org/10.21437/Interspeech.2018-2284", 5, "interspeech", 2018], ["Investigations on Data Augmentation and Loss Functions for Deep Learning Based Speech-Background Separation", ["Hakan Erdogan", "Takuya Yoshioka"], "https://doi.org/10.21437/Interspeech.2018-2441", 5, "interspeech", 2018]], "Alla Menshikova": [0, ["Language-Dependent Melody Embeddings", ["Daniil Kocharov", "Alla Menshikova"], "https://doi.org/10.21437/Interspeech.2018-1962", 4, "interspeech", 2018]], "Youhyun Shin": [0.979451596736908, ["Slot Filling with Delexicalized Sentence Generation", ["Youhyun Shin", "Kang Min Yoo", "Sang-goo Lee"], "https://doi.org/10.21437/Interspeech.2018-1808", 5, "interspeech", 2018]], "Georgios Paraskevopoulos": [0, ["Integrating Recurrence Dynamics for Speech Emotion Recognition", ["Efthymios Tzinis", "Georgios Paraskevopoulos", "Christos Baziotis", "Alexandros Potamianos"], "https://doi.org/10.21437/Interspeech.2018-1377", 5, "interspeech", 2018]], "Richard Socher": [0, ["A Multi-Discriminator CycleGAN for Unsupervised Non-Parallel Speech Domain Adaptation", ["Ehsan Hosseini-Asl", "Yingbo Zhou", "Caiming Xiong", "Richard Socher"], "https://doi.org/10.21437/Interspeech.2018-1535", 5, "interspeech", 2018]], "Ke Wang": [0.00021147707593627274, ["Investigating Generative Adversarial Networks Based Speech Dereverberation for Robust Speech Recognition", ["Ke Wang", "Junbo Zhang", "Sining Sun", "Yujun Wang", "Fei Xiang", "Lei Xie"], "https://doi.org/10.21437/Interspeech.2018-1780", 5, "interspeech", 2018], ["Empirical Evaluation of Speaker Adaptation on DNN Based Acoustic Model", ["Ke Wang", "Junbo Zhang", "Yujun Wang", "Lei Xie"], "https://doi.org/10.21437/Interspeech.2018-1897", 5, "interspeech", 2018]], "Albert Rilliard": [0, ["Cross-cultural (A)symmetries in Audio-visual Attitude Perception", ["Hansjorg Mixdorff", "Albert Rilliard", "Tan Lee", "Matthew K. H. Ma", "Angelika Honemann"], "https://doi.org/10.21437/Interspeech.2018-1373", 5, "interspeech", 2018]], "Bo Li": [0, ["Domain Adaptation Using Factorized Hidden Layer for Robust Automatic Speech Recognition", ["Khe Chai Sim", "Arun Narayanan", "Ananya Misra", "Anshuman Tripathi", "Golan Pundak", "Tara N. Sainath", "Parisa Haghani", "Bo Li", "Michiel Bacchiani"], "https://doi.org/10.21437/Interspeech.2018-2246", 5, "interspeech", 2018]], "Subhadip Mukherjee": [0, ["Speech Enhancement Using the Minimum-probability-of-error Criterion", ["Jishnu Sadasivan", "Subhadip Mukherjee", "Chandra Sekhar Seelamantula"], "https://doi.org/10.21437/Interspeech.2018-1294", 5, "interspeech", 2018]], "Konstantinos Kyriakopoulos": [0, ["A Deep Learning Approach to Assessing Non-native Pronunciation of English Using Phone Distances", ["Konstantinos Kyriakopoulos", "Kate Knill", "Mark J. F. Gales"], "https://doi.org/10.21437/Interspeech.2018-1087", 5, "interspeech", 2018], ["Impact of ASR Performance on Free Speaking Language Assessment", ["Kate Knill", "Mark J. F. Gales", "Konstantinos Kyriakopoulos", "Andrey Malinin", "Anton Ragni", "Yu Wang", "Andrew Caines"], "https://doi.org/10.21437/Interspeech.2018-1312", 5, "interspeech", 2018]], "Ankit Raj": [0, ["Leveraging Second-Order Log-Linear Model for Improved Deep Learning Based ASR Performance", ["Ankit Raj", "Shakti P. Rath", "Jithendra Vepa"], "https://doi.org/10.21437/Interspeech.2018-1156", 5, "interspeech", 2018]], "David Chiang": [0, ["Leveraging Translations for Speech Transcription in Low-resource Settings", ["Antonios Anastasopoulos", "David Chiang"], "https://doi.org/10.21437/Interspeech.2018-2162", 5, "interspeech", 2018]], "Lorenz Diener": [0, ["Investigating Objective Intelligibility in Real-Time EMG-to-Speech Conversion", ["Lorenz Diener", "Tanja Schultz"], "https://doi.org/10.21437/Interspeech.2018-2080", 5, "interspeech", 2018]], "Christopher J. Smalt": [0, ["Vocal Biomarkers for Cognitive Performance Estimation in a Working Memory Task", ["Jennifer Sloboda", "Adam C. Lammert", "James R. Williamson", "Christopher J. Smalt", "Daryush D. Mehta", "C. O. L. Ian Curry", "Kristin Heaton", "Jeff Palmer", "Thomas F. Quatieri"], "https://doi.org/10.21437/Interspeech.2018-2418", 5, "interspeech", 2018]], "Xiaoxiao Ma": [0, ["Stress Distribution of Given Information in Chinese Reading Texts", ["Yuan Jia", "Xiaoxiao Ma"], "https://doi.org/10.21437/Interspeech.2018-1602", 5, "interspeech", 2018]], "Sunao Hara": [0, ["Naturalness Improvement Algorithm for Reconstructed Glossectomy Patient's Speech Using Spectral Differential Modification in Voice Conversion", ["Hiroki Murakami", "Sunao Hara", "Masanobu Abe", "Masaaki Sato", "Shogo Minagi"], "https://doi.org/10.21437/Interspeech.2018-1239", 5, "interspeech", 2018]], "Haifeng Li": [0, ["Towards Temporal Modelling of Categorical Speech Emotion Recognition", ["Wenjing Han", "Huabin Ruan", "Xiaomin Chen", "Zhixiang Wang", "Haifeng Li", "Bjorn W. Schuller"], "https://doi.org/10.21437/Interspeech.2018-1858", 5, "interspeech", 2018]], "Senjam Shantirani Devi": [0, ["Glotto Vibrato Graph: A Device and Method for Recording, Analysis and Visualization of Glottal Activity", ["Kishalay Chakraborty", "Senjam Shantirani Devi", "Sanjeevan Devnath", "S. R. Mahadeva Prasanna", "Priyankoo Sarmah"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3046.html", 2, "interspeech", 2018]], "Tiina Murtola": [0, ["Interaction Mechanisms between Glottal Source and Vocal Tract in Pitch Glides", ["Tiina Murtola", "Jarmo Malinen"], "https://doi.org/10.21437/Interspeech.2018-1827", 5, "interspeech", 2018]], "Van Tung Pham": [0, ["Mandarin-English Code-switching Speech Recognition", ["Haihua Xu", "Van Tung Pham", "Zin Tun Kyaw", "Zhi Hao Lim", "Eng Siong Chng", "Haizhou Li"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3014.html", 2, "interspeech", 2018]], "Deepu Vijayasenan": [0, ["Prediction of Aesthetic Elements in Karnatic Music: A Machine Learning Approach", ["Ragesh Rajan M", "Ashwin Vijayakumar", "Deepu Vijayasenan"], "https://doi.org/10.21437/Interspeech.2018-991", 5, "interspeech", 2018]], "Jinyu Li": [0, ["Cycle-Consistent Speech Enhancement", ["Zhong Meng", "Jinyu Li", "Yifan Gong", "Biing-Hwang Fred Juang"], "https://doi.org/10.21437/Interspeech.2018-2409", 5, "interspeech", 2018], ["Layer Trajectory LSTM", ["Jinyu Li", "Changliang Liu", "Yifan Gong"], "https://doi.org/10.21437/Interspeech.2018-1485", 5, "interspeech", 2018], ["Improved Training for Online End-to-end Speech Recognition Systems", ["Suyoun Kim", "Michael L. Seltzer", "Jinyu Li", "Rui Zhao"], "https://doi.org/10.21437/Interspeech.2018-2517", 5, "interspeech", 2018], ["Adversarial Feature-Mapping for Speech Enhancement", ["Zhong Meng", "Jinyu Li", "Yifan Gong", "Biing-Hwang Fred Juang"], "https://doi.org/10.21437/Interspeech.2018-2461", 5, "interspeech", 2018]], "Guozhen An": [1.6238163157850094e-11, ["Deep Personality Recognition for Deception Detection", ["Guozhen An", "Sarah Ita Levitan", "Julia Hirschberg", "Rivka Levitan"], "https://doi.org/10.21437/Interspeech.2018-2269", 5, "interspeech", 2018], ["Lexical and Acoustic Deep Learning Model for Personality Recognition", ["Guozhen An", "Rivka Levitan"], "https://doi.org/10.21437/Interspeech.2018-2263", 5, "interspeech", 2018]], "Chao Wang": [0.3783327341079712, ["A Simple Model for Detection of Rare Sound Events", ["Weiran Wang", "Chieh-Chi Kao", "Chao Wang"], "https://doi.org/10.21437/Interspeech.2018-2338", 5, "interspeech", 2018], ["R-CRNN: Region-based Convolutional Recurrent Neural Network for Audio Event Detection", ["Chieh-Chi Kao", "Weiran Wang", "Ming Sun", "Chao Wang"], "https://doi.org/10.21437/Interspeech.2018-2323", 5, "interspeech", 2018], ["Detecting Media Sound Presence in Acoustic Scenes", ["Constantinos Papayiannis", "Justice Amoh", "Viktor Rozgic", "Shiva Sundaram", "Chao Wang"], "https://doi.org/10.21437/Interspeech.2018-2559", 5, "interspeech", 2018]], "Mahsa Yarmohammadi": [0, ["Semi-Orthogonal Low-Rank Matrix Factorization for Deep Neural Networks", ["Daniel Povey", "Gaofeng Cheng", "Yiming Wang", "Ke Li", "Hainan Xu", "Mahsa Yarmohammadi", "Sanjeev Khudanpur"], "https://doi.org/10.21437/Interspeech.2018-1417", 5, "interspeech", 2018]], "Eshete Derb Emiru": [0, ["Multi-frame Quantization of LSF Parameters Using a Deep Autoencoder and Pyramid Vector Quantizer", ["Yaxing Li", "Eshete Derb Emiru", "Shengwu Xiong", "Anna Zhu", "Pengfei Duan", "Yichang Li"], "https://doi.org/10.21437/Interspeech.2018-2577", 5, "interspeech", 2018]], "Takaaki Shochi": [0, ["Cultural Differences in Pattern Matching: Multisensory Recognition of Socio-affective Prosody", ["Takaaki Shochi", "Jean-Luc Rouas", "Marine Guerry", "Donna Erickson"], "https://doi.org/10.21437/Interspeech.2018-1795", 5, "interspeech", 2018]], "Jeremy Lee": [2.2895234508268913e-07, ["Game-based Spoken Dialog Language Learning Applications for Young Students", ["Keelan Evanini", "Veronika Timpe-Laughlin", "Eugene Tsuprun", "Ian Blood", "Jeremy Lee", "James V. Bruno", "Vikram Ramanarayanan", "Patrick L. Lange", "David Suendermann-Oeft"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3045.html", 2, "interspeech", 2018]], "Ambika Prasad Mishra": [0, ["Weighting Pitch Contour and Loudness Contour in Mandarin Tone Perception in Cochlear Implant Listeners", ["Qinglin Meng", "Nengheng Zheng", "Ambika Prasad Mishra", "Jacinta Dan Luo", "Jan W. H. Schnupp"], "https://doi.org/10.21437/Interspeech.2018-1245", 4, "interspeech", 2018]], "Katerina Zmolikova": [0, ["BUT System for DIHARD Speech Diarization Challenge 2018", ["Mireia Diez", "Federico Landini", "Lukas Burget", "Johan Rohdin", "Anna Silnova", "Katerina Zmolikova", "Ondrej Novotny", "Karel Vesely", "Ondrej Glembek", "Oldrich Plchot", "Ladislav Mosner", "Pavel Matejka"], "https://doi.org/10.21437/Interspeech.2018-1749", 5, "interspeech", 2018]], "Neil Shah": [0, ["Effectiveness of Generative Adversarial Network for Non-Audible Murmur-to-Whisper Speech Conversion", ["Neil Shah", "Nirmesh J. Shah", "Hemant A. Patil"], "https://doi.org/10.21437/Interspeech.2018-1565", 5, "interspeech", 2018]], "Dieter Maurer": [0, ["The Zurich Corpus of Vowel and Voice Quality, Version 1.0", ["Dieter Maurer", "Christian dHeureuse", "Heidy Suter", "Volker Dellwo", "Daniel Friedrichs", "Thayabaran Kathiresan"], "https://doi.org/10.21437/Interspeech.2018-1542", 5, "interspeech", 2018], ["Influences of Fundamental Oscillation on Speaker Identification in Vocalic Utterances by Humans and Computers", ["Volker Dellwo", "Thayabaran Kathiresan", "Elisa Pellegrino", "Lei He", "Sandra Schwab", "Dieter Maurer"], "https://doi.org/10.21437/Interspeech.2018-2331", 5, "interspeech", 2018]], "Simon King": [0, ["Learning Interpretable Control Dimensions for Speech Synthesis by Using External Data", ["Zack Hodari", "Oliver Watts", "Srikanth Ronanki", "Simon King"], "https://doi.org/10.21437/Interspeech.2018-2075", 5, "interspeech", 2018], ["Exemplar-based Speech Waveform Generation", ["Oliver Watts", "Cassia Valentini-Botinhao", "Felipe Espic", "Simon King"], "https://doi.org/10.21437/Interspeech.2018-1857", 5, "interspeech", 2018], ["Impact of Different Speech Types on Listening Effort", ["Olympia Simantiraki", "Martin Cooke", "Simon King"], "https://doi.org/10.21437/Interspeech.2018-1358", 5, "interspeech", 2018], ["Using Pupillometry to Measure the Cognitive Load of Synthetic Speech", ["Avashna Govender", "Simon King"], "https://doi.org/10.21437/Interspeech.2018-1174", 5, "interspeech", 2018], ["Measuring the Cognitive Load of Synthetic Speech Using a Dual Task Paradigm", ["Avashna Govender", "Simon King"], "https://doi.org/10.21437/Interspeech.2018-1199", 5, "interspeech", 2018]], "Zhongqiang Huang": [0, ["Automatic Speech Recognition and Topic Identification from Speech for Almost-Zero-Resource Languages", ["Matthew Wiesner", "Chunxi Liu", "Lucas Ondel", "Craig Harman", "Vimal Manohar", "Jan Trmal", "Zhongqiang Huang", "Najim Dehak", "Sanjeev Khudanpur"], "https://doi.org/10.21437/Interspeech.2018-1836", 5, "interspeech", 2018]], "Goutam Saha": [0, ["Wavelet Transform Based Mel-scaled Features for Acoustic Scene Classification", ["Shefali Waldekar", "Goutam Saha"], "https://doi.org/10.21437/Interspeech.2018-2083", 5, "interspeech", 2018]], "Masaaki Sato": [0, ["Naturalness Improvement Algorithm for Reconstructed Glossectomy Patient's Speech Using Spectral Differential Modification in Voice Conversion", ["Hiroki Murakami", "Sunao Hara", "Masanobu Abe", "Masaaki Sato", "Shogo Minagi"], "https://doi.org/10.21437/Interspeech.2018-1239", 5, "interspeech", 2018]], "Martin Karafiat": [0, ["BUT OpenSAT 2017 Speech Recognition System", ["Martin Karafiat", "Murali Karthick Baskar", "Igor Szoke", "Vladimir Malenovsky", "Karel Vesely", "Frantisek Grezl", "Lukas Burget", "Jan Cernocky"], "https://doi.org/10.21437/Interspeech.2018-2457", 5, "interspeech", 2018], ["BUT System for Low Resource Indian Language ASR", ["Bhargav Pulugundla", "Murali Karthick Baskar", "Santosh Kesiraju", "Ekaterina Egorova", "Martin Karafiat", "Lukas Burget", "Jan Cernocky"], "https://doi.org/10.21437/Interspeech.2018-1302", 5, "interspeech", 2018]], "Jilt Sebastian": [0, ["Denoising and Raw-waveform Networks for Weakly-Supervised Gender Identification on Noisy Speech", ["Jilt Sebastian", "Manoj Kumar", "Pavan Kumar D. S.", "Mathew Magimai-Doss", "Hema A. Murthy", "Shrikanth Narayanan"], "https://doi.org/10.21437/Interspeech.2018-2321", 5, "interspeech", 2018], ["Implementing Fusion Techniques for the Classification of Paralinguistic Information", ["Bogdan Vlasenko", "Jilt Sebastian", "Pavan Kumar D. S.", "Mathew Magimai-Doss"], "https://doi.org/10.21437/Interspeech.2018-2360", 5, "interspeech", 2018]], "Wei Xia": [0, ["Speaker Recognition with Nonlinear Distortion: Clipping Analysis and Impact", ["Wei Xia", "John H. L. Hansen"], "https://doi.org/10.21437/Interspeech.2018-2430", 5, "interspeech", 2018]], "Ioana Vasilescu": [0, ["Exploring Temporal Reduction in Dialectal Spanish: A Large-scale Study of Lenition of Voiced Stops and Coda-s", ["Ioana Vasilescu", "Nidia Hernandez", "Bianca Vieru", "Lori Lamel"], "https://doi.org/10.21437/Interspeech.2018-1256", 5, "interspeech", 2018]], "Manoj Kumar": [0, ["Denoising and Raw-waveform Networks for Weakly-Supervised Gender Identification on Noisy Speech", ["Jilt Sebastian", "Manoj Kumar", "Pavan Kumar D. S.", "Mathew Magimai-Doss", "Hema A. Murthy", "Shrikanth Narayanan"], "https://doi.org/10.21437/Interspeech.2018-2321", 5, "interspeech", 2018], ["A Knowledge Driven Structural Segmentation Approach for Play-Talk Classification During Autism Assessment", ["Manoj Kumar", "Pooja Chebolu", "So Hyun Kim", "Kassandra Martinez", "Catherine Lord", "Shrikanth Narayanan"], "https://doi.org/10.21437/Interspeech.2018-1516", 5, "interspeech", 2018]], "Alexander Koller": [0, ["DialogOS: Simple and Extensible Dialogue Modeling", ["Alexander Koller", "Timo Baumann", "Arne Kohn"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3002.html", 2, "interspeech", 2018]], "Sophie van Malderen": [0, ["Towards a Better Characterization of Parkinsonian Speech: A Multidimensional Acoustic Study", ["Veronique Delvaux", "Kathy Huet", "Myriam Piccaluga", "Sophie van Malderen", "Bernard Harmegnies"], "https://doi.org/10.21437/Interspeech.2018-1054", 5, "interspeech", 2018]], "Xiangyu Zeng": [0, ["User Information Augmented Semantic Frame Parsing Using Progressive Neural Networks", ["Yilin Shen", "Xiangyu Zeng", "Yu Wang", "Hongxia Jin"], "https://doi.org/10.21437/Interspeech.2018-1149", 5, "interspeech", 2018]], "Zain Tariq": [0, ["Rapid Collection of Spontaneous Speech Corpora Using Telephonic Community Forums", ["Agha Ali Raza", "Awais Athar", "Shan Randhawa", "Zain Tariq", "Muhammad Bilal Saleem", "Haris Bin Zia", "Umar Saif", "Roni Rosenfeld"], "https://doi.org/10.21437/Interspeech.2018-1139", 5, "interspeech", 2018]], "Alain Ghio": [0, ["Automatic Evaluation of Speech Intelligibility Based on I-vectors in the Context of Head and Neck Cancers", ["Imed Laaridh", "Corinne Fredouille", "Alain Ghio", "Muriel Lalain", "Virginie Woisard"], "https://doi.org/10.21437/Interspeech.2018-1266", 5, "interspeech", 2018]], "Heidi Christensen": [0, ["Detecting Signs of Dementia Using Word Vector Representations", ["Bahman Mirheidari", "Daniel Blackburn", "Traci Walker", "Annalena Venneri", "Markus Reuber", "Heidi Christensen"], "https://doi.org/10.21437/Interspeech.2018-1764", 5, "interspeech", 2018]], "Sudarsana Reddy Kadiri": [0, ["Discriminating Nasals and Approximants in English Language Using Zero Time Windowing", ["RaviShankar Prasad", "Sudarsana Reddy Kadiri", "Suryakanth V. Gangashetty", "Bayya Yegnanarayana"], "https://doi.org/10.21437/Interspeech.2018-1032", 5, "interspeech", 2018], ["Breathy to Tense Voice Discrimination using Zero-Time Windowing Cepstral Coefficients (ZTWCCs)", ["Sudarsana Reddy Kadiri", "Bayya Yegnanarayana"], "https://doi.org/10.21437/Interspeech.2018-2498", 5, "interspeech", 2018], ["Analysis and Detection of Phonation Modes in Singing Voice using Excitation Source Features and Single Frequency Filtering Cepstral Coefficients (SFFCC)", ["Sudarsana Reddy Kadiri", "Bayya Yegnanarayana"], "https://doi.org/10.21437/Interspeech.2018-2502", 5, "interspeech", 2018], ["Detection of Glottal Closure Instants in Degraded Speech Using Single Frequency Filtering Analysis", ["Gunnam Aneeja", "Sudarsana Reddy Kadiri", "Bayya Yegnanarayana"], "https://doi.org/10.21437/Interspeech.2018-1018", 5, "interspeech", 2018], ["Estimation of Fundamental Frequency from Singing Voice Using Harmonics of Impulse-like Excitation Source", ["Sudarsana Reddy Kadiri", "Bayya Yegnanarayana"], "https://doi.org/10.21437/Interspeech.2018-2495", 5, "interspeech", 2018]], "Nikos Tsourakis": [0, ["A Robust Context-Dependent Speech-to-Speech Phraselator Toolkit for Alexa", ["Manny Rayner", "Nikos Tsourakis", "Jan Stanek"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3006.html", 2, "interspeech", 2018]], "Nam Le": [0, ["Robust and Discriminative Speaker Embedding via Intra-Class Distance Variance Regularization", ["Nam Le", "Jean-Marc Odobez"], "https://doi.org/10.21437/Interspeech.2018-1685", 5, "interspeech", 2018]], "Bhavik Vachhani": [0, ["Dysarthric Speech Recognition Using Time-delay Neural Network Based Denoising Autoencoder", ["Chitralekha Bhat", "Biswajit Das", "Bhavik Vachhani", "Sunil Kumar Kopparapu"], "https://doi.org/10.21437/Interspeech.2018-1754", 5, "interspeech", 2018], ["Data Augmentation Using Healthy Speech for Dysarthric Speech Recognition", ["Bhavik Vachhani", "Chitralekha Bhat", "Sunil Kumar Kopparapu"], "https://doi.org/10.21437/Interspeech.2018-1751", 5, "interspeech", 2018]], "Jennifer Sloboda": [0, ["Vocal Biomarkers for Cognitive Performance Estimation in a Working Memory Task", ["Jennifer Sloboda", "Adam C. Lammert", "James R. Williamson", "Christopher J. Smalt", "Daryush D. Mehta", "C. O. L. Ian Curry", "Kristin Heaton", "Jeff Palmer", "Thomas F. Quatieri"], "https://doi.org/10.21437/Interspeech.2018-2418", 5, "interspeech", 2018]], "Rahul Gupta": [0, ["On Enhancing Speech Emotion Recognition Using Generative Adversarial Networks", ["Saurabh Sahu", "Rahul Gupta", "Carol Y. Espy-Wilson"], "https://doi.org/10.21437/Interspeech.2018-1883", 5, "interspeech", 2018]], "Kento Horio": [0, ["Audio-visual Voice Conversion Using Deep Canonical Correlation Analysis for Deep Bottleneck Features", ["Satoshi Tamura", "Kento Horio", "Hajime Endo", "Satoru Hayamizu", "Tomoki Toda"], "https://doi.org/10.21437/Interspeech.2018-2286", 5, "interspeech", 2018]], "Hywel Richards": [0, ["Efficient Voice Trigger Detection for Low Resource Hardware", ["Siddharth Sigtia", "Rob Haynes", "Hywel Richards", "Erik Marchi", "John Bridle"], "https://doi.org/10.21437/Interspeech.2018-2204", 5, "interspeech", 2018]], "Volker Dellwo": [0, ["The Zurich Corpus of Vowel and Voice Quality, Version 1.0", ["Dieter Maurer", "Christian dHeureuse", "Heidy Suter", "Volker Dellwo", "Daniel Friedrichs", "Thayabaran Kathiresan"], "https://doi.org/10.21437/Interspeech.2018-1542", 5, "interspeech", 2018], ["Influences of Fundamental Oscillation on Speaker Identification in Vocalic Utterances by Humans and Computers", ["Volker Dellwo", "Thayabaran Kathiresan", "Elisa Pellegrino", "Lei He", "Sandra Schwab", "Dieter Maurer"], "https://doi.org/10.21437/Interspeech.2018-2331", 5, "interspeech", 2018]], "Abhishek Patel": [0, ["A Deep Reinforcement Learning Based Multimodal Coaching Model (DCM) for Slot Filling in Spoken Language Understanding(SLU)", ["Yu Wang", "Abhishek Patel", "Yilin Shen", "Hongxia Jin"], "https://doi.org/10.21437/Interspeech.2018-1379", 5, "interspeech", 2018]], "Aravind Illa": [0, ["Low Resource Acoustic-to-articulatory Inversion Using Bi-directional Long Short Term Memory", ["Aravind Illa", "Prasanta Kumar Ghosh"], "https://doi.org/10.21437/Interspeech.2018-1843", 5, "interspeech", 2018]], "Ewald van der Westhuizen": [0, ["Building a Unified Code-Switching ASR System for South African Languages", ["Emre Yilmaz", "Astik Biswas", "Ewald van der Westhuizen", "Febe de Wet", "Thomas Niesler"], "https://doi.org/10.21437/Interspeech.2018-1966", 5, "interspeech", 2018], ["Multilingual Neural Network Acoustic Modelling for ASR of Under-Resourced English-isiZulu Code-Switched Speech", ["Astik Biswas", "Febe de Wet", "Ewald van der Westhuizen", "Emre Yilmaz", "Thomas Niesler"], "https://doi.org/10.21437/Interspeech.2018-1711", 5, "interspeech", 2018]], "Chi-Chun Lee": [0.2932860553264618, ["Automatic Assessment of Individual Culture Attribute of Power Distance Using a Social Context-Enhanced Prosodic Network Representation", ["Fu-Sheng Tsai", "Hao-Chun Yang", "Wei-Wen Chang", "Chi-Chun Lee"], "https://doi.org/10.21437/Interspeech.2018-1523", 5, "interspeech", 2018], ["Self-Assessed Affect Recognition Using Fusion of Attentional BLSTM and Static Acoustic Features", ["Bo-Hao Su", "Sung-Lin Yeh", "Ming-Ya Ko", "Huan-Yu Chen", "Shun-Chang Zhong", "Jeng-Lin Li", "Chi-Chun Lee"], "https://doi.org/10.21437/Interspeech.2018-2261", 5, "interspeech", 2018], ["An Interlocutor-Modulated Attentional LSTM for Differentiating between Subgroups of Autism Spectrum Disorder", ["Yun-Shao Lin", "Susan Shur-Fen Gau", "Chi-Chun Lee"], "https://doi.org/10.21437/Interspeech.2018-1288", 5, "interspeech", 2018], ["Encoding Individual Acoustic Features Using Dyad-Augmented Deep Variational Representations for Dialog-level Emotion Recognition", ["Jeng-Lin Li", "Chi-Chun Lee"], "https://doi.org/10.21437/Interspeech.2018-1455", 5, "interspeech", 2018], ["Learning Conditional Acoustic Latent Representation with Gender and Age Attributes for Automatic Pain Level Recognition", ["Jeng-Lin Li", "Yi-Ming Weng", "Chip-Jin Ng", "Chi-Chun Lee"], "https://doi.org/10.21437/Interspeech.2018-1298", 5, "interspeech", 2018]], "Michael Wand": [0, ["Domain-Adversarial Training for Session Independent EMG-based Speech Recognition", ["Michael Wand", "Tanja Schultz", "Jurgen Schmidhuber"], "https://doi.org/10.21437/Interspeech.2018-2318", 5, "interspeech", 2018]], "Yi-Chiao Wu": [6.146273167338418e-14, ["Exemplar-Based Spectral Detail Compensation for Voice Conversion", ["Yu-Huai Peng", "Hsin-Te Hwang", "Yi-Chiao Wu", "Yu Tsao", "Hsin-Min Wang"], "https://doi.org/10.21437/Interspeech.2018-1662", 5, "interspeech", 2018], ["Collapsed Speech Segment Detection and Suppression for WaveNet Vocoder", ["Yi-Chiao Wu", "Kazuhiro Kobayashi", "Tomoki Hayashi", "Patrick Lumban Tobing", "Tomoki Toda"], "https://doi.org/10.21437/Interspeech.2018-1210", 5, "interspeech", 2018]], "Xueliang Zhang": [0, ["Robust TDOA Estimation Based on Time-Frequency Masking and Deep Neural Networks", ["Zhong-Qiu Wang", "Xueliang Zhang", "DeLiang Wang"], "https://doi.org/10.21437/Interspeech.2018-1652", 5, "interspeech", 2018], ["Using Shifted Real Spectrum Mask as Training Target for Supervised Speech Separation", ["Yun Liu", "Hui Zhang", "Xueliang Zhang"], "https://doi.org/10.21437/Interspeech.2018-1650", 5, "interspeech", 2018]], "Narumi Ohashi": [0, ["Multi-resolution Gammachirp Envelope Distortion Index for Intelligibility Prediction of Noisy Speech", ["Katsuhiko Yamamoto", "Toshio Irino", "Narumi Ohashi", "Shoko Araki", "Keisuke Kinoshita", "Tomohiro Nakatani"], "https://doi.org/10.21437/Interspeech.2018-1291", 5, "interspeech", 2018]], "Ondrej Novotny": [0, ["Dereverberation and Beamforming in Robust Far-Field Speaker Recognition", ["Ladislav Mosner", "Oldrich Plchot", "Pavel Matejka", "Ondrej Novotny", "Jan Cernocky"], "https://doi.org/10.21437/Interspeech.2018-2306", 5, "interspeech", 2018], ["BUT System for DIHARD Speech Diarization Challenge 2018", ["Mireia Diez", "Federico Landini", "Lukas Burget", "Johan Rohdin", "Anna Silnova", "Katerina Zmolikova", "Ondrej Novotny", "Karel Vesely", "Ondrej Glembek", "Oldrich Plchot", "Ladislav Mosner", "Pavel Matejka"], "https://doi.org/10.21437/Interspeech.2018-1749", 5, "interspeech", 2018]], "Jiahong Yuan": [0, ["GlobalTIMIT: Acoustic-Phonetic Datasets for the World's Languages", ["Nattanun Chanchaochai", "Christopher Cieri", "Japhet Debrah", "Hongwei Ding", "Yue Jiang", "Sishi Liao", "Mark Liberman", "Jonathan Wright", "Jiahong Yuan", "Juhong Zhan", "Yuqing Zhan"], "https://doi.org/10.21437/Interspeech.2018-1185", 5, "interspeech", 2018], ["Pitch Characteristics of L2 English Speech by Chinese Speakers: A Large-scale Study", ["Jiahong Yuan", "Qiusi Dong", "Fei Wu", "Huan Luan", "Xiaofei Yang", "Hui Lin", "Yang Liu"], "https://doi.org/10.21437/Interspeech.2018-1556", 5, "interspeech", 2018]], "Bhuvana Ramabhadran": [0, ["Open Problems in Speech Recognition", ["Bhuvana Ramabhadran"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/4006.html", 1, "interspeech", 2018], ["Data Augmentation Improves Recognition of Foreign Accented Speech", ["Takashi Fukuda", "Raul Fernandez", "Andrew Rosenberg", "Samuel Thomas", "Bhuvana Ramabhadran", "Alexander Sorin", "Gakuto Kurata"], "https://doi.org/10.21437/Interspeech.2018-1211", 5, "interspeech", 2018]], "Angel Maredia": [0, ["Acoustic-Prosodic Indicators of Deception and Trust in Interview Dialogues", ["Sarah Ita Levitan", "Angel Maredia", "Julia Hirschberg"], "https://doi.org/10.21437/Interspeech.2018-2443", 5, "interspeech", 2018]], "Zafi Sherhan Syed": [0, ["Computational Paralinguistics: Automatic Assessment of Emotions, Mood and Behavioural State from Acoustics of Speech", ["Zafi Sherhan Syed", "Julien Schroeter", "Kirill A. Sidorov", "A. David Marshall"], "https://doi.org/10.21437/Interspeech.2018-2019", 5, "interspeech", 2018]], "Krishna Somandepalli": [0, ["Improving Gender Identification in Movie Audio Using Cross-Domain Data", ["Rajat Hebbar", "Krishna Somandepalli", "Shrikanth Narayanan"], "https://doi.org/10.21437/Interspeech.2018-1462", 5, "interspeech", 2018]], "Heewoo Jun": [0.9923319220542908, ["Cold Fusion: Training Seq2Seq Models Together with Language Models", ["Anuroop Sriram", "Heewoo Jun", "Sanjeev Satheesh", "Adam Coates"], "https://doi.org/10.21437/Interspeech.2018-1392", 5, "interspeech", 2018]], "Wei Wang": [0.00018742437532637268, ["Interactions between Vowels and Nasal Codas in Mandarin Speakers' Perception of Nasal Finals", ["Chong Cao", "Wei Wei", "Wei Wang", "Yanlu Xie", "Jinsong Zhang"], "https://doi.org/10.21437/Interspeech.2018-2025", 5, "interspeech", 2018]], "Nathan Wan": [0, ["Speech Recognition for Medical Conversations", ["Chung-Cheng Chiu", "Anshuman Tripathi", "Katherine Chou", "Chris Co", "Navdeep Jaitly", "Diana Jaunzeikare", "Anjuli Kannan", "Patrick Nguyen", "Hasim Sak", "Ananth Sankar", "Justin Tansuwan", "Nathan Wan", "Yonghui Wu", "Xuedong Zhang"], "https://doi.org/10.21437/Interspeech.2018-40", 5, "interspeech", 2018]], "Lalnunsiami Ngente": [0, ["Robust Mizo Continuous Speech Recognition", ["Abhishek Dey", "Biswajit Dev Sarma", "Wendy Lalhminghlui", "Lalnunsiami Ngente", "Parismita Gogoi", "Priyankoo Sarmah", "S. R. Mahadeva Prasanna", "Rohit Sinha", "S. R. Nirmala"], "https://doi.org/10.21437/Interspeech.2018-2125", 5, "interspeech", 2018]], "Masato Mimura": [0, ["Forward-Backward Attention Decoder", ["Masato Mimura", "Shinsuke Sakai", "Tatsuya Kawahara"], "https://doi.org/10.21437/Interspeech.2018-1160", 5, "interspeech", 2018], ["Encoder Transfer for Attention-based Acoustic-to-word Speech Recognition", ["Sei Ueno", "Takafumi Moriya", "Masato Mimura", "Shinsuke Sakai", "Yusuke Shinohara", "Yoshikazu Yamaguchi", "Yushi Aono", "Tatsuya Kawahara"], "https://doi.org/10.21437/Interspeech.2018-1424", 5, "interspeech", 2018]], "Yuqing Zhan": [0, ["GlobalTIMIT: Acoustic-Phonetic Datasets for the World's Languages", ["Nattanun Chanchaochai", "Christopher Cieri", "Japhet Debrah", "Hongwei Ding", "Yue Jiang", "Sishi Liao", "Mark Liberman", "Jonathan Wright", "Jiahong Yuan", "Juhong Zhan", "Yuqing Zhan"], "https://doi.org/10.21437/Interspeech.2018-1185", 5, "interspeech", 2018]], "Soumitro Chakrabarty": [0, ["Single-Channel Dereverberation Using Direct MMSE Optimization and Bidirectional LSTM Networks", ["Wolfgang Mack", "Soumitro Chakrabarty", "Fabian-Robert Stoter", "Sebastian Braun", "Bernd Edler", "Emanuel A. P. Habets"], "https://doi.org/10.21437/Interspeech.2018-1296", 5, "interspeech", 2018]], "Oren Sar Shalom": [0, ["Word Emphasis Prediction for Expressive Text to Speech", ["Yosi Mass", "Slava Shechtman", "Moran Mordechay", "Ron Hoory", "Oren Sar Shalom", "Guy Lev", "David Konopnicki"], "https://doi.org/10.21437/Interspeech.2018-1159", 5, "interspeech", 2018]], "Dengke Tang": [0, ["An End-to-End Deep Learning Framework for Speech Emotion Recognition of Atypical Individuals", ["Dengke Tang", "Junlin Zeng", "Ming Li"], "https://doi.org/10.21437/Interspeech.2018-2581", 5, "interspeech", 2018]], "Kumud Tripathi": [0, ["Analysis of sparse representation based feature on speech mode classification", ["Kumud Tripathi", "K. Sreenivasa Rao"], "https://doi.org/10.21437/Interspeech.2018-1921", 5, "interspeech", 2018]], "Vishwas M. Shetty": [0, ["Articulatory and Stacked Bottleneck Features for Low Resource Speech Recognition", ["Vishwas M. Shetty", "Rini A. Sharon", "Basil Abraham", "Tejaswi Seeram", "Anusha Prakash", "Nithya Ravi", "Srinivasan Umesh"], "https://doi.org/10.21437/Interspeech.2018-2226", 5, "interspeech", 2018]], "Yingbo Zhou": [0, ["A Multi-Discriminator CycleGAN for Unsupervised Non-Parallel Speech Domain Adaptation", ["Ehsan Hosseini-Asl", "Yingbo Zhou", "Caiming Xiong", "Richard Socher"], "https://doi.org/10.21437/Interspeech.2018-1535", 5, "interspeech", 2018]], "Lukas Mateju": [0, ["Using Deep Neural Networks for Identification of Slavic Languages from Acoustic Signal", ["Lukas Mateju", "Petr Cerva", "Jindrich Zdansky", "Radek Safarik"], "https://doi.org/10.21437/Interspeech.2018-1165", 5, "interspeech", 2018]], "Ching-Feng Yeh": [0, ["Training Augmentation with Adversarial Examples for Robust Speech Recognition", ["Sining Sun", "Ching-Feng Yeh", "Mari Ostendorf", "Mei-Yuh Hwang", "Lei Xie"], "https://doi.org/10.21437/Interspeech.2018-1247", 5, "interspeech", 2018]], "Raul Fernandez": [0, ["Data Augmentation Improves Recognition of Foreign Accented Speech", ["Takashi Fukuda", "Raul Fernandez", "Andrew Rosenberg", "Samuel Thomas", "Bhuvana Ramabhadran", "Alexander Sorin", "Gakuto Kurata"], "https://doi.org/10.21437/Interspeech.2018-1211", 5, "interspeech", 2018]], "Patrick Dotsch": [0, ["Segmental Encoder-Decoder Models for Large Vocabulary Automatic Speech Recognition", ["Eugen Beck", "Mirko Hannemann", "Patrick Dotsch", "Ralf Schluter", "Hermann Ney"], "https://doi.org/10.21437/Interspeech.2018-1212", 5, "interspeech", 2018]], "Nikhil Mohanan": [0, ["A Non-convolutive NMF Model for Speech Dereverberation", ["Nikhil Mohanan", "Rajbabu Velmurugan", "Preeti Rao"], "https://doi.org/10.21437/Interspeech.2018-1834", 5, "interspeech", 2018]], "Philip C. Woodland": [0, ["Speaker Adaptation and Adaptive Training for Jointly Optimised Tandem Systems", ["Yu Wang", "Chao Zhang", "Mark J. F. Gales", "Philip C. Woodland"], "https://doi.org/10.21437/Interspeech.2018-2432", 5, "interspeech", 2018], ["Semi-tied Units for Efficient Gating in LSTM and Highway Networks", ["Chao Zhang", "Philip C. Woodland"], "https://doi.org/10.21437/Interspeech.2018-2158", 5, "interspeech", 2018], ["Combining Natural Gradient with Hessian Free Methods for Sequence Training", ["Adnan Haider", "Philip C. Woodland"], "https://doi.org/10.21437/Interspeech.2018-2335", 5, "interspeech", 2018]], "Bernard Harmegnies": [0, ["Towards a Better Characterization of Parkinsonian Speech: A Multidimensional Acoustic Study", ["Veronique Delvaux", "Kathy Huet", "Myriam Piccaluga", "Sophie van Malderen", "Bernard Harmegnies"], "https://doi.org/10.21437/Interspeech.2018-1054", 5, "interspeech", 2018]], "Matthew Roddy": [0, ["Investigating Speech Features for Continuous Turn-Taking Prediction Using LSTMs", ["Matthew Roddy", "Gabriel Skantze", "Naomi Harte"], "https://doi.org/10.21437/Interspeech.2018-2124", 5, "interspeech", 2018]], "Abualsoud Hanani": [0, ["An Optimization Based Approach for Solving Spoken CALL Shared Task", ["Mohammad Ateeq", "Abualsoud Hanani", "Aziz Qaroush"], "https://doi.org/10.21437/Interspeech.2018-1328", 5, "interspeech", 2018]], "Elie Khoury": [0, ["Speech Synthesis in the Wild", ["Ganesh Sivaraman", "Parav Nagarsheth", "Elie Khoury"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3050.html", 2, "interspeech", 2018]], "Yilin Shen": [0, ["Training Recurrent Neural Network through Moment Matching for NLP Applications", ["Yue Deng", "Yilin Shen", "KaWai Chen", "Hongxia Jin"], "https://doi.org/10.21437/Interspeech.2018-1369", 5, "interspeech", 2018], ["A Deep Reinforcement Learning Based Multimodal Coaching Model (DCM) for Slot Filling in Spoken Language Understanding(SLU)", ["Yu Wang", "Abhishek Patel", "Yilin Shen", "Hongxia Jin"], "https://doi.org/10.21437/Interspeech.2018-1379", 5, "interspeech", 2018], ["Robust Spoken Language Understanding via Paraphrasing", ["Avik Ray", "Yilin Shen", "Hongxia Jin"], "https://doi.org/10.21437/Interspeech.2018-2358", 5, "interspeech", 2018], ["User Information Augmented Semantic Frame Parsing Using Progressive Neural Networks", ["Yilin Shen", "Xiangyu Zeng", "Yu Wang", "Hongxia Jin"], "https://doi.org/10.21437/Interspeech.2018-1149", 5, "interspeech", 2018]], "A. David Marshall": [0, ["Computational Paralinguistics: Automatic Assessment of Emotions, Mood and Behavioural State from Acoustics of Speech", ["Zafi Sherhan Syed", "Julien Schroeter", "Kirill A. Sidorov", "A. David Marshall"], "https://doi.org/10.21437/Interspeech.2018-2019", 5, "interspeech", 2018]], "Abhishek Pandey": [0, ["CACTAS - Collaborative Audio Categorization and Transcription for ASR Systems", ["Mithul Mathivanan", "Kinnera Saranu", "Abhishek Pandey", "Jithendra Vepa"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3029.html", 2, "interspeech", 2018]], "Yan Song": [0.0022822055616416037, ["Improved Supervised Locality Preserving Projection for I-vector Based Speaker Verification", ["Lanhua You", "Wu Guo", "Yan Song", "Sheng Zhang"], "https://doi.org/10.21437/Interspeech.2018-41", 5, "interspeech", 2018], ["Acoustic Modeling with Densely Connected Residual Network for Multichannel Speech Recognition", ["Jian Tang", "Yan Song", "Lirong Dai", "Ian Vince McLoughlin"], "https://doi.org/10.21437/Interspeech.2018-1089", 5, "interspeech", 2018], ["An Attention Pooling Based Representation Learning Method for Speech Emotion Recognition", ["Pengcheng Li", "Yan Song", "Ian Vince McLoughlin", "Wu Guo", "Lirong Dai"], "https://doi.org/10.21437/Interspeech.2018-1242", 5, "interspeech", 2018], ["Early Detection of Continuous and Partial Audio Events Using CNN", ["Ian Vince McLoughlin", "Yan Song", "Lam Dang Pham", "Ramaswamy Palaniappan", "Huy Phan", "Yue Lang"], "https://doi.org/10.21437/Interspeech.2018-1821", 5, "interspeech", 2018], ["An Improved Deep Embedding Learning Method for Short Duration Speaker Verification", ["Zhifu Gao", "Yan Song", "Ian Vince McLoughlin", "Wu Guo", "Lirong Dai"], "https://doi.org/10.21437/Interspeech.2018-1515", 5, "interspeech", 2018]], "Jan Niehues": [0, ["Low-Latency Neural Speech Translation", ["Jan Niehues", "Ngoc-Quan Pham", "Thanh-Le Ha", "Matthias Sperber", "Alex Waibel"], "https://doi.org/10.21437/Interspeech.2018-1055", 5, "interspeech", 2018], ["Term Extraction via Neural Sequence Labeling a Comparative Evaluation of Strategies Using Recurrent Neural Networks", ["Maren Kucza", "Jan Niehues", "Thomas Zenkel", "Alex Waibel", "Sebastian Stuker"], "https://doi.org/10.21437/Interspeech.2018-2017", 5, "interspeech", 2018], ["Self-Attentional Acoustic Models", ["Matthias Sperber", "Jan Niehues", "Graham Neubig", "Sebastian Stuker", "Alex Waibel"], "https://doi.org/10.21437/Interspeech.2018-1910", 5, "interspeech", 2018]], "Kuldip K. Paliwal": [0, ["Bidirectional Long-Short Term Memory Network-based Estimation of Reliable Spectral Component Locations", ["Aaron Nicolson", "Kuldip K. Paliwal"], "https://doi.org/10.21437/Interspeech.2018-1134", 5, "interspeech", 2018]], "Binbin Shen": [0, ["Detection of Glottal Closure Instants from Speech Signals: A Convolutional Neural Network Based Method", ["Shuai Yang", "Zhiyong Wu", "Binbin Shen", "Helen Meng"], "https://doi.org/10.21437/Interspeech.2018-1281", 5, "interspeech", 2018]], "Liat Kaver": [0, ["AVA-Speech: A Densely Labeled Dataset of Speech Activity in Movies", ["Sourish Chaudhuri", "Joseph Roth", "Daniel P. W. Ellis", "Andrew C. Gallagher", "Liat Kaver", "Radhika Marvin", "Caroline Pantofaru", "Nathan Reale", "Loretta Guarino Reid", "Kevin W. Wilson", "Zhonghua Xi"], "https://doi.org/10.21437/Interspeech.2018-2028", 5, "interspeech", 2018]], "Lixin Wang": [8.11050171023453e-07, ["Factorized Deep Neural Network Adaptation for Automatic Scoring of L2 Speech in English Speaking Tests", ["Dean Luo", "Chunxiao Zhang", "Linzhong Xia", "Lixin Wang"], "https://doi.org/10.21437/Interspeech.2018-2138", 5, "interspeech", 2018]], "Kazuhiro Kobayashi": [0, ["Collapsed Speech Segment Detection and Suppression for WaveNet Vocoder", ["Yi-Chiao Wu", "Kazuhiro Kobayashi", "Tomoki Hayashi", "Patrick Lumban Tobing", "Tomoki Toda"], "https://doi.org/10.21437/Interspeech.2018-1210", 5, "interspeech", 2018]], "Jacolien van Rij": [0, ["Neural Response Development During Distributional Learning", ["Natalie Boll-Avetisyan", "Jessie S. Nixon", "Tomas O. Lentz", "Liquan Liu", "Sandrien van Ommen", "Cagri Coltekin", "Jacolien van Rij"], "https://doi.org/10.21437/Interspeech.2018-2072", 5, "interspeech", 2018]], "Anita Bagi": [0, ["Identifying Schizophrenia Based on Temporal Parameters in Spontaneous Speech", ["Gabor Gosztolya", "Anita Bagi", "Szilvia Szaloki", "Istvan Szendi", "Ildiko Hoffmann"], "https://doi.org/10.21437/Interspeech.2018-1079", 5, "interspeech", 2018]], "Chih Chi Hu": [0, ["Online Incremental Learning for Speaker-Adaptive Language Models", ["Chih Chi Hu", "Bing Liu", "John Shen", "Ian Lane"], "https://doi.org/10.21437/Interspeech.2018-2259", 5, "interspeech", 2018]], "Jose A. Gonzalez": [0, ["A Deep Identity Representation for Noise Robust Spoofing Detection", ["Alejandro Gomez Alanis", "Antonio M. Peinado", "Jose A. Gonzalez", "Angel M. Gomez"], "https://doi.org/10.21437/Interspeech.2018-1909", 5, "interspeech", 2018]], "Yang Shi": [0, ["Filter Sampling and Combination CNN (FSC-CNN): A Compact CNN Model for Small-footprint ASR Acoustic Modeling Using Raw Waveforms", ["Jinxi Guo", "Ning Xu", "Xin Chen", "Yang Shi", "Kaiyuan Xu", "Abeer Alwan"], "https://doi.org/10.21437/Interspeech.2018-1370", 5, "interspeech", 2018]], "Vinayak Abrol": [0, ["Deep Convex Representations: Feature Representations for Bioacoustics Classification", ["Anshul Thakur", "Vinayak Abrol", "Pulkit Sharma", "Padmanabhan Rajan"], "https://doi.org/10.21437/Interspeech.2018-1705", 5, "interspeech", 2018], ["ASe: Acoustic Scene Embedding Using Deep Archetypal Analysis and GMM", ["Pulkit Sharma", "Vinayak Abrol", "Anshul Thakur"], "https://doi.org/10.21437/Interspeech.2018-1481", 5, "interspeech", 2018]], "Daniela Braga": [0, ["Machine Learning Powered Data Platform for High-Quality Speech and NLP Workflows", ["Joao Freitas", "Jorge Ribeiro", "Daan Baldewijns", "Sara Oliveira", "Daniela Braga"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3033.html", 2, "interspeech", 2018]], "Peter B. Marschik": [0, ["The INTERSPEECH 2018 Computational Paralinguistics Challenge: Atypical & Self-Assessed Affect, Crying & Heart Beats", ["Bjorn W. Schuller", "Stefan Steidl", "Anton Batliner", "Peter B. Marschik", "Harald Baumeister", "Fengquan Dong", "Simone Hantke", "Florian B. Pokorny", "Eva-Maria Rathner", "Katrin D. Bartl-Pokorny", "Christa Einspieler", "Dajie Zhang", "Alice Baird", "Shahin Amiriparian", "Kun Qian", "Zhao Ren", "Maximilian Schmitt", "Panagiotis Tzirakis", "Stefanos Zafeiriou"], "https://doi.org/10.21437/Interspeech.2018-51", 5, "interspeech", 2018]], "Pierre Bessiere": [0, ["COSMO SylPhon: A Bayesian Perceptuo-motor Model to Assess Phonological Learning", ["Marie-Lou Barnaud", "Julien Diard", "Pierre Bessiere", "Jean-Luc Schwartz"], "https://doi.org/10.21437/Interspeech.2018-73", 5, "interspeech", 2018]], "Xuan Ji": [0.00044238030386622995, ["Text-Dependent Speech Enhancement for Small-Footprint Robust Keyword Detection", ["Meng Yu", "Xuan Ji", "Yi Gao", "Lianwu Chen", "Jie Chen", "Jimeng Zheng", "Dan Su", "Dong Yu"], "https://doi.org/10.21437/Interspeech.2018-1668", 5, "interspeech", 2018]], "John R. Hershey": [0, ["End-to-End Speech Separation with Unfolded Iterative Phase Reconstruction", ["Zhong-Qiu Wang", "Jonathan Le Roux", "DeLiang Wang", "John R. Hershey"], "https://doi.org/10.21437/Interspeech.2018-1629", 5, "interspeech", 2018]], "Shoufeng Lin": [0, ["A New Frequency Coverage Metric and a New Subband Encoding Model, with an Application in Pitch Estimation", ["Shoufeng Lin"], "https://doi.org/10.21437/Interspeech.2018-2590", 5, "interspeech", 2018]], "Chao Zhang": [0, ["Speaker Adaptation and Adaptive Training for Jointly Optimised Tandem Systems", ["Yu Wang", "Chao Zhang", "Mark J. F. Gales", "Philip C. Woodland"], "https://doi.org/10.21437/Interspeech.2018-2432", 5, "interspeech", 2018], ["Semi-tied Units for Efficient Gating in LSTM and Highway Networks", ["Chao Zhang", "Philip C. Woodland"], "https://doi.org/10.21437/Interspeech.2018-2158", 5, "interspeech", 2018]], "Abhash Deka": [0, ["AGROASSAM: A Web Based Assamese Speech Recognition Application for Retrieving Agricultural Commodity Price and Weather Information", ["Abhishek Dey", "Abhash Deka", "Siddika Imani", "Barsha Deka", "Rohit Sinha", "S. R. Mahadeva Prasanna", "Priyankoo Sarmah", "K. Samudravijaya", "S. R. Nirmala"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3048.html", 2, "interspeech", 2018]], "Paavo Alku": [0, ["Time-regularized Linear Prediction for Noise-robust Extraction of the Spectral Envelope of Speech", ["Manu Airaksinen", "Lauri Juvela", "Okko Rasanen", "Paavo Alku"], "https://doi.org/10.21437/Interspeech.2018-1230", 5, "interspeech", 2018], ["Speaker-independent Raw Waveform Model for Glottal Excitation", ["Lauri Juvela", "Vassilis Tsiaras", "Bajibabu Bollepalli", "Manu Airaksinen", "Junichi Yamagishi", "Paavo Alku"], "https://doi.org/10.21437/Interspeech.2018-1635", 5, "interspeech", 2018], ["Dysarthric Speech Classification Using Glottal Features Computed from Non-words, Words and Sentences", ["N. P. Narendra", "Paavo Alku"], "https://doi.org/10.21437/Interspeech.2018-1059", 5, "interspeech", 2018]], "Tuomas Virtanen": [0, ["Reducing Interference with Phase Recovery in DNN-based Monaural Singing Voice Separation", ["Paul Magron", "Konstantinos Drossos", "Stylianos Ioannis Mimilakis", "Tuomas Virtanen"], "https://doi.org/10.21437/Interspeech.2018-1845", 5, "interspeech", 2018], ["Expectation-Maximization Algorithms for Itakura-Saito Nonnegative Matrix Factorization", ["Paul Magron", "Tuomas Virtanen"], "https://doi.org/10.21437/Interspeech.2018-1840", 5, "interspeech", 2018]], "Elmar Noth": [0, ["A Multitask Learning Approach to Assess the Dysarthria Severity in Patients with Parkinson's Disease", ["Juan Camilo Vasquez-Correa", "Tomas Arias-Vergara", "Juan Rafael Orozco-Arroyave", "Elmar Noth"], "https://doi.org/10.21437/Interspeech.2018-1988", 5, "interspeech", 2018], ["Multimodal I-vectors to Detect and Evaluate Parkinson's Disease", ["Nicanor Garcia", "Juan Camilo Vasquez-Correa", "Juan Rafael Orozco-Arroyave", "Elmar Noth"], "https://doi.org/10.21437/Interspeech.2018-2295", 5, "interspeech", 2018]], "Longfei Yang": [5.717766364543575e-11, ["Improving Mandarin Tone Recognition Using Convolutional Bidirectional Long Short-Term Memory with Attention", ["Longfei Yang", "Yanlu Xie", "Jinsong Zhang"], "https://doi.org/10.21437/Interspeech.2018-2561", 5, "interspeech", 2018]], "M. Joana Correia": [0, ["Mining Multimodal Repositories for Speech Affecting Diseases", ["M. Joana Correia", "Bhiksha Raj", "Isabel Trancoso", "Francisco Teixeira"], "https://doi.org/10.21437/Interspeech.2018-1806", 5, "interspeech", 2018]], "Lani Mathew": [0, ["Voice Analysis Using Acoustic and Throat Microphones for Speech Therapy", ["Lani Mathew", "K. Gopakumar"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3005.html", 2, "interspeech", 2018]], "Herve Bredin": [0, ["Neural Speech Turn Segmentation and Affinity Propagation for Speaker Diarization", ["Ruiqing Yin", "Herve Bredin", "Claude Barras"], "https://doi.org/10.21437/Interspeech.2018-1750", 5, "interspeech", 2018]], "Timothee Kheyrkhah": [0, ["Performance Analysis of the 2017 NIST Language Recognition Evaluation", ["Seyed Omid Sadjadi", "Timothee Kheyrkhah", "Craig S. Greenberg", "Elliot Singer", "Douglas A. Reynolds", "Lisa P. Mason", "Jaime Hernandez-Cordero"], "https://doi.org/10.21437/Interspeech.2018-69", 5, "interspeech", 2018]], "Tae Jin Park": [0.8472927659749985, ["Multimodal Speaker Segmentation and Diarization Using Lexical and Acoustic Cues via Sequence to Sequence Neural Networks", ["Tae Jin Park", "Panayiotis G. Georgiou"], "https://doi.org/10.21437/Interspeech.2018-1364", 5, "interspeech", 2018]], "Fabien Ringeval": [0, ["Bags in Bag: Generating Context-Aware Bags for Tracking Emotions from Speech", ["Jing Han", "Zixing Zhang", "Maximilian Schmitt", "Zhao Ren", "Fabien Ringeval", "Bjorn W. Schuller"], "https://doi.org/10.21437/Interspeech.2018-996", 5, "interspeech", 2018]], "Anjuli Kannan": [0, ["Semi-supervised Learning for Information Extraction from Dialogue", ["Anjuli Kannan", "Kai Chen", "Diana Jaunzeikare", "Alvin Rajkomar"], "https://doi.org/10.21437/Interspeech.2018-1318", 5, "interspeech", 2018], ["Contextual Speech Recognition in End-to-end Neural Network Systems Using Beam Search", ["Ian Williams", "Anjuli Kannan", "Petar S. Aleksic", "David Rybach", "Tara N. Sainath"], "https://doi.org/10.21437/Interspeech.2018-2416", 5, "interspeech", 2018], ["Speech Recognition for Medical Conversations", ["Chung-Cheng Chiu", "Anshuman Tripathi", "Katherine Chou", "Chris Co", "Navdeep Jaitly", "Diana Jaunzeikare", "Anjuli Kannan", "Patrick Nguyen", "Hasim Sak", "Ananth Sankar", "Justin Tansuwan", "Nathan Wan", "Yonghui Wu", "Xuedong Zhang"], "https://doi.org/10.21437/Interspeech.2018-40", 5, "interspeech", 2018]], "Mark J. F. Gales": [0, ["Speaker Adaptation and Adaptive Training for Jointly Optimised Tandem Systems", ["Yu Wang", "Chao Zhang", "Mark J. F. Gales", "Philip C. Woodland"], "https://doi.org/10.21437/Interspeech.2018-2432", 5, "interspeech", 2018], ["Waveform-Based Speaker Representations for Speech Synthesis", ["Moquan Wan", "Gilles Degottex", "Mark J. F. Gales"], "https://doi.org/10.21437/Interspeech.2018-1154", 5, "interspeech", 2018], ["A Deep Learning Approach to Assessing Non-native Pronunciation of English Using Phone Distances", ["Konstantinos Kyriakopoulos", "Kate Knill", "Mark J. F. Gales"], "https://doi.org/10.21437/Interspeech.2018-1087", 5, "interspeech", 2018], ["Impact of ASR Performance on Free Speaking Language Assessment", ["Kate Knill", "Mark J. F. Gales", "Konstantinos Kyriakopoulos", "Andrey Malinin", "Anton Ragni", "Yu Wang", "Andrew Caines"], "https://doi.org/10.21437/Interspeech.2018-1312", 5, "interspeech", 2018], ["Automatic Speech Recognition System Development in the \"Wild\"", ["Anton Ragni", "Mark J. F. Gales"], "https://doi.org/10.21437/Interspeech.2018-1085", 5, "interspeech", 2018], ["Active Memory Networks for Language Modeling", ["Oscar Chen", "Anton Ragni", "Mark J. F. Gales", "Xie Chen"], "https://doi.org/10.21437/Interspeech.2018-78", 5, "interspeech", 2018]], "Yu Rong": [0, ["Cross-language Perception of Mandarin Lexical Tones by Mongolian-speaking Bilinguals in the Inner Mongolia Autonomous Region, China", ["Kimiko Tsukada", "Yu Rong"], "https://doi.org/10.21437/Interspeech.2018-48", 5, "interspeech", 2018]], "Hagai Taitelbaum": [0, ["Adding New Classes without Access to the Original Training Data with Applications to Language Identification", ["Hagai Taitelbaum", "Ehud Ben-Reuven", "Jacob Goldberger"], "https://doi.org/10.21437/Interspeech.2018-1342", 5, "interspeech", 2018]], "Berrak Sisman": [0, ["Wavelet Analysis of Speaker Dependent and Independent Prosody for Voice Conversion", ["Berrak Sisman", "Haizhou Li"], "https://doi.org/10.21437/Interspeech.2018-1499", 5, "interspeech", 2018], ["A Voice Conversion Framework with Tandem Feature Sparse Representation and Speaker-Adapted WaveNet Vocoder", ["Berrak Sisman", "Mingyang Zhang", "Haizhou Li"], "https://doi.org/10.21437/Interspeech.2018-1131", 5, "interspeech", 2018]], "Pavan Kumar D. S.": [0, ["Denoising and Raw-waveform Networks for Weakly-Supervised Gender Identification on Noisy Speech", ["Jilt Sebastian", "Manoj Kumar", "Pavan Kumar D. S.", "Mathew Magimai-Doss", "Hema A. Murthy", "Shrikanth Narayanan"], "https://doi.org/10.21437/Interspeech.2018-2321", 5, "interspeech", 2018], ["Implementing Fusion Techniques for the Classification of Paralinguistic Information", ["Bogdan Vlasenko", "Jilt Sebastian", "Pavan Kumar D. S.", "Mathew Magimai-Doss"], "https://doi.org/10.21437/Interspeech.2018-2360", 5, "interspeech", 2018]], "John S. Novak III": [0, ["Effects of User Controlled Speech Rate on Intelligibility in Noisy Environments", ["John S. Novak III", "Robert V. Kenyon"], "https://doi.org/10.21437/Interspeech.2018-63", 5, "interspeech", 2018]], "Xueyang Zhang": [0, ["Speaker Diarization with Enhancing Speech for the First DIHARD Challenge", ["Lei Sun", "Jun Du", "Chao Jiang", "Xueyang Zhang", "Shan He", "Bing Yin", "Chin-Hui Lee"], "https://doi.org/10.21437/Interspeech.2018-1742", 5, "interspeech", 2018]], "Katsuhiko Yamamoto": [0, ["Multi-resolution Gammachirp Envelope Distortion Index for Intelligibility Prediction of Noisy Speech", ["Katsuhiko Yamamoto", "Toshio Irino", "Narumi Ohashi", "Shoko Araki", "Keisuke Kinoshita", "Tomohiro Nakatani"], "https://doi.org/10.21437/Interspeech.2018-1291", 5, "interspeech", 2018]], "Yibin Zheng": [0, ["BLSTM-CRF Based End-to-End Prosodic Boundary Prediction with Context Sensitive Embeddings in a Text-to-Speech Front-End", ["Yibin Zheng", "Jianhua Tao", "Zhengqi Wen", "Ya Li"], "https://doi.org/10.21437/Interspeech.2018-1472", 5, "interspeech", 2018], ["Transfer Learning Based Progressive Neural Networks for Acoustic Modeling in Statistical Parametric Speech Synthesis", ["Ruibo Fu", "Jianhua Tao", "Yibin Zheng", "Zhengqi Wen"], "https://doi.org/10.21437/Interspeech.2018-1265", 5, "interspeech", 2018], ["On the Application and Compression of Deep Time Delay Neural Network for Embedded Statistical Parametric Speech Synthesis", ["Yibin Zheng", "Jianhua Tao", "Zhengqi Wen", "Ruibo Fu"], "https://doi.org/10.21437/Interspeech.2018-1970", 5, "interspeech", 2018], ["Deep Metric Learning for the Target Cost in Unit-Selection Speech Synthesizer", ["Ruibo Fu", "Jianhua Tao", "Yibin Zheng", "Zhengqi Wen"], "https://doi.org/10.21437/Interspeech.2018-1305", 5, "interspeech", 2018]], "Victor Sreeram": [0, ["Spoofing Detection Using Adaptive Weighting Framework and Clustering Analysis", ["Yuanjun Zhao", "Roberto Togneri", "Victor Sreeram"], "https://doi.org/10.21437/Interspeech.2018-1042", 5, "interspeech", 2018]], "Yuewen Cao": [0, ["Rapid Style Adaptation Using Residual Error Embedding for Expressive Speech Synthesis", ["Xixin Wu", "Yuewen Cao", "Mu Wang", "Songxiang Liu", "Shiyin Kang", "Zhiyong Wu", "Xunying Liu", "Dan Su", "Dong Yu", "Helen Meng"], "https://doi.org/10.21437/Interspeech.2018-1991", 5, "interspeech", 2018]], "Federico Landini": [0, ["BUT System for DIHARD Speech Diarization Challenge 2018", ["Mireia Diez", "Federico Landini", "Lukas Burget", "Johan Rohdin", "Anna Silnova", "Katerina Zmolikova", "Ondrej Novotny", "Karel Vesely", "Ondrej Glembek", "Oldrich Plchot", "Ladislav Mosner", "Pavel Matejka"], "https://doi.org/10.21437/Interspeech.2018-1749", 5, "interspeech", 2018]], "Evgeny Dmitriev": [0, ["LOCUST - Longitudinal Corpus and Toolset for Speaker Verification", ["Evgeny Dmitriev", "Yulia Kim", "Anastasia Matveeva", "Claude Montacie", "Yannick Boulard", "Yadviga Sinyavskaya", "Yulia Zhukova", "Adam Zarazinski", "Egor Akhanov", "Ilya I. Viksnin", "Andrei A. Shlykov", "Maria Usova"], "https://doi.org/10.21437/Interspeech.2018-2412", 5, "interspeech", 2018]], "Yoshinori Sagisaka": [0, ["Analysis of L2 Learners' Progress of Distinguishing Mandarin Tone 2 and Tone 3", ["Yue Sun", "Win Thuzar Kyaw", "Jinsong Zhang", "Yoshinori Sagisaka"], "https://doi.org/10.21437/Interspeech.2018-1983", 5, "interspeech", 2018]], "Ian Blood": [0, ["Game-based Spoken Dialog Language Learning Applications for Young Students", ["Keelan Evanini", "Veronika Timpe-Laughlin", "Eugene Tsuprun", "Ian Blood", "Jeremy Lee", "James V. Bruno", "Vikram Ramanarayanan", "Patrick L. Lange", "David Suendermann-Oeft"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3045.html", 2, "interspeech", 2018]], "Thomas F. Campbell": [0, ["Fusing Text-dependent Word-level i-Vector Models to Screen 'at Risk' Child Speech", ["Prasanna V. Kothalkar", "Johanna Rudolph", "Christine Dollaghan", "Jennifer McGlothlin", "Thomas F. Campbell", "John H. L. Hansen"], "https://doi.org/10.21437/Interspeech.2018-1465", 5, "interspeech", 2018]], "Kirill A. Sidorov": [0, ["Computational Paralinguistics: Automatic Assessment of Emotions, Mood and Behavioural State from Acoustics of Speech", ["Zafi Sherhan Syed", "Julien Schroeter", "Kirill A. Sidorov", "A. David Marshall"], "https://doi.org/10.21437/Interspeech.2018-2019", 5, "interspeech", 2018]], "Adam Zarazinski": [0, ["LOCUST - Longitudinal Corpus and Toolset for Speaker Verification", ["Evgeny Dmitriev", "Yulia Kim", "Anastasia Matveeva", "Claude Montacie", "Yannick Boulard", "Yadviga Sinyavskaya", "Yulia Zhukova", "Adam Zarazinski", "Egor Akhanov", "Ilya I. Viksnin", "Andrei A. Shlykov", "Maria Usova"], "https://doi.org/10.21437/Interspeech.2018-2412", 5, "interspeech", 2018]], "Zhiheng Ouyang": [0, ["A Deep Neural Network Based Harmonic Noise Model for Speech Enhancement", ["Zhiheng Ouyang", "Hongjiang Yu", "Wei-Ping Zhu", "Benoit Champagne"], "https://doi.org/10.21437/Interspeech.2018-1114", 5, "interspeech", 2018]], "Adnan Haider": [0, ["Combining Natural Gradient with Hessian Free Methods for Sequence Training", ["Adnan Haider", "Philip C. Woodland"], "https://doi.org/10.21437/Interspeech.2018-2335", 5, "interspeech", 2018]], "Yun-Shao Lin": [0, ["An Interlocutor-Modulated Attentional LSTM for Differentiating between Subgroups of Autism Spectrum Disorder", ["Yun-Shao Lin", "Susan Shur-Fen Gau", "Chi-Chun Lee"], "https://doi.org/10.21437/Interspeech.2018-1288", 5, "interspeech", 2018]], "Michiel Bacchiani": [0, ["Domain Adaptation Using Factorized Hidden Layer for Robust Automatic Speech Recognition", ["Khe Chai Sim", "Arun Narayanan", "Ananya Misra", "Anshuman Tripathi", "Golan Pundak", "Tara N. Sainath", "Parisa Haghani", "Bo Li", "Michiel Bacchiani"], "https://doi.org/10.21437/Interspeech.2018-2246", 5, "interspeech", 2018], ["Efficient Implementation of the Room Simulator for Training Deep Neural Network Acoustic Models", ["Chanwoo Kim", "Ehsan Variani", "Arun Narayanan", "Michiel Bacchiani"], "https://doi.org/10.21437/Interspeech.2018-2566", 5, "interspeech", 2018]], "Nisar Shah": [0, ["Development of Large Vocabulary Speech Recognition System with Keyword Search for Manipuri", ["Tanvina Patel", "Krishna D. N", "Noor Fathima", "Nisar Shah", "Mahima C", "Deepak Kumar", "Anuroop Iyengar"], "https://doi.org/10.21437/Interspeech.2018-2133", 5, "interspeech", 2018], ["An Automatic Speech Transcription System for Manipuri Language", ["Tanvina Patel", "Krishna D. N", "Noor Fathima", "Nisar Shah", "Mahima C", "Deepak Kumar", "Anuroop Iyengar"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3043.html", 2, "interspeech", 2018]], "Nancy F. Chen": [0, ["Topic and Keyword Identification for Low-resourced Speech Using Cross-Language Transfer Learning", ["Wenda Chen", "Mark Hasegawa-Johnson", "Nancy F. Chen"], "https://doi.org/10.21437/Interspeech.2018-1283", 5, "interspeech", 2018]], "Ziping Zhao": [0, ["Exploring Spatio-Temporal Representations by Integrating Attention-based Bidirectional-LSTM-RNNs and FCNs for Speech Emotion Recognition", ["Ziping Zhao", "Yu Zheng", "Zixing Zhang", "Haishuai Wang", "Yiqin Zhao", "Chao Li"], "https://doi.org/10.21437/Interspeech.2018-1477", 5, "interspeech", 2018]], "Matthew Wiesner": [0, ["Automatic Speech Recognition and Topic Identification from Speech for Almost-Zero-Resource Languages", ["Matthew Wiesner", "Chunxi Liu", "Lucas Ondel", "Craig Harman", "Vimal Manohar", "Jan Trmal", "Zhongqiang Huang", "Najim Dehak", "Sanjeev Khudanpur"], "https://doi.org/10.21437/Interspeech.2018-1836", 5, "interspeech", 2018], ["ESPnet: End-to-End Speech Processing Toolkit", ["Shinji Watanabe", "Takaaki Hori", "Shigeki Karita", "Tomoki Hayashi", "Jiro Nishitoba", "Yuya Unno", "Nelson Enrique Yalta Soplin", "Jahn Heymann", "Matthew Wiesner", "Nanxin Chen", "Adithya Renduchintala", "Tsubasa Ochiai"], "https://doi.org/10.21437/Interspeech.2018-1456", 5, "interspeech", 2018], ["Multi-Modal Data Augmentation for End-to-end ASR", ["Adithya Renduchintala", "Shuoyang Ding", "Matthew Wiesner", "Shinji Watanabe"], "https://doi.org/10.21437/Interspeech.2018-2456", 5, "interspeech", 2018]], "Carol Y. Espy-Wilson": [0, ["Noise Robust Acoustic to Articulatory Speech Inversion", ["Nadee Seneviratne", "Ganesh Sivaraman", "Vikramjit Mitra", "Carol Y. Espy-Wilson"], "https://doi.org/10.21437/Interspeech.2018-1509", 5, "interspeech", 2018], ["On Enhancing Speech Emotion Recognition Using Generative Adversarial Networks", ["Saurabh Sahu", "Rahul Gupta", "Carol Y. Espy-Wilson"], "https://doi.org/10.21437/Interspeech.2018-1883", 5, "interspeech", 2018]], "Ailbhe Ni Chasaide": [0, ["Voice Source Contribution to Prominence Perception: Rd Implementation", ["Andy Murphy", "Irena Yanushevskaya", "Ailbhe Ni Chasaide", "Christer Gobl"], "https://doi.org/10.21437/Interspeech.2018-2352", 5, "interspeech", 2018], ["On the Relationship between Glottal Pulse Shape and Its Spectrum: Correlations of Open Quotient, Pulse Skew and Peak Flow with Source Harmonic Amplitudes", ["Christer Gobl", "Andy Murphy", "Irena Yanushevskaya", "Ailbhe Ni Chasaide"], "https://doi.org/10.21437/Interspeech.2018-2532", 5, "interspeech", 2018]], "Michael Horgan": [0, ["Voice Conversion with Conditional SampleRNN", ["Cong Zhou", "Michael Horgan", "Vivek Kumar", "Cristina Vasco", "Dan Darcy"], "https://doi.org/10.21437/Interspeech.2018-1121", 5, "interspeech", 2018]], "Tomohiro Nagata": [0, ["Effects of Dimensional Input on Paralinguistic Information Perceived from Synthesized Dialogue Speech with Neural Network", ["Masaki Yokoyama", "Tomohiro Nagata", "Hiroki Mori"], "https://doi.org/10.21437/Interspeech.2018-2042", 4, "interspeech", 2018]], "Ramon Prieto": [0, ["Liulishuo's System for the Spoken CALL Shared Task 2018", ["Huy Nguyen", "Lei Chen", "Ramon Prieto", "Chuan Wang", "Yang Liu"], "https://doi.org/10.21437/Interspeech.2018-1309", 5, "interspeech", 2018]], "Disong Wang": [0.01610933756455779, ["Joint Noise and Reverberation Adaptive Learning for Robust Speaker DOA Estimation with an Acoustic Vector Sensor", ["Disong Wang", "Yuexian Zou"], "https://doi.org/10.21437/Interspeech.2018-1135", 5, "interspeech", 2018]], "Milton Sarria Paja": [0, ["Classification of Nonverbal Human Produced Audio Events: A Pilot Study", ["Rachel E. Bouserhal", "Philippe Chabot", "Milton Sarria Paja", "Patrick Cardinal", "Jeremie Voix"], "https://doi.org/10.21437/Interspeech.2018-2299", 5, "interspeech", 2018]], "Abhilash Sainathan": [0, ["An Optimization Framework for Recovery of Speech from Phase-Encoded Spectrograms", ["Abhilash Sainathan", "Sunil Rudresh", "Chandra Sekhar Seelamantula"], "https://doi.org/10.21437/Interspeech.2018-1987", 5, "interspeech", 2018]], "Geoffrey S. Meltzner": [0, ["Data Requirements, Selection and Augmentation for DNN-based Speech Synthesis from Crowdsourced Data", ["Markus Toman", "Geoffrey S. Meltzner", "Rupal Patel"], "https://doi.org/10.21437/Interspeech.2018-1316", 5, "interspeech", 2018]], "Ji Wu": [0.005666777724400163, ["Temporal Transformer Networks for Acoustic Scene Classification", ["Teng Zhang", "Kailai Zhang", "Ji Wu"], "https://doi.org/10.21437/Interspeech.2018-1152", 5, "interspeech", 2018], ["Data Independent Sequence Augmentation Method for Acoustic Scene Classification", ["Teng Zhang", "Kailai Zhang", "Ji Wu"], "https://doi.org/10.21437/Interspeech.2018-1250", 5, "interspeech", 2018], ["Multi-modal Attention Mechanisms in LSTM and Its Application to Acoustic Scene Classification", ["Teng Zhang", "Kailai Zhang", "Ji Wu"], "https://doi.org/10.21437/Interspeech.2018-1138", 5, "interspeech", 2018]], "Shefali Waldekar": [0, ["Wavelet Transform Based Mel-scaled Features for Acoustic Scene Classification", ["Shefali Waldekar", "Goutam Saha"], "https://doi.org/10.21437/Interspeech.2018-2083", 5, "interspeech", 2018]], "Yanhua Long": [0, ["Active Learning for LF-MMI Trained Neural Networks in ASR", ["Yanhua Long", "Hong Ye", "Yijie Li", "Jiaen Liang"], "https://doi.org/10.21437/Interspeech.2018-1162", 5, "interspeech", 2018]], "Chunxi Liu": [0, ["Automatic Speech Recognition and Topic Identification from Speech for Almost-Zero-Resource Languages", ["Matthew Wiesner", "Chunxi Liu", "Lucas Ondel", "Craig Harman", "Vimal Manohar", "Jan Trmal", "Zhongqiang Huang", "Najim Dehak", "Sanjeev Khudanpur"], "https://doi.org/10.21437/Interspeech.2018-1836", 5, "interspeech", 2018]], "Brecht Desplanques": [0, ["Cross-lingual Speech Emotion Recognition through Factor Analysis", ["Brecht Desplanques", "Kris Demuynck"], "https://doi.org/10.21437/Interspeech.2018-1778", 5, "interspeech", 2018]], "Eugene Tsuprun": [0, ["Game-based Spoken Dialog Language Learning Applications for Young Students", ["Keelan Evanini", "Veronika Timpe-Laughlin", "Eugene Tsuprun", "Ian Blood", "Jeremy Lee", "James V. Bruno", "Vikram Ramanarayanan", "Patrick L. Lange", "David Suendermann-Oeft"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3045.html", 2, "interspeech", 2018], ["Toward Scalable Dialog Technology for Conversational Language Learning: Case Study of the TOEFL\u00ae MOOC", ["Vikram Ramanarayanan", "David Pautler", "Patrick L. Lange", "Eugene Tsuprun", "Rutuja Ubale", "Keelan Evanini", "David Suendermann-Oeft"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3032.html", 2, "interspeech", 2018]], "Vaishnavi Yeruva": [0, ["On Convolutional LSTM Modeling for Joint Wake-Word Detection and Text Dependent Speaker Verification", ["Rajath Kumar", "Vaishnavi Yeruva", "Sriram Ganapathy"], "https://doi.org/10.21437/Interspeech.2018-1759", 5, "interspeech", 2018]], "Daniil Kocharov": [0, ["Language-Dependent Melody Embeddings", ["Daniil Kocharov", "Alla Menshikova"], "https://doi.org/10.21437/Interspeech.2018-1962", 4, "interspeech", 2018]], "Sharath T. S.": [0, ["Neural MultiVoice Models for Expressing Novel Personalities in Dialog", ["Shereen Oraby", "Lena Reed", "Sharath T. S.", "Shubhangi Tandon", "Marilyn A. Walker"], "https://doi.org/10.21437/Interspeech.2018-2174", 5, "interspeech", 2018]], "Zhi Ming Chua": [0, ["Using Voice Quality Supervectors for Affect Identification", ["Soo Jin Park", "Amber Afshan", "Zhi Ming Chua", "Abeer Alwan"], "https://doi.org/10.21437/Interspeech.2018-1401", 5, "interspeech", 2018]], "Sin-Horng Chen": [0, ["An Exploration of Local Speaking Rate Variations in Mandarin Read Speech", ["Guan-Ting Liou", "Chen-Yu Chiang", "Yih-Ru Wang", "Sin-Horng Chen"], "https://doi.org/10.21437/Interspeech.2018-1214", 5, "interspeech", 2018]], "Thomas Fang Zheng": [0, ["Imbalance Learning-based Framework for Fear Recognition in the MediaEval Emotional Impact of Movies Task", ["Xiaotong Zhang", "Xingliang Cheng", "Mingxing Xu", "Thomas Fang Zheng"], "https://doi.org/10.21437/Interspeech.2018-1744", 5, "interspeech", 2018]], "Hiroki Mori": [0, ["Effects of Dimensional Input on Paralinguistic Information Perceived from Synthesized Dialogue Speech with Neural Network", ["Masaki Yokoyama", "Tomohiro Nagata", "Hiroki Mori"], "https://doi.org/10.21437/Interspeech.2018-2042", 4, "interspeech", 2018]], "Ning Xu": [0, ["Filter Sampling and Combination CNN (FSC-CNN): A Compact CNN Model for Small-footprint ASR Acoustic Modeling Using Raw Waveforms", ["Jinxi Guo", "Ning Xu", "Xin Chen", "Yang Shi", "Kaiyuan Xu", "Abeer Alwan"], "https://doi.org/10.21437/Interspeech.2018-1370", 5, "interspeech", 2018]], "Lakshmish Kaushik": [0, ["Fearless Steps: Apollo-11 Corpus Advancements for Speech Technologies from Earth to the Moon", ["John H. L. Hansen", "Abhijeet Sangwan", "Aditya Joglekar", "Ahmet Emin Bulut", "Lakshmish Kaushik", "Chengzhu Yu"], "https://doi.org/10.21437/Interspeech.2018-1942", 5, "interspeech", 2018]], "Pankaj Joshi": [0, ["Time Aggregation Operators for Multi-label Audio Event Detection", ["Pankaj Joshi", "Digvijaysingh Gautam", "Ganesh Ramakrishnan", "Preethi Jyothi"], "https://doi.org/10.21437/Interspeech.2018-1637", 5, "interspeech", 2018]], "Mattias Heldner": [0, ["Creak in the Respiratory Cycle", ["Katlin Aare", "Partel Lippus", "Marcin Wlodarczak", "Mattias Heldner"], "https://doi.org/10.21437/Interspeech.2018-2165", 5, "interspeech", 2018]], "Mark Hasegawa-Johnson": [0, ["Infant Emotional Outbursts Detection in Infant-parent Spoken Interactions", ["Yijia Xu", "Mark Hasegawa-Johnson", "Nancy McElwain"], "https://doi.org/10.21437/Interspeech.2018-2429", 5, "interspeech", 2018], ["Visualizing Phoneme Category Adaptation in Deep Neural Networks", ["Odette Scharenborg", "Sebastian Tiesmeyer", "Mark Hasegawa-Johnson", "Najim Dehak"], "https://doi.org/10.21437/Interspeech.2018-1707", 5, "interspeech", 2018], ["Topic and Keyword Identification for Low-resourced Speech Using Cross-Language Transfer Learning", ["Wenda Chen", "Mark Hasegawa-Johnson", "Nancy F. Chen"], "https://doi.org/10.21437/Interspeech.2018-1283", 5, "interspeech", 2018], ["Improving DNNs Trained with Non-Native Transcriptions Using Knowledge Distillation and Target Interpolation", ["Amit Das", "Mark Hasegawa-Johnson"], "https://doi.org/10.21437/Interspeech.2018-1450", 5, "interspeech", 2018], ["Improved ASR for Under-resourced Languages through Multi-task Learning with Acoustic Landmarks", ["Di He", "Boon Pang Lim", "Xuesong Yang", "Mark Hasegawa-Johnson", "Deming Chen"], "https://doi.org/10.21437/Interspeech.2018-1124", 5, "interspeech", 2018], ["Speaker Adaptive Audio-Visual Fusion for the Open-Vocabulary Section of AVICAR", ["Leda Sari", "Mark Hasegawa-Johnson", "Kumaran S", "Georg Stemmer", "Krishnakumar N. Nair"], "https://doi.org/10.21437/Interspeech.2018-2359", 5, "interspeech", 2018]], "Stephan Schmid": [0, ["Regional Variation of /r/ in Swiss German Dialects", ["Adrian Leemann", "Stephan Schmid", "Dieter Studer-Joho", "Marie-Jose Kolly"], "https://doi.org/10.21437/Interspeech.2018-1065", 5, "interspeech", 2018]], "Tom Backstrom": [0, ["Dithered Quantization for Frequency-Domain Speech and Audio Coding", ["Tom Backstrom", "Johannes Fischer", "Sneha Das"], "https://doi.org/10.21437/Interspeech.2018-46", 5, "interspeech", 2018], ["Postfiltering with Complex Spectral Correlations for Speech and Audio Coding", ["Sneha Das", "Tom Backstrom"], "https://doi.org/10.21437/Interspeech.2018-1026", 5, "interspeech", 2018], ["Postfiltering Using Log-Magnitude Spectrum for Speech and Audio Coding", ["Sneha Das", "Tom Backstrom"], "https://doi.org/10.21437/Interspeech.2018-1027", 5, "interspeech", 2018]], "Tomas O. Lentz": [0, ["Neural Response Development During Distributional Learning", ["Natalie Boll-Avetisyan", "Jessie S. Nixon", "Tomas O. Lentz", "Liquan Liu", "Sandrien van Ommen", "Cagri Coltekin", "Jacolien van Rij"], "https://doi.org/10.21437/Interspeech.2018-2072", 5, "interspeech", 2018]], "Tatsuya Kawahara": [0, ["Engagement Recognition in Spoken Dialogue via Neural Network by Aggregating Different Annotators' Models", ["Koji Inoue", "Divesh Lala", "Katsuya Takanashi", "Tatsuya Kawahara"], "https://doi.org/10.21437/Interspeech.2018-2067", 5, "interspeech", 2018], ["Prediction of Turn-taking Using Multitask Learning with Prediction of Backchannels and Fillers", ["Kohei Hara", "Koji Inoue", "Katsuya Takanashi", "Tatsuya Kawahara"], "https://doi.org/10.21437/Interspeech.2018-1442", 5, "interspeech", 2018], ["Forward-Backward Attention Decoder", ["Masato Mimura", "Shinsuke Sakai", "Tatsuya Kawahara"], "https://doi.org/10.21437/Interspeech.2018-1160", 5, "interspeech", 2018], ["Encoder Transfer for Attention-based Acoustic-to-word Speech Recognition", ["Sei Ueno", "Takafumi Moriya", "Masato Mimura", "Shinsuke Sakai", "Yusuke Shinohara", "Yoshikazu Yamaguchi", "Yushi Aono", "Tatsuya Kawahara"], "https://doi.org/10.21437/Interspeech.2018-1424", 5, "interspeech", 2018], ["Improving CTC-based Acoustic Model with Very Deep Residual Time-delay Neural Networks", ["Sheng Li", "Xugang Lu", "Ryoichi Takashima", "Peng Shen", "Tatsuya Kawahara", "Hisashi Kawai"], "https://doi.org/10.21437/Interspeech.2018-1475", 5, "interspeech", 2018]], "Anita Szakay": [0, ["Weighting of Coda Voicing Cues: Glottalisation and Vowel Duration", ["Joshua Penney", "Felicity Cox", "Anita Szakay"], "https://doi.org/10.21437/Interspeech.2018-1677", 5, "interspeech", 2018]], "Tomoya Yanagita": [0, ["Incremental TTS for Japanese Language", ["Tomoya Yanagita", "Sakriani Sakti", "Satoshi Nakamura"], "https://doi.org/10.21437/Interspeech.2018-1561", 5, "interspeech", 2018]], "Shobhana Ganesh": [0, ["Talker Diarization in the Wild: the Case of Child-centered Daylong Audio-recordings", ["Alejandrina Cristia", "Shobhana Ganesh", "Marisa Casillas", "Sriram Ganapathy"], "https://doi.org/10.21437/Interspeech.2018-2078", 5, "interspeech", 2018]], "Naoya Takahashi": [0, ["PhaseNet: Discretized Phase Modeling with Deep Neural Networks for Audio Source Separation", ["Naoya Takahashi", "Purvi Agrawal", "Nabarun Goswami", "Yuki Mitsufuji"], "https://doi.org/10.21437/Interspeech.2018-1773", 5, "interspeech", 2018]], "Sneha Das": [0, ["Dithered Quantization for Frequency-Domain Speech and Audio Coding", ["Tom Backstrom", "Johannes Fischer", "Sneha Das"], "https://doi.org/10.21437/Interspeech.2018-46", 5, "interspeech", 2018], ["Postfiltering with Complex Spectral Correlations for Speech and Audio Coding", ["Sneha Das", "Tom Backstrom"], "https://doi.org/10.21437/Interspeech.2018-1026", 5, "interspeech", 2018], ["Postfiltering Using Log-Magnitude Spectrum for Speech and Audio Coding", ["Sneha Das", "Tom Backstrom"], "https://doi.org/10.21437/Interspeech.2018-1027", 5, "interspeech", 2018]], "Akhilesh Kumar Dubey": [0, ["Pitch-Adaptive Front-end Feature for Hypernasality Detection", ["Akhilesh Kumar Dubey", "S. R. Mahadeva Prasanna", "Samarendra Dandapat"], "https://doi.org/10.21437/Interspeech.2018-1251", 5, "interspeech", 2018]], "Eva Fringi": [0, ["Analysis of Phone Errors Attributable to Phonological Effects Associated With Language Acquisition Through Bottleneck Feature Visualisations", ["Eva Fringi", "Martin J. Russell"], "https://doi.org/10.21437/Interspeech.2018-2422", 5, "interspeech", 2018]], "Chris Biemann": [0, ["Unspeech: Unsupervised Speech Context Embeddings", ["Benjamin Milde", "Chris Biemann"], "https://doi.org/10.21437/Interspeech.2018-2194", 5, "interspeech", 2018]], "Lars F. Villemoes": [0, ["Temporal Noise Shaping with Companding", ["Arijit Biswas", "Per Hedelin", "Lars F. Villemoes", "Vinay Melkote"], "https://doi.org/10.21437/Interspeech.2018-2096", 5, "interspeech", 2018]], "Aline Villavicencio": [0, ["Unsupervised Word Segmentation from Speech with Attention", ["Pierre Godard", "Marcely Zanon Boito", "Lucas Ondel", "Alexandre Berard", "Francois Yvon", "Aline Villavicencio", "Laurent Besacier"], "https://doi.org/10.21437/Interspeech.2018-1308", 5, "interspeech", 2018]], "Raphael Cohen": [0, ["Fully Automatic Speaker Separation System, with Automatic Enrolling of Recurrent Speakers", ["Raphael Cohen", "Orgad Keller", "Jason Levy", "Russell Levy", "Micha Breakstone", "Amit Ashkenazi"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3034.html", 2, "interspeech", 2018]], "Michael Riley": [0, ["Semantic Lattice Processing in Contextual Automatic Speech Recognition for Google Assistant", ["Leonid Velikovich", "Ian Williams", "Justin Scheiner", "Petar S. Aleksic", "Pedro J. Moreno", "Michael Riley"], "https://doi.org/10.21437/Interspeech.2018-2453", 5, "interspeech", 2018]], "K. Sreenivasa Rao": [0, ["Analysis of sparse representation based feature on speech mode classification", ["Kumud Tripathi", "K. Sreenivasa Rao"], "https://doi.org/10.21437/Interspeech.2018-1921", 5, "interspeech", 2018], ["Harmonic-Percussive Source Separation of Polyphonic Music by Suppressing Impulsive Noise Events", ["Gurunath Reddy M.", "K. Sreenivasa Rao", "Partha Pratim Das"], "https://doi.org/10.21437/Interspeech.2018-1310", 5, "interspeech", 2018], ["Indian Languages ASR: A Multilingual Phone Recognition Framework with IPA Based Common Phone-set, Predicted Articulatory Features and Feature fusion", ["K. E. Manjunath", "K. Sreenivasa Rao", "Dinesh Babu Jayagopi", "V. Ramasubramanian"], "https://doi.org/10.21437/Interspeech.2018-2529", 5, "interspeech", 2018], ["Classification of Disorders in Vocal Folds Using Electroglottographic Signal", ["Tanumay Mandal", "K. Sreenivasa Rao", "Sanjay Kumar Gupta"], "https://doi.org/10.21437/Interspeech.2018-1967", 5, "interspeech", 2018]], "Cristina Gorrostieta": [0, ["Attention-based Sequence Classification for Affect Detection", ["Cristina Gorrostieta", "Richard Brutti", "Kye Taylor", "Avi Shapiro", "Joseph Moran", "Ali Azarbayejani", "John Kane"], "https://doi.org/10.21437/Interspeech.2018-1610", 5, "interspeech", 2018]], "Cassia Valentini-Botinhao": [0, ["Exemplar-based Speech Waveform Generation", ["Oliver Watts", "Cassia Valentini-Botinhao", "Felipe Espic", "Simon King"], "https://doi.org/10.21437/Interspeech.2018-1857", 5, "interspeech", 2018]], "Wenju Liu": [0, ["Deep Noise Tracking Network: A Hybrid Signal Processing/Deep Learning Approach to Speech Enhancement", ["Shuai Nie", "Shan Liang", "Bin Liu", "Yaping Zhang", "Wenju Liu", "Jianhua Tao"], "https://doi.org/10.21437/Interspeech.2018-1020", 5, "interspeech", 2018]], "Divesh Lala": [0, ["Engagement Recognition in Spoken Dialogue via Neural Network by Aggregating Different Annotators' Models", ["Koji Inoue", "Divesh Lala", "Katsuya Takanashi", "Tatsuya Kawahara"], "https://doi.org/10.21437/Interspeech.2018-2067", 5, "interspeech", 2018]], "Saturnino Luz": [0, ["An Active Feature Transformation Method for Attitude Recognition of Video Bloggers", ["Fasih Haider", "Fahim A. Salim", "Owen Conlan", "Saturnino Luz"], "https://doi.org/10.21437/Interspeech.2018-1222", 5, "interspeech", 2018], ["Improving Response Time of Active Speaker Detection Using Visual Prosody Information Prior to Articulation", ["Fasih Haider", "Saturnino Luz", "Carl Vogel", "Nick Campbell"], "https://doi.org/10.21437/Interspeech.2018-2310", 5, "interspeech", 2018]], "Marie-Jose Kolly": [0, ["Regional Variation of /r/ in Swiss German Dialects", ["Adrian Leemann", "Stephan Schmid", "Dieter Studer-Joho", "Marie-Jose Kolly"], "https://doi.org/10.21437/Interspeech.2018-1065", 5, "interspeech", 2018]], "James Gibson": [0, ["Combined Speaker Clustering and Role Recognition in Conversational Speech", ["Nikolaos Flemotomos", "Pavlos Papadopoulos", "James Gibson", "Shrikanth Narayanan"], "https://doi.org/10.21437/Interspeech.2018-1654", 5, "interspeech", 2018], ["Language Features for Automated Evaluation of Cognitive Behavior Psychotherapy Sessions", ["Nikolaos Flemotomos", "Victor R. Martinez", "James Gibson", "David C. Atkins", "Torrey Creed", "Shrikanth Narayanan"], "https://doi.org/10.21437/Interspeech.2018-1518", 5, "interspeech", 2018], ["Using Prosodic and Lexical Information for Learning Utterance-level Behaviors in Psychotherapy", ["Karan Singla", "Zhuohao Chen", "Nikolaos Flemotomos", "James Gibson", "Dogan Can", "David C. Atkins", "Shrikanth Narayanan"], "https://doi.org/10.21437/Interspeech.2018-2551", 5, "interspeech", 2018]], "Heiga Zen": [0, ["Sequence-to-sequence Neural Network Model with 2D Attention for Learning Japanese Pitch Accents", ["Antoine Bruguier", "Heiga Zen", "Arkady Arkhangorodsky"], "https://doi.org/10.21437/Interspeech.2018-1381", 4, "interspeech", 2018]], "Tal Drory": [0, ["The IBM Virtual Voice Creator", ["Alexander Sorin", "Slava Shechtman", "Zvi Kons", "Ron Hoory", "Shay Ben-David", "Joe Pavitt", "Shai Rozenberg", "Carmel Rabinovitz", "Tal Drory"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3011.html", 2, "interspeech", 2018]], "Emilia Parada-Cabaleiro": [0, ["The Perception and Analysis of the Likeability and Human Likeness of Synthesized Speech", ["Alice Baird", "Emilia Parada-Cabaleiro", "Simone Hantke", "Felix Burkhardt", "Nicholas Cummins", "Bjorn W. Schuller"], "https://doi.org/10.21437/Interspeech.2018-1093", 5, "interspeech", 2018], ["Categorical vs Dimensional Perception of Italian Emotional Speech", ["Emilia Parada-Cabaleiro", "Giovanni Costantini", "Anton Batliner", "Alice Baird", "Bjorn W. Schuller"], "https://doi.org/10.21437/Interspeech.2018-47", 5, "interspeech", 2018]], "Meng Yu": [0.0010469693806953728, ["Permutation Invariant Training of Generative Adversarial Network for Monaural Speech Separation", ["Lianwu Chen", "Meng Yu", "Yanmin Qian", "Dan Su", "Dong Yu"], "https://doi.org/10.21437/Interspeech.2018-1603", 5, "interspeech", 2018], ["Deep Extractor Network for Target Speaker Recovery from Single Channel Speech Mixtures", ["Jun Wang", "Jie Chen", "Dan Su", "Lianwu Chen", "Meng Yu", "Yanmin Qian", "Dong Yu"], "https://doi.org/10.21437/Interspeech.2018-1205", 5, "interspeech", 2018], ["Text-Dependent Speech Enhancement for Small-Footprint Robust Keyword Detection", ["Meng Yu", "Xuan Ji", "Yi Gao", "Lianwu Chen", "Jie Chen", "Jimeng Zheng", "Dan Su", "Dong Yu"], "https://doi.org/10.21437/Interspeech.2018-1668", 5, "interspeech", 2018]], "Ahmad-Reza Sadeghi": [0, ["VoiceGuard: Secure and Private Speech Processing", ["Ferdinand Brasser", "Tommaso Frassetto", "Korbinian Riedhammer", "Ahmad-Reza Sadeghi", "Thomas Schneider", "Christian Weinert"], "https://doi.org/10.21437/Interspeech.2018-2032", 5, "interspeech", 2018]], "Daan Baldewijns": [0, ["Machine Learning Powered Data Platform for High-Quality Speech and NLP Workflows", ["Joao Freitas", "Jorge Ribeiro", "Daan Baldewijns", "Sara Oliveira", "Daniela Braga"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3033.html", 2, "interspeech", 2018]], "Jeffrey Hetherly": [0, ["Voices Obscured in Complex Environmental Settings (VOiCES) Corpus", ["Colleen Richey", "Maria Auxiliadora Barrios", "Zeb Armstrong", "Chris Bartels", "Horacio Franco", "Martin Graciarena", "Aaron Lawson", "Mahesh Kumar Nandwana", "Allen R. Stauffer", "Julien van Hout", "Paul Gamble", "Jeffrey Hetherly", "Cory Stephenson", "Karl Ni"], "https://doi.org/10.21437/Interspeech.2018-1454", 5, "interspeech", 2018], ["Deep Speech Denoising with Vector Space Projections", ["Jeffrey Hetherly", "Paul Gamble", "Maria Alejandra Barrios", "Cory Stephenson", "Karl Ni"], "https://doi.org/10.21437/Interspeech.2018-83", 5, "interspeech", 2018]], "Barsha Deka": [0, ["AGROASSAM: A Web Based Assamese Speech Recognition Application for Retrieving Agricultural Commodity Price and Weather Information", ["Abhishek Dey", "Abhash Deka", "Siddika Imani", "Barsha Deka", "Rohit Sinha", "S. R. Mahadeva Prasanna", "Priyankoo Sarmah", "K. Samudravijaya", "S. R. Nirmala"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3048.html", 2, "interspeech", 2018]], "Juan Carlos Gomez": [0, ["A French-Spanish Multimodal Speech Communication Corpus Incorporating Acoustic Data, Facial, Hands and Arms Gestures Information", ["Lucas D. Terissi", "Gonzalo D. Sad", "Mauricio Cerda", "Slim Ouni", "Rodrigo Galvez", "Juan Carlos Gomez", "Bernard Girau", "Nancy Hitschfeld-Kahler"], "https://doi.org/10.21437/Interspeech.2018-2212", 5, "interspeech", 2018]], "Douglas D. OShaughnessy": [0, ["Investigating Speech Enhancement and Perceptual Quality for Speech Emotion Recognition", ["Anderson R. Avila", "Md. Jahangir Alam", "Douglas D. OShaughnessy", "Tiago H. Falk"], "https://doi.org/10.21437/Interspeech.2018-2350", 5, "interspeech", 2018]], "Diane Hirschfeld": [0, ["Classification of Correction Turns in Multilingual Dialogue Corpus", ["Ivan Kraljevski", "Diane Hirschfeld"], "https://doi.org/10.21437/Interspeech.2018-1348", 5, "interspeech", 2018]], "Kei Akuzawa": [0, ["Expressive Speech Synthesis via Modeling Expressions with Variational Autoencoder", ["Kei Akuzawa", "Yusuke Iwasawa", "Yutaka Matsuo"], "https://doi.org/10.21437/Interspeech.2018-1113", 5, "interspeech", 2018]], "Khe Chai Sim": [1.1623309546848759e-05, ["Domain Adaptation Using Factorized Hidden Layer for Robust Automatic Speech Recognition", ["Khe Chai Sim", "Arun Narayanan", "Ananya Misra", "Anshuman Tripathi", "Golan Pundak", "Tara N. Sainath", "Parisa Haghani", "Bo Li", "Michiel Bacchiani"], "https://doi.org/10.21437/Interspeech.2018-2246", 5, "interspeech", 2018]], "Chandana S": [0, ["Automatic Visual Augmentation for Concatenation Based Synthesized Articulatory Videos from Real-time MRI Data for Spoken Language Training", ["Chandana S", "Chiranjeevi Yarra", "Ritu Aggarwal", "Sanjeev Kumar Mittal", "N. K. Kausthubha", "Raseena K. T", "Astha Singh", "Prasanta Kumar Ghosh"], "https://doi.org/10.21437/Interspeech.2018-1570", 5, "interspeech", 2018]], "Andrew Caines": [0, ["Impact of ASR Performance on Free Speaking Language Assessment", ["Kate Knill", "Mark J. F. Gales", "Konstantinos Kyriakopoulos", "Andrey Malinin", "Anton Ragni", "Yu Wang", "Andrew Caines"], "https://doi.org/10.21437/Interspeech.2018-1312", 5, "interspeech", 2018], ["Overview of the 2018 Spoken CALL Shared Task", ["Claudia Baur", "Andrew Caines", "Cathy Chua", "Johanna Gerlach", "Mengjie Qian", "Manny Rayner", "Martin J. Russell", "Helmer Strik", "Xizi Wei"], "https://doi.org/10.21437/Interspeech.2018-97", 5, "interspeech", 2018]], "Nicholas Cummins": [0, ["State of Mind: Classification through Self-reported Affect and Word Use in Speech", ["Eva-Maria Rathner", "Yannik Terhorst", "Nicholas Cummins", "Bjorn W. Schuller", "Harald Baumeister"], "https://doi.org/10.21437/Interspeech.2018-2043", 5, "interspeech", 2018], ["Recognition of Echolalic Autistic Child Vocalisations Utilising Convolutional Recurrent Neural Networks", ["Shahin Amiriparian", "Alice Baird", "Sahib Julka", "Alyssa Alcorn", "Sandra Ottl", "Suncica Petrovic", "Eloise Ainger", "Nicholas Cummins", "Bjorn W. Schuller"], "https://doi.org/10.21437/Interspeech.2018-1772", 5, "interspeech", 2018], ["The Perception and Analysis of the Likeability and Human Likeness of Synthesized Speech", ["Alice Baird", "Emilia Parada-Cabaleiro", "Simone Hantke", "Felix Burkhardt", "Nicholas Cummins", "Bjorn W. Schuller"], "https://doi.org/10.21437/Interspeech.2018-1093", 5, "interspeech", 2018], ["How Did You like 2017? Detection of Language Markers of Depression and Narcissism in Personal Narratives", ["Eva-Maria Rathner", "Julia Djamali", "Yannik Terhorst", "Bjorn W. Schuller", "Nicholas Cummins", "Gudrun Salamon", "Christina Hunger-Schoppe", "Harald Baumeister"], "https://doi.org/10.21437/Interspeech.2018-2040", 5, "interspeech", 2018]], "Yusuke Iwasawa": [0, ["Expressive Speech Synthesis via Modeling Expressions with Variational Autoencoder", ["Kei Akuzawa", "Yusuke Iwasawa", "Yutaka Matsuo"], "https://doi.org/10.21437/Interspeech.2018-1113", 5, "interspeech", 2018]], "Manjunath Mulimani": [0, ["Robust Acoustic Event Classification Using Bag-of-Visual-Words", ["Manjunath Mulimani", "Shashidhar G. Koolagudi"], "https://doi.org/10.21437/Interspeech.2018-1905", 4, "interspeech", 2018]], "Risheng Xia": [0, ["Multi-talker Speech Separation Based on Permutation Invariant Training and Beamforming", ["Lu Yin", "Ziteng Wang", "Risheng Xia", "Junfeng Li", "Yonghong Yan"], "https://doi.org/10.21437/Interspeech.2018-1739", 5, "interspeech", 2018]], "Heidy Suter": [0, ["The Zurich Corpus of Vowel and Voice Quality, Version 1.0", ["Dieter Maurer", "Christian dHeureuse", "Heidy Suter", "Volker Dellwo", "Daniel Friedrichs", "Thayabaran Kathiresan"], "https://doi.org/10.21437/Interspeech.2018-1542", 5, "interspeech", 2018]], "Jiaen Liang": [0, ["Active Learning for LF-MMI Trained Neural Networks in ASR", ["Yanhua Long", "Hong Ye", "Yijie Li", "Jiaen Liang"], "https://doi.org/10.21437/Interspeech.2018-1162", 5, "interspeech", 2018]], "Kimberley Mulder": [0, ["Analyzing EEG Signals in Auditory Speech Comprehension Using Temporal Response Functions and Generalized Additive Models", ["Kimberley Mulder", "Louis ten Bosch", "Lou Boves"], "https://doi.org/10.21437/Interspeech.2018-1676", 5, "interspeech", 2018]], "Tom Ko": [0.00024866758030839264, ["Long Distance Voice Channel Diagnosis Using Deep Neural Networks", ["Zhen Qin", "Tom Ko", "Guangjian Tian"], "https://doi.org/10.21437/Interspeech.2018-1428", 4, "interspeech", 2018], ["Self-Attentive Speaker Embeddings for Text-Independent Speaker Verification", ["Yingke Zhu", "Tom Ko", "David Snyder", "Brian Mak", "Daniel Povey"], "https://doi.org/10.21437/Interspeech.2018-1158", 5, "interspeech", 2018]], "Yu-An Chung": [0.18233120441436768, ["Speech2Vec: A Sequence-to-Sequence Framework for Learning Word Embeddings from Speech", ["Yu-An Chung", "James R. Glass"], "https://doi.org/10.21437/Interspeech.2018-2341", 5, "interspeech", 2018]], "Jie Li": [0, ["Gated Recurrent Unit Based Acoustic Modeling with Future Context", ["Jie Li", "Xiaorui Wang", "Yuanyuan Zhao", "Yan Li"], "https://doi.org/10.21437/Interspeech.2018-1544", 5, "interspeech", 2018]], "Shankar Ananthakrishnan": [0, ["Play Duration Based User-Entity Affinity Modeling in Spoken Dialog System", ["Bo Xiao", "Nicholas Monath", "Shankar Ananthakrishnan", "Abishek Ravi"], "https://doi.org/10.21437/Interspeech.2018-1100", 5, "interspeech", 2018]], "Chunlei Zhang": [0, ["A Multistage Training Framework for Acoustic-to-Word Model", ["Chengzhu Yu", "Chunlei Zhang", "Chao Weng", "Jia Cui", "Dong Yu"], "https://doi.org/10.21437/Interspeech.2018-1452", 5, "interspeech", 2018]], "Li-Rong Dai": [0, ["WaveNet Vocoder with Limited Training Data for Voice Conversion", ["Li-Juan Liu", "Zhen-Hua Ling", "Yuan Jiang", "Ming Zhou", "Li-Rong Dai"], "https://doi.org/10.21437/Interspeech.2018-1190", 5, "interspeech", 2018], ["Learning and Modeling Unit Embeddings for Improving HMM-based Unit Selection Speech Synthesis", ["Xiao Zhou", "Zhen-Hua Ling", "Zhi-Ping Zhou", "Li-Rong Dai"], "https://doi.org/10.21437/Interspeech.2018-1198", 5, "interspeech", 2018]], "Yaping Zhang": [0, ["Deep Noise Tracking Network: A Hybrid Signal Processing/Deep Learning Approach to Speech Enhancement", ["Shuai Nie", "Shan Liang", "Bin Liu", "Yaping Zhang", "Wenju Liu", "Jianhua Tao"], "https://doi.org/10.21437/Interspeech.2018-1020", 5, "interspeech", 2018]], "Mirjam Ernestus": [0, ["Analyzing Reaction Time Sequences from Human Participants in Auditory Experiments", ["Louis ten Bosch", "Mirjam Ernestus", "Lou Boves"], "https://doi.org/10.21437/Interspeech.2018-1728", 5, "interspeech", 2018]], "Anuroop Iyengar": [0, ["Development of Large Vocabulary Speech Recognition System with Keyword Search for Manipuri", ["Tanvina Patel", "Krishna D. N", "Noor Fathima", "Nisar Shah", "Mahima C", "Deepak Kumar", "Anuroop Iyengar"], "https://doi.org/10.21437/Interspeech.2018-2133", 5, "interspeech", 2018], ["An Automatic Speech Transcription System for Manipuri Language", ["Tanvina Patel", "Krishna D. N", "Noor Fathima", "Nisar Shah", "Mahima C", "Deepak Kumar", "Anuroop Iyengar"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3043.html", 2, "interspeech", 2018], ["TDNN-based Multilingual Speech Recognition System for Low Resource Indian Languages", ["Noor Fathima", "Tanvina Patel", "Mahima C", "Anuroop Iyengar"], "https://doi.org/10.21437/Interspeech.2018-2117", 5, "interspeech", 2018]], "Daryush D. Mehta": [0, ["Vocal Biomarkers for Cognitive Performance Estimation in a Working Memory Task", ["Jennifer Sloboda", "Adam C. Lammert", "James R. Williamson", "Christopher J. Smalt", "Daryush D. Mehta", "C. O. L. Ian Curry", "Kristin Heaton", "Jeff Palmer", "Thomas F. Quatieri"], "https://doi.org/10.21437/Interspeech.2018-2418", 5, "interspeech", 2018]], "Barbara E. Bullock": [0, ["Should Code-switching Models Be Asymmetric?", ["Barbara E. Bullock", "Gualberto A. Guzman", "Jacqueline Serigos", "Almeida Jacqueline Toribio"], "https://doi.org/10.21437/Interspeech.2018-1284", 5, "interspeech", 2018]], "Vera Cabarrao": [0, ["Acoustic-prosodic Entrainment in Structural Metadata Events", ["Vera Cabarrao", "Fernando Batista", "Helena Moniz", "Isabel Trancoso", "Ana Isabel Mata"], "https://doi.org/10.21437/Interspeech.2018-2366", 5, "interspeech", 2018]], "Kaiyu Shi": [0, ["Structured Word Embedding for Low Memory Neural Network Language Model", ["Kaiyu Shi", "Kai Yu"], "https://doi.org/10.21437/Interspeech.2018-1057", 5, "interspeech", 2018]], "Erik Edwards": [0, ["An Automated Assistant for Medical Scribes", ["Gregory P. Finley", "Erik Edwards", "Amanda Robinson", "Najmeh Sadoughi", "James Fone", "Mark Miller", "David Suendermann-Oeft", "Michael Brenndoerfer", "Nico Axtmann"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3047.html", 2, "interspeech", 2018]], "Padmanabhan Rajan": [0, ["All-Conv Net for Bird Activity Detection: Significance of Learned Pooling", ["Arjun Pankajakshan", "Anshul Thakur", "Daksh Thapar", "Padmanabhan Rajan", "Aditya Nigam"], "https://doi.org/10.21437/Interspeech.2018-1522", 5, "interspeech", 2018], ["Deep Convex Representations: Feature Representations for Bioacoustics Classification", ["Anshul Thakur", "Vinayak Abrol", "Pulkit Sharma", "Padmanabhan Rajan"], "https://doi.org/10.21437/Interspeech.2018-1705", 5, "interspeech", 2018]], "Paul Foulkes": [0, ["The Individual and the System: Assessing the Stability of the Output of a Semi-automatic Forensic Voice Comparison System", ["Vincent Hughes", "Philip Harrison", "Paul Foulkes", "Peter French", "Colleen Kavanagh", "Eugenia San Segundo Fernandez"], "https://doi.org/10.21437/Interspeech.2018-1649", 5, "interspeech", 2018]], "Ganji Sreeram": [0, ["A Novel Approach for Effective Recognition of the Code-Switched Data on Monolingual Language Model", ["Ganji Sreeram", "Rohit Sinha"], "https://doi.org/10.21437/Interspeech.2018-1259", 5, "interspeech", 2018]], "Ilya I. Viksnin": [0, ["LOCUST - Longitudinal Corpus and Toolset for Speaker Verification", ["Evgeny Dmitriev", "Yulia Kim", "Anastasia Matveeva", "Claude Montacie", "Yannick Boulard", "Yadviga Sinyavskaya", "Yulia Zhukova", "Adam Zarazinski", "Egor Akhanov", "Ilya I. Viksnin", "Andrei A. Shlykov", "Maria Usova"], "https://doi.org/10.21437/Interspeech.2018-2412", 5, "interspeech", 2018]], "Emanuel A. P. Habets": [0, ["Single-Channel Dereverberation Using Direct MMSE Optimization and Bidirectional LSTM Networks", ["Wolfgang Mack", "Soumitro Chakrabarty", "Fabian-Robert Stoter", "Sebastian Braun", "Bernd Edler", "Emanuel A. P. Habets"], "https://doi.org/10.21437/Interspeech.2018-1296", 5, "interspeech", 2018]], "Rob Haynes": [0, ["Efficient Voice Trigger Detection for Low Resource Hardware", ["Siddharth Sigtia", "Rob Haynes", "Hywel Richards", "Erik Marchi", "John Bridle"], "https://doi.org/10.21437/Interspeech.2018-2204", 5, "interspeech", 2018]], "Albert Haque": [0, ["Conditional End-to-End Audio Transforms", ["Albert Haque", "Michelle Guo", "Prateek Verma"], "https://doi.org/10.21437/Interspeech.2018-38", 5, "interspeech", 2018]], "Ian Lane": [0, ["Densely Connected Networks for Conversational Speech Recognition", ["Kyu J. Han", "Akshay Chandrashekaran", "Jungsuk Kim", "Ian Lane"], "https://doi.org/10.21437/Interspeech.2018-1486", 5, "interspeech", 2018], ["Online Incremental Learning for Speaker-Adaptive Language Models", ["Chih Chi Hu", "Bing Liu", "John Shen", "Ian Lane"], "https://doi.org/10.21437/Interspeech.2018-2259", 5, "interspeech", 2018]], "Raseena K. T": [0, ["Automatic Visual Augmentation for Concatenation Based Synthesized Articulatory Videos from Real-time MRI Data for Spoken Language Training", ["Chandana S", "Chiranjeevi Yarra", "Ritu Aggarwal", "Sanjeev Kumar Mittal", "N. K. Kausthubha", "Raseena K. T", "Astha Singh", "Prasanta Kumar Ghosh"], "https://doi.org/10.21437/Interspeech.2018-1570", 5, "interspeech", 2018]], "Ahmed Imtiaz Humayun": [0, ["An Ensemble of Transfer, Semi-supervised and Supervised Learning Methods for Pathological Heart Sound Classification", ["Ahmed Imtiaz Humayun", "Md. Tauhiduzzaman Khan", "Shabnam Ghaffarzadegan", "Zhe Feng", "Taufiq Hasan"], "https://doi.org/10.21437/Interspeech.2018-2413", 5, "interspeech", 2018]], "Sonya Karisma": [0, ["Investigating the Role of Familiar Face and Voice Cues in Speech Processing in Noise", ["Jeesun Kim", "Sonya Karisma", "Vincent Aubanel", "Chris Davis"], "https://doi.org/10.21437/Interspeech.2018-1812", 4, "interspeech", 2018]], "Shoukang Hu": [0, ["Gaussian Process Neural Networks for Speech Recognition", ["Max W. Y. Lam", "Shoukang Hu", "Xurong Xie", "Shansong Liu", "Jianwei Yu", "Rongfeng Su", "Xunying Liu", "Helen Meng"], "https://doi.org/10.21437/Interspeech.2018-1823", 5, "interspeech", 2018], ["Development of the CUHK Dysarthric Speech Recognition System for the UA Speech Corpus", ["Jianwei Yu", "Xurong Xie", "Shansong Liu", "Shoukang Hu", "Max W. Y. Lam", "Xixin Wu", "Ka Ho Wong", "Xunying Liu", "Helen Meng"], "https://doi.org/10.21437/Interspeech.2018-1541", 5, "interspeech", 2018]], "Pushpavathi M": [0, ["Detection of Glottal Activity Errors in Production of Stop Consonants in Children with Cleft Lip and Palate", ["Vikram C. M.", "S. R. Mahadeva Prasanna", "Ajish K. Abraham", "Pushpavathi M", "Girish K. S"], "https://doi.org/10.21437/Interspeech.2018-1665", 5, "interspeech", 2018]], "Boon Pang Lim": [0.9906301498413086, ["Improved ASR for Under-resourced Languages through Multi-task Learning with Acoustic Landmarks", ["Di He", "Boon Pang Lim", "Xuesong Yang", "Mark Hasegawa-Johnson", "Deming Chen"], "https://doi.org/10.21437/Interspeech.2018-1124", 5, "interspeech", 2018]], "Lam Dang Pham": [0, ["Early Detection of Continuous and Partial Audio Events Using CNN", ["Ian Vince McLoughlin", "Yan Song", "Lam Dang Pham", "Ramaswamy Palaniappan", "Huy Phan", "Yue Lang"], "https://doi.org/10.21437/Interspeech.2018-1821", 5, "interspeech", 2018]], "Ricard Marxer": [0, ["DNN Driven Speaker Independent Audio-Visual Mask Estimation for Speech Separation", ["Mandar Gogate", "Ahsan Adeel", "Ricard Marxer", "Jon Barker", "Amir Hussain"], "https://doi.org/10.21437/Interspeech.2018-2516", 5, "interspeech", 2018]], "Nils Holzenberger": [0, ["Learning Word Embeddings: Unsupervised Methods for Fixed-size Representations of Variable-length Speech Segments", ["Nils Holzenberger", "Mingxing Du", "Julien Karadayi", "Rachid Riad", "Emmanuel Dupoux"], "https://doi.org/10.21437/Interspeech.2018-2364", 5, "interspeech", 2018]], "Eric Buschermohle": [0, ["What Do Classifiers Actually Learn? a Case Study on Emotion Recognition Datasets", ["Patrick Meyer", "Eric Buschermohle", "Tim Fingscheidt"], "https://doi.org/10.21437/Interspeech.2018-1851", 5, "interspeech", 2018]], "Purva Kulkarni": [0, ["Deep Neural Networks for Emotion Recognition Combining Audio and Transcripts", ["Jaejin Cho", "Raghavendra Pappagari", "Purva Kulkarni", "Jesus Villalba", "Yishay Carmiel", "Najim Dehak"], "https://doi.org/10.21437/Interspeech.2018-2466", 5, "interspeech", 2018]], "Yun Wang": [0.0668149832636118, ["Comparing the Max and Noisy-Or Pooling Functions in Multiple Instance Learning for Weakly Supervised Sequence Learning Tasks", ["Yun Wang", "Juncheng Li", "Florian Metze"], "https://doi.org/10.21437/Interspeech.2018-990", 5, "interspeech", 2018], ["The ACLEW DiViMe: An Easy-to-use Diarization Tool", ["Adrien Le Franc", "Eric Riebling", "Julien Karadayi", "Yun Wang", "Camila Scaff", "Florian Metze", "Alejandrina Cristia"], "https://doi.org/10.21437/Interspeech.2018-2324", 5, "interspeech", 2018], ["Multiple Instance Deep Learning for Weakly Supervised Small-Footprint Audio Event Detection", ["Shao-Yen Tseng", "Juncheng Li", "Yun Wang", "Florian Metze", "Joseph Szurley", "Samarjit Das"], "https://doi.org/10.21437/Interspeech.2018-1120", 5, "interspeech", 2018]], "Richard Stern": [0, ["A Priori SNR Estimation Based on a Recurrent Neural Network for Robust Speech Enhancement", ["Yangyang Xia", "Richard Stern"], "https://doi.org/10.21437/Interspeech.2018-2423", 5, "interspeech", 2018]], "Pooja Chebolu": [0, ["A Knowledge Driven Structural Segmentation Approach for Play-Talk Classification During Autism Assessment", ["Manoj Kumar", "Pooja Chebolu", "So Hyun Kim", "Kassandra Martinez", "Catherine Lord", "Shrikanth Narayanan"], "https://doi.org/10.21437/Interspeech.2018-1516", 5, "interspeech", 2018]], "Lei Sun": [0.001596404705196619, ["Speaker Diarization with Enhancing Speech for the First DIHARD Challenge", ["Lei Sun", "Jun Du", "Chao Jiang", "Xueyang Zhang", "Shan He", "Bing Yin", "Chin-Hui Lee"], "https://doi.org/10.21437/Interspeech.2018-1742", 5, "interspeech", 2018]], "Monika Podsiadlo": [0, ["Experiments with Training Corpora for Statistical Text-to-speech Systems", ["Monika Podsiadlo", "Victor Ungureanu"], "https://doi.org/10.21437/Interspeech.2018-2400", 5, "interspeech", 2018]], "Meredith Moore": [0, ["Whistle-blowing ASRs: Evaluating the Need for More Inclusive Speech Recognition Systems", ["Meredith Moore", "Hemanth Venkateswara", "Sethuraman Panchanathan"], "https://doi.org/10.21437/Interspeech.2018-2391", 5, "interspeech", 2018]], "Michael T. Johnson": [0, ["Speaker Embedding Extraction with Phonetic Information", ["Yi Liu", "Liang He", "Jia Liu", "Michael T. Johnson"], "https://doi.org/10.21437/Interspeech.2018-1226", 5, "interspeech", 2018]], "Wenyu Jin": [0.0013258533726911992, ["Classification of Huntington Disease Using Acoustic and Lexical Features", ["Matthew Perez", "Wenyu Jin", "Duc Le", "Noelle Carlozzi", "Praveen Dayalu", "Angela Roberts", "Emily Mower Provost"], "https://doi.org/10.21437/Interspeech.2018-2029", 5, "interspeech", 2018]], "Neil Zeghidour": [0, ["End-to-End Speech Recognition from the Raw Waveform", ["Neil Zeghidour", "Nicolas Usunier", "Gabriel Synnaeve", "Ronan Collobert", "Emmanuel Dupoux"], "https://doi.org/10.21437/Interspeech.2018-2414", 5, "interspeech", 2018], ["Sampling Strategies in Siamese Networks for Unsupervised Speech Representation Learning", ["Rachid Riad", "Corentin Dancette", "Julien Karadayi", "Neil Zeghidour", "Thomas Schatz", "Emmanuel Dupoux"], "https://doi.org/10.21437/Interspeech.2018-2384", 5, "interspeech", 2018]], "Paul Gamble": [0, ["Voices Obscured in Complex Environmental Settings (VOiCES) Corpus", ["Colleen Richey", "Maria Auxiliadora Barrios", "Zeb Armstrong", "Chris Bartels", "Horacio Franco", "Martin Graciarena", "Aaron Lawson", "Mahesh Kumar Nandwana", "Allen R. Stauffer", "Julien van Hout", "Paul Gamble", "Jeffrey Hetherly", "Cory Stephenson", "Karl Ni"], "https://doi.org/10.21437/Interspeech.2018-1454", 5, "interspeech", 2018], ["Deep Speech Denoising with Vector Space Projections", ["Jeffrey Hetherly", "Paul Gamble", "Maria Alejandra Barrios", "Cory Stephenson", "Karl Ni"], "https://doi.org/10.21437/Interspeech.2018-83", 5, "interspeech", 2018]], "Nandini Bondale": [0, ["A Study of Lexical and Prosodic Cues to Segmentation in a Hindi-English Code-switched Discourse", ["Preeti Rao", "Mugdha Pandya", "Kamini Sabu", "Kanhaiya Kumar", "Nandini Bondale"], "https://doi.org/10.21437/Interspeech.2018-1600", 5, "interspeech", 2018]], "Phil Rose": [0, ["Dialect-geographical Acoustic-Tonetics: Five Disyllabic Tone Sandhi Patterns in Cognate Words from the Wu Dialects of Zh\u00e8Ji\u0101Ng Province", ["Phil Rose"], "https://doi.org/10.21437/Interspeech.2018-1130", 5, "interspeech", 2018]], "Srikantan S. Nagarajan": [0, ["FACTS: A Hierarchical Task-based Control Model of Speech Incorporating Sensory Feedback", ["Benjamin Parrell", "Vikram Ramanarayanan", "Srikantan S. Nagarajan", "John F. Houde"], "https://doi.org/10.21437/Interspeech.2018-2087", 5, "interspeech", 2018]], "Longting Xu": [0, ["Co-whitening of I-vectors for Short and Long Duration Speaker Verification", ["Longting Xu", "Kong-Aik Lee", "Haizhou Li", "Zhen Yang"], "https://doi.org/10.21437/Interspeech.2018-1246", 5, "interspeech", 2018]], "Dinesh Babu Jayagopi": [0, ["Indian Languages ASR: A Multilingual Phone Recognition Framework with IPA Based Common Phone-set, Predicted Articulatory Features and Feature fusion", ["K. E. Manjunath", "K. Sreenivasa Rao", "Dinesh Babu Jayagopi", "V. Ramasubramanian"], "https://doi.org/10.21437/Interspeech.2018-2529", 5, "interspeech", 2018]], "Felicity Cox": [0, ["Weighting of Coda Voicing Cues: Glottalisation and Vowel Duration", ["Joshua Penney", "Felicity Cox", "Anita Szakay"], "https://doi.org/10.21437/Interspeech.2018-1677", 5, "interspeech", 2018]], "Suliang Bu": [0, ["A Probability Weighted Beamformer for Noise Robust ASR", ["Suliang Bu", "Yunxin Zhao", "Mei-Yuh Hwang", "Sining Sun"], "https://doi.org/10.21437/Interspeech.2018-2427", 5, "interspeech", 2018]], "Maddala Venkata Siva Krishna": [0, ["DA-IICT/IIITV System for Low Resource Speech Recognition Challenge 2018", ["Hardik B. Sailor", "Maddala Venkata Siva Krishna", "Diksha Chhabra", "Ankur T. Patil", "Madhu R. Kamble", "Hemant A. Patil"], "https://doi.org/10.21437/Interspeech.2018-1553", 5, "interspeech", 2018]], "Sebastian Moller": [0, ["Detecting Packet-Loss Concealment Using Formant Features and Decision Tree Learning", ["Gabriel Mittag", "Sebastian Moller"], "https://doi.org/10.21437/Interspeech.2018-1098", 5, "interspeech", 2018]], "Hsin-Hsi Chen": [0, ["Discourse Marker Detection for Hesitation Events on Mandarin Conversation", ["Yu-Wun Wang", "Hen-Hsen Huang", "Kuan-Yu Chen", "Hsin-Hsi Chen"], "https://doi.org/10.21437/Interspeech.2018-2129", 5, "interspeech", 2018]], "Matthew K. H. Ma": [0, ["Cross-cultural (A)symmetries in Audio-visual Attitude Perception", ["Hansjorg Mixdorff", "Albert Rilliard", "Tan Lee", "Matthew K. H. Ma", "Angelika Honemann"], "https://doi.org/10.21437/Interspeech.2018-1373", 5, "interspeech", 2018]], "Arpit Gupta": [0, ["Contextual Slot Carryover for Disparate Schemas", ["Chetan Naik", "Arpit Gupta", "Hancheng Ge", "Lambert Mathias", "Ruhi Sarikaya"], "https://doi.org/10.21437/Interspeech.2018-1035", 5, "interspeech", 2018]], "Todd Rosenstock": [0, ["Cross-language Phoneme Mapping for Low-resource Languages: An Exploration of Benefits and Trade-offs", ["Nick K. Chibuye", "Todd Rosenstock", "Brian DeRenzi"], "https://doi.org/10.21437/Interspeech.2018-2454", 5, "interspeech", 2018]], "Jan Mizgajski": [0, ["Punctuation Prediction Model for Conversational Speech", ["Piotr Zelasko", "Piotr Szymanski", "Jan Mizgajski", "Adrian Szymczak", "Yishay Carmiel", "Najim Dehak"], "https://doi.org/10.21437/Interspeech.2018-1096", 5, "interspeech", 2018]], "Takashi Nose": [0, ["Analyzing Effect of Physical Expression on English Proficiency for Multimodal Computer-Assisted Language Learning", ["Haoran Wu", "Yuya Chiba", "Takashi Nose", "Akinori Ito"], "https://doi.org/10.21437/Interspeech.2018-1425", 5, "interspeech", 2018]], "Marie Kunesova": [0, ["ZCU-NTIS Speaker Diarization System for the DIHARD 2018 Challenge", ["Zbynek Zajic", "Marie Kunesova", "Jan Zelinka", "Marek Hruz"], "https://doi.org/10.21437/Interspeech.2018-1252", 5, "interspeech", 2018]], "Gonzalo D. Sad": [0, ["A French-Spanish Multimodal Speech Communication Corpus Incorporating Acoustic Data, Facial, Hands and Arms Gestures Information", ["Lucas D. Terissi", "Gonzalo D. Sad", "Mauricio Cerda", "Slim Ouni", "Rodrigo Galvez", "Juan Carlos Gomez", "Bernard Girau", "Nancy Hitschfeld-Kahler"], "https://doi.org/10.21437/Interspeech.2018-2212", 5, "interspeech", 2018]], "Bo Chen": [0, ["High-quality Voice Conversion Using Spectrogram-Based WaveNet Vocoder", ["Kuan Chen", "Bo Chen", "Jiahao Lai", "Kai Yu"], "https://doi.org/10.21437/Interspeech.2018-1528", 5, "interspeech", 2018]], "Ming Lei": [0, ["Acoustic Modeling with DFSMN-CTC and Joint CTC-CE Learning", ["Shiliang Zhang", "Ming Lei"], "https://doi.org/10.21437/Interspeech.2018-1049", 5, "interspeech", 2018], ["Compact Feedforward Sequential Memory Networks for Small-footprint Keyword Spotting", ["Mengzhe Chen", "Shiliang Zhang", "Ming Lei", "Yong Liu", "Haitao Yao", "Jie Gao"], "https://doi.org/10.21437/Interspeech.2018-1204", 5, "interspeech", 2018]], "Hynek Hermansky": [0, ["Stream Attention for Distributed Multi-Microphone Speech Recognition", ["Xiaofei Wang", "Ruizhi Li", "Hynek Hermansky"], "https://doi.org/10.21437/Interspeech.2018-1037", 5, "interspeech", 2018]], "Xie Chen": [0, ["Active Memory Networks for Language Modeling", ["Oscar Chen", "Anton Ragni", "Mark J. F. Gales", "Xie Chen"], "https://doi.org/10.21437/Interspeech.2018-78", 5, "interspeech", 2018]], "Zhe Feng": [0, ["An Ensemble of Transfer, Semi-supervised and Supervised Learning Methods for Pathological Heart Sound Classification", ["Ahmed Imtiaz Humayun", "Md. Tauhiduzzaman Khan", "Shabnam Ghaffarzadegan", "Zhe Feng", "Taufiq Hasan"], "https://doi.org/10.21437/Interspeech.2018-2413", 5, "interspeech", 2018]], "Min-Jae Hwang": [0.8463334739208221, ["A Unified Framework for the Generation of Glottal Signals in Deep Learning-based Parametric Speech Synthesis Systems", ["Min-Jae Hwang", "Eunwoo Song", "Jin-Seob Kim", "Hong-Goo Kang"], "https://doi.org/10.21437/Interspeech.2018-1590", 5, "interspeech", 2018]], "P. V. Muhammed Shifas": [0, ["Speech Intelligibility Enhancement Based on a Non-causal Wavenet-like Model", ["P. V. Muhammed Shifas", "Vassilis Tsiaras", "Yannis Stylianou"], "https://doi.org/10.21437/Interspeech.2018-2119", 5, "interspeech", 2018]], "Vivek Kumar": [0, ["Voice Conversion with Conditional SampleRNN", ["Cong Zhou", "Michael Horgan", "Vivek Kumar", "Cristina Vasco", "Dan Darcy"], "https://doi.org/10.21437/Interspeech.2018-1121", 5, "interspeech", 2018]], "Hye-jin Shim": [0.820603758096695, ["Avoiding Speaker Overfitting in End-to-End DNNs Using Raw Waveform for Text-Independent Speaker Verification", ["Jee-weon Jung", "Hee-Soo Heo", "Il-Ho Yang", "Hye-jin Shim", "Ha-Jin Yu"], "https://doi.org/10.21437/Interspeech.2018-1608", 5, "interspeech", 2018]], "Dmitrii Fedotov": [0, ["LSTM Based Cross-corpus and Cross-task Acoustic Emotion Recognition", ["Heysem Kaya", "Dmitrii Fedotov", "Ali Yesilkanat", "Oxana Verkholyak", "Yang Zhang", "Alexey Karpov"], "https://doi.org/10.21437/Interspeech.2018-2298", 5, "interspeech", 2018]], "Amber Afshan": [0, ["Using Voice Quality Supervectors for Affect Identification", ["Soo Jin Park", "Amber Afshan", "Zhi Ming Chua", "Abeer Alwan"], "https://doi.org/10.21437/Interspeech.2018-1401", 5, "interspeech", 2018], ["Effectiveness of Voice Quality Features in Detecting Depression", ["Amber Afshan", "Jinxi Guo", "Soo Jin Park", "Vijay Ravi", "Jonathan Flint", "Abeer Alwan"], "https://doi.org/10.21437/Interspeech.2018-1399", 5, "interspeech", 2018]], "Xi Ma": [0, ["Emotion Recognition from Variable-Length Speech Segments Using Deep Learning on Spectrograms", ["Xi Ma", "Zhiyong Wu", "Jia Jia", "Mingxing Xu", "Helen Meng", "Lianhong Cai"], "https://doi.org/10.21437/Interspeech.2018-2228", 5, "interspeech", 2018]], "Nirmesh J. Shah": [0, ["Effectiveness of Dynamic Features in INCA and Temporal Context-INCA", ["Nirmesh J. Shah", "Hemant A. Patil"], "https://doi.org/10.21437/Interspeech.2018-1538", 5, "interspeech", 2018], ["Unsupervised Vocal Tract Length Warped Posterior Features for Non-Parallel Voice Conversion", ["Nirmesh J. Shah", "Maulik C. Madhavi", "Hemant A. Patil"], "https://doi.org/10.21437/Interspeech.2018-1712", 5, "interspeech", 2018], ["Effectiveness of Generative Adversarial Network for Non-Audible Murmur-to-Whisper Speech Conversion", ["Neil Shah", "Nirmesh J. Shah", "Hemant A. Patil"], "https://doi.org/10.21437/Interspeech.2018-1565", 5, "interspeech", 2018]], "Bin Zhao": [0, ["Revealing Spatiotemporal Brain Dynamics of Speech Production Based on EEG and Eye Movement", ["Bin Zhao", "Jinfeng Huang", "Gaoyan Zhang", "Jianwu Dang", "Minbo Chen", "YingjianFu", "Longbiao Wang"], "https://doi.org/10.21437/Interspeech.2018-1908", 5, "interspeech", 2018]], "Antonio M. Peinado": [0, ["A Deep Identity Representation for Noise Robust Spoofing Detection", ["Alejandro Gomez Alanis", "Antonio M. Peinado", "Jose A. Gonzalez", "Angel M. Gomez"], "https://doi.org/10.21437/Interspeech.2018-1909", 5, "interspeech", 2018]], "Marine Guerry": [0, ["Cultural Differences in Pattern Matching: Multisensory Recognition of Socio-affective Prosody", ["Takaaki Shochi", "Jean-Luc Rouas", "Marine Guerry", "Donna Erickson"], "https://doi.org/10.21437/Interspeech.2018-1795", 5, "interspeech", 2018]], "Yi Luo": [0, ["Real-time Single-channel Dereverberation and Separation with Time-domain Audio Separation Network", ["Yi Luo", "Nima Mesgarani"], "https://doi.org/10.21437/Interspeech.2018-2290", 5, "interspeech", 2018], ["Music Source Activity Detection and Separation Using Deep Attractor Network", ["Rajath Kumar", "Yi Luo", "Nima Mesgarani"], "https://doi.org/10.21437/Interspeech.2018-2326", 5, "interspeech", 2018]], "Arsha Nagrani": [0, ["VoxCeleb2: Deep Speaker Recognition", ["Joon Son Chung", "Arsha Nagrani", "Andrew Zisserman"], "https://doi.org/10.21437/Interspeech.2018-1929", 5, "interspeech", 2018]], "Yike Zhang": [0, ["Improving Language Modeling with an Adversarial Critic for Automatic Speech Recognition", ["Yike Zhang", "Pengyuan Zhang", "Yonghong Yan"], "https://doi.org/10.21437/Interspeech.2018-1111", 5, "interspeech", 2018]], "Seiichi Nakagawa": [0, ["Multiple Phase Information Combination for Replay Attacks Detection", ["Dongbo Li", "Longbiao Wang", "Jianwu Dang", "Meng Liu", "Zeyan Oo", "Seiichi Nakagawa", "Haotian Guan", "Xiangang Li"], "https://doi.org/10.21437/Interspeech.2018-2001", 5, "interspeech", 2018]], "Li-Juan Liu": [0, ["WaveNet Vocoder with Limited Training Data for Voice Conversion", ["Li-Juan Liu", "Zhen-Hua Ling", "Yuan Jiang", "Ming Zhou", "Li-Rong Dai"], "https://doi.org/10.21437/Interspeech.2018-1190", 5, "interspeech", 2018]], "Andrey Malinin": [0, ["Impact of ASR Performance on Free Speaking Language Assessment", ["Kate Knill", "Mark J. F. Gales", "Konstantinos Kyriakopoulos", "Andrey Malinin", "Anton Ragni", "Yu Wang", "Andrew Caines"], "https://doi.org/10.21437/Interspeech.2018-1312", 5, "interspeech", 2018]], "Mousmita Sarma": [0, ["Extracting Speaker's Gender, Accent, Age and Emotional State from Speech", ["Nagendra Kumar Goel", "Mousmita Sarma", "Tejendra Kushwah", "Dharmesh Agarwal", "Zikra Iqbal", "Surbhi Chauhan"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3036.html", 2, "interspeech", 2018], ["Emotion Identification from Raw Speech Signals Using DNNs", ["Mousmita Sarma", "Pegah Ghahremani", "Daniel Povey", "Nagendra Kumar Goel", "Kandarpa Kumar Sarma", "Najim Dehak"], "https://doi.org/10.21437/Interspeech.2018-1353", 5, "interspeech", 2018]], "Soheil Khorram": [0, ["The PRIORI Emotion Dataset: Linking Mood to Emotion Detected In-the-Wild", ["Soheil Khorram", "Mimansa Jaiswal", "John Gideon", "Melvin G. McInnis", "Emily Mower Provost"], "https://doi.org/10.21437/Interspeech.2018-2355", 5, "interspeech", 2018]], "Aija Elg": [0, ["Captaina: Integrated Pronunciation Practice and Data Collection Portal", ["Aku Rouhe", "Reima Karhila", "Aija Elg", "Minnaleena Toivola", "Peter Smit", "Anna-Riikka Smolander", "Mikko Kurimo"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3015.html", 2, "interspeech", 2018]], "Sebastian Stuker": [0, ["Term Extraction via Neural Sequence Labeling a Comparative Evaluation of Strategies Using Recurrent Neural Networks", ["Maren Kucza", "Jan Niehues", "Thomas Zenkel", "Alex Waibel", "Sebastian Stuker"], "https://doi.org/10.21437/Interspeech.2018-2017", 5, "interspeech", 2018], ["Neural Language Codes for Multilingual Acoustic Models", ["Markus Muller", "Sebastian Stuker", "Alex Waibel"], "https://doi.org/10.21437/Interspeech.2018-1241", 5, "interspeech", 2018], ["Self-Attentional Acoustic Models", ["Matthias Sperber", "Jan Niehues", "Graham Neubig", "Sebastian Stuker", "Alex Waibel"], "https://doi.org/10.21437/Interspeech.2018-1910", 5, "interspeech", 2018]], "Ronan Collobert": [0, ["End-to-End Speech Recognition from the Raw Waveform", ["Neil Zeghidour", "Nicolas Usunier", "Gabriel Synnaeve", "Ronan Collobert", "Emmanuel Dupoux"], "https://doi.org/10.21437/Interspeech.2018-2414", 5, "interspeech", 2018]], "Deyi Tuo": [0, ["Deep Discriminative Embeddings for Duration Robust Speaker Verification", ["Na Li", "Deyi Tuo", "Dan Su", "Zhifeng Li", "Dong Yu"], "https://doi.org/10.21437/Interspeech.2018-1769", 5, "interspeech", 2018]], "Natalia Dyrenko": [0, ["The Diphthongs of Formal Nigerian English: A Preliminary Acoustic Analysis", ["Natalia Dyrenko", "Robert Fuchs"], "https://doi.org/10.21437/Interspeech.2018-2373", 5, "interspeech", 2018]], "Ruoming Pang": [0, ["Compression of End-to-End Models", ["Ruoming Pang", "Tara N. Sainath", "Rohit Prabhavalkar", "Suyog Gupta", "Yonghui Wu", "Shuyuan Zhang", "Chung-Cheng Chiu"], "https://doi.org/10.21437/Interspeech.2018-1025", 5, "interspeech", 2018]], "Haihua Xu": [0, ["Mandarin-English Code-switching Speech Recognition", ["Haihua Xu", "Van Tung Pham", "Zin Tun Kyaw", "Zhi Hao Lim", "Eng Siong Chng", "Haizhou Li"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3014.html", 2, "interspeech", 2018], ["Study of Semi-supervised Approaches to Improving English-Mandarin Code-Switching Speech Recognition", ["Pengcheng Guo", "Haihua Xu", "Lei Xie", "Eng Siong Chng"], "https://doi.org/10.21437/Interspeech.2018-1974", 5, "interspeech", 2018]], "Fei Xiang": [0, ["Investigating Generative Adversarial Networks Based Speech Dereverberation for Robust Speech Recognition", ["Ke Wang", "Junbo Zhang", "Sining Sun", "Yujun Wang", "Fei Xiang", "Lei Xie"], "https://doi.org/10.21437/Interspeech.2018-1780", 5, "interspeech", 2018]], "Jinghua Zhong": [0, ["Voice Conversion Across Arbitrary Speakers Based on a Single Target-Speaker Utterance", ["Songxiang Liu", "Jinghua Zhong", "Lifa Sun", "Xixin Wu", "Xunying Liu", "Helen Meng"], "https://doi.org/10.21437/Interspeech.2018-1504", 5, "interspeech", 2018]], "Radek Safarik": [0, ["Using Deep Neural Networks for Identification of Slavic Languages from Acoustic Signal", ["Lukas Mateju", "Petr Cerva", "Jindrich Zdansky", "Radek Safarik"], "https://doi.org/10.21437/Interspeech.2018-1165", 5, "interspeech", 2018]], "Xuemin Zhao": [0, ["Cross-Lingual Multi-Task Neural Architecture for Spoken Language Understanding", ["Yujiang Li", "Xuemin Zhao", "Weiqun Xu", "Yonghong Yan"], "https://doi.org/10.21437/Interspeech.2018-1039", 5, "interspeech", 2018]], "Ramya Viswanathan": [0, ["Hierarchical Accent Determination and Application in a Large Scale ASR System", ["Ramya Viswanathan", "Periyasamy Paramasivam", "Jithendra Vepa"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3030.html", 2, "interspeech", 2018]], "Visar Berisha": [0, ["A Discriminative Acoustic-Prosodic Approach for Measuring Local Entrainment", ["Megan M. Willi", "Stephanie A. Borrie", "Tyson S. Barrett", "Ming Tu", "Visar Berisha"], "https://doi.org/10.21437/Interspeech.2018-1419", 5, "interspeech", 2018], ["Investigating the Role of L1 in Automatic Pronunciation Evaluation of L2 Speech", ["Ming Tu", "Anna Grabek", "Julie Liss", "Visar Berisha"], "https://doi.org/10.21437/Interspeech.2018-1350", 5, "interspeech", 2018], ["Triplet Network with Attention for Speaker Diarization", ["Huan Song", "Megan M. Willi", "Jayaraman J. Thiagarajan", "Visar Berisha", "Andreas Spanias"], "https://doi.org/10.21437/Interspeech.2018-2305", 5, "interspeech", 2018]], "Kuan-Yu Chen": [0, ["Discourse Marker Detection for Hesitation Events on Mandarin Conversation", ["Yu-Wun Wang", "Hen-Hsen Huang", "Kuan-Yu Chen", "Hsin-Hsi Chen"], "https://doi.org/10.21437/Interspeech.2018-2129", 5, "interspeech", 2018], ["Completely Unsupervised Phoneme Recognition by Adversarially Learning Mapping Relationships from Audio Embeddings", ["Da-Rong Liu", "Kuan-Yu Chen", "Hung-yi Lee", "Lin-Shan Lee"], "https://doi.org/10.21437/Interspeech.2018-1800", 5, "interspeech", 2018]], "Simone Hantke": [0, ["The INTERSPEECH 2018 Computational Paralinguistics Challenge: Atypical & Self-Assessed Affect, Crying & Heart Beats", ["Bjorn W. Schuller", "Stefan Steidl", "Anton Batliner", "Peter B. Marschik", "Harald Baumeister", "Fengquan Dong", "Simone Hantke", "Florian B. Pokorny", "Eva-Maria Rathner", "Katrin D. Bartl-Pokorny", "Christa Einspieler", "Dajie Zhang", "Alice Baird", "Shahin Amiriparian", "Kun Qian", "Zhao Ren", "Maximilian Schmitt", "Panagiotis Tzirakis", "Stefanos Zafeiriou"], "https://doi.org/10.21437/Interspeech.2018-51", 5, "interspeech", 2018], ["The Perception and Analysis of the Likeability and Human Likeness of Synthesized Speech", ["Alice Baird", "Emilia Parada-Cabaleiro", "Simone Hantke", "Felix Burkhardt", "Nicholas Cummins", "Bjorn W. Schuller"], "https://doi.org/10.21437/Interspeech.2018-1093", 5, "interspeech", 2018], ["Annotator Trustability-based Cooperative Learning Solutions for Intelligent Audio Analysis", ["Simone Hantke", "Christoph Stemp", "Bjorn W. Schuller"], "https://doi.org/10.21437/Interspeech.2018-1019", 5, "interspeech", 2018]], "Bin Ma": [0, ["Learning Acoustic Word Embeddings with Temporal Context for Query-by-Example Speech Search", ["Yougen Yuan", "Cheung-Chi Leung", "Lei Xie", "Hongjie Chen", "Bin Ma", "Haizhou Li"], "https://doi.org/10.21437/Interspeech.2018-1010", 5, "interspeech", 2018]], "Bin Liu": [0, ["Deep Noise Tracking Network: A Hybrid Signal Processing/Deep Learning Approach to Speech Enhancement", ["Shuai Nie", "Shan Liang", "Bin Liu", "Yaping Zhang", "Wenju Liu", "Jianhua Tao"], "https://doi.org/10.21437/Interspeech.2018-1020", 5, "interspeech", 2018]], "Paul Roe": [0, ["Deep Learning Techniques for Koala Activity Detection", ["Ivan Himawan", "Michael Towsey", "Bradley Law", "Paul Roe"], "https://doi.org/10.21437/Interspeech.2018-1143", 5, "interspeech", 2018]], "Junaid Qadir": [0, ["Transfer Learning for Improving Speech Emotion Classification Accuracy", ["Siddique Latif", "Rajib Rana", "Shahzad Younis", "Junaid Qadir", "Julien Epps"], "https://doi.org/10.21437/Interspeech.2018-1625", 5, "interspeech", 2018], ["Variational Autoencoders for Learning Latent Representations of Speech Emotion: A Preliminary Study", ["Siddique Latif", "Rajib Rana", "Junaid Qadir", "Julien Epps"], "https://doi.org/10.21437/Interspeech.2018-1568", 5, "interspeech", 2018]], "Junfeng Li": [0, ["Multi-talker Speech Separation Based on Permutation Invariant Training and Beamforming", ["Lu Yin", "Ziteng Wang", "Risheng Xia", "Junfeng Li", "Yonghong Yan"], "https://doi.org/10.21437/Interspeech.2018-1739", 5, "interspeech", 2018]], "Yu-Wun Wang": [0.9930607676506042, ["Discourse Marker Detection for Hesitation Events on Mandarin Conversation", ["Yu-Wun Wang", "Hen-Hsen Huang", "Kuan-Yu Chen", "Hsin-Hsi Chen"], "https://doi.org/10.21437/Interspeech.2018-2129", 5, "interspeech", 2018]], "Fanny Meunier": [0, ["Loud and Shouted Speech Perception at Variable Distances in a Forest", ["Julien Meyer", "Fanny Meunier", "Laure Dentel", "Noelia Do Carmo Blanco", "Frederic Sebe"], "https://doi.org/10.21437/Interspeech.2018-2089", 5, "interspeech", 2018], ["Phoneme Resistance and Phoneme Confusion in Noise: Impact of Dyslexia", ["Noelia Do Carmo Blanco", "Julien Meyer", "Michel Hoen", "Fanny Meunier"], "https://doi.org/10.21437/Interspeech.2018-1271", 5, "interspeech", 2018]], "Tomoki Toda": [0, ["Multi-Head Decoder for End-to-End Speech Recognition", ["Tomoki Hayashi", "Shinji Watanabe", "Tomoki Toda", "Kazuya Takeda"], "https://doi.org/10.21437/Interspeech.2018-1655", 5, "interspeech", 2018], ["Collapsed Speech Segment Detection and Suppression for WaveNet Vocoder", ["Yi-Chiao Wu", "Kazuhiro Kobayashi", "Tomoki Hayashi", "Patrick Lumban Tobing", "Tomoki Toda"], "https://doi.org/10.21437/Interspeech.2018-1210", 5, "interspeech", 2018], ["Frequency Domain Variants of Velvet Noise and Their Application to Speech Processing and Synthesis", ["Hideki Kawahara", "Ken-Ichi Sakakibara", "Masanori Morise", "Hideki Banno", "Tomoki Toda", "Toshio Irino"], "https://doi.org/10.21437/Interspeech.2018-43", 5, "interspeech", 2018], ["Audio-visual Voice Conversion Using Deep Canonical Correlation Analysis for Deep Bottleneck Features", ["Satoshi Tamura", "Kento Horio", "Hajime Endo", "Satoru Hayamizu", "Tomoki Toda"], "https://doi.org/10.21437/Interspeech.2018-2286", 5, "interspeech", 2018], ["Designing a Pneumatic Bionic Voice Prosthesis - A Statistical Approach for Source Excitation Generation", ["Farzaneh Ahmadi", "Tomoki Toda"], "https://doi.org/10.21437/Interspeech.2018-1043", 5, "interspeech", 2018]], "Shun-Chang Zhong": [0, ["Self-Assessed Affect Recognition Using Fusion of Attentional BLSTM and Static Acoustic Features", ["Bo-Hao Su", "Sung-Lin Yeh", "Ming-Ya Ko", "Huan-Yu Chen", "Shun-Chang Zhong", "Jeng-Lin Li", "Chi-Chun Lee"], "https://doi.org/10.21437/Interspeech.2018-2261", 5, "interspeech", 2018]], "Francis Tom": [0, ["End-To-End Audio Replay Attack Detection Using Deep Convolutional Networks with Attention", ["Francis Tom", "Mohit Jain", "Prasenjit Dey"], "https://doi.org/10.21437/Interspeech.2018-2279", 5, "interspeech", 2018]], "Pamir Gogoi": [0, ["Analysis of Breathiness in Contextual Vowel of Voiceless Nasals in Mizo", ["Pamir Gogoi", "Sishir Kalita", "Parismita Gogoi", "Ratree Wayland", "Priyankoo Sarmah", "S. R. Mahadeva Prasanna"], "https://doi.org/10.21437/Interspeech.2018-1899", 5, "interspeech", 2018]], "Kai Chen": [0, ["Semi-supervised Learning for Information Extraction from Dialogue", ["Anjuli Kannan", "Kai Chen", "Diana Jaunzeikare", "Alvin Rajkomar"], "https://doi.org/10.21437/Interspeech.2018-1318", 5, "interspeech", 2018]], "Sidharth Aggarwal": [0, ["Brain-Computer Interface using Electroencephalogram Signatures of Eye Blinks", ["Srihari Maruthachalam", "Sidharth Aggarwal", "Mari Ganesh Kumar", "Mriganka Sur", "Hema A. Murthy"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3019.html", 2, "interspeech", 2018]], "Christoph Boddeker": [0, ["Integrating Neural Network Based Beamforming and Weighted Prediction Error Dereverberation", ["Lukas Drude", "Christoph Boddeker", "Jahn Heymann", "Reinhold Haeb-Umbach", "Keisuke Kinoshita", "Marc Delcroix", "Tomohiro Nakatani"], "https://doi.org/10.21437/Interspeech.2018-2196", 5, "interspeech", 2018]], "Gabriel Skantze": [0, ["Investigating Speech Features for Continuous Turn-Taking Prediction Using LSTMs", ["Matthew Roddy", "Gabriel Skantze", "Naomi Harte"], "https://doi.org/10.21437/Interspeech.2018-2124", 5, "interspeech", 2018]], "Nagapuri Srinivas": [0, ["Enhancement of Noisy Speech Signal by Non-Local Means Estimation of Variational Mode Functions", ["Nagapuri Srinivas", "Gayadhar Pradhan", "Syed Shahnawazuddin"], "https://doi.org/10.21437/Interspeech.2018-1928", 5, "interspeech", 2018]], "Veronique Delvaux": [0, ["Towards a Better Characterization of Parkinsonian Speech: A Multidimensional Acoustic Study", ["Veronique Delvaux", "Kathy Huet", "Myriam Piccaluga", "Sophie van Malderen", "Bernard Harmegnies"], "https://doi.org/10.21437/Interspeech.2018-1054", 5, "interspeech", 2018]], "Takayuki Arai": [0, ["Flexible Tongue Housed in a Static Model of the Vocal Tract With Jaws, Lips and Teeth", ["Takayuki Arai"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3004.html", 2, "interspeech", 2018]], "Pauline Hilt": [0, ["Analyzing Vocal Tract Movements During Speech Accommodation", ["Sankar Mukherjee", "Thierry Legou", "Leonardo Lancia", "Pauline Hilt", "Alice Tomassini", "Luciano Fadiga", "Alessandro DAusilio", "Leonardo Badino", "Noel Nguyen"], "https://doi.org/10.21437/Interspeech.2018-2084", 5, "interspeech", 2018]], "C. O. L. Ian Curry": [0, ["Vocal Biomarkers for Cognitive Performance Estimation in a Working Memory Task", ["Jennifer Sloboda", "Adam C. Lammert", "James R. Williamson", "Christopher J. Smalt", "Daryush D. Mehta", "C. O. L. Ian Curry", "Kristin Heaton", "Jeff Palmer", "Thomas F. Quatieri"], "https://doi.org/10.21437/Interspeech.2018-2418", 5, "interspeech", 2018]], "Ian Vince McLoughlin": [0, ["Acoustic Modeling with Densely Connected Residual Network for Multichannel Speech Recognition", ["Jian Tang", "Yan Song", "Lirong Dai", "Ian Vince McLoughlin"], "https://doi.org/10.21437/Interspeech.2018-1089", 5, "interspeech", 2018], ["An Attention Pooling Based Representation Learning Method for Speech Emotion Recognition", ["Pengcheng Li", "Yan Song", "Ian Vince McLoughlin", "Wu Guo", "Lirong Dai"], "https://doi.org/10.21437/Interspeech.2018-1242", 5, "interspeech", 2018], ["Early Detection of Continuous and Partial Audio Events Using CNN", ["Ian Vince McLoughlin", "Yan Song", "Lam Dang Pham", "Ramaswamy Palaniappan", "Huy Phan", "Yue Lang"], "https://doi.org/10.21437/Interspeech.2018-1821", 5, "interspeech", 2018], ["An Improved Deep Embedding Learning Method for Short Duration Speaker Verification", ["Zhifu Gao", "Yan Song", "Ian Vince McLoughlin", "Wu Guo", "Lirong Dai"], "https://doi.org/10.21437/Interspeech.2018-1515", 5, "interspeech", 2018]], "Patrick Meyer": [0, ["What Do Classifiers Actually Learn? a Case Study on Emotion Recognition Datasets", ["Patrick Meyer", "Eric Buschermohle", "Tim Fingscheidt"], "https://doi.org/10.21437/Interspeech.2018-1851", 5, "interspeech", 2018]], "Ahsan Adeel": [0, ["DNN Driven Speaker Independent Audio-Visual Mask Estimation for Speech Separation", ["Mandar Gogate", "Ahsan Adeel", "Ricard Marxer", "Jon Barker", "Amir Hussain"], "https://doi.org/10.21437/Interspeech.2018-2516", 5, "interspeech", 2018]], "Jun R. Wang": [0.07243982143700123, ["Articulation-to-Speech Synthesis Using Articulatory Flesh Point Sensors' Orientation Information", ["Beiming Cao", "Myung Jong Kim", "Jun R. Wang", "Jan P. H. van Santen", "Ted Mau", "Jun Wang"], "https://doi.org/10.21437/Interspeech.2018-2484", 5, "interspeech", 2018]], "Leda Sari": [0, ["Speaker Adaptive Audio-Visual Fusion for the Open-Vocabulary Section of AVICAR", ["Leda Sari", "Mark Hasegawa-Johnson", "Kumaran S", "Georg Stemmer", "Krishnakumar N. Nair"], "https://doi.org/10.21437/Interspeech.2018-2359", 5, "interspeech", 2018]], "Raghav Menon": [0, ["Fast ASR-free and Almost Zero-resource Keyword Spotting Using DTW and CNNs for Humanitarian Monitoring", ["Raghav Menon", "Herman Kamper", "John Quinn", "Thomas Niesler"], "https://doi.org/10.21437/Interspeech.2018-1580", 5, "interspeech", 2018]], "Phil D. Green": [0, ["A Lightly Supervised Approach to Detect Stuttering in Children's Speech", ["Sadeen Alharbi", "Madina Hasan", "Anthony J. H. Simons", "Shelagh Brumfitt", "Phil D. Green"], "https://doi.org/10.21437/Interspeech.2018-2155", 5, "interspeech", 2018]], "Antonio Miguel": [0, ["Estimation of the Number of Speakers with Variational Bayesian PLDA in the DIHARD Diarization Challenge", ["Ignacio Vinals", "Pablo Gimeno", "Alfonso Ortega", "Antonio Miguel", "Eduardo Lleida"], "https://doi.org/10.21437/Interspeech.2018-1841", 5, "interspeech", 2018]], "Parisa Haghani": [0, ["Domain Adaptation Using Factorized Hidden Layer for Robust Automatic Speech Recognition", ["Khe Chai Sim", "Arun Narayanan", "Ananya Misra", "Anshuman Tripathi", "Golan Pundak", "Tara N. Sainath", "Parisa Haghani", "Bo Li", "Michiel Bacchiani"], "https://doi.org/10.21437/Interspeech.2018-2246", 5, "interspeech", 2018]], "Ziteng Wang": [7.954608172155986e-08, ["Multi-talker Speech Separation Based on Permutation Invariant Training and Beamforming", ["Lu Yin", "Ziteng Wang", "Risheng Xia", "Junfeng Li", "Yonghong Yan"], "https://doi.org/10.21437/Interspeech.2018-1739", 5, "interspeech", 2018]], "Alexander Zatvornitskiy": [0, ["An Investigation of Mixup Training Strategies for Acoustic Models in ASR", ["Ivan Medennikov", "Yuri Y. Khokhlov", "Aleksei Romanenko", "Dmitry Popov", "Natalia A. Tomashenko", "Ivan Sorokin", "Alexander Zatvornitskiy"], "https://doi.org/10.21437/Interspeech.2018-2191", 5, "interspeech", 2018]], "Naoyuki Kanda": [0, ["Lattice-free State-level Minimum Bayes Risk Training of Acoustic Models", ["Naoyuki Kanda", "Yusuke Fujita", "Kenji Nagamatsu"], "https://doi.org/10.21437/Interspeech.2018-79", 5, "interspeech", 2018]], "Gudrun Salamon": [0, ["How Did You like 2017? Detection of Language Markers of Depression and Narcissism in Personal Narratives", ["Eva-Maria Rathner", "Julia Djamali", "Yannik Terhorst", "Bjorn W. Schuller", "Nicholas Cummins", "Gudrun Salamon", "Christina Hunger-Schoppe", "Harald Baumeister"], "https://doi.org/10.21437/Interspeech.2018-2040", 5, "interspeech", 2018]], "Hema A. Murthy": [0, ["Resyllabification in Indian Languages and Its Implications in Text-to-speech Systems", ["Mahesh M", "Jeena J. Prakash", "Hema A. Murthy"], "https://doi.org/10.21437/Interspeech.2018-1176", 5, "interspeech", 2018], ["Denoising and Raw-waveform Networks for Weakly-Supervised Gender Identification on Noisy Speech", ["Jilt Sebastian", "Manoj Kumar", "Pavan Kumar D. S.", "Mathew Magimai-Doss", "Hema A. Murthy", "Shrikanth Narayanan"], "https://doi.org/10.21437/Interspeech.2018-2321", 5, "interspeech", 2018], ["Mobile Application for Learning Languages for the Unlettered", ["Gayathri G", "N. Mohana", "Radhika Pal", "Hema A. Murthy"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3012.html", 2, "interspeech", 2018], ["Decision-level Feature Switching as a Paradigm for Replay Attack Detection", ["M. S. Saranya", "Hema A. Murthy"], "https://doi.org/10.21437/Interspeech.2018-1494", 5, "interspeech", 2018], ["Brain-Computer Interface using Electroencephalogram Signatures of Eye Blinks", ["Srihari Maruthachalam", "Sidharth Aggarwal", "Mari Ganesh Kumar", "Mriganka Sur", "Hema A. Murthy"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3019.html", 2, "interspeech", 2018], ["Information Bottleneck Based Percussion Instrument Diarization System for Taniavartanam Segments of Carnatic Music Concerts", ["Nauman Dawalatabad", "Jom Kuriakose", "Chellu Chandra Sekhar", "Hema A. Murthy"], "https://doi.org/10.21437/Interspeech.2018-1203", 5, "interspeech", 2018], ["Early Vocabulary Development Through Picture-based Software Solutions", ["G. R. Kasthuri", "Prabha Ramanathan", "Hema A. Murthy", "Namita Jacob", "Anil Prabhakar"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3022.html", 2, "interspeech", 2018], ["Code-switching in Indic Speech Synthesisers", ["Anju Leela Thomas", "Anusha Prakash", "Arun Baby", "Hema A. Murthy"], "https://doi.org/10.21437/Interspeech.2018-1178", 5, "interspeech", 2018], ["Transcription Correction for Indian Languages Using Acoustic Signatures", ["Jeena J. Prakash", "Golda Brunet Rajan", "Hema A. Murthy"], "https://doi.org/10.21437/Interspeech.2018-1188", 5, "interspeech", 2018]], "Yijia Xu": [0, ["Infant Emotional Outbursts Detection in Infant-parent Spoken Interactions", ["Yijia Xu", "Mark Hasegawa-Johnson", "Nancy McElwain"], "https://doi.org/10.21437/Interspeech.2018-2429", 5, "interspeech", 2018]], "Jeena J. Prakash": [0, ["Resyllabification in Indian Languages and Its Implications in Text-to-speech Systems", ["Mahesh M", "Jeena J. Prakash", "Hema A. Murthy"], "https://doi.org/10.21437/Interspeech.2018-1176", 5, "interspeech", 2018], ["Transcription Correction for Indian Languages Using Acoustic Signatures", ["Jeena J. Prakash", "Golda Brunet Rajan", "Hema A. Murthy"], "https://doi.org/10.21437/Interspeech.2018-1188", 5, "interspeech", 2018]], "Akshay Chandrashekaran": [0, ["Densely Connected Networks for Conversational Speech Recognition", ["Kyu J. Han", "Akshay Chandrashekaran", "Jungsuk Kim", "Ian Lane"], "https://doi.org/10.21437/Interspeech.2018-1486", 5, "interspeech", 2018]], "Bin Li": [0, ["Acoustic Analysis of Whispery Voice Disguise in Mandarin Chinese", ["Cuiling Zhang", "Bin Li", "Si Chen", "Yike Yang"], "https://doi.org/10.21437/Interspeech.2018-2598", 4, "interspeech", 2018]], "Adrien Le Franc": [0, ["The ACLEW DiViMe: An Easy-to-use Diarization Tool", ["Adrien Le Franc", "Eric Riebling", "Julien Karadayi", "Yun Wang", "Camila Scaff", "Florian Metze", "Alejandrina Cristia"], "https://doi.org/10.21437/Interspeech.2018-2324", 5, "interspeech", 2018]], "Peter Guzewich": [0, ["Cross-Corpora Convolutional Deep Neural Network Dereverberation Preprocessing for Speaker Verification and Speech Enhancement", ["Peter Guzewich", "Stephen A. Zahorian", "Xiao Chen", "Hao Zhang"], "https://doi.org/10.21437/Interspeech.2018-2238", 5, "interspeech", 2018]], "Daniel Povey": [0, ["End-to-end Speech Recognition Using Lattice-free MMI", ["Hossein Hadian", "Hossein Sameti", "Daniel Povey", "Sanjeev Khudanpur"], "https://doi.org/10.21437/Interspeech.2018-1423", 5, "interspeech", 2018], ["End-to-end Deep Neural Network Age Estimation", ["Pegah Ghahremani", "Phani Sankar Nidadavolu", "Nanxin Chen", "Jesus Villalba", "Daniel Povey", "Sanjeev Khudanpur", "Najim Dehak"], "https://doi.org/10.21437/Interspeech.2018-2015", 5, "interspeech", 2018], ["Acoustic Modeling from Frequency Domain Representations of Speech", ["Pegah Ghahremani", "Hossein Hadian", "Hang Lv", "Daniel Povey", "Sanjeev Khudanpur"], "https://doi.org/10.21437/Interspeech.2018-1453", 5, "interspeech", 2018], ["Output-Gate Projected Gated Recurrent Unit for Speech Recognition", ["Gaofeng Cheng", "Daniel Povey", "Lu Huang", "Ji Xu", "Sanjeev Khudanpur", "Yonghong Yan"], "https://doi.org/10.21437/Interspeech.2018-1403", 5, "interspeech", 2018], ["A GPU-based WFST Decoder with Exact Lattice Generation", ["Zhehuai Chen", "Justin Luitjens", "Hainan Xu", "Yiming Wang", "Daniel Povey", "Sanjeev Khudanpur"], "https://doi.org/10.21437/Interspeech.2018-1339", 5, "interspeech", 2018], ["Diarization is Hard: Some Experiences and Lessons Learned for the JHU Team in the Inaugural DIHARD Challenge", ["Gregory Sell", "David Snyder", "Alan McCree", "Daniel Garcia-Romero", "Jesus Villalba", "Matthew Maciejewski", "Vimal Manohar", "Najim Dehak", "Daniel Povey", "Shinji Watanabe", "Sanjeev Khudanpur"], "https://doi.org/10.21437/Interspeech.2018-1893", 5, "interspeech", 2018], ["Emotion Identification from Raw Speech Signals Using DNNs", ["Mousmita Sarma", "Pegah Ghahremani", "Daniel Povey", "Nagendra Kumar Goel", "Kandarpa Kumar Sarma", "Najim Dehak"], "https://doi.org/10.21437/Interspeech.2018-1353", 5, "interspeech", 2018], ["Recurrent Neural Network Language Model Adaptation for Conversational Speech Recognition", ["Ke Li", "Hainan Xu", "Yiming Wang", "Daniel Povey", "Sanjeev Khudanpur"], "https://doi.org/10.21437/Interspeech.2018-1413", 5, "interspeech", 2018], ["Self-Attentive Speaker Embeddings for Text-Independent Speaker Verification", ["Yingke Zhu", "Tom Ko", "David Snyder", "Brian Mak", "Daniel Povey"], "https://doi.org/10.21437/Interspeech.2018-1158", 5, "interspeech", 2018], ["Semi-Orthogonal Low-Rank Matrix Factorization for Deep Neural Networks", ["Daniel Povey", "Gaofeng Cheng", "Yiming Wang", "Ke Li", "Hainan Xu", "Mahsa Yarmohammadi", "Sanjeev Khudanpur"], "https://doi.org/10.21437/Interspeech.2018-1417", 5, "interspeech", 2018]], "Zhixiang Wang": [8.865029250029852e-15, ["Towards Temporal Modelling of Categorical Speech Emotion Recognition", ["Wenjing Han", "Huabin Ruan", "Xiaomin Chen", "Zhixiang Wang", "Haifeng Li", "Bjorn W. Schuller"], "https://doi.org/10.21437/Interspeech.2018-1858", 5, "interspeech", 2018]], "Chao Li": [0, ["Exploring Spatio-Temporal Representations by Integrating Attention-based Bidirectional-LSTM-RNNs and FCNs for Speech Emotion Recognition", ["Ziping Zhao", "Yu Zheng", "Zixing Zhang", "Haishuai Wang", "Yiqin Zhao", "Chao Li"], "https://doi.org/10.21437/Interspeech.2018-1477", 5, "interspeech", 2018]], "Annalena Venneri": [0, ["Detecting Signs of Dementia Using Word Vector Representations", ["Bahman Mirheidari", "Daniel Blackburn", "Traci Walker", "Annalena Venneri", "Markus Reuber", "Heidi Christensen"], "https://doi.org/10.21437/Interspeech.2018-1764", 5, "interspeech", 2018]], "Ragesh Rajan M": [0, ["Prediction of Aesthetic Elements in Karnatic Music: A Machine Learning Approach", ["Ragesh Rajan M", "Ashwin Vijayakumar", "Deepu Vijayasenan"], "https://doi.org/10.21437/Interspeech.2018-991", 5, "interspeech", 2018]], "Aaron Lawson": [0, ["Robust Speaker Recognition from Distant Speech under Real Reverberant Environments Using Speaker Embeddings", ["Mahesh Kumar Nandwana", "Julien van Hout", "Mitchell McLaren", "Allen R. Stauffer", "Colleen Richey", "Aaron Lawson", "Martin Graciarena"], "https://doi.org/10.21437/Interspeech.2018-2221", 5, "interspeech", 2018], ["Voices Obscured in Complex Environmental Settings (VOiCES) Corpus", ["Colleen Richey", "Maria Auxiliadora Barrios", "Zeb Armstrong", "Chris Bartels", "Horacio Franco", "Martin Graciarena", "Aaron Lawson", "Mahesh Kumar Nandwana", "Allen R. Stauffer", "Julien van Hout", "Paul Gamble", "Jeffrey Hetherly", "Cory Stephenson", "Karl Ni"], "https://doi.org/10.21437/Interspeech.2018-1454", 5, "interspeech", 2018], ["Analysis of Complementary Information Sources in the Speaker Embeddings Framework", ["Mahesh Kumar Nandwana", "Mitchell McLaren", "Diego Castan", "Julien van Hout", "Aaron Lawson"], "https://doi.org/10.21437/Interspeech.2018-1102", 5, "interspeech", 2018]], "Christos Baziotis": [0, ["Integrating Recurrence Dynamics for Speech Emotion Recognition", ["Efthymios Tzinis", "Georgios Paraskevopoulos", "Christos Baziotis", "Alexandros Potamianos"], "https://doi.org/10.21437/Interspeech.2018-1377", 5, "interspeech", 2018]], "Jan P. H. van Santen": [0, ["Articulation-to-Speech Synthesis Using Articulatory Flesh Point Sensors' Orientation Information", ["Beiming Cao", "Myung Jong Kim", "Jun R. Wang", "Jan P. H. van Santen", "Ted Mau", "Jun Wang"], "https://doi.org/10.21437/Interspeech.2018-2484", 5, "interspeech", 2018]], "Jessie S. Nixon": [0, ["Neural Response Development During Distributional Learning", ["Natalie Boll-Avetisyan", "Jessie S. Nixon", "Tomas O. Lentz", "Liquan Liu", "Sandrien van Ommen", "Cagri Coltekin", "Jacolien van Rij"], "https://doi.org/10.21437/Interspeech.2018-2072", 5, "interspeech", 2018], ["Effective Acoustic Cue Learning Is Not Just Statistical, It Is Discriminative", ["Jessie S. Nixon"], "https://doi.org/10.21437/Interspeech.2018-1024", 5, "interspeech", 2018]], "Susan Shur-Fen Gau": [0, ["An Interlocutor-Modulated Attentional LSTM for Differentiating between Subgroups of Autism Spectrum Disorder", ["Yun-Shao Lin", "Susan Shur-Fen Gau", "Chi-Chun Lee"], "https://doi.org/10.21437/Interspeech.2018-1288", 5, "interspeech", 2018]], "Joao Cabral": [0, ["Estimation of the Asymmetry Parameter of the Glottal Flow Waveform Using the Electroglottographic Signal", ["Joao Cabral"], "https://doi.org/10.21437/Interspeech.2018-2371", 5, "interspeech", 2018]], "Shaoguang Mao": [0, ["Unsupervised Discovery of Non-native Phonetic Patterns in L2 English Speech for Mispronunciation Detection and Diagnosis", ["Xu Li", "Shaoguang Mao", "Xixin Wu", "Kun Li", "Xunying Liu", "Helen Meng"], "https://doi.org/10.21437/Interspeech.2018-2027", 5, "interspeech", 2018]], "Alex S. Cohen": [0, ["Modeling Self-Reported and Observed Affect from Speech", ["Jian Cheng", "Jared Bernstein", "Elizabeth Rosenfeld", "Peter W. Foltz", "Alex S. Cohen", "Terje B. Holmlund", "Brita Elvevag"], "https://doi.org/10.21437/Interspeech.2018-2222", 5, "interspeech", 2018]], "Patrick Nguyen": [0, ["Speech Recognition for Medical Conversations", ["Chung-Cheng Chiu", "Anshuman Tripathi", "Katherine Chou", "Chris Co", "Navdeep Jaitly", "Diana Jaunzeikare", "Anjuli Kannan", "Patrick Nguyen", "Hasim Sak", "Ananth Sankar", "Justin Tansuwan", "Nathan Wan", "Yonghui Wu", "Xuedong Zhang"], "https://doi.org/10.21437/Interspeech.2018-40", 5, "interspeech", 2018]], "Krishnakumar N. Nair": [0, ["Speaker Adaptive Audio-Visual Fusion for the Open-Vocabulary Section of AVICAR", ["Leda Sari", "Mark Hasegawa-Johnson", "Kumaran S", "Georg Stemmer", "Krishnakumar N. Nair"], "https://doi.org/10.21437/Interspeech.2018-2359", 5, "interspeech", 2018]], "Laure Dentel": [0, ["Loud and Shouted Speech Perception at Variable Distances in a Forest", ["Julien Meyer", "Fanny Meunier", "Laure Dentel", "Noelia Do Carmo Blanco", "Frederic Sebe"], "https://doi.org/10.21437/Interspeech.2018-2089", 5, "interspeech", 2018]], "Cuiling Zhang": [0, ["Acoustic Analysis of Whispery Voice Disguise in Mandarin Chinese", ["Cuiling Zhang", "Bin Li", "Si Chen", "Yike Yang"], "https://doi.org/10.21437/Interspeech.2018-2598", 4, "interspeech", 2018]], "Cheung-Chi Leung": [0, ["Learning Acoustic Word Embeddings with Temporal Context for Query-by-Example Speech Search", ["Yougen Yuan", "Cheung-Chi Leung", "Lei Xie", "Hongjie Chen", "Bin Ma", "Haizhou Li"], "https://doi.org/10.21437/Interspeech.2018-1010", 5, "interspeech", 2018]], "Ivan Medennikov": [0, ["An Investigation of Mixup Training Strategies for Acoustic Models in ASR", ["Ivan Medennikov", "Yuri Y. Khokhlov", "Aleksei Romanenko", "Dmitry Popov", "Natalia A. Tomashenko", "Ivan Sorokin", "Alexander Zatvornitskiy"], "https://doi.org/10.21437/Interspeech.2018-2191", 5, "interspeech", 2018]], "Akihiro Kato": [0, ["Waveform to Single Sinusoid Regression to Estimate the F0 Contour from Noisy Speech Using Recurrent Deep Neural Networks", ["Akihiro Kato", "Tomi Kinnunen"], "https://doi.org/10.21437/Interspeech.2018-1671", 5, "interspeech", 2018]], "Gaofeng Cheng": [0, ["Output-Gate Projected Gated Recurrent Unit for Speech Recognition", ["Gaofeng Cheng", "Daniel Povey", "Lu Huang", "Ji Xu", "Sanjeev Khudanpur", "Yonghong Yan"], "https://doi.org/10.21437/Interspeech.2018-1403", 5, "interspeech", 2018], ["Investigation on the Combination of Batch Normalization and Dropout in BLSTM-based Acoustic Modeling for ASR", ["Wenjie Li", "Gaofeng Cheng", "Fengpei Ge", "Pengyuan Zhang", "Yonghong Yan"], "https://doi.org/10.21437/Interspeech.2018-1597", 5, "interspeech", 2018], ["Semi-Orthogonal Low-Rank Matrix Factorization for Deep Neural Networks", ["Daniel Povey", "Gaofeng Cheng", "Yiming Wang", "Ke Li", "Hainan Xu", "Mahsa Yarmohammadi", "Sanjeev Khudanpur"], "https://doi.org/10.21437/Interspeech.2018-1417", 5, "interspeech", 2018]], "Md. Tauhiduzzaman Khan": [0, ["An Ensemble of Transfer, Semi-supervised and Supervised Learning Methods for Pathological Heart Sound Classification", ["Ahmed Imtiaz Humayun", "Md. Tauhiduzzaman Khan", "Shabnam Ghaffarzadegan", "Zhe Feng", "Taufiq Hasan"], "https://doi.org/10.21437/Interspeech.2018-2413", 5, "interspeech", 2018]], "Andreas Seiderer": [0, ["Deep Learning in Paralinguistic Recognition Tasks: Are Hand-crafted Features Still Relevant?", ["Johannes Wagner", "Dominik Schiller", "Andreas Seiderer", "Elisabeth Andre"], "https://doi.org/10.21437/Interspeech.2018-1238", 5, "interspeech", 2018]], "Max W. Y. Lam": [0, ["Gaussian Process Neural Networks for Speech Recognition", ["Max W. Y. Lam", "Shoukang Hu", "Xurong Xie", "Shansong Liu", "Jianwei Yu", "Rongfeng Su", "Xunying Liu", "Helen Meng"], "https://doi.org/10.21437/Interspeech.2018-1823", 5, "interspeech", 2018], ["Development of the CUHK Dysarthric Speech Recognition System for the UA Speech Corpus", ["Jianwei Yu", "Xurong Xie", "Shansong Liu", "Shoukang Hu", "Max W. Y. Lam", "Xixin Wu", "Ka Ho Wong", "Xunying Liu", "Helen Meng"], "https://doi.org/10.21437/Interspeech.2018-1541", 5, "interspeech", 2018]], "Patrick Hanebrink": [0, ["Full Bayesian Hidden Markov Model Variational Autoencoder for Acoustic Unit Discovery", ["Thomas Glarner", "Patrick Hanebrink", "Janek Ebbers", "Reinhold Haeb-Umbach"], "https://doi.org/10.21437/Interspeech.2018-2148", 5, "interspeech", 2018]], "Niko Brummer": [0, ["Fast Variational Bayes for Heavy-tailed PLDA Applied to i-vectors and x-vectors", ["Anna Silnova", "Niko Brummer", "Daniel Garcia-Romero", "David Snyder", "Lukas Burget"], "https://doi.org/10.21437/Interspeech.2018-2128", 5, "interspeech", 2018]], "Matthew Maciejewski": [0, ["Diarization is Hard: Some Experiences and Lessons Learned for the JHU Team in the Inaugural DIHARD Challenge", ["Gregory Sell", "David Snyder", "Alan McCree", "Daniel Garcia-Romero", "Jesus Villalba", "Matthew Maciejewski", "Vimal Manohar", "Najim Dehak", "Daniel Povey", "Shinji Watanabe", "Sanjeev Khudanpur"], "https://doi.org/10.21437/Interspeech.2018-1893", 5, "interspeech", 2018]], "Mia Atcheson": [0, ["Demonstrating and Modelling Systematic Time-varying Annotator Disagreement in Continuous Emotion Annotation", ["Mia Atcheson", "Vidhyasaharan Sethu", "Julien Epps"], "https://doi.org/10.21437/Interspeech.2018-1933", 5, "interspeech", 2018]], "Rif A. Saurous": [0, ["Emotion Recognition from Human Speech Using Temporal Information and Deep Learning", ["John Kim", "Rif A. Saurous"], "https://doi.org/10.21437/Interspeech.2018-1132", 4, "interspeech", 2018]], "Dravyansh Sharma": [0, ["On Training and Evaluation of Grapheme-to-Phoneme Mappings with Limited Data", ["Dravyansh Sharma"], "https://doi.org/10.21437/Interspeech.2018-1920", 5, "interspeech", 2018], ["Dictionary Augmented Sequence-to-Sequence Neural Network for Grapheme to Phoneme Prediction", ["Antoine Bruguier", "Anton Bakhtin", "Dravyansh Sharma"], "https://doi.org/10.21437/Interspeech.2018-2061", 5, "interspeech", 2018]], "Shansong Liu": [0, ["Gaussian Process Neural Networks for Speech Recognition", ["Max W. Y. Lam", "Shoukang Hu", "Xurong Xie", "Shansong Liu", "Jianwei Yu", "Rongfeng Su", "Xunying Liu", "Helen Meng"], "https://doi.org/10.21437/Interspeech.2018-1823", 5, "interspeech", 2018], ["Development of the CUHK Dysarthric Speech Recognition System for the UA Speech Corpus", ["Jianwei Yu", "Xurong Xie", "Shansong Liu", "Shoukang Hu", "Max W. Y. Lam", "Xixin Wu", "Ka Ho Wong", "Xunying Liu", "Helen Meng"], "https://doi.org/10.21437/Interspeech.2018-1541", 5, "interspeech", 2018]], "Marisa Casillas": [0, ["Comparison of Syllabification Algorithms and Training Strategies for Robust Word Count Estimation across Different Languages and Recording Conditions", ["Okko Rasanen", "Shreyas Seshadri", "Marisa Casillas"], "https://doi.org/10.21437/Interspeech.2018-1047", 5, "interspeech", 2018], ["Talker Diarization in the Wild: the Case of Child-centered Daylong Audio-recordings", ["Alejandrina Cristia", "Shobhana Ganesh", "Marisa Casillas", "Sriram Ganapathy"], "https://doi.org/10.21437/Interspeech.2018-2078", 5, "interspeech", 2018]], "Lu Huang": [0, ["Output-Gate Projected Gated Recurrent Unit for Speech Recognition", ["Gaofeng Cheng", "Daniel Povey", "Lu Huang", "Ji Xu", "Sanjeev Khudanpur", "Yonghong Yan"], "https://doi.org/10.21437/Interspeech.2018-1403", 5, "interspeech", 2018]], "Runnan Li": [0, ["Siamese Recurrent Auto-Encoder Representation for Query-by-Example Spoken Term Detection", ["Ziwei Zhu", "Zhiyong Wu", "Runnan Li", "Helen Meng", "Lianhong Cai"], "https://doi.org/10.21437/Interspeech.2018-1788", 5, "interspeech", 2018]], "Jia Liu": [0, ["Speaker Embedding Extraction with Phonetic Information", ["Yi Liu", "Liang He", "Jia Liu", "Michael T. Johnson"], "https://doi.org/10.21437/Interspeech.2018-1226", 5, "interspeech", 2018]], "Sahib Julka": [0, ["Recognition of Echolalic Autistic Child Vocalisations Utilising Convolutional Recurrent Neural Networks", ["Shahin Amiriparian", "Alice Baird", "Sahib Julka", "Alyssa Alcorn", "Sandra Ottl", "Suncica Petrovic", "Eloise Ainger", "Nicholas Cummins", "Bjorn W. Schuller"], "https://doi.org/10.21437/Interspeech.2018-1772", 5, "interspeech", 2018]], "Oxana Verkholyak": [0, ["LSTM Based Cross-corpus and Cross-task Acoustic Emotion Recognition", ["Heysem Kaya", "Dmitrii Fedotov", "Ali Yesilkanat", "Oxana Verkholyak", "Yang Zhang", "Alexey Karpov"], "https://doi.org/10.21437/Interspeech.2018-2298", 5, "interspeech", 2018]], "Yang Cui": [0, ["A New Glottal Neural Vocoder for Speech Synthesis", ["Yang Cui", "Xi Wang", "Lei He", "Frank K. Soong"], "https://doi.org/10.21437/Interspeech.2018-1757", 5, "interspeech", 2018]], "Christopher Liberatore": [0, ["Improving Sparse Representations in Exemplar-Based Voice Conversion with a Phoneme-Selective Objective Function", ["Shaojin Ding", "Guanlong Zhao", "Christopher Liberatore", "Ricardo Gutierrez-Osuna"], "https://doi.org/10.21437/Interspeech.2018-1272", 5, "interspeech", 2018], ["Learning Structured Dictionaries for Exemplar-based Voice Conversion", ["Shaojin Ding", "Christopher Liberatore", "Ricardo Gutierrez-Osuna"], "https://doi.org/10.21437/Interspeech.2018-1295", 5, "interspeech", 2018]], "Jean-Francois Bonastre": [0, ["Voice Comparison and Rhythm: Behavioral Differences between Target and Non-target Comparisons", ["Moez Ajili", "Jean-Francois Bonastre", "Solange Rossato"], "https://doi.org/10.21437/Interspeech.2018-61", 5, "interspeech", 2018], ["Speech Database and Protocol Validation Using Waveform Entropy", ["Itshak Lapidot", "Hector Delgado", "Massimiliano Todisco", "Nicholas W. D. Evans", "Jean-Francois Bonastre"], "https://doi.org/10.21437/Interspeech.2018-2330", 5, "interspeech", 2018]], "Anthony Larcher": [0, ["S4D: Speaker Diarization Toolkit in Python", ["Pierre-Alexandre Broux", "Florent Desnous", "Anthony Larcher", "Simon Petitrenaud", "Jean Carrive", "Sylvain Meignier"], "https://doi.org/10.21437/Interspeech.2018-1232", 5, "interspeech", 2018]], "Maida Percival": [0, ["An Ultrasound Study of Gemination in Coronal Stops in Eastern Oromo", ["Maida Percival", "Alexei Kochetov", "Yoonjung Kang"], "https://doi.org/10.21437/Interspeech.2018-2512", 5, "interspeech", 2018]], "Jesus Villalba": [0, ["An Investigation of Non-linear i-vectors for Speaker Verification", ["Nanxin Chen", "Jesus Villalba", "Najim Dehak"], "https://doi.org/10.21437/Interspeech.2018-2474", 5, "interspeech", 2018], ["Deep Neural Networks for Emotion Recognition Combining Audio and Transcripts", ["Jaejin Cho", "Raghavendra Pappagari", "Purva Kulkarni", "Jesus Villalba", "Yishay Carmiel", "Najim Dehak"], "https://doi.org/10.21437/Interspeech.2018-2466", 5, "interspeech", 2018], ["End-to-end Deep Neural Network Age Estimation", ["Pegah Ghahremani", "Phani Sankar Nidadavolu", "Nanxin Chen", "Jesus Villalba", "Daniel Povey", "Sanjeev Khudanpur", "Najim Dehak"], "https://doi.org/10.21437/Interspeech.2018-2015", 5, "interspeech", 2018], ["Investigation on Bandwidth Extension for Speaker Recognition", ["Phani Sankar Nidadavolu", "Cheng-I Lai", "Jesus Villalba", "Najim Dehak"], "https://doi.org/10.21437/Interspeech.2018-2394", 5, "interspeech", 2018], ["Effectiveness of Single-Channel BLSTM Enhancement for Language Identification", ["Peter Sibbern Frederiksen", "Jesus Villalba", "Shinji Watanabe", "Zheng-Hua Tan", "Najim Dehak"], "https://doi.org/10.21437/Interspeech.2018-2458", 5, "interspeech", 2018], ["Diarization is Hard: Some Experiences and Lessons Learned for the JHU Team in the Inaugural DIHARD Challenge", ["Gregory Sell", "David Snyder", "Alan McCree", "Daniel Garcia-Romero", "Jesus Villalba", "Matthew Maciejewski", "Vimal Manohar", "Najim Dehak", "Daniel Povey", "Shinji Watanabe", "Sanjeev Khudanpur"], "https://doi.org/10.21437/Interspeech.2018-1893", 5, "interspeech", 2018]], "Nicholas Monath": [0, ["Play Duration Based User-Entity Affinity Modeling in Spoken Dialog System", ["Bo Xiao", "Nicholas Monath", "Shankar Ananthakrishnan", "Abishek Ravi"], "https://doi.org/10.21437/Interspeech.2018-1100", 5, "interspeech", 2018]], "Parav Nagarsheth": [0, ["Speech Synthesis in the Wild", ["Ganesh Sivaraman", "Parav Nagarsheth", "Elie Khoury"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3050.html", 2, "interspeech", 2018]], "Fahim A. Salim": [0, ["An Active Feature Transformation Method for Attitude Recognition of Video Bloggers", ["Fasih Haider", "Fahim A. Salim", "Owen Conlan", "Saturnino Luz"], "https://doi.org/10.21437/Interspeech.2018-1222", 5, "interspeech", 2018]], "Stanislav Peshterliev": [0, ["Statistical Model Compression for Small-Footprint Natural Language Understanding", ["Grant P. Strimel", "Kanthashree Mysore Sathyendra", "Stanislav Peshterliev"], "https://doi.org/10.21437/Interspeech.2018-1333", 5, "interspeech", 2018]], "Maharajan Chellapriyadharshini": [0, ["Semi-supervised and Active-learning Scenarios: Efficient Acoustic Model Refinement for a Low Resource Indian Language", ["Maharajan Chellapriyadharshini", "Anoop Toffy", "Srinivasa Raghavan K. M.", "V. Ramasubramanian"], "https://doi.org/10.21437/Interspeech.2018-2486", 5, "interspeech", 2018]], "Emily Mower Provost": [0, ["Classification of Huntington Disease Using Acoustic and Lexical Features", ["Matthew Perez", "Wenyu Jin", "Duc Le", "Noelle Carlozzi", "Praveen Dayalu", "Angela Roberts", "Emily Mower Provost"], "https://doi.org/10.21437/Interspeech.2018-2029", 5, "interspeech", 2018], ["The PRIORI Emotion Dataset: Linking Mood to Emotion Detected In-the-Wild", ["Soheil Khorram", "Mimansa Jaiswal", "John Gideon", "Melvin G. McInnis", "Emily Mower Provost"], "https://doi.org/10.21437/Interspeech.2018-2355", 5, "interspeech", 2018]], "Tommaso Frassetto": [0, ["VoiceGuard: Secure and Private Speech Processing", ["Ferdinand Brasser", "Tommaso Frassetto", "Korbinian Riedhammer", "Ahmad-Reza Sadeghi", "Thomas Schneider", "Christian Weinert"], "https://doi.org/10.21437/Interspeech.2018-2032", 5, "interspeech", 2018]], "Karel Vesely": [0, ["BUT OpenSAT 2017 Speech Recognition System", ["Martin Karafiat", "Murali Karthick Baskar", "Igor Szoke", "Vladimir Malenovsky", "Karel Vesely", "Frantisek Grezl", "Lukas Burget", "Jan Cernocky"], "https://doi.org/10.21437/Interspeech.2018-2457", 5, "interspeech", 2018], ["BUT System for DIHARD Speech Diarization Challenge 2018", ["Mireia Diez", "Federico Landini", "Lukas Burget", "Johan Rohdin", "Anna Silnova", "Katerina Zmolikova", "Ondrej Novotny", "Karel Vesely", "Ondrej Glembek", "Oldrich Plchot", "Ladislav Mosner", "Pavel Matejka"], "https://doi.org/10.21437/Interspeech.2018-1749", 5, "interspeech", 2018], ["Lightly Supervised vs. Semi-supervised Training of Acoustic Model on Luxembourgish for Low-resource Automatic Speech Recognition", ["Karel Vesely", "Carlos Segura", "Igor Szoke", "Jordi Luque", "Jan Cernocky"], "https://doi.org/10.21437/Interspeech.2018-2361", 5, "interspeech", 2018]], "Avashna Govender": [0, ["Using Pupillometry to Measure the Cognitive Load of Synthetic Speech", ["Avashna Govender", "Simon King"], "https://doi.org/10.21437/Interspeech.2018-1174", 5, "interspeech", 2018], ["Measuring the Cognitive Load of Synthetic Speech Using a Dual Task Paradigm", ["Avashna Govender", "Simon King"], "https://doi.org/10.21437/Interspeech.2018-1199", 5, "interspeech", 2018]], "Xunying Liu": [0, ["Voice Conversion Across Arbitrary Speakers Based on a Single Target-Speaker Utterance", ["Songxiang Liu", "Jinghua Zhong", "Lifa Sun", "Xixin Wu", "Xunying Liu", "Helen Meng"], "https://doi.org/10.21437/Interspeech.2018-1504", 5, "interspeech", 2018], ["Gaussian Process Neural Networks for Speech Recognition", ["Max W. Y. Lam", "Shoukang Hu", "Xurong Xie", "Shansong Liu", "Jianwei Yu", "Rongfeng Su", "Xunying Liu", "Helen Meng"], "https://doi.org/10.21437/Interspeech.2018-1823", 5, "interspeech", 2018], ["Unsupervised Discovery of Non-native Phonetic Patterns in L2 English Speech for Mispronunciation Detection and Diagnosis", ["Xu Li", "Shaoguang Mao", "Xixin Wu", "Kun Li", "Xunying Liu", "Helen Meng"], "https://doi.org/10.21437/Interspeech.2018-2027", 5, "interspeech", 2018], ["Development of the CUHK Dysarthric Speech Recognition System for the UA Speech Corpus", ["Jianwei Yu", "Xurong Xie", "Shansong Liu", "Shoukang Hu", "Max W. Y. Lam", "Xixin Wu", "Ka Ho Wong", "Xunying Liu", "Helen Meng"], "https://doi.org/10.21437/Interspeech.2018-1541", 5, "interspeech", 2018], ["Rapid Style Adaptation Using Residual Error Embedding for Expressive Speech Synthesis", ["Xixin Wu", "Yuewen Cao", "Mu Wang", "Songxiang Liu", "Shiyin Kang", "Zhiyong Wu", "Xunying Liu", "Dan Su", "Dong Yu", "Helen Meng"], "https://doi.org/10.21437/Interspeech.2018-1991", 5, "interspeech", 2018], ["Semi-supervised Cross-domain Visual Feature Learning for Audio-Visual Broadcast Speech Transcription", ["Rongfeng Su", "Xunying Liu", "Lan Wang"], "https://doi.org/10.21437/Interspeech.2018-1063", 5, "interspeech", 2018]], "Matthew C. Kelley": [0, ["A Comparison of Input Types to a Deep Neural Network-based Forced Aligner", ["Matthew C. Kelley", "Benjamin V. Tucker"], "https://doi.org/10.21437/Interspeech.2018-1115", 5, "interspeech", 2018]], "Hugo Van hamme": [0, ["Capsule Networks for Low Resource Spoken Language Understanding", ["Vincent Renkens", "Hugo Van hamme"], "https://doi.org/10.21437/Interspeech.2018-1013", 5, "interspeech", 2018], ["State Gradients for RNN Memory Analysis", ["Lyan Verwimp", "Hugo Van hamme", "Vincent Renkens", "Patrick Wambacq"], "https://doi.org/10.21437/Interspeech.2018-1153", 5, "interspeech", 2018], ["Memory Time Span in LSTMs for Multi-Speaker Source Separation", ["Jeroen Zegers", "Hugo Van hamme"], "https://doi.org/10.21437/Interspeech.2018-2082", 5, "interspeech", 2018]], "Subhadeep Dey": [0, ["Analysis of Language Dependent Front-End for Speaker Recognition", ["Srikanth R. Madikeri", "Subhadeep Dey", "Petr Motlicek"], "https://doi.org/10.21437/Interspeech.2018-2071", 5, "interspeech", 2018], ["End-to-end Text-dependent Speaker Verification Using Novel Distance Measures", ["Subhadeep Dey", "Srikanth R. Madikeri", "Petr Motlicek"], "https://doi.org/10.21437/Interspeech.2018-2300", 5, "interspeech", 2018]], "Naomi Harte": [0, ["Investigating Speech Features for Continuous Turn-Taking Prediction Using LSTMs", ["Matthew Roddy", "Gabriel Skantze", "Naomi Harte"], "https://doi.org/10.21437/Interspeech.2018-2124", 5, "interspeech", 2018]], "Stefan Braun": [0, ["Multi-channel Attention for End-to-End Speech Recognition", ["Stefan Braun", "Daniel Neil", "Jithendar Anumula", "Enea Ceolini", "Shih-Chii Liu"], "https://doi.org/10.21437/Interspeech.2018-1301", 5, "interspeech", 2018]], "Chiheb Trabelsi": [0, ["Quaternion Convolutional Neural Networks for End-to-End Automatic Speech Recognition", ["Titouan Parcollet", "Ying Zhang", "Mohamed Morchid", "Chiheb Trabelsi", "Georges Linares", "Renato de Mori", "Yoshua Bengio"], "https://doi.org/10.21437/Interspeech.2018-1898", 5, "interspeech", 2018]], "Hen-Hsen Huang": [0, ["Discourse Marker Detection for Hesitation Events on Mandarin Conversation", ["Yu-Wun Wang", "Hen-Hsen Huang", "Kuan-Yu Chen", "Hsin-Hsi Chen"], "https://doi.org/10.21437/Interspeech.2018-2129", 5, "interspeech", 2018]], "Frantisek Grezl": [0, ["BUT OpenSAT 2017 Speech Recognition System", ["Martin Karafiat", "Murali Karthick Baskar", "Igor Szoke", "Vladimir Malenovsky", "Karel Vesely", "Frantisek Grezl", "Lukas Burget", "Jan Cernocky"], "https://doi.org/10.21437/Interspeech.2018-2457", 5, "interspeech", 2018]], "Reza Lotfian": [0, ["Predicting Categorical Emotions by Jointly Learning Primary and Secondary Emotions through Multitask Learning", ["Reza Lotfian", "Carlos Busso"], "https://doi.org/10.21437/Interspeech.2018-2464", 5, "interspeech", 2018]], "Chenglin Xu": [0, ["A Shifted Delta Coefficient Objective for Monaural Speech Separation Using Multi-task Learning", ["Chenglin Xu", "Wei Rao", "Eng Siong Chng", "Haizhou Li"], "https://doi.org/10.21437/Interspeech.2018-1150", 5, "interspeech", 2018]], "Kazuya Takeda": [0, ["Multi-Head Decoder for End-to-End Speech Recognition", ["Tomoki Hayashi", "Shinji Watanabe", "Tomoki Toda", "Kazuya Takeda"], "https://doi.org/10.21437/Interspeech.2018-1655", 5, "interspeech", 2018]], "William F. Katz": [0, ["Sensorimotor Response to Tongue Displacement Imagery by Talkers with Parkinson's Disease", ["William F. Katz", "Patrick Reidy", "Divya Prabhakaran"], "https://doi.org/10.21437/Interspeech.2018-2592", 5, "interspeech", 2018]], "Matthew Faytak": [0, ["The Retroflex-dental Contrast in Punjabi Stops and Nasals: A Principal Component Analysis of Ultrasound Images", ["Alexei Kochetov", "Matthew Faytak", "Kiranpreet Nara"], "https://doi.org/10.21437/Interspeech.2018-1457", 5, "interspeech", 2018]], "Sang-Jin Kim": [0.8939444720745087, ["Korean Singing Voice Synthesis Based on an LSTM Recurrent Neural Network", ["Juntae Kim", "Heejin Choi", "Jinuk Park", "Minsoo Hahn", "Sang-Jin Kim", "Jong-Jin Kim"], "https://doi.org/10.21437/Interspeech.2018-1575", 5, "interspeech", 2018]], "Yi Liu": [0, ["Speaker Embedding Extraction with Phonetic Information", ["Yi Liu", "Liang He", "Jia Liu", "Michael T. Johnson"], "https://doi.org/10.21437/Interspeech.2018-1226", 5, "interspeech", 2018]], "Chao Weng": [0, ["Improving Attention Based Sequence-to-Sequence Models for End-to-End English Conversational Speech Recognition", ["Chao Weng", "Jia Cui", "Guangsen Wang", "Jun Wang", "Chengzhu Yu", "Dan Su", "Dong Yu"], "https://doi.org/10.21437/Interspeech.2018-1030", 5, "interspeech", 2018], ["A Multistage Training Framework for Acoustic-to-Word Model", ["Chengzhu Yu", "Chunlei Zhang", "Chao Weng", "Jia Cui", "Dong Yu"], "https://doi.org/10.21437/Interspeech.2018-1452", 5, "interspeech", 2018]], "Fahimeh Bahmaninezhad": [0, ["Compensation for Domain Mismatch in Text-independent Speaker Recognition", ["Fahimeh Bahmaninezhad", "John H. L. Hansen"], "https://doi.org/10.21437/Interspeech.2018-1446", 5, "interspeech", 2018]], "Piotr Zelasko": [0, ["Punctuation Prediction Model for Conversational Speech", ["Piotr Zelasko", "Piotr Szymanski", "Jan Mizgajski", "Adrian Szymczak", "Yishay Carmiel", "Najim Dehak"], "https://doi.org/10.21437/Interspeech.2018-1096", 5, "interspeech", 2018]], "Frederic Sebe": [0, ["Loud and Shouted Speech Perception at Variable Distances in a Forest", ["Julien Meyer", "Fanny Meunier", "Laure Dentel", "Noelia Do Carmo Blanco", "Frederic Sebe"], "https://doi.org/10.21437/Interspeech.2018-2089", 5, "interspeech", 2018]], "Joachim Fainberg": [0, ["Learning to Adapt: A Meta-learning Approach for Speaker Adaptation", ["Ondrej Klejch", "Joachim Fainberg", "Peter Bell"], "https://doi.org/10.21437/Interspeech.2018-1244", 5, "interspeech", 2018]], "Patrick Cardinal": [0, ["Classification of Nonverbal Human Produced Audio Events: A Pilot Study", ["Rachel E. Bouserhal", "Philippe Chabot", "Milton Sarria Paja", "Patrick Cardinal", "Jeremie Voix"], "https://doi.org/10.21437/Interspeech.2018-2299", 5, "interspeech", 2018]], "James R. Glass": [0, ["Speech2Vec: A Sequence-to-Sequence Framework for Learning Word Embeddings from Speech", ["Yu-An Chung", "James R. Glass"], "https://doi.org/10.21437/Interspeech.2018-2341", 5, "interspeech", 2018], ["Scalable Factorized Hierarchical Variational Autoencoder Training", ["Wei-Ning Hsu", "James R. Glass"], "https://doi.org/10.21437/Interspeech.2018-1034", 5, "interspeech", 2018], ["Unsupervised Adaptation with Interpretable Disentangled Representations for Distant Conversational Speech Recognition", ["Wei-Ning Hsu", "Hao Tang", "James R. Glass"], "https://doi.org/10.21437/Interspeech.2018-1097", 5, "interspeech", 2018], ["Detecting Depression with Audio/Text Sequence Modeling of Interviews", ["Tuka Al Hanai", "Mohammad M. Ghassemi", "James R. Glass"], "https://doi.org/10.21437/Interspeech.2018-2522", 5, "interspeech", 2018], ["A Study of Enhancement, Augmentation and Autoencoder Methods for Domain Adaptation in Distant Speech Recognition", ["Hao Tang", "Wei-Ning Hsu", "Francois Grondin", "James R. Glass"], "https://doi.org/10.21437/Interspeech.2018-2030", 5, "interspeech", 2018]], "Sadeen Alharbi": [0, ["A Lightly Supervised Approach to Detect Stuttering in Children's Speech", ["Sadeen Alharbi", "Madina Hasan", "Anthony J. H. Simons", "Shelagh Brumfitt", "Phil D. Green"], "https://doi.org/10.21437/Interspeech.2018-2155", 5, "interspeech", 2018]], "Kristin Teplansky": [0, ["Automatic Speech Recognition with Articulatory Information and a Unified Dictionary for Hindi, Marathi, Bengali and Oriya", ["Debadatta Dash", "Myung Jong Kim", "Kristin Teplansky", "Jun Wang"], "https://doi.org/10.21437/Interspeech.2018-2122", 5, "interspeech", 2018], ["Automatic Early Detection of Amyotrophic Lateral Sclerosis from Intelligible Speech Using Convolutional Neural Networks", ["Kwanghoon An", "Myung Jong Kim", "Kristin Teplansky", "Jordan R. Green", "Thomas Campbell", "Yana Yunusova", "Daragh Heitzman", "Jun Wang"], "https://doi.org/10.21437/Interspeech.2018-2496", 5, "interspeech", 2018]], "Peixin Chen": [0, ["Gated Convolutional Neural Network for Sentence Matching", ["Peixin Chen", "Wu Guo", "Zhi Chen", "Jian Sun", "Lanhua You"], "https://doi.org/10.21437/Interspeech.2018-70", 5, "interspeech", 2018]], "Tomi Kinnunen": [0, ["Integrated Presentation Attack Detection and Automatic Speaker Verification: Common Features and Gaussian Back-end Fusion", ["Massimiliano Todisco", "Hector Delgado", "Kong-Aik Lee", "Md. Sahidullah", "Nicholas W. D. Evans", "Tomi Kinnunen", "Junichi Yamagishi"], "https://doi.org/10.21437/Interspeech.2018-2289", 5, "interspeech", 2018], ["Waveform to Single Sinusoid Regression to Estimate the F0 Contour from Noisy Speech Using Recurrent Deep Neural Networks", ["Akihiro Kato", "Tomi Kinnunen"], "https://doi.org/10.21437/Interspeech.2018-1671", 5, "interspeech", 2018]], "Chris Bartels": [0, ["Voices Obscured in Complex Environmental Settings (VOiCES) Corpus", ["Colleen Richey", "Maria Auxiliadora Barrios", "Zeb Armstrong", "Chris Bartels", "Horacio Franco", "Martin Graciarena", "Aaron Lawson", "Mahesh Kumar Nandwana", "Allen R. Stauffer", "Julien van Hout", "Paul Gamble", "Jeffrey Hetherly", "Cory Stephenson", "Karl Ni"], "https://doi.org/10.21437/Interspeech.2018-1454", 5, "interspeech", 2018], ["Articulatory Features for ASR of Pathological Speech", ["Emre Yilmaz", "Vikramjit Mitra", "Chris Bartels", "Horacio Franco"], "https://doi.org/10.21437/Interspeech.2018-67", 5, "interspeech", 2018]], "David Rybach": [0, ["Contextual Speech Recognition in End-to-end Neural Network Systems Using Beam Search", ["Ian Williams", "Anjuli Kannan", "Petar S. Aleksic", "David Rybach", "Tara N. Sainath"], "https://doi.org/10.21437/Interspeech.2018-2416", 5, "interspeech", 2018]], "Daniel Garcia-Romero": [0, ["Fast Variational Bayes for Heavy-tailed PLDA Applied to i-vectors and x-vectors", ["Anna Silnova", "Niko Brummer", "Daniel Garcia-Romero", "David Snyder", "Lukas Burget"], "https://doi.org/10.21437/Interspeech.2018-2128", 5, "interspeech", 2018], ["Diarization is Hard: Some Experiences and Lessons Learned for the JHU Team in the Inaugural DIHARD Challenge", ["Gregory Sell", "David Snyder", "Alan McCree", "Daniel Garcia-Romero", "Jesus Villalba", "Matthew Maciejewski", "Vimal Manohar", "Najim Dehak", "Daniel Povey", "Shinji Watanabe", "Sanjeev Khudanpur"], "https://doi.org/10.21437/Interspeech.2018-1893", 5, "interspeech", 2018]], "Alfonso Ortega": [0, ["Estimation of the Number of Speakers with Variational Bayesian PLDA in the DIHARD Diarization Challenge", ["Ignacio Vinals", "Pablo Gimeno", "Alfonso Ortega", "Antonio Miguel", "Eduardo Lleida"], "https://doi.org/10.21437/Interspeech.2018-1841", 5, "interspeech", 2018]], "Phani Sankar Nidadavolu": [0, ["End-to-end Deep Neural Network Age Estimation", ["Pegah Ghahremani", "Phani Sankar Nidadavolu", "Nanxin Chen", "Jesus Villalba", "Daniel Povey", "Sanjeev Khudanpur", "Najim Dehak"], "https://doi.org/10.21437/Interspeech.2018-2015", 5, "interspeech", 2018], ["Investigation on Bandwidth Extension for Speaker Recognition", ["Phani Sankar Nidadavolu", "Cheng-I Lai", "Jesus Villalba", "Najim Dehak"], "https://doi.org/10.21437/Interspeech.2018-2394", 5, "interspeech", 2018]], "Bernard Girau": [0, ["A French-Spanish Multimodal Speech Communication Corpus Incorporating Acoustic Data, Facial, Hands and Arms Gestures Information", ["Lucas D. Terissi", "Gonzalo D. Sad", "Mauricio Cerda", "Slim Ouni", "Rodrigo Galvez", "Juan Carlos Gomez", "Bernard Girau", "Nancy Hitschfeld-Kahler"], "https://doi.org/10.21437/Interspeech.2018-2212", 5, "interspeech", 2018]], "Francois Yvon": [0, ["Unsupervised Word Segmentation from Speech with Attention", ["Pierre Godard", "Marcely Zanon Boito", "Lucas Ondel", "Alexandre Berard", "Francois Yvon", "Aline Villavicencio", "Laurent Besacier"], "https://doi.org/10.21437/Interspeech.2018-1308", 5, "interspeech", 2018]], "Paul Magron": [0, ["Reducing Interference with Phase Recovery in DNN-based Monaural Singing Voice Separation", ["Paul Magron", "Konstantinos Drossos", "Stylianos Ioannis Mimilakis", "Tuomas Virtanen"], "https://doi.org/10.21437/Interspeech.2018-1845", 5, "interspeech", 2018], ["Expectation-Maximization Algorithms for Itakura-Saito Nonnegative Matrix Factorization", ["Paul Magron", "Tuomas Virtanen"], "https://doi.org/10.21437/Interspeech.2018-1840", 5, "interspeech", 2018]], "Avik Ray": [0, ["Robust Spoken Language Understanding via Paraphrasing", ["Avik Ray", "Yilin Shen", "Hongxia Jin"], "https://doi.org/10.21437/Interspeech.2018-2358", 5, "interspeech", 2018]], "Katherine Mitchell": [0, ["The Effect of Exposure to High Altitude and Heat on Speech Articulatory Coordination", ["James R. Williamson", "Thomas F. Quatieri", "Adam C. Lammert", "Katherine Mitchell", "Katherine Finkelstein", "Nicole Ekon", "Caitlin Dillon", "Robert Kenefick", "Kristin Heaton"], "https://doi.org/10.21437/Interspeech.2018-2372", 5, "interspeech", 2018]], "Roni Rosenfeld": [0, ["Rapid Collection of Spontaneous Speech Corpora Using Telephonic Community Forums", ["Agha Ali Raza", "Awais Athar", "Shan Randhawa", "Zain Tariq", "Muhammad Bilal Saleem", "Haris Bin Zia", "Umar Saif", "Roni Rosenfeld"], "https://doi.org/10.21437/Interspeech.2018-1139", 5, "interspeech", 2018]], "Najim Dehak": [0, ["An Investigation of Non-linear i-vectors for Speaker Verification", ["Nanxin Chen", "Jesus Villalba", "Najim Dehak"], "https://doi.org/10.21437/Interspeech.2018-2474", 5, "interspeech", 2018], ["Deep Neural Networks for Emotion Recognition Combining Audio and Transcripts", ["Jaejin Cho", "Raghavendra Pappagari", "Purva Kulkarni", "Jesus Villalba", "Yishay Carmiel", "Najim Dehak"], "https://doi.org/10.21437/Interspeech.2018-2466", 5, "interspeech", 2018], ["End-to-end Deep Neural Network Age Estimation", ["Pegah Ghahremani", "Phani Sankar Nidadavolu", "Nanxin Chen", "Jesus Villalba", "Daniel Povey", "Sanjeev Khudanpur", "Najim Dehak"], "https://doi.org/10.21437/Interspeech.2018-2015", 5, "interspeech", 2018], ["Investigation on Bandwidth Extension for Speaker Recognition", ["Phani Sankar Nidadavolu", "Cheng-I Lai", "Jesus Villalba", "Najim Dehak"], "https://doi.org/10.21437/Interspeech.2018-2394", 5, "interspeech", 2018], ["Visualizing Phoneme Category Adaptation in Deep Neural Networks", ["Odette Scharenborg", "Sebastian Tiesmeyer", "Mark Hasegawa-Johnson", "Najim Dehak"], "https://doi.org/10.21437/Interspeech.2018-1707", 5, "interspeech", 2018], ["Effectiveness of Single-Channel BLSTM Enhancement for Language Identification", ["Peter Sibbern Frederiksen", "Jesus Villalba", "Shinji Watanabe", "Zheng-Hua Tan", "Najim Dehak"], "https://doi.org/10.21437/Interspeech.2018-2458", 5, "interspeech", 2018], ["Automatic Speech Recognition and Topic Identification from Speech for Almost-Zero-Resource Languages", ["Matthew Wiesner", "Chunxi Liu", "Lucas Ondel", "Craig Harman", "Vimal Manohar", "Jan Trmal", "Zhongqiang Huang", "Najim Dehak", "Sanjeev Khudanpur"], "https://doi.org/10.21437/Interspeech.2018-1836", 5, "interspeech", 2018], ["Punctuation Prediction Model for Conversational Speech", ["Piotr Zelasko", "Piotr Szymanski", "Jan Mizgajski", "Adrian Szymczak", "Yishay Carmiel", "Najim Dehak"], "https://doi.org/10.21437/Interspeech.2018-1096", 5, "interspeech", 2018], ["Diarization is Hard: Some Experiences and Lessons Learned for the JHU Team in the Inaugural DIHARD Challenge", ["Gregory Sell", "David Snyder", "Alan McCree", "Daniel Garcia-Romero", "Jesus Villalba", "Matthew Maciejewski", "Vimal Manohar", "Najim Dehak", "Daniel Povey", "Shinji Watanabe", "Sanjeev Khudanpur"], "https://doi.org/10.21437/Interspeech.2018-1893", 5, "interspeech", 2018], ["Emotion Identification from Raw Speech Signals Using DNNs", ["Mousmita Sarma", "Pegah Ghahremani", "Daniel Povey", "Nagendra Kumar Goel", "Kandarpa Kumar Sarma", "Najim Dehak"], "https://doi.org/10.21437/Interspeech.2018-1353", 5, "interspeech", 2018]], "Shmuel Peleg": [0, ["Visual Speech Enhancement", ["Aviv Gabbay", "Asaph Shamir", "Shmuel Peleg"], "https://doi.org/10.21437/Interspeech.2018-1955", 5, "interspeech", 2018]], "Peter Jancovic": [0, ["Exploring How Phone Classification Neural Networks Learn Phonetic Information by Visualising and Interpreting Bottleneck Features", ["Linxue Bai", "Philip Weber", "Peter Jancovic", "Martin J. Russell"], "https://doi.org/10.21437/Interspeech.2018-2462", 5, "interspeech", 2018], ["The University of Birmingham 2018 Spoken CALL Shared Task Systems", ["Mengjie Qian", "Xizi Wei", "Peter Jancovic", "Martin J. Russell"], "https://doi.org/10.21437/Interspeech.2018-1372", 5, "interspeech", 2018], ["Phone Recognition Using a Non-Linear Manifold with Broad Phone Class Dependent DNNs", ["Mengjie Qian", "Linxue Bai", "Peter Jancovic", "Martin J. Russell"], "https://doi.org/10.21437/Interspeech.2018-1376", 5, "interspeech", 2018]], "Wu Guo": [0, ["Improved Supervised Locality Preserving Projection for I-vector Based Speaker Verification", ["Lanhua You", "Wu Guo", "Yan Song", "Sheng Zhang"], "https://doi.org/10.21437/Interspeech.2018-41", 5, "interspeech", 2018], ["Gated Convolutional Neural Network for Sentence Matching", ["Peixin Chen", "Wu Guo", "Zhi Chen", "Jian Sun", "Lanhua You"], "https://doi.org/10.21437/Interspeech.2018-70", 5, "interspeech", 2018], ["An Attention Pooling Based Representation Learning Method for Speech Emotion Recognition", ["Pengcheng Li", "Yan Song", "Ian Vince McLoughlin", "Wu Guo", "Lirong Dai"], "https://doi.org/10.21437/Interspeech.2018-1242", 5, "interspeech", 2018], ["An Improved Deep Embedding Learning Method for Short Duration Speaker Verification", ["Zhifu Gao", "Yan Song", "Ian Vince McLoughlin", "Wu Guo", "Lirong Dai"], "https://doi.org/10.21437/Interspeech.2018-1515", 5, "interspeech", 2018]], "Haishuai Wang": [3.3426786246389963e-15, ["Exploring Spatio-Temporal Representations by Integrating Attention-based Bidirectional-LSTM-RNNs and FCNs for Speech Emotion Recognition", ["Ziping Zhao", "Yu Zheng", "Zixing Zhang", "Haishuai Wang", "Yiqin Zhao", "Chao Li"], "https://doi.org/10.21437/Interspeech.2018-1477", 5, "interspeech", 2018]], "Purvi Agrawal": [0, ["PhaseNet: Discretized Phase Modeling with Deep Neural Networks for Audio Source Separation", ["Naoya Takahashi", "Purvi Agrawal", "Nabarun Goswami", "Yuki Mitsufuji"], "https://doi.org/10.21437/Interspeech.2018-1773", 5, "interspeech", 2018], ["Comparison of Unsupervised Modulation Filter Learning Methods for ASR", ["Purvi Agrawal", "Sriram Ganapathy"], "https://doi.org/10.21437/Interspeech.2018-1972", 5, "interspeech", 2018]], "Danny Merkx": [0, ["Articulatory Feature Classification Using Convolutional Neural Networks", ["Danny Merkx", "Odette Scharenborg"], "https://doi.org/10.21437/Interspeech.2018-2275", 5, "interspeech", 2018]], "Chris Davis": [0, ["Investigating the Role of Familiar Face and Voice Cues in Speech Processing in Noise", ["Jeesun Kim", "Sonya Karisma", "Vincent Aubanel", "Chris Davis"], "https://doi.org/10.21437/Interspeech.2018-1812", 4, "interspeech", 2018], ["Characterizing Rhythm Differences between Strong and Weak Accented L2 Speech", ["Chris Davis", "Jeesun Kim"], "https://doi.org/10.21437/Interspeech.2018-1798", 5, "interspeech", 2018]], "John Quinn": [0, ["Fast ASR-free and Almost Zero-resource Keyword Spotting Using DTW and CNNs for Humanitarian Monitoring", ["Raghav Menon", "Herman Kamper", "John Quinn", "Thomas Niesler"], "https://doi.org/10.21437/Interspeech.2018-1580", 5, "interspeech", 2018]], "Shuyuan Zhang": [0, ["Compression of End-to-End Models", ["Ruoming Pang", "Tara N. Sainath", "Rohit Prabhavalkar", "Suyog Gupta", "Yonghui Wu", "Shuyuan Zhang", "Chung-Cheng Chiu"], "https://doi.org/10.21437/Interspeech.2018-1025", 5, "interspeech", 2018]], "Zhehuai Chen": [0, ["A GPU-based WFST Decoder with Exact Lattice Generation", ["Zhehuai Chen", "Justin Luitjens", "Hainan Xu", "Yiming Wang", "Daniel Povey", "Sanjeev Khudanpur"], "https://doi.org/10.21437/Interspeech.2018-1339", 5, "interspeech", 2018], ["Knowledge Distillation for Sequence Model", ["Mingkun Huang", "Yongbin You", "Zhehuai Chen", "Yanmin Qian", "Kai Yu"], "https://doi.org/10.21437/Interspeech.2018-1589", 5, "interspeech", 2018]], "Chung-Cheng Chiu": [0, ["Compression of End-to-End Models", ["Ruoming Pang", "Tara N. Sainath", "Rohit Prabhavalkar", "Suyog Gupta", "Yonghui Wu", "Shuyuan Zhang", "Chung-Cheng Chiu"], "https://doi.org/10.21437/Interspeech.2018-1025", 5, "interspeech", 2018], ["Speech Recognition for Medical Conversations", ["Chung-Cheng Chiu", "Anshuman Tripathi", "Katherine Chou", "Chris Co", "Navdeep Jaitly", "Diana Jaunzeikare", "Anjuli Kannan", "Patrick Nguyen", "Hasim Sak", "Ananth Sankar", "Justin Tansuwan", "Nathan Wan", "Yonghui Wu", "Xuedong Zhang"], "https://doi.org/10.21437/Interspeech.2018-40", 5, "interspeech", 2018]], "Kathy Huet": [0, ["Towards a Better Characterization of Parkinsonian Speech: A Multidimensional Acoustic Study", ["Veronique Delvaux", "Kathy Huet", "Myriam Piccaluga", "Sophie van Malderen", "Bernard Harmegnies"], "https://doi.org/10.21437/Interspeech.2018-1054", 5, "interspeech", 2018]], "Aswin Shanmugam Subramanian": [0, ["Building State-of-the-art Distant Speech Recognition Using the CHiME-4 Challenge with a Setup of Speech Enhancement Baseline", ["Szu-Jui Chen", "Aswin Shanmugam Subramanian", "Hainan Xu", "Shinji Watanabe"], "https://doi.org/10.21437/Interspeech.2018-1262", 5, "interspeech", 2018], ["Student-Teacher Learning for BLSTM Mask-based Speech Enhancement", ["Aswin Shanmugam Subramanian", "Szu-Jui Chen", "Shinji Watanabe"], "https://doi.org/10.21437/Interspeech.2018-2440", 5, "interspeech", 2018]], "Ali Raza Syed": [0, ["Concatenative Resynthesis with Improved Training Signals for Speech Enhancement", ["Ali Raza Syed", "Viet Anh Trinh", "Michael I. Mandel"], "https://doi.org/10.21437/Interspeech.2018-2439", 5, "interspeech", 2018]], "Tamas Grosz": [0, ["General Utterance-Level Feature Extraction for Classifying Crying Sounds, Atypical & Self-Assessed Affect and Heart Beats", ["Gabor Gosztolya", "Tamas Grosz", "Laszlo Toth"], "https://doi.org/10.21437/Interspeech.2018-1076", 5, "interspeech", 2018], ["Multi-Task Learning of Speech Recognition and Speech Synthesis Parameters for Ultrasound-based Silent Speech Interfaces", ["Laszlo Toth", "Gabor Gosztolya", "Tamas Grosz", "Alexandra Marko", "Tamas Gabor Csapo"], "https://doi.org/10.21437/Interspeech.2018-1078", 5, "interspeech", 2018]], "Santiago Pascual": [0, ["Spanish Statistical Parametric Speech Synthesis Using a Neural Vocoder", ["Antonio Bonafonte", "Santiago Pascual", "Georgina Dorca"], "https://doi.org/10.21437/Interspeech.2018-2417", 4, "interspeech", 2018]], "Shai Rozenberg": [0, ["The IBM Virtual Voice Creator", ["Alexander Sorin", "Slava Shechtman", "Zvi Kons", "Ron Hoory", "Shay Ben-David", "Joe Pavitt", "Shai Rozenberg", "Carmel Rabinovitz", "Tal Drory"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3011.html", 2, "interspeech", 2018]], "Jianguo Wei": [0, ["Tongue Segmentation with Geometrically Constrained Snake Model", ["Zhihua Su", "Jianguo Wei", "Qiang Fang", "Jianrong Wang", "Kiyoshi Honda"], "https://doi.org/10.21437/Interspeech.2018-1108", 5, "interspeech", 2018]], "Mithun Das Gupta": [0, ["HoloCompanion: An MR Friend for EveryOne", ["Annam Naresh", "Rushabh Gandhi", "Mallikarjuna Rao Bellamkonda", "Mithun Das Gupta"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3017.html", 2, "interspeech", 2018]], "Brian McFee": [0, ["Bubble Cooperative Networks for Identifying Important Speech Cues", ["Viet Anh Trinh", "Brian McFee", "Michael I. Mandel"], "https://doi.org/10.21437/Interspeech.2018-2377", 5, "interspeech", 2018]], "Anil Kumar Vuppala": [0, ["An Exploration towards Joint Acoustic Modeling for Indian Languages: IIIT-H Submission for Low Resource Speech Recognition Challenge for Indian Languages, INTERSPEECH 2018", ["Hari Krishna Vydana", "Krishna Gurugubelli", "Vishnu Vidyadhara Raju Vegesna", "Anil Kumar Vuppala"], "https://doi.org/10.21437/Interspeech.2018-1584", 5, "interspeech", 2018]], "Felipe Espic": [0, ["Exemplar-based Speech Waveform Generation", ["Oliver Watts", "Cassia Valentini-Botinhao", "Felipe Espic", "Simon King"], "https://doi.org/10.21437/Interspeech.2018-1857", 5, "interspeech", 2018]], "Francis C. K. Wong": [0, ["Experience-dependent Influence of Music and Language on Lexical Pitch Learning Is Not Additive", ["Akshay Raj Maggu", "Patrick C. M. Wong", "Hanjun Liu", "Francis C. K. Wong"], "https://doi.org/10.21437/Interspeech.2018-2104", 4, "interspeech", 2018]], "Ryoichi Takashima": [0, ["Improving CTC-based Acoustic Model with Very Deep Residual Time-delay Neural Networks", ["Sheng Li", "Xugang Lu", "Ryoichi Takashima", "Peng Shen", "Tatsuya Kawahara", "Hisashi Kawai"], "https://doi.org/10.21437/Interspeech.2018-1475", 5, "interspeech", 2018]], "Hongwei Song": [9.227629860220077e-08, ["A Compact and Discriminative Feature Based on Auditory Summary Statistics for Acoustic Scene Classification", ["Hongwei Song", "Jiqing Han", "Shiwen Deng"], "https://doi.org/10.21437/Interspeech.2018-1299", 5, "interspeech", 2018]], "Efthymios Tzinis": [0, ["Integrating Recurrence Dynamics for Speech Emotion Recognition", ["Efthymios Tzinis", "Georgios Paraskevopoulos", "Christos Baziotis", "Alexandros Potamianos"], "https://doi.org/10.21437/Interspeech.2018-1377", 5, "interspeech", 2018]], "Bernd Edler": [0, ["Single-Channel Dereverberation Using Direct MMSE Optimization and Bidirectional LSTM Networks", ["Wolfgang Mack", "Soumitro Chakrabarty", "Fabian-Robert Stoter", "Sebastian Braun", "Bernd Edler", "Emanuel A. P. Habets"], "https://doi.org/10.21437/Interspeech.2018-1296", 5, "interspeech", 2018]], "Soumi Maiti": [0, ["Large Vocabulary Concatenative Resynthesis", ["Soumi Maiti", "Joey Ching", "Michael I. Mandel"], "https://doi.org/10.21437/Interspeech.2018-2383", 5, "interspeech", 2018]], "Navdeep Jaitly": [0, ["Speech Recognition for Medical Conversations", ["Chung-Cheng Chiu", "Anshuman Tripathi", "Katherine Chou", "Chris Co", "Navdeep Jaitly", "Diana Jaunzeikare", "Anjuli Kannan", "Patrick Nguyen", "Hasim Sak", "Ananth Sankar", "Justin Tansuwan", "Nathan Wan", "Yonghui Wu", "Xuedong Zhang"], "https://doi.org/10.21437/Interspeech.2018-40", 5, "interspeech", 2018]], "Suguru Kabashima": [0, ["A Study of Objective Measurement of Comprehensibility through Native Speakers' Shadowing of Learners' Utterances", ["Yusuke Inoue", "Suguru Kabashima", "Daisuke Saito", "Nobuaki Minematsu", "Kumi Kanamura", "Yutaka Yamauchi"], "https://doi.org/10.21437/Interspeech.2018-1860", 5, "interspeech", 2018]], "Ignacio Vinals": [0, ["Estimation of the Number of Speakers with Variational Bayesian PLDA in the DIHARD Diarization Challenge", ["Ignacio Vinals", "Pablo Gimeno", "Alfonso Ortega", "Antonio Miguel", "Eduardo Lleida"], "https://doi.org/10.21437/Interspeech.2018-1841", 5, "interspeech", 2018]], "Astha Singh": [0, ["Relating Articulatory Motions in Different Speaking Rates", ["Astha Singh", "G. Nisha Meenakshi", "Prasanta Kumar Ghosh"], "https://doi.org/10.21437/Interspeech.2018-1862", 5, "interspeech", 2018], ["Automatic Visual Augmentation for Concatenation Based Synthesized Articulatory Videos from Real-time MRI Data for Spoken Language Training", ["Chandana S", "Chiranjeevi Yarra", "Ritu Aggarwal", "Sanjeev Kumar Mittal", "N. K. Kausthubha", "Raseena K. T", "Astha Singh", "Prasanta Kumar Ghosh"], "https://doi.org/10.21437/Interspeech.2018-1570", 5, "interspeech", 2018]], "Na Li": [0, ["Deep Discriminative Embeddings for Duration Robust Speaker Verification", ["Na Li", "Deyi Tuo", "Dan Su", "Zhifeng Li", "Dong Yu"], "https://doi.org/10.21437/Interspeech.2018-1769", 5, "interspeech", 2018]], "Yang Yue": [0, ["Vowels and Diphthongs in Hangzhou Wu Chinese Dialect", ["Yang Yue", "Fang Hu"], "https://doi.org/10.21437/Interspeech.2018-1225", 5, "interspeech", 2018]], "Sibsambhu Kar": [0, ["Speech Emotion Recognition Using Spectrogram & Phoneme Embedding", ["Promod Yenigalla", "Abhay Kumar", "Suraj Tripathi", "Chirag Singh", "Sibsambhu Kar", "Jithendra Vepa"], "https://doi.org/10.21437/Interspeech.2018-1811", 5, "interspeech", 2018]], "Jaesung Bae": [0.9978321045637131, ["End-to-End Speech Command Recognition with Capsule Network", ["Jaesung Bae", "Dae-Shik Kim"], "https://doi.org/10.21437/Interspeech.2018-1888", 5, "interspeech", 2018]], "Nico Axtmann": [0, ["An Automated Assistant for Medical Scribes", ["Gregory P. Finley", "Erik Edwards", "Amanda Robinson", "Najmeh Sadoughi", "James Fone", "Mark Miller", "David Suendermann-Oeft", "Michael Brenndoerfer", "Nico Axtmann"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3047.html", 2, "interspeech", 2018]], "Dharmesh Agarwal": [0, ["Extracting Speaker's Gender, Accent, Age and Emotional State from Speech", ["Nagendra Kumar Goel", "Mousmita Sarma", "Tejendra Kushwah", "Dharmesh Agarwal", "Zikra Iqbal", "Surbhi Chauhan"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3036.html", 2, "interspeech", 2018]], "Tomoharu Iwata": [0, ["Semi-Supervised End-to-End Speech Recognition", ["Shigeki Karita", "Shinji Watanabe", "Tomoharu Iwata", "Atsunori Ogawa", "Marc Delcroix"], "https://doi.org/10.21437/Interspeech.2018-1746", 5, "interspeech", 2018]], "Hong Liu": [0, ["Multiple Concurrent Sound Source Tracking Based on Observation-Guided Adaptive Particle Filter", ["Hong Liu", "Haipeng Lan", "Bing Yang", "Cheng Pang"], "https://doi.org/10.21437/Interspeech.2018-1248", 5, "interspeech", 2018]], "Juraj Simko": [0, ["Articulatory Consequences of Vocal Effort Elicitation Method", ["Elisabet Eir Cortes", "Marcin Wlodarczak", "Juraj Simko"], "https://doi.org/10.21437/Interspeech.2018-1038", 5, "interspeech", 2018], ["Prominence-based Evaluation of L2 Prosody", ["Heini Kallio", "Antti Suni", "Paivi Virkkunen", "Juraj Simko"], "https://doi.org/10.21437/Interspeech.2018-1873", 5, "interspeech", 2018]], "Hongying Yang": [1.1244134157095687e-06, ["Measuring the Band Importance Function for Mandarin Chinese with a Bayesian Adaptive Procedure", ["Yufan Du", "Yi Shen", "Hongying Yang", "Xihong Wu", "Jing Chen"], "https://doi.org/10.21437/Interspeech.2018-1825", 5, "interspeech", 2018]], "Christian dHeureuse": [0, ["The Zurich Corpus of Vowel and Voice Quality, Version 1.0", ["Dieter Maurer", "Christian dHeureuse", "Heidy Suter", "Volker Dellwo", "Daniel Friedrichs", "Thayabaran Kathiresan"], "https://doi.org/10.21437/Interspeech.2018-1542", 5, "interspeech", 2018]], "Vishwa Gupta": [0, ["CRIM's System for the MGB-3 English Multi-Genre Broadcast Media Transcription", ["Vishwa Gupta", "Gilles Boulianne"], "https://doi.org/10.21437/Interspeech.2018-2079", 5, "interspeech", 2018], ["Deeply Fused Speaker Embeddings for Text-Independent Speaker Verification", ["Gautam Bhattacharya", "Md. Jahangir Alam", "Vishwa Gupta", "Patrick Kenny"], "https://doi.org/10.21437/Interspeech.2018-1688", 5, "interspeech", 2018]], "Maria Auxiliadora Barrios": [0, ["Voices Obscured in Complex Environmental Settings (VOiCES) Corpus", ["Colleen Richey", "Maria Auxiliadora Barrios", "Zeb Armstrong", "Chris Bartels", "Horacio Franco", "Martin Graciarena", "Aaron Lawson", "Mahesh Kumar Nandwana", "Allen R. Stauffer", "Julien van Hout", "Paul Gamble", "Jeffrey Hetherly", "Cory Stephenson", "Karl Ni"], "https://doi.org/10.21437/Interspeech.2018-1454", 5, "interspeech", 2018]], "Jenny Yu": [7.454775868609431e-06, ["Truncation and Compression in Southern German and Australian English", ["Jenny Yu", "Katharina Zahner"], "https://doi.org/10.21437/Interspeech.2018-2513", 5, "interspeech", 2018]], "Yasuo Kuniyoshi": [0, ["Implementation of Respiration in Articulatory Synthesis Using a Pressure-Volume Lung Model", ["Keisuke Tanihara", "Shogo Yonekura", "Yasuo Kuniyoshi"], "https://doi.org/10.21437/Interspeech.2018-1080", 5, "interspeech", 2018]], "Biswajit Das": [0, ["Dysarthric Speech Recognition Using Time-delay Neural Network Based Denoising Autoencoder", ["Chitralekha Bhat", "Biswajit Das", "Bhavik Vachhani", "Sunil Kumar Kopparapu"], "https://doi.org/10.21437/Interspeech.2018-1754", 5, "interspeech", 2018]], "Eliathamby Ambikairajah": [0, ["Detection of Replay-Spoofing Attacks Using Frequency Modulation Features", ["Tharshini Gunendradasan", "Buddhi Wickramasinghe", "Phu Ngoc Le", "Eliathamby Ambikairajah", "Julien Epps"], "https://doi.org/10.21437/Interspeech.2018-1473", 5, "interspeech", 2018], ["Frequency Domain Linear Prediction Features for Replay Spoofing Attack Detection", ["Buddhi Wickramasinghe", "Saad Irtza", "Eliathamby Ambikairajah", "Julien Epps"], "https://doi.org/10.21437/Interspeech.2018-1574", 5, "interspeech", 2018], ["Deep Siamese Architecture Based Replay Detection for Secure Voice Biometric", ["Kaavya Sriskandaraja", "Vidhyasaharan Sethu", "Eliathamby Ambikairajah"], "https://doi.org/10.21437/Interspeech.2018-1819", 5, "interspeech", 2018], ["Modulation Dynamic Features for the Detection of Replay Attacks", ["Gajan Suthokumar", "Vidhyasaharan Sethu", "Chamith Wijenayake", "Eliathamby Ambikairajah"], "https://doi.org/10.21437/Interspeech.2018-1846", 5, "interspeech", 2018], ["Sub-band Envelope Features Using Frequency Domain Linear Prediction for Short Duration Language Identification", ["Sarith Fernando", "Vidhyasaharan Sethu", "Eliathamby Ambikairajah"], "https://doi.org/10.21437/Interspeech.2018-1805", 5, "interspeech", 2018]], "Bo-Hao Su": [0, ["Self-Assessed Affect Recognition Using Fusion of Attentional BLSTM and Static Acoustic Features", ["Bo-Hao Su", "Sung-Lin Yeh", "Ming-Ya Ko", "Huan-Yu Chen", "Shun-Chang Zhong", "Jeng-Lin Li", "Chi-Chun Lee"], "https://doi.org/10.21437/Interspeech.2018-2261", 5, "interspeech", 2018]], "Paul Kranzusch": [0, ["Prediction of Subjective Listening Effort from Acoustic Data with Non-Intrusive Deep Models", ["Paul Kranzusch", "Rainer Huber", "Melanie Kruger", "Birger Kollmeier", "Bernd T. Meyer"], "https://doi.org/10.21437/Interspeech.2018-1375", 5, "interspeech", 2018]], "Daniel P. W. Ellis": [0, ["AVA-Speech: A Densely Labeled Dataset of Speech Activity in Movies", ["Sourish Chaudhuri", "Joseph Roth", "Daniel P. W. Ellis", "Andrew C. Gallagher", "Liat Kaver", "Radhika Marvin", "Caroline Pantofaru", "Nathan Reale", "Loretta Guarino Reid", "Kevin W. Wilson", "Zhonghua Xi"], "https://doi.org/10.21437/Interspeech.2018-2028", 5, "interspeech", 2018]], "Shaojin Ding": [0, ["Improving Sparse Representations in Exemplar-Based Voice Conversion with a Phoneme-Selective Objective Function", ["Shaojin Ding", "Guanlong Zhao", "Christopher Liberatore", "Ricardo Gutierrez-Osuna"], "https://doi.org/10.21437/Interspeech.2018-1272", 5, "interspeech", 2018], ["Learning Structured Dictionaries for Exemplar-based Voice Conversion", ["Shaojin Ding", "Christopher Liberatore", "Ricardo Gutierrez-Osuna"], "https://doi.org/10.21437/Interspeech.2018-1295", 5, "interspeech", 2018]], "Siyuan Feng": [0, ["Improving Cross-Lingual Knowledge Transferability Using Multilingual TDNN-BLSTM with Language-Dependent Pre-Final Layer", ["Siyuan Feng", "Tan Lee"], "https://doi.org/10.21437/Interspeech.2018-1182", 5, "interspeech", 2018], ["Exploiting Speaker and Phonetic Diversity of Mismatched Language Resources for Unsupervised Subword Modeling", ["Siyuan Feng", "Tan Lee"], "https://doi.org/10.21437/Interspeech.2018-1081", 5, "interspeech", 2018], ["Automatic Speech Assessment for People with Aphasia Using TDNN-BLSTM with Multi-Task Learning", ["Ying Qin", "Tan Lee", "Siyuan Feng", "Anthony Pak-Hin Kong"], "https://doi.org/10.21437/Interspeech.2018-1630", 5, "interspeech", 2018]], "Sven Magg": [0, ["Conversational Analysis Using Utterance-level Attention-based Bidirectional Recurrent Neural Networks", ["Chandrakant Bothe", "Sven Magg", "Cornelius Weber", "Stefan Wermter"], "https://doi.org/10.21437/Interspeech.2018-2527", 5, "interspeech", 2018]], "Jian Huang": [0, ["Speech Emotion Recognition from Variable-Length Inputs with Triplet Loss Function", ["Jian Huang", "Ya Li", "Jianhua Tao", "Zhen Lian"], "https://doi.org/10.21437/Interspeech.2018-1432", 5, "interspeech", 2018]], "Yuri Y. Khokhlov": [0, ["Speaker Adaptive Training and Mixup Regularization for Neural Network Acoustic Models in Automatic Speech Recognition", ["Natalia A. Tomashenko", "Yuri Y. Khokhlov", "Yannick Esteve"], "https://doi.org/10.21437/Interspeech.2018-2209", 5, "interspeech", 2018], ["An Investigation of Mixup Training Strategies for Acoustic Models in ASR", ["Ivan Medennikov", "Yuri Y. Khokhlov", "Aleksei Romanenko", "Dmitry Popov", "Natalia A. Tomashenko", "Ivan Sorokin", "Alexander Zatvornitskiy"], "https://doi.org/10.21437/Interspeech.2018-2191", 5, "interspeech", 2018]], "Jennifer Cole": [0, ["Information Structure, Affect and Prenuclear Prominence in American English", ["Eleanor Chodroff", "Jennifer Cole"], "https://doi.org/10.21437/Interspeech.2018-1529", 5, "interspeech", 2018]], "Yang Liu": [0, ["Liulishuo's System for the Spoken CALL Shared Task 2018", ["Huy Nguyen", "Lei Chen", "Ramon Prieto", "Chuan Wang", "Yang Liu"], "https://doi.org/10.21437/Interspeech.2018-1309", 5, "interspeech", 2018], ["Pitch Characteristics of L2 English Speech by Chinese Speakers: A Large-scale Study", ["Jiahong Yuan", "Qiusi Dong", "Fei Wu", "Huan Luan", "Xiaofei Yang", "Hui Lin", "Yang Liu"], "https://doi.org/10.21437/Interspeech.2018-1556", 5, "interspeech", 2018]], "Yoonho Boo": [0.9421125650405884, ["Hierarchical Recurrent Neural Networks for Acoustic Modeling", ["Jinhwan Park", "Iksoo Choi", "Yoonho Boo", "Wonyong Sung"], "https://doi.org/10.21437/Interspeech.2018-1797", 5, "interspeech", 2018]], "Guillermo A. Cecchi": [0, ["Detection of Amyotrophic Lateral Sclerosis (ALS) via Acoustic Analysis", ["Raquel Norel", "Mary Pietrowicz", "Carla Agurto", "Shay Rishoni", "Guillermo A. Cecchi"], "https://doi.org/10.21437/Interspeech.2018-2389", 5, "interspeech", 2018]], "Yingke Zhu": [0, ["Self-Attentive Speaker Embeddings for Text-Independent Speaker Verification", ["Yingke Zhu", "Tom Ko", "David Snyder", "Brian Mak", "Daniel Povey"], "https://doi.org/10.21437/Interspeech.2018-1158", 5, "interspeech", 2018]], "Florent Desnous": [0, ["S4D: Speaker Diarization Toolkit in Python", ["Pierre-Alexandre Broux", "Florent Desnous", "Anthony Larcher", "Simon Petitrenaud", "Jean Carrive", "Sylvain Meignier"], "https://doi.org/10.21437/Interspeech.2018-1232", 5, "interspeech", 2018]], "Henk van den Heuvel": [0, ["Acoustic and Textual Data Augmentation for Improved ASR of Code-Switching Speech", ["Emre Yilmaz", "Henk van den Heuvel", "David A. van Leeuwen"], "https://doi.org/10.21437/Interspeech.2018-52", 5, "interspeech", 2018]], "Martin Cooke": [0, ["Impact of Different Speech Types on Listening Effort", ["Olympia Simantiraki", "Martin Cooke", "Simon King"], "https://doi.org/10.21437/Interspeech.2018-1358", 5, "interspeech", 2018]], "Aku Rouhe": [0, ["Captaina: Integrated Pronunciation Practice and Data Collection Portal", ["Aku Rouhe", "Reima Karhila", "Aija Elg", "Minnaleena Toivola", "Peter Smit", "Anna-Riikka Smolander", "Mikko Kurimo"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3015.html", 2, "interspeech", 2018]], "Sanjay Kumar Gupta": [0, ["Classification of Disorders in Vocal Folds Using Electroglottographic Signal", ["Tanumay Mandal", "K. Sreenivasa Rao", "Sanjay Kumar Gupta"], "https://doi.org/10.21437/Interspeech.2018-1967", 5, "interspeech", 2018]], "Ankur Gandhe": [0, ["Contextual Language Model Adaptation for Conversational Agents", ["Anirudh Raju", "Behnam Hedayatnia", "Linda Liu", "Ankur Gandhe", "Chandra Khatri", "Angeliki Metallinou", "Anu Venkatesh", "Ariya Rastrow"], "https://doi.org/10.21437/Interspeech.2018-1122", 5, "interspeech", 2018]], "Aleksei Romanenko": [0, ["An Investigation of Mixup Training Strategies for Acoustic Models in ASR", ["Ivan Medennikov", "Yuri Y. Khokhlov", "Aleksei Romanenko", "Dmitry Popov", "Natalia A. Tomashenko", "Ivan Sorokin", "Alexander Zatvornitskiy"], "https://doi.org/10.21437/Interspeech.2018-2191", 5, "interspeech", 2018]], "Chitralekha Bhat": [0, ["Dysarthric Speech Recognition Using Time-delay Neural Network Based Denoising Autoencoder", ["Chitralekha Bhat", "Biswajit Das", "Bhavik Vachhani", "Sunil Kumar Kopparapu"], "https://doi.org/10.21437/Interspeech.2018-1754", 5, "interspeech", 2018], ["Data Augmentation Using Healthy Speech for Dysarthric Speech Recognition", ["Bhavik Vachhani", "Chitralekha Bhat", "Sunil Kumar Kopparapu"], "https://doi.org/10.21437/Interspeech.2018-1751", 5, "interspeech", 2018]], "Ke Li": [0, ["Recurrent Neural Network Language Model Adaptation for Conversational Speech Recognition", ["Ke Li", "Hainan Xu", "Yiming Wang", "Daniel Povey", "Sanjeev Khudanpur"], "https://doi.org/10.21437/Interspeech.2018-1413", 5, "interspeech", 2018], ["Semi-Orthogonal Low-Rank Matrix Factorization for Deep Neural Networks", ["Daniel Povey", "Gaofeng Cheng", "Yiming Wang", "Ke Li", "Hainan Xu", "Mahsa Yarmohammadi", "Sanjeev Khudanpur"], "https://doi.org/10.21437/Interspeech.2018-1417", 5, "interspeech", 2018]], "Rodrigo Galvez": [0, ["A French-Spanish Multimodal Speech Communication Corpus Incorporating Acoustic Data, Facial, Hands and Arms Gestures Information", ["Lucas D. Terissi", "Gonzalo D. Sad", "Mauricio Cerda", "Slim Ouni", "Rodrigo Galvez", "Juan Carlos Gomez", "Bernard Girau", "Nancy Hitschfeld-Kahler"], "https://doi.org/10.21437/Interspeech.2018-2212", 5, "interspeech", 2018]], "Li Liu": [0, ["Visual Recognition of Continuous Cued Speech Using a Tandem CNN-HMM Approach", ["Li Liu", "Thomas Hueber", "Gang Feng", "Denis Beautemps"], "https://doi.org/10.21437/Interspeech.2018-2434", 5, "interspeech", 2018]], "Soma Khan": [0, ["PannoMulloKathan: Voice Enabled Mobile App for Agricultural Commodity Price Dissemination in Bengali Language", ["Madhab Pal", "Rajib Roy", "Soma Khan", "Milton Samirakshma Bepari", "Joyanta Basu"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3027.html", 2, "interspeech", 2018]], "Ladislav Mosner": [0, ["Dereverberation and Beamforming in Robust Far-Field Speaker Recognition", ["Ladislav Mosner", "Oldrich Plchot", "Pavel Matejka", "Ondrej Novotny", "Jan Cernocky"], "https://doi.org/10.21437/Interspeech.2018-2306", 5, "interspeech", 2018], ["BUT System for DIHARD Speech Diarization Challenge 2018", ["Mireia Diez", "Federico Landini", "Lukas Burget", "Johan Rohdin", "Anna Silnova", "Katerina Zmolikova", "Ondrej Novotny", "Karel Vesely", "Ondrej Glembek", "Oldrich Plchot", "Ladislav Mosner", "Pavel Matejka"], "https://doi.org/10.21437/Interspeech.2018-1749", 5, "interspeech", 2018]], "Hong Zhang": [0, ["Analyzing Thai Tone Distribution through Functional Data Analysis", ["Hong Zhang"], "https://doi.org/10.21437/Interspeech.2018-2115", 5, "interspeech", 2018]], "Kaavya Sriskandaraja": [0, ["Deep Siamese Architecture Based Replay Detection for Secure Voice Biometric", ["Kaavya Sriskandaraja", "Vidhyasaharan Sethu", "Eliathamby Ambikairajah"], "https://doi.org/10.21437/Interspeech.2018-1819", 5, "interspeech", 2018]], "Angelika Honemann": [0, ["Cross-cultural (A)symmetries in Audio-visual Attitude Perception", ["Hansjorg Mixdorff", "Albert Rilliard", "Tan Lee", "Matthew K. H. Ma", "Angelika Honemann"], "https://doi.org/10.21437/Interspeech.2018-1373", 5, "interspeech", 2018]], "Robert Fuchs": [0, ["The Diphthongs of Formal Nigerian English: A Preliminary Acoustic Analysis", ["Natalia Dyrenko", "Robert Fuchs"], "https://doi.org/10.21437/Interspeech.2018-2373", 5, "interspeech", 2018]], "Patrick C. M. Wong": [0, ["Learning Two Tone Languages Enhances the Brainstem Encoding of Lexical Tones", ["Akshay Raj Maggu", "Wenqing Zong", "Vina Law", "Patrick C. M. Wong"], "https://doi.org/10.21437/Interspeech.2018-2130", 5, "interspeech", 2018], ["Experience-dependent Influence of Music and Language on Lexical Pitch Learning Is Not Additive", ["Akshay Raj Maggu", "Patrick C. M. Wong", "Hanjun Liu", "Francis C. K. Wong"], "https://doi.org/10.21437/Interspeech.2018-2104", 4, "interspeech", 2018]], "Noel Nguyen": [0, ["Analyzing Vocal Tract Movements During Speech Accommodation", ["Sankar Mukherjee", "Thierry Legou", "Leonardo Lancia", "Pauline Hilt", "Alice Tomassini", "Luciano Fadiga", "Alessandro DAusilio", "Leonardo Badino", "Noel Nguyen"], "https://doi.org/10.21437/Interspeech.2018-2084", 5, "interspeech", 2018]], "Robert V. Kenyon": [0, ["Effects of User Controlled Speech Rate on Intelligibility in Noisy Environments", ["John S. Novak III", "Robert V. Kenyon"], "https://doi.org/10.21437/Interspeech.2018-63", 5, "interspeech", 2018]], "Sibo Tong": [0, ["Fast Language Adaptation Using Phonological Information", ["Sibo Tong", "Philip N. Garner", "Herve Bourlard"], "https://doi.org/10.21437/Interspeech.2018-1990", 5, "interspeech", 2018]], "David Snyder": [0, ["Fast Variational Bayes for Heavy-tailed PLDA Applied to i-vectors and x-vectors", ["Anna Silnova", "Niko Brummer", "Daniel Garcia-Romero", "David Snyder", "Lukas Burget"], "https://doi.org/10.21437/Interspeech.2018-2128", 5, "interspeech", 2018], ["Diarization is Hard: Some Experiences and Lessons Learned for the JHU Team in the Inaugural DIHARD Challenge", ["Gregory Sell", "David Snyder", "Alan McCree", "Daniel Garcia-Romero", "Jesus Villalba", "Matthew Maciejewski", "Vimal Manohar", "Najim Dehak", "Daniel Povey", "Shinji Watanabe", "Sanjeev Khudanpur"], "https://doi.org/10.21437/Interspeech.2018-1893", 5, "interspeech", 2018], ["Self-Attentive Speaker Embeddings for Text-Independent Speaker Verification", ["Yingke Zhu", "Tom Ko", "David Snyder", "Brian Mak", "Daniel Povey"], "https://doi.org/10.21437/Interspeech.2018-1158", 5, "interspeech", 2018]], "Nitya Tiwari": [0, ["Implementation of Digital Hearing Aid as a Smartphone Application", ["Saketh Sharma", "Nitya Tiwari", "Prem C. Pandey"], "https://doi.org/10.21437/Interspeech.2018-2031", 5, "interspeech", 2018]], "Anil Prabhakar": [0, ["Early Vocabulary Development Through Picture-based Software Solutions", ["G. R. Kasthuri", "Prabha Ramanathan", "Hema A. Murthy", "Namita Jacob", "Anil Prabhakar"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3022.html", 2, "interspeech", 2018]], "Yanmin Qian": [0, ["Permutation Invariant Training of Generative Adversarial Network for Monaural Speech Separation", ["Lianwu Chen", "Meng Yu", "Yanmin Qian", "Dan Su", "Dong Yu"], "https://doi.org/10.21437/Interspeech.2018-1603", 5, "interspeech", 2018], ["Deep Extractor Network for Target Speaker Recovery from Single Channel Speech Mixtures", ["Jun Wang", "Jie Chen", "Dan Su", "Lianwu Chen", "Meng Yu", "Yanmin Qian", "Dong Yu"], "https://doi.org/10.21437/Interspeech.2018-1205", 5, "interspeech", 2018], ["Monaural Multi-Talker Speech Recognition with Attention Mechanism and Gated Convolutional Networks", ["Xuankai Chang", "Yanmin Qian", "Dong Yu"], "https://doi.org/10.21437/Interspeech.2018-1547", 5, "interspeech", 2018], ["Knowledge Distillation for Sequence Model", ["Mingkun Huang", "Yongbin You", "Zhehuai Chen", "Yanmin Qian", "Kai Yu"], "https://doi.org/10.21437/Interspeech.2018-1589", 5, "interspeech", 2018]], "Shakti P. Rath": [0, ["Leveraging Second-Order Log-Linear Model for Improved Deep Learning Based ASR Performance", ["Ankit Raj", "Shakti P. Rath", "Jithendra Vepa"], "https://doi.org/10.21437/Interspeech.2018-1156", 5, "interspeech", 2018]], "Kang Min Yoo": [0.004616012214682996, ["Slot Filling with Delexicalized Sentence Generation", ["Youhyun Shin", "Kang Min Yoo", "Sang-goo Lee"], "https://doi.org/10.21437/Interspeech.2018-1808", 5, "interspeech", 2018]], "Youssef Oualil": [0, ["Iterative Learning of Speech Recognition Models for Air Traffic Control", ["Ajay Srinivasamurthy", "Petr Motlicek", "Mittul Singh", "Youssef Oualil", "Matthias Kleinert", "Heiko Ehr", "Hartmut Helmke"], "https://doi.org/10.21437/Interspeech.2018-1447", 5, "interspeech", 2018]], "Yuan Jia": [0, ["Stress Distribution of Given Information in Chinese Reading Texts", ["Yuan Jia", "Xiaoxiao Ma"], "https://doi.org/10.21437/Interspeech.2018-1602", 5, "interspeech", 2018]], "Christina Hunger-Schoppe": [0, ["How Did You like 2017? Detection of Language Markers of Depression and Narcissism in Personal Narratives", ["Eva-Maria Rathner", "Julia Djamali", "Yannik Terhorst", "Bjorn W. Schuller", "Nicholas Cummins", "Gudrun Salamon", "Christina Hunger-Schoppe", "Harald Baumeister"], "https://doi.org/10.21437/Interspeech.2018-2040", 5, "interspeech", 2018]], "Tsubasa Ochiai": [0, ["ESPnet: End-to-End Speech Processing Toolkit", ["Shinji Watanabe", "Takaaki Hori", "Shigeki Karita", "Tomoki Hayashi", "Jiro Nishitoba", "Yuya Unno", "Nelson Enrique Yalta Soplin", "Jahn Heymann", "Matthew Wiesner", "Nanxin Chen", "Adithya Renduchintala", "Tsubasa Ochiai"], "https://doi.org/10.21437/Interspeech.2018-1456", 5, "interspeech", 2018]], "Corinne Fredouille": [0, ["Automatic Evaluation of Speech Intelligibility Based on I-vectors in the Context of Head and Neck Cancers", ["Imed Laaridh", "Corinne Fredouille", "Alain Ghio", "Muriel Lalain", "Virginie Woisard"], "https://doi.org/10.21437/Interspeech.2018-1266", 5, "interspeech", 2018]], "Zhaocheng Huang": [0, ["Depression Detection from Short Utterances via Diverse Smartphones in Natural Environmental Conditions", ["Zhaocheng Huang", "Julien Epps", "Dale Joachim", "Michael Chen"], "https://doi.org/10.21437/Interspeech.2018-1743", 5, "interspeech", 2018]], "Gayadhar Pradhan": [0, ["Analysis of Variational Mode Functions for Robust Detection of Vowels", ["Surbhi Sakshi", "Avinash Kumar", "Gayadhar Pradhan"], "https://doi.org/10.21437/Interspeech.2018-1947", 5, "interspeech", 2018], ["Enhancement of Noisy Speech Signal by Non-Local Means Estimation of Variational Mode Functions", ["Nagapuri Srinivas", "Gayadhar Pradhan", "Syed Shahnawazuddin"], "https://doi.org/10.21437/Interspeech.2018-1928", 5, "interspeech", 2018], ["Non-Uniform Spectral Smoothing for Robust Children's Speech Recognition", ["Ishwar Chandra Yadav", "Avinash Kumar", "Syed Shahnawazuddin", "Gayadhar Pradhan"], "https://doi.org/10.21437/Interspeech.2018-1828", 5, "interspeech", 2018]], "Somnath Roy": [0, ["A Hybrid Approach to Grapheme to Phoneme Conversion in Assamese", ["Somnath Roy", "Shakuntala Mahanta"], "https://doi.org/10.21437/Interspeech.2018-1694", 5, "interspeech", 2018]], "Di He": [0, ["Improved ASR for Under-resourced Languages through Multi-task Learning with Acoustic Landmarks", ["Di He", "Boon Pang Lim", "Xuesong Yang", "Mark Hasegawa-Johnson", "Deming Chen"], "https://doi.org/10.21437/Interspeech.2018-1124", 5, "interspeech", 2018]], "Tsuneo Kato": [0, ["Automatic Assessment of L2 English Word Prosody Using Weighted Distances of F0 and Intensity Contours", ["Quy-Thao Truong", "Tsuneo Kato", "Seiichi Yamamoto"], "https://doi.org/10.21437/Interspeech.2018-1386", 5, "interspeech", 2018]], "Harald Baumeister": [0, ["The INTERSPEECH 2018 Computational Paralinguistics Challenge: Atypical & Self-Assessed Affect, Crying & Heart Beats", ["Bjorn W. Schuller", "Stefan Steidl", "Anton Batliner", "Peter B. Marschik", "Harald Baumeister", "Fengquan Dong", "Simone Hantke", "Florian B. Pokorny", "Eva-Maria Rathner", "Katrin D. Bartl-Pokorny", "Christa Einspieler", "Dajie Zhang", "Alice Baird", "Shahin Amiriparian", "Kun Qian", "Zhao Ren", "Maximilian Schmitt", "Panagiotis Tzirakis", "Stefanos Zafeiriou"], "https://doi.org/10.21437/Interspeech.2018-51", 5, "interspeech", 2018], ["State of Mind: Classification through Self-reported Affect and Word Use in Speech", ["Eva-Maria Rathner", "Yannik Terhorst", "Nicholas Cummins", "Bjorn W. Schuller", "Harald Baumeister"], "https://doi.org/10.21437/Interspeech.2018-2043", 5, "interspeech", 2018], ["How Did You like 2017? Detection of Language Markers of Depression and Narcissism in Personal Narratives", ["Eva-Maria Rathner", "Julia Djamali", "Yannik Terhorst", "Bjorn W. Schuller", "Nicholas Cummins", "Gudrun Salamon", "Christina Hunger-Schoppe", "Harald Baumeister"], "https://doi.org/10.21437/Interspeech.2018-2040", 5, "interspeech", 2018]], "Liuhui Deng": [0, ["Investigation on Estimation of Sentence Probability by Combining Forward, Backward and Bi-directional LSTM-RNNs", ["Kazuki Irie", "Zhihong Lei", "Liuhui Deng", "Ralf Schluter", "Hermann Ney"], "https://doi.org/10.21437/Interspeech.2018-1766", 4, "interspeech", 2018]], "Hirokazu Masataki": [0, ["Neural Error Corrective Language Models for Automatic Speech Recognition", ["Tomohiro Tanaka", "Ryo Masumura", "Hirokazu Masataki", "Yushi Aono"], "https://doi.org/10.21437/Interspeech.2018-1430", 5, "interspeech", 2018], ["Role Play Dialogue Aware Language Models Based on Conditional Hierarchical Recurrent Encoder-Decoder", ["Ryo Masumura", "Tomohiro Tanaka", "Atsushi Ando", "Hirokazu Masataki", "Yushi Aono"], "https://doi.org/10.21437/Interspeech.2018-2185", 5, "interspeech", 2018]], "Spyros Matsoukas": [0, ["Device-directed Utterance Detection", ["Sri Harish Reddy Mallidi", "Roland Maas", "Kyle Goehner", "Ariya Rastrow", "Spyros Matsoukas", "Bjorn Hoffmeister"], "https://doi.org/10.21437/Interspeech.2018-1531", 4, "interspeech", 2018]], "Jinuk Park": [0.9862816631793976, ["Korean Singing Voice Synthesis Based on an LSTM Recurrent Neural Network", ["Juntae Kim", "Heejin Choi", "Jinuk Park", "Minsoo Hahn", "Sang-Jin Kim", "Jong-Jin Kim"], "https://doi.org/10.21437/Interspeech.2018-1575", 5, "interspeech", 2018]], "Sebastian Braun": [0, ["Single-Channel Dereverberation Using Direct MMSE Optimization and Bidirectional LSTM Networks", ["Wolfgang Mack", "Soumitro Chakrabarty", "Fabian-Robert Stoter", "Sebastian Braun", "Bernd Edler", "Emanuel A. P. Habets"], "https://doi.org/10.21437/Interspeech.2018-1296", 5, "interspeech", 2018]], "Katrin D. Bartl-Pokorny": [0, ["The INTERSPEECH 2018 Computational Paralinguistics Challenge: Atypical & Self-Assessed Affect, Crying & Heart Beats", ["Bjorn W. Schuller", "Stefan Steidl", "Anton Batliner", "Peter B. Marschik", "Harald Baumeister", "Fengquan Dong", "Simone Hantke", "Florian B. Pokorny", "Eva-Maria Rathner", "Katrin D. Bartl-Pokorny", "Christa Einspieler", "Dajie Zhang", "Alice Baird", "Shahin Amiriparian", "Kun Qian", "Zhao Ren", "Maximilian Schmitt", "Panagiotis Tzirakis", "Stefanos Zafeiriou"], "https://doi.org/10.21437/Interspeech.2018-51", 5, "interspeech", 2018]], "Peter Sibbern Frederiksen": [0, ["Effectiveness of Single-Channel BLSTM Enhancement for Language Identification", ["Peter Sibbern Frederiksen", "Jesus Villalba", "Shinji Watanabe", "Zheng-Hua Tan", "Najim Dehak"], "https://doi.org/10.21437/Interspeech.2018-2458", 5, "interspeech", 2018]], "Sri Harish Reddy Mallidi": [0, ["Device-directed Utterance Detection", ["Sri Harish Reddy Mallidi", "Roland Maas", "Kyle Goehner", "Ariya Rastrow", "Spyros Matsoukas", "Bjorn Hoffmeister"], "https://doi.org/10.21437/Interspeech.2018-1531", 4, "interspeech", 2018]], "Tara N. Sainath": [0, ["Compression of End-to-End Models", ["Ruoming Pang", "Tara N. Sainath", "Rohit Prabhavalkar", "Suyog Gupta", "Yonghui Wu", "Shuyuan Zhang", "Chung-Cheng Chiu"], "https://doi.org/10.21437/Interspeech.2018-1025", 5, "interspeech", 2018], ["Domain Adaptation Using Factorized Hidden Layer for Robust Automatic Speech Recognition", ["Khe Chai Sim", "Arun Narayanan", "Ananya Misra", "Anshuman Tripathi", "Golan Pundak", "Tara N. Sainath", "Parisa Haghani", "Bo Li", "Michiel Bacchiani"], "https://doi.org/10.21437/Interspeech.2018-2246", 5, "interspeech", 2018], ["Contextual Speech Recognition in End-to-end Neural Network Systems Using Beam Search", ["Ian Williams", "Anjuli Kannan", "Petar S. Aleksic", "David Rybach", "Tara N. Sainath"], "https://doi.org/10.21437/Interspeech.2018-2416", 5, "interspeech", 2018]], "Jom Kuriakose": [0, ["Information Bottleneck Based Percussion Instrument Diarization System for Taniavartanam Segments of Carnatic Music Concerts", ["Nauman Dawalatabad", "Jom Kuriakose", "Chellu Chandra Sekhar", "Hema A. Murthy"], "https://doi.org/10.21437/Interspeech.2018-1203", 5, "interspeech", 2018]], "Ron Hoory": [0, ["The IBM Virtual Voice Creator", ["Alexander Sorin", "Slava Shechtman", "Zvi Kons", "Ron Hoory", "Shay Ben-David", "Joe Pavitt", "Shai Rozenberg", "Carmel Rabinovitz", "Tal Drory"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3011.html", 2, "interspeech", 2018], ["Word Emphasis Prediction for Expressive Text to Speech", ["Yosi Mass", "Slava Shechtman", "Moran Mordechay", "Ron Hoory", "Oren Sar Shalom", "Guy Lev", "David Konopnicki"], "https://doi.org/10.21437/Interspeech.2018-1159", 5, "interspeech", 2018]], "Aziz Qaroush": [0, ["An Optimization Based Approach for Solving Spoken CALL Shared Task", ["Mohammad Ateeq", "Abualsoud Hanani", "Aziz Qaroush"], "https://doi.org/10.21437/Interspeech.2018-1328", 5, "interspeech", 2018]], "Priya Pallavi": [0, ["Phase-locked Loop (PLL) Based Phase Estimation in Single Channel Speech Enhancement", ["Priya Pallavi", "Ch. V. Rama Rao"], "https://doi.org/10.21437/Interspeech.2018-1950", 4, "interspeech", 2018]], "Maxime Le Coz": [0, ["Automatically Measuring L2 Speech Fluency without the Need of ASR: A Proof-of-concept Study with Japanese Learners of French", ["Lionel Fontan", "Maxime Le Coz", "Sylvain Detey"], "https://doi.org/10.21437/Interspeech.2018-1336", 5, "interspeech", 2018]], "Hiroki Murakami": [0, ["Naturalness Improvement Algorithm for Reconstructed Glossectomy Patient's Speech Using Spectral Differential Modification in Voice Conversion", ["Hiroki Murakami", "Sunao Hara", "Masanobu Abe", "Masaaki Sato", "Shogo Minagi"], "https://doi.org/10.21437/Interspeech.2018-1239", 5, "interspeech", 2018]], "Kinnera Saranu": [0, ["CACTAS - Collaborative Audio Categorization and Transcription for ASR Systems", ["Mithul Mathivanan", "Kinnera Saranu", "Abhishek Pandey", "Jithendra Vepa"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3029.html", 2, "interspeech", 2018]], "Brian Mak": [0, ["Fast Derivation of Cross-lingual Document Vectors from Self-attentive Neural Machine Translation Model", ["Wei Li", "Brian Mak"], "https://doi.org/10.21437/Interspeech.2018-1459", 5, "interspeech", 2018], ["Self-Attentive Speaker Embeddings for Text-Independent Speaker Verification", ["Yingke Zhu", "Tom Ko", "David Snyder", "Brian Mak", "Daniel Povey"], "https://doi.org/10.21437/Interspeech.2018-1158", 5, "interspeech", 2018]], "Eric Nyberg": [0, ["Investigating Utterance Level Representations for Detecting Intent from Acoustics", ["Sai Krishna Rallabandi", "Bhavya Karki", "Carla Viegas", "Eric Nyberg", "Alan W. Black"], "https://doi.org/10.21437/Interspeech.2018-2149", 5, "interspeech", 2018]], "Matthias Kleinert": [0, ["Iterative Learning of Speech Recognition Models for Air Traffic Control", ["Ajay Srinivasamurthy", "Petr Motlicek", "Mittul Singh", "Youssef Oualil", "Matthias Kleinert", "Heiko Ehr", "Hartmut Helmke"], "https://doi.org/10.21437/Interspeech.2018-1447", 5, "interspeech", 2018]], "Jaime Lorenzo-Trueba": [0, ["Expressive Speech Synthesis Using Sentiment Embeddings", ["Igor Jauk", "Jaime Lorenzo-Trueba", "Junichi Yamagishi", "Antonio Bonafonte"], "https://doi.org/10.21437/Interspeech.2018-2467", 5, "interspeech", 2018]], "Heysem Kaya": [0, ["LSTM Based Cross-corpus and Cross-task Acoustic Emotion Recognition", ["Heysem Kaya", "Dmitrii Fedotov", "Ali Yesilkanat", "Oxana Verkholyak", "Yang Zhang", "Alexey Karpov"], "https://doi.org/10.21437/Interspeech.2018-2298", 5, "interspeech", 2018]], "Etienne Parizet": [0, ["Who Are You Listening to? Towards a Dynamic Measure of Auditory Attention to Speech-on-speech", ["Moira-Phoebe Huet", "Christophe Micheyl", "Etienne Gaudrain", "Etienne Parizet"], "https://doi.org/10.21437/Interspeech.2018-2053", 4, "interspeech", 2018]], "Ivan Sorokin": [0, ["An Investigation of Mixup Training Strategies for Acoustic Models in ASR", ["Ivan Medennikov", "Yuri Y. Khokhlov", "Aleksei Romanenko", "Dmitry Popov", "Natalia A. Tomashenko", "Ivan Sorokin", "Alexander Zatvornitskiy"], "https://doi.org/10.21437/Interspeech.2018-2191", 5, "interspeech", 2018]], "Valter Akira Miasato Filho": [0, ["Joint Discriminative Embedding Learning, Speech Activity and Overlap Detection for the DIHARD Speaker Diarization Challenge", ["Valter Akira Miasato Filho", "Diego Augusto Silva", "Luis Gustavo Depra Cuozzo"], "https://doi.org/10.21437/Interspeech.2018-2304", 5, "interspeech", 2018]], "Mari Ostendorf": [0, ["Training Augmentation with Adversarial Examples for Robust Speech Recognition", ["Sining Sun", "Ching-Feng Yeh", "Mari Ostendorf", "Mei-Yuh Hwang", "Lei Xie"], "https://doi.org/10.21437/Interspeech.2018-1247", 5, "interspeech", 2018]], "T. V. Ananthapadmanabha": [0, ["Estimation of the Vocal Tract Length of Vowel Sounds Based on the Frequency of the Significant Spectral Valley", ["T. V. Ananthapadmanabha", "Ramakrishnan A. G."], "https://doi.org/10.21437/Interspeech.2018-1105", 5, "interspeech", 2018]], "Cheng-I Lai": [0, ["Investigation on Bandwidth Extension for Speaker Recognition", ["Phani Sankar Nidadavolu", "Cheng-I Lai", "Jesus Villalba", "Najim Dehak"], "https://doi.org/10.21437/Interspeech.2018-2394", 5, "interspeech", 2018]], "Jacques C. Koreman": [0, ["Category Similarity in Multilingual Pronunciation Training", ["Jacques C. Koreman"], "https://doi.org/10.21437/Interspeech.2018-1938", 5, "interspeech", 2018]], "Jungsuk Kim": [0.9982424378395081, ["Densely Connected Networks for Conversational Speech Recognition", ["Kyu J. Han", "Akshay Chandrashekaran", "Jungsuk Kim", "Ian Lane"], "https://doi.org/10.21437/Interspeech.2018-1486", 5, "interspeech", 2018]], "Mahesh M": [0, ["Resyllabification in Indian Languages and Its Implications in Text-to-speech Systems", ["Mahesh M", "Jeena J. Prakash", "Hema A. Murthy"], "https://doi.org/10.21437/Interspeech.2018-1176", 5, "interspeech", 2018]], "Vijay Ravi": [0, ["Effectiveness of Voice Quality Features in Detecting Depression", ["Amber Afshan", "Jinxi Guo", "Soo Jin Park", "Vijay Ravi", "Jonathan Flint", "Abeer Alwan"], "https://doi.org/10.21437/Interspeech.2018-1399", 5, "interspeech", 2018]], "Orgad Keller": [0, ["Fully Automatic Speaker Separation System, with Automatic Enrolling of Recurrent Speakers", ["Raphael Cohen", "Orgad Keller", "Jason Levy", "Russell Levy", "Micha Breakstone", "Amit Ashkenazi"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3034.html", 2, "interspeech", 2018]], "Dheeraj Sai D. V. L. N": [0, ["Speech Source Separation Using ICA in Constant Q Transform Domain", ["Dheeraj Sai D. V. L. N", "Kishor K. S", "Sri Rama Murty Kodukula"], "https://doi.org/10.21437/Interspeech.2018-1732", 5, "interspeech", 2018]], "Jun Wang": [0.07243982143700123, ["Deep Extractor Network for Target Speaker Recovery from Single Channel Speech Mixtures", ["Jun Wang", "Jie Chen", "Dan Su", "Lianwu Chen", "Meng Yu", "Yanmin Qian", "Dong Yu"], "https://doi.org/10.21437/Interspeech.2018-1205", 5, "interspeech", 2018], ["Improving Attention Based Sequence-to-Sequence Models for End-to-End English Conversational Speech Recognition", ["Chao Weng", "Jia Cui", "Guangsen Wang", "Jun Wang", "Chengzhu Yu", "Dan Su", "Dong Yu"], "https://doi.org/10.21437/Interspeech.2018-1030", 5, "interspeech", 2018], ["Automatic Speech Recognition with Articulatory Information and a Unified Dictionary for Hindi, Marathi, Bengali and Oriya", ["Debadatta Dash", "Myung Jong Kim", "Kristin Teplansky", "Jun Wang"], "https://doi.org/10.21437/Interspeech.2018-2122", 5, "interspeech", 2018], ["Automatic Early Detection of Amyotrophic Lateral Sclerosis from Intelligible Speech Using Convolutional Neural Networks", ["Kwanghoon An", "Myung Jong Kim", "Kristin Teplansky", "Jordan R. Green", "Thomas Campbell", "Yana Yunusova", "Daragh Heitzman", "Jun Wang"], "https://doi.org/10.21437/Interspeech.2018-2496", 5, "interspeech", 2018], ["Dysarthric Speech Recognition Using Convolutional LSTM Neural Network", ["Myung Jong Kim", "Beiming Cao", "Kwanghoon An", "Jun Wang"], "https://doi.org/10.21437/Interspeech.2018-2250", 5, "interspeech", 2018], ["Articulation-to-Speech Synthesis Using Articulatory Flesh Point Sensors' Orientation Information", ["Beiming Cao", "Myung Jong Kim", "Jun R. Wang", "Jan P. H. van Santen", "Ted Mau", "Jun Wang"], "https://doi.org/10.21437/Interspeech.2018-2484", 5, "interspeech", 2018]], "Madhab Pal": [0, ["PannoMulloKathan: Voice Enabled Mobile App for Agricultural Commodity Price Dissemination in Bengali Language", ["Madhab Pal", "Rajib Roy", "Soma Khan", "Milton Samirakshma Bepari", "Joyanta Basu"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3027.html", 2, "interspeech", 2018]], "Lesly Miculicich Werlen": [0, ["CNN Based Query by Example Spoken Term Detection", ["Dhananjay Ram", "Lesly Miculicich Werlen", "Herve Bourlard"], "https://doi.org/10.21437/Interspeech.2018-1722", 5, "interspeech", 2018]], "Abinay Reddy N": [0, ["Reconstructing Neutral Speech from Tracheoesophageal Speech", ["Abinay Reddy N", "M. V. Achuth Rao", "G. Nisha Meenakshi", "Prasanta Kumar Ghosh"], "https://doi.org/10.21437/Interspeech.2018-1907", 5, "interspeech", 2018]], "Markus Muller": [0, ["Neural Language Codes for Multilingual Acoustic Models", ["Markus Muller", "Sebastian Stuker", "Alex Waibel"], "https://doi.org/10.21437/Interspeech.2018-1241", 5, "interspeech", 2018]], "Anna Zhu": [0, ["Multi-frame Quantization of LSF Parameters Using a Deep Autoencoder and Pyramid Vector Quantizer", ["Yaxing Li", "Eshete Derb Emiru", "Shengwu Xiong", "Anna Zhu", "Pengfei Duan", "Yichang Li"], "https://doi.org/10.21437/Interspeech.2018-2577", 5, "interspeech", 2018], ["Multi-frame Coding of LSF Parameters Using Block-Constrained Trellis Coded Vector Quantization", ["Yaxing Li", "Shan Xu", "Shengwu Xiong", "Anna Zhu", "Pengfei Duan", "Yueming Ding"], "https://doi.org/10.21437/Interspeech.2018-2578", 5, "interspeech", 2018]], "Bahman Mirheidari": [0, ["Detecting Signs of Dementia Using Word Vector Representations", ["Bahman Mirheidari", "Daniel Blackburn", "Traci Walker", "Annalena Venneri", "Markus Reuber", "Heidi Christensen"], "https://doi.org/10.21437/Interspeech.2018-1764", 5, "interspeech", 2018]], "Kumaran S": [0, ["Speaker Adaptive Audio-Visual Fusion for the Open-Vocabulary Section of AVICAR", ["Leda Sari", "Mark Hasegawa-Johnson", "Kumaran S", "Georg Stemmer", "Krishnakumar N. Nair"], "https://doi.org/10.21437/Interspeech.2018-2359", 5, "interspeech", 2018]], "Avinash Kumar": [0, ["Analysis of Variational Mode Functions for Robust Detection of Vowels", ["Surbhi Sakshi", "Avinash Kumar", "Gayadhar Pradhan"], "https://doi.org/10.21437/Interspeech.2018-1947", 5, "interspeech", 2018], ["Non-Uniform Spectral Smoothing for Robust Children's Speech Recognition", ["Ishwar Chandra Yadav", "Avinash Kumar", "Syed Shahnawazuddin", "Gayadhar Pradhan"], "https://doi.org/10.21437/Interspeech.2018-1828", 5, "interspeech", 2018]], "Christer Gobl": [0, ["Voice Source Contribution to Prominence Perception: Rd Implementation", ["Andy Murphy", "Irena Yanushevskaya", "Ailbhe Ni Chasaide", "Christer Gobl"], "https://doi.org/10.21437/Interspeech.2018-2352", 5, "interspeech", 2018], ["On the Relationship between Glottal Pulse Shape and Its Spectrum: Correlations of Open Quotient, Pulse Skew and Peak Flow with Source Harmonic Amplitudes", ["Christer Gobl", "Andy Murphy", "Irena Yanushevskaya", "Ailbhe Ni Chasaide"], "https://doi.org/10.21437/Interspeech.2018-2532", 5, "interspeech", 2018]], "Sebastien Marcel": [0, ["On Learning Vocal Tract System Related Speaker Discriminative Information from Raw Signal Using CNNs", ["Hannah Muckenhirn", "Mathew Magimai-Doss", "Sebastien Marcel"], "https://doi.org/10.21437/Interspeech.2018-1696", 5, "interspeech", 2018]], "Iroro Orife": [0, ["Attentive Sequence-to-Sequence Learning for Diacritic Restoration of Yor\u00f9B\u00e1 Language Text", ["Iroro Orife"], "https://doi.org/10.21437/Interspeech.2018-42", 5, "interspeech", 2018]], "Viet Anh Trinh": [0, ["Concatenative Resynthesis with Improved Training Signals for Speech Enhancement", ["Ali Raza Syed", "Viet Anh Trinh", "Michael I. Mandel"], "https://doi.org/10.21437/Interspeech.2018-2439", 5, "interspeech", 2018], ["Bubble Cooperative Networks for Identifying Important Speech Cues", ["Viet Anh Trinh", "Brian McFee", "Michael I. Mandel"], "https://doi.org/10.21437/Interspeech.2018-2377", 5, "interspeech", 2018]], "Zhi Chen": [0, ["Gated Convolutional Neural Network for Sentence Matching", ["Peixin Chen", "Wu Guo", "Zhi Chen", "Jian Sun", "Lanhua You"], "https://doi.org/10.21437/Interspeech.2018-70", 5, "interspeech", 2018]], "Masayuki Suzuki": [0, ["Inference-Invariant Transformation of Batch Normalization for Domain Adaptation of Acoustic Models", ["Masayuki Suzuki", "Tohru Nagano", "Gakuto Kurata", "Samuel Thomas"], "https://doi.org/10.21437/Interspeech.2018-1563", 5, "interspeech", 2018]], "Priyankoo Sarmah": [0, ["Analysis of Breathiness in Contextual Vowel of Voiceless Nasals in Mizo", ["Pamir Gogoi", "Sishir Kalita", "Parismita Gogoi", "Ratree Wayland", "Priyankoo Sarmah", "S. R. Mahadeva Prasanna"], "https://doi.org/10.21437/Interspeech.2018-1899", 5, "interspeech", 2018], ["Robust Mizo Continuous Speech Recognition", ["Abhishek Dey", "Biswajit Dev Sarma", "Wendy Lalhminghlui", "Lalnunsiami Ngente", "Parismita Gogoi", "Priyankoo Sarmah", "S. R. Mahadeva Prasanna", "Rohit Sinha", "S. R. Nirmala"], "https://doi.org/10.21437/Interspeech.2018-2125", 5, "interspeech", 2018], ["Glotto Vibrato Graph: A Device and Method for Recording, Analysis and Visualization of Glottal Activity", ["Kishalay Chakraborty", "Senjam Shantirani Devi", "Sanjeevan Devnath", "S. R. Mahadeva Prasanna", "Priyankoo Sarmah"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3046.html", 2, "interspeech", 2018], ["AGROASSAM: A Web Based Assamese Speech Recognition Application for Retrieving Agricultural Commodity Price and Weather Information", ["Abhishek Dey", "Abhash Deka", "Siddika Imani", "Barsha Deka", "Rohit Sinha", "S. R. Mahadeva Prasanna", "Priyankoo Sarmah", "K. Samudravijaya", "S. R. Nirmala"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3048.html", 2, "interspeech", 2018]], "Ashwin Vijayakumar": [0, ["Prediction of Aesthetic Elements in Karnatic Music: A Machine Learning Approach", ["Ragesh Rajan M", "Ashwin Vijayakumar", "Deepu Vijayasenan"], "https://doi.org/10.21437/Interspeech.2018-991", 5, "interspeech", 2018]], "Donna Erickson": [0, ["Cultural Differences in Pattern Matching: Multisensory Recognition of Socio-affective Prosody", ["Takaaki Shochi", "Jean-Luc Rouas", "Marine Guerry", "Donna Erickson"], "https://doi.org/10.21437/Interspeech.2018-1795", 5, "interspeech", 2018]], "Szu-Lin Wu": [2.360034557113977e-06, ["Spoken SQuAD: A Study of Mitigating the Impact of Speech Recognition Errors on Listening Comprehension", ["Chia-Hsuan Lee", "Szu-Lin Wu", "Chi-Liang Liu", "Hung-yi Lee"], "https://doi.org/10.21437/Interspeech.2018-1714", 5, "interspeech", 2018]], "Yeon-Jun Kim": [0.9998818039894104, ["Multilingual Deep Neural Network Training Using Cyclical Learning Rate", ["Andreas Soeborg Kirkedal", "Yeon-Jun Kim"], "https://doi.org/10.21437/Interspeech.2018-1891", 5, "interspeech", 2018]], "Yu Wang": [0, ["Speaker Adaptation and Adaptive Training for Jointly Optimised Tandem Systems", ["Yu Wang", "Chao Zhang", "Mark J. F. Gales", "Philip C. Woodland"], "https://doi.org/10.21437/Interspeech.2018-2432", 5, "interspeech", 2018], ["Impact of ASR Performance on Free Speaking Language Assessment", ["Kate Knill", "Mark J. F. Gales", "Konstantinos Kyriakopoulos", "Andrey Malinin", "Anton Ragni", "Yu Wang", "Andrew Caines"], "https://doi.org/10.21437/Interspeech.2018-1312", 5, "interspeech", 2018], ["A Deep Reinforcement Learning Based Multimodal Coaching Model (DCM) for Slot Filling in Spoken Language Understanding(SLU)", ["Yu Wang", "Abhishek Patel", "Yilin Shen", "Hongxia Jin"], "https://doi.org/10.21437/Interspeech.2018-1379", 5, "interspeech", 2018], ["User Information Augmented Semantic Frame Parsing Using Progressive Neural Networks", ["Yilin Shen", "Xiangyu Zeng", "Yu Wang", "Hongxia Jin"], "https://doi.org/10.21437/Interspeech.2018-1149", 5, "interspeech", 2018]], "Yannis Stylianou": [0, ["A Case Study on the Importance of Belief State Representation for Dialogue Policy Management", ["Margarita Kotti", "Vassilios Diakoloukas", "Alexandros Papangelis", "Michail Lagoudakis", "Yannis Stylianou"], "https://doi.org/10.21437/Interspeech.2018-1293", 5, "interspeech", 2018], ["Weighting Time-Frequency Representation of Speech Using Auditory Saliency for Automatic Speech Recognition", ["Cong-Thanh Do", "Yannis Stylianou"], "https://doi.org/10.21437/Interspeech.2018-1721", 5, "interspeech", 2018], ["Speech Intelligibility Enhancement Based on a Non-causal Wavenet-like Model", ["P. V. Muhammed Shifas", "Vassilis Tsiaras", "Yannis Stylianou"], "https://doi.org/10.21437/Interspeech.2018-2119", 5, "interspeech", 2018]], "Terje B. Holmlund": [0, ["Modeling Self-Reported and Observed Affect from Speech", ["Jian Cheng", "Jared Bernstein", "Elizabeth Rosenfeld", "Peter W. Foltz", "Alex S. Cohen", "Terje B. Holmlund", "Brita Elvevag"], "https://doi.org/10.21437/Interspeech.2018-2222", 5, "interspeech", 2018]], "Debadatta Dash": [0, ["Automatic Speech Recognition with Articulatory Information and a Unified Dictionary for Hindi, Marathi, Bengali and Oriya", ["Debadatta Dash", "Myung Jong Kim", "Kristin Teplansky", "Jun Wang"], "https://doi.org/10.21437/Interspeech.2018-2122", 5, "interspeech", 2018]], "Jian Tang": [0, ["Acoustic Modeling with Densely Connected Residual Network for Multichannel Speech Recognition", ["Jian Tang", "Yan Song", "Lirong Dai", "Ian Vince McLoughlin"], "https://doi.org/10.21437/Interspeech.2018-1089", 5, "interspeech", 2018]], "Rupal Patel": [0, ["Data Requirements, Selection and Augmentation for DNN-based Speech Synthesis from Crowdsourced Data", ["Markus Toman", "Geoffrey S. Meltzner", "Rupal Patel"], "https://doi.org/10.21437/Interspeech.2018-1316", 5, "interspeech", 2018]], "Pengfei Duan": [0, ["Multi-frame Quantization of LSF Parameters Using a Deep Autoencoder and Pyramid Vector Quantizer", ["Yaxing Li", "Eshete Derb Emiru", "Shengwu Xiong", "Anna Zhu", "Pengfei Duan", "Yichang Li"], "https://doi.org/10.21437/Interspeech.2018-2577", 5, "interspeech", 2018], ["Multi-frame Coding of LSF Parameters Using Block-Constrained Trellis Coded Vector Quantization", ["Yaxing Li", "Shan Xu", "Shengwu Xiong", "Anna Zhu", "Pengfei Duan", "Yueming Ding"], "https://doi.org/10.21437/Interspeech.2018-2578", 5, "interspeech", 2018]], "Anil Ramakrishna": [0, ["Computational Modeling of Conversational Humor in Psychotherapy", ["Anil Ramakrishna", "Timothy Greer", "David C. Atkins", "Shrikanth Narayanan"], "https://doi.org/10.21437/Interspeech.2018-1583", 5, "interspeech", 2018]], "Andrea Bandini": [0, ["Automatic Detection of Orofacial Impairment in Stroke", ["Andrea Bandini", "Jordan R. Green", "Brian Richburg", "Yana Yunusova"], "https://doi.org/10.21437/Interspeech.2018-2475", 5, "interspeech", 2018]], "Xiaotong Zhang": [0, ["Imbalance Learning-based Framework for Fear Recognition in the MediaEval Emotional Impact of Movies Task", ["Xiaotong Zhang", "Xingliang Cheng", "Mingxing Xu", "Thomas Fang Zheng"], "https://doi.org/10.21437/Interspeech.2018-1744", 5, "interspeech", 2018]], "Tejendra Kushwah": [0, ["Extracting Speaker's Gender, Accent, Age and Emotional State from Speech", ["Nagendra Kumar Goel", "Mousmita Sarma", "Tejendra Kushwah", "Dharmesh Agarwal", "Zikra Iqbal", "Surbhi Chauhan"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3036.html", 2, "interspeech", 2018]], "Tanmay Parekh": [0, ["Dual Language Models for Code Switched Speech Recognition", ["Saurabh Garg", "Tanmay Parekh", "Preethi Jyothi"], "https://doi.org/10.21437/Interspeech.2018-1343", 5, "interspeech", 2018]], "K. E. Manjunath": [0, ["Indian Languages ASR: A Multilingual Phone Recognition Framework with IPA Based Common Phone-set, Predicted Articulatory Features and Feature fusion", ["K. E. Manjunath", "K. Sreenivasa Rao", "Dinesh Babu Jayagopi", "V. Ramasubramanian"], "https://doi.org/10.21437/Interspeech.2018-2529", 5, "interspeech", 2018]], "Yusuke Fujita": [0, ["Lattice-free State-level Minimum Bayes Risk Training of Acoustic Models", ["Naoyuki Kanda", "Yusuke Fujita", "Kenji Nagamatsu"], "https://doi.org/10.21437/Interspeech.2018-79", 5, "interspeech", 2018]], "Joon Son Chung": [0.7989451438188553, ["VoxCeleb2: Deep Speaker Recognition", ["Joon Son Chung", "Arsha Nagrani", "Andrew Zisserman"], "https://doi.org/10.21437/Interspeech.2018-1929", 5, "interspeech", 2018], ["The Conversation: Deep Audio-Visual Speech Enhancement", ["Triantafyllos Afouras", "Joon Son Chung", "Andrew Zisserman"], "https://doi.org/10.21437/Interspeech.2018-1400", 5, "interspeech", 2018], ["Deep Lip Reading: A Comparison of Models and an Online Application", ["Triantafyllos Afouras", "Joon Son Chung", "Andrew Zisserman"], "https://doi.org/10.21437/Interspeech.2018-1943", 5, "interspeech", 2018]], "Arpita Gang": [3.9162862406141863e-13, ["Towards Automated Single Channel Source Separation Using Neural Networks", ["Arpita Gang", "Pravesh Biyani", "Akshay Soni"], "https://doi.org/10.21437/Interspeech.2018-2065", 5, "interspeech", 2018]], "Balamurali B. T": [0, ["Automated Classification of Vowel-Gesture Parameters Using External Broadband Excitation", ["Balamurali B. T", "Jer-Ming Chen"], "https://doi.org/10.21437/Interspeech.2018-1756", 4, "interspeech", 2018]], "Rujie Liu": [0, ["Double Joint Bayesian Modeling of DNN Local I-Vector for Text Dependent Speaker Verification with Random Digit Strings", ["Ziqiang Shi", "Huibin Lin", "Liu Liu", "Rujie Liu"], "https://doi.org/10.21437/Interspeech.2018-1103", 5, "interspeech", 2018], ["Joint Learning of J-Vector Extractor and Joint Bayesian Model for Text Dependent Speaker Verification", ["Ziqiang Shi", "Liu Liu", "Huibin Lin", "Rujie Liu"], "https://doi.org/10.21437/Interspeech.2018-1500", 5, "interspeech", 2018], ["Latent Factor Analysis of Deep Bottleneck Features for Speaker Verification with Random Digit Strings", ["Ziqiang Shi", "Huibin Lin", "Liu Liu", "Rujie Liu"], "https://doi.org/10.21437/Interspeech.2018-1422", 5, "interspeech", 2018]], "Zhao Ren": [0, ["The INTERSPEECH 2018 Computational Paralinguistics Challenge: Atypical & Self-Assessed Affect, Crying & Heart Beats", ["Bjorn W. Schuller", "Stefan Steidl", "Anton Batliner", "Peter B. Marschik", "Harald Baumeister", "Fengquan Dong", "Simone Hantke", "Florian B. Pokorny", "Eva-Maria Rathner", "Katrin D. Bartl-Pokorny", "Christa Einspieler", "Dajie Zhang", "Alice Baird", "Shahin Amiriparian", "Kun Qian", "Zhao Ren", "Maximilian Schmitt", "Panagiotis Tzirakis", "Stefanos Zafeiriou"], "https://doi.org/10.21437/Interspeech.2018-51", 5, "interspeech", 2018], ["Bags in Bag: Generating Context-Aware Bags for Tracking Emotions from Speech", ["Jing Han", "Zixing Zhang", "Maximilian Schmitt", "Zhao Ren", "Fabien Ringeval", "Bjorn W. Schuller"], "https://doi.org/10.21437/Interspeech.2018-996", 5, "interspeech", 2018]], "Divya Prabhakaran": [0, ["Sensorimotor Response to Tongue Displacement Imagery by Talkers with Parkinson's Disease", ["William F. Katz", "Patrick Reidy", "Divya Prabhakaran"], "https://doi.org/10.21437/Interspeech.2018-2592", 5, "interspeech", 2018]], "Xugang Lu": [0, ["Temporal Attentive Pooling for Acoustic Event Detection", ["Xugang Lu", "Peng Shen", "Sheng Li", "Yu Tsao", "Hisashi Kawai"], "https://doi.org/10.21437/Interspeech.2018-1552", 4, "interspeech", 2018], ["Feature Representation of Short Utterances Based on Knowledge Distillation for Spoken Language Identification", ["Peng Shen", "Xugang Lu", "Sheng Li", "Hisashi Kawai"], "https://doi.org/10.21437/Interspeech.2018-1519", 5, "interspeech", 2018], ["Improving CTC-based Acoustic Model with Very Deep Residual Time-delay Neural Networks", ["Sheng Li", "Xugang Lu", "Ryoichi Takashima", "Peng Shen", "Tatsuya Kawahara", "Hisashi Kawai"], "https://doi.org/10.21437/Interspeech.2018-1475", 5, "interspeech", 2018]], "Jie Cui": [0, ["Wuxi Speakers' Production and Perception of Coda Nasals in Mandarin", ["Lei Wang", "Jie Cui", "Ying Chen"], "https://doi.org/10.21437/Interspeech.2018-2224", 4, "interspeech", 2018]], "John Kane": [0, ["Attention-based Sequence Classification for Affect Detection", ["Cristina Gorrostieta", "Richard Brutti", "Kye Taylor", "Avi Shapiro", "Joseph Moran", "Ali Azarbayejani", "John Kane"], "https://doi.org/10.21437/Interspeech.2018-1610", 5, "interspeech", 2018]], "Carlos Busso": [0, ["Preference-Learning with Qualitative Agreement for Sentence Level Emotional Annotations", ["Srinivas Parthasarathy", "Carlos Busso"], "https://doi.org/10.21437/Interspeech.2018-2478", 5, "interspeech", 2018], ["Role of Regularization in the Prediction of Valence from Speech", ["Kusha Sridhar", "Srinivas Parthasarathy", "Carlos Busso"], "https://doi.org/10.21437/Interspeech.2018-2508", 5, "interspeech", 2018], ["Predicting Categorical Emotions by Jointly Learning Primary and Secondary Emotions through Multitask Learning", ["Reza Lotfian", "Carlos Busso"], "https://doi.org/10.21437/Interspeech.2018-2464", 5, "interspeech", 2018], ["Audiovisual Speech Activity Detection with Advanced Long Short-Term Memory", ["Fei Tao", "Carlos Busso"], "https://doi.org/10.21437/Interspeech.2018-2490", 5, "interspeech", 2018], ["Ladder Networks for Emotion Recognition: Using Unsupervised Auxiliary Tasks to Improve Predictions of Emotional Attributes", ["Srinivas Parthasarathy", "Carlos Busso"], "https://doi.org/10.21437/Interspeech.2018-1391", 5, "interspeech", 2018]], "Alexey Karpov": [0, ["LSTM Based Cross-corpus and Cross-task Acoustic Emotion Recognition", ["Heysem Kaya", "Dmitrii Fedotov", "Ali Yesilkanat", "Oxana Verkholyak", "Yang Zhang", "Alexey Karpov"], "https://doi.org/10.21437/Interspeech.2018-2298", 5, "interspeech", 2018]], "Pablo Gimeno": [0, ["Estimation of the Number of Speakers with Variational Bayesian PLDA in the DIHARD Diarization Challenge", ["Ignacio Vinals", "Pablo Gimeno", "Alfonso Ortega", "Antonio Miguel", "Eduardo Lleida"], "https://doi.org/10.21437/Interspeech.2018-1841", 5, "interspeech", 2018]], "Anna Grabek": [0, ["Investigating the Role of L1 in Automatic Pronunciation Evaluation of L2 Speech", ["Ming Tu", "Anna Grabek", "Julie Liss", "Visar Berisha"], "https://doi.org/10.21437/Interspeech.2018-1350", 5, "interspeech", 2018]], "Tianzhu Geng": [0, ["Emotional Prosody Perception in Mandarin-speaking Congenital Amusics", ["Yixin Zhang", "Tianzhu Geng", "Jinsong Zhang"], "https://doi.org/10.21437/Interspeech.2018-91", 5, "interspeech", 2018]], "Madina Hasan": [0, ["A Lightly Supervised Approach to Detect Stuttering in Children's Speech", ["Sadeen Alharbi", "Madina Hasan", "Anthony J. H. Simons", "Shelagh Brumfitt", "Phil D. Green"], "https://doi.org/10.21437/Interspeech.2018-2155", 5, "interspeech", 2018]], "Sharon Goldwater": [0, ["Low-Resource Speech-to-Text Translation", ["Sameer Bansal", "Herman Kamper", "Karen Livescu", "Adam Lopez", "Sharon Goldwater"], "https://doi.org/10.21437/Interspeech.2018-1326", 5, "interspeech", 2018], ["Multilingual Bottleneck Features for Subword Modeling in Zero-resource Languages", ["Enno Hermann", "Sharon Goldwater"], "https://doi.org/10.21437/Interspeech.2018-2334", 5, "interspeech", 2018]], "Yasuhito Ohsugi": [0, ["A Comparative Study of Statistical Conversion of Face to Voice Based on Their Subjective Impressions", ["Yasuhito Ohsugi", "Daisuke Saito", "Nobuaki Minematsu"], "https://doi.org/10.21437/Interspeech.2018-2005", 5, "interspeech", 2018]], "Yi Xu": [0, ["A Weighted Superposition of Functional Contours Model for Modelling Contextual Prominence of Elementary Prosodic Contours", ["Branislav Gerazov", "Gerard Bailly", "Yi Xu"], "https://doi.org/10.21437/Interspeech.2018-1286", 5, "interspeech", 2018]], "Elisa Pellegrino": [0, ["Influences of Fundamental Oscillation on Speaker Identification in Vocalic Utterances by Humans and Computers", ["Volker Dellwo", "Thayabaran Kathiresan", "Elisa Pellegrino", "Lei He", "Sandra Schwab", "Dieter Maurer"], "https://doi.org/10.21437/Interspeech.2018-2331", 5, "interspeech", 2018]], "Renato de Mori": [0, ["Quaternion Convolutional Neural Networks for End-to-End Automatic Speech Recognition", ["Titouan Parcollet", "Ying Zhang", "Mohamed Morchid", "Chiheb Trabelsi", "Georges Linares", "Renato de Mori", "Yoshua Bengio"], "https://doi.org/10.21437/Interspeech.2018-1898", 5, "interspeech", 2018]], "Kai-Zhan Lee": [2.626446352071987e-10, ["A Comparison of Speaker-based and Utterance-based Data Selection for Text-to-Speech Synthesis", ["Kai-Zhan Lee", "Erica Cooper", "Julia Hirschberg"], "https://doi.org/10.21437/Interspeech.2018-1313", 5, "interspeech", 2018]], "Lambert Mathias": [0, ["Contextual Slot Carryover for Disparate Schemas", ["Chetan Naik", "Arpit Gupta", "Hancheng Ge", "Lambert Mathias", "Ruhi Sarikaya"], "https://doi.org/10.21437/Interspeech.2018-1035", 5, "interspeech", 2018]], "Zhuo Chen": [0, ["Recognizing Overlapped Speech in Meetings: A Multichannel Separation Approach Using Neural Networks", ["Takuya Yoshioka", "Hakan Erdogan", "Zhuo Chen", "Xiong Xiao", "Fil Alleva"], "https://doi.org/10.21437/Interspeech.2018-2284", 5, "interspeech", 2018]], "Yangyang Xia": [0, ["A Priori SNR Estimation Based on a Recurrent Neural Network for Robust Speech Enhancement", ["Yangyang Xia", "Richard Stern"], "https://doi.org/10.21437/Interspeech.2018-2423", 5, "interspeech", 2018]], "Shay Rishoni": [0, ["Detection of Amyotrophic Lateral Sclerosis (ALS) via Acoustic Analysis", ["Raquel Norel", "Mary Pietrowicz", "Carla Agurto", "Shay Rishoni", "Guillermo A. Cecchi"], "https://doi.org/10.21437/Interspeech.2018-2389", 5, "interspeech", 2018]], "Leonardo Lancia": [0, ["Analyzing Vocal Tract Movements During Speech Accommodation", ["Sankar Mukherjee", "Thierry Legou", "Leonardo Lancia", "Pauline Hilt", "Alice Tomassini", "Luciano Fadiga", "Alessandro DAusilio", "Leonardo Badino", "Noel Nguyen"], "https://doi.org/10.21437/Interspeech.2018-2084", 5, "interspeech", 2018]], "David A. van Leeuwen": [0, ["Acoustic and Textual Data Augmentation for Improved ASR of Code-Switching Speech", ["Emre Yilmaz", "Henk van den Heuvel", "David A. van Leeuwen"], "https://doi.org/10.21437/Interspeech.2018-52", 5, "interspeech", 2018]], "Akshay Raj Maggu": [0, ["Learning Two Tone Languages Enhances the Brainstem Encoding of Lexical Tones", ["Akshay Raj Maggu", "Wenqing Zong", "Vina Law", "Patrick C. M. Wong"], "https://doi.org/10.21437/Interspeech.2018-2130", 5, "interspeech", 2018], ["Experience-dependent Influence of Music and Language on Lexical Pitch Learning Is Not Additive", ["Akshay Raj Maggu", "Patrick C. M. Wong", "Hanjun Liu", "Francis C. K. Wong"], "https://doi.org/10.21437/Interspeech.2018-2104", 4, "interspeech", 2018]], "Dan Su": [0, ["Permutation Invariant Training of Generative Adversarial Network for Monaural Speech Separation", ["Lianwu Chen", "Meng Yu", "Yanmin Qian", "Dan Su", "Dong Yu"], "https://doi.org/10.21437/Interspeech.2018-1603", 5, "interspeech", 2018], ["Deep Extractor Network for Target Speaker Recovery from Single Channel Speech Mixtures", ["Jun Wang", "Jie Chen", "Dan Su", "Lianwu Chen", "Meng Yu", "Yanmin Qian", "Dong Yu"], "https://doi.org/10.21437/Interspeech.2018-1205", 5, "interspeech", 2018], ["Improving Attention Based Sequence-to-Sequence Models for End-to-End English Conversational Speech Recognition", ["Chao Weng", "Jia Cui", "Guangsen Wang", "Jun Wang", "Chengzhu Yu", "Dan Su", "Dong Yu"], "https://doi.org/10.21437/Interspeech.2018-1030", 5, "interspeech", 2018], ["Deep Discriminative Embeddings for Duration Robust Speaker Verification", ["Na Li", "Deyi Tuo", "Dan Su", "Zhifeng Li", "Dong Yu"], "https://doi.org/10.21437/Interspeech.2018-1769", 5, "interspeech", 2018], ["Text-Dependent Speech Enhancement for Small-Footprint Robust Keyword Detection", ["Meng Yu", "Xuan Ji", "Yi Gao", "Lianwu Chen", "Jie Chen", "Jimeng Zheng", "Dan Su", "Dong Yu"], "https://doi.org/10.21437/Interspeech.2018-1668", 5, "interspeech", 2018], ["Rapid Style Adaptation Using Residual Error Embedding for Expressive Speech Synthesis", ["Xixin Wu", "Yuewen Cao", "Mu Wang", "Songxiang Liu", "Shiyin Kang", "Zhiyong Wu", "Xunying Liu", "Dan Su", "Dong Yu", "Helen Meng"], "https://doi.org/10.21437/Interspeech.2018-1991", 5, "interspeech", 2018]], "Julien van Hout": [0, ["Robust Speaker Recognition from Distant Speech under Real Reverberant Environments Using Speaker Embeddings", ["Mahesh Kumar Nandwana", "Julien van Hout", "Mitchell McLaren", "Allen R. Stauffer", "Colleen Richey", "Aaron Lawson", "Martin Graciarena"], "https://doi.org/10.21437/Interspeech.2018-2221", 5, "interspeech", 2018], ["Voices Obscured in Complex Environmental Settings (VOiCES) Corpus", ["Colleen Richey", "Maria Auxiliadora Barrios", "Zeb Armstrong", "Chris Bartels", "Horacio Franco", "Martin Graciarena", "Aaron Lawson", "Mahesh Kumar Nandwana", "Allen R. Stauffer", "Julien van Hout", "Paul Gamble", "Jeffrey Hetherly", "Cory Stephenson", "Karl Ni"], "https://doi.org/10.21437/Interspeech.2018-1454", 5, "interspeech", 2018], ["Analysis of Complementary Information Sources in the Speaker Embeddings Framework", ["Mahesh Kumar Nandwana", "Mitchell McLaren", "Diego Castan", "Julien van Hout", "Aaron Lawson"], "https://doi.org/10.21437/Interspeech.2018-1102", 5, "interspeech", 2018]], "Jeremie Voix": [0, ["Classification of Nonverbal Human Produced Audio Events: A Pilot Study", ["Rachel E. Bouserhal", "Philippe Chabot", "Milton Sarria Paja", "Patrick Cardinal", "Jeremie Voix"], "https://doi.org/10.21437/Interspeech.2018-2299", 5, "interspeech", 2018]], "Takashi Kudo": [0, ["Detection of Dementia from Responses to Atypical Questions Asked by Embodied Conversational Agents", ["Tsuyoki Ujiro", "Hiroki Tanaka", "Hiroyoshi Adachi", "Hiroaki Kazui", "Manabu Ikeda", "Takashi Kudo", "Satoshi Nakamura"], "https://doi.org/10.21437/Interspeech.2018-1514", 5, "interspeech", 2018]], "Colin Vaz": [0, ["Exploring the Relationship between Conic Affinity of NMF Dictionaries and Speech Enhancement Metrics", ["Pavlos Papadopoulos", "Colin Vaz", "Shrikanth Narayanan"], "https://doi.org/10.21437/Interspeech.2018-1387", 5, "interspeech", 2018]], "Benoit Champagne": [0, ["A Deep Neural Network Based Harmonic Noise Model for Speech Enhancement", ["Zhiheng Ouyang", "Hongjiang Yu", "Wei-Ping Zhu", "Benoit Champagne"], "https://doi.org/10.21437/Interspeech.2018-1114", 5, "interspeech", 2018]], "Christa Einspieler": [0, ["The INTERSPEECH 2018 Computational Paralinguistics Challenge: Atypical & Self-Assessed Affect, Crying & Heart Beats", ["Bjorn W. Schuller", "Stefan Steidl", "Anton Batliner", "Peter B. Marschik", "Harald Baumeister", "Fengquan Dong", "Simone Hantke", "Florian B. Pokorny", "Eva-Maria Rathner", "Katrin D. Bartl-Pokorny", "Christa Einspieler", "Dajie Zhang", "Alice Baird", "Shahin Amiriparian", "Kun Qian", "Zhao Ren", "Maximilian Schmitt", "Panagiotis Tzirakis", "Stefanos Zafeiriou"], "https://doi.org/10.21437/Interspeech.2018-51", 5, "interspeech", 2018]], "Maria Alejandra Barrios": [0, ["Deep Speech Denoising with Vector Space Projections", ["Jeffrey Hetherly", "Paul Gamble", "Maria Alejandra Barrios", "Cory Stephenson", "Karl Ni"], "https://doi.org/10.21437/Interspeech.2018-83", 5, "interspeech", 2018]], "Linjuan Zhang": [0, ["Speech Emotion Recognition by Combining Amplitude and Phase Information Using Convolutional Neural Network", ["Lili Guo", "Longbiao Wang", "Jianwu Dang", "Linjuan Zhang", "Haotian Guan", "Xiangang Li"], "https://doi.org/10.21437/Interspeech.2018-2156", 5, "interspeech", 2018]], "Huibin Lin": [0, ["Double Joint Bayesian Modeling of DNN Local I-Vector for Text Dependent Speaker Verification with Random Digit Strings", ["Ziqiang Shi", "Huibin Lin", "Liu Liu", "Rujie Liu"], "https://doi.org/10.21437/Interspeech.2018-1103", 5, "interspeech", 2018], ["Joint Learning of J-Vector Extractor and Joint Bayesian Model for Text Dependent Speaker Verification", ["Ziqiang Shi", "Liu Liu", "Huibin Lin", "Rujie Liu"], "https://doi.org/10.21437/Interspeech.2018-1500", 5, "interspeech", 2018], ["Latent Factor Analysis of Deep Bottleneck Features for Speaker Verification with Random Digit Strings", ["Ziqiang Shi", "Huibin Lin", "Liu Liu", "Rujie Liu"], "https://doi.org/10.21437/Interspeech.2018-1422", 5, "interspeech", 2018]], "Yutaka Yamauchi": [0, ["A Study of Objective Measurement of Comprehensibility through Native Speakers' Shadowing of Learners' Utterances", ["Yusuke Inoue", "Suguru Kabashima", "Daisuke Saito", "Nobuaki Minematsu", "Kumi Kanamura", "Yutaka Yamauchi"], "https://doi.org/10.21437/Interspeech.2018-1860", 5, "interspeech", 2018]], "Behnam Hedayatnia": [0, ["Contextual Language Model Adaptation for Conversational Agents", ["Anirudh Raju", "Behnam Hedayatnia", "Linda Liu", "Ankur Gandhe", "Chandra Khatri", "Angeliki Metallinou", "Anu Venkatesh", "Ariya Rastrow"], "https://doi.org/10.21437/Interspeech.2018-1122", 5, "interspeech", 2018]], "Bhavya Karki": [0, ["Investigating Utterance Level Representations for Detecting Intent from Acoustics", ["Sai Krishna Rallabandi", "Bhavya Karki", "Carla Viegas", "Eric Nyberg", "Alan W. Black"], "https://doi.org/10.21437/Interspeech.2018-2149", 5, "interspeech", 2018]], "Yanlu Xie": [0, ["Improving Mandarin Tone Recognition Using Convolutional Bidirectional Long Short-Term Memory with Attention", ["Longfei Yang", "Yanlu Xie", "Jinsong Zhang"], "https://doi.org/10.21437/Interspeech.2018-2561", 5, "interspeech", 2018], ["A Preliminary Study on Tonal Coarticulation in Continuous Speech", ["Lixia Hao", "Wei Zhang", "Yanlu Xie", "Jinsong Zhang"], "https://doi.org/10.21437/Interspeech.2018-1849", 5, "interspeech", 2018], ["Interactions between Vowels and Nasal Codas in Mandarin Speakers' Perception of Nasal Finals", ["Chong Cao", "Wei Wei", "Wei Wang", "Yanlu Xie", "Jinsong Zhang"], "https://doi.org/10.21437/Interspeech.2018-2025", 5, "interspeech", 2018]], "Martin J. Russell": [0, ["Exploring How Phone Classification Neural Networks Learn Phonetic Information by Visualising and Interpreting Bottleneck Features", ["Linxue Bai", "Philip Weber", "Peter Jancovic", "Martin J. Russell"], "https://doi.org/10.21437/Interspeech.2018-2462", 5, "interspeech", 2018], ["Overview of the 2018 Spoken CALL Shared Task", ["Claudia Baur", "Andrew Caines", "Cathy Chua", "Johanna Gerlach", "Mengjie Qian", "Manny Rayner", "Martin J. Russell", "Helmer Strik", "Xizi Wei"], "https://doi.org/10.21437/Interspeech.2018-97", 5, "interspeech", 2018], ["The University of Birmingham 2018 Spoken CALL Shared Task Systems", ["Mengjie Qian", "Xizi Wei", "Peter Jancovic", "Martin J. Russell"], "https://doi.org/10.21437/Interspeech.2018-1372", 5, "interspeech", 2018], ["Analysis of Phone Errors Attributable to Phonological Effects Associated With Language Acquisition Through Bottleneck Feature Visualisations", ["Eva Fringi", "Martin J. Russell"], "https://doi.org/10.21437/Interspeech.2018-2422", 5, "interspeech", 2018], ["Phone Recognition Using a Non-Linear Manifold with Broad Phone Class Dependent DNNs", ["Mengjie Qian", "Linxue Bai", "Peter Jancovic", "Martin J. Russell"], "https://doi.org/10.21437/Interspeech.2018-1376", 5, "interspeech", 2018]], "Patrick Wambacq": [0, ["State Gradients for RNN Memory Analysis", ["Lyan Verwimp", "Hugo Van hamme", "Vincent Renkens", "Patrick Wambacq"], "https://doi.org/10.21437/Interspeech.2018-1153", 5, "interspeech", 2018]], "Cheng-chieh Yeh": [0, ["Multi-target Voice Conversion without Parallel Data by Adversarially Learning Disentangled Audio Representations", ["Ju-Chieh Chou", "Cheng-chieh Yeh", "Hung-yi Lee", "Lin-Shan Lee"], "https://doi.org/10.21437/Interspeech.2018-1830", 5, "interspeech", 2018]], "Xuedong Zhang": [0, ["Speech Recognition for Medical Conversations", ["Chung-Cheng Chiu", "Anshuman Tripathi", "Katherine Chou", "Chris Co", "Navdeep Jaitly", "Diana Jaunzeikare", "Anjuli Kannan", "Patrick Nguyen", "Hasim Sak", "Ananth Sankar", "Justin Tansuwan", "Nathan Wan", "Yonghui Wu", "Xuedong Zhang"], "https://doi.org/10.21437/Interspeech.2018-40", 5, "interspeech", 2018]], "Ziwei Zhu": [0, ["Siamese Recurrent Auto-Encoder Representation for Query-by-Example Spoken Term Detection", ["Ziwei Zhu", "Zhiyong Wu", "Runnan Li", "Helen Meng", "Lianhong Cai"], "https://doi.org/10.21437/Interspeech.2018-1788", 5, "interspeech", 2018]], "Yannick Esteve": [0, ["Task Specific Sentence Embeddings for ASR Error Detection", ["Sahar Ghannay", "Yannick Esteve", "Nathalie Camelin"], "https://doi.org/10.21437/Interspeech.2018-2211", 5, "interspeech", 2018], ["Speaker Adaptive Training and Mixup Regularization for Neural Network Acoustic Models in Automatic Speech Recognition", ["Natalia A. Tomashenko", "Yuri Y. Khokhlov", "Yannick Esteve"], "https://doi.org/10.21437/Interspeech.2018-2209", 5, "interspeech", 2018], ["Acoustic-dependent Phonemic Transcription for Text-to-speech Synthesis", ["Kevin Vythelingum", "Yannick Esteve", "Olivier Rosec"], "https://doi.org/10.21437/Interspeech.2018-1306", 5, "interspeech", 2018]], "Weipeng He": [0, ["Joint Localization and Classification of Multiple Sound Sources Using a Multi-task Neural Network", ["Weipeng He", "Petr Motlicek", "Jean-Marc Odobez"], "https://doi.org/10.21437/Interspeech.2018-1269", 5, "interspeech", 2018]], "Ajish K. Abraham": [0, ["Detection of Glottal Activity Errors in Production of Stop Consonants in Children with Cleft Lip and Palate", ["Vikram C. M.", "S. R. Mahadeva Prasanna", "Ajish K. Abraham", "Pushpavathi M", "Girish K. S"], "https://doi.org/10.21437/Interspeech.2018-1665", 5, "interspeech", 2018]], "Pulkit Sharma": [0, ["Deep Convex Representations: Feature Representations for Bioacoustics Classification", ["Anshul Thakur", "Vinayak Abrol", "Pulkit Sharma", "Padmanabhan Rajan"], "https://doi.org/10.21437/Interspeech.2018-1705", 5, "interspeech", 2018], ["ASe: Acoustic Scene Embedding Using Deep Archetypal Analysis and GMM", ["Pulkit Sharma", "Vinayak Abrol", "Anshul Thakur"], "https://doi.org/10.21437/Interspeech.2018-1481", 5, "interspeech", 2018]], "Yusuke Shinohara": [0, ["Automatic DNN Node Pruning Using Mixture Distribution-based Group Regularization", ["Tsukasa Yoshida", "Takafumi Moriya", "Kazuho Watanabe", "Yusuke Shinohara", "Yoshikazu Yamaguchi", "Yushi Aono"], "https://doi.org/10.21437/Interspeech.2018-2062", 5, "interspeech", 2018], ["Multi-task Learning with Augmentation Strategy for Acoustic-to-word Attention-based Encoder-decoder Speech Recognition", ["Takafumi Moriya", "Sei Ueno", "Yusuke Shinohara", "Marc Delcroix", "Yoshikazu Yamaguchi", "Yushi Aono"], "https://doi.org/10.21437/Interspeech.2018-1866", 5, "interspeech", 2018], ["Encoder Transfer for Attention-based Acoustic-to-word Speech Recognition", ["Sei Ueno", "Takafumi Moriya", "Masato Mimura", "Shinsuke Sakai", "Yusuke Shinohara", "Yoshikazu Yamaguchi", "Yushi Aono", "Tatsuya Kawahara"], "https://doi.org/10.21437/Interspeech.2018-1424", 5, "interspeech", 2018]], "Felix Burkhardt": [0, ["The Perception and Analysis of the Likeability and Human Likeness of Synthesized Speech", ["Alice Baird", "Emilia Parada-Cabaleiro", "Simone Hantke", "Felix Burkhardt", "Nicholas Cummins", "Bjorn W. Schuller"], "https://doi.org/10.21437/Interspeech.2018-1093", 5, "interspeech", 2018]], "Elisabeth Andre": [0, ["Deep Learning in Paralinguistic Recognition Tasks: Are Hand-crafted Features Still Relevant?", ["Johannes Wagner", "Dominik Schiller", "Andreas Seiderer", "Elisabeth Andre"], "https://doi.org/10.21437/Interspeech.2018-1238", 5, "interspeech", 2018]], "Angel M. Gomez": [0, ["A Deep Identity Representation for Noise Robust Spoofing Detection", ["Alejandro Gomez Alanis", "Antonio M. Peinado", "Jose A. Gonzalez", "Angel M. Gomez"], "https://doi.org/10.21437/Interspeech.2018-1909", 5, "interspeech", 2018]], "Jahn Heymann": [0, ["ESPnet: End-to-End Speech Processing Toolkit", ["Shinji Watanabe", "Takaaki Hori", "Shigeki Karita", "Tomoki Hayashi", "Jiro Nishitoba", "Yuya Unno", "Nelson Enrique Yalta Soplin", "Jahn Heymann", "Matthew Wiesner", "Nanxin Chen", "Adithya Renduchintala", "Tsubasa Ochiai"], "https://doi.org/10.21437/Interspeech.2018-1456", 5, "interspeech", 2018], ["Integrating Neural Network Based Beamforming and Weighted Prediction Error Dereverberation", ["Lukas Drude", "Christoph Boddeker", "Jahn Heymann", "Reinhold Haeb-Umbach", "Keisuke Kinoshita", "Marc Delcroix", "Tomohiro Nakatani"], "https://doi.org/10.21437/Interspeech.2018-2196", 5, "interspeech", 2018]], "Parismita Gogoi": [0, ["Analysis of Breathiness in Contextual Vowel of Voiceless Nasals in Mizo", ["Pamir Gogoi", "Sishir Kalita", "Parismita Gogoi", "Ratree Wayland", "Priyankoo Sarmah", "S. R. Mahadeva Prasanna"], "https://doi.org/10.21437/Interspeech.2018-1899", 5, "interspeech", 2018], ["Robust Mizo Continuous Speech Recognition", ["Abhishek Dey", "Biswajit Dev Sarma", "Wendy Lalhminghlui", "Lalnunsiami Ngente", "Parismita Gogoi", "Priyankoo Sarmah", "S. R. Mahadeva Prasanna", "Rohit Sinha", "S. R. Nirmala"], "https://doi.org/10.21437/Interspeech.2018-2125", 5, "interspeech", 2018]], "Dominik Julg": [0, ["The CSU-K Rule-Based System for the 2nd Edition Spoken CALL Shared Task", ["Dominik Julg", "Mario Kunstek", "Cem Philipp Freimoser", "Kay Berkling", "Mengjie Qian"], "https://doi.org/10.21437/Interspeech.2018-1000", 5, "interspeech", 2018]], "S. R. Mahadeva Prasanna": [0, ["Spoken Keyword Detection Using Joint DTW-CNN", ["Ravi Shankar", "Vikram C. M.", "S. R. Mahadeva Prasanna"], "https://doi.org/10.21437/Interspeech.2018-1436", 5, "interspeech", 2018], ["Analysis of Breathiness in Contextual Vowel of Voiceless Nasals in Mizo", ["Pamir Gogoi", "Sishir Kalita", "Parismita Gogoi", "Ratree Wayland", "Priyankoo Sarmah", "S. R. Mahadeva Prasanna"], "https://doi.org/10.21437/Interspeech.2018-1899", 5, "interspeech", 2018], ["Self-similarity Matrix Based Intelligibility Assessment of Cleft Lip and Palate Speech", ["Sishir Kalita", "S. R. Mahadeva Prasanna", "Samarendra Dandapat"], "https://doi.org/10.21437/Interspeech.2018-1125", 5, "interspeech", 2018], ["Pitch-Adaptive Front-end Feature for Hypernasality Detection", ["Akhilesh Kumar Dubey", "S. R. Mahadeva Prasanna", "Samarendra Dandapat"], "https://doi.org/10.21437/Interspeech.2018-1251", 5, "interspeech", 2018], ["Detection of Glottal Activity Errors in Production of Stop Consonants in Children with Cleft Lip and Palate", ["Vikram C. M.", "S. R. Mahadeva Prasanna", "Ajish K. Abraham", "Pushpavathi M", "Girish K. S"], "https://doi.org/10.21437/Interspeech.2018-1665", 5, "interspeech", 2018], ["Exploration of Compressed ILPR Features for Replay Attack Detection", ["Sarfaraz Jelil", "Sishir Kalita", "S. R. Mahadeva Prasanna", "Rohit Sinha"], "https://doi.org/10.21437/Interspeech.2018-1297", 5, "interspeech", 2018], ["Robust Mizo Continuous Speech Recognition", ["Abhishek Dey", "Biswajit Dev Sarma", "Wendy Lalhminghlui", "Lalnunsiami Ngente", "Parismita Gogoi", "Priyankoo Sarmah", "S. R. Mahadeva Prasanna", "Rohit Sinha", "S. R. Nirmala"], "https://doi.org/10.21437/Interspeech.2018-2125", 5, "interspeech", 2018], ["Processing Transition Regions of Glottal Stop Substituted /S/ for Intelligibility Enhancement of Cleft Palate Speech", ["Protima Nomo Sudro", "Sishir Kalita", "S. R. Mahadeva Prasanna"], "https://doi.org/10.21437/Interspeech.2018-1646", 5, "interspeech", 2018], ["Estimation of Hypernasality Scores from Cleft Lip and Palate Speech", ["Vikram C. M.", "Ayush Tripathi", "Sishir Kalita", "S. R. Mahadeva Prasanna"], "https://doi.org/10.21437/Interspeech.2018-1631", 5, "interspeech", 2018], ["Epoch Extraction from Pathological Children Speech Using Single Pole Filtering Approach", ["Vikram C. M.", "S. R. Mahadeva Prasanna"], "https://doi.org/10.21437/Interspeech.2018-1613", 5, "interspeech", 2018], ["Glotto Vibrato Graph: A Device and Method for Recording, Analysis and Visualization of Glottal Activity", ["Kishalay Chakraborty", "Senjam Shantirani Devi", "Sanjeevan Devnath", "S. R. Mahadeva Prasanna", "Priyankoo Sarmah"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3046.html", 2, "interspeech", 2018], ["AGROASSAM: A Web Based Assamese Speech Recognition Application for Retrieving Agricultural Commodity Price and Weather Information", ["Abhishek Dey", "Abhash Deka", "Siddika Imani", "Barsha Deka", "Rohit Sinha", "S. R. Mahadeva Prasanna", "Priyankoo Sarmah", "K. Samudravijaya", "S. R. Nirmala"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3048.html", 2, "interspeech", 2018]], "Christian Raymond": [0, ["Is ATIS Too Shallow to Go Deeper for Benchmarking Spoken Language Understanding Models?", ["Frederic Bechet", "Christian Raymond"], "https://doi.org/10.21437/Interspeech.2018-2256", 5, "interspeech", 2018]], "Xingliang Cheng": [0, ["Imbalance Learning-based Framework for Fear Recognition in the MediaEval Emotional Impact of Movies Task", ["Xiaotong Zhang", "Xingliang Cheng", "Mingxing Xu", "Thomas Fang Zheng"], "https://doi.org/10.21437/Interspeech.2018-1744", 5, "interspeech", 2018]], "Periyasamy Paramasivam": [0, ["Hierarchical Accent Determination and Application in a Large Scale ASR System", ["Ramya Viswanathan", "Periyasamy Paramasivam", "Jithendra Vepa"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3030.html", 2, "interspeech", 2018]], "Shiliang Zhang": [0, ["Acoustic Modeling with DFSMN-CTC and Joint CTC-CE Learning", ["Shiliang Zhang", "Ming Lei"], "https://doi.org/10.21437/Interspeech.2018-1049", 5, "interspeech", 2018], ["Compact Feedforward Sequential Memory Networks for Small-footprint Keyword Spotting", ["Mengzhe Chen", "Shiliang Zhang", "Ming Lei", "Yong Liu", "Haitao Yao", "Jie Gao"], "https://doi.org/10.21437/Interspeech.2018-1204", 5, "interspeech", 2018]], "Wei Li": [0, ["Fast Derivation of Cross-lingual Document Vectors from Self-attentive Neural Machine Translation Model", ["Wei Li", "Brian Mak"], "https://doi.org/10.21437/Interspeech.2018-1459", 5, "interspeech", 2018]], "Cong Zhou": [0, ["Voice Conversion with Conditional SampleRNN", ["Cong Zhou", "Michael Horgan", "Vivek Kumar", "Cristina Vasco", "Dan Darcy"], "https://doi.org/10.21437/Interspeech.2018-1121", 5, "interspeech", 2018]], "Jindrich Matousek": [0, ["Glottal Closure Instant Detection from Speech Signal Using Voting Classifier and Recursive Feature Elimination", ["Jindrich Matousek", "Daniel Tihelka"], "https://doi.org/10.21437/Interspeech.2018-1147", 5, "interspeech", 2018]], "John Kim": [1, ["Emotion Recognition from Human Speech Using Temporal Information and Deep Learning", ["John Kim", "Rif A. Saurous"], "https://doi.org/10.21437/Interspeech.2018-1132", 4, "interspeech", 2018]], "Shiwen Deng": [0, ["Unsupervised Temporal Feature Learning Based on Sparse Coding Embedded BoAW for Acoustic Event Recognition", ["Liwen Zhang", "Jiqing Han", "Shiwen Deng"], "https://doi.org/10.21437/Interspeech.2018-1243", 5, "interspeech", 2018], ["A Compact and Discriminative Feature Based on Auditory Summary Statistics for Acoustic Scene Classification", ["Hongwei Song", "Jiqing Han", "Shiwen Deng"], "https://doi.org/10.21437/Interspeech.2018-1299", 5, "interspeech", 2018]], "Julien Schroeter": [0, ["Computational Paralinguistics: Automatic Assessment of Emotions, Mood and Behavioural State from Acoustics of Speech", ["Zafi Sherhan Syed", "Julien Schroeter", "Kirill A. Sidorov", "A. David Marshall"], "https://doi.org/10.21437/Interspeech.2018-2019", 5, "interspeech", 2018]], "Chengzhu Yu": [1.484971062382101e-05, ["Improving Attention Based Sequence-to-Sequence Models for End-to-End English Conversational Speech Recognition", ["Chao Weng", "Jia Cui", "Guangsen Wang", "Jun Wang", "Chengzhu Yu", "Dan Su", "Dong Yu"], "https://doi.org/10.21437/Interspeech.2018-1030", 5, "interspeech", 2018], ["A Multistage Training Framework for Acoustic-to-Word Model", ["Chengzhu Yu", "Chunlei Zhang", "Chao Weng", "Jia Cui", "Dong Yu"], "https://doi.org/10.21437/Interspeech.2018-1452", 5, "interspeech", 2018], ["Fearless Steps: Apollo-11 Corpus Advancements for Speech Technologies from Earth to the Moon", ["John H. L. Hansen", "Abhijeet Sangwan", "Aditya Joglekar", "Ahmet Emin Bulut", "Lakshmish Kaushik", "Chengzhu Yu"], "https://doi.org/10.21437/Interspeech.2018-1942", 5, "interspeech", 2018]], "Stylianos Ioannis Mimilakis": [0, ["Reducing Interference with Phase Recovery in DNN-based Monaural Singing Voice Separation", ["Paul Magron", "Konstantinos Drossos", "Stylianos Ioannis Mimilakis", "Tuomas Virtanen"], "https://doi.org/10.21437/Interspeech.2018-1845", 5, "interspeech", 2018]], "Ming Li": [0, ["An End-to-End Deep Learning Framework for Speech Emotion Recognition of Atypical Individuals", ["Dengke Tang", "Junlin Zeng", "Ming Li"], "https://doi.org/10.21437/Interspeech.2018-2581", 5, "interspeech", 2018], ["Analysis of Length Normalization in End-to-End Speaker Verification System", ["Weicheng Cai", "Jinkun Chen", "Ming Li"], "https://doi.org/10.21437/Interspeech.2018-92", 5, "interspeech", 2018]], "Shiva Kumar H. R": [0, ["Online Speech Translation System for Tamil", ["Madhavaraj Ayyavu", "Shiva Kumar H. R", "Ramakrishnan A. G"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3035.html", 2, "interspeech", 2018]], "Bayya Yegnanarayana": [0, ["Discriminating Nasals and Approximants in English Language Using Zero Time Windowing", ["RaviShankar Prasad", "Sudarsana Reddy Kadiri", "Suryakanth V. Gangashetty", "Bayya Yegnanarayana"], "https://doi.org/10.21437/Interspeech.2018-1032", 5, "interspeech", 2018], ["Identification and Classification of Fricatives in Speech Using Zero Time Windowing Method", ["RaviShankar Prasad", "Bayya Yegnanarayana"], "https://doi.org/10.21437/Interspeech.2018-1958", 5, "interspeech", 2018], ["Breathy to Tense Voice Discrimination using Zero-Time Windowing Cepstral Coefficients (ZTWCCs)", ["Sudarsana Reddy Kadiri", "Bayya Yegnanarayana"], "https://doi.org/10.21437/Interspeech.2018-2498", 5, "interspeech", 2018], ["Analysis and Detection of Phonation Modes in Singing Voice using Excitation Source Features and Single Frequency Filtering Cepstral Coefficients (SFFCC)", ["Sudarsana Reddy Kadiri", "Bayya Yegnanarayana"], "https://doi.org/10.21437/Interspeech.2018-2502", 5, "interspeech", 2018], ["Detection of Glottal Closure Instants in Degraded Speech Using Single Frequency Filtering Analysis", ["Gunnam Aneeja", "Sudarsana Reddy Kadiri", "Bayya Yegnanarayana"], "https://doi.org/10.21437/Interspeech.2018-1018", 5, "interspeech", 2018], ["Estimation of Fundamental Frequency from Singing Voice Using Harmonics of Impulse-like Excitation Source", ["Sudarsana Reddy Kadiri", "Bayya Yegnanarayana"], "https://doi.org/10.21437/Interspeech.2018-2495", 5, "interspeech", 2018], ["Determining Speaker Location from Speech in a Practical Environment", ["B. H. V. S. Narayanamurthy", "J. V. Satyanarayana", "Bayya Yegnanarayana"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3042.html", 2, "interspeech", 2018]], "Emmanuel Dupoux": [0, ["End-to-End Speech Recognition from the Raw Waveform", ["Neil Zeghidour", "Nicolas Usunier", "Gabriel Synnaeve", "Ronan Collobert", "Emmanuel Dupoux"], "https://doi.org/10.21437/Interspeech.2018-2414", 5, "interspeech", 2018], ["Sampling Strategies in Siamese Networks for Unsupervised Speech Representation Learning", ["Rachid Riad", "Corentin Dancette", "Julien Karadayi", "Neil Zeghidour", "Thomas Schatz", "Emmanuel Dupoux"], "https://doi.org/10.21437/Interspeech.2018-2384", 5, "interspeech", 2018], ["Learning Word Embeddings: Unsupervised Methods for Fixed-size Representations of Variable-length Speech Segments", ["Nils Holzenberger", "Mingxing Du", "Julien Karadayi", "Rachid Riad", "Emmanuel Dupoux"], "https://doi.org/10.21437/Interspeech.2018-2364", 5, "interspeech", 2018]], "Stephane Roman": [0, ["Prosodic Focus Acquisition in French Early Cochlear Implanted Children", ["Chadi Farah", "Stephane Roman", "Mariapaola DImperio"], "https://doi.org/10.21437/Interspeech.2018-1320", 5, "interspeech", 2018]], "Phu Ngoc Le": [0, ["Detection of Replay-Spoofing Attacks Using Frequency Modulation Features", ["Tharshini Gunendradasan", "Buddhi Wickramasinghe", "Phu Ngoc Le", "Eliathamby Ambikairajah", "Julien Epps"], "https://doi.org/10.21437/Interspeech.2018-1473", 5, "interspeech", 2018]], "Katharina Zahner": [0, ["Truncation and Compression in Southern German and Australian English", ["Jenny Yu", "Katharina Zahner"], "https://doi.org/10.21437/Interspeech.2018-2513", 5, "interspeech", 2018]], "Mimansa Jaiswal": [0, ["The PRIORI Emotion Dataset: Linking Mood to Emotion Detected In-the-Wild", ["Soheil Khorram", "Mimansa Jaiswal", "John Gideon", "Melvin G. McInnis", "Emily Mower Provost"], "https://doi.org/10.21437/Interspeech.2018-2355", 5, "interspeech", 2018]], "Maximilian Schmitt": [0, ["The INTERSPEECH 2018 Computational Paralinguistics Challenge: Atypical & Self-Assessed Affect, Crying & Heart Beats", ["Bjorn W. Schuller", "Stefan Steidl", "Anton Batliner", "Peter B. Marschik", "Harald Baumeister", "Fengquan Dong", "Simone Hantke", "Florian B. Pokorny", "Eva-Maria Rathner", "Katrin D. Bartl-Pokorny", "Christa Einspieler", "Dajie Zhang", "Alice Baird", "Shahin Amiriparian", "Kun Qian", "Zhao Ren", "Maximilian Schmitt", "Panagiotis Tzirakis", "Stefanos Zafeiriou"], "https://doi.org/10.21437/Interspeech.2018-51", 5, "interspeech", 2018], ["Bags in Bag: Generating Context-Aware Bags for Tracking Emotions from Speech", ["Jing Han", "Zixing Zhang", "Maximilian Schmitt", "Zhao Ren", "Fabien Ringeval", "Bjorn W. Schuller"], "https://doi.org/10.21437/Interspeech.2018-996", 5, "interspeech", 2018]], "Carmel Rabinovitz": [0, ["The IBM Virtual Voice Creator", ["Alexander Sorin", "Slava Shechtman", "Zvi Kons", "Ron Hoory", "Shay Ben-David", "Joe Pavitt", "Shai Rozenberg", "Carmel Rabinovitz", "Tal Drory"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3011.html", 2, "interspeech", 2018]], "Bastian Schnell": [0, ["A Neural Model to Predict Parameters for a Generalized Command Response Model of Intonation", ["Bastian Schnell", "Philip N. Garner"], "https://doi.org/10.21437/Interspeech.2018-1904", 5, "interspeech", 2018]], "Sishi Liao": [0, ["GlobalTIMIT: Acoustic-Phonetic Datasets for the World's Languages", ["Nattanun Chanchaochai", "Christopher Cieri", "Japhet Debrah", "Hongwei Ding", "Yue Jiang", "Sishi Liao", "Mark Liberman", "Jonathan Wright", "Jiahong Yuan", "Juhong Zhan", "Yuqing Zhan"], "https://doi.org/10.21437/Interspeech.2018-1185", 5, "interspeech", 2018]], "Bhiksha Raj": [0, ["Mining Multimodal Repositories for Speech Affecting Diseases", ["M. Joana Correia", "Bhiksha Raj", "Isabel Trancoso", "Francisco Teixeira"], "https://doi.org/10.21437/Interspeech.2018-1806", 5, "interspeech", 2018]], "Yannik Terhorst": [0, ["State of Mind: Classification through Self-reported Affect and Word Use in Speech", ["Eva-Maria Rathner", "Yannik Terhorst", "Nicholas Cummins", "Bjorn W. Schuller", "Harald Baumeister"], "https://doi.org/10.21437/Interspeech.2018-2043", 5, "interspeech", 2018], ["How Did You like 2017? Detection of Language Markers of Depression and Narcissism in Personal Narratives", ["Eva-Maria Rathner", "Julia Djamali", "Yannik Terhorst", "Bjorn W. Schuller", "Nicholas Cummins", "Gudrun Salamon", "Christina Hunger-Schoppe", "Harald Baumeister"], "https://doi.org/10.21437/Interspeech.2018-2040", 5, "interspeech", 2018]], "Liwen Zhang": [0, ["Unsupervised Temporal Feature Learning Based on Sparse Coding Embedded BoAW for Acoustic Event Recognition", ["Liwen Zhang", "Jiqing Han", "Shiwen Deng"], "https://doi.org/10.21437/Interspeech.2018-1243", 5, "interspeech", 2018]], "Lisa P. Mason": [0, ["Performance Analysis of the 2017 NIST Language Recognition Evaluation", ["Seyed Omid Sadjadi", "Timothee Kheyrkhah", "Craig S. Greenberg", "Elliot Singer", "Douglas A. Reynolds", "Lisa P. Mason", "Jaime Hernandez-Cordero"], "https://doi.org/10.21437/Interspeech.2018-69", 5, "interspeech", 2018]], "Daniel Neil": [0, ["Multi-channel Attention for End-to-End Speech Recognition", ["Stefan Braun", "Daniel Neil", "Jithendar Anumula", "Enea Ceolini", "Shih-Chii Liu"], "https://doi.org/10.21437/Interspeech.2018-1301", 5, "interspeech", 2018]], "Nathan Reale": [0, ["AVA-Speech: A Densely Labeled Dataset of Speech Activity in Movies", ["Sourish Chaudhuri", "Joseph Roth", "Daniel P. W. Ellis", "Andrew C. Gallagher", "Liat Kaver", "Radhika Marvin", "Caroline Pantofaru", "Nathan Reale", "Loretta Guarino Reid", "Kevin W. Wilson", "Zhonghua Xi"], "https://doi.org/10.21437/Interspeech.2018-2028", 5, "interspeech", 2018]], "Sethuraman Panchanathan": [0, ["Whistle-blowing ASRs: Evaluating the Need for More Inclusive Speech Recognition Systems", ["Meredith Moore", "Hemanth Venkateswara", "Sethuraman Panchanathan"], "https://doi.org/10.21437/Interspeech.2018-2391", 5, "interspeech", 2018]], "Juntae Kim": [0.9839552938938141, ["Korean Singing Voice Synthesis Based on an LSTM Recurrent Neural Network", ["Juntae Kim", "Heejin Choi", "Jinuk Park", "Minsoo Hahn", "Sang-Jin Kim", "Jong-Jin Kim"], "https://doi.org/10.21437/Interspeech.2018-1575", 5, "interspeech", 2018]], "Korbinian Riedhammer": [0, ["VoiceGuard: Secure and Private Speech Processing", ["Ferdinand Brasser", "Tommaso Frassetto", "Korbinian Riedhammer", "Ahmad-Reza Sadeghi", "Thomas Schneider", "Christian Weinert"], "https://doi.org/10.21437/Interspeech.2018-2032", 5, "interspeech", 2018]], "Lili Guo": [0, ["Speech Emotion Recognition by Combining Amplitude and Phase Information Using Convolutional Neural Network", ["Lili Guo", "Longbiao Wang", "Jianwu Dang", "Linjuan Zhang", "Haotian Guan", "Xiangang Li"], "https://doi.org/10.21437/Interspeech.2018-2156", 5, "interspeech", 2018]], "Shahram Ghorbani": [0, ["Leveraging Native Language Information for Improved Accented Speech Recognition", ["Shahram Ghorbani", "John H. L. Hansen"], "https://doi.org/10.21437/Interspeech.2018-1378", 5, "interspeech", 2018]], "Shan He": [0, ["Speaker Diarization with Enhancing Speech for the First DIHARD Challenge", ["Lei Sun", "Jun Du", "Chao Jiang", "Xueyang Zhang", "Shan He", "Bing Yin", "Chin-Hui Lee"], "https://doi.org/10.21437/Interspeech.2018-1742", 5, "interspeech", 2018]], "Bing Yin": [0, ["Speaker Diarization with Enhancing Speech for the First DIHARD Challenge", ["Lei Sun", "Jun Du", "Chao Jiang", "Xueyang Zhang", "Shan He", "Bing Yin", "Chin-Hui Lee"], "https://doi.org/10.21437/Interspeech.2018-1742", 5, "interspeech", 2018]], "Alena Witzlack-Makarevich": [0, ["A First Investigation of the Timing of Turn-taking in Ruuli", ["Tuarik Buanzur", "Margaret Zellers", "Saudah Namyalo", "Alena Witzlack-Makarevich"], "https://doi.org/10.21437/Interspeech.2018-1254", 5, "interspeech", 2018]], "Wei Rao": [0, ["A Shifted Delta Coefficient Objective for Monaural Speech Separation Using Multi-task Learning", ["Chenglin Xu", "Wei Rao", "Eng Siong Chng", "Haizhou Li"], "https://doi.org/10.21437/Interspeech.2018-1150", 5, "interspeech", 2018]], "Shengwu Xiong": [0, ["Multi-frame Quantization of LSF Parameters Using a Deep Autoencoder and Pyramid Vector Quantizer", ["Yaxing Li", "Eshete Derb Emiru", "Shengwu Xiong", "Anna Zhu", "Pengfei Duan", "Yichang Li"], "https://doi.org/10.21437/Interspeech.2018-2577", 5, "interspeech", 2018], ["Multi-frame Coding of LSF Parameters Using Block-Constrained Trellis Coded Vector Quantization", ["Yaxing Li", "Shan Xu", "Shengwu Xiong", "Anna Zhu", "Pengfei Duan", "Yueming Ding"], "https://doi.org/10.21437/Interspeech.2018-2578", 5, "interspeech", 2018]], "Laszlo Toth": [0, ["General Utterance-Level Feature Extraction for Classifying Crying Sounds, Atypical & Self-Assessed Affect and Heart Beats", ["Gabor Gosztolya", "Tamas Grosz", "Laszlo Toth"], "https://doi.org/10.21437/Interspeech.2018-1076", 5, "interspeech", 2018], ["Multi-Task Learning of Speech Recognition and Speech Synthesis Parameters for Ultrasound-based Silent Speech Interfaces", ["Laszlo Toth", "Gabor Gosztolya", "Tamas Grosz", "Alexandra Marko", "Tamas Gabor Csapo"], "https://doi.org/10.21437/Interspeech.2018-1078", 5, "interspeech", 2018]], "Amit Ashkenazi": [0, ["Fully Automatic Speaker Separation System, with Automatic Enrolling of Recurrent Speakers", ["Raphael Cohen", "Orgad Keller", "Jason Levy", "Russell Levy", "Micha Breakstone", "Amit Ashkenazi"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3034.html", 2, "interspeech", 2018]], "Lei He": [0, ["A New Glottal Neural Vocoder for Speech Synthesis", ["Yang Cui", "Xi Wang", "Lei He", "Frank K. Soong"], "https://doi.org/10.21437/Interspeech.2018-1757", 5, "interspeech", 2018], ["Influences of Fundamental Oscillation on Speaker Identification in Vocalic Utterances by Humans and Computers", ["Volker Dellwo", "Thayabaran Kathiresan", "Elisa Pellegrino", "Lei He", "Sandra Schwab", "Dieter Maurer"], "https://doi.org/10.21437/Interspeech.2018-2331", 5, "interspeech", 2018]], "Jithendra Vepa": [0, ["CACTAS - Collaborative Audio Categorization and Transcription for ASR Systems", ["Mithul Mathivanan", "Kinnera Saranu", "Abhishek Pandey", "Jithendra Vepa"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3029.html", 2, "interspeech", 2018], ["Hierarchical Accent Determination and Application in a Large Scale ASR System", ["Ramya Viswanathan", "Periyasamy Paramasivam", "Jithendra Vepa"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3030.html", 2, "interspeech", 2018], ["Speech Emotion Recognition Using Spectrogram & Phoneme Embedding", ["Promod Yenigalla", "Abhay Kumar", "Suraj Tripathi", "Chirag Singh", "Sibsambhu Kar", "Jithendra Vepa"], "https://doi.org/10.21437/Interspeech.2018-1811", 5, "interspeech", 2018], ["Leveraging Second-Order Log-Linear Model for Improved Deep Learning Based ASR Performance", ["Ankit Raj", "Shakti P. Rath", "Jithendra Vepa"], "https://doi.org/10.21437/Interspeech.2018-1156", 5, "interspeech", 2018]], "Sishir Kalita": [0, ["Analysis of Breathiness in Contextual Vowel of Voiceless Nasals in Mizo", ["Pamir Gogoi", "Sishir Kalita", "Parismita Gogoi", "Ratree Wayland", "Priyankoo Sarmah", "S. R. Mahadeva Prasanna"], "https://doi.org/10.21437/Interspeech.2018-1899", 5, "interspeech", 2018], ["Self-similarity Matrix Based Intelligibility Assessment of Cleft Lip and Palate Speech", ["Sishir Kalita", "S. R. Mahadeva Prasanna", "Samarendra Dandapat"], "https://doi.org/10.21437/Interspeech.2018-1125", 5, "interspeech", 2018], ["Exploration of Compressed ILPR Features for Replay Attack Detection", ["Sarfaraz Jelil", "Sishir Kalita", "S. R. Mahadeva Prasanna", "Rohit Sinha"], "https://doi.org/10.21437/Interspeech.2018-1297", 5, "interspeech", 2018], ["Processing Transition Regions of Glottal Stop Substituted /S/ for Intelligibility Enhancement of Cleft Palate Speech", ["Protima Nomo Sudro", "Sishir Kalita", "S. R. Mahadeva Prasanna"], "https://doi.org/10.21437/Interspeech.2018-1646", 5, "interspeech", 2018], ["Estimation of Hypernasality Scores from Cleft Lip and Palate Speech", ["Vikram C. M.", "Ayush Tripathi", "Sishir Kalita", "S. R. Mahadeva Prasanna"], "https://doi.org/10.21437/Interspeech.2018-1631", 5, "interspeech", 2018]], "Jeesun Kim": [0.9742622375488281, ["Investigating the Role of Familiar Face and Voice Cues in Speech Processing in Noise", ["Jeesun Kim", "Sonya Karisma", "Vincent Aubanel", "Chris Davis"], "https://doi.org/10.21437/Interspeech.2018-1812", 4, "interspeech", 2018], ["Characterizing Rhythm Differences between Strong and Weak Accented L2 Speech", ["Chris Davis", "Jeesun Kim"], "https://doi.org/10.21437/Interspeech.2018-1798", 5, "interspeech", 2018]], "Chong Cao": [0, ["Interactions between Vowels and Nasal Codas in Mandarin Speakers' Perception of Nasal Finals", ["Chong Cao", "Wei Wei", "Wei Wang", "Yanlu Xie", "Jinsong Zhang"], "https://doi.org/10.21437/Interspeech.2018-2025", 5, "interspeech", 2018]], "Jithendar Anumula": [0, ["Multi-channel Attention for End-to-End Speech Recognition", ["Stefan Braun", "Daniel Neil", "Jithendar Anumula", "Enea Ceolini", "Shih-Chii Liu"], "https://doi.org/10.21437/Interspeech.2018-1301", 5, "interspeech", 2018], ["Speaker Activity Detection and Minimum Variance Beamforming for Source Separation", ["Enea Ceolini", "Jithendar Anumula", "Adrian E. G. Huber", "Ilya Kiselev", "Shih-Chii Liu"], "https://doi.org/10.21437/Interspeech.2018-1606", 5, "interspeech", 2018]], "Ali Azarbayejani": [0, ["Attention-based Sequence Classification for Affect Detection", ["Cristina Gorrostieta", "Richard Brutti", "Kye Taylor", "Avi Shapiro", "Joseph Moran", "Ali Azarbayejani", "John Kane"], "https://doi.org/10.21437/Interspeech.2018-1610", 5, "interspeech", 2018]], "Qiusi Dong": [2.889376844450453e-07, ["Pitch Characteristics of L2 English Speech by Chinese Speakers: A Large-scale Study", ["Jiahong Yuan", "Qiusi Dong", "Fei Wu", "Huan Luan", "Xiaofei Yang", "Hui Lin", "Yang Liu"], "https://doi.org/10.21437/Interspeech.2018-1556", 5, "interspeech", 2018]], "Jochen Weiner": [0, ["Investigating the Effect of Audio Duration on Dementia Detection Using Acoustic Features", ["Jochen Weiner", "Miguel Angrick", "Srinivasan Umesh", "Tanja Schultz"], "https://doi.org/10.21437/Interspeech.2018-57", 5, "interspeech", 2018]], "Xizi Wei": [0, ["Overview of the 2018 Spoken CALL Shared Task", ["Claudia Baur", "Andrew Caines", "Cathy Chua", "Johanna Gerlach", "Mengjie Qian", "Manny Rayner", "Martin J. Russell", "Helmer Strik", "Xizi Wei"], "https://doi.org/10.21437/Interspeech.2018-97", 5, "interspeech", 2018], ["The University of Birmingham 2018 Spoken CALL Shared Task Systems", ["Mengjie Qian", "Xizi Wei", "Peter Jancovic", "Martin J. Russell"], "https://doi.org/10.21437/Interspeech.2018-1372", 5, "interspeech", 2018]], "Patrick L. Lange": [0, ["Game-based Spoken Dialog Language Learning Applications for Young Students", ["Keelan Evanini", "Veronika Timpe-Laughlin", "Eugene Tsuprun", "Ian Blood", "Jeremy Lee", "James V. Bruno", "Vikram Ramanarayanan", "Patrick L. Lange", "David Suendermann-Oeft"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3045.html", 2, "interspeech", 2018], ["Toward Scalable Dialog Technology for Conversational Language Learning: Case Study of the TOEFL\u00ae MOOC", ["Vikram Ramanarayanan", "David Pautler", "Patrick L. Lange", "Eugene Tsuprun", "Rutuja Ubale", "Keelan Evanini", "David Suendermann-Oeft"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3032.html", 2, "interspeech", 2018]], "Anshul Thakur": [0, ["All-Conv Net for Bird Activity Detection: Significance of Learned Pooling", ["Arjun Pankajakshan", "Anshul Thakur", "Daksh Thapar", "Padmanabhan Rajan", "Aditya Nigam"], "https://doi.org/10.21437/Interspeech.2018-1522", 5, "interspeech", 2018], ["Deep Convex Representations: Feature Representations for Bioacoustics Classification", ["Anshul Thakur", "Vinayak Abrol", "Pulkit Sharma", "Padmanabhan Rajan"], "https://doi.org/10.21437/Interspeech.2018-1705", 5, "interspeech", 2018], ["ASe: Acoustic Scene Embedding Using Deep Archetypal Analysis and GMM", ["Pulkit Sharma", "Vinayak Abrol", "Anshul Thakur"], "https://doi.org/10.21437/Interspeech.2018-1481", 5, "interspeech", 2018]], "Pavan Karjol": [0, ["Speech Enhancement Using Deep Mixture of Experts Based on Hard Expectation Maximization", ["Pavan Karjol", "Prasanta Kumar Ghosh"], "https://doi.org/10.21437/Interspeech.2018-1730", 5, "interspeech", 2018]], "Jee-weon Jung": [0.9995425939559937, ["Avoiding Speaker Overfitting in End-to-End DNNs Using Raw Waveform for Text-Independent Speaker Verification", ["Jee-weon Jung", "Hee-Soo Heo", "Il-Ho Yang", "Hye-jin Shim", "Ha-Jin Yu"], "https://doi.org/10.21437/Interspeech.2018-1608", 5, "interspeech", 2018]], "Jer-Ming Chen": [0, ["Automated Classification of Vowel-Gesture Parameters Using External Broadband Excitation", ["Balamurali B. T", "Jer-Ming Chen"], "https://doi.org/10.21437/Interspeech.2018-1756", 4, "interspeech", 2018]], "Michael Chen": [0, ["Depression Detection from Short Utterances via Diverse Smartphones in Natural Environmental Conditions", ["Zhaocheng Huang", "Julien Epps", "Dale Joachim", "Michael Chen"], "https://doi.org/10.21437/Interspeech.2018-1743", 5, "interspeech", 2018]], "Arun Narayanan": [0, ["Domain Adaptation Using Factorized Hidden Layer for Robust Automatic Speech Recognition", ["Khe Chai Sim", "Arun Narayanan", "Ananya Misra", "Anshuman Tripathi", "Golan Pundak", "Tara N. Sainath", "Parisa Haghani", "Bo Li", "Michiel Bacchiani"], "https://doi.org/10.21437/Interspeech.2018-2246", 5, "interspeech", 2018], ["Efficient Implementation of the Room Simulator for Training Deep Neural Network Acoustic Models", ["Chanwoo Kim", "Ehsan Variani", "Arun Narayanan", "Michiel Bacchiani"], "https://doi.org/10.21437/Interspeech.2018-2566", 5, "interspeech", 2018]], "Xiaoke Qi": [0, ["Sparsity-Constrained Weight Mapping for Head-Related Transfer Functions Individualization from Anthropometric Features", ["Xiaoke Qi", "Jianhua Tao"], "https://doi.org/10.21437/Interspeech.2018-1615", 5, "interspeech", 2018]], "Cong-Thanh Do": [3.3881790386658395e-06, ["Weighting Time-Frequency Representation of Speech Using Auditory Saliency for Automatic Speech Recognition", ["Cong-Thanh Do", "Yannis Stylianou"], "https://doi.org/10.21437/Interspeech.2018-1721", 5, "interspeech", 2018]], "Xiaorui Wang": [8.41449110909609e-12, ["Gated Recurrent Unit Based Acoustic Modeling with Future Context", ["Jie Li", "Xiaorui Wang", "Yuanyuan Zhao", "Yan Li"], "https://doi.org/10.21437/Interspeech.2018-1544", 5, "interspeech", 2018]], "Ji-Chen Yang": [0.00023265991330845281, ["Feature with Complementarity of Statistics and Principal Information for Spoofing Detection", ["Ji-Chen Yang", "Changhuai You", "Qianhua He"], "https://doi.org/10.21437/Interspeech.2018-1693", 5, "interspeech", 2018]], "Sarah Verhulst": [0, ["Biophysically-inspired Features Improve the Generalizability of Neural Network-based Speech Enhancement Systems", ["Deepak Baby", "Sarah Verhulst"], "https://doi.org/10.21437/Interspeech.2018-1237", 5, "interspeech", 2018]], "Sunit Sivasankaran": [0, ["Keyword Based Speaker Localization: Localizing a Target Speaker in a Multi-speaker Environment", ["Sunit Sivasankaran", "Emmanuel Vincent", "Dominique Fohr"], "https://doi.org/10.21437/Interspeech.2018-1526", 5, "interspeech", 2018]], "Joyanta Basu": [0, ["PannoMulloKathan: Voice Enabled Mobile App for Agricultural Commodity Price Dissemination in Bengali Language", ["Madhab Pal", "Rajib Roy", "Soma Khan", "Milton Samirakshma Bepari", "Joyanta Basu"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3027.html", 2, "interspeech", 2018]], "Umar Saif": [0, ["Rapid Collection of Spontaneous Speech Corpora Using Telephonic Community Forums", ["Agha Ali Raza", "Awais Athar", "Shan Randhawa", "Zain Tariq", "Muhammad Bilal Saleem", "Haris Bin Zia", "Umar Saif", "Roni Rosenfeld"], "https://doi.org/10.21437/Interspeech.2018-1139", 5, "interspeech", 2018]], "Igor Szoke": [0, ["BUT OpenSAT 2017 Speech Recognition System", ["Martin Karafiat", "Murali Karthick Baskar", "Igor Szoke", "Vladimir Malenovsky", "Karel Vesely", "Frantisek Grezl", "Lukas Burget", "Jan Cernocky"], "https://doi.org/10.21437/Interspeech.2018-2457", 5, "interspeech", 2018], ["Lightly Supervised vs. Semi-supervised Training of Acoustic Model on Luxembourgish for Low-resource Automatic Speech Recognition", ["Karel Vesely", "Carlos Segura", "Igor Szoke", "Jordi Luque", "Jan Cernocky"], "https://doi.org/10.21437/Interspeech.2018-2361", 5, "interspeech", 2018]], "Atul Rai": [0, ["Learning Discriminative Features for Speaker Identification and Verification", ["Sarthak Yadav", "Atul Rai"], "https://doi.org/10.21437/Interspeech.2018-1015", 5, "interspeech", 2018]], "Jiacen Zhang": [0, ["I-vector Transformation Using Conditional Generative Adversarial Networks for Short Utterance Speaker Verification", ["Jiacen Zhang", "Nakamasa Inoue", "Koichi Shinoda"], "https://doi.org/10.21437/Interspeech.2018-1680", 5, "interspeech", 2018]], "Changhuai You": [0, ["Feature with Complementarity of Statistics and Principal Information for Spoofing Detection", ["Ji-Chen Yang", "Changhuai You", "Qianhua He"], "https://doi.org/10.21437/Interspeech.2018-1693", 5, "interspeech", 2018]], "Johanna Rudolph": [0, ["Fusing Text-dependent Word-level i-Vector Models to Screen 'at Risk' Child Speech", ["Prasanna V. Kothalkar", "Johanna Rudolph", "Christine Dollaghan", "Jennifer McGlothlin", "Thomas F. Campbell", "John H. L. Hansen"], "https://doi.org/10.21437/Interspeech.2018-1465", 5, "interspeech", 2018]], "John J. Soraghan": [0, ["A Deep Learning Method for Pathological Voice Detection Using Convolutional Deep Belief Networks", ["Huiyi Wu", "John J. Soraghan", "Anja Lowit", "Gaetano Di Caterina"], "https://doi.org/10.21437/Interspeech.2018-1351", 5, "interspeech", 2018]], "Mauricio Cerda": [0, ["A French-Spanish Multimodal Speech Communication Corpus Incorporating Acoustic Data, Facial, Hands and Arms Gestures Information", ["Lucas D. Terissi", "Gonzalo D. Sad", "Mauricio Cerda", "Slim Ouni", "Rodrigo Galvez", "Juan Carlos Gomez", "Bernard Girau", "Nancy Hitschfeld-Kahler"], "https://doi.org/10.21437/Interspeech.2018-2212", 5, "interspeech", 2018]], "Qiang Fang": [0, ["Tongue Segmentation with Geometrically Constrained Snake Model", ["Zhihua Su", "Jianguo Wei", "Qiang Fang", "Jianrong Wang", "Kiyoshi Honda"], "https://doi.org/10.21437/Interspeech.2018-1108", 5, "interspeech", 2018]], "Bekir Berker Turker": [0, ["Audio-Visual Prediction of Head-Nod and Turn-Taking Events in Dyadic Interactions", ["Bekir Berker Turker", "Engin Erzin", "Yucel Yemez", "T. Metin Sezgin"], "https://doi.org/10.21437/Interspeech.2018-2215", 5, "interspeech", 2018]], "Zixing Zhang": [0, ["Evolving Learning for Analysing Mood-Related Infant Vocalisation", ["Zixing Zhang", "Jing Han", "Kun Qian", "Bjorn W. Schuller"], "https://doi.org/10.21437/Interspeech.2018-1914", 5, "interspeech", 2018], ["Exploring Spatio-Temporal Representations by Integrating Attention-based Bidirectional-LSTM-RNNs and FCNs for Speech Emotion Recognition", ["Ziping Zhao", "Yu Zheng", "Zixing Zhang", "Haishuai Wang", "Yiqin Zhao", "Chao Li"], "https://doi.org/10.21437/Interspeech.2018-1477", 5, "interspeech", 2018], ["Automated Classification of Children's Linguistic versus Non-Linguistic Vocalisations", ["Zixing Zhang", "Alejandrina Cristia", "Anne A. Warlaumont", "Bjorn W. Schuller"], "https://doi.org/10.21437/Interspeech.2018-2523", 5, "interspeech", 2018], ["Bags in Bag: Generating Context-Aware Bags for Tracking Emotions from Speech", ["Jing Han", "Zixing Zhang", "Maximilian Schmitt", "Zhao Ren", "Fabien Ringeval", "Bjorn W. Schuller"], "https://doi.org/10.21437/Interspeech.2018-996", 5, "interspeech", 2018]], "Slim Ouni": [0, ["A French-Spanish Multimodal Speech Communication Corpus Incorporating Acoustic Data, Facial, Hands and Arms Gestures Information", ["Lucas D. Terissi", "Gonzalo D. Sad", "Mauricio Cerda", "Slim Ouni", "Rodrigo Galvez", "Juan Carlos Gomez", "Bernard Girau", "Nancy Hitschfeld-Kahler"], "https://doi.org/10.21437/Interspeech.2018-2212", 5, "interspeech", 2018], ["Phoneme-to-Articulatory Mapping Using Bidirectional Gated RNN", ["Theo Biasutto-Lervat", "Slim Ouni"], "https://doi.org/10.21437/Interspeech.2018-1202", 5, "interspeech", 2018]], "Dilip Kumar Margam": [0, ["Global SNR Estimation of Speech Signals Using Entropy and Uncertainty Estimates from Dropout Networks", ["Rohith Aralikatti", "Dilip Kumar Margam", "Tanay Sharma", "Abhinav Thanda", "Shankar M. Venkatesan"], "https://doi.org/10.21437/Interspeech.2018-1884", 5, "interspeech", 2018]], "Linzhong Xia": [0, ["Factorized Deep Neural Network Adaptation for Automatic Scoring of L2 Speech in English Speaking Tests", ["Dean Luo", "Chunxiao Zhang", "Linzhong Xia", "Lixin Wang"], "https://doi.org/10.21437/Interspeech.2018-2138", 5, "interspeech", 2018]], "Jitendra Kumar Dhiman": [0, ["Multicomponent 2-D AM-FM Modeling of Speech Spectrograms", ["Jitendra Kumar Dhiman", "Neeraj Sharma", "Chandra Sekhar Seelamantula"], "https://doi.org/10.21437/Interspeech.2018-1937", 5, "interspeech", 2018]], "Paola Escudero": [0, ["Perceptual Sensitivity to Spectral Change in Australian English Close Front Vowels: An Electroencephalographic Investigation", ["Daniel Williams", "Paola Escudero", "Adamantios I. Gafos"], "https://doi.org/10.21437/Interspeech.2018-2505", 5, "interspeech", 2018]], "Ming-Ya Ko": [0.00966183515265584, ["Self-Assessed Affect Recognition Using Fusion of Attentional BLSTM and Static Acoustic Features", ["Bo-Hao Su", "Sung-Lin Yeh", "Ming-Ya Ko", "Huan-Yu Chen", "Shun-Chang Zhong", "Jeng-Lin Li", "Chi-Chun Lee"], "https://doi.org/10.21437/Interspeech.2018-2261", 5, "interspeech", 2018]], "Ming Tu": [0, ["A Discriminative Acoustic-Prosodic Approach for Measuring Local Entrainment", ["Megan M. Willi", "Stephanie A. Borrie", "Tyson S. Barrett", "Ming Tu", "Visar Berisha"], "https://doi.org/10.21437/Interspeech.2018-1419", 5, "interspeech", 2018], ["Investigating the Role of L1 in Automatic Pronunciation Evaluation of L2 Speech", ["Ming Tu", "Anna Grabek", "Julie Liss", "Visar Berisha"], "https://doi.org/10.21437/Interspeech.2018-1350", 5, "interspeech", 2018]], "Antonio Bonafonte": [0, ["Visualizing Punctuation Restoration in Speech Transcripts with Prosograph", ["Alp Oktem", "Mireia Farrus", "Antonio Bonafonte"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3028.html", 2, "interspeech", 2018], ["Spanish Statistical Parametric Speech Synthesis Using a Neural Vocoder", ["Antonio Bonafonte", "Santiago Pascual", "Georgina Dorca"], "https://doi.org/10.21437/Interspeech.2018-2417", 4, "interspeech", 2018], ["Expressive Speech Synthesis Using Sentiment Embeddings", ["Igor Jauk", "Jaime Lorenzo-Trueba", "Junichi Yamagishi", "Antonio Bonafonte"], "https://doi.org/10.21437/Interspeech.2018-2467", 5, "interspeech", 2018]], "Jurgen Schmidhuber": [0, ["Domain-Adversarial Training for Session Independent EMG-based Speech Recognition", ["Michael Wand", "Tanja Schultz", "Jurgen Schmidhuber"], "https://doi.org/10.21437/Interspeech.2018-2318", 5, "interspeech", 2018]], "Heejin Choi": [0.9188794493675232, ["Korean Singing Voice Synthesis Based on an LSTM Recurrent Neural Network", ["Juntae Kim", "Heejin Choi", "Jinuk Park", "Minsoo Hahn", "Sang-Jin Kim", "Jong-Jin Kim"], "https://doi.org/10.21437/Interspeech.2018-1575", 5, "interspeech", 2018]], "Thomas Hain": [0, ["On the Usefulness of the Speech Phase Spectrum for Pitch Extraction", ["Erfan Loweimi", "Jon Barker", "Thomas Hain"], "https://doi.org/10.21437/Interspeech.2018-1062", 5, "interspeech", 2018], ["Improved Acoustic Modelling for Automatic Literacy Assessment of Children", ["Mauro Nicolao", "Michiel Sanders", "Thomas Hain"], "https://doi.org/10.21437/Interspeech.2018-2118", 5, "interspeech", 2018]], "Ken-Ichi Sakakibara": [0, ["Frequency Domain Variants of Velvet Noise and Their Application to Speech Processing and Synthesis", ["Hideki Kawahara", "Ken-Ichi Sakakibara", "Masanori Morise", "Hideki Banno", "Tomoki Toda", "Toshio Irino"], "https://doi.org/10.21437/Interspeech.2018-43", 5, "interspeech", 2018]], "Saketh Sharma": [0, ["Implementation of Digital Hearing Aid as a Smartphone Application", ["Saketh Sharma", "Nitya Tiwari", "Prem C. Pandey"], "https://doi.org/10.21437/Interspeech.2018-2031", 5, "interspeech", 2018]], "Shiva Sundaram": [0, ["Detecting Media Sound Presence in Acoustic Scenes", ["Constantinos Papayiannis", "Justice Amoh", "Viktor Rozgic", "Shiva Sundaram", "Chao Wang"], "https://doi.org/10.21437/Interspeech.2018-2559", 5, "interspeech", 2018]], "Frank Broz": [0, ["Who Said That? a Comparative Study of Non-negative Matrix Factorization Techniques", ["Teun F. Krikke", "Frank Broz", "David Lane"], "https://doi.org/10.21437/Interspeech.2018-1807", 5, "interspeech", 2018]], "Samarjit Das": [0, ["Multiple Instance Deep Learning for Weakly Supervised Small-Footprint Audio Event Detection", ["Shao-Yen Tseng", "Juncheng Li", "Yun Wang", "Florian Metze", "Joseph Szurley", "Samarjit Das"], "https://doi.org/10.21437/Interspeech.2018-1120", 5, "interspeech", 2018]], "Katsuya Takanashi": [0, ["Engagement Recognition in Spoken Dialogue via Neural Network by Aggregating Different Annotators' Models", ["Koji Inoue", "Divesh Lala", "Katsuya Takanashi", "Tatsuya Kawahara"], "https://doi.org/10.21437/Interspeech.2018-2067", 5, "interspeech", 2018], ["Prediction of Turn-taking Using Multitask Learning with Prediction of Backchannels and Fillers", ["Kohei Hara", "Koji Inoue", "Katsuya Takanashi", "Tatsuya Kawahara"], "https://doi.org/10.21437/Interspeech.2018-1442", 5, "interspeech", 2018]], "Yusuke Inoue": [0, ["A Study of Objective Measurement of Comprehensibility through Native Speakers' Shadowing of Learners' Utterances", ["Yusuke Inoue", "Suguru Kabashima", "Daisuke Saito", "Nobuaki Minematsu", "Kumi Kanamura", "Yutaka Yamauchi"], "https://doi.org/10.21437/Interspeech.2018-1860", 5, "interspeech", 2018]], "Allen R. Stauffer": [0, ["Robust Speaker Recognition from Distant Speech under Real Reverberant Environments Using Speaker Embeddings", ["Mahesh Kumar Nandwana", "Julien van Hout", "Mitchell McLaren", "Allen R. Stauffer", "Colleen Richey", "Aaron Lawson", "Martin Graciarena"], "https://doi.org/10.21437/Interspeech.2018-2221", 5, "interspeech", 2018], ["Voices Obscured in Complex Environmental Settings (VOiCES) Corpus", ["Colleen Richey", "Maria Auxiliadora Barrios", "Zeb Armstrong", "Chris Bartels", "Horacio Franco", "Martin Graciarena", "Aaron Lawson", "Mahesh Kumar Nandwana", "Allen R. Stauffer", "Julien van Hout", "Paul Gamble", "Jeffrey Hetherly", "Cory Stephenson", "Karl Ni"], "https://doi.org/10.21437/Interspeech.2018-1454", 5, "interspeech", 2018]], "Hao Li": [0, ["EMPHASIS: An Emotional Phoneme-based Acoustic Model for Speech Synthesis System", ["Hao Li", "Yongguo Kang", "Zhenyu Wang"], "https://doi.org/10.21437/Interspeech.2018-1511", 5, "interspeech", 2018]], "Sergey Novoselov": [0, ["Triplet Loss Based Cosine Similarity Metric Learning for Text-independent Speaker Recognition", ["Sergey Novoselov", "Vadim Shchemelinin", "Andrey Shulipa", "Alexander Kozlov", "Ivan Kremnev"], "https://doi.org/10.21437/Interspeech.2018-1209", 5, "interspeech", 2018]], "Mithul Mathivanan": [0, ["CACTAS - Collaborative Audio Categorization and Transcription for ASR Systems", ["Mithul Mathivanan", "Kinnera Saranu", "Abhishek Pandey", "Jithendra Vepa"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3029.html", 2, "interspeech", 2018]], "Kassandra Martinez": [0, ["A Knowledge Driven Structural Segmentation Approach for Play-Talk Classification During Autism Assessment", ["Manoj Kumar", "Pooja Chebolu", "So Hyun Kim", "Kassandra Martinez", "Catherine Lord", "Shrikanth Narayanan"], "https://doi.org/10.21437/Interspeech.2018-1516", 5, "interspeech", 2018]], "Zhi-Ping Zhou": [0, ["Learning and Modeling Unit Embeddings for Improving HMM-based Unit Selection Speech Synthesis", ["Xiao Zhou", "Zhen-Hua Ling", "Zhi-Ping Zhou", "Li-Rong Dai"], "https://doi.org/10.21437/Interspeech.2018-1198", 5, "interspeech", 2018]], "Hisashi Kawai": [0, ["Temporal Attentive Pooling for Acoustic Event Detection", ["Xugang Lu", "Peng Shen", "Sheng Li", "Yu Tsao", "Hisashi Kawai"], "https://doi.org/10.21437/Interspeech.2018-1552", 4, "interspeech", 2018], ["Feature Representation of Short Utterances Based on Knowledge Distillation for Spoken Language Identification", ["Peng Shen", "Xugang Lu", "Sheng Li", "Hisashi Kawai"], "https://doi.org/10.21437/Interspeech.2018-1519", 5, "interspeech", 2018], ["Multilingual Grapheme-to-Phoneme Conversion with Global Character Vectors", ["Jinfu Ni", "Yoshinori Shiga", "Hisashi Kawai"], "https://doi.org/10.21437/Interspeech.2018-1626", 5, "interspeech", 2018], ["Improving CTC-based Acoustic Model with Very Deep Residual Time-delay Neural Networks", ["Sheng Li", "Xugang Lu", "Ryoichi Takashima", "Peng Shen", "Tatsuya Kawahara", "Hisashi Kawai"], "https://doi.org/10.21437/Interspeech.2018-1475", 5, "interspeech", 2018]], "Koichi Shinoda": [0, ["Detecting Alzheimer's Disease Using Gated Convolutional Neural Network from Audio Data", ["Tifani Warnita", "Nakamasa Inoue", "Koichi Shinoda"], "https://doi.org/10.21437/Interspeech.2018-1713", 5, "interspeech", 2018], ["Attentive Statistics Pooling for Deep Speaker Embedding", ["Koji Okabe", "Takafumi Koshinaka", "Koichi Shinoda"], "https://doi.org/10.21437/Interspeech.2018-993", 5, "interspeech", 2018], ["I-vector Transformation Using Conditional Generative Adversarial Networks for Short Utterance Speaker Verification", ["Jiacen Zhang", "Nakamasa Inoue", "Koichi Shinoda"], "https://doi.org/10.21437/Interspeech.2018-1680", 5, "interspeech", 2018]], "Koji Okabe": [0, ["Attentive Statistics Pooling for Deep Speaker Embedding", ["Koji Okabe", "Takafumi Koshinaka", "Koichi Shinoda"], "https://doi.org/10.21437/Interspeech.2018-993", 5, "interspeech", 2018]], "Stefanos Zafeiriou": [0, ["The INTERSPEECH 2018 Computational Paralinguistics Challenge: Atypical & Self-Assessed Affect, Crying & Heart Beats", ["Bjorn W. Schuller", "Stefan Steidl", "Anton Batliner", "Peter B. Marschik", "Harald Baumeister", "Fengquan Dong", "Simone Hantke", "Florian B. Pokorny", "Eva-Maria Rathner", "Katrin D. Bartl-Pokorny", "Christa Einspieler", "Dajie Zhang", "Alice Baird", "Shahin Amiriparian", "Kun Qian", "Zhao Ren", "Maximilian Schmitt", "Panagiotis Tzirakis", "Stefanos Zafeiriou"], "https://doi.org/10.21437/Interspeech.2018-51", 5, "interspeech", 2018]], "Noelia Do Carmo Blanco": [0, ["Loud and Shouted Speech Perception at Variable Distances in a Forest", ["Julien Meyer", "Fanny Meunier", "Laure Dentel", "Noelia Do Carmo Blanco", "Frederic Sebe"], "https://doi.org/10.21437/Interspeech.2018-2089", 5, "interspeech", 2018], ["Phoneme Resistance and Phoneme Confusion in Noise: Impact of Dyslexia", ["Noelia Do Carmo Blanco", "Julien Meyer", "Michel Hoen", "Fanny Meunier"], "https://doi.org/10.21437/Interspeech.2018-1271", 5, "interspeech", 2018]], "Promod Yenigalla": [0, ["Speech Emotion Recognition Using Spectrogram & Phoneme Embedding", ["Promod Yenigalla", "Abhay Kumar", "Suraj Tripathi", "Chirag Singh", "Sibsambhu Kar", "Jithendra Vepa"], "https://doi.org/10.21437/Interspeech.2018-1811", 5, "interspeech", 2018]], "Sunil Kumar Kopparapu": [0, ["Dysarthric Speech Recognition Using Time-delay Neural Network Based Denoising Autoencoder", ["Chitralekha Bhat", "Biswajit Das", "Bhavik Vachhani", "Sunil Kumar Kopparapu"], "https://doi.org/10.21437/Interspeech.2018-1754", 5, "interspeech", 2018], ["Data Augmentation Using Healthy Speech for Dysarthric Speech Recognition", ["Bhavik Vachhani", "Chitralekha Bhat", "Sunil Kumar Kopparapu"], "https://doi.org/10.21437/Interspeech.2018-1751", 5, "interspeech", 2018], ["Analysis of the Effect of Speech-Laugh on Speaker Recognition System", ["Sri Harsha Dumpala", "Ashish Panda", "Sunil Kumar Kopparapu"], "https://doi.org/10.21437/Interspeech.2018-2090", 5, "interspeech", 2018]], "Thomas Schneider": [0, ["VoiceGuard: Secure and Private Speech Processing", ["Ferdinand Brasser", "Tommaso Frassetto", "Korbinian Riedhammer", "Ahmad-Reza Sadeghi", "Thomas Schneider", "Christian Weinert"], "https://doi.org/10.21437/Interspeech.2018-2032", 5, "interspeech", 2018]], "H. Timothy Bunnell": [0, ["The Use of Machine Learning and Phonetic Endophenotypes to Discover Genetic Variants Associated with Speech Sound Disorder", ["Jason Lilley", "Erin Crowgey", "H. Timothy Bunnell"], "https://doi.org/10.21437/Interspeech.2018-2398", 5, "interspeech", 2018]], "Ankur T. Patil": [0, ["DA-IICT/IIITV System for Low Resource Speech Recognition Challenge 2018", ["Hardik B. Sailor", "Maddala Venkata Siva Krishna", "Diksha Chhabra", "Ankur T. Patil", "Madhu R. Kamble", "Hemant A. Patil"], "https://doi.org/10.21437/Interspeech.2018-1553", 5, "interspeech", 2018]], "Sarthak Yadav": [0, ["Learning Discriminative Features for Speaker Identification and Verification", ["Sarthak Yadav", "Atul Rai"], "https://doi.org/10.21437/Interspeech.2018-1015", 5, "interspeech", 2018]], "Mengjie Qian": [0, ["Overview of the 2018 Spoken CALL Shared Task", ["Claudia Baur", "Andrew Caines", "Cathy Chua", "Johanna Gerlach", "Mengjie Qian", "Manny Rayner", "Martin J. Russell", "Helmer Strik", "Xizi Wei"], "https://doi.org/10.21437/Interspeech.2018-97", 5, "interspeech", 2018], ["The CSU-K Rule-Based System for the 2nd Edition Spoken CALL Shared Task", ["Dominik Julg", "Mario Kunstek", "Cem Philipp Freimoser", "Kay Berkling", "Mengjie Qian"], "https://doi.org/10.21437/Interspeech.2018-1000", 5, "interspeech", 2018], ["The University of Birmingham 2018 Spoken CALL Shared Task Systems", ["Mengjie Qian", "Xizi Wei", "Peter Jancovic", "Martin J. Russell"], "https://doi.org/10.21437/Interspeech.2018-1372", 5, "interspeech", 2018], ["Phone Recognition Using a Non-Linear Manifold with Broad Phone Class Dependent DNNs", ["Mengjie Qian", "Linxue Bai", "Peter Jancovic", "Martin J. Russell"], "https://doi.org/10.21437/Interspeech.2018-1376", 5, "interspeech", 2018]], "Helmer Strik": [0, ["Overview of the 2018 Spoken CALL Shared Task", ["Claudia Baur", "Andrew Caines", "Cathy Chua", "Johanna Gerlach", "Mengjie Qian", "Manny Rayner", "Martin J. Russell", "Helmer Strik", "Xizi Wei"], "https://doi.org/10.21437/Interspeech.2018-97", 5, "interspeech", 2018]], "Parth Suresh": [0, ["Subband Weighting for Binaural Speech Source Localization", ["Girija Ramesan Karthik", "Parth Suresh", "Prasanta Kumar Ghosh"], "https://doi.org/10.21437/Interspeech.2018-2173", 5, "interspeech", 2018]], "Phil Howson": [0, ["Gestural Lenition of Rhotics Captures Variation in Brazilian Portuguese", ["Phil Howson", "Alexei Kochetov"], "https://doi.org/10.21437/Interspeech.2018-1404", 5, "interspeech", 2018]], "Mirko Hannemann": [0, ["Segmental Encoder-Decoder Models for Large Vocabulary Automatic Speech Recognition", ["Eugen Beck", "Mirko Hannemann", "Patrick Dotsch", "Ralf Schluter", "Hermann Ney"], "https://doi.org/10.21437/Interspeech.2018-1212", 5, "interspeech", 2018]], "Katherine Chou": [0, ["Speech Recognition for Medical Conversations", ["Chung-Cheng Chiu", "Anshuman Tripathi", "Katherine Chou", "Chris Co", "Navdeep Jaitly", "Diana Jaunzeikare", "Anjuli Kannan", "Patrick Nguyen", "Hasim Sak", "Ananth Sankar", "Justin Tansuwan", "Nathan Wan", "Yonghui Wu", "Xuedong Zhang"], "https://doi.org/10.21437/Interspeech.2018-40", 5, "interspeech", 2018]], "Wei Zhang": [0, ["A Preliminary Study on Tonal Coarticulation in Continuous Speech", ["Lixia Hao", "Wei Zhang", "Yanlu Xie", "Jinsong Zhang"], "https://doi.org/10.21437/Interspeech.2018-1849", 5, "interspeech", 2018]], "Prasanta Kumar Ghosh": [0, ["Whispered Speech to Neutral Speech Conversion Using Bidirectional LSTMs", ["G. Nisha Meenakshi", "Prasanta Kumar Ghosh"], "https://doi.org/10.21437/Interspeech.2018-1487", 5, "interspeech", 2018], ["Intonation tutor by SPIRE (In-SPIRE): An Online Tool for an Automatic Feedback to the Second Language Learners in Learning Intonation", ["Anand P. A", "Chiranjeevi Yarra", "N. K. Kausthubha", "Prasanta Kumar Ghosh"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3008.html", 2, "interspeech", 2018], ["Subband Weighting for Binaural Speech Source Localization", ["Girija Ramesan Karthik", "Parth Suresh", "Prasanta Kumar Ghosh"], "https://doi.org/10.21437/Interspeech.2018-2173", 5, "interspeech", 2018], ["Reconstructing Neutral Speech from Tracheoesophageal Speech", ["Abinay Reddy N", "M. V. Achuth Rao", "G. Nisha Meenakshi", "Prasanta Kumar Ghosh"], "https://doi.org/10.21437/Interspeech.2018-1907", 5, "interspeech", 2018], ["SPIRE-SST: An Automatic Web-based Self-learning Tool for Syllable Stress Tutoring (SST) to the Second Language Learners", ["Chiranjeevi Yarra", "Anand P. A", "N. K. Kausthubha", "Prasanta Kumar Ghosh"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3009.html", 2, "interspeech", 2018], ["Relating Articulatory Motions in Different Speaking Rates", ["Astha Singh", "G. Nisha Meenakshi", "Prasanta Kumar Ghosh"], "https://doi.org/10.21437/Interspeech.2018-1862", 5, "interspeech", 2018], ["Automatic Glottis Localization and Segmentation in Stroboscopic Videos Using Deep Neural Network", ["M. V. Achuth Rao", "Rahul Krishnamurthy", "Pebbili Gopikishore", "Veeramani Priyadharshini", "Prasanta Kumar Ghosh"], "https://doi.org/10.21437/Interspeech.2018-2572", 5, "interspeech", 2018], ["Low Resource Acoustic-to-articulatory Inversion Using Bi-directional Long Short Term Memory", ["Aravind Illa", "Prasanta Kumar Ghosh"], "https://doi.org/10.21437/Interspeech.2018-1843", 5, "interspeech", 2018], ["Automatic Visual Augmentation for Concatenation Based Synthesized Articulatory Videos from Real-time MRI Data for Spoken Language Training", ["Chandana S", "Chiranjeevi Yarra", "Ritu Aggarwal", "Sanjeev Kumar Mittal", "N. K. Kausthubha", "Raseena K. T", "Astha Singh", "Prasanta Kumar Ghosh"], "https://doi.org/10.21437/Interspeech.2018-1570", 5, "interspeech", 2018], ["Air-Tissue Boundary Segmentation in Real-Time Magnetic Resonance Imaging Video Using Semantic Segmentation with Fully Convolutional Networks", ["C. A. Valliappan", "Renuka Mannem", "Prasanta Kumar Ghosh"], "https://doi.org/10.21437/Interspeech.2018-1939", 5, "interspeech", 2018], ["Speech Enhancement Using Deep Mixture of Experts Based on Hard Expectation Maximization", ["Pavan Karjol", "Prasanta Kumar Ghosh"], "https://doi.org/10.21437/Interspeech.2018-1730", 5, "interspeech", 2018]], "Iain Matthews": [0, ["Joint Learning of Facial Expression and Head Pose from Speech", ["David Greenwood", "Iain Matthews", "Stephen D. Laycock"], "https://doi.org/10.21437/Interspeech.2018-2587", 5, "interspeech", 2018]], "Srikanth R. Madikeri": [0, ["Analysis of Language Dependent Front-End for Speaker Recognition", ["Srikanth R. Madikeri", "Subhadeep Dey", "Petr Motlicek"], "https://doi.org/10.21437/Interspeech.2018-2071", 5, "interspeech", 2018], ["End-to-end Text-dependent Speaker Verification Using Novel Distance Measures", ["Subhadeep Dey", "Srikanth R. Madikeri", "Petr Motlicek"], "https://doi.org/10.21437/Interspeech.2018-2300", 5, "interspeech", 2018]], "Shi-wook Lee": [0.6669017821550369, ["Empirical Analysis of Score Fusion Application to Combined Neural Networks for Open Vocabulary Spoken Term Detection", ["Shi-wook Lee", "Kazuyo Tanaka", "Yoshiaki Itoh"], "https://doi.org/10.21437/Interspeech.2018-1776", 5, "interspeech", 2018]], "Md. Hafizur Rahman": [0, ["Employing Phonetic Information in DNN Speaker Embeddings to Improve Speaker Recognition Performance", ["Md. Hafizur Rahman", "Ivan Himawan", "Mitchell McLaren", "Clinton Fookes", "Sridha Sridharan"], "https://doi.org/10.21437/Interspeech.2018-1804", 5, "interspeech", 2018]], "Jayadev Billa": [0, ["ISI ASR System for the Low Resource Speech Recognition Challenge for Indian Languages", ["Jayadev Billa"], "https://doi.org/10.21437/Interspeech.2018-2473", 5, "interspeech", 2018]], "Bishnu S. Atal": [0, ["From Vocoders to Code-Excited Linear Prediction: Learning How We Hear What We Hear", ["Bishnu S. Atal"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/4001.html", 1, "interspeech", 2018]], "Jiqing Han": [5.275537318993884e-06, ["Unsupervised Temporal Feature Learning Based on Sparse Coding Embedded BoAW for Acoustic Event Recognition", ["Liwen Zhang", "Jiqing Han", "Shiwen Deng"], "https://doi.org/10.21437/Interspeech.2018-1243", 5, "interspeech", 2018], ["A Compact and Discriminative Feature Based on Auditory Summary Statistics for Acoustic Scene Classification", ["Hongwei Song", "Jiqing Han", "Shiwen Deng"], "https://doi.org/10.21437/Interspeech.2018-1299", 5, "interspeech", 2018]], "Jan Trmal": [0, ["The Fifth 'CHiME' Speech Separation and Recognition Challenge: Dataset, Task and Baselines", ["Jon Barker", "Shinji Watanabe", "Emmanuel Vincent", "Jan Trmal"], "https://doi.org/10.21437/Interspeech.2018-1768", 5, "interspeech", 2018], ["Automatic Speech Recognition and Topic Identification from Speech for Almost-Zero-Resource Languages", ["Matthew Wiesner", "Chunxi Liu", "Lucas Ondel", "Craig Harman", "Vimal Manohar", "Jan Trmal", "Zhongqiang Huang", "Najim Dehak", "Sanjeev Khudanpur"], "https://doi.org/10.21437/Interspeech.2018-1836", 5, "interspeech", 2018]], "Yujia Xiao": [0, ["Paired Phone-Posteriors Approach to ESL Pronunciation Quality Assessment", ["Yujia Xiao", "Frank K. Soong", "Wenping Hu"], "https://doi.org/10.21437/Interspeech.2018-1270", 5, "interspeech", 2018]], "Jinkun Chen": [0, ["Analysis of Length Normalization in End-to-End Speaker Verification System", ["Weicheng Cai", "Jinkun Chen", "Ming Li"], "https://doi.org/10.21437/Interspeech.2018-92", 5, "interspeech", 2018]], "Almeida Jacqueline Toribio": [0, ["Should Code-switching Models Be Asymmetric?", ["Barbara E. Bullock", "Gualberto A. Guzman", "Jacqueline Serigos", "Almeida Jacqueline Toribio"], "https://doi.org/10.21437/Interspeech.2018-1284", 5, "interspeech", 2018]], "Yoshua Bengio": [0, ["Quaternion Convolutional Neural Networks for End-to-End Automatic Speech Recognition", ["Titouan Parcollet", "Ying Zhang", "Mohamed Morchid", "Chiheb Trabelsi", "Georges Linares", "Renato de Mori", "Yoshua Bengio"], "https://doi.org/10.21437/Interspeech.2018-1898", 5, "interspeech", 2018], ["Twin Regularization for Online Speech Recognition", ["Mirco Ravanelli", "Dmitriy Serdyuk", "Yoshua Bengio"], "https://doi.org/10.21437/Interspeech.2018-1407", 5, "interspeech", 2018]], "Beena Ahmed": [0, ["Anomaly Detection Approach for Pronunciation Verification of Disordered Speech Using Speech Attribute Features", ["Mostafa Ali Shahin", "Beena Ahmed", "Jim X. Ji", "Kirrie J. Ballard"], "https://doi.org/10.21437/Interspeech.2018-1319", 5, "interspeech", 2018]], "Nicholas W. D. Evans": [0, ["Integrated Presentation Attack Detection and Automatic Speaker Verification: Common Features and Gaussian Back-end Fusion", ["Massimiliano Todisco", "Hector Delgado", "Kong-Aik Lee", "Md. Sahidullah", "Nicholas W. D. Evans", "Tomi Kinnunen", "Junichi Yamagishi"], "https://doi.org/10.21437/Interspeech.2018-2289", 5, "interspeech", 2018], ["Artificial Bandwidth Extension with Memory Inclusion Using Semi-supervised Stacked Auto-encoders", ["Pramod B. Bachhav", "Massimiliano Todisco", "Nicholas W. D. Evans"], "https://doi.org/10.21437/Interspeech.2018-2213", 5, "interspeech", 2018], ["Speech Database and Protocol Validation Using Waveform Entropy", ["Itshak Lapidot", "Hector Delgado", "Massimiliano Todisco", "Nicholas W. D. Evans", "Jean-Francois Bonastre"], "https://doi.org/10.21437/Interspeech.2018-2330", 5, "interspeech", 2018], ["The EURECOM Submission to the First DIHARD Challenge", ["Jose Patino", "Hector Delgado", "Nicholas W. D. Evans"], "https://doi.org/10.21437/Interspeech.2018-2172", 5, "interspeech", 2018]], "Jong-Jin Kim": [0.9510593414306641, ["Korean Singing Voice Synthesis Based on an LSTM Recurrent Neural Network", ["Juntae Kim", "Heejin Choi", "Jinuk Park", "Minsoo Hahn", "Sang-Jin Kim", "Jong-Jin Kim"], "https://doi.org/10.21437/Interspeech.2018-1575", 5, "interspeech", 2018]], "Natalia A. Tomashenko": [0, ["Speaker Adaptive Training and Mixup Regularization for Neural Network Acoustic Models in Automatic Speech Recognition", ["Natalia A. Tomashenko", "Yuri Y. Khokhlov", "Yannick Esteve"], "https://doi.org/10.21437/Interspeech.2018-2209", 5, "interspeech", 2018], ["An Investigation of Mixup Training Strategies for Acoustic Models in ASR", ["Ivan Medennikov", "Yuri Y. Khokhlov", "Aleksei Romanenko", "Dmitry Popov", "Natalia A. Tomashenko", "Ivan Sorokin", "Alexander Zatvornitskiy"], "https://doi.org/10.21437/Interspeech.2018-2191", 5, "interspeech", 2018]], "Jiro Nishitoba": [0, ["ESPnet: End-to-End Speech Processing Toolkit", ["Shinji Watanabe", "Takaaki Hori", "Shigeki Karita", "Tomoki Hayashi", "Jiro Nishitoba", "Yuya Unno", "Nelson Enrique Yalta Soplin", "Jahn Heymann", "Matthew Wiesner", "Nanxin Chen", "Adithya Renduchintala", "Tsubasa Ochiai"], "https://doi.org/10.21437/Interspeech.2018-1456", 5, "interspeech", 2018]], "Milton Samirakshma Bepari": [0, ["PannoMulloKathan: Voice Enabled Mobile App for Agricultural Commodity Price Dissemination in Bengali Language", ["Madhab Pal", "Rajib Roy", "Soma Khan", "Milton Samirakshma Bepari", "Joyanta Basu"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3027.html", 2, "interspeech", 2018]], "Lianwu Chen": [0, ["Permutation Invariant Training of Generative Adversarial Network for Monaural Speech Separation", ["Lianwu Chen", "Meng Yu", "Yanmin Qian", "Dan Su", "Dong Yu"], "https://doi.org/10.21437/Interspeech.2018-1603", 5, "interspeech", 2018], ["Deep Extractor Network for Target Speaker Recovery from Single Channel Speech Mixtures", ["Jun Wang", "Jie Chen", "Dan Su", "Lianwu Chen", "Meng Yu", "Yanmin Qian", "Dong Yu"], "https://doi.org/10.21437/Interspeech.2018-1205", 5, "interspeech", 2018], ["Text-Dependent Speech Enhancement for Small-Footprint Robust Keyword Detection", ["Meng Yu", "Xuan Ji", "Yi Gao", "Lianwu Chen", "Jie Chen", "Jimeng Zheng", "Dan Su", "Dong Yu"], "https://doi.org/10.21437/Interspeech.2018-1668", 5, "interspeech", 2018]], "Soo Jin Park": [0.9360999912023544, ["Using Voice Quality Supervectors for Affect Identification", ["Soo Jin Park", "Amber Afshan", "Zhi Ming Chua", "Abeer Alwan"], "https://doi.org/10.21437/Interspeech.2018-1401", 5, "interspeech", 2018], ["Effectiveness of Voice Quality Features in Detecting Depression", ["Amber Afshan", "Jinxi Guo", "Soo Jin Park", "Vijay Ravi", "Jonathan Flint", "Abeer Alwan"], "https://doi.org/10.21437/Interspeech.2018-1399", 5, "interspeech", 2018]], "Md. Sahidullah": [0, ["Integrated Presentation Attack Detection and Automatic Speaker Verification: Common Features and Gaussian Back-end Fusion", ["Massimiliano Todisco", "Hector Delgado", "Kong-Aik Lee", "Md. Sahidullah", "Nicholas W. D. Evans", "Tomi Kinnunen", "Junichi Yamagishi"], "https://doi.org/10.21437/Interspeech.2018-2289", 5, "interspeech", 2018]], "Mingkun Huang": [0, ["Knowledge Distillation for Sequence Model", ["Mingkun Huang", "Yongbin You", "Zhehuai Chen", "Yanmin Qian", "Kai Yu"], "https://doi.org/10.21437/Interspeech.2018-1589", 5, "interspeech", 2018]], "Julien Meyer": [0, ["Length Contrast and Covarying Features: Whistled Speech as a Case Study", ["Rachid Ridouane", "Giuseppina Turco", "Julien Meyer"], "https://doi.org/10.21437/Interspeech.2018-1060", 5, "interspeech", 2018], ["Loud and Shouted Speech Perception at Variable Distances in a Forest", ["Julien Meyer", "Fanny Meunier", "Laure Dentel", "Noelia Do Carmo Blanco", "Frederic Sebe"], "https://doi.org/10.21437/Interspeech.2018-2089", 5, "interspeech", 2018], ["Phoneme Resistance and Phoneme Confusion in Noise: Impact of Dyslexia", ["Noelia Do Carmo Blanco", "Julien Meyer", "Michel Hoen", "Fanny Meunier"], "https://doi.org/10.21437/Interspeech.2018-1271", 5, "interspeech", 2018]], "Massimiliano Todisco": [0, ["Integrated Presentation Attack Detection and Automatic Speaker Verification: Common Features and Gaussian Back-end Fusion", ["Massimiliano Todisco", "Hector Delgado", "Kong-Aik Lee", "Md. Sahidullah", "Nicholas W. D. Evans", "Tomi Kinnunen", "Junichi Yamagishi"], "https://doi.org/10.21437/Interspeech.2018-2289", 5, "interspeech", 2018], ["Artificial Bandwidth Extension with Memory Inclusion Using Semi-supervised Stacked Auto-encoders", ["Pramod B. Bachhav", "Massimiliano Todisco", "Nicholas W. D. Evans"], "https://doi.org/10.21437/Interspeech.2018-2213", 5, "interspeech", 2018], ["Speech Database and Protocol Validation Using Waveform Entropy", ["Itshak Lapidot", "Hector Delgado", "Massimiliano Todisco", "Nicholas W. D. Evans", "Jean-Francois Bonastre"], "https://doi.org/10.21437/Interspeech.2018-2330", 5, "interspeech", 2018]], "Pierre-Alexandre Broux": [0, ["S4D: Speaker Diarization Toolkit in Python", ["Pierre-Alexandre Broux", "Florent Desnous", "Anthony Larcher", "Simon Petitrenaud", "Jean Carrive", "Sylvain Meignier"], "https://doi.org/10.21437/Interspeech.2018-1232", 5, "interspeech", 2018]], "Dmitry Popov": [0, ["An Investigation of Mixup Training Strategies for Acoustic Models in ASR", ["Ivan Medennikov", "Yuri Y. Khokhlov", "Aleksei Romanenko", "Dmitry Popov", "Natalia A. Tomashenko", "Ivan Sorokin", "Alexander Zatvornitskiy"], "https://doi.org/10.21437/Interspeech.2018-2191", 5, "interspeech", 2018]], "James R. Williamson": [0, ["The Effect of Exposure to High Altitude and Heat on Speech Articulatory Coordination", ["James R. Williamson", "Thomas F. Quatieri", "Adam C. Lammert", "Katherine Mitchell", "Katherine Finkelstein", "Nicole Ekon", "Caitlin Dillon", "Robert Kenefick", "Kristin Heaton"], "https://doi.org/10.21437/Interspeech.2018-2372", 5, "interspeech", 2018], ["Vocal Biomarkers for Cognitive Performance Estimation in a Working Memory Task", ["Jennifer Sloboda", "Adam C. Lammert", "James R. Williamson", "Christopher J. Smalt", "Daryush D. Mehta", "C. O. L. Ian Curry", "Kristin Heaton", "Jeff Palmer", "Thomas F. Quatieri"], "https://doi.org/10.21437/Interspeech.2018-2418", 5, "interspeech", 2018]], "Anne A. Warlaumont": [0, ["Automated Classification of Children's Linguistic versus Non-Linguistic Vocalisations", ["Zixing Zhang", "Alejandrina Cristia", "Anne A. Warlaumont", "Bjorn W. Schuller"], "https://doi.org/10.21437/Interspeech.2018-2523", 5, "interspeech", 2018]], "Ye Wang": [0.001440670166630298, ["Automatic Pronunciation Evaluation of Singing", ["Chitralekha Gupta", "Haizhou Li", "Ye Wang"], "https://doi.org/10.21437/Interspeech.2018-1267", 5, "interspeech", 2018]], "Peter Bell": [0, ["Learning to Adapt: A Meta-learning Approach for Speaker Adaptation", ["Ondrej Klejch", "Joachim Fainberg", "Peter Bell"], "https://doi.org/10.21437/Interspeech.2018-1244", 5, "interspeech", 2018]], "Ivana Lucic": [0, ["L2-ARCTIC: A Non-native English Speech Corpus", ["Guanlong Zhao", "Sinem Sonsaat", "Alif Silpachai", "Ivana Lucic", "Evgeny Chukharev-Hudilainen", "John Levis", "Ricardo Gutierrez-Osuna"], "https://doi.org/10.21437/Interspeech.2018-1110", 5, "interspeech", 2018]], "Jun Du": [0, ["Speaker Diarization with Enhancing Speech for the First DIHARD Challenge", ["Lei Sun", "Jun Du", "Chao Jiang", "Xueyang Zhang", "Shan He", "Bing Yin", "Chin-Hui Lee"], "https://doi.org/10.21437/Interspeech.2018-1742", 5, "interspeech", 2018], ["Error Modeling via Asymmetric Laplace Distribution for Deep Neural Network Based Single-Channel Speech Enhancement", ["Li Chai", "Jun Du", "Chin-Hui Lee"], "https://doi.org/10.21437/Interspeech.2018-1439", 5, "interspeech", 2018]], "Justin Tansuwan": [0, ["Speech Recognition for Medical Conversations", ["Chung-Cheng Chiu", "Anshuman Tripathi", "Katherine Chou", "Chris Co", "Navdeep Jaitly", "Diana Jaunzeikare", "Anjuli Kannan", "Patrick Nguyen", "Hasim Sak", "Ananth Sankar", "Justin Tansuwan", "Nathan Wan", "Yonghui Wu", "Xuedong Zhang"], "https://doi.org/10.21437/Interspeech.2018-40", 5, "interspeech", 2018]], "Yuya Unno": [0, ["ESPnet: End-to-End Speech Processing Toolkit", ["Shinji Watanabe", "Takaaki Hori", "Shigeki Karita", "Tomoki Hayashi", "Jiro Nishitoba", "Yuya Unno", "Nelson Enrique Yalta Soplin", "Jahn Heymann", "Matthew Wiesner", "Nanxin Chen", "Adithya Renduchintala", "Tsubasa Ochiai"], "https://doi.org/10.21437/Interspeech.2018-1456", 5, "interspeech", 2018]], "Koichi Mori": [0, ["Automatic Evaluation of Soft Articulatory Contact for Stuttering Treatment", ["Keiko Ochi", "Koichi Mori", "Naomi Sakai"], "https://doi.org/10.21437/Interspeech.2018-2544", 5, "interspeech", 2018]], "Dean Luo": [0, ["Factorized Deep Neural Network Adaptation for Automatic Scoring of L2 Speech in English Speaking Tests", ["Dean Luo", "Chunxiao Zhang", "Linzhong Xia", "Lixin Wang"], "https://doi.org/10.21437/Interspeech.2018-2138", 5, "interspeech", 2018]], "Luis Gustavo Depra Cuozzo": [0, ["Joint Discriminative Embedding Learning, Speech Activity and Overlap Detection for the DIHARD Speaker Diarization Challenge", ["Valter Akira Miasato Filho", "Diego Augusto Silva", "Luis Gustavo Depra Cuozzo"], "https://doi.org/10.21437/Interspeech.2018-2304", 5, "interspeech", 2018]], "Mohit Jain": [0, ["End-To-End Audio Replay Attack Detection Using Deep Convolutional Networks with Attention", ["Francis Tom", "Mohit Jain", "Prasenjit Dey"], "https://doi.org/10.21437/Interspeech.2018-2279", 5, "interspeech", 2018]], "Zhi Hao Lim": [5.027808586133276e-10, ["Mandarin-English Code-switching Speech Recognition", ["Haihua Xu", "Van Tung Pham", "Zin Tun Kyaw", "Zhi Hao Lim", "Eng Siong Chng", "Haizhou Li"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3014.html", 2, "interspeech", 2018]], "Marcin Wlodarczak": [0, ["Creak in the Respiratory Cycle", ["Katlin Aare", "Partel Lippus", "Marcin Wlodarczak", "Mattias Heldner"], "https://doi.org/10.21437/Interspeech.2018-2165", 5, "interspeech", 2018], ["Articulatory Consequences of Vocal Effort Elicitation Method", ["Elisabet Eir Cortes", "Marcin Wlodarczak", "Juraj Simko"], "https://doi.org/10.21437/Interspeech.2018-1038", 5, "interspeech", 2018]], "Alexei Kochetov": [0, ["Gestural Lenition of Rhotics Captures Variation in Brazilian Portuguese", ["Phil Howson", "Alexei Kochetov"], "https://doi.org/10.21437/Interspeech.2018-1404", 5, "interspeech", 2018], ["The Retroflex-dental Contrast in Punjabi Stops and Nasals: A Principal Component Analysis of Ultrasound Images", ["Alexei Kochetov", "Matthew Faytak", "Kiranpreet Nara"], "https://doi.org/10.21437/Interspeech.2018-1457", 5, "interspeech", 2018], ["An Ultrasound Study of Gemination in Coronal Stops in Eastern Oromo", ["Maida Percival", "Alexei Kochetov", "Yoonjung Kang"], "https://doi.org/10.21437/Interspeech.2018-2512", 5, "interspeech", 2018]], "Febe de Wet": [0, ["Building a Unified Code-Switching ASR System for South African Languages", ["Emre Yilmaz", "Astik Biswas", "Ewald van der Westhuizen", "Febe de Wet", "Thomas Niesler"], "https://doi.org/10.21437/Interspeech.2018-1966", 5, "interspeech", 2018], ["Multilingual Neural Network Acoustic Modelling for ASR of Under-Resourced English-isiZulu Code-Switched Speech", ["Astik Biswas", "Febe de Wet", "Ewald van der Westhuizen", "Emre Yilmaz", "Thomas Niesler"], "https://doi.org/10.21437/Interspeech.2018-1711", 5, "interspeech", 2018]], "Ziqiang Shi": [0, ["Double Joint Bayesian Modeling of DNN Local I-Vector for Text Dependent Speaker Verification with Random Digit Strings", ["Ziqiang Shi", "Huibin Lin", "Liu Liu", "Rujie Liu"], "https://doi.org/10.21437/Interspeech.2018-1103", 5, "interspeech", 2018], ["Joint Learning of J-Vector Extractor and Joint Bayesian Model for Text Dependent Speaker Verification", ["Ziqiang Shi", "Liu Liu", "Huibin Lin", "Rujie Liu"], "https://doi.org/10.21437/Interspeech.2018-1500", 5, "interspeech", 2018], ["Latent Factor Analysis of Deep Bottleneck Features for Speaker Verification with Random Digit Strings", ["Ziqiang Shi", "Huibin Lin", "Liu Liu", "Rujie Liu"], "https://doi.org/10.21437/Interspeech.2018-1422", 5, "interspeech", 2018]], "Abhinav Rastogi": [0, ["An Efficient Approach to Encoding Context for Spoken Language Understanding", ["Raghav Gupta", "Abhinav Rastogi", "Dilek Hakkani-Tur"], "https://doi.org/10.21437/Interspeech.2018-2403", 5, "interspeech", 2018]], "Theo Biasutto-Lervat": [0, ["Phoneme-to-Articulatory Mapping Using Bidirectional Gated RNN", ["Theo Biasutto-Lervat", "Slim Ouni"], "https://doi.org/10.21437/Interspeech.2018-1202", 5, "interspeech", 2018]], "Haichuan Bai": [2.774560048379726e-08, ["Deep Convolutional Neural Network with Scalogram for Audio Scene Modeling", ["Hangting Chen", "Pengyuan Zhang", "Haichuan Bai", "Qingsheng Yuan", "Xiuguo Bao", "Yonghong Yan"], "https://doi.org/10.21437/Interspeech.2018-1524", 5, "interspeech", 2018]], "Jim X. Ji": [0.0916331447660923, ["Anomaly Detection Approach for Pronunciation Verification of Disordered Speech Using Speech Attribute Features", ["Mostafa Ali Shahin", "Beena Ahmed", "Jim X. Ji", "Kirrie J. Ballard"], "https://doi.org/10.21437/Interspeech.2018-1319", 5, "interspeech", 2018]], "Titouan Parcollet": [0, ["Quaternion Convolutional Neural Networks for End-to-End Automatic Speech Recognition", ["Titouan Parcollet", "Ying Zhang", "Mohamed Morchid", "Chiheb Trabelsi", "Georges Linares", "Renato de Mori", "Yoshua Bengio"], "https://doi.org/10.21437/Interspeech.2018-1898", 5, "interspeech", 2018]], "Astik Biswas": [0, ["Building a Unified Code-Switching ASR System for South African Languages", ["Emre Yilmaz", "Astik Biswas", "Ewald van der Westhuizen", "Febe de Wet", "Thomas Niesler"], "https://doi.org/10.21437/Interspeech.2018-1966", 5, "interspeech", 2018], ["Multilingual Neural Network Acoustic Modelling for ASR of Under-Resourced English-isiZulu Code-Switched Speech", ["Astik Biswas", "Febe de Wet", "Ewald van der Westhuizen", "Emre Yilmaz", "Thomas Niesler"], "https://doi.org/10.21437/Interspeech.2018-1711", 5, "interspeech", 2018]], "Lorenzo Spreafico": [0, ["UltraFit: A Speaker-friendly Headset for Ultrasound Recordings in Speech Science", ["Lorenzo Spreafico", "Michael Pucher", "Anna Matosova"], "https://doi.org/10.21437/Interspeech.2018-995", 4, "interspeech", 2018]], "Samuel Myer": [0, ["Efficient Keyword Spotting Using Time Delay Neural Networks", ["Samuel Myer", "Vikrant Singh Tomar"], "https://doi.org/10.21437/Interspeech.2018-1979", 5, "interspeech", 2018]], "Jan W. H. Schnupp": [0, ["Weighting Pitch Contour and Loudness Contour in Mandarin Tone Perception in Cochlear Implant Listeners", ["Qinglin Meng", "Nengheng Zheng", "Ambika Prasad Mishra", "Jacinta Dan Luo", "Jan W. H. Schnupp"], "https://doi.org/10.21437/Interspeech.2018-1245", 4, "interspeech", 2018]], "Gunnam Aneeja": [0, ["Detection of Glottal Closure Instants in Degraded Speech Using Single Frequency Filtering Analysis", ["Gunnam Aneeja", "Sudarsana Reddy Kadiri", "Bayya Yegnanarayana"], "https://doi.org/10.21437/Interspeech.2018-1018", 5, "interspeech", 2018]], "Emmanuel Vincent": [0, ["The Fifth 'CHiME' Speech Separation and Recognition Challenge: Dataset, Task and Baselines", ["Jon Barker", "Shinji Watanabe", "Emmanuel Vincent", "Jan Trmal"], "https://doi.org/10.21437/Interspeech.2018-1768", 5, "interspeech", 2018], ["Keyword Based Speaker Localization: Localizing a Target Speaker in a Multi-speaker Environment", ["Sunit Sivasankaran", "Emmanuel Vincent", "Dominique Fohr"], "https://doi.org/10.21437/Interspeech.2018-1526", 5, "interspeech", 2018]], "Najmeh Sadoughi": [0, ["An Automated Assistant for Medical Scribes", ["Gregory P. Finley", "Erik Edwards", "Amanda Robinson", "Najmeh Sadoughi", "James Fone", "Mark Miller", "David Suendermann-Oeft", "Michael Brenndoerfer", "Nico Axtmann"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3047.html", 2, "interspeech", 2018]], "Tanvina Patel": [0, ["Development of Large Vocabulary Speech Recognition System with Keyword Search for Manipuri", ["Tanvina Patel", "Krishna D. N", "Noor Fathima", "Nisar Shah", "Mahima C", "Deepak Kumar", "Anuroop Iyengar"], "https://doi.org/10.21437/Interspeech.2018-2133", 5, "interspeech", 2018], ["An Automatic Speech Transcription System for Manipuri Language", ["Tanvina Patel", "Krishna D. N", "Noor Fathima", "Nisar Shah", "Mahima C", "Deepak Kumar", "Anuroop Iyengar"], "http://www.isca-speech.org/archive/Interspeech_2018/abstracts/3043.html", 2, "interspeech", 2018], ["TDNN-based Multilingual Speech Recognition System for Low Resource Indian Languages", ["Noor Fathima", "Tanvina Patel", "Mahima C", "Anuroop Iyengar"], "https://doi.org/10.21437/Interspeech.2018-2117", 5, "interspeech", 2018]], "Anastasia Matveeva": [0, ["LOCUST - Longitudinal Corpus and Toolset for Speaker Verification", ["Evgeny Dmitriev", "Yulia Kim", "Anastasia Matveeva", "Claude Montacie", "Yannick Boulard", "Yadviga Sinyavskaya", "Yulia Zhukova", "Adam Zarazinski", "Egor Akhanov", "Ilya I. Viksnin", "Andrei A. Shlykov", "Maria Usova"], "https://doi.org/10.21437/Interspeech.2018-2412", 5, "interspeech", 2018]], "Hiroki Tanaka": [0, ["Detection of Dementia from Responses to Atypical Questions Asked by Embodied Conversational Agents", ["Tsuyoki Ujiro", "Hiroki Tanaka", "Hiroyoshi Adachi", "Hiroaki Kazui", "Manabu Ikeda", "Takashi Kudo", "Satoshi Nakamura"], "https://doi.org/10.21437/Interspeech.2018-1514", 5, "interspeech", 2018]], "Sarah Ita Levitan": [0, ["Acoustic-Prosodic Indicators of Deception and Trust in Interview Dialogues", ["Sarah Ita Levitan", "Angel Maredia", "Julia Hirschberg"], "https://doi.org/10.21437/Interspeech.2018-2443", 5, "interspeech", 2018], ["Deep Personality Recognition for Deception Detection", ["Guozhen An", "Sarah Ita Levitan", "Julia Hirschberg", "Rivka Levitan"], "https://doi.org/10.21437/Interspeech.2018-2269", 5, "interspeech", 2018]], "Kentaro Sone": [0, ["DNN-based Speech Synthesis for Small Data Sets Considering Bidirectional Speech-Text Conversion", ["Kentaro Sone", "Toru Nakashika"], "https://doi.org/10.21437/Interspeech.2018-1460", 5, "interspeech", 2018]], "Toshiko Isei-Jaakkola": [0, ["Respiratory and Respiratory Muscular Control in JL1's and JL2's Text Reading Utilizing 4-RSTs and a Soft Respiratory Mask with a Two-Way Bulb", ["Toshiko Isei-Jaakkola", "Keiko Ochi", "Keikichi Hirose"], "https://doi.org/10.21437/Interspeech.2018-1948", 5, "interspeech", 2018]], "Brian Richburg": [0, ["Automatic Detection of Orofacial Impairment in Stroke", ["Andrea Bandini", "Jordan R. Green", "Brian Richburg", "Yana Yunusova"], "https://doi.org/10.21437/Interspeech.2018-2475", 5, "interspeech", 2018]], "Nick K. Chibuye": [0, ["Cross-language Phoneme Mapping for Low-resource Languages: An Exploration of Benefits and Trade-offs", ["Nick K. Chibuye", "Todd Rosenstock", "Brian DeRenzi"], "https://doi.org/10.21437/Interspeech.2018-2454", 5, "interspeech", 2018]], "Taehwan Kim": [0.925512820482254, ["Investigation of Using Disentangled and Interpretable Representations for One-shot Cross-lingual Voice Conversion", ["Seyed Hamidreza Mohammadi", "Taehwan Kim"], "https://doi.org/10.21437/Interspeech.2018-2525", 5, "interspeech", 2018]], "Sanjeev Khudanpur": [0, ["End-to-end Speech Recognition Using Lattice-free MMI", ["Hossein Hadian", "Hossein Sameti", "Daniel Povey", "Sanjeev Khudanpur"], "https://doi.org/10.21437/Interspeech.2018-1423", 5, "interspeech", 2018], ["End-to-end Deep Neural Network Age Estimation", ["Pegah Ghahremani", "Phani Sankar Nidadavolu", "Nanxin Chen", "Jesus Villalba", "Daniel Povey", "Sanjeev Khudanpur", "Najim Dehak"], "https://doi.org/10.21437/Interspeech.2018-2015", 5, "interspeech", 2018], ["Acoustic Modeling from Frequency Domain Representations of Speech", ["Pegah Ghahremani", "Hossein Hadian", "Hang Lv", "Daniel Povey", "Sanjeev Khudanpur"], "https://doi.org/10.21437/Interspeech.2018-1453", 5, "interspeech", 2018], ["Output-Gate Projected Gated Recurrent Unit for Speech Recognition", ["Gaofeng Cheng", "Daniel Povey", "Lu Huang", "Ji Xu", "Sanjeev Khudanpur", "Yonghong Yan"], "https://doi.org/10.21437/Interspeech.2018-1403", 5, "interspeech", 2018], ["Automatic Speech Recognition and Topic Identification from Speech for Almost-Zero-Resource Languages", ["Matthew Wiesner", "Chunxi Liu", "Lucas Ondel", "Craig Harman", "Vimal Manohar", "Jan Trmal", "Zhongqiang Huang", "Najim Dehak", "Sanjeev Khudanpur"], "https://doi.org/10.21437/Interspeech.2018-1836", 5, "interspeech", 2018], ["A GPU-based WFST Decoder with Exact Lattice Generation", ["Zhehuai Chen", "Justin Luitjens", "Hainan Xu", "Yiming Wang", "Daniel Povey", "Sanjeev Khudanpur"], "https://doi.org/10.21437/Interspeech.2018-1339", 5, "interspeech", 2018], ["Diarization is Hard: Some Experiences and Lessons Learned for the JHU Team in the Inaugural DIHARD Challenge", ["Gregory Sell", "David Snyder", "Alan McCree", "Daniel Garcia-Romero", "Jesus Villalba", "Matthew Maciejewski", "Vimal Manohar", "Najim Dehak", "Daniel Povey", "Shinji Watanabe", "Sanjeev Khudanpur"], "https://doi.org/10.21437/Interspeech.2018-1893", 5, "interspeech", 2018], ["Recurrent Neural Network Language Model Adaptation for Conversational Speech Recognition", ["Ke Li", "Hainan Xu", "Yiming Wang", "Daniel Povey", "Sanjeev Khudanpur"], "https://doi.org/10.21437/Interspeech.2018-1413", 5, "interspeech", 2018], ["Semi-Orthogonal Low-Rank Matrix Factorization for Deep Neural Networks", ["Daniel Povey", "Gaofeng Cheng", "Yiming Wang", "Ke Li", "Hainan Xu", "Mahsa Yarmohammadi", "Sanjeev Khudanpur"], "https://doi.org/10.21437/Interspeech.2018-1417", 5, "interspeech", 2018]], "Nicanor Garcia": [0, ["Multimodal I-vectors to Detect and Evaluate Parkinson's Disease", ["Nicanor Garcia", "Juan Camilo Vasquez-Correa", "Juan Rafael Orozco-Arroyave", "Elmar Noth"], "https://doi.org/10.21437/Interspeech.2018-2295", 5, "interspeech", 2018]], "Shinji Watanabe": [0, ["Semi-Supervised End-to-End Speech Recognition", ["Shigeki Karita", "Shinji Watanabe", "Tomoharu Iwata", "Atsunori Ogawa", "Marc Delcroix"], "https://doi.org/10.21437/Interspeech.2018-1746", 5, "interspeech", 2018], ["Multi-Head Decoder for End-to-End Speech Recognition", ["Tomoki Hayashi", "Shinji Watanabe", "Tomoki Toda", "Kazuya Takeda"], "https://doi.org/10.21437/Interspeech.2018-1655", 5, "interspeech", 2018], ["The Fifth 'CHiME' Speech Separation and Recognition Challenge: Dataset, Task and Baselines", ["Jon Barker", "Shinji Watanabe", "Emmanuel Vincent", "Jan Trmal"], "https://doi.org/10.21437/Interspeech.2018-1768", 5, "interspeech", 2018], ["Building State-of-the-art Distant Speech Recognition Using the CHiME-4 Challenge with a Setup of Speech Enhancement Baseline", ["Szu-Jui Chen", "Aswin Shanmugam Subramanian", "Hainan Xu", "Shinji Watanabe"], "https://doi.org/10.21437/Interspeech.2018-1262", 5, "interspeech", 2018], ["Effectiveness of Single-Channel BLSTM Enhancement for Language Identification", ["Peter Sibbern Frederiksen", "Jesus Villalba", "Shinji Watanabe", "Zheng-Hua Tan", "Najim Dehak"], "https://doi.org/10.21437/Interspeech.2018-2458", 5, "interspeech", 2018], ["ESPnet: End-to-End Speech Processing Toolkit", ["Shinji Watanabe", "Takaaki Hori", "Shigeki Karita", "Tomoki Hayashi", "Jiro Nishitoba", "Yuya Unno", "Nelson Enrique Yalta Soplin", "Jahn Heymann", "Matthew Wiesner", "Nanxin Chen", "Adithya Renduchintala", "Tsubasa Ochiai"], "https://doi.org/10.21437/Interspeech.2018-1456", 5, "interspeech", 2018], ["Multi-Modal Data Augmentation for End-to-end ASR", ["Adithya Renduchintala", "Shuoyang Ding", "Matthew Wiesner", "Shinji Watanabe"], "https://doi.org/10.21437/Interspeech.2018-2456", 5, "interspeech", 2018], ["Auxiliary Feature Based Adaptation of End-to-end ASR Systems", ["Marc Delcroix", "Shinji Watanabe", "Atsunori Ogawa", "Shigeki Karita", "Tomohiro Nakatani"], "https://doi.org/10.21437/Interspeech.2018-1438", 5, "interspeech", 2018], ["Diarization is Hard: Some Experiences and Lessons Learned for the JHU Team in the Inaugural DIHARD Challenge", ["Gregory Sell", "David Snyder", "Alan McCree", "Daniel Garcia-Romero", "Jesus Villalba", "Matthew Maciejewski", "Vimal Manohar", "Najim Dehak", "Daniel Povey", "Shinji Watanabe", "Sanjeev Khudanpur"], "https://doi.org/10.21437/Interspeech.2018-1893", 5, "interspeech", 2018], ["Student-Teacher Learning for BLSTM Mask-based Speech Enhancement", ["Aswin Shanmugam Subramanian", "Szu-Jui Chen", "Shinji Watanabe"], "https://doi.org/10.21437/Interspeech.2018-2440", 5, "interspeech", 2018]], "Kirrie J. Ballard": [0, ["Anomaly Detection Approach for Pronunciation Verification of Disordered Speech Using Speech Attribute Features", ["Mostafa Ali Shahin", "Beena Ahmed", "Jim X. Ji", "Kirrie J. Ballard"], "https://doi.org/10.21437/Interspeech.2018-1319", 5, "interspeech", 2018]], "Hiroyoshi Adachi": [0, ["Detection of Dementia from Responses to Atypical Questions Asked by Embodied Conversational Agents", ["Tsuyoki Ujiro", "Hiroki Tanaka", "Hiroyoshi Adachi", "Hiroaki Kazui", "Manabu Ikeda", "Takashi Kudo", "Satoshi Nakamura"], "https://doi.org/10.21437/Interspeech.2018-1514", 5, "interspeech", 2018]], "Yi Shen": [0, ["Measuring the Band Importance Function for Mandarin Chinese with a Bayesian Adaptive Procedure", ["Yufan Du", "Yi Shen", "Hongying Yang", "Xihong Wu", "Jing Chen"], "https://doi.org/10.21437/Interspeech.2018-1825", 5, "interspeech", 2018]], "Mitchell McLaren": [0, ["A Generalization of PLDA for Joint Modeling of Speaker Identity and Multiple Nuisance Conditions", ["Luciana Ferrer", "Mitchell McLaren"], "https://doi.org/10.21437/Interspeech.2018-1280", 5, "interspeech", 2018], ["Robust Speaker Recognition from Distant Speech under Real Reverberant Environments Using Speaker Embeddings", ["Mahesh Kumar Nandwana", "Julien van Hout", "Mitchell McLaren", "Allen R. Stauffer", "Colleen Richey", "Aaron Lawson", "Martin Graciarena"], "https://doi.org/10.21437/Interspeech.2018-2221", 5, "interspeech", 2018], ["Analysis of Complementary Information Sources in the Speaker Embeddings Framework", ["Mahesh Kumar Nandwana", "Mitchell McLaren", "Diego Castan", "Julien van Hout", "Aaron Lawson"], "https://doi.org/10.21437/Interspeech.2018-1102", 5, "interspeech", 2018], ["Employing Phonetic Information in DNN Speaker Embeddings to Improve Speaker Recognition Performance", ["Md. Hafizur Rahman", "Ivan Himawan", "Mitchell McLaren", "Clinton Fookes", "Sridha Sridharan"], "https://doi.org/10.21437/Interspeech.2018-1804", 5, "interspeech", 2018]], "Ryo Masumura": [0, ["Neural Error Corrective Language Models for Automatic Speech Recognition", ["Tomohiro Tanaka", "Ryo Masumura", "Hirokazu Masataki", "Yushi Aono"], "https://doi.org/10.21437/Interspeech.2018-1430", 5, "interspeech", 2018], ["Role Play Dialogue Aware Language Models Based on Conditional Hierarchical Recurrent Encoder-Decoder", ["Ryo Masumura", "Tomohiro Tanaka", "Atsushi Ando", "Hirokazu Masataki", "Yushi Aono"], "https://doi.org/10.21437/Interspeech.2018-2185", 5, "interspeech", 2018], ["Automatic Question Detection from Acoustic and Phonetic Features Using Feature-wise Pre-training", ["Atsushi Ando", "Reine Asakawa", "Ryo Masumura", "Hosana Kamiyama", "Satoshi Kobashikawa", "Yushi Aono"], "https://doi.org/10.21437/Interspeech.2018-1755", 5, "interspeech", 2018]], "Protima Nomo Sudro": [0, ["Processing Transition Regions of Glottal Stop Substituted /S/ for Intelligibility Enhancement of Cleft Palate Speech", ["Protima Nomo Sudro", "Sishir Kalita", "S. R. Mahadeva Prasanna"], "https://doi.org/10.21437/Interspeech.2018-1646", 5, "interspeech", 2018]], "Masaki Yokoyama": [0, ["Effects of Dimensional Input on Paralinguistic Information Perceived from Synthesized Dialogue Speech with Neural Network", ["Masaki Yokoyama", "Tomohiro Nagata", "Hiroki Mori"], "https://doi.org/10.21437/Interspeech.2018-2042", 4, "interspeech", 2018]]}