{"Suliang Bu": [0, ["A Novel Method to Correct Steering Vectors in MVDR Beamformer for Noise Robust ASR", ["Suliang Bu", "Yunxin Zhao", "Mei-Yuh Hwang"], "https://doi.org/10.21437/Interspeech.2019-2944", 5, "interspeech", 2019]], "Thibault Viglino": [0, ["End-to-End Accented Speech Recognition", ["Thibault Viglino", "Petr Motlicek", "Milos Cernak"], "https://doi.org/10.21437/Interspeech.2019-2122", 5, "interspeech", 2019]], "Aggelina Chatziagapi": [0, ["Data Augmentation Using GANs for Speech Emotion Recognition", ["Aggelina Chatziagapi", "Georgios Paraskevopoulos", "Dimitris Sgouropoulos", "Georgios Pantazopoulos", "Malvina Nikandrou", "Theodoros Giannakopoulos", "Athanasios Katsamanis", "Alexandros Potamianos", "Shrikanth Narayanan"], "https://doi.org/10.21437/Interspeech.2019-2561", 5, "interspeech", 2019]], "Zbynek Zajic": [0, ["UWB-NTIS Speaker Diarization System for the DIHARD II 2019 Challenge", ["Zbynek Zajic", "Marie Kunesova", "Marek Hruz", "Jan Vanek"], "https://doi.org/10.21437/Interspeech.2019-1385", 5, "interspeech", 2019]], "Brij Mohan Lal Srivastava": [0, ["Privacy-Preserving Adversarial Representation Learning in ASR: Reality or Illusion?", ["Brij Mohan Lal Srivastava", "Aurelien Bellet", "Marc Tommasi", "Emmanuel Vincent"], "https://doi.org/10.21437/Interspeech.2019-2415", 5, "interspeech", 2019]], "Hui Luo": [0, ["Cross-Corpus Speech Emotion Recognition Using Semi-Supervised Transfer Non-Negative Matrix Factorization with Adaptation Regularization", ["Hui Luo", "Jiqing Han"], "https://doi.org/10.21437/Interspeech.2019-2041", 5, "interspeech", 2019]], "Yexin Yang": [1.4208983429853106e-05, ["The SJTU Robust Anti-Spoofing System for the ASVspoof 2019 Challenge", ["Yexin Yang", "Hongji Wang", "Heinrich Dinkel", "Zhengyang Chen", "Shuai Wang", "Yanmin Qian", "Kai Yu"], "https://doi.org/10.21437/Interspeech.2019-2170", 5, "interspeech", 2019]], "Jeng-Lin Li": [0, ["Attentive to Individual: A Multimodal Emotion Recognition Network with Personalized Attention Profile", ["Jeng-Lin Li", "Chi-Chun Lee"], "https://doi.org/10.21437/Interspeech.2019-2044", 5, "interspeech", 2019]], "Mittul Singh": [0, ["Subword RNNLM Approximations for Out-Of-Vocabulary Keyword Search", ["Mittul Singh", "Sami Virpioja", "Peter Smit", "Mikko Kurimo"], "https://doi.org/10.21437/Interspeech.2019-1329", 5, "interspeech", 2019]], "Chen-Chou Lo": [0, ["MOSNet: Deep Learning-Based Objective Assessment for Voice Conversion", ["Chen-Chou Lo", "Szu-Wei Fu", "Wen-Chin Huang", "Xin Wang", "Junichi Yamagishi", "Yu Tsao", "Hsin-Min Wang"], "https://doi.org/10.21437/Interspeech.2019-2003", 5, "interspeech", 2019]], "Noe Tits": [0, ["Visualization and Interpretation of Latent Spaces for Controlling Expressive Speech Synthesis Through Audio Analysis", ["Noe Tits", "Fengna Wang", "Kevin El Haddad", "Vincent Pagel", "Thierry Dutoit"], "https://doi.org/10.21437/Interspeech.2019-1426", 5, "interspeech", 2019]], "Camille Noufi": [0, ["Vocal Biomarker Assessment Following Pediatric Traumatic Brain Injury: A Retrospective Cohort Study", ["Camille Noufi", "Adam C. Lammert", "Daryush D. Mehta", "James R. Williamson", "Gregory Ciccarelli", "Douglas E. Sturim", "Jordan R. Green", "Thomas F. Campbell", "Thomas F. Quatieri"], "https://doi.org/10.21437/Interspeech.2019-1200", 5, "interspeech", 2019]], "Khoi-Nguyen C. Mac": [0, ["Large-Scale Mixed-Bandwidth Deep Neural Network Acoustic Modeling for Automatic Speech Recognition", ["Khoi-Nguyen C. Mac", "Xiaodong Cui", "Wei Zhang", "Michael Picheny"], "https://doi.org/10.21437/Interspeech.2019-2641", 5, "interspeech", 2019]], "Truc Nguyen": [0, ["Acoustic Scene Classification with Mismatched Devices Using CliqueNets and Mixup Data Augmentation", ["Truc Nguyen", "Franz Pernkopf"], "https://doi.org/10.21437/Interspeech.2019-3002", 5, "interspeech", 2019]], "Shucong Zhang": [0, ["Trainable Dynamic Subsampling for End-to-End Speech Recognition", ["Shucong Zhang", "Erfan Loweimi", "Yumo Xu", "Peter Bell", "Steve Renals"], "https://doi.org/10.21437/Interspeech.2019-2778", 5, "interspeech", 2019]], "Titouan Parcollet": [0, ["M2H-GAN: A GAN-Based Mapping from Machine to Human Transcripts for Speech Understanding", ["Titouan Parcollet", "Mohamed Morchid", "Xavier Bost", "Georges Linares"], "https://doi.org/10.21437/Interspeech.2019-2662", 5, "interspeech", 2019], ["Real to H-Space Encoder for Speech Recognition", ["Titouan Parcollet", "Mohamed Morchid", "Georges Linares", "Renato De Mori"], "https://doi.org/10.21437/Interspeech.2019-1539", 5, "interspeech", 2019]], "Kyle Williams": [0, ["Zero Shot Intent Classification Using Long-Short Term Memory Networks", ["Kyle Williams"], "https://doi.org/10.21437/Interspeech.2019-1274", 5, "interspeech", 2019]], "Yingke Zhu": [0, ["Mixup Learning Strategies for Text-Independent Speaker Verification", ["Yingke Zhu", "Tom Ko", "Brian Mak"], "https://doi.org/10.21437/Interspeech.2019-2250", 5, "interspeech", 2019]], "Sashi Novitasari": [0, ["Sequence-to-Sequence Learning via Attention Transfer for Incremental Speech Recognition", ["Sashi Novitasari", "Andros Tjandra", "Sakriani Sakti", "Satoshi Nakamura"], "https://doi.org/10.21437/Interspeech.2019-2985", 5, "interspeech", 2019]], "Patrick von Platen": [0, ["Multi-Span Acoustic Modelling Using Raw Waveform Signals", ["Patrick von Platen", "Chao Zhang", "Philip C. Woodland"], "https://doi.org/10.21437/Interspeech.2019-2454", 5, "interspeech", 2019]], "Adele Jatteau": [0, ["\" Gra[f] e!\" Word-Final Devoicing of Obstruents in Standard French: An Acoustic Study Based on Large Corpora", ["Adele Jatteau", "Ioana Vasilescu", "Lori Lamel", "Martine Adda-Decker", "Nicolas Audibert"], "https://doi.org/10.21437/Interspeech.2019-2329", 5, "interspeech", 2019]], "Naoya Takahashi": [0, ["Recursive Speech Separation for Unknown Number of Speakers", ["Naoya Takahashi", "Sudarsanam Parthasaarathy", "Nabarun Goswami", "Yuki Mitsufuji"], "https://doi.org/10.21437/Interspeech.2019-1550", 5, "interspeech", 2019]], "Mariya Kharaman": [0, ["The Processing of Prosodic Cues to Rhetorical Question Interpretation: Psycholinguistic and Neurolinguistics Evidence", ["Mariya Kharaman", "Manluolan Xu", "Carsten Eulitz", "Bettina Braun"], "https://doi.org/10.21437/Interspeech.2019-2528", 5, "interspeech", 2019]], "Weicheng Cai": [0, ["The DKU Replay Detection System for the ASVspoof 2019 Challenge: On Data Augmentation, Feature Representation, Classification, and Fusion", ["Weicheng Cai", "Haiwei Wu", "Danwei Cai", "Ming Li"], "https://doi.org/10.21437/Interspeech.2019-1230", 5, "interspeech", 2019]], "Prashanth Gurunath Shivakumar": [0, ["Spoken Language Intent Detection Using Confusion2Vec", ["Prashanth Gurunath Shivakumar", "Mu Yang", "Panayiotis G. Georgiou"], "https://doi.org/10.21437/Interspeech.2019-2226", 5, "interspeech", 2019]], "Fang-Yu Kuo": [0, ["Selection and Training Schemes for Improving TTS Voice Built on Found Data", ["Fang-Yu Kuo", "Iris Chuoying Ouyang", "Sandesh Aryal", "Pierre Lanchantin"], "https://doi.org/10.21437/Interspeech.2019-2816", 5, "interspeech", 2019]], "Jiri Martinek": [0, ["Multi-Lingual Dialogue Act Recognition with Deep Learning Methods", ["Jiri Martinek", "Pavel Kral", "Ladislav Lenc", "Christophe Cerisara"], "https://doi.org/10.21437/Interspeech.2019-1691", 5, "interspeech", 2019]], "Pin-Tuan Huang": [0, ["Exploring the Encoder Layers of Discriminative Autoencoders for LVCSR", ["Pin-Tuan Huang", "Hung-Shin Lee", "Syu-Siang Wang", "Kuan-Yu Chen", "Yu Tsao", "Hsin-Min Wang"], "https://doi.org/10.21437/Interspeech.2019-1717", 5, "interspeech", 2019]], "Ke-Xin He": [0, ["Hierarchical Pooling Structure for Weakly Labeled Sound Event Detection", ["Ke-Xin He", "Yu-Han Shen", "Wei-Qiang Zhang"], "https://doi.org/10.21437/Interspeech.2019-2049", 5, "interspeech", 2019]], "Yonatan Belinkov": [0, ["Analyzing Phonetic and Graphemic Representations in End-to-End Automatic Speech Recognition", ["Yonatan Belinkov", "Ahmed Ali", "James R. Glass"], "https://doi.org/10.21437/Interspeech.2019-2599", 5, "interspeech", 2019]], "Mirko Marras": [0, ["Adversarial Optimization for Dictionary Attacks on Speaker Verification", ["Mirko Marras", "Pawel Korus", "Nasir D. Memon", "Gianni Fenu"], "https://doi.org/10.21437/Interspeech.2019-2430", 5, "interspeech", 2019]], "Fasih Haider": [0, ["A System for Real-Time Privacy Preserving Data Collection for Ambient Assisted Living", ["Fasih Haider", "Saturnino Luz"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8037.html", 2, "interspeech", 2019]], "Keiichi Tokuda": [0, ["Statistical Approach to Speech Synthesis: Past, Present and Future", ["Keiichi Tokuda"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/abs1.html", 0, "interspeech", 2019]], "Chiranjeevi Yarra": [0, ["SPIRE-fluent: A Self-Learning App for Tutoring Oral Fluency to Second Language English Learners", ["Chiranjeevi Yarra", "Aparna Srinivasan", "Sravani Gottimukkala", "Prasanta Kumar Ghosh"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8008.html", 2, "interspeech", 2019]], "Reima Karhila": [0, ["Transparent Pronunciation Scoring Using Articulatorily Weighted Phoneme Edit Distance", ["Reima Karhila", "Anna-Riikka Smolander", "Sari Ylinen", "Mikko Kurimo"], "https://doi.org/10.21437/Interspeech.2019-1785", 5, "interspeech", 2019]], "Yiting Lu": [0, ["Impact of ASR Performance on Spoken Grammatical Error Detection", ["Yiting Lu", "Mark J. F. Gales", "Kate M. Knill", "P. P. Manakul", "Linlin Wang", "Y. Wang"], "https://doi.org/10.21437/Interspeech.2019-1706", 5, "interspeech", 2019]], "Cathryn Snyder": [0, ["Individual Variation in Cognitive Processing Style Predicts Differences in Phonetic Imitation of Device and Human Voices", ["Cathryn Snyder", "Michelle Cohn", "Georgia Zellou"], "https://doi.org/10.21437/Interspeech.2019-2669", 5, "interspeech", 2019]], "Catherine Lai": [0, ["Detecting Topic-Oriented Speaker Stance in Conversational Speech", ["Catherine Lai", "Beatrice Alex", "Johanna D. Moore", "Leimin Tian", "Tatsuro Hori", "Gianpiero Francesca"], "https://doi.org/10.21437/Interspeech.2019-2632", 5, "interspeech", 2019]], "David Ayllon": [0, ["Investigating the Effects of Noisy and Reverberant Speech in Text-to-Speech Systems", ["David Ayllon", "Hector A. Sanchez-Hevia", "Carol Figueroa", "Pierre Lanchantin"], "https://doi.org/10.21437/Interspeech.2019-3104", 5, "interspeech", 2019], ["A Strategy for Improved Phone-Level Lyrics-to-Audio Alignment for Speech-to-Singing Synthesis", ["David Ayllon", "Fernando Villavicencio", "Pierre Lanchantin"], "https://doi.org/10.21437/Interspeech.2019-3049", 5, "interspeech", 2019]], "Sishir Kalita": [0, ["Nasal Air Emission in Sibilant Fricatives of Cleft Lip and Palate Speech", ["Sishir Kalita", "Protima Nomo Sudro", "S. R. Mahadeva Prasanna", "Samarendra Dandapat"], "https://doi.org/10.21437/Interspeech.2019-2345", 5, "interspeech", 2019]], "Sudarsana Reddy Kadiri": [0, ["Mel-Frequency Cepstral Coefficients of Voice Source Waveforms for Classification of Phonation Types in Speech", ["Sudarsana Reddy Kadiri", "Paavo Alku"], "https://doi.org/10.21437/Interspeech.2019-2863", 5, "interspeech", 2019]], "Mohamed Ismail Yasar Arafath K": [0, ["Automatic Detection of Breath Using Voice Activity Detection and SVM Classifier with Application on News Reports", ["Mohamed Ismail Yasar Arafath K", "Aurobinda Routray"], "https://doi.org/10.21437/Interspeech.2019-2434", 5, "interspeech", 2019]], "Niccolo Sacchi": [0, ["Open-Vocabulary Keyword Spotting with Audio and Text Embeddings", ["Niccolo Sacchi", "Alexandre Nanchen", "Martin Jaggi", "Milos Cernak"], "https://doi.org/10.21437/Interspeech.2019-1846", 5, "interspeech", 2019]], "Mutian He": [0, ["Robust Sequence-to-Sequence Acoustic Modeling with Stepwise Monotonic Attention for Neural TTS", ["Mutian He", "Yan Deng", "Lei He"], "https://doi.org/10.21437/Interspeech.2019-1972", 5, "interspeech", 2019]], "Peter Wu": [3.579678886644899e-09, ["Ordinal Triplet Loss: Investigating Sleepiness Detection from Speech", ["Peter Wu", "Sai Krishna Rallabandi", "Alan W. Black", "Eric Nyberg"], "https://doi.org/10.21437/Interspeech.2019-2278", 5, "interspeech", 2019]], "Inga Run Helgadottir": [0, ["The Althingi ASR System", ["Inga Run Helgadottir", "Anna Bjork Nikulasdottir", "Michal Borsky", "Judy Y. Fong", "Robert Kjaran", "Jon Gudnason"], "https://doi.org/10.21437/Interspeech.2019-1248", 5, "interspeech", 2019]], "Pavel Denisov": [0, ["End-to-End Multi-Speaker Speech Recognition Using Speaker Embeddings and Transfer Learning", ["Pavel Denisov", "Ngoc Thang Vu"], "https://doi.org/10.21437/Interspeech.2019-1130", 5, "interspeech", 2019]], "Rachel Albar": [0, ["Phonological Awareness of French Rising Contours in Japanese Learners", ["Rachel Albar", "Hiyon Yoo"], "https://doi.org/10.21437/Interspeech.2019-2856", 5, "interspeech", 2019]], "Shoukang Hu": [0, ["LF-MMI Training of Bayesian and Gaussian Process Time Delay Neural Networks for Speech Recognition", ["Shoukang Hu", "Xurong Xie", "Shansong Liu", "Max W. Y. Lam", "Jianwei Yu", "Xixin Wu", "Xunying Liu", "Helen Meng"], "https://doi.org/10.21437/Interspeech.2019-2379", 5, "interspeech", 2019], ["The CUHK Dysarthric Speech Recognition Systems for English and Cantonese", ["Shoukang Hu", "Shansong Liu", "Heng Fai Chang", "Mengzhe Geng", "Jiani Chen", "Lau Wing Chung", "To Ka Hei", "Jianwei Yu", "Ka Ho Wong", "Xunying Liu", "Helen Meng"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8047.html", 2, "interspeech", 2019]], "Katerina Papadimitriou": [0, ["End-to-End Convolutional Sequence Learning for ASL Fingerspelling Recognition", ["Katerina Papadimitriou", "Gerasimos Potamianos"], "https://doi.org/10.21437/Interspeech.2019-2422", 5, "interspeech", 2019]], "Siqi Zheng": [0, ["Towards a Fault-Tolerant Speaker Verification System: A Regularization Approach to Reduce the Condition Number", ["Siqi Zheng", "Gang Liu", "Hongbin Suo", "Yun Lei"], "https://doi.org/10.21437/Interspeech.2019-1442", 5, "interspeech", 2019], ["Autoencoder-Based Semi-Supervised Curriculum Learning for Out-of-Domain Speaker Verification", ["Siqi Zheng", "Gang Liu", "Hongbin Suo", "Yun Lei"], "https://doi.org/10.21437/Interspeech.2019-1440", 5, "interspeech", 2019]], "Kristijan Gjoreski": [0, ["Cross-Lingual Transfer Learning for Affective Spoken Dialogue Systems", ["Kristijan Gjoreski", "Aleksandar Gjoreski", "Ivan Kraljevski", "Diane Hirschfeld"], "https://doi.org/10.21437/Interspeech.2019-2163", 5, "interspeech", 2019]], "Loren Lugosch": [0, ["Speech Model Pre-Training for End-to-End Spoken Language Understanding", ["Loren Lugosch", "Mirco Ravanelli", "Patrick Ignoto", "Vikrant Singh Tomar", "Yoshua Bengio"], "https://doi.org/10.21437/Interspeech.2019-2396", 5, "interspeech", 2019]], "Tomoki Hayashi": [0, ["Pre-Trained Text Embeddings for Enhanced Text-to-Speech Synthesis", ["Tomoki Hayashi", "Shinji Watanabe", "Tomoki Toda", "Kazuya Takeda", "Shubham Toshniwal", "Karen Livescu"], "https://doi.org/10.21437/Interspeech.2019-3177", 5, "interspeech", 2019]], "Sara Dahmani": [0, ["Conditional Variational Auto-Encoder for Text-Driven Expressive AudioVisual Speech Synthesis", ["Sara Dahmani", "Vincent Colotte", "Valerian Girard", "Slim Ouni"], "https://doi.org/10.21437/Interspeech.2019-2848", 5, "interspeech", 2019]], "Hang Su": [0, ["Unsupervised Methods for Audio Classification from Lecture Discussion Recordings", ["Hang Su", "Borislav Dzodzo", "Xixin Wu", "Xunying Liu", "Helen Meng"], "https://doi.org/10.21437/Interspeech.2019-2384", 5, "interspeech", 2019]], "Colin T. Annand": [0, ["Using Ultrasound Imaging to Create Augmented Visual Biofeedback for Articulatory Practice", ["Colin T. Annand", "Maurice Lamb", "Sarah Dugan", "Sarah R. Li", "Hannah M. Woeste", "T. Douglas Mast", "Michael A. Riley", "Jack A. Masterson", "Neeraja Mahalingam", "Kathryn J. Eary", "Caroline Spencer", "Suzanne Boyce", "Stephanie Jackson", "Anoosha Baxi", "Renee Seward"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8036.html", 2, "interspeech", 2019]], "Andrei C. Coman": [0, ["An Incremental Turn-Taking Model for Task-Oriented Dialog Systems", ["Andrei C. Coman", "Koichiro Yoshino", "Yukitoshi Murase", "Satoshi Nakamura", "Giuseppe Riccardi"], "https://doi.org/10.21437/Interspeech.2019-1826", 5, "interspeech", 2019]], "Astik Biswas": [0, ["Improved Low-Resource Somali Speech Recognition by Semi-Supervised Acoustic and Language Model Training", ["Astik Biswas", "Raghav Menon", "Ewald van der Westhuizen", "Thomas Niesler"], "https://doi.org/10.21437/Interspeech.2019-1328", 5, "interspeech", 2019], ["Semi-Supervised Acoustic Model Training for Five-Lingual Code-Switched ASR", ["Astik Biswas", "Emre Yilmaz", "Febe de Wet", "Ewald van der Westhuizen", "Thomas Niesler"], "https://doi.org/10.21437/Interspeech.2019-1325", 5, "interspeech", 2019]], "Ziqiang Shi": [0, ["Deep Attention Gated Dilated Temporal Convolutional Networks with Intra-Parallel Convolutional Modules for End-to-End Monaural Speech Separation", ["Ziqiang Shi", "Huibin Lin", "Liu Liu", "Rujie Liu", "Jiqing Han", "Anyan Shi"], "https://doi.org/10.21437/Interspeech.2019-1373", 5, "interspeech", 2019], ["End-to-End Monaural Speech Separation with Multi-Scale Dynamic Weighted Gated Dilated Convolutional Pyramid Network", ["Ziqiang Shi", "Huibin Lin", "Liu Liu", "Rujie Liu", "Shoji Hayakawa", "Shouji Harada", "Jiqing Han"], "https://doi.org/10.21437/Interspeech.2019-1292", 5, "interspeech", 2019]], "Yu-Chen Lin": [0, ["IA-NET: Acceleration and Compression of Speech Enhancement Using Integer-Adder Deep Neural Network", ["Yu-Chen Lin", "Yi-Te Hsu", "Szu-Wei Fu", "Yu Tsao", "Tei-Wei Kuo"], "https://doi.org/10.21437/Interspeech.2019-1207", 5, "interspeech", 2019]], "Juan M. Martin-Donas": [0, ["Multi-Channel Block-Online Source Extraction Based on Utterance Adaptation", ["Juan M. Martin-Donas", "Jens Heitkaemper", "Reinhold Haeb-Umbach", "Angel M. Gomez", "Antonio M. Peinado"], "https://doi.org/10.21437/Interspeech.2019-2244", 5, "interspeech", 2019]], "Heiga Zen": [0, ["LibriTTS: A Corpus Derived from LibriSpeech for Text-to-Speech", ["Heiga Zen", "Viet Dang", "Rob Clark", "Yu Zhang", "Ron J. Weiss", "Ye Jia", "Zhifeng Chen", "Yonghui Wu"], "https://doi.org/10.21437/Interspeech.2019-2441", 5, "interspeech", 2019]], "Karan Malhotra": [0, ["Active Learning Methods for Low Resource End-to-End Speech Recognition", ["Karan Malhotra", "Shubham Bansal", "Sriram Ganapathy"], "https://doi.org/10.21437/Interspeech.2019-2316", 5, "interspeech", 2019]], "A. Miwardelli": [0, ["Splash: Speech and Language Assessment in Schools and Homes", ["A. Miwardelli", "I. Gallagher", "J. Gibson", "Napoleon Katsos", "Kate M. Knill", "H. Wood"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8027.html", 2, "interspeech", 2019]], "Anna Piunova": [0, ["Rescoring Keyword Search Confidence Estimates with Graph-Based Re-Ranking Using Acoustic Word Embeddings", ["Anna Piunova", "Eugen Beck", "Ralf Schluter", "Hermann Ney"], "https://doi.org/10.21437/Interspeech.2019-1817", 5, "interspeech", 2019]], "Riyaz Ahmad Bhat": [0, ["Neural Transition Systems for Modeling Hierarchical Semantic Representations", ["Riyaz Ahmad Bhat", "John Chen", "Rashmi Prasad", "Srinivas Bangalore"], "https://doi.org/10.21437/Interspeech.2019-3075", 5, "interspeech", 2019]], "Erinc Dikici": [0, ["The SAIL LABS Media Mining Indexer and the CAVA Framework", ["Erinc Dikici", "Gerhard Backfried", "Jurgen Riedler"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8029.html", 2, "interspeech", 2019]], "Adria Mallol-Ragolta": [0, ["A Hierarchical Attention Network-Based Approach for Depression Detection from Transcribed Clinical Interviews", ["Adria Mallol-Ragolta", "Ziping Zhao", "Lukas Stappen", "Nicholas Cummins", "Bjorn W. Schuller"], "https://doi.org/10.21437/Interspeech.2019-2036", 5, "interspeech", 2019]], "Anderson R. Avila": [0, ["Blind Channel Response Estimation for Replay Attack Detection", ["Anderson R. Avila", "Md. Jahangir Alam", "Douglas D. OShaughnessy", "Tiago H. Falk"], "https://doi.org/10.21437/Interspeech.2019-2956", 5, "interspeech", 2019]], "Ajda Gokcen": [0, ["Dual Encoder Classifier Models as Constraints in Neural Text Normalization", ["Ajda Gokcen", "Hao Zhang", "Richard Sproat"], "https://doi.org/10.21437/Interspeech.2019-1135", 5, "interspeech", 2019]], "Avik Ray": [0, ["Iterative Delexicalization for Improved Spoken Language Understanding", ["Avik Ray", "Yilin Shen", "Hongxia Jin"], "https://doi.org/10.21437/Interspeech.2019-2955", 5, "interspeech", 2019]], "Tamas Gabor Csapo": [0, ["Ultrasound-Based Silent Speech Interface Built on a Continuous Vocoder", ["Tamas Gabor Csapo", "Mohammed Salah Al-Radhi", "Geza Nemeth", "Gabor Gosztolya", "Tamas Grosz", "Laszlo Toth", "Alexandra Marko"], "https://doi.org/10.21437/Interspeech.2019-2046", 5, "interspeech", 2019]], "Jennifer Williams": [0, ["Speech Replay Detection with x-Vector Attack Embeddings and Spectral Features", ["Jennifer Williams", "Joanna Rownicka"], "https://doi.org/10.21437/Interspeech.2019-1760", 5, "interspeech", 2019], ["Disentangling Style Factors from Speaker Representations", ["Jennifer Williams", "Simon King"], "https://doi.org/10.21437/Interspeech.2019-1769", 5, "interspeech", 2019]], "Hanna Mazzawi": [0, ["Improving Keyword Spotting and Language Identification via Neural Architecture Search at Scale", ["Hanna Mazzawi", "Xavi Gonzalvo", "Aleks Kracun", "Prashant Sridhar", "Niranjan Subrahmanya", "Ignacio Lopez-Moreno", "Hyun-Jin Park", "Patrick Violette"], "https://doi.org/10.21437/Interspeech.2019-1916", 5, "interspeech", 2019]], "Hee-Soo Heo": [0.996008962392807, ["Acoustic Scene Classification Using Teacher-Student Learning with Soft-Labels", ["Hee-Soo Heo", "Jee-weon Jung", "Hye-jin Shim", "Ha-Jin Yu"], "https://doi.org/10.21437/Interspeech.2019-1989", 5, "interspeech", 2019], ["End-to-End Losses Based on Speaker Basis Vectors and All-Speaker Hard Negative Mining for Speaker Verification", ["Hee-Soo Heo", "Jee-weon Jung", "Il-Ho Yang", "Sung-Hyun Yoon", "Hye-jin Shim", "Ha-Jin Yu"], "https://doi.org/10.21437/Interspeech.2019-1986", 5, "interspeech", 2019]], "Annika Nijveld": [0, ["ERP Signal Analysis with Temporal Resolution Using a Time Window Bank", ["Annika Nijveld", "Louis ten Bosch", "Mirjam Ernestus"], "https://doi.org/10.21437/Interspeech.2019-2729", 5, "interspeech", 2019]], "Huy Phan": [0, ["Spatio-Temporal Attention Pooling for Audio Scene Classification", ["Huy Phan", "Oliver Y. Chen", "Lam Pham", "Philipp Koch", "Maarten De Vos", "Ian Vince McLoughlin", "Alfred Mertins"], "https://doi.org/10.21437/Interspeech.2019-3040", 5, "interspeech", 2019]], "Zhaoyi Gu": [2.6499289741688248e-11, ["Speech Separation Using Independent Vector Analysis with an Amplitude Variable Gaussian Mixture Model", ["Zhaoyi Gu", "Jing Lu", "Kai Chen"], "https://doi.org/10.21437/Interspeech.2019-2076", 5, "interspeech", 2019]], "Divesh Lala": [0, ["Analysis of Effect and Timing of Fillers in Natural Turn-Taking", ["Divesh Lala", "Shizuka Nakamura", "Tatsuya Kawahara"], "https://doi.org/10.21437/Interspeech.2019-1527", 5, "interspeech", 2019]], "Vijay Ravi": [0, ["Voice Quality and Between-Frame Entropy for Sleepiness Estimation", ["Vijay Ravi", "Soo Jin Park", "Amber Afshan", "Abeer Alwan"], "https://doi.org/10.21437/Interspeech.2019-2988", 5, "interspeech", 2019]], "Yi Liu": [0, ["Large Margin Softmax Loss for Speaker Verification", ["Yi Liu", "Liang He", "Jia Liu"], "https://doi.org/10.21437/Interspeech.2019-2357", 5, "interspeech", 2019]], "Michael Picheny": [0, ["Challenging the Boundaries of Speech Recognition: The MALACH Corpus", ["Michael Picheny", "Zoltan Tuske", "Brian Kingsbury", "Kartik Audhkhasi", "Xiaodong Cui", "George Saon"], "https://doi.org/10.21437/Interspeech.2019-1907", 5, "interspeech", 2019]], "Pablo Perez Zarazaga": [0, ["Sound Privacy: A Conversational Speech Corpus for Quantifying the Experience of Privacy", ["Pablo Perez Zarazaga", "Sneha Das", "Tom Backstrom", "Vishnu Vidyadhara Raju Vegesna", "Anil Kumar Vuppala"], "https://doi.org/10.21437/Interspeech.2019-1172", 5, "interspeech", 2019]], "Sandeep Nallan Chakravarthula": [0, ["Predicting Behavior in Cancer-Afflicted Patient and Spouse Interactions Using Speech and Language", ["Sandeep Nallan Chakravarthula", "Haoqi Li", "Shao-Yen Tseng", "Maija Reblin", "Panayiotis G. Georgiou"], "https://doi.org/10.21437/Interspeech.2019-1888", 5, "interspeech", 2019]], "Youzhi Tu": [0, ["Variational Domain Adversarial Learning for Speaker Verification", ["Youzhi Tu", "Man-Wai Mak", "Jen-Tzung Chien"], "https://doi.org/10.21437/Interspeech.2019-2168", 5, "interspeech", 2019]], "Shen Huang": [0, ["Multimedia Simultaneous Translation System for Minority Language Communication with Mandarin", ["Shen Huang", "Bojie Hu", "Shan Huang", "Pengfei Hu", "Jian Kang", "Zhiqiang Lv", "Jinghao Yan", "Qi Ju", "Shiyin Kang", "Deyi Tuo", "Guangzhi Li", "Nurmemet Yolwas"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8020.html", 2, "interspeech", 2019]], "Shuai Wang": [2.6364129013245474e-07, ["On the Usage of Phonetic Information for Text-Independent Speaker Embedding Extraction", ["Shuai Wang", "Johan Rohdin", "Lukas Burget", "Oldrich Plchot", "Yanmin Qian", "Kai Yu", "Jan Cernocky"], "https://doi.org/10.21437/Interspeech.2019-3036", 5, "interspeech", 2019]], "Andy T. Liu": [0, ["Unsupervised End-to-End Learning of Discrete Linguistic Units for Voice Conversion", ["Andy T. Liu", "Po-chun Hsu", "Hung-yi Lee"], "https://doi.org/10.21437/Interspeech.2019-2048", 5, "interspeech", 2019]], "Gautam Bhattacharya": [0, ["Deep Speaker Recognition: Modular or Monolithic?", ["Gautam Bhattacharya", "Md. Jahangir Alam", "Patrick Kenny"], "https://doi.org/10.21437/Interspeech.2019-3146", 5, "interspeech", 2019]], "Kristina Tesch": [0, ["On Nonlinear Spatial Filtering in Multichannel Speech Enhancement", ["Kristina Tesch", "Robert Rehr", "Timo Gerkmann"], "https://doi.org/10.21437/Interspeech.2019-2751", 5, "interspeech", 2019]], "Andreas Triantafyllopoulos": [0, ["Towards Robust Speech Emotion Recognition Using Deep Residual Networks for Speech Enhancement", ["Andreas Triantafyllopoulos", "Gil Keren", "Johannes Wagner", "Ingmar Steiner", "Bjorn W. Schuller"], "https://doi.org/10.21437/Interspeech.2019-1811", 5, "interspeech", 2019]], "Shreyas Seshadri": [0, ["Augmented CycleGANs for Continuous Scale Normal-to-Lombard Speaking Style Conversion", ["Shreyas Seshadri", "Lauri Juvela", "Paavo Alku", "Okko Rasanen"], "https://doi.org/10.21437/Interspeech.2019-1681", 5, "interspeech", 2019]], "Vicky Zayats": [0, ["Disfluencies and Human Speech Transcription Errors", ["Vicky Zayats", "Trang Tran", "Richard A. Wright", "Courtney Mansfield", "Mari Ostendorf"], "https://doi.org/10.21437/Interspeech.2019-3134", 5, "interspeech", 2019]], "Ye Bai": [0.001440670166630298, ["A Time Delay Neural Network with Shared Weight Self-Attention for Small-Footprint Keyword Spotting", ["Ye Bai", "Jiangyan Yi", "Jianhua Tao", "Zhengqi Wen", "Zhengkun Tian", "Chenghao Zhao", "Cunhang Fan"], "https://doi.org/10.21437/Interspeech.2019-1676", 5, "interspeech", 2019], ["Learn Spelling from Teachers: Transferring Knowledge from Language Models to Sequence-to-Sequence Speech Recognition", ["Ye Bai", "Jiangyan Yi", "Jianhua Tao", "Zhengkun Tian", "Zhengqi Wen"], "https://doi.org/10.21437/Interspeech.2019-1554", 5, "interspeech", 2019]], "Tae Jin Park": [0.8472927659749985, ["Speaker Diarization with Lexical Information", ["Tae Jin Park", "Kyu J. Han", "Jing Huang", "Xiaodong He", "Bowen Zhou", "Panayiotis G. Georgiou", "Shrikanth Narayanan"], "https://doi.org/10.21437/Interspeech.2019-1947", 5, "interspeech", 2019], ["The Second DIHARD Challenge: System Description for USC-SAIL Team", ["Tae Jin Park", "Manoj Kumar", "Nikolaos Flemotomos", "Monisankha Pal", "Raghuveer Peri", "Rimita Lahiri", "Panayiotis G. Georgiou", "Shrikanth Narayanan"], "https://doi.org/10.21437/Interspeech.2019-1903", 5, "interspeech", 2019]], "Chelzy Belitz": [0, ["A Machine Learning Based Clustering Protocol for Determining Hearing Aid Initial Configurations from Pure-Tone Audiograms", ["Chelzy Belitz", "Hussnain Ali", "John H. L. Hansen"], "https://doi.org/10.21437/Interspeech.2019-3091", 5, "interspeech", 2019]], "Chaoran Liu": [0, ["A Neural Turn-Taking Model without RNN", ["Chaoran Liu", "Carlos Toshinori Ishi", "Hiroshi Ishiguro"], "https://doi.org/10.21437/Interspeech.2019-2270", 5, "interspeech", 2019]], "Wendy Lalhminghlui": [0, ["Vowel-Tone Interaction in Two Tibeto-Burman Languages", ["Wendy Lalhminghlui", "Viyazonuo Terhiija", "Priyankoo Sarmah"], "https://doi.org/10.21437/Interspeech.2019-2808", 5, "interspeech", 2019]], "Joao Monteiro": [0, ["Combining Speaker Recognition and Metric Learning for Speaker-Dependent Representation Learning", ["Joao Monteiro", "Md. Jahangir Alam", "Tiago H. Falk"], "https://doi.org/10.21437/Interspeech.2019-2974", 5, "interspeech", 2019]], "Mousmita Sarma": [0, ["Improving Emotion Identification Using Phone Posteriors in Raw Speech Waveform Based DNN", ["Mousmita Sarma", "Pegah Ghahremani", "Daniel Povey", "Nagendra Kumar Goel", "Kandarpa Kumar Sarma", "Najim Dehak"], "https://doi.org/10.21437/Interspeech.2019-2093", 5, "interspeech", 2019]], "P. V. Muhammed Shifas": [0, ["A Non-Causal FFTNet Architecture for Speech Enhancement", ["P. V. Muhammed Shifas", "Nagaraj Adiga", "Vassilis Tsiaras", "Yannis Stylianou"], "https://doi.org/10.21437/Interspeech.2019-2622", 5, "interspeech", 2019]], "Awni Hannun": [0, ["Sequence-to-Sequence Speech Recognition with Time-Depth Separable Convolutions", ["Awni Hannun", "Ann Lee", "Qiantong Xu", "Ronan Collobert"], "https://doi.org/10.21437/Interspeech.2019-2460", 5, "interspeech", 2019]], "Md Asif Jalal": [0, ["Learning Temporal Clusters Using Capsule Routing for Speech Emotion Recognition", ["Md Asif Jalal", "Erfan Loweimi", "Roger K. Moore", "Thomas Hain"], "https://doi.org/10.21437/Interspeech.2019-3068", 5, "interspeech", 2019]], "Philipp Klumpp": [0, ["Feature Space Visualization with Spatial Similarity Maps for Pathological Speech Data", ["Philipp Klumpp", "Juan Camilo Vasquez-Correa", "Tino Haderlein", "Elmar Noth"], "https://doi.org/10.21437/Interspeech.2019-2080", 5, "interspeech", 2019]], "Yi Zhao": [0, ["Does the Lombard Effect Improve Emotional Communication in Noise? - Analysis of Emotional Speech Acted in Noise", ["Yi Zhao", "Atsushi Ando", "Shinji Takaki", "Junichi Yamagishi", "Satoshi Kobashikawa"], "https://doi.org/10.21437/Interspeech.2019-1605", 5, "interspeech", 2019]], "Jeroen Zegers": [0, ["CNN-LSTM Models for Multi-Speaker Source Separation Using Bayesian Hyper Parameter Optimization", ["Jeroen Zegers", "Hugo Van hamme"], "https://doi.org/10.21437/Interspeech.2019-2423", 5, "interspeech", 2019]], "Yerbolat Khassanov": [0, ["Constrained Output Embeddings for End-to-End Code-Switching Speech Recognition with Only Monolingual Data", ["Yerbolat Khassanov", "Haihua Xu", "Van Tung Pham", "Zhiping Zeng", "Eng Siong Chng", "Chongjia Ni", "Bin Ma"], "https://doi.org/10.21437/Interspeech.2019-1867", 5, "interspeech", 2019], ["Enriching Rare Word Representations in Neural Language Models by Embedding Matrix Augmentation", ["Yerbolat Khassanov", "Zhiping Zeng", "Van Tung Pham", "Haihua Xu", "Eng Siong Chng"], "https://doi.org/10.21437/Interspeech.2019-1858", 5, "interspeech", 2019]], "Eleanor Chodroff": [0, ["Testing the Distinctiveness of Intonational Tunes: Evidence from Imitative Productions in American English", ["Eleanor Chodroff", "Jennifer S. Cole"], "https://doi.org/10.21437/Interspeech.2019-2684", 5, "interspeech", 2019]], "Qinyi Wang": [1.6792620627370525e-08, ["Code-Switching Detection Using ASR-Generated Language Posteriors", ["Qinyi Wang", "Emre Yilmaz", "Adem Derinel", "Haizhou Li"], "https://doi.org/10.21437/Interspeech.2019-1161", 5, "interspeech", 2019]], "Gyorgy Kovacs": [0, ["Examining the Combination of Multi-Band Processing and Channel Dropout for Robust Speech Recognition", ["Gyorgy Kovacs", "Laszlo Toth", "Dirk Van Compernolle", "Marcus Liwicki"], "https://doi.org/10.21437/Interspeech.2019-3215", 5, "interspeech", 2019]], "Simon Roessig": [0, ["Dimensions of Prosodic Prominence in an Attractor Model", ["Simon Roessig", "Doris Mucke", "Lena Pagel"], "https://doi.org/10.21437/Interspeech.2019-2227", 5, "interspeech", 2019]], "Conceicao Cunha": [0, ["On the Role of Oral Configurations in European Portuguese Nasal Vowels", ["Conceicao Cunha", "Samuel S. Silva", "Antonio J. S. Teixeira", "Catarina Oliveira", "Paula Martins", "Arun A. Joseph", "Jens Frahm"], "https://doi.org/10.21437/Interspeech.2019-2232", 5, "interspeech", 2019]], "Emre Yilmaz": [0, ["Large-Scale Speaker Diarization of Radio Broadcast Archives", ["Emre Yilmaz", "Adem Derinel", "Kun Zhou", "Henk van den Heuvel", "Niko Brummer", "Haizhou Li", "David A. van Leeuwen"], "https://doi.org/10.21437/Interspeech.2019-1399", 5, "interspeech", 2019], ["Multi-Graph Decoding for Code-Switching ASR", ["Emre Yilmaz", "Samuel Cohen", "Xianghu Yue", "David A. van Leeuwen", "Haizhou Li"], "https://doi.org/10.21437/Interspeech.2019-1125", 5, "interspeech", 2019]], "Rahul Gupta": [0, ["One-vs-All Models for Asynchronous Training: An Empirical Analysis", ["Rahul Gupta", "Aman Alok", "Shankar Ananthakrishnan"], "https://doi.org/10.21437/Interspeech.2019-2760", 5, "interspeech", 2019]], "Buddhi Wickramasinghe": [0, ["Biologically Inspired Adaptive-Q Filterbanks for Replay Spoofing Attack Detection", ["Buddhi Wickramasinghe", "Eliathamby Ambikairajah", "Julien Epps"], "https://doi.org/10.21437/Interspeech.2019-1535", 5, "interspeech", 2019]], "Ahmed Ali": [0, ["Towards Variability Resistant Dialectal Speech Evaluation", ["Ahmed Ali", "Salam Khalifa", "Nizar Habash"], "https://doi.org/10.21437/Interspeech.2019-2692", 5, "interspeech", 2019]], "Ralf Schluter": [0, ["Survey Talk: Modeling in Automatic Speech Recognition: Beyond Hidden Markov Models", ["Ralf Schluter"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/abs4.html", 0, "interspeech", 2019]], "Hansi Yang": [0.5, ["Music Genre Classification Using Duplicated Convolutional Layers in Neural Networks", ["Hansi Yang", "Wei-Qiang Zhang"], "https://doi.org/10.21437/Interspeech.2019-1298", 5, "interspeech", 2019]], "Jee-weon Jung": [0.9995425939559937, ["Replay Attack Detection with Complementary High-Resolution Information Using End-to-End DNN for the ASVspoof 2019 Challenge", ["Jee-weon Jung", "Hye-jin Shim", "Hee-Soo Heo", "Ha-Jin Yu"], "https://doi.org/10.21437/Interspeech.2019-1991", 5, "interspeech", 2019], ["RawNet: Advanced End-to-End Deep Neural Network Using Raw Waveforms for Text-Independent Speaker Verification", ["Jee-weon Jung", "Hee-Soo Heo", "Ju-ho Kim", "Hye-jin Shim", "Ha-Jin Yu"], "https://doi.org/10.21437/Interspeech.2019-1982", 5, "interspeech", 2019]], "Ju Lin": [0, ["Speech Enhancement Using Forked Generative Adversarial Networks with Spectral Subtraction", ["Ju Lin", "Sufeng Niu", "Zice Wei", "Xiang Lan", "Adriaan J. van Wijngaarden", "Melissa C. Smith", "Kuang-Ching Wang"], "https://doi.org/10.21437/Interspeech.2019-2954", 5, "interspeech", 2019]], "Harishchandra Dubey": [0, ["Toeplitz Inverse Covariance Based Robust Speaker Clustering for Naturalistic Audio Streams", ["Harishchandra Dubey", "Abhijeet Sangwan", "John H. L. Hansen"], "https://doi.org/10.21437/Interspeech.2019-1102", 5, "interspeech", 2019]], "Victor R. Martinez": [0, ["Identifying Therapist and Client Personae for Therapeutic Alliance Estimation", ["Victor R. Martinez", "Nikolaos Flemotomos", "Victor Ardulov", "Krishna Somandepalli", "Simon B. Goldberg", "Zac E. Imel", "David C. Atkins", "Shrikanth Narayanan"], "https://doi.org/10.21437/Interspeech.2019-2829", 5, "interspeech", 2019]], "Ryandhimas E. Zezario": [0, ["Specialized Speech Enhancement Model Selection Based on Learned Non-Intrusive Quality Assessment Metric", ["Ryandhimas E. Zezario", "Szu-Wei Fu", "Xugang Lu", "Hsin-Min Wang", "Yu Tsao"], "https://doi.org/10.21437/Interspeech.2019-2425", 5, "interspeech", 2019]], "Hao Sun": [0.05930156260728836, ["Token-Level Ensemble Distillation for Grapheme-to-Phoneme Conversion", ["Hao Sun", "Xu Tan", "Jun-Wei Gan", "Hongzhi Liu", "Sheng Zhao", "Tao Qin", "Tie-Yan Liu"], "https://doi.org/10.21437/Interspeech.2019-1208", 5, "interspeech", 2019]], "Fahimeh Bahmaninezhad": [0, ["A Comprehensive Study of Speech Separation: Spectrogram vs Waveform Separation", ["Fahimeh Bahmaninezhad", "Jian Wu", "Rongzhi Gu", "Shi-Xiong Zhang", "Yong Xu", "Meng Yu", "Dong Yu"], "https://doi.org/10.21437/Interspeech.2019-3181", 5, "interspeech", 2019]], "Khe Chai Sim": [1.1623309546848759e-05, ["An Investigation into On-Device Personalization of End-to-End Automatic Speech Recognition Models", ["Khe Chai Sim", "Petr Zadrazil", "Francoise Beaufays"], "https://doi.org/10.21437/Interspeech.2019-1752", 5, "interspeech", 2019]], "Takashi Maekaku": [0, ["Simultaneous Detection and Localization of a Wake-Up Word Using Multi-Task Learning of the Duration and Endpoint", ["Takashi Maekaku", "Yusuke Kida", "Akihiko Sugiyama"], "https://doi.org/10.21437/Interspeech.2019-1180", 5, "interspeech", 2019]], "Shounan An": [9.443089766136836e-06, ["Robust Keyword Spotting via Recycle-Pooling for Mobile Game", ["Shounan An", "Youngsoo Kim", "Hu Xu", "Jinwoo Lee", "Myungwoo Lee", "Insoo Oh"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8010.html", 2, "interspeech", 2019]], "Pierre-Michel Bousquet": [0, ["On Robustness of Unsupervised Domain Adaptation for Speaker Recognition", ["Pierre-Michel Bousquet", "Mickael Rouvier"], "https://doi.org/10.21437/Interspeech.2019-1524", 5, "interspeech", 2019]], "Yu Zhang": [0, ["Learning to Speak Fluently in a Foreign Language: Multilingual Speech Synthesis and Cross-Language Voice Cloning", ["Yu Zhang", "Ron J. Weiss", "Heiga Zen", "Yonghui Wu", "Zhifeng Chen", "R. J. Skerry-Ryan", "Ye Jia", "Andrew Rosenberg", "Bhuvana Ramabhadran"], "https://doi.org/10.21437/Interspeech.2019-2668", 5, "interspeech", 2019]], "I-Hung Hsu": [0, ["NIESR: Nuisance Invariant End-to-End Speech Recognition", ["I-Hung Hsu", "Ayush Jaiswal", "Premkumar Natarajan"], "https://doi.org/10.21437/Interspeech.2019-1836", 5, "interspeech", 2019]], "Jack Serrino": [0, ["Contextual Recovery of Out-of-Lattice Named Entities in Automatic Speech Recognition", ["Jack Serrino", "Leonid Velikovich", "Petar S. Aleksic", "Cyril Allauzen"], "https://doi.org/10.21437/Interspeech.2019-2962", 5, "interspeech", 2019]], "Xizi Wei": [0, ["Neural Network-Based Modeling of Phonetic Durations", ["Xizi Wei", "Melvyn Hunt", "Adrian Skilling"], "https://doi.org/10.21437/Interspeech.2019-2102", 5, "interspeech", 2019]], "Natalia Tomashenko": [0, ["Investigating Adaptation and Transfer Learning for End-to-End Spoken Language Understanding from Speech", ["Natalia Tomashenko", "Antoine Caubriere", "Yannick Esteve"], "https://doi.org/10.21437/Interspeech.2019-2158", 5, "interspeech", 2019]], "Hui Lu": [0, ["One-Shot Voice Conversion with Global Speaker Embeddings", ["Hui Lu", "Zhiyong Wu", "Dongyang Dai", "Runnan Li", "Shiyin Kang", "Jia Jia", "Helen Meng"], "https://doi.org/10.21437/Interspeech.2019-2365", 5, "interspeech", 2019]], "Hiroki Mori": [0, ["Conversational and Social Laughter Synthesis with WaveNet", ["Hiroki Mori", "Tomohiro Nagata", "Yoshiko Arimoto"], "https://doi.org/10.21437/Interspeech.2019-2131", 4, "interspeech", 2019]], "Eva Szekely": [0, ["Off the Cuff: Exploring Extemporaneous Speech Delivery with TTS", ["Eva Szekely", "Gustav Eje Henter", "Jonas Beskow", "Joakim Gustafson"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8026.html", 2, "interspeech", 2019], ["Spontaneous Conversational Speech Synthesis from Found Data", ["Eva Szekely", "Gustav Eje Henter", "Jonas Beskow", "Joakim Gustafson"], "https://doi.org/10.21437/Interspeech.2019-2836", 5, "interspeech", 2019]], "Eric Sun": [4.787108991877176e-05, ["Layer Trajectory BLSTM", ["Eric Sun", "Jinyu Li", "Yifan Gong"], "https://doi.org/10.21437/Interspeech.2019-2971", 5, "interspeech", 2019]], "Nadee Seneviratne": [0, ["Multi-Corpus Acoustic-to-Articulatory Speech Inversion", ["Nadee Seneviratne", "Ganesh Sivaraman", "Carol Y. Espy-Wilson"], "https://doi.org/10.21437/Interspeech.2019-3168", 5, "interspeech", 2019]], "Harish Arsikere": [0, ["Multi-Dialect Acoustic Modeling Using Phone Mapping and Online i-Vectors", ["Harish Arsikere", "Ashtosh Sapru", "Sri Garimella"], "https://doi.org/10.21437/Interspeech.2019-2881", 5, "interspeech", 2019]], "Pingchuan Ma": [0, ["Investigating the Lombard Effect Influence on End-to-End Audio-Visual Speech Recognition", ["Pingchuan Ma", "Stavros Petridis", "Maja Pantic"], "https://doi.org/10.21437/Interspeech.2019-2726", 5, "interspeech", 2019]], "Janaki Sheth": [0, ["Identifying Input Features for Development of Real-Time Translation of Neural Signals to Text", ["Janaki Sheth", "Ariel Tankus", "Michelle Tran", "Lindy Comstock", "Itzhak Fried", "William Speier"], "https://doi.org/10.21437/Interspeech.2019-3092", 5, "interspeech", 2019]], "Bidisha Sharma": [0, ["A Combination of Model-Based and Feature-Based Strategy for Speech-to-Singing Alignment", ["Bidisha Sharma", "Haizhou Li"], "https://doi.org/10.21437/Interspeech.2019-1942", 5, "interspeech", 2019], ["Multi-Level Adaptive Speech Activity Detector for Speech in Naturalistic Environments", ["Bidisha Sharma", "Rohan Kumar Das", "Haizhou Li"], "https://doi.org/10.21437/Interspeech.2019-1928", 5, "interspeech", 2019], ["On the Importance of Audio-Source Separation for Singer Identification in Polyphonic Music", ["Bidisha Sharma", "Rohan Kumar Das", "Haizhou Li"], "https://doi.org/10.21437/Interspeech.2019-1925", 5, "interspeech", 2019]], "Mattias Heldner": [0, ["Voice Quality as a Turn-Taking Cue", ["Mattias Heldner", "Marcin Wlodarczak", "Stefan Benus", "Agustin Gravano"], "https://doi.org/10.21437/Interspeech.2019-1592", 5, "interspeech", 2019]], "E. Felker": [0, ["Lexically Guided Perceptual Learning of a Vowel Shift in an Interactive L2 Listening Context", ["E. Felker", "Mirjam Ernestus", "Mirjam Broersma"], "https://doi.org/10.21437/Interspeech.2019-1414", 5, "interspeech", 2019]], "Like Hui": [0, ["Kernel Machines Beat Deep Neural Networks on Mask-Based Single-Channel Speech Enhancement", ["Like Hui", "Siyuan Ma", "Mikhail Belkin"], "https://doi.org/10.21437/Interspeech.2019-1344", 5, "interspeech", 2019]], "Lanhua You": [0, ["Multi-Task Learning with High-Order Statistics for x-Vector Based Text-Independent Speaker Verification", ["Lanhua You", "Wu Guo", "Li-Rong Dai", "Jun Du"], "https://doi.org/10.21437/Interspeech.2019-2264", 5, "interspeech", 2019], ["Deep Neural Network Embeddings with Gating Mechanisms for Text-Independent Speaker Verification", ["Lanhua You", "Wu Guo", "Li-Rong Dai", "Jun Du"], "https://doi.org/10.21437/Interspeech.2019-1746", 5, "interspeech", 2019]], "Shashi Kumar": [0, ["Far-Field Speech Enhancement Using Heteroscedastic Autoencoder for Improved Speech Recognition", ["Shashi Kumar", "Shakti P. Rath"], "https://doi.org/10.21437/Interspeech.2019-2032", 5, "interspeech", 2019]], "Chenda Li": [0, ["Prosody Usage Optimization for Children Speech Recognition with Zero Resource Children Speech", ["Chenda Li", "Yanmin Qian"], "https://doi.org/10.21437/Interspeech.2019-2659", 5, "interspeech", 2019]], "Guanlong Zhao": [0, ["Foreign Accent Conversion by Synthesizing Speech from Phonetic Posteriorgrams", ["Guanlong Zhao", "Shaojin Ding", "Ricardo Gutierrez-Osuna"], "https://doi.org/10.21437/Interspeech.2019-1778", 5, "interspeech", 2019]], "Sungrack Yun": [0.9998851120471954, ["An End-to-End Text-Independent Speaker Verification Framework with a Keyword Adversarial Network", ["Sungrack Yun", "Janghoon Cho", "Jungyun Eum", "Wonil Chang", "Kyuwoong Hwang"], "https://doi.org/10.21437/Interspeech.2019-2208", 5, "interspeech", 2019]], "Shengkui Zhao": [0, ["Fast Learning for Non-Parallel Many-to-Many Voice Conversion with Residual Star Generative Adversarial Networks", ["Shengkui Zhao", "Trung Hieu Nguyen", "Hao Wang", "Bin Ma"], "https://doi.org/10.21437/Interspeech.2019-2067", 5, "interspeech", 2019], ["Multi-Task Multi-Network Joint-Learning of Deep Residual Networks and Cycle-Consistency Generative Adversarial Networks for Robust Speech Recognition", ["Shengkui Zhao", "Chongjia Ni", "Rong Tong", "Bin Ma"], "https://doi.org/10.21437/Interspeech.2019-2078", 5, "interspeech", 2019]], "Zixiaofan Yang": [1.3875621835380487e-18, ["Predicting Humor by Learning from Time-Aligned Comments", ["Zixiaofan Yang", "Bingyan Hu", "Julia Hirschberg"], "https://doi.org/10.21437/Interspeech.2019-3113", 5, "interspeech", 2019], ["Linguistically-Informed Training of Acoustic Word Embeddings for Low-Resource Languages", ["Zixiaofan Yang", "Julia Hirschberg"], "https://doi.org/10.21437/Interspeech.2019-3119", 5, "interspeech", 2019]], "Thomas Pellegrini": [0, ["The Airbus Air Traffic Control Speech Recognition 2018 Challenge: Towards ATC Automatic Transcription and Call Sign Detection", ["Thomas Pellegrini", "Jerome Farinas", "Estelle Delpech", "Francois Lancelot"], "https://doi.org/10.21437/Interspeech.2019-1962", 5, "interspeech", 2019]], "Christian Bergler": [0, ["Deep Learning for Orca Call Type Identification - A Fully Unsupervised Approach", ["Christian Bergler", "Manuel Schmitt", "Rachael Xi Cheng", "Andreas K. Maier", "Volker Barth", "Elmar Noth"], "https://doi.org/10.21437/Interspeech.2019-1857", 5, "interspeech", 2019]], "Shuzhuang Xu": [0, ["Direct F0 Estimation with Neural-Network-Based Regression", ["Shuzhuang Xu", "Hiroshi Shimodaira"], "https://doi.org/10.21437/Interspeech.2019-3267", 5, "interspeech", 2019]], "Omnia Ibrahim": [0, ["Fundamental Frequency Accommodation in Multi-Party Human-Robot Game Interactions: The Effect of Winning or Losing", ["Omnia Ibrahim", "Gabriel Skantze", "Sabine Stoll", "Volker Dellwo"], "https://doi.org/10.21437/Interspeech.2019-2496", 5, "interspeech", 2019]], "Anne Hermes": [0, ["Intragestural Variation in Natural Sentence Production: Essential Tremor Patients Treated with DBS", ["Anne Hermes", "Doris Mucke", "Tabea Thies", "Michael T. Barbe"], "https://doi.org/10.21437/Interspeech.2019-2389", 5, "interspeech", 2019]], "Katherine Metcalf": [0, ["Mirroring to Build Trust in Digital Assistants", ["Katherine Metcalf", "Barry-John Theobald", "Garrett Weinberg", "Robert Lee", "Ing-Marie Jonsson", "Russ Webb", "Nicholas Apostoloff"], "https://doi.org/10.21437/Interspeech.2019-1829", 5, "interspeech", 2019]], "Sangwook Park": [0.9990171939134598, ["A Study of a Cross-Language Perception Based on Cortical Analysis Using Biomimetic STRFs", ["Sangwook Park", "David K. Han", "Mounya Elhilali"], "https://doi.org/10.21437/Interspeech.2019-2507", 5, "interspeech", 2019]], "Golan Levy": [0, ["GECKO - A Tool for Effective Annotation of Human Conversations", ["Golan Levy", "Raquel Sitman", "Ido Amir", "Eduard Golshtein", "Ran Mochary", "Eilon Reshef", "Roi Reichart", "Omri Allouche"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8025.html", 2, "interspeech", 2019]], "Debadatta Dash": [0, ["Towards a Speaker Independent Speech-BCI Using Speaker Adaptation", ["Debadatta Dash", "Alan Wisler", "Paul Ferrari", "Jun Wang"], "https://doi.org/10.21437/Interspeech.2019-3109", 5, "interspeech", 2019], ["Spatial and Spectral Fingerprint in the Brain: Speaker Identification from Single Trial MEG Signals", ["Debadatta Dash", "Paul Ferrari", "Jun Wang"], "https://doi.org/10.21437/Interspeech.2019-3105", 5, "interspeech", 2019]], "Patricia Thaine": [0, ["Extracting Mel-Frequency and Bark-Frequency Cepstral Coefficients from Encrypted Signals", ["Patricia Thaine", "Gerald Penn"], "https://doi.org/10.21437/Interspeech.2019-1136", 5, "interspeech", 2019]], "Pramit Saha": [0, ["SPEAK YOUR MIND! Towards Imagined Speech Recognition with Hierarchical Deep Learning", ["Pramit Saha", "Muhammad Abdul-Mageed", "Sidney S. Fels"], "https://doi.org/10.21437/Interspeech.2019-3041", 5, "interspeech", 2019]], "Bajibabu Bollepalli": [0, ["Lombard Speech Synthesis Using Transfer Learning in a Tacotron Text-to-Speech System", ["Bajibabu Bollepalli", "Lauri Juvela", "Paavo Alku"], "https://doi.org/10.21437/Interspeech.2019-1333", 5, "interspeech", 2019]], "Pieter Appeltans": [0, ["Practical Applicability of Deep Neural Networks for Overlapping Speaker Separation", ["Pieter Appeltans", "Jeroen Zegers", "Hugo Van hamme"], "https://doi.org/10.21437/Interspeech.2019-1807", 5, "interspeech", 2019]], "Gerardo Roa Dabike": [0, ["Automatic Lyric Transcription from Karaoke Vocal Tracks: Resources and a Baseline System", ["Gerardo Roa Dabike", "Jon Barker"], "https://doi.org/10.21437/Interspeech.2019-2378", 5, "interspeech", 2019]], "Rupayan Chakraborty": [0, ["Front-End Feature Compensation and Denoising for Noise Robust Speech Emotion Recognition", ["Rupayan Chakraborty", "Ashish Panda", "Meghna Pandharipande", "Sonal Joshi", "Sunil Kumar Kopparapu"], "https://doi.org/10.21437/Interspeech.2019-2243", 5, "interspeech", 2019]], "Jia Xin Koh": [1.8766590947905115e-08, ["Building the Singapore English National Speech Corpus", ["Jia Xin Koh", "Aqilah Mislan", "Kevin Khoo", "Brian Ang", "Wilson Ang", "Charmaine Ng", "Ying-Ying Tan"], "https://doi.org/10.21437/Interspeech.2019-1525", 5, "interspeech", 2019]], "Cibu Johny": [0, ["Cross-Lingual Consistency of Phonological Features: An Empirical Study", ["Cibu Johny", "Alexander Gutkin", "Martin Jansche"], "https://doi.org/10.21437/Interspeech.2019-2184", 5, "interspeech", 2019]], "Kohei Hara": [0, ["Turn-Taking Prediction Based on Detection of Transition Relevance Place", ["Kohei Hara", "Koji Inoue", "Katsuya Takanashi", "Tatsuya Kawahara"], "https://doi.org/10.21437/Interspeech.2019-1537", 5, "interspeech", 2019]], "Ryo Masumura": [0, ["Improving Conversation-Context Language Models with Multiple Spoken Language Understanding Models", ["Ryo Masumura", "Tomohiro Tanaka", "Atsushi Ando", "Hosana Kamiyama", "Takanobu Oba", "Satoshi Kobashikawa", "Yushi Aono"], "https://doi.org/10.21437/Interspeech.2019-1534", 5, "interspeech", 2019], ["End-to-End Automatic Speech Recognition with a Reconstruction Criterion Using Speech-to-Text and Text-to-Speech Encoder-Decoders", ["Ryo Masumura", "Hiroshi Sato", "Tomohiro Tanaka", "Takafumi Moriya", "Yusuke Ijima", "Takanobu Oba"], "https://doi.org/10.21437/Interspeech.2019-2111", 5, "interspeech", 2019]], "Ascension Gallardo-Antolin": [0, ["A Saliency-Based Attention LSTM Model for Cognitive Load Classification from Speech", ["Ascension Gallardo-Antolin", "Juan Manuel Montero"], "https://doi.org/10.21437/Interspeech.2019-1603", 5, "interspeech", 2019]], "Wikus Pienaar": [0, ["Online Speech Processing and Analysis Suite", ["Wikus Pienaar", "Daan Wissing"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8007.html", 2, "interspeech", 2019]], "Rohit Voleti": [0, ["Objective Assessment of Social Skills Using Automated Language Analysis for Identification of Schizophrenia and Bipolar Disorder", ["Rohit Voleti", "Stephanie Woolridge", "Julie M. Liss", "Melissa Milanovic", "Christopher R. Bowie", "Visar Berisha"], "https://doi.org/10.21437/Interspeech.2019-2960", 5, "interspeech", 2019]], "Shadi Pirhosseinloo": [0, ["Monaural Speech Enhancement with Dilated Convolutions", ["Shadi Pirhosseinloo", "Jonathan S. Brumberg"], "https://doi.org/10.21437/Interspeech.2019-2782", 5, "interspeech", 2019]], "Jia-Xiang Chen": [0, ["A Chinese Dataset for Identifying Speakers in Novels", ["Jia-Xiang Chen", "Zhen-Hua Ling", "Li-Rong Dai"], "https://doi.org/10.21437/Interspeech.2019-1614", 5, "interspeech", 2019]], "Nirmesh J. Shah": [0, ["Phone Aware Nearest Neighbor Technique Using Spectral Transition Measure for Non-Parallel Voice Conversion", ["Nirmesh J. Shah", "Hemant A. Patil"], "https://doi.org/10.21437/Interspeech.2019-1504", 5, "interspeech", 2019], ["Whether to Pretrain DNN or not?: An Empirical Analysis for Voice Conversion", ["Nirmesh J. Shah", "Hardik B. Sailor", "Hemant A. Patil"], "https://doi.org/10.21437/Interspeech.2019-2608", 5, "interspeech", 2019]], "Zexin Cai": [0, ["Polyphone Disambiguation for Mandarin Chinese Using Conditional Neural Network with Multi-Level Embedding Features", ["Zexin Cai", "Yaogen Yang", "Chuxiong Zhang", "Xiaoyi Qin", "Ming Li"], "https://doi.org/10.21437/Interspeech.2019-1235", 5, "interspeech", 2019]], "Tharshini Gunendradasan": [0, ["An Adaptive-Q Cochlear Model for Replay Spoofing Detection", ["Tharshini Gunendradasan", "Eliathamby Ambikairajah", "Julien Epps", "Haizhou Li"], "https://doi.org/10.21437/Interspeech.2019-2361", 5, "interspeech", 2019]], "Zhehuai Chen": [0, ["Joint Grapheme and Phoneme Embeddings for Contextual End-to-End ASR", ["Zhehuai Chen", "Mahaveer Jain", "Yongqiang Wang", "Michael L. Seltzer", "Christian Fuegen"], "https://doi.org/10.21437/Interspeech.2019-1434", 5, "interspeech", 2019]], "Carlo Drioli": [0, ["Aerodynamics and Lumped-Masses Combined with Delay Lines for Modeling Vertical and Anterior-Posterior Phase Differences in Pathological Vocal Fold Vibration", ["Carlo Drioli", "Philipp Aichinger"], "https://doi.org/10.21437/Interspeech.2019-2338", 5, "interspeech", 2019]], "Antoine Caubriere": [0, ["Curriculum-Based Transfer Learning for an Effective End-to-End Spoken Language Understanding and Domain Portability", ["Antoine Caubriere", "Natalia A. Tomashenko", "Antoine Laurent", "Emmanuel Morin", "Nathalie Camelin", "Yannick Esteve"], "https://doi.org/10.21437/Interspeech.2019-1832", 5, "interspeech", 2019]], "Nigel G. Ward": [0, ["Survey Talk: Prosody Research and Applications: The State of the Art", ["Nigel G. Ward"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/abs20.html", 0, "interspeech", 2019]], "Samik Sadhu": [0, ["Modulation Vectors as Robust Feature Representation for ASR in Domain Mismatched Conditions", ["Samik Sadhu", "Hynek Hermansky"], "https://doi.org/10.21437/Interspeech.2019-2723", 5, "interspeech", 2019]], "Michele Gubian": [0, ["Tracking the New Zealand English NEAR/SQUARE Merger Using Functional Principal Components Analysis", ["Michele Gubian", "Jonathan Harrington", "Mary Stevens", "Florian Schiel", "Paul Warren"], "https://doi.org/10.21437/Interspeech.2019-2115", 5, "interspeech", 2019], ["Zooming in on Spatiotemporal V-to-C Coarticulation with Functional PCA", ["Michele Gubian", "Manfred Pastatter", "Marianne Pouplier"], "https://doi.org/10.21437/Interspeech.2019-2143", 5, "interspeech", 2019]], "Cory Stephenson": [0, ["Semi-Supervised Voice Conversion with Amortized Variational Inference", ["Cory Stephenson", "Gokce Keskin", "Anil Thomas", "Oguz H. Elibol"], "https://doi.org/10.21437/Interspeech.2019-1840", 5, "interspeech", 2019]], "Ivan Halim Parmonangan": [0, ["Speech Quality Evaluation of Synthesized Japanese Speech Using EEG", ["Ivan Halim Parmonangan", "Hiroki Tanaka", "Sakriani Sakti", "Shinnosuke Takamichi", "Satoshi Nakamura"], "https://doi.org/10.21437/Interspeech.2019-2059", 5, "interspeech", 2019]], "Laurent El Shafey": [0, ["Joint Speech Recognition and Speaker Diarization via Sequence Transduction", ["Laurent El Shafey", "Hagen Soltau", "Izhak Shafran"], "https://doi.org/10.21437/Interspeech.2019-1943", 5, "interspeech", 2019]], "Qiuying Shi": [0, ["Subspace Pooling Based Temporal Features Extraction for Audio Event Recognition", ["Qiuying Shi", "Hui Luo", "Jiqing Han"], "https://doi.org/10.21437/Interspeech.2019-2047", 5, "interspeech", 2019]], "Ruchao Fan": [0, ["An Online Attention-Based Model for Speech Recognition", ["Ruchao Fan", "Pan Zhou", "Wei Chen", "Jia Jia", "Gang Liu"], "https://doi.org/10.21437/Interspeech.2019-2218", 5, "interspeech", 2019]], "Hironori Takemoto": [0, ["Speech Organ Contour Extraction Using Real-Time MRI and Machine Learning Method", ["Hironori Takemoto", "Tsubasa Goto", "Yuya Hagihara", "Sayaka Hamanaka", "Tatsuya Kitamura", "Yukiko Nota", "Kikuo Maekawa"], "https://doi.org/10.21437/Interspeech.2019-1593", 5, "interspeech", 2019]], "Jianwei Yu": [1.7882772346267117e-10, ["Comparative Study of Parametric and Representation Uncertainty Modeling for Recurrent Neural Network Language Models", ["Jianwei Yu", "Max W. Y. Lam", "Shoukang Hu", "Xixin Wu", "Xu Li", "Yuewen Cao", "Xunying Liu", "Helen Meng"], "https://doi.org/10.21437/Interspeech.2019-1927", 5, "interspeech", 2019]], "Yan Xiong": [0, ["Residual + Capsule Networks (ResCap) for Simultaneous Single-Channel Overlapped Keyword Recognition", ["Yan Xiong", "Visar Berisha", "Chaitali Chakrabarti"], "https://doi.org/10.21437/Interspeech.2019-2913", 5, "interspeech", 2019]], "Nagaraj Adiga": [0, ["Speech Enhancement for Noise-Robust Speech Synthesis Using Wasserstein GAN", ["Nagaraj Adiga", "Yannis Pantazis", "Vassilis Tsiaras", "Yannis Stylianou"], "https://doi.org/10.21437/Interspeech.2019-2648", 5, "interspeech", 2019]], "Ziping Zhao": [0, ["Attention-Enhanced Connectionist Temporal Classification for Discrete Speech Emotion Recognition", ["Ziping Zhao", "Zhongtian Bao", "Zixing Zhang", "Nicholas Cummins", "Haishuai Wang", "Bjorn W. Schuller"], "https://doi.org/10.21437/Interspeech.2019-1649", 5, "interspeech", 2019]], "Alexandros Koumparoulis": [0, ["MobiLipNet: Resource-Efficient Deep Learning Based Lipreading", ["Alexandros Koumparoulis", "Gerasimos Potamianos"], "https://doi.org/10.21437/Interspeech.2019-2618", 5, "interspeech", 2019]], "Nichola Lubold": [0, ["Do Conversational Partners Entrain on Articulatory Precision?", ["Nichola Lubold", "Stephanie A. Borrie", "Tyson S. Barrett", "Megan M. Willi", "Visar Berisha"], "https://doi.org/10.21437/Interspeech.2019-1786", 5, "interspeech", 2019]], "Charles C. Onu": [0, ["Neural Transfer Learning for Cry-Based Diagnosis of Perinatal Asphyxia", ["Charles C. Onu", "Jonathan Lebensold", "William L. Hamilton", "Doina Precup"], "https://doi.org/10.21437/Interspeech.2019-2340", 5, "interspeech", 2019]], "Alex Mayle": [0, ["Diagnosing Dysarthria with Long Short-Term Memory Networks", ["Alex Mayle", "Zhiwei Mou", "Razvan C. Bunescu", "Sadegh Mirshekarian", "Li Xu", "Chang Liu"], "https://doi.org/10.21437/Interspeech.2019-2903", 5, "interspeech", 2019]], "Min Tang": [0, ["Hybrid Arbitration Using Raw ASR String and NLU Information - Taking the Best of Both Embedded World and Cloud World", ["Min Tang"], "https://doi.org/10.21437/Interspeech.2019-2586", 5, "interspeech", 2019]], "Hui-Ting Hong": [1.5810451827746874e-06, ["Investigating the Variability of Voice Quality and Pain Levels as a Function of Multiple Clinical Parameters", ["Hui-Ting Hong", "Jeng-Lin Li", "Yi-Ming Weng", "Chip-Jin Ng", "Chi-Chun Lee"], "https://doi.org/10.21437/Interspeech.2019-2247", 5, "interspeech", 2019]], "Bogdan Ludusan": [0, ["Laughter Dynamics in Dyadic Conversations", ["Bogdan Ludusan", "Petra Wagner"], "https://doi.org/10.21437/Interspeech.2019-1733", 5, "interspeech", 2019], ["Nasal Consonant Discrimination in Infant- and Adult-Directed Speech", ["Bogdan Ludusan", "Annett Jorschick", "Reiko Mazuka"], "https://doi.org/10.21437/Interspeech.2019-1737", 5, "interspeech", 2019]], "Luis Bernardo": [0, ["Unbabel Talk - Human Verified Translations for Voice Instant Messaging", ["Luis Bernardo", "Mathieu Giquel", "Sebastiao Quintas", "Paulo Dimas", "Helena Moniz", "Isabel Trancoso"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8034.html", 2, "interspeech", 2019]], "Rahul Goel": [0, ["HyST: A Hybrid Approach for Flexible and Accurate Dialogue State Tracking", ["Rahul Goel", "Shachi Paul", "Dilek Hakkani-Tur"], "https://doi.org/10.21437/Interspeech.2019-1863", 5, "interspeech", 2019]], "Mingye Dong": [0.0735570676624775, ["Vocal Pitch Extraction in Polyphonic Music Using Convolutional Residual Network", ["Mingye Dong", "Jie Wu", "Jian Luan"], "https://doi.org/10.21437/Interspeech.2019-2286", 5, "interspeech", 2019]], "Janina Molczanow": [0, ["An Acoustic Study of Vowel Undershoot in a System with Several Degrees of Prominence", ["Janina Molczanow", "Beata Lukaszewicz", "Anna Lukaszewicz"], "https://doi.org/10.21437/Interspeech.2019-1806", 5, "interspeech", 2019]], "Xugang Lu": [0, ["Class-Wise Centroid Distance Metric Learning for Acoustic Event Detection", ["Xugang Lu", "Peng Shen", "Sheng Li", "Yu Tsao", "Hisashi Kawai"], "https://doi.org/10.21437/Interspeech.2019-2271", 5, "interspeech", 2019]], "Wiehan Agenbag": [0, ["Improving Automatically Induced Lexicons for Highly Agglutinating Languages Using Data-Driven Morphological Segmentation", ["Wiehan Agenbag", "Thomas Niesler"], "https://doi.org/10.21437/Interspeech.2019-2164", 5, "interspeech", 2019]], "Jingyang Zhang": [0, ["Multi-Scale Time-Frequency Attention for Acoustic Event Detection", ["Jingyang Zhang", "Wenhao Ding", "Jintao Kang", "Liang He"], "https://doi.org/10.21437/Interspeech.2019-1587", 5, "interspeech", 2019]], "Cal Peyser": [0, ["Improving Performance of End-to-End ASR on Numeric Sequences", ["Cal Peyser", "Hao Zhang", "Tara N. Sainath", "Zelin Wu"], "https://doi.org/10.21437/Interspeech.2019-1345", 5, "interspeech", 2019]], "Long Wu": [0.010015965672209859, ["Speaker-Invariant Feature-Mapping for Distant Speech Recognition via Adversarial Teacher-Student Learning", ["Long Wu", "Hangting Chen", "Li Wang", "Pengyuan Zhang", "Yonghong Yan"], "https://doi.org/10.21437/Interspeech.2019-2136", 5, "interspeech", 2019]], "Alan McCree": [0, ["Speaker Diarization Using Leave-One-Out Gaussian PLDA Clustering of DNN Embeddings", ["Alan McCree", "Gregory Sell", "Daniel Garcia-Romero"], "https://doi.org/10.21437/Interspeech.2019-2912", 5, "interspeech", 2019]], "Suwon Shon": [0, ["MCE 2018: The 1st Multi-Target Speaker Detection and Identification Challenge Evaluation", ["Suwon Shon", "Najim Dehak", "Douglas A. Reynolds", "James R. Glass"], "https://doi.org/10.21437/Interspeech.2019-1572", 5, "interspeech", 2019], ["VoiceID Loss: Speech Enhancement for Speaker Verification", ["Suwon Shon", "Hao Tang", "James R. Glass"], "https://doi.org/10.21437/Interspeech.2019-1496", 5, "interspeech", 2019], ["Large-Scale Speaker Retrieval on Random Speaker Variability Subspace", ["Suwon Shon", "Younggun Lee", "Taesu Kim"], "https://doi.org/10.21437/Interspeech.2019-1498", 5, "interspeech", 2019]], "Wiebke Ahlers": [0, ["Sibilant Variation in New Englishes: A Comparative Sociophonetic Study of Trinidadian and American English /s(tr)/-Retraction", ["Wiebke Ahlers", "Philipp Meer"], "https://doi.org/10.21437/Interspeech.2019-1821", 5, "interspeech", 2019]], "John S. Novak III": [0, ["The Effects of Time Expansion on English as a Second Language Individuals", ["John S. Novak III", "Daniel Bunn", "Robert V. Kenyon"], "https://doi.org/10.21437/Interspeech.2019-2763", 5, "interspeech", 2019]], "Akhilesh Kumar Dubey": [0, ["Hypernasality Severity Detection Using Constant Q Cepstral Coefficients", ["Akhilesh Kumar Dubey", "S. R. Mahadeva Prasanna", "S. Dandapat"], "https://doi.org/10.21437/Interspeech.2019-2151", 5, "interspeech", 2019]], "Jian Gao": [0, ["Nonparallel Emotional Speech Conversion", ["Jian Gao", "Deep Chakraborty", "Hamidou Tembine", "Olaitan Olaleye"], "https://doi.org/10.21437/Interspeech.2019-2878", 5, "interspeech", 2019]], "Feng-Guang Su": [0, ["Personalized Dialogue Response Generation Learned from Monologues", ["Feng-Guang Su", "Aliyah R. Hsu", "Yi-Lin Tuan", "Hung-yi Lee"], "https://doi.org/10.21437/Interspeech.2019-1696", 5, "interspeech", 2019]], "Kyubyong Park": [0.9501790404319763, ["CSS10: A Collection of Single Speaker Speech Datasets for 10 Languages", ["Kyubyong Park", "Thomas Mulc"], "https://doi.org/10.21437/Interspeech.2019-1500", 5, "interspeech", 2019]], "Hongwei Song": [9.227629860220077e-08, ["Acoustic Scene Classification by Implicitly Identifying Distinct Sound Events", ["Hongwei Song", "Jiqing Han", "Shiwen Deng", "Zhihao Du"], "https://doi.org/10.21437/Interspeech.2019-2231", 5, "interspeech", 2019]], "Gene-Ping Yang": [2.743683413797271e-08, ["Improved Speech Separation with Time-and-Frequency Cross-Domain Joint Embedding and Clustering", ["Gene-Ping Yang", "Chao-I Tuan", "Hung-yi Lee", "Lin-Shan Lee"], "https://doi.org/10.21437/Interspeech.2019-2181", 5, "interspeech", 2019]], "Gabor Gosztolya": [0, ["Calibrating DNN Posterior Probability Estimates of HMM/DNN Models to Improve Social Signal Detection from Audio Data", ["Gabor Gosztolya", "Laszlo Toth"], "https://doi.org/10.21437/Interspeech.2019-2552", 5, "interspeech", 2019], ["Using Fisher Vector and Bag-of-Audio-Words Representations to Identify Styrian Dialects, Sleepiness, Baby & Orca Sounds", ["Gabor Gosztolya"], "https://doi.org/10.21437/Interspeech.2019-1726", 5, "interspeech", 2019], ["Using the Bag-of-Audio-Word Feature Representation of ASR DNN Posteriors for Paralinguistic Classification", ["Gabor Gosztolya"], "https://doi.org/10.21437/Interspeech.2019-1163", 5, "interspeech", 2019]], "Amin Fazel": [0, ["Deep Multitask Acoustic Echo Cancellation", ["Amin Fazel", "Mostafa El-Khamy", "Jungwon Lee"], "https://doi.org/10.21437/Interspeech.2019-2908", 5, "interspeech", 2019]], "Subhadeep Dey": [0, ["Exploiting Semi-Supervised Training Through a Dropout Regularization in End-to-End Speech Recognition", ["Subhadeep Dey", "Petr Motlicek", "Trung Bui", "Franck Dernoncourt"], "https://doi.org/10.21437/Interspeech.2019-3246", 5, "interspeech", 2019]], "Yoshiki Masuyama": [0, ["Multichannel Loss Function for Supervised Speech Source Separation by Mask-Based Beamforming", ["Yoshiki Masuyama", "Masahito Togami", "Tatsuya Komatsu"], "https://doi.org/10.21437/Interspeech.2019-1289", 5, "interspeech", 2019]], "Shiri Lev-Ari": [0, ["The Different Roles of Expectations in Phonetic and Lexical Processing", ["Shiri Lev-Ari", "Robin Dodsworth", "Jeff Mielke", "Sharon Peperkamp"], "https://doi.org/10.21437/Interspeech.2019-1795", 5, "interspeech", 2019]], "Deniece S. Nazareth": [0, ["An Acoustic and Lexical Analysis of Emotional Valence in Spontaneous Speech: Autobiographical Memory Recall in Older Adults", ["Deniece S. Nazareth", "Ellen Tournier", "Sarah Leimkotter", "Esther Janse", "Dirk Heylen", "Gerben J. Westerhof", "Khiet P. Truong"], "https://doi.org/10.21437/Interspeech.2019-1823", 5, "interspeech", 2019]], "Daniel T. Braithwaite": [0, ["Speech Enhancement with Variance Constrained Autoencoders", ["Daniel T. Braithwaite", "W. Bastiaan Kleijn"], "https://doi.org/10.21437/Interspeech.2019-1809", 5, "interspeech", 2019]], "Ivan Medennikov": [0, ["The STC ASR System for the VOiCES from a Distance Challenge 2019", ["Ivan Medennikov", "Yuri Y. Khokhlov", "Aleksei Romanenko", "Ivan Sorokin", "Anton Mitrofanov", "Vladimir Bataev", "Andrei Andrusenko", "Tatiana Prisyach", "Mariya Korenevskaya", "Oleg Petrov", "Alexander Zatvornitskiy"], "https://doi.org/10.21437/Interspeech.2019-1574", 5, "interspeech", 2019], ["The STC ASR System for the VOiCES from a Distance Challenge 2019", ["Ivan Medennikov", "Yuri Y. Khokhlov", "Aleksei Romanenko", "Ivan Sorokin", "Anton Mitrofanov", "Vladimir Bataev", "Andrei Andrusenko", "Tatiana Prisyach", "Mariya Korenevskaya", "Oleg Petrov", "Alexander Zatvornitskiy"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/abs17.html", 0, "interspeech", 2019]], "Fu-Kai Chuang": [0, ["Speaker-Aware Deep Denoising Autoencoder with Embedded Speaker Identity for Speech Enhancement", ["Fu-Kai Chuang", "Syu-Siang Wang", "Jeih-weih Hung", "Yu Tsao", "Shih-Hau Fang"], "https://doi.org/10.21437/Interspeech.2019-2108", 5, "interspeech", 2019]], "Louise Ratko": [0, ["Articulation of Vowel Length Contrasts in Australian English", ["Louise Ratko", "Michael I. Proctor", "Felicity Cox"], "https://doi.org/10.21437/Interspeech.2019-2995", 5, "interspeech", 2019]], "Sibo Tong": [0, ["Unbiased Semi-Supervised LF-MMI Training Using Dropout", ["Sibo Tong", "Apoorv Vyas", "Philip N. Garner", "Herve Bourlard"], "https://doi.org/10.21437/Interspeech.2019-2678", 5, "interspeech", 2019]], "John H. L. Hansen": [0, ["The 2019 Inaugural Fearless Steps Challenge: A Giant Leap for Naturalistic Audio", ["John H. L. Hansen", "Aditya Joglekar", "Meena Chandra Shekhar", "Vinay Kothapally", "Chengzhu Yu", "Lakshmish Kaushik", "Abhijeet Sangwan"], "https://doi.org/10.21437/Interspeech.2019-2301", 5, "interspeech", 2019]], "Shun-Chang Zhong": [0, ["Predicting Group Performances Using a Personality Composite-Network Architecture During Collaborative Task", ["Shun-Chang Zhong", "Yun-Shao Lin", "Chun-Min Chang", "Yi-Ching Liu", "Chi-Chun Lee"], "https://doi.org/10.21437/Interspeech.2019-2087", 5, "interspeech", 2019]], "Ellen Marklund": [0, ["No Distributional Learning in Adults from Attended Listening to Non-Speech", ["Ellen Marklund", "Johan Sjons", "Lisa Gustavsson", "Elisabet Eir Cortes"], "https://doi.org/10.21437/Interspeech.2019-1674", 5, "interspeech", 2019]], "Xiaoqi Li": [0, ["A Convolutional Neural Network with Non-Local Module for Speech Enhancement", ["Xiaoqi Li", "Yaxing Li", "Meng Li", "Shan Xu", "Yuanjie Dong", "Xinrong Sun", "Shengwu Xiong"], "https://doi.org/10.21437/Interspeech.2019-2472", 5, "interspeech", 2019]], "Manasa Prasad": [0, ["Building Large-Vocabulary ASR Systems for Languages Without Any Audio Training Data", ["Manasa Prasad", "Daan van Esch", "Sandy Ritchie", "Jonas Fromseier Mortensen"], "https://doi.org/10.21437/Interspeech.2019-1775", 5, "interspeech", 2019]], "Samuel S. Silva": [0, ["Exploring Critical Articulator Identification from 50Hz RT-MRI Data of the Vocal Tract", ["Samuel S. Silva", "Antonio J. S. Teixeira", "Conceicao Cunha", "Nuno Almeida", "Arun A. Joseph", "Jens Frahm"], "https://doi.org/10.21437/Interspeech.2019-2897", 5, "interspeech", 2019]], "Xingfeng Li": [0, ["The Contribution of Acoustic Features Analysis to Model Emotion Perceptual Process for Language Diversity", ["Xingfeng Li", "Masato Akagi"], "https://doi.org/10.21437/Interspeech.2019-2229", 5, "interspeech", 2019]], "Xue Bai": [1.5237832030834397e-05, ["A Hybrid Approach to Acoustic Scene Classification Based on Universal Acoustic Models", ["Xue Bai", "Jun Du", "Zi-Rui Wang", "Chin-Hui Lee"], "https://doi.org/10.21437/Interspeech.2019-2171", 5, "interspeech", 2019]], "Juan Camilo Vasquez-Correa": [0, ["Phonet: A Tool Based on Gated Recurrent Neural Networks to Extract Phonological Posteriors from Speech", ["Juan Camilo Vasquez-Correa", "Philipp Klumpp", "Juan Rafael Orozco-Arroyave", "Elmar Noth"], "https://doi.org/10.21437/Interspeech.2019-1405", 5, "interspeech", 2019], ["Apkinson: A Mobile Solution for Multimodal Assessment of Patients with Parkinson's Disease", ["Juan Camilo Vasquez-Correa", "Tomas Arias-Vergara", "Philipp Klumpp", "M. Strauss", "Arne Kuderle", "Nils Roth", "S. Bayerl", "Nicanor Garcia-Ospina", "Paula Andrea Perez-Toro", "L. Felipe Parra-Gallego", "Cristian David Rios-Urrego", "D. Escobar-Grisales", "Juan Rafael Orozco-Arroyave", "Bjorn Eskofier", "Elmar Noth"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8003.html", 2, "interspeech", 2019]], "Dan Du": [0, ["The Production of Chinese Affricates /ts/ and /tsh/ by Native Urdu Speakers", ["Dan Du", "Jinsong Zhang"], "https://doi.org/10.21437/Interspeech.2019-1638", 5, "interspeech", 2019]], "Nursadul Mamun": [0, ["Quantifying Cochlear Implant Users' Ability for Speaker Identification Using CI Auditory Stimuli", ["Nursadul Mamun", "Ria Ghosh", "John H. L. Hansen"], "https://doi.org/10.21437/Interspeech.2019-1852", 5, "interspeech", 2019], ["Convolutional Neural Network-Based Speech Enhancement for Cochlear Implant Recipients", ["Nursadul Mamun", "Soheil Khorram", "John H. L. Hansen"], "https://doi.org/10.21437/Interspeech.2019-1850", 5, "interspeech", 2019]], "Han Zhu": [0, ["Multi-Accent Adaptation Based on Gate Mechanism", ["Han Zhu", "Li Wang", "Pengyuan Zhang", "Yonghong Yan"], "https://doi.org/10.21437/Interspeech.2019-3155", 5, "interspeech", 2019]], "Gabor Kiss": [0, ["Depression State Assessment: Application for Detection of Depression by Speech", ["Gabor Kiss", "David Sztaho", "Klara Vicsi"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8004.html", 2, "interspeech", 2019]], "Wangyou Zhang": [0, ["Knowledge Distillation for End-to-End Monaural Multi-Talker ASR System", ["Wangyou Zhang", "Xuankai Chang", "Yanmin Qian"], "https://doi.org/10.21437/Interspeech.2019-3192", 5, "interspeech", 2019], ["Robust DOA Estimation Based on Convolutional Neural Network and Time-Frequency Masking", ["Wangyou Zhang", "Ying Zhou", "Yanmin Qian"], "https://doi.org/10.21437/Interspeech.2019-3158", 5, "interspeech", 2019]], "Ruizhi Li": [0, ["Performance Monitoring for End-to-End Speech Recognition", ["Ruizhi Li", "Gregory Sell", "Hynek Hermansky"], "https://doi.org/10.21437/Interspeech.2019-3137", 5, "interspeech", 2019]], "Adele Aubin": [0, ["Improving Speech Synthesis with Discourse Relations", ["Adele Aubin", "Alessandra Cervone", "Oliver Watts", "Simon King"], "https://doi.org/10.21437/Interspeech.2019-1945", 5, "interspeech", 2019]], "Yuan-Hao Yi": [1.506132818462902e-07, ["Singing Voice Synthesis Using Deep Autoregressive Neural Networks for Acoustic Modeling", ["Yuan-Hao Yi", "Yang Ai", "Zhen-Hua Ling", "Li-Rong Dai"], "https://doi.org/10.21437/Interspeech.2019-1563", 5, "interspeech", 2019]], "Jeong-Uk Bang": [0.9999900758266449, ["Extending an Acoustic Data-Driven Phone Set for Spontaneous Speech Recognition", ["Jeong-Uk Bang", "Mu-Yeol Choi", "Sang-Hun Kim", "Oh-Wook Kwon"], "https://doi.org/10.21437/Interspeech.2019-1979", 5, "interspeech", 2019]], "Hannah King": [0, ["The Contribution of Lip Protrusion to Anglo-English /r/: Evidence from Hyper- and Non-Hyperarticulated Speech", ["Hannah King", "Emmanuel Ferragne"], "https://doi.org/10.21437/Interspeech.2019-2851", 5, "interspeech", 2019]], "Lucy Skidmore": [0, ["Using Alexa for Flashcard-Based Learning", ["Lucy Skidmore", "Roger K. Moore"], "https://doi.org/10.21437/Interspeech.2019-2893", 5, "interspeech", 2019]], "Amanda Seidl": [0, ["Towards Detection of Canonical Babbling by Citizen Scientists: Performance as a Function of Clip Length", ["Amanda Seidl", "Anne S. Warlaumont", "Alejandrina Cristia"], "https://doi.org/10.21437/Interspeech.2019-1773", 5, "interspeech", 2019]], "Anjuli Kannan": [0, ["Large-Scale Multilingual Speech Recognition with a Streaming End-to-End Model", ["Anjuli Kannan", "Arindrima Datta", "Tara N. Sainath", "Eugene Weinstein", "Bhuvana Ramabhadran", "Yonghui Wu", "Ankur Bapna", "Zhifeng Chen", "Seungji Lee"], "https://doi.org/10.21437/Interspeech.2019-2858", 5, "interspeech", 2019]], "Markus Kitza": [0, ["Cumulative Adaptation for BLSTM Acoustic Models", ["Markus Kitza", "Pavel Golik", "Ralf Schluter", "Hermann Ney"], "https://doi.org/10.21437/Interspeech.2019-2162", 5, "interspeech", 2019]], "Andros Tjandra": [0, ["VQVAE Unsupervised Unit Discovery and Multi-Scale Code2Spec Inverter for Zerospeech Challenge 2019", ["Andros Tjandra", "Berrak Sisman", "Mingyang Zhang", "Sakriani Sakti", "Haizhou Li", "Satoshi Nakamura"], "https://doi.org/10.21437/Interspeech.2019-3232", 5, "interspeech", 2019]], "Lukas Drude": [0, ["Unsupervised Training of Neural Mask-Based Beamforming", ["Lukas Drude", "Jahn Heymann", "Reinhold Haeb-Umbach"], "https://doi.org/10.21437/Interspeech.2019-2549", 5, "interspeech", 2019]], "John Gideon": [0, ["Emotion Recognition from Natural Phone Conversations in Individuals with and without Recent Suicidal Ideation", ["John Gideon", "Heather T. Schatten", "Melvin G. McInnis", "Emily Mower Provost"], "https://doi.org/10.21437/Interspeech.2019-1830", 5, "interspeech", 2019]], "Alexandra Marko": [0, ["Articulatory Analysis of Transparent Vowel /i\u02d0/ in Harmonic and Antiharmonic Hungarian Stems: Is There a Difference?", ["Alexandra Marko", "Marton Bartok", "Tamas Gabor Csapo", "Tekla Etelka Graczi", "Andrea Deme"], "https://doi.org/10.21437/Interspeech.2019-2352", 5, "interspeech", 2019]], "Tom Backstrom": [0, ["End-to-End Optimization of Source Models for Speech and Audio Coding Using a Machine Learning Framework", ["Tom Backstrom"], "https://doi.org/10.21437/Interspeech.2019-1284", 5, "interspeech", 2019]], "Tomas Arias-Vergara": [0, ["Phone-Attribute Posteriors to Evaluate the Speech of Cochlear Implant Users", ["Tomas Arias-Vergara", "Juan Rafael Orozco-Arroyave", "Milos Cernak", "Sandra Gollwitzer", "Maria Schuster", "Elmar Noth"], "https://doi.org/10.21437/Interspeech.2019-2144", 5, "interspeech", 2019]], "Anirudh Raju": [0, ["Scalable Multi Corpora Neural Language Models for ASR", ["Anirudh Raju", "Denis Filimonov", "Gautam Tiwari", "Guitang Lan", "Ariya Rastrow"], "https://doi.org/10.21437/Interspeech.2019-3060", 5, "interspeech", 2019]], "Ankur T. Patil": [0, ["Energy Separation-Based Instantaneous Frequency Estimation for Cochlear Cepstral Feature for Replay Spoof Detection", ["Ankur T. Patil", "Rajul Acharya", "Pulikonda Krishna Aditya Sai", "Hemant A. Patil"], "https://doi.org/10.21437/Interspeech.2019-2742", 5, "interspeech", 2019]], "Eran Raveh": [0, ["Three's a Crowd? Effects of a Second Human on Vocal Accommodation with a Voice Assistant", ["Eran Raveh", "Ingo Siegert", "Ingmar Steiner", "Iona Gessinger", "Bernd Mobius"], "https://doi.org/10.21437/Interspeech.2019-1825", 5, "interspeech", 2019]], "Motoyuki Suzuki": [0, ["Lyrics Recognition from Singing Voice Focused on Correspondence Between Voice and Notes", ["Motoyuki Suzuki", "Sho Tomita", "Tomoki Morita"], "https://doi.org/10.21437/Interspeech.2019-1318", 4, "interspeech", 2019]], "Zhiping Zeng": [0, ["On the End-to-End Solution to Mandarin-English Code-Switching Speech Recognition", ["Zhiping Zeng", "Yerbolat Khassanov", "Van Tung Pham", "Haihua Xu", "Eng Siong Chng", "Haizhou Li"], "https://doi.org/10.21437/Interspeech.2019-1429", 5, "interspeech", 2019]], "Yibin Zheng": [0, ["Forward-Backward Decoding for Regularizing End-to-End TTS", ["Yibin Zheng", "Xi Wang", "Lei He", "Shifeng Pan", "Frank K. Soong", "Zhengqi Wen", "Jianhua Tao"], "https://doi.org/10.21437/Interspeech.2019-2325", 5, "interspeech", 2019]], "Roger K. Moore": [0, ["On the Use/Misuse of the Term 'Phoneme'", ["Roger K. Moore", "Lucy Skidmore"], "https://doi.org/10.21437/Interspeech.2019-2711", 5, "interspeech", 2019]], "Hannah P. Rowe": [0, ["Profiling Speech Motor Impairments in Persons with Amyotrophic Lateral Sclerosis: An Acoustic-Based Approach", ["Hannah P. Rowe", "Jordan R. Green"], "https://doi.org/10.21437/Interspeech.2019-2911", 5, "interspeech", 2019]], "Maximillian Paulus": [0, ["Talker Intelligibility and Listening Effort with Temporally Modified Speech", ["Maximillian Paulus", "Valerie Hazan", "Patti Adank"], "https://doi.org/10.21437/Interspeech.2019-1402", 5, "interspeech", 2019]], "Jingbei Li": [0, ["Knowledge-Based Linguistic Encoding for End-to-End Mandarin Text-to-Speech Synthesis", ["Jingbei Li", "Zhiyong Wu", "Runnan Li", "Pengpeng Zhi", "Song Yang", "Helen Meng"], "https://doi.org/10.21437/Interspeech.2019-1118", 5, "interspeech", 2019]], "Pavel Sturm": [0, ["Perceptual Evaluation of Early versus Late F0 Peaks in the Intonation Structure of Czech Question-Word Questions", ["Pavel Sturm", "Jan Volin"], "https://doi.org/10.21437/Interspeech.2019-2082", 5, "interspeech", 2019]], "Bolaji Yusuf": [0, ["Temporally-Aware Acoustic Unit Discovery for Zerospeech 2019 Challenge", ["Bolaji Yusuf", "Alican Gok", "Batuhan Gundogdu", "Oyku Deniz Kose", "Murat Saraclar"], "https://doi.org/10.21437/Interspeech.2019-1430", 5, "interspeech", 2019], ["An Empirical Evaluation of DTW Subsampling Methods for Keyword Search", ["Bolaji Yusuf", "Murat Saraclar"], "https://doi.org/10.21437/Interspeech.2019-2413", 5, "interspeech", 2019]], "Dominik Schiller": [0, ["Relevance-Based Feature Masking: Improving Neural Network Based Whale Classification Through Explainable Artificial Intelligence", ["Dominik Schiller", "Tobias Huber", "Florian Lingenfelser", "Michael Dietz", "Andreas Seiderer", "Elisabeth Andre"], "https://doi.org/10.21437/Interspeech.2019-2707", 5, "interspeech", 2019]], "Kazuki Irie": [0, ["On the Choice of Modeling Unit for Sequence-to-Sequence Speech Recognition", ["Kazuki Irie", "Rohit Prabhavalkar", "Anjuli Kannan", "Antoine Bruguier", "David Rybach", "Patrick Nguyen"], "https://doi.org/10.21437/Interspeech.2019-2277", 5, "interspeech", 2019], ["Language Modeling with Deep Transformers", ["Kazuki Irie", "Albert Zeyer", "Ralf Schluter", "Hermann Ney"], "https://doi.org/10.21437/Interspeech.2019-2225", 5, "interspeech", 2019]], "Pengcheng Guo": [0, ["Unsupervised Adaptation with Adversarial Dropout Regularization for Robust Speech Recognition", ["Pengcheng Guo", "Sining Sun", "Lei Xie"], "https://doi.org/10.21437/Interspeech.2019-2544", 5, "interspeech", 2019]], "Kartik Audhkhasi": [0, ["Forget a Bit to Learn Better: Soft Forgetting for CTC-Based Automatic Speech Recognition", ["Kartik Audhkhasi", "George Saon", "Zoltan Tuske", "Brian Kingsbury", "Michael Picheny"], "https://doi.org/10.21437/Interspeech.2019-2841", 5, "interspeech", 2019]], "Sunghye Cho": [0.9963593035936356, ["Automatic Detection of Autism Spectrum Disorder in Children Using Acoustic and Text Features from Brief Natural Conversations", ["Sunghye Cho", "Mark Liberman", "Neville Ryant", "Meredith Cola", "Robert T. Schultz", "Julia Parish-Morris"], "https://doi.org/10.21437/Interspeech.2019-1452", 5, "interspeech", 2019], ["Automatic Detection of Prosodic Focus in American English", ["Sunghye Cho", "Mark Liberman", "Yong-cheol Lee"], "https://doi.org/10.21437/Interspeech.2019-1668", 5, "interspeech", 2019]], "Hiroshi Seki": [0, ["End-to-End Multilingual Multi-Speaker Speech Recognition", ["Hiroshi Seki", "Takaaki Hori", "Shinji Watanabe", "Jonathan Le Roux", "John R. Hershey"], "https://doi.org/10.21437/Interspeech.2019-3038", 5, "interspeech", 2019], ["Vectorized Beam Search for CTC-Attention-Based Speech Recognition", ["Hiroshi Seki", "Takaaki Hori", "Shinji Watanabe", "Niko Moritz", "Jonathan Le Roux"], "https://doi.org/10.21437/Interspeech.2019-2860", 5, "interspeech", 2019]], "Yusuke Fujita": [0, ["End-to-End Neural Speaker Diarization with Permutation-Free Objectives", ["Yusuke Fujita", "Naoyuki Kanda", "Shota Horiguchi", "Kenji Nagamatsu", "Shinji Watanabe"], "https://doi.org/10.21437/Interspeech.2019-2899", 5, "interspeech", 2019]], "Seyedeh Zahra Razavi": [0, ["Investigating Linguistic and Semantic Features for Turn-Taking Prediction in Open-Domain Human-Computer Conversation", ["Seyedeh Zahra Razavi", "Benjamin Kane", "Lenhart K. Schubert"], "https://doi.org/10.21437/Interspeech.2019-3152", 5, "interspeech", 2019]], "Nobukatsu Hojo": [0, ["Evaluating Intention Communication by TTS Using Explicit Definitions of Illocutionary Act Performance", ["Nobukatsu Hojo", "Noboru Miyazaki"], "https://doi.org/10.21437/Interspeech.2019-2188", 5, "interspeech", 2019]], "Marc Delcroix": [0, ["End-to-End SpeakerBeam for Single Channel Target Speech Recognition", ["Marc Delcroix", "Shinji Watanabe", "Tsubasa Ochiai", "Keisuke Kinoshita", "Shigeki Karita", "Atsunori Ogawa", "Tomohiro Nakatani"], "https://doi.org/10.21437/Interspeech.2019-1856", 5, "interspeech", 2019]], "Danny Merkx": [0, ["Language Learning Using Speech to Image Retrieval", ["Danny Merkx", "Stefan L. Frank", "Mirjam Ernestus"], "https://doi.org/10.21437/Interspeech.2019-3067", 5, "interspeech", 2019]], "Kyu J. Han": [0.11794104427099228, ["Survey Talk: When Attention Meets Speech Applications: Speech & Speaker Recognition Perspective", ["Kyu J. Han", "Ramon Prieto", "Tao Ma"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/abs5.html", 0, "interspeech", 2019], ["Multi-Stride Self-Attention for Speech Recognition", ["Kyu J. Han", "Jing Huang", "Yun Tang", "Xiaodong He", "Bowen Zhou"], "https://doi.org/10.21437/Interspeech.2019-1973", 5, "interspeech", 2019]], "Karan Taneja": [0, ["Exploiting Monolingual Speech Corpora for Code-Mixed Speech Recognition", ["Karan Taneja", "Satarupa Guha", "Preethi Jyothi", "Basil Abraham"], "https://doi.org/10.21437/Interspeech.2019-1959", 5, "interspeech", 2019]], "Manuel Sam Ribeiro": [0, ["Ultrasound Tongue Imaging for Diarization and Alignment of Child Speech Therapy Sessions", ["Manuel Sam Ribeiro", "Aciel Eshky", "Korin Richmond", "Steve Renals"], "https://doi.org/10.21437/Interspeech.2019-2612", 5, "interspeech", 2019]], "Min-Jae Hwang": [0.8463334739208221, ["Parameter Enhancement for MELP Speech Codec in Noisy Communication Environment", ["Min-Jae Hwang", "Hong-Goo Kang"], "https://doi.org/10.21437/Interspeech.2019-3249", 5, "interspeech", 2019]], "Langzhou Chen": [0, ["Acoustic Model Bootstrapping Using Semi-Supervised Learning", ["Langzhou Chen", "Volker Leutnant"], "https://doi.org/10.21437/Interspeech.2019-2818", 5, "interspeech", 2019]], "Yanping Chen": [0, ["Rare Sound Event Detection Using Deep Learning and Data Augmentation", ["Yanping Chen", "Hongxia Jin"], "https://doi.org/10.21437/Interspeech.2019-1985", 5, "interspeech", 2019]], "Jana Vosse": [0, ["A User-Friendly and Adaptable Re-Implementation of an Acoustic Prominence Detection and Annotation Tool", ["Jana Vosse", "Petra Wagner"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8015.html", 2, "interspeech", 2019]], "Mingyue Niu": [0, ["Automatic Depression Level Detection via \u2113p-Norm Pooling", ["Mingyue Niu", "Jianhua Tao", "Bin Liu", "Cunhang Fan"], "https://doi.org/10.21437/Interspeech.2019-1617", 5, "interspeech", 2019]], "Jianfeng Zhou": [0, ["Deep Speaker Embedding Extraction with Channel-Wise Feature Responses and Additive Supervision Softmax Loss Function", ["Jianfeng Zhou", "Tao Jiang", "Zheng Li", "Lin Li", "Qingyang Hong"], "https://doi.org/10.21437/Interspeech.2019-1704", 5, "interspeech", 2019]], "Jaime Lorenzo-Trueba": [0, ["Towards Achieving Robust Universal Neural Vocoding", ["Jaime Lorenzo-Trueba", "Thomas Drugman", "Javier Latorre", "Thomas Merritt", "Bartosz Putrycz", "Roberto Barra-Chicote", "Alexis Moinet", "Vatsal Aggarwal"], "https://doi.org/10.21437/Interspeech.2019-1424", 5, "interspeech", 2019]], "Ignacio Vinals": [0, ["ViVoLAB Speaker Diarization System for the DIHARD 2019 Challenge", ["Ignacio Vinals", "Pablo Gimeno", "Alfonso Ortega Gimenez", "Antonio Miguel", "Eduardo Lleida"], "https://doi.org/10.21437/Interspeech.2019-2462", 5, "interspeech", 2019], ["Phonetically-Aware Embeddings, Wide Residual Networks with Time-Delay Neural Networks and Self Attention Models for the 2018 NIST Speaker Recognition Evaluation", ["Ignacio Vinals", "Dayana Ribas", "Victoria Mingote", "Jorge Llombart", "Pablo Gimeno", "Antonio Miguel", "Alfonso Ortega Gimenez", "Eduardo Lleida"], "https://doi.org/10.21437/Interspeech.2019-2417", 5, "interspeech", 2019]], "Sheng Li": [0, ["End-to-End Articulatory Attribute Modeling for Low-Resource Multilingual Speech Recognition", ["Sheng Li", "Chenchen Ding", "Xugang Lu", "Peng Shen", "Tatsuya Kawahara", "Hisashi Kawai"], "https://doi.org/10.21437/Interspeech.2019-2092", 5, "interspeech", 2019], ["Investigating Radical-Based End-to-End Speech Recognition Systems for Chinese Dialects and Japanese", ["Sheng Li", "Xugang Lu", "Chenchen Ding", "Peng Shen", "Tatsuya Kawahara", "Hisashi Kawai"], "https://doi.org/10.21437/Interspeech.2019-2104", 5, "interspeech", 2019], ["Improving Transformer-Based Speech Recognition Systems with Compressed Structure and Speech Attributes Augmentation", ["Sheng Li", "Dabre Raj", "Xugang Lu", "Peng Shen", "Tatsuya Kawahara", "Hisashi Kawai"], "https://doi.org/10.21437/Interspeech.2019-2112", 5, "interspeech", 2019]], "Zvi Kons": [0, ["High Quality, Lightweight and Adaptable TTS Using LPCNet", ["Zvi Kons", "Slava Shechtman", "Alexander Sorin", "Carmel Rabinovitz", "Ron Hoory"], "https://doi.org/10.21437/Interspeech.2019-1705", 5, "interspeech", 2019]], "Leda Sari": [0, ["Learning Speaker Aware Offsets for Speaker Adaptation of Neural Networks", ["Leda Sari", "Samuel Thomas", "Mark A. Hasegawa-Johnson"], "https://doi.org/10.21437/Interspeech.2019-1788", 5, "interspeech", 2019]], "Guillaume Fuchs": [0, ["Super-Wideband Spectral Envelope Modeling for Speech Coding", ["Guillaume Fuchs", "Chamran Ashour", "Tom Backstrom"], "https://doi.org/10.21437/Interspeech.2019-1620", 5, "interspeech", 2019]], "Yulong Liang": [0, ["The LeVoice Far-Field Speech Recognition System for VOiCES from a Distance Challenge 2019", ["Yulong Liang", "Lin Yang", "Xuyang Wang", "Yingjie Li", "Chen Jia", "Junjie Wang"], "https://doi.org/10.21437/Interspeech.2019-1944", 5, "interspeech", 2019]], "Takahito Suzuki": [0, ["Knowledge Distillation for Throat Microphone Speech Recognition", ["Takahito Suzuki", "Jun Ogata", "Takashi Tsunakawa", "Masafumi Nishida", "Masafumi Nishimura"], "https://doi.org/10.21437/Interspeech.2019-1597", 5, "interspeech", 2019]], "Shreya Khare": [0, ["Adversarial Black-Box Attacks on Automatic Speech Recognition Systems Using Multi-Objective Evolutionary Optimization", ["Shreya Khare", "Rahul Aralikatte", "Senthil Mani"], "https://doi.org/10.21437/Interspeech.2019-2420", 5, "interspeech", 2019]], "Jun Chen": [0, ["An Attention-Based Hybrid Network for Automatic Detection of Alzheimer's Disease from Narrative Speech", ["Jun Chen", "Ji Zhu", "Jieping Ye"], "https://doi.org/10.21437/Interspeech.2019-2872", 5, "interspeech", 2019]], "Brendan Shillingford": [0, ["Large-Scale Visual Speech Recognition", ["Brendan Shillingford", "Yannis M. Assael", "Matthew W. Hoffman", "Thomas Paine", "Cian Hughes", "Utsav Prabhu", "Hank Liao", "Hasim Sak", "Kanishka Rao", "Lorrayne Bennett", "Marie Mulville", "Misha Denil", "Ben Coppin", "Ben Laurie", "Andrew W. Senior", "Nando de Freitas"], "https://doi.org/10.21437/Interspeech.2019-1669", 5, "interspeech", 2019]], "Efthymios Georgiou": [0, ["Deep Hierarchical Fusion with Application in Sentiment Analysis", ["Efthymios Georgiou", "Charilaos Papaioannou", "Alexandros Potamianos"], "https://doi.org/10.21437/Interspeech.2019-3243", 5, "interspeech", 2019]], "Steffen Schneider": [0, ["wav2vec: Unsupervised Pre-Training for Speech Recognition", ["Steffen Schneider", "Alexei Baevski", "Ronan Collobert", "Michael Auli"], "https://doi.org/10.21437/Interspeech.2019-1873", 5, "interspeech", 2019]], "Geon Woo Lee": [0.9999426007270813, ["Directional Audio Rendering Using a Neural Network Based Personalized HRTF", ["Geon Woo Lee", "Jung Hyuk Lee", "Seong Ju Kim", "Hong Kook Kim"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8005.html", 2, "interspeech", 2019]], "Zheng Lian": [0, ["Conversational Emotion Analysis via Attention Mechanisms", ["Zheng Lian", "Jianhua Tao", "Bin Liu", "Jian Huang"], "https://doi.org/10.21437/Interspeech.2019-1577", 5, "interspeech", 2019], ["Unsupervised Representation Learning with Future Observation Prediction for Speech Emotion Recognition", ["Zheng Lian", "Jianhua Tao", "Bin Liu", "Jian Huang"], "https://doi.org/10.21437/Interspeech.2019-1582", 5, "interspeech", 2019]], "Juheon Lee": [0.9739110469818115, ["Adversarially Trained End-to-End Korean Singing Voice Synthesis System", ["Juheon Lee", "Hyeong-Seok Choi", "Chang-Bin Jeon", "Junghyun Koo", "Kyogu Lee"], "https://doi.org/10.21437/Interspeech.2019-1722", 5, "interspeech", 2019]], "Takuya Yoshioka": [0, ["Meeting Transcription Using Asynchronous Distant Microphones", ["Takuya Yoshioka", "Dimitrios Dimitriadis", "Andreas Stolcke", "William Hinthorn", "Zhuo Chen", "Michael Zeng", "Xuedong Huang"], "https://doi.org/10.21437/Interspeech.2019-3088", 5, "interspeech", 2019]], "Sharon Peperkamp": [0, ["Compensation for French Liquid Deletion During Auditory Sentence Processing", ["Sharon Peperkamp", "Alvaro Martin Iturralde Zurita"], "https://doi.org/10.21437/Interspeech.2019-2950", 5, "interspeech", 2019], ["Liquid Deletion in French Child-Directed Speech", ["Sharon Peperkamp", "Monica Hegde", "Maria Julia Carbajal"], "https://doi.org/10.21437/Interspeech.2019-2838", 5, "interspeech", 2019]], "Yiheng Jiang": [0, ["An Effective Deep Embedding Learning Architecture for Speaker Verification", ["Yiheng Jiang", "Yan Song", "Ian McLoughlin", "Zhifu Gao", "Li-Rong Dai"], "https://doi.org/10.21437/Interspeech.2019-1606", 5, "interspeech", 2019]], "Daniel R. Turner": [0, ["Perception of Pitch Contours in Speech and Nonspeech", ["Daniel R. Turner", "Ann R. Bradlow", "Jennifer S. Cole"], "https://doi.org/10.21437/Interspeech.2019-2619", 5, "interspeech", 2019]], "Hiroaki Takatsu": [0, ["Recognition of Intentions of Users' Short Responses for Conversational News Delivery System", ["Hiroaki Takatsu", "Katsuya Yokoyama", "Yoichi Matsuyama", "Hiroshi Honda", "Shinya Fujie", "Tetsunori Kobayashi"], "https://doi.org/10.21437/Interspeech.2019-2121", 5, "interspeech", 2019]], "Leyuan Qu": [0, ["LipSound: Neural Mel-Spectrogram Reconstruction for Lip Reading", ["Leyuan Qu", "Cornelius Weber", "Stefan Wermter"], "https://doi.org/10.21437/Interspeech.2019-1393", 5, "interspeech", 2019]], "Ahmed Mustafa": [0, ["Analysis by Adversarial Synthesis - A Novel Approach for Speech Vocoding", ["Ahmed Mustafa", "Arijit Biswas", "Christian Bergler", "Julia Schottenhamml", "Andreas K. Maier"], "https://doi.org/10.21437/Interspeech.2019-1195", 5, "interspeech", 2019]], "Mahesh Kumar Nandwana": [0, ["The VOiCES from a Distance Challenge 2019", ["Mahesh Kumar Nandwana", "Julien van Hout", "Colleen Richey", "Mitchell McLaren", "Maria Auxiliadora Barrios", "Aaron Lawson"], "https://doi.org/10.21437/Interspeech.2019-1837", 5, "interspeech", 2019], ["The VOiCES from a Distance Challenge 2019", ["Mahesh Kumar Nandwana", "Julien van Hout", "Colleen Richey", "Mitchell McLaren", "Maria Alejandra Barrios", "Aaron Lawson"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/abs14.html", 0, "interspeech", 2019], ["Analysis of Critical Metadata Factors for the Calibration of Speaker Recognition Systems", ["Mahesh Kumar Nandwana", "Luciana Ferrer", "Mitchell McLaren", "Diego Castan", "Aaron Lawson"], "https://doi.org/10.21437/Interspeech.2019-1808", 5, "interspeech", 2019]], "Sung-Lin Yeh": [0, ["Using Attention Networks and Adversarial Augmentation for Styrian Dialect Continuous Sleepiness and Baby Sound Recognition", ["Sung-Lin Yeh", "Gao-Yi Chao", "Bo-Hao Su", "Yu-Lin Huang", "Meng-Han Lin", "Yin-Chun Tsai", "Yu-Wen Tai", "Zheng-Chi Lu", "Chieh-Yu Chen", "Tsung-Ming Tai", "Chiu-Wang Tseng", "Cheng-Kuang Lee", "Chi-Chun Lee"], "https://doi.org/10.21437/Interspeech.2019-2110", 5, "interspeech", 2019]], "Jinming Zhao": [0, ["Speech Emotion Recognition in Dyadic Dialogues with Attentive Interaction Modeling", ["Jinming Zhao", "Shizhe Chen", "Jingjun Liang", "Qin Jin"], "https://doi.org/10.21437/Interspeech.2019-2103", 5, "interspeech", 2019]], "Andrea Deme": [0, ["V-to-V Coarticulation Induced Acoustic and Articulatory Variability of Vowels: The Effect of Pitch-Accent", ["Andrea Deme", "Marton Bartok", "Tekla Etelka Graczi", "Tamas Gabor Csapo", "Alexandra Marko"], "https://doi.org/10.21437/Interspeech.2019-2890", 5, "interspeech", 2019]], "Daniel Korzekwa": [0, ["Interpretable Deep Learning Model for the Detection and Reconstruction of Dysarthric Speech", ["Daniel Korzekwa", "Roberto Barra-Chicote", "Bozena Kostek", "Thomas Drugman", "Mateusz Lajszczak"], "https://doi.org/10.21437/Interspeech.2019-1206", 5, "interspeech", 2019]], "Dravyansh Sharma": [0, ["Better Morphology Prediction for Better Speech Systems", ["Dravyansh Sharma", "Melissa Wilson", "Antoine Bruguier"], "https://doi.org/10.21437/Interspeech.2019-3207", 5, "interspeech", 2019]], "K. G. van Leeuwen": [0, ["CNN-Based Phoneme Classifier from Vocal Tract MRI Learns Embedding Consistent with Articulatory Topology", ["K. G. van Leeuwen", "P. Bos", "Stefano Trebeschi", "Maarten J. A. van Alphen", "Luuk Voskuilen", "Ludi E. Smeele", "Ferdi van der Heijden", "R. J. J. H. van Son"], "https://doi.org/10.21437/Interspeech.2019-1173", 5, "interspeech", 2019]], "Alice Rueda": [0, ["Feature Representation of Pathophysiology of Parkinsonian Dysarthria", ["Alice Rueda", "Juan Camilo Vasquez-Correa", "Cristian David Rios-Urrego", "Juan Rafael Orozco-Arroyave", "Sridhar Krishnan", "Elmar Noth"], "https://doi.org/10.21437/Interspeech.2019-2490", 5, "interspeech", 2019]], "Per Fallgren": [0, ["How to Annotate 100 Hours in 45 Minutes", ["Per Fallgren", "Zofia Malisz", "Jens Edlund"], "https://doi.org/10.21437/Interspeech.2019-1648", 5, "interspeech", 2019]], "Gurunath Reddy M.": [0, ["Glottal Closure Instants Detection from Speech Signal by Deep Features Extracted from Raw Speech and Linear Prediction Residual", ["Gurunath Reddy M.", "K. Sreenivasa Rao", "Partha Pratim Das"], "https://doi.org/10.21437/Interspeech.2019-1981", 5, "interspeech", 2019]], "Guan-Lin Chao": [0, ["BERT-DST: Scalable End-to-End Dialogue State Tracking with Bidirectional Encoder Representations from Transformer", ["Guan-Lin Chao", "Ian Lane"], "https://doi.org/10.21437/Interspeech.2019-1355", 5, "interspeech", 2019]], "Ying Qin": [0, ["Automatic Assessment of Language Impairment Based on Raw ASR Output", ["Ying Qin", "Tan Lee", "Anthony Pak-Hin Kong"], "https://doi.org/10.21437/Interspeech.2019-1688", 5, "interspeech", 2019]], "Jan Chorowski": [0, ["Towards Using Context-Dependent Symbols in CTC Without State-Tying Decision Trees", ["Jan Chorowski", "Adrian Lancucki", "Bartosz Kostka", "Michal Zapotoczny"], "https://doi.org/10.21437/Interspeech.2019-2720", 5, "interspeech", 2019]], "Chang Liu": [0, ["Character-Aware Sub-Word Level Language Modeling for Uyghur and Turkish ASR", ["Chang Liu", "Zhen Zhang", "Pengyuan Zhang", "Yonghong Yan"], "https://doi.org/10.21437/Interspeech.2019-1484", 5, "interspeech", 2019]], "Yu-Ren Chien": [0, ["F0 Variability Measures Based on Glottal Closure Instants", ["Yu-Ren Chien", "Michal Borsky", "Jon Gudnason"], "https://doi.org/10.21437/Interspeech.2019-1326", 4, "interspeech", 2019]], "K. N. R. K. Raju Alluri": [0, ["IIIT-H Spoofing Countermeasures for Automatic Speaker Verification Spoofing and Countermeasures Challenge 2019", ["K. N. R. K. Raju Alluri", "Anil Kumar Vuppala"], "https://doi.org/10.21437/Interspeech.2019-1623", 5, "interspeech", 2019]], "Zhi Chen": [0, ["Neural Text Clustering with Document-Level Attention Based on Dynamic Soft Labels", ["Zhi Chen", "Wu Guo", "Li-Rong Dai", "Zhen-Hua Ling", "Jun Du"], "https://doi.org/10.21437/Interspeech.2019-1417", 5, "interspeech", 2019]], "Moustafa Alzantot": [0, ["Deep Residual Neural Networks for Audio Spoofing Detection", ["Moustafa Alzantot", "Ziqi Wang", "Mani B. Srivastava"], "https://doi.org/10.21437/Interspeech.2019-3174", 5, "interspeech", 2019]], "Hao Zhang": [0, ["Deep Learning for Joint Acoustic Echo and Noise Cancellation with Nonlinear Distortions", ["Hao Zhang", "Ke Tan", "DeLiang Wang"], "https://doi.org/10.21437/Interspeech.2019-2651", 5, "interspeech", 2019]], "Zhiying Huang": [0, ["Audio Tagging with Compact Feedforward Sequential Memory Network and Audio-to-Audio Ratio Based Data Augmentation", ["Zhiying Huang", "Shiliang Zhang", "Ming Lei"], "https://doi.org/10.21437/Interspeech.2019-1302", 5, "interspeech", 2019]], "Haoran Miao": [0, ["Online Hybrid CTC/Attention Architecture for End-to-End Speech Recognition", ["Haoran Miao", "Gaofeng Cheng", "Pengyuan Zhang", "Ta Li", "Yonghong Yan"], "https://doi.org/10.21437/Interspeech.2019-2018", 5, "interspeech", 2019]], "Yashesh Gaur": [0, ["Acoustic-to-Phrase Models for Speech Recognition", ["Yashesh Gaur", "Jinyu Li", "Zhong Meng", "Yifan Gong"], "https://doi.org/10.21437/Interspeech.2019-3056", 5, "interspeech", 2019]], "Marziye Eshghi": [0, ["Reduced Task Adaptation in Alternating Motion Rate Tasks as an Early Marker of Bulbar Involvement in Amyotrophic Lateral Sclerosis", ["Marziye Eshghi", "Panying Rong", "Antje S. Mefferd", "Kaila L. Stipancic", "Yana Yunusova", "Jordan R. Green"], "https://doi.org/10.21437/Interspeech.2019-2546", 5, "interspeech", 2019]], "Mohsin Y. Ahmed": [0, ["DeepLung: Smartphone Convolutional Neural Network-Based Inference of Lung Anomalies for Pulmonary Patients", ["Mohsin Y. Ahmed", "Md. Mahbubur Rahman", "Jilong Kuang"], "https://doi.org/10.21437/Interspeech.2019-2953", 5, "interspeech", 2019]], "Paarth Neekhara": [0, ["Expediting TTS Synthesis with Adversarial Vocoding", ["Paarth Neekhara", "Chris Donahue", "Miller S. Puckette", "Shlomo Dubnov", "Julian J. McAuley"], "https://doi.org/10.21437/Interspeech.2019-3099", 5, "interspeech", 2019], ["Universal Adversarial Perturbations for Speech Recognition Systems", ["Paarth Neekhara", "Shehzeen Hussain", "Prakhar Pandey", "Shlomo Dubnov", "Julian J. McAuley", "Farinaz Koushanfar"], "https://doi.org/10.21437/Interspeech.2019-1353", 5, "interspeech", 2019]], "Seyed Hamidreza Mohammadi": [0, ["One-Shot Voice Conversion with Disentangled Representations by Leveraging Phonetic Posteriorgrams", ["Seyed Hamidreza Mohammadi", "Taehwan Kim"], "https://doi.org/10.21437/Interspeech.2019-1798", 5, "interspeech", 2019]], "Han-Chi Hsieh": [0, ["Consonant Classification in Mandarin Based on the Depth Image Feature: A Pilot Study", ["Han-Chi Hsieh", "Wei-Zhong Zheng", "Ko-Chiang Chen", "Ying-Hui Lai"], "https://doi.org/10.21437/Interspeech.2019-1893", 5, "interspeech", 2019]], "Luis Serrano": [0, ["Parallel vs. Non-Parallel Voice Conversion for Esophageal Speech", ["Luis Serrano", "Sneha Raman", "David Tavarez", "Eva Navas", "Inma Hernaez"], "https://doi.org/10.21437/Interspeech.2019-2194", 5, "interspeech", 2019]], "Chitralekha Gupta": [0, ["Acoustic Modeling for Automatic Lyrics-to-Audio Alignment", ["Chitralekha Gupta", "Emre Yilmaz", "Haizhou Li"], "https://doi.org/10.21437/Interspeech.2019-1520", 5, "interspeech", 2019], ["NUS Speak-to-Sing: A Web Platform for Personalized Speech-to-Singing Conversion", ["Chitralekha Gupta", "Karthika Vijayan", "Bidisha Sharma", "Xiaoxue Gao", "Haizhou Li"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8041.html", 2, "interspeech", 2019]], "Monica Dominguez": [0, ["PyToBI: A Toolkit for ToBI Labeling Under Python", ["Monica Dominguez", "Patrick Louis Rohrer", "Juan Soler Company"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8021.html", 2, "interspeech", 2019]], "Marketa Juzova": [0, ["Unified Language-Independent DNN-Based G2P Converter", ["Marketa Juzova", "Daniel Tihelka", "Jakub Vit"], "https://doi.org/10.21437/Interspeech.2019-2335", 5, "interspeech", 2019]], "Deepika Gupta": [0, ["Artificial Bandwidth Extension Using H\u221e Optimization", ["Deepika Gupta", "Hanumant Singh Shekhawat"], "https://doi.org/10.21437/Interspeech.2019-1580", 5, "interspeech", 2019]], "Wenjie Li": [0, ["Target Speaker Recovery and Recognition Network with Average x-Vector and Global Training", ["Wenjie Li", "Pengyuan Zhang", "Yonghong Yan"], "https://doi.org/10.21437/Interspeech.2019-1692", 5, "interspeech", 2019]], "Songxiang Liu": [0, ["Jointly Trained Conversion Model and WaveNet Vocoder for Non-Parallel Voice Conversion Using Mel-Spectrograms and Phonetic Posteriorgrams", ["Songxiang Liu", "Yuewen Cao", "Xixin Wu", "Lifa Sun", "Xunying Liu", "Helen Meng"], "https://doi.org/10.21437/Interspeech.2019-1316", 5, "interspeech", 2019]], "Sarah E. Gutz": [0, ["Early Identification of Speech Changes Due to Amyotrophic Lateral Sclerosis Using Machine Classification", ["Sarah E. Gutz", "Jun Wang", "Yana Yunusova", "Jordan R. Green"], "https://doi.org/10.21437/Interspeech.2019-2967", 5, "interspeech", 2019]], "Dipjyoti Paul": [0, ["Non-Parallel Voice Conversion Using Weighted Generative Adversarial Networks", ["Dipjyoti Paul", "Yannis Pantazis", "Yannis Stylianou"], "https://doi.org/10.21437/Interspeech.2019-2869", 5, "interspeech", 2019]], "Gyorgy Szaszak": [0, ["Leveraging a Character, Word and Prosody Triplet for an ASR Error Robust and Agglutination Friendly Punctuation Approach", ["Gyorgy Szaszak", "Mate Akos Tundik"], "https://doi.org/10.21437/Interspeech.2019-2132", 5, "interspeech", 2019]], "Rongjin Li": [0, ["Anti-Spoofing Speaker Verification System with Multi-Feature Integration and Multi-Task Learning", ["Rongjin Li", "Miao Zhao", "Zheng Li", "Lin Li", "Qingyang Hong"], "https://doi.org/10.21437/Interspeech.2019-1698", 5, "interspeech", 2019]], "Bharat Padi": [0, ["Attention Based Hybrid i-Vector BLSTM Model for Language Recognition", ["Bharat Padi", "Anand Mohan", "Sriram Ganapathy"], "https://doi.org/10.21437/Interspeech.2019-2371", 5, "interspeech", 2019]], "Luc Ardaillon": [0, ["Fully-Convolutional Network for Pitch Estimation of Speech Signals", ["Luc Ardaillon", "Axel Roebel"], "https://doi.org/10.21437/Interspeech.2019-2815", 5, "interspeech", 2019]], "Prakhar Swarup": [0, ["Improving ASR Confidence Scores for Alexa Using Acoustic and Hypothesis Embeddings", ["Prakhar Swarup", "Roland Maas", "Sri Garimella", "Sri Harish Mallidi", "Bjorn Hoffmeister"], "https://doi.org/10.21437/Interspeech.2019-1241", 5, "interspeech", 2019]], "Annie Tremblay": [0, ["Foreign-Language Knowledge Enhances Artificial-Language Segmentation", ["Annie Tremblay", "Mirjam Broersma"], "https://doi.org/10.21437/Interspeech.2019-2446", 5, "interspeech", 2019]], "Azam Rabiee": [0, ["Adjusting Pleasure-Arousal-Dominance for Continuous Emotional Text-to-Speech Synthesizer", ["Azam Rabiee", "Tae-Ho Kim", "Soo-Young Lee"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8045.html", 2, "interspeech", 2019]], "Mengnan Chen": [0, ["Cross-Lingual, Multi-Speaker Text-To-Speech Synthesis Using Neural Speaker Embedding", ["Mengnan Chen", "Minchuan Chen", "Shuang Liang", "Jun Ma", "Lei Chen", "Shaojun Wang", "Jing Xiao"], "https://doi.org/10.21437/Interspeech.2019-1632", 5, "interspeech", 2019]], "Moritz Meier": [0, ["Comparative Analysis of Think-Aloud Methods for Everyday Activities in the Context of Cognitive Robotics", ["Moritz Meier", "Celeste Mason", "Felix Putze", "Tanja Schultz"], "https://doi.org/10.21437/Interspeech.2019-3072", 5, "interspeech", 2019]], "Chieh-Chi Kao": [0, ["Sub-Band Convolutional Neural Networks for Small-Footprint Spoken Term Classification", ["Chieh-Chi Kao", "Ming Sun", "Yixin Gao", "Shiv Vitaladevuni", "Chao Wang"], "https://doi.org/10.21437/Interspeech.2019-1766", 5, "interspeech", 2019]], "Liming Wang": [7.770433512632735e-06, ["Multimodal Word Discovery and Retrieval with Phone Sequence and Image Concepts", ["Liming Wang", "Mark A. Hasegawa-Johnson"], "https://doi.org/10.21437/Interspeech.2019-1487", 5, "interspeech", 2019]], "Tasavat Trisitichoke": [0, ["Analysis of Native Listeners' Facial Microexpressions While Shadowing Non-Native Speech - Potential of Shadowers' Facial Expressions for Comprehensibility Prediction", ["Tasavat Trisitichoke", "Shintaro Ando", "Daisuke Saito", "Nobuaki Minematsu"], "https://doi.org/10.21437/Interspeech.2019-1953", 5, "interspeech", 2019]], "Ruixi Lin": [0, ["Optimizing Voice Activity Detection for Noisy Conditions", ["Ruixi Lin", "Charles Costello", "Charles Jankowski", "Vishwas Mruthyunjaya"], "https://doi.org/10.21437/Interspeech.2019-1776", 5, "interspeech", 2019]], "Felix Weninger": [0, ["Deep Learning Based Mandarin Accent Identification for Accent Robust ASR", ["Felix Weninger", "Yang Sun", "Junho Park", "Daniel Willett", "Puming Zhan"], "https://doi.org/10.21437/Interspeech.2019-2737", 5, "interspeech", 2019], ["Listen, Attend, Spell and Adapt: Speaker Adapted Sequence-to-Sequence ASR", ["Felix Weninger", "Jesus Andres-Ferrer", "Xinwei Li", "Puming Zhan"], "https://doi.org/10.21437/Interspeech.2019-2719", 5, "interspeech", 2019]], "Massimiliano Todisco": [0, ["ASVspoof 2019: Future Horizons in Spoofed and Fake Audio Detection", ["Massimiliano Todisco", "Xin Wang", "Ville Vestman", "Md. Sahidullah", "Hector Delgado", "Andreas Nautsch", "Junichi Yamagishi", "Nicholas W. D. Evans", "Tomi H. Kinnunen", "Kong Aik Lee"], "https://doi.org/10.21437/Interspeech.2019-2249", 5, "interspeech", 2019]], "Maximilian Schmitt": [0, ["Continuous Emotion Recognition in Speech - Do We Need Recurrence?", ["Maximilian Schmitt", "Nicholas Cummins", "Bjorn W. Schuller"], "https://doi.org/10.21437/Interspeech.2019-2710", 5, "interspeech", 2019]], "Shilei Zhang": [0, ["Few-Shot Audio Classification with Attentional Graph Neural Networks", ["Shilei Zhang", "Yong Qin", "Kewei Sun", "Yonghua Lin"], "https://doi.org/10.21437/Interspeech.2019-1532", 5, "interspeech", 2019]], "Ernest Pusateri": [0, ["Connecting and Comparing Language Model Interpolation Techniques", ["Ernest Pusateri", "Christophe Van Gysel", "Rami Botros", "Sameer Badaskar", "Mirko Hannemann", "Youssef Oualil", "Ilya Oparin"], "https://doi.org/10.21437/Interspeech.2019-1822", 5, "interspeech", 2019]], "Wei-Ning Hsu": [0, ["Transfer Learning from Audio-Visual Grounding to Speech Recognition", ["Wei-Ning Hsu", "David Harwath", "James R. Glass"], "https://doi.org/10.21437/Interspeech.2019-1227", 5, "interspeech", 2019]], "Yiteng Huang": [0, ["Multi-Microphone Adaptive Noise Cancellation for Robust Hotword Detection", ["Yiteng Huang", "Turaj Zakizadeh Shabestary", "Alexander Gruenstein", "Li Wan"], "https://doi.org/10.21437/Interspeech.2019-3006", 5, "interspeech", 2019]], "Mingyang Zhang": [0, ["Joint Training Framework for Text-to-Speech and Voice Conversion Using Multi-Source Tacotron and WaveNet", ["Mingyang Zhang", "Xin Wang", "Fuming Fang", "Haizhou Li", "Junichi Yamagishi"], "https://doi.org/10.21437/Interspeech.2019-1357", 5, "interspeech", 2019]], "Meet H. Soni": [0, ["Label Driven Time-Frequency Masking for Robust Continuous Speech Recognition", ["Meet H. Soni", "Ashish Panda"], "https://doi.org/10.21437/Interspeech.2019-2172", 5, "interspeech", 2019], ["Generative Noise Modeling and Channel Simulation for Robust Speech Recognition in Unseen Conditions", ["Meet H. Soni", "Sonal Joshi", "Ashish Panda"], "https://doi.org/10.21437/Interspeech.2019-2090", 5, "interspeech", 2019]], "Kaylah Lalonde": [0, ["Effects of Natural Variability in Cross-Modal Temporal Correlations on Audiovisual Speech Recognition Benefit", ["Kaylah Lalonde"], "https://doi.org/10.21437/Interspeech.2019-2931", 5, "interspeech", 2019]], "Siyuan Feng": [0, ["Improving Unsupervised Subword Modeling via Disentangled Speech Representation Learning and Transformation", ["Siyuan Feng", "Tan Lee"], "https://doi.org/10.21437/Interspeech.2019-1338", 5, "interspeech", 2019], ["Combining Adversarial Training and Disentangled Speech Representation for Robust Zero-Resource Subword Modeling", ["Siyuan Feng", "Tan Lee", "Zhiyuan Peng"], "https://doi.org/10.21437/Interspeech.2019-1337", 5, "interspeech", 2019]], "Yusuke Kurita": [0, ["Robustness of Statistical Voice Conversion Based on Direct Waveform Modification Against Background Sounds", ["Yusuke Kurita", "Kazuhiro Kobayashi", "Kazuya Takeda", "Tomoki Toda"], "https://doi.org/10.21437/Interspeech.2019-2206", 5, "interspeech", 2019]], "Ding Zhao": [0, ["Shallow-Fusion End-to-End Contextual Biasing", ["Ding Zhao", "Tara N. Sainath", "David Rybach", "Pat Rondon", "Deepti Bhatia", "Bo Li", "Ruoming Pang"], "https://doi.org/10.21437/Interspeech.2019-1209", 5, "interspeech", 2019]], "Xianyun Wang": [6.437032880057814e-07, ["Masking Estimation with Phase Restoration of Clean Speech for Monaural Speech Enhancement", ["Xianyun Wang", "Changchun Bao"], "https://doi.org/10.21437/Interspeech.2019-1141", 5, "interspeech", 2019]], "Lucas Ondel": [0, ["Bayesian Subspace Hidden Markov Model for Acoustic Unit Discovery", ["Lucas Ondel", "Hari Krishna Vydana", "Lukas Burget", "Jan Cernocky"], "https://doi.org/10.21437/Interspeech.2019-2224", 5, "interspeech", 2019]], "Jason Li": [0, ["Jasper: An End-to-End Convolutional Neural Acoustic Model", ["Jason Li", "Vitaly Lavrukhin", "Boris Ginsburg", "Ryan Leary", "Oleksii Kuchaiev", "Jonathan M. Cohen", "Huyen Nguyen", "Ravi Teja Gadde"], "https://doi.org/10.21437/Interspeech.2019-1819", 5, "interspeech", 2019]], "Tanay Sharma": [0, ["Real Time Online Visual End Point Detection Using Unidirectional LSTM", ["Tanay Sharma", "Rohith Chandrashekar Aralikatti", "Dilip Kumar Margam", "Abhinav Thanda", "Sharad Roy", "Pujitha Appan Kandala", "Shankar M. Venkatesan"], "https://doi.org/10.21437/Interspeech.2019-3253", 5, "interspeech", 2019]], "Thomas Kisler": [0, ["Styrian Dialect Classification: Comparing and Fusing Classifiers Based on a Feature Selection Using a Genetic Algorithm", ["Thomas Kisler", "Raphael Winkelmann", "Florian Schiel"], "https://doi.org/10.21437/Interspeech.2019-2540", 5, "interspeech", 2019]], "Manoj Kumar Ramanathi": [0, ["ASR Inspired Syllable Stress Detection for Pronunciation Evaluation Without Using a Supervised Classifier and Syllable Level Features", ["Manoj Kumar Ramanathi", "Chiranjeevi Yarra", "Prasanta Kumar Ghosh"], "https://doi.org/10.21437/Interspeech.2019-2091", 5, "interspeech", 2019]], "Sandro Cumani": [0, ["Normal Variance-Mean Mixtures for Unsupervised Score Calibration", ["Sandro Cumani"], "https://doi.org/10.21437/Interspeech.2019-1609", 5, "interspeech", 2019]], "Anke Sennema": [0, ["Vietnamese Learners Tackling the German /\u0283t/ in Perception", ["Anke Sennema", "Silke Hamann"], "https://doi.org/10.21437/Interspeech.2019-2832", 4, "interspeech", 2019]], "Venkata Srikanth Nallanthighal": [0, ["Deep Sensing of Breathing Signal During Conversational Speech", ["Venkata Srikanth Nallanthighal", "Aki Harma", "Helmer Strik"], "https://doi.org/10.21437/Interspeech.2019-1796", 5, "interspeech", 2019]], "Nehory Carmi": [0, ["A Storyteller's Tale: Literature Audiobooks Genre Classification Using CNN and RNN Architectures", ["Nehory Carmi", "Azaria Cohen", "Mireille Avigal", "Anat Lerner"], "https://doi.org/10.21437/Interspeech.2019-1154", 4, "interspeech", 2019]], "Jean-Marc Valin": [0, ["A Real-Time Wideband Neural Vocoder at 1.6kb/s Using LPCNet", ["Jean-Marc Valin", "Jan Skoglund"], "https://doi.org/10.21437/Interspeech.2019-1255", 5, "interspeech", 2019]], "Oksana Rasskazova": [0, ["Temporal Coordination of Articulatory and Respiratory Events Prior to Speech Initiation", ["Oksana Rasskazova", "Christine Mooshammer", "Susanne Fuchs"], "https://doi.org/10.21437/Interspeech.2019-2876", 5, "interspeech", 2019]], "Mattia Antonino Di Gangi": [0, ["Adapting Transformer to End-to-End Spoken Language Translation", ["Mattia Antonino Di Gangi", "Matteo Negri", "Marco Turchi"], "https://doi.org/10.21437/Interspeech.2019-3045", 5, "interspeech", 2019]], "Gautam Mantena": [0, ["Bandwidth Embeddings for Mixed-Bandwidth Speech Recognition", ["Gautam Mantena", "Ozlem Kalinli", "Ossama Abdel-Hamid", "Don McAllaster"], "https://doi.org/10.21437/Interspeech.2019-2589", 5, "interspeech", 2019]], "Yilin Shen": [0, ["Interpreting and Improving Deep Neural SLU Models via Vocabulary Importance", ["Yilin Shen", "Wenhu Chen", "Hongxia Jin"], "https://doi.org/10.21437/Interspeech.2019-3184", 5, "interspeech", 2019]], "Zoltan Tuske": [0, ["Advancing Sequence-to-Sequence Based Speech Recognition", ["Zoltan Tuske", "Kartik Audhkhasi", "George Saon"], "https://doi.org/10.21437/Interspeech.2019-3018", 5, "interspeech", 2019]], "Theo Biasutto-Lervat": [0, ["Modeling Labial Coarticulation with Bidirectional Gated Recurrent Networks and Transfer Learning", ["Theo Biasutto-Lervat", "Sara Dahmani", "Slim Ouni"], "https://doi.org/10.21437/Interspeech.2019-2097", 5, "interspeech", 2019]], "Konstantinos Vougioukas": [0, ["Video-Driven Speech Reconstruction Using Generative Adversarial Networks", ["Konstantinos Vougioukas", "Pingchuan Ma", "Stavros Petridis", "Maja Pantic"], "https://doi.org/10.21437/Interspeech.2019-1445", 5, "interspeech", 2019]], "Qiang Gao": [0, ["ToneNet: A CNN Model of Tone Classification of Mandarin Chinese", ["Qiang Gao", "Shutao Sun", "Yaping Yang"], "https://doi.org/10.21437/Interspeech.2019-1483", 5, "interspeech", 2019]], "Daniel S. Park": [3.925836655760406e-09, ["SpecAugment: A Simple Data Augmentation Method for Automatic Speech Recognition", ["Daniel S. Park", "William Chan", "Yu Zhang", "Chung-Cheng Chiu", "Barret Zoph", "Ekin D. Cubuk", "Quoc V. Le"], "https://doi.org/10.21437/Interspeech.2019-2680", 5, "interspeech", 2019]], "Ondrej Novotny": [0, ["Factorization of Discriminatively Trained i-Vector Extractor for Speaker Recognition", ["Ondrej Novotny", "Oldrich Plchot", "Ondrej Glembek", "Lukas Burget"], "https://doi.org/10.21437/Interspeech.2019-1757", 5, "interspeech", 2019]], "Seungwoo Choi": [0.9979142248630524, ["Temporal Convolution for Real-Time Keyword Spotting on Mobile Devices", ["Seungwoo Choi", "Seokjun Seo", "Beomjun Shin", "Hyeongmin Byun", "Martin Kersner", "Beomsu Kim", "Dongyoung Kim", "Sungjoo Ha"], "https://doi.org/10.21437/Interspeech.2019-1363", 5, "interspeech", 2019]], "Raghav Menon": [0, ["Feature Exploration for Almost Zero-Resource ASR-Free Keyword Spotting Using a Multilingual Bottleneck Extractor and Correspondence Autoencoders", ["Raghav Menon", "Herman Kamper", "Ewald van der Westhuizen", "John Quinn", "Thomas Niesler"], "https://doi.org/10.21437/Interspeech.2019-1665", 5, "interspeech", 2019]], "Tze Yuang Chong": [2.8871034629673886e-07, ["The I2R's ASR System for the VOiCES from a Distance Challenge 2019", ["Tze Yuang Chong", "Kye Min Tan", "Kah Kuan Teh", "Chang Huai You", "Hanwu Sun", "Tran Huy Dat"], "https://doi.org/10.21437/Interspeech.2019-2130", 5, "interspeech", 2019], ["The I2R's ASR System for the VOiCES from a Distance Challenge 2019", ["Tze Yuang Chong", "Kye Min Tan", "Kah Kuan Teh", "Chang Huai You", "Hanwu Sun", "Tran Huy Dat"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/abs18.html", 0, "interspeech", 2019]], "Vedran Vukotic": [0, ["Mining Polysemous Triplets with Recurrent Neural Networks for Spoken Language Understanding", ["Vedran Vukotic", "Christian Raymond"], "https://doi.org/10.21437/Interspeech.2019-2977", 5, "interspeech", 2019]], "Max W. Y. Lam": [0, ["Extract, Adapt and Recognize: An End-to-End Neural Network for Corrupted Monaural Speech Recognition", ["Max W. Y. Lam", "Jun Wang", "Xunying Liu", "Helen Meng", "Dan Su", "Dong Yu"], "https://doi.org/10.21437/Interspeech.2019-1626", 5, "interspeech", 2019]], "Jesus Villalba": [0, ["State-of-the-Art Speaker Recognition for Telephone and Video Speech: The JHU-MIT Submission for NIST SRE18", ["Jesus Villalba", "Nanxin Chen", "David Snyder", "Daniel Garcia-Romero", "Alan McCree", "Gregory Sell", "Jonas Borgstrom", "Fred Richardson", "Suwon Shon", "Francois Grondin", "Reda Dehak", "Leibny Paola Garcia-Perera", "Daniel Povey", "Pedro A. Torres-Carrasquillo", "Sanjeev Khudanpur", "Najim Dehak"], "https://doi.org/10.21437/Interspeech.2019-2713", 5, "interspeech", 2019]], "Nilay Shrivastava": [0, ["MobiVSR : Efficient and Light-Weight Neural Network for Visual Speech Recognition on Mobile Devices", ["Nilay Shrivastava", "Astitwa Saxena", "Yaman Kumar", "Rajiv Ratn Shah", "Amanda Stent", "Debanjan Mahata", "Preeti Kaur", "Roger Zimmermann"], "https://doi.org/10.21437/Interspeech.2019-3273", 5, "interspeech", 2019]], "Erfan Loweimi": [0, ["On Learning Interpretable CNNs with Parametric Modulated Kernel-Based Filters", ["Erfan Loweimi", "Peter Bell", "Steve Renals"], "https://doi.org/10.21437/Interspeech.2019-1257", 5, "interspeech", 2019]], "Konstantinos Kyriakopoulos": [0, ["A Deep Learning Approach to Automatic Characterisation of Rhythm in Non-Native English Speech", ["Konstantinos Kyriakopoulos", "Kate M. Knill", "Mark J. F. Gales"], "https://doi.org/10.21437/Interspeech.2019-3186", 5, "interspeech", 2019]], "Fang Hu": [0, ["Frication as a Vowel Feature? - Evidence from the Rui'an Wu Chinese Dialect", ["Fang Hu", "Youjue He"], "https://doi.org/10.21437/Interspeech.2019-1134", 5, "interspeech", 2019]], "Georgios Paraskevopoulos": [0, ["Unsupervised Low-Rank Representations for Speech Emotion Recognition", ["Georgios Paraskevopoulos", "Efthymios Tzinis", "Nikolaos Ellinas", "Theodoros Giannakopoulos", "Alexandros Potamianos"], "https://doi.org/10.21437/Interspeech.2019-2769", 5, "interspeech", 2019]], "Yuanfeng Song": [4.1360019575886753e-10, ["Topic-Aware Dialogue Speech Recognition with Transfer Learning", ["Yuanfeng Song", "Di Jiang", "Xueyang Wu", "Qian Xu", "Raymond Chi-Wing Wong", "Qiang Yang"], "https://doi.org/10.21437/Interspeech.2019-1694", 5, "interspeech", 2019]], "Ben Foley": [0, ["Elpis, an Accessible Speech-to-Text Tool", ["Ben Foley", "Alina Rakhi", "Nicholas Lambourne", "Nicholas Buckeridge", "Janet Wiles"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8006.html", 2, "interspeech", 2019]], "Yang Zhang": [0, ["VAE-Based Regularization for Deep Speaker Embedding", ["Yang Zhang", "Lantian Li", "Dong Wang"], "https://doi.org/10.21437/Interspeech.2019-2486", 5, "interspeech", 2019]], "Ryan Eloff": [0, ["Unsupervised Acoustic Unit Discovery for Speech Synthesis Using Discrete Latent-Variable Neural Networks", ["Ryan Eloff", "Andre Nortje", "Benjamin van Niekerk", "Avashna Govender", "Leanne Nortje", "Arnu Pretorius", "Elan Van Biljon", "Ewald van der Westhuizen", "Lisa van Staden", "Herman Kamper"], "https://doi.org/10.21437/Interspeech.2019-1518", 5, "interspeech", 2019]], "Lyan Verwimp": [0, ["Reverse Transfer Learning: Can Word Embeddings Trained for Different NLP Tasks Improve Neural Language Models?", ["Lyan Verwimp", "Jerome R. Bellegarda"], "https://doi.org/10.21437/Interspeech.2019-1332", 5, "interspeech", 2019]], "Katrin Angerbauer": [0, ["Automatic Compression of Subtitles with Neural Networks and its Effect on User Experience", ["Katrin Angerbauer", "Heike Adel", "Ngoc Thang Vu"], "https://doi.org/10.21437/Interspeech.2019-1750", 5, "interspeech", 2019]], "Yuriko Yokoe": [0, ["Place Shift as an Autonomous Process: Evidence from Japanese Listeners", ["Yuriko Yokoe"], "https://doi.org/10.21437/Interspeech.2019-2302", 5, "interspeech", 2019]], "Pranav Ladkat": [0, ["Two Tiered Distributed Training Algorithm for Acoustic Modeling", ["Pranav Ladkat", "Oleg Rybakov", "Radhika Arava", "Sree Hari Krishnan Parthasarathi", "I-Fan Chen", "Nikko Strom"], "https://doi.org/10.21437/Interspeech.2019-1859", 5, "interspeech", 2019]], "Bowen Shi": [0, ["Compression of Acoustic Event Detection Models with Quantized Distillation", ["Bowen Shi", "Ming Sun", "Chieh-Chi Kao", "Viktor Rozgic", "Spyros Matsoukas", "Chao Wang"], "https://doi.org/10.21437/Interspeech.2019-1747", 5, "interspeech", 2019]], "Kenichi Arai": [0, ["Predicting Speech Intelligibility of Enhanced Speech Using Phone Accuracy of DNN-Based ASR System", ["Kenichi Arai", "Shoko Araki", "Atsunori Ogawa", "Keisuke Kinoshita", "Tomohiro Nakatani", "Katsuhiko Yamamoto", "Toshio Irino"], "https://doi.org/10.21437/Interspeech.2019-1381", 5, "interspeech", 2019]], "Jan Michalsky": [0, ["Towards the Prosody of Persuasion in Competitive Negotiation. The Relationship Between f0 and Negotiation Success in Same Sex Sales Tasks", ["Jan Michalsky", "Heike Schoormann", "Thomas Schultze"], "https://doi.org/10.21437/Interspeech.2019-3031", 5, "interspeech", 2019]], "Saurabh Sahu": [0, ["Multi-Modal Learning for Speech Emotion Recognition: An Analysis and Comparison of ASR Outputs with Ground Truth Transcription", ["Saurabh Sahu", "Vikramjit Mitra", "Nadee Seneviratne", "Carol Y. Espy-Wilson"], "https://doi.org/10.21437/Interspeech.2019-1149", 5, "interspeech", 2019]], "Chiori Hori": [0, ["Joint Student-Teacher Learning for Audio-Visual Scene-Aware Dialog", ["Chiori Hori", "Anoop Cherian", "Tim K. Marks", "Takaaki Hori"], "https://doi.org/10.21437/Interspeech.2019-3143", 5, "interspeech", 2019]], "Fanny Guitard-Ivent": [0, ["Are IP Initial Vowels Acoustically More Distinct? Results from LDA and CNN Classifications", ["Fanny Guitard-Ivent", "Gabriele Chignoli", "Cecile Fougeron", "Laurianne Georgeton"], "https://doi.org/10.21437/Interspeech.2019-2153", 5, "interspeech", 2019]], "Tianchi Liu": [0, ["A Unified Framework for Speaker and Utterance Verification", ["Tianchi Liu", "Maulik C. Madhavi", "Rohan Kumar Das", "Haizhou Li"], "https://doi.org/10.21437/Interspeech.2019-1994", 5, "interspeech", 2019]], "Li-Wei Chen": [0, ["Generative Adversarial Networks for Unpaired Voice Transformation on Impaired Speech", ["Li-Wei Chen", "Hung-yi Lee", "Yu Tsao"], "https://doi.org/10.21437/Interspeech.2019-1265", 5, "interspeech", 2019]], "Benjamin Milde": [0, ["SparseSpeech: Unsupervised Acoustic Unit Discovery with Memory-Augmented Sequence Autoencoders", ["Benjamin Milde", "Chris Biemann"], "https://doi.org/10.21437/Interspeech.2019-2938", 5, "interspeech", 2019]], "Wei Xue": [0, ["Direct-Path Signal Cross-Correlation Estimation for Sound Source Localization in Reverberation", ["Wei Xue", "Ying Tong", "Guohong Ding", "Chao Zhang", "Tao Ma", "Xiaodong He", "Bowen Zhou"], "https://doi.org/10.21437/Interspeech.2019-1488", 5, "interspeech", 2019]], "Ji Ming": [0, ["Full-Sentence Correlation: A Method to Handle Unpredictable Noise for Robust Speech Recognition", ["Ji Ming", "Danny Crookes"], "https://doi.org/10.21437/Interspeech.2019-2127", 5, "interspeech", 2019]], "Andy Murphy": [0, ["The Role of Voice Quality in the Perception of Prominence in Synthetic Speech", ["Andy Murphy", "Irena Yanushevskaya", "Ailbhe Ni Chasaide", "Christer Gobl"], "https://doi.org/10.21437/Interspeech.2019-2761", 5, "interspeech", 2019]], "Gabriel Marzinotto": [0, ["Adapting a FrameNet Semantic Parser for Spoken Language Understanding Using Adversarial Learning", ["Gabriel Marzinotto", "Geraldine Damnati", "Frederic Bechet"], "https://doi.org/10.21437/Interspeech.2019-2732", 5, "interspeech", 2019]], "Tara N. Sainath": [0, ["Two-Pass End-to-End Speech Recognition", ["Tara N. Sainath", "Ruoming Pang", "David Rybach", "Yanzhang He", "Rohit Prabhavalkar", "Wei Li", "Mirko Visontai", "Qiao Liang", "Trevor Strohman", "Yonghui Wu", "Ian McGraw", "Chung-Cheng Chiu"], "https://doi.org/10.21437/Interspeech.2019-1341", 5, "interspeech", 2019]], "Jacob Sager": [0, ["VESUS: A Crowd-Annotated Database to Study Emotion Production and Perception in Spoken English", ["Jacob Sager", "Ravi Shankar", "Jacob Reinhold", "Archana Venkataraman"], "https://doi.org/10.21437/Interspeech.2019-1413", 5, "interspeech", 2019]], "Dan Oneata": [0, ["Kite: Automatic Speech Recognition for Unmanned Aerial Vehicles", ["Dan Oneata", "Horia Cucu"], "https://doi.org/10.21437/Interspeech.2019-1390", 5, "interspeech", 2019]], "Fadi Biadsy": [0, ["Parrotron: An End-to-End Speech-to-Speech Conversion Model and its Applications to Hearing-Impaired Speech and Speech Separation", ["Fadi Biadsy", "Ron J. Weiss", "Pedro J. Moreno", "Dimitri Kanvesky", "Ye Jia"], "https://doi.org/10.21437/Interspeech.2019-1789", 5, "interspeech", 2019]], "Qiang Huang": [0, ["Detecting Mismatch Between Speech and Transcription Using Cross-Modal Attention", ["Qiang Huang", "Thomas Hain"], "https://doi.org/10.21437/Interspeech.2019-2125", 5, "interspeech", 2019]], "Ryuichi Yamamoto": [0, ["Probability Density Distillation with Generative Adversarial Networks for High-Quality Parallel Waveform Generation", ["Ryuichi Yamamoto", "Eunwoo Song", "Jae-Min Kim"], "https://doi.org/10.21437/Interspeech.2019-1965", 5, "interspeech", 2019]], "Olivier Perrotin": [0, ["GFM-Voc: A Real-Time Voice Quality Modification System", ["Olivier Perrotin", "Ian Vince McLoughlin"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8018.html", 2, "interspeech", 2019]], "Bjorn W. Schuller": [0, ["The INTERSPEECH 2019 Computational Paralinguistics Challenge: Styrian Dialects, Continuous Sleepiness, Baby Sounds & Orca Activity", ["Bjorn W. Schuller", "Anton Batliner", "Christian Bergler", "Florian B. Pokorny", "Jarek Krajewski", "Margaret Cychosz", "Ralf Vollmann", "Sonja-Dana Roelen", "Sebastian Schnieder", "Elika Bergelson", "Alejandrina Cristia", "Amanda Seidl", "Anne S. Warlaumont", "Lisa Yankowitz", "Elmar Noth", "Shahin Amiriparian", "Simone Hantke", "Maximilian Schmitt"], "https://doi.org/10.21437/Interspeech.2019-1122", 5, "interspeech", 2019]], "Xinhao Wang": [5.575397210577648e-07, ["Automatic Detection of Off-Topic Spoken Responses Using Very Deep Convolutional Neural Networks", ["Xinhao Wang", "Su-Youn Yoon", "Keelan Evanini", "Klaus Zechner", "Yao Qian"], "https://doi.org/10.21437/Interspeech.2019-1848", 5, "interspeech", 2019]], "Tatiana Likhomanenko": [0, ["Who Needs Words? Lexicon-Free Speech Recognition", ["Tatiana Likhomanenko", "Gabriel Synnaeve", "Ronan Collobert"], "https://doi.org/10.21437/Interspeech.2019-3107", 5, "interspeech", 2019]], "Okko Rasanen": [0, ["A Computational Model of Early Language Acquisition from Audiovisual Experiences of Young Infants", ["Okko Rasanen", "Khazar Khorrami"], "https://doi.org/10.21437/Interspeech.2019-1523", 5, "interspeech", 2019]], "Karthik Pandia D. S": [0, ["Zero Resource Speech Synthesis Using Transcripts Derived from Perceptual Acoustic Units", ["Karthik Pandia D. S", "Hema A. Murthy"], "https://doi.org/10.21437/Interspeech.2019-2336", 5, "interspeech", 2019]], "Charlotte Sorensen": [0, ["Harmonic Beamformers for Non-Intrusive Speech Intelligibility Prediction", ["Charlotte Sorensen", "Jesper Bunsow Boldt", "Mads Graesboll Christensen"], "https://doi.org/10.21437/Interspeech.2019-2929", 5, "interspeech", 2019], ["Validation of the Non-Intrusive Codebook-Based Short Time Objective Intelligibility Metric for Processed Speech", ["Charlotte Sorensen", "Jesper B. Boldt", "Mads G. Christensen"], "https://doi.org/10.21437/Interspeech.2019-1625", 5, "interspeech", 2019]], "Daisuke Fukunaga": [0, ["GPU-Based WFST Decoding with Extra Large Language Model", ["Daisuke Fukunaga", "Yoshiki Tanaka", "Yuichi Kageyama"], "https://doi.org/10.21437/Interspeech.2019-2101", 5, "interspeech", 2019]], "Suhas B. N.": [0, ["Comparison of Speech Tasks and Recording Devices for Voice Based Automatic Classification of Healthy Subjects and Patients with Amyotrophic Lateral Sclerosis", ["Suhas B. N.", "Deep Patel", "Nithin Rao Koluguri", "Yamini Belur", "Pradeep Reddy", "Atchayaram Nalini", "Ravi Yadav", "Dipanjan Gope", "Prasanta Kumar Ghosh"], "https://doi.org/10.21437/Interspeech.2019-1285", 5, "interspeech", 2019]], "Hyeon Seung Lee": [0.999962717294693, ["End-to-End Multi-Channel Speech Enhancement Using Inter-Channel Time-Restricted Attention on Raw Waveform", ["Hyeon Seung Lee", "Hyung Yong Kim", "Woo Hyun Kang", "Jeunghun Kim", "Nam Soo Kim"], "https://doi.org/10.21437/Interspeech.2019-2397", 5, "interspeech", 2019]], "Yoan Dinkov": [0, ["Predicting the Leading Political Ideology of YouTube Channels Using Acoustic, Textual, and Metadata Information", ["Yoan Dinkov", "Ahmed Ali", "Ivan Koychev", "Preslav Nakov"], "https://doi.org/10.21437/Interspeech.2019-2965", 5, "interspeech", 2019]], "Ye Jia": [0, ["Direct Speech-to-Speech Translation with a Sequence-to-Sequence Model", ["Ye Jia", "Ron J. Weiss", "Fadi Biadsy", "Wolfgang Macherey", "Melvin Johnson", "Zhifeng Chen", "Yonghui Wu"], "https://doi.org/10.21437/Interspeech.2019-1951", 5, "interspeech", 2019]], "Midia Yousefi": [0, ["Probabilistic Permutation Invariant Training for Speech Separation", ["Midia Yousefi", "Soheil Khorram", "John H. L. Hansen"], "https://doi.org/10.21437/Interspeech.2019-1827", 5, "interspeech", 2019]], "David A. Braude": [0, ["All Together Now: The Living Audio Dataset", ["David A. Braude", "Matthew P. Aylett", "Caoimhin Laoide-Kemp", "Simone Ashby", "Kristen M. Scott", "Brian O Raghallaigh", "Anna Braudo", "Alex Brouwer", "Adriana Stan"], "https://doi.org/10.21437/Interspeech.2019-2448", 5, "interspeech", 2019]], "Mary Pietrowicz": [0, ["A New Approach for Automating Analysis of Responses on Verbal Fluency Tests from Subjects At-Risk for Schizophrenia", ["Mary Pietrowicz", "Carla Agurto", "Raquel Norel", "Elif Eyigoz", "Guillermo A. Cecchi", "Zarina R. Bilgrami", "Cheryl Corcoran"], "https://doi.org/10.21437/Interspeech.2019-2987", 5, "interspeech", 2019]], "Saurabhchand Bhati": [0, ["Unsupervised Acoustic Segmentation and Clustering Using Siamese Network Embeddings", ["Saurabhchand Bhati", "Shekhar Nayak", "K. Sri Rama Murty", "Najim Dehak"], "https://doi.org/10.21437/Interspeech.2019-2981", 5, "interspeech", 2019]], "Oliver Niebuhr": [0, ["God as Interlocutor - Real or Imaginary? Prosodic Markers of Dialogue Speech and Expected Efficacy in Spoken Prayer", ["Oliver Niebuhr", "Uffe Schjoedt"], "https://doi.org/10.21437/Interspeech.2019-1193", 5, "interspeech", 2019], ["PASCAL and DPA: A Pilot Study on Using Prosodic Competence Scores to Predict Communicative Skills for Team Working and Public Speaking", ["Oliver Niebuhr", "Jan Michalsky"], "https://doi.org/10.21437/Interspeech.2019-3034", 5, "interspeech", 2019], ["Do not Hesitate! - Unless You Do it Shortly or Nasally: How the Phonetics of Filled Pauses Determine Their Subjective Frequency and Perceived Speaker Performance", ["Oliver Niebuhr", "Kerstin Fischer"], "https://doi.org/10.21437/Interspeech.2019-1194", 5, "interspeech", 2019]], "Anna Bjork Nikulasdottir": [0, ["Bootstrapping a Text Normalization System for an Inflected Language. Numbers as a Test Case", ["Anna Bjork Nikulasdottir", "Jon Gudnason"], "https://doi.org/10.21437/Interspeech.2019-2367", 5, "interspeech", 2019]], "Munir Georges": [0, ["Ultra-Compact NLU: Neuronal Network Binarization as Regularization", ["Munir Georges", "Krzysztof Czarnowski", "Tobias Bocklet"], "https://doi.org/10.21437/Interspeech.2019-2591", 5, "interspeech", 2019]], "Gianmarco Cerutti": [0, ["Neural Network Distillation on IoT Platforms for Sound Event Detection", ["Gianmarco Cerutti", "Rahul Prasad", "Alessio Brutti", "Elisabetta Farella"], "https://doi.org/10.21437/Interspeech.2019-2394", 5, "interspeech", 2019]], "Bilal Soomro": [0, ["Towards Debugging Deep Neural Networks by Generating Speech Utterances", ["Bilal Soomro", "Anssi Kanervisto", "Trung Ngo Trong", "Ville Hautamaki"], "https://doi.org/10.21437/Interspeech.2019-2339", 5, "interspeech", 2019]], "Robert Gale": [0, ["Improving ASR Systems for Children with Autism and Language Impairment Using Domain-Focused DNN Transfer Techniques", ["Robert Gale", "Liu Chen", "Jill Dolata", "Jan P. H. van Santen", "Meysam Asgari"], "https://doi.org/10.21437/Interspeech.2019-3161", 5, "interspeech", 2019]], "Zhenrui Zhang": [0, ["Vowels and Diphthongs in the Xupu Xiang Chinese Dialect", ["Zhenrui Zhang", "Fang Hu"], "https://doi.org/10.21437/Interspeech.2019-1174", 5, "interspeech", 2019]], "Yanan Guo": [0, ["Speech Augmentation via Speaker-Specific Noise in Unseen Environment", ["Yanan Guo", "Ziping Zhao", "Yide Ma", "Bjorn W. Schuller"], "https://doi.org/10.21437/Interspeech.2019-2712", 5, "interspeech", 2019]], "Muhammad Umar Farooq": [0, ["Improving Large Vocabulary Urdu Speech Recognition System Using Deep Neural Networks", ["Muhammad Umar Farooq", "Farah Adeeba", "Sahar Rauf", "Sarmad Hussain"], "https://doi.org/10.21437/Interspeech.2019-2629", 5, "interspeech", 2019]], "Jose Vicente Egas Lopez": [0, ["Assessing Parkinson's Disease from Speech Using Fisher Vectors", ["Jose Vicente Egas Lopez", "Juan Rafael Orozco-Arroyave", "Gabor Gosztolya"], "https://doi.org/10.21437/Interspeech.2019-2217", 5, "interspeech", 2019]], "Anna V. Runarsdottir": [0, ["Lattice Re-Scoring During Manual Editing for Automatic Error Correction of ASR Transcripts", ["Anna V. Runarsdottir", "Inga Run Helgadottir", "Jon Gudnason"], "https://doi.org/10.21437/Interspeech.2019-1790", 5, "interspeech", 2019]], "Gakuto Kurata": [0, ["Guiding CTC Posterior Spike Timings for Improved Posterior Fusion and Knowledge Distillation", ["Gakuto Kurata", "Kartik Audhkhasi"], "https://doi.org/10.21437/Interspeech.2019-1952", 5, "interspeech", 2019], ["Multi-Task CTC Training with Auxiliary Feature Reconstruction for End-to-End Speech Recognition", ["Gakuto Kurata", "Kartik Audhkhasi"], "https://doi.org/10.21437/Interspeech.2019-1710", 5, "interspeech", 2019]], "Kusha Sridhar": [0, ["Speech Emotion Recognition with a Reject Option", ["Kusha Sridhar", "Carlos Busso"], "https://doi.org/10.21437/Interspeech.2019-1842", 5, "interspeech", 2019]], "Meredith Moore": [0, ["Say What? A Dataset for Exploring the Error Patterns That Two ASR Engines Make", ["Meredith Moore", "Michael Saxon", "Hemanth Venkateswara", "Visar Berisha", "Sethuraman Panchanathan"], "https://doi.org/10.21437/Interspeech.2019-3096", 5, "interspeech", 2019]], "Frederic Bechet": [0, ["Benchmarking Benchmarks: Introducing New Automatic Indicators for Benchmarking Spoken Language Understanding Corpora", ["Frederic Bechet", "Christian Raymond"], "https://doi.org/10.21437/Interspeech.2019-3033", 5, "interspeech", 2019]], "Bin Li": [0, ["Influence of Contextuality on Prosodic Realization of Information Structure in Chinese Dialogues", ["Bin Li", "Yuan Jia"], "https://doi.org/10.21437/Interspeech.2019-2291", 5, "interspeech", 2019]], "Saeed Bagheri": [0, ["Exploiting Multi-Channel Speech Presence Probability in Parametric Multi-Channel Wiener Filter", ["Saeed Bagheri", "Daniele Giacobello"], "https://doi.org/10.21437/Interspeech.2019-2665", 5, "interspeech", 2019]], "Marvin Rajwadi": [0, ["Explaining Sentiment Classification", ["Marvin Rajwadi", "Cornelius Glackin", "Julie A. Wall", "Gerard Chollet", "Nigel Cannings"], "https://doi.org/10.21437/Interspeech.2019-2743", 5, "interspeech", 2019]], "Danwei Cai": [0, ["The DKU System for the Speaker Recognition Task of the 2019 VOiCES from a Distance Challenge", ["Danwei Cai", "Xiaoyi Qin", "Weicheng Cai", "Ming Li"], "https://doi.org/10.21437/Interspeech.2019-1435", 5, "interspeech", 2019], ["Multi-Channel Training for End-to-End Speaker Recognition Under Reverberant and Noisy Environment", ["Danwei Cai", "Xiaoyi Qin", "Ming Li"], "https://doi.org/10.21437/Interspeech.2019-1437", 5, "interspeech", 2019], ["The DKU-SMIIP System for NIST 2018 Speaker Recognition Evaluation", ["Danwei Cai", "Weicheng Cai", "Ming Li"], "https://doi.org/10.21437/Interspeech.2019-1436", 5, "interspeech", 2019]], "Jorge Llombart": [0, ["Speech Enhancement with Wide Residual Networks in Reverberant Environments", ["Jorge Llombart", "Dayana Ribas", "Antonio Miguel", "Luis Vicente", "Alfonso Ortega Gimenez", "Eduardo Lleida"], "https://doi.org/10.21437/Interspeech.2019-1745", 5, "interspeech", 2019], ["Progressive Speech Enhancement with Residual Connections", ["Jorge Llombart", "Dayana Ribas", "Antonio Miguel", "Luis Vicente", "Alfonso Ortega Gimenez", "Eduardo Lleida"], "https://doi.org/10.21437/Interspeech.2019-1748", 5, "interspeech", 2019]], "Sebastian Springenberg": [0, ["Predictive Auxiliary Variational Autoencoder for Representation Learning of Global Speech Characteristics", ["Sebastian Springenberg", "Egor Lakomkin", "Cornelius Weber", "Stefan Wermter"], "https://doi.org/10.21437/Interspeech.2019-2845", 5, "interspeech", 2019]], "Daniel Garcia-Romero": [0, ["x-Vector DNN Refinement with Full-Length Recordings for Speaker Recognition", ["Daniel Garcia-Romero", "David Snyder", "Gregory Sell", "Alan McCree", "Daniel Povey", "Sanjeev Khudanpur"], "https://doi.org/10.21437/Interspeech.2019-2205", 4, "interspeech", 2019], ["Speaker Recognition Benchmark Using the CHiME-5 Corpus", ["Daniel Garcia-Romero", "David Snyder", "Shinji Watanabe", "Gregory Sell", "Alan McCree", "Daniel Povey", "Sanjeev Khudanpur"], "https://doi.org/10.21437/Interspeech.2019-2174", 5, "interspeech", 2019]], "Martin Karafiat": [0, ["Analysis of Multilingual Sequence-to-Sequence Speech Recognition Systems", ["Martin Karafiat", "Murali Karthick Baskar", "Shinji Watanabe", "Takaaki Hori", "Matthew Wiesner", "Jan Cernocky"], "https://doi.org/10.21437/Interspeech.2019-2355", 5, "interspeech", 2019]], "Nguyen Bach": [0, ["Noisy BiLSTM-Based Models for Disfluency Detection", ["Nguyen Bach", "Fei Huang"], "https://doi.org/10.21437/Interspeech.2019-1336", 5, "interspeech", 2019]], "Fei Chen": [0, ["Contributions of Consonant-Vowel Transitions to Mandarin Tone Identification in Simulated Electric-Acoustic Hearing", ["Fei Chen"], "https://doi.org/10.21437/Interspeech.2019-1124", 5, "interspeech", 2019]], "Wei Rao": [0, ["Target Speaker Extraction for Multi-Talker Speaker Verification", ["Wei Rao", "Chenglin Xu", "Eng Siong Chng", "Haizhou Li"], "https://doi.org/10.21437/Interspeech.2019-1410", 5, "interspeech", 2019]], "Harry Bleyan": [0, ["Developing Pronunciation Models in New Languages Faster by Exploiting Common Grapheme-to-Phoneme Correspondences Across Languages", ["Harry Bleyan", "Sandy Ritchie", "Jonas Fromseier Mortensen", "Daan van Esch"], "https://doi.org/10.21437/Interspeech.2019-1781", 5, "interspeech", 2019]], "Jian Yao": [0, ["Coarse-to-Fine Optimization for Speech Enhancement", ["Jian Yao", "Ahmad Al-Dahle"], "https://doi.org/10.21437/Interspeech.2019-2792", 5, "interspeech", 2019]], "Jack Parry": [0, ["Analysis of Deep Learning Architectures for Cross-Corpus Speech Emotion Recognition", ["Jack Parry", "Dimitri Palaz", "Georgia Clarke", "Pauline Lecomte", "Rebecca Mead", "Michael Berger", "Gregor Hofer"], "https://doi.org/10.21437/Interspeech.2019-2753", 5, "interspeech", 2019]], "Yi-Chiao Wu": [6.146273167338418e-14, ["Quasi-Periodic WaveNet Vocoder: A Pitch Dependent Dilated Convolution Model for Parametric Speech Generation", ["Yi-Chiao Wu", "Tomoki Hayashi", "Patrick Lumban Tobing", "Kazuhiro Kobayashi", "Tomoki Toda"], "https://doi.org/10.21437/Interspeech.2019-1232", 5, "interspeech", 2019]], "Nusrah Hussain": [0, ["Speech Driven Backchannel Generation Using Deep Q-Network for Enhancing Engagement in Human-Robot Interaction", ["Nusrah Hussain", "Engin Erzin", "T. Metin Sezgin", "Yucel Yemez"], "https://doi.org/10.21437/Interspeech.2019-2521", 5, "interspeech", 2019]], "Abinay Reddy Naini": [0, ["Whisper to Neutral Mapping Using Cosine Similarity Maximization in i-Vector Space for Speaker Verification", ["Abinay Reddy Naini", "Achuth Rao M. V", "Prasanta Kumar Ghosh"], "https://doi.org/10.21437/Interspeech.2019-2280", 5, "interspeech", 2019]], "Gao-Yi Chao": [0, ["Enforcing Semantic Consistency for Cross Corpus Valence Regression from Speech Using Adversarial Discrepancy Learning", ["Gao-Yi Chao", "Yun-Shao Lin", "Chun-Min Chang", "Chi-Chun Lee"], "https://doi.org/10.21437/Interspeech.2019-2037", 5, "interspeech", 2019]], "Qingjian Lin": [0, ["LSTM Based Similarity Measurement with Spectral Clustering for Speaker Diarization", ["Qingjian Lin", "Ruiqing Yin", "Ming Li", "Herve Bredin", "Claude Barras"], "https://doi.org/10.21437/Interspeech.2019-1388", 5, "interspeech", 2019]], "Umair Khan": [0, ["Auto-Encoding Nearest Neighbor i-Vectors for Speaker Verification", ["Umair Khan", "Miquel India", "Javier Hernando"], "https://doi.org/10.21437/Interspeech.2019-1444", 5, "interspeech", 2019]], "Aniruddha Tammewar": [0, ["Modeling User Context for Valence Prediction from Narratives", ["Aniruddha Tammewar", "Alessandra Cervone", "Eva-Maria Messner", "Giuseppe Riccardi"], "https://doi.org/10.21437/Interspeech.2019-2489", 5, "interspeech", 2019]], "Ju-Chieh Chou": [0, ["One-Shot Voice Conversion by Separating Speaker and Content Representations with Instance Normalization", ["Ju-Chieh Chou", "Hung-yi Lee"], "https://doi.org/10.21437/Interspeech.2019-2663", 5, "interspeech", 2019]], "Antti Suni": [0, ["Comparative Analysis of Prosodic Characteristics Using WaveNet Embeddings", ["Antti Suni", "Marcin Wlodarczak", "Martti Vainio", "Juraj Simko"], "https://doi.org/10.21437/Interspeech.2019-2373", 5, "interspeech", 2019]], "Lukas Mateju": [0, ["An Approach to Online Speaker Change Point Detection Using DNNs and WFSTs", ["Lukas Mateju", "Petr Cerva", "Jindrich Zdansky"], "https://doi.org/10.21437/Interspeech.2019-1407", 5, "interspeech", 2019]], "Takuma Okamoto": [0, ["Real-Time Neural Text-to-Speech with Sequence-to-Sequence Acoustic Model and WaveGlow or Single Gaussian WaveRNN Vocoders", ["Takuma Okamoto", "Tomoki Toda", "Yoshinori Shiga", "Hisashi Kawai"], "https://doi.org/10.21437/Interspeech.2019-1288", 5, "interspeech", 2019]], "Jian Wu": [0.40413545072078705, ["Improved Speaker-Dependent Separation for CHiME-5 Challenge", ["Jian Wu", "Yong Xu", "Shi-Xiong Zhang", "Lianwu Chen", "Meng Yu", "Lei Xie", "Dong Yu"], "https://doi.org/10.21437/Interspeech.2019-1569", 5, "interspeech", 2019]], "Dhananjaya Gowda": [0, ["Multi-Task Multi-Resolution Char-to-BPE Cross-Attention Decoder for End-to-End Speech Recognition", ["Dhananjaya Gowda", "Abhinav Garg", "Kwangyoun Kim", "Mehul Kumar", "Chanwoo Kim"], "https://doi.org/10.21437/Interspeech.2019-3216", 5, "interspeech", 2019]], "Jibin Wu": [0.4061788022518158, ["Robust Sound Recognition: A Neuromorphic Approach", ["Jibin Wu", "Zihan Pan", "Malu Zhang", "Rohan Kumar Das", "Yansong Chua", "Haizhou Li"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8032.html", 2, "interspeech", 2019]], "Chang Huai You": [0, ["Device Feature Extractor for Replay Spoofing Detection", ["Chang Huai You", "Jichen Yang", "Huy Dat Tran"], "https://doi.org/10.21437/Interspeech.2019-2137", 5, "interspeech", 2019]], "Tomohiro Nakatani": [0, ["Simultaneous Denoising and Dereverberation for Low-Latency Applications Using Frame-by-Frame Online Unified Convolutional Beamformer", ["Tomohiro Nakatani", "Keisuke Kinoshita"], "https://doi.org/10.21437/Interspeech.2019-1286", 5, "interspeech", 2019]], "Daniil Kocharov": [0, ["Prosodic Factors Influencing Vowel Reduction in Russian", ["Daniil Kocharov", "Tatiana Kachkovskaia", "Pavel A. Skrelin"], "https://doi.org/10.21437/Interspeech.2019-2918", 5, "interspeech", 2019]], "Logan Ford": [0, ["A Deep Residual Network for Large-Scale Acoustic Scene Analysis", ["Logan Ford", "Hao Tang", "Francois Grondin", "James R. Glass"], "https://doi.org/10.21437/Interspeech.2019-2731", 5, "interspeech", 2019]], "Yuanchao Li": [0, ["Improved End-to-End Speech Emotion Recognition Using Self Attention Mechanism and Multitask Learning", ["Yuanchao Li", "Tianyu Zhao", "Tatsuya Kawahara"], "https://doi.org/10.21437/Interspeech.2019-2594", 5, "interspeech", 2019]], "Florian Metze": [0, ["Survey Talk: Multimodal Processing of Speech and Language", ["Florian Metze"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/abs22.html", 0, "interspeech", 2019]], "Jen-Tzung Chien": [0, ["Meta Learning for Hyperparameter Optimization in Dialogue System", ["Jen-Tzung Chien", "Wei Xiang Lieow"], "https://doi.org/10.21437/Interspeech.2019-1383", 5, "interspeech", 2019], ["Self Attention in Variational Sequential Learning for Summarization", ["Jen-Tzung Chien", "Chun-Wei Wang"], "https://doi.org/10.21437/Interspeech.2019-1548", 5, "interspeech", 2019]], "Hassan Taherian": [0, ["Deep Learning Based Multi-Channel Speaker Recognition in Noisy and Reverberant Environments", ["Hassan Taherian", "Zhong-Qiu Wang", "DeLiang Wang"], "https://doi.org/10.21437/Interspeech.2019-1428", 5, "interspeech", 2019]], "Pujitha Appan Kandala": [0, ["Speaker Adaptation for Lip-Reading Using Visual Identity Vectors", ["Pujitha Appan Kandala", "Abhinav Thanda", "Dilip Kumar Margam", "Rohith Chandrashekar Aralikatti", "Tanay Sharma", "Sharad Roy", "Shankar M. Venkatesan"], "https://doi.org/10.21437/Interspeech.2019-3237", 5, "interspeech", 2019]], "Jan Niehues": [0, ["Survey Talk: A Survey on Speech Translation", ["Jan Niehues"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/abs9.html", 0, "interspeech", 2019]], "Tianqi Wang": [4.794821872877719e-09, ["Towards the Speech Features of Mild Cognitive Impairment: Universal Evidence from Structured and Unstructured Connected Speech of Chinese", ["Tianqi Wang", "Chongyuan Lian", "Jingshen Pan", "Quanlei Yan", "Feiqi Zhu", "Manwa L. Ng", "Lan Wang", "Nan Yan"], "https://doi.org/10.21437/Interspeech.2019-2414", 5, "interspeech", 2019], ["Towards the Speech Features of Early-Stage Dementia: Design and Application of the Mandarin Elderly Cognitive Speech Database", ["Tianqi Wang", "Quanlei Yan", "Jingshen Pan", "Feiqi Zhu", "Rongfeng Su", "Yi Guo", "Lan Wang", "Nan Yan"], "https://doi.org/10.21437/Interspeech.2019-2453", 5, "interspeech", 2019]], "Anda Ouyang": [0, ["Speech Based Emotion Prediction: Can a Linear Model Work?", ["Anda Ouyang", "Ting Dang", "Vidhyasaharan Sethu", "Eliathamby Ambikairajah"], "https://doi.org/10.21437/Interspeech.2019-3149", 5, "interspeech", 2019]], "Yiming Wang": [5.499646135831426e-06, ["The JHU ASR System for VOiCES from a Distance Challenge 2019", ["Yiming Wang", "David Snyder", "Hainan Xu", "Vimal Manohar", "Phani Sankar Nidadavolu", "Daniel Povey", "Sanjeev Khudanpur"], "https://doi.org/10.21437/Interspeech.2019-1948", 5, "interspeech", 2019]], "Huashan Pan": [0, ["A Mandarin Prosodic Boundary Prediction Model Based on Multi-Task Learning", ["Huashan Pan", "Xiulin Li", "Zhiqiang Huang"], "https://doi.org/10.21437/Interspeech.2019-1400", 4, "interspeech", 2019]], "Mirco Ravanelli": [0, ["Learning Speaker Representations with Mutual Information", ["Mirco Ravanelli", "Yoshua Bengio"], "https://doi.org/10.21437/Interspeech.2019-2380", 5, "interspeech", 2019]], "Shashwat Uttam": [0, ["Hush-Hush Speak: Speech Reconstruction Using Silent Videos", ["Shashwat Uttam", "Yaman Kumar", "Dhruva Sahrawat", "Mansi Aggarwal", "Rajiv Ratn Shah", "Debanjan Mahata", "Amanda Stent"], "https://doi.org/10.21437/Interspeech.2019-3269", 5, "interspeech", 2019]], "Pablo Arantes": [0, ["Quantifying Fundamental Frequency Modulation as a Function of Language, Speaking Style and Speaker", ["Pablo Arantes", "Anders Eriksson"], "https://doi.org/10.21437/Interspeech.2019-2857", 5, "interspeech", 2019]], "Renuka Mannem": [0, ["Acoustic and Articulatory Feature Based Speech Rate Estimation Using a Convolutional Dense Neural Network", ["Renuka Mannem", "Jhansi Mallela", "Aravind Illa", "Prasanta Kumar Ghosh"], "https://doi.org/10.21437/Interspeech.2019-2295", 5, "interspeech", 2019]], "Mireia Diez": [0, ["Bayesian HMM Based x-Vector Clustering for Speaker Diarization", ["Mireia Diez", "Lukas Burget", "Shuai Wang", "Johan Rohdin", "Jan Cernocky"], "https://doi.org/10.21437/Interspeech.2019-2813", 5, "interspeech", 2019]], "Protima Nomo Sudro": [0, ["Modification of Devoicing Error in Cleft Lip and Palate Speech", ["Protima Nomo Sudro", "S. R. Mahadeva Prasanna"], "https://doi.org/10.21437/Interspeech.2019-2604", 5, "interspeech", 2019]], "Miao Cao": [0, ["Pyramid Memory Block and Timestep Attention for Speech Emotion Recognition", ["Miao Cao", "Chun Yang", "Fang Zhou", "Xu-Cheng Yin"], "https://doi.org/10.21437/Interspeech.2019-3140", 5, "interspeech", 2019]], "Alp Oktem": [0, ["Prosodic Phrase Alignment for Machine Dubbing", ["Alp Oktem", "Mireia Farrus", "Antonio Bonafonte"], "https://doi.org/10.21437/Interspeech.2019-1621", 5, "interspeech", 2019]], "J. Hui": [0, ["Effects of Base-Frequency and Spectral Envelope on Deep-Learning Speech Separation and Recognition Models", ["J. Hui", "Y. Wei", "S. T. Chen", "R. H. Y. So"], "https://doi.org/10.21437/Interspeech.2019-1715", 5, "interspeech", 2019]], "Dieter Maurer": [0, ["Formant Pattern and Spectral Shape Ambiguity of Vowel Sounds, and Related Phenomena of Vowel Acoustics - Exemplary Evidence", ["Dieter Maurer", "Heidy Suter", "Christian dHereuse", "Volker Dellwo"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8017.html", 2, "interspeech", 2019]], "Li Liu": [0, ["Automatic Detection of the Temporal Segmentation of Hand Movements in British English Cued Speech", ["Li Liu", "Jianze Li", "Gang Feng", "Xiao-Ping Steven Zhang"], "https://doi.org/10.21437/Interspeech.2019-2353", 5, "interspeech", 2019]], "Grandee Lee": [3.118355152764707e-06, ["Linguistically Motivated Parallel Data Augmentation for Code-Switch Language Modeling", ["Grandee Lee", "Xianghu Yue", "Haizhou Li"], "https://doi.org/10.21437/Interspeech.2019-1382", 5, "interspeech", 2019]], "Liang Lu": [0, ["Self-Teaching Networks", ["Liang Lu", "Eric Sun", "Yifan Gong"], "https://doi.org/10.21437/Interspeech.2019-1467", 5, "interspeech", 2019]], "Cheng-I Lai": [0, ["ASSERT: Anti-Spoofing with Squeeze-Excitation and Residual Networks", ["Cheng-I Lai", "Nanxin Chen", "Jesus Villalba", "Najim Dehak"], "https://doi.org/10.21437/Interspeech.2019-1794", 5, "interspeech", 2019]], "Zhifu Gao": [0, ["Improving Aggregation and Loss Function for Better Embedding Learning in End-to-End Speaker Verification System", ["Zhifu Gao", "Yan Song", "Ian McLoughlin", "Pengcheng Li", "Yiheng Jiang", "Li-Rong Dai"], "https://doi.org/10.21437/Interspeech.2019-1489", 5, "interspeech", 2019]], "Atsunori Ogawa": [0, ["Improved Deep Duel Model for Rescoring N-Best Speech Recognition List Using Backward LSTMLM and Ensemble Encoders", ["Atsunori Ogawa", "Marc Delcroix", "Shigeki Karita", "Tomohiro Nakatani"], "https://doi.org/10.21437/Interspeech.2019-1949", 5, "interspeech", 2019]], "Qing Wang": [0.00010747280612122267, ["Adversarial Regularization for End-to-End Robust Speaker Verification", ["Qing Wang", "Pengcheng Guo", "Sining Sun", "Lei Xie", "John H. L. Hansen"], "https://doi.org/10.21437/Interspeech.2019-2983", 5, "interspeech", 2019]], "Takashi Fukuda": [0, ["Direct Neuron-Wise Fusion of Cognate Neural Networks", ["Takashi Fukuda", "Masayuki Suzuki", "Gakuto Kurata"], "https://doi.org/10.21437/Interspeech.2019-1930", 5, "interspeech", 2019]], "Arindam Jati": [0, ["Multi-Task Discriminative Training of Hybrid DNN-TVM Model for Speaker Verification with Noisy and Far-Field Speech", ["Arindam Jati", "Raghuveer Peri", "Monisankha Pal", "Tae Jin Park", "Naveen Kumar", "Ruchir Travadi", "Panayiotis G. Georgiou", "Shrikanth Narayanan"], "https://doi.org/10.21437/Interspeech.2019-3010", 5, "interspeech", 2019]], "Sonia DApolito": [0, ["L2 Pronunciation Accuracy and Context: A Pilot Study on the Realization of Geminates in Italian as L2 by French Learners", ["Sonia DApolito", "Barbara Gili Fivela"], "https://doi.org/10.21437/Interspeech.2019-2934", 5, "interspeech", 2019]], "Rongzhi Gu": [2.6207646053322264e-09, ["Neural Spatial Filter: Target Speaker Speech Separation Assisted with Directional Information", ["Rongzhi Gu", "Lianwu Chen", "Shi-Xiong Zhang", "Jimeng Zheng", "Yong Xu", "Meng Yu", "Dan Su", "Yuexian Zou", "Dong Yu"], "https://doi.org/10.21437/Interspeech.2019-2266", 5, "interspeech", 2019]], "Masahito Togami": [0, ["Variational Bayesian Multi-Channel Speech Dereverberation Under Noisy Environments with Probabilistic Convolutive Transfer Function", ["Masahito Togami", "Tatsuya Komatsu"], "https://doi.org/10.21437/Interspeech.2019-1220", 5, "interspeech", 2019]], "Xurong Xie": [0, ["Fast DNN Acoustic Model Speaker Adaptation by Learning Hidden Unit Contribution Features", ["Xurong Xie", "Xunying Liu", "Tan Lee", "Lan Wang"], "https://doi.org/10.21437/Interspeech.2019-2050", 5, "interspeech", 2019]], "Victor Soto": [0, ["Improving Code-Switched Language Modeling Performance Using Cognate Features", ["Victor Soto", "Julia Hirschberg"], "https://doi.org/10.21437/Interspeech.2019-2681", 5, "interspeech", 2019]], "David Griol": [0, ["Discovering Dialog Rules by Means of an Evolutionary Approach", ["David Griol", "Zoraida Callejas"], "https://doi.org/10.21437/Interspeech.2019-2230", 5, "interspeech", 2019]], "Joon-Young Yang": [0.9999984800815582, ["Joint Optimization of Neural Acoustic Beamforming and Dereverberation with x-Vectors for Robust Speaker Verification", ["Joon-Young Yang", "Joon-Hyuk Chang"], "https://doi.org/10.21437/Interspeech.2019-1356", 5, "interspeech", 2019]], "Neville Ryant": [0, ["The Second DIHARD Diarization Challenge: Dataset, Task, and Baselines", ["Neville Ryant", "Kenneth Church", "Christopher Cieri", "Alejandrina Cristia", "Jun Du", "Sriram Ganapathy", "Mark Liberman"], "https://doi.org/10.21437/Interspeech.2019-1268", 5, "interspeech", 2019]], "Nanxin Chen": [0, ["Tied Mixture of Factor Analyzers Layer to Combine Frame Level Representations in Neural Speaker Embeddings", ["Nanxin Chen", "Jesus Villalba", "Najim Dehak"], "https://doi.org/10.21437/Interspeech.2019-1782", 5, "interspeech", 2019]], "Florian Schiel": [0, ["BAS Web Services for Automatic Subtitle Creation and Anonymization", ["Florian Schiel", "Thomas Kisler"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8001.html", 2, "interspeech", 2019]], "Mohamed Eldesouki": [0, ["FarSpeech: Arabic Natural Language Processing for Live Arabic Speech", ["Mohamed Eldesouki", "Naassih Gopee", "Ahmed Ali", "Kareem Darwish"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8030.html", 2, "interspeech", 2019]], "Mohit Goyal": [0, ["Detection of Glottal Closure Instants from Raw Speech Using Convolutional Neural Networks", ["Mohit Goyal", "Varun Srivastava", "Prathosh A. P."], "https://doi.org/10.21437/Interspeech.2019-2587", 5, "interspeech", 2019]], "Ming Li": [0, ["Survey Talk: End-to-End Deep Neural Network Based Speaker and Language Recognition", ["Ming Li", "Weicheng Cai", "Danwei Cai"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/abs10.html", 0, "interspeech", 2019]], "Christoph Luscher": [0, ["RWTH ASR Systems for LibriSpeech: Hybrid vs Attention", ["Christoph Luscher", "Eugen Beck", "Kazuki Irie", "Markus Kitza", "Wilfried Michel", "Albert Zeyer", "Ralf Schluter", "Hermann Ney"], "https://doi.org/10.21437/Interspeech.2019-1780", 5, "interspeech", 2019]], "Tomasz Rutowski": [0, ["Optimizing Speech-Input Length for Speaker-Independent Depression Classification", ["Tomasz Rutowski", "Amir Harati", "Yang Lu", "Elizabeth Shriberg"], "https://doi.org/10.21437/Interspeech.2019-3095", 5, "interspeech", 2019]], "Shachi Paul": [0, ["Towards Universal Dialogue Act Tagging for Task-Oriented Dialogues", ["Shachi Paul", "Rahul Goel", "Dilek Hakkani-Tur"], "https://doi.org/10.21437/Interspeech.2019-1866", 5, "interspeech", 2019]], "Zhenyu Tang": [0, ["Regression and Classification for Direction-of-Arrival Estimation with Convolutional Recurrent Neural Networks", ["Zhenyu Tang", "John D. Kanu", "Kevin Hogan", "Dinesh Manocha"], "https://doi.org/10.21437/Interspeech.2019-1111", 5, "interspeech", 2019]], "Kowovi Comivi Alowonou": [0, ["Acoustic and Articulatory Study of Ewe Vowels: A Comparative Study of Male and Female", ["Kowovi Comivi Alowonou", "Jianguo Wei", "Wenhuan Lu", "Zhicheng Liu", "Kiyoshi Honda", "Jianwu Dang"], "https://doi.org/10.21437/Interspeech.2019-2196", 5, "interspeech", 2019]], "Shota Horiguchi": [0, ["Multimodal Response Obligation Detection with Unsupervised Online Domain Adaptation", ["Shota Horiguchi", "Naoyuki Kanda", "Kenji Nagamatsu"], "https://doi.org/10.21437/Interspeech.2019-1313", 5, "interspeech", 2019]], "Kathryn P. Connaghan": [0, ["Use of Beiwe Smartphone App to Identify and Track Speech Decline in Amyotrophic Lateral Sclerosis (ALS)", ["Kathryn P. Connaghan", "Jordan R. Green", "Sabrina Paganoni", "James Chan", "Harli Weber", "Ella Collins", "Brian Richburg", "Marziye Eshghi", "Jukka-Pekka Onnela", "James D. Berry"], "https://doi.org/10.21437/Interspeech.2019-3126", 5, "interspeech", 2019]], "Mohan Li": [0, ["Framewise Supervised Training Towards End-to-End Speech Recognition Models: First Results", ["Mohan Li", "Yuanjiang Cao", "Weicong Zhou", "Min Liu"], "https://doi.org/10.21437/Interspeech.2019-1117", 5, "interspeech", 2019]], "Scott Lewis": [0, ["An Articulatory-Acoustic Investigation into GOOSE-Fronting in German-English Bilinguals Residing in London, UK", ["Scott Lewis", "Adib Mehrabi", "Esther de Leeuw"], "https://doi.org/10.21437/Interspeech.2019-2637", 5, "interspeech", 2019]], "Petra Wagner": [0, ["Pitch Accent Trajectories Across Different Conditions of Visibility and Information Structure - Evidence from Spontaneous Dyadic Interaction", ["Petra Wagner", "Nataliya Bryhadyr", "Marin Schroer"], "https://doi.org/10.21437/Interspeech.2019-1619", 5, "interspeech", 2019]], "Manuel Pariente": [0, ["A Statistically Principled and Computationally Efficient Approach to Speech Enhancement Using Variational Autoencoders", ["Manuel Pariente", "Antoine Deleforge", "Emmanuel Vincent"], "https://doi.org/10.21437/Interspeech.2019-1398", 5, "interspeech", 2019]], "Joon Son Chung": [0.7989451438188553, ["Who Said That?: Audio-Visual Speaker Diarisation of Real-World Meetings", ["Joon Son Chung", "Bong-Jin Lee", "Icksang Han"], "https://doi.org/10.21437/Interspeech.2019-3116", 5, "interspeech", 2019]], "Valerie Hazan": [0, ["Subjective Evaluation of Communicative Effort for Younger and Older Adults in Interactive Tasks with Energetic and Informational Masking", ["Valerie Hazan", "Outi Tuomainen", "Linda Taschenberger"], "https://doi.org/10.21437/Interspeech.2019-2215", 5, "interspeech", 2019]], "Pravin Bhaskar Ramteke": [0, ["NITK Kids' Speech Corpus", ["Pravin Bhaskar Ramteke", "Sujata Supanekar", "Pradyoth Hegde", "Hanna Nelson", "Venkataraja Aithal", "Shashidhar G. Koolagudi"], "https://doi.org/10.21437/Interspeech.2019-2061", 5, "interspeech", 2019]], "Ching Hua Lee": [9.075021983884213e-11, ["On Mitigating Acoustic Feedback in Hearing Aids with Frequency Warping by All-Pass Networks", ["Ching Hua Lee", "Kuan-Lin Chen", "Fredric J. Harris", "Bhaskar D. Rao", "Harinath Garudadri"], "https://doi.org/10.21437/Interspeech.2019-3195", 5, "interspeech", 2019]], "Sofoklis Kakouros": [0, ["Prosodic Representations of Prominence Classification Neural Networks and Autoencoders Using Bottleneck Features", ["Sofoklis Kakouros", "Antti Suni", "Juraj Simko", "Martti Vainio"], "https://doi.org/10.21437/Interspeech.2019-2984", 5, "interspeech", 2019]], "Shan Luo": [0, ["Phonetic Detail Encoding in Explaining the Size of Speech Planning Window", ["Shan Luo"], "https://doi.org/10.21437/Interspeech.2019-1412", 5, "interspeech", 2019]], "Kong Aik Lee": [2.7774383966061578e-06, ["I4U Submission to NIST SRE 2018: Leveraging from a Decade of Shared Experiences", ["Kong Aik Lee", "Ville Hautamaki", "Tomi H. Kinnunen", "Hitoshi Yamamoto", "Koji Okabe", "Ville Vestman", "Jing Huang", "Guohong Ding", "Hanwu Sun", "Anthony Larcher", "Rohan Kumar Das", "Haizhou Li", "Mickael Rouvier", "Pierre-Michel Bousquet", "Wei Rao", "Qing Wang", "Chunlei Zhang", "Fahimeh Bahmaninezhad", "Hector Delgado", "Massimiliano Todisco"], "https://doi.org/10.21437/Interspeech.2019-1533", 5, "interspeech", 2019], ["The NEC-TT 2018 Speaker Verification System", ["Kong Aik Lee", "Hitoshi Yamamoto", "Koji Okabe", "Qiongqiong Wang", "Ling Guo", "Takafumi Koshinaka", "Jiacen Zhang", "Koichi Shinoda"], "https://doi.org/10.21437/Interspeech.2019-1517", 5, "interspeech", 2019]], "Vasiliy Radostev": [0, ["Speech-Based Web Navigation for Limited Mobility Users", ["Vasiliy Radostev", "Serge Berger", "Justin Tabrizi", "Pasha Kamyshev", "Hisami Suzuki"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8042.html", 2, "interspeech", 2019]], "Barbara Schuppler": [0, ["Prosodic Effects on Plosive Duration in German and Austrian German", ["Barbara Schuppler", "Margaret Zellers"], "https://doi.org/10.21437/Interspeech.2019-2197", 5, "interspeech", 2019]], "Xinyu Li": [0, ["Speech Audio Super-Resolution for Speech Recognition", ["Xinyu Li", "Venkata Chebiyyam", "Katrin Kirchhoff"], "https://doi.org/10.21437/Interspeech.2019-3043", 5, "interspeech", 2019], ["Multi-Stream Network with Temporal Attention for Environmental Sound Classification", ["Xinyu Li", "Venkata Chebiyyam", "Katrin Kirchhoff"], "https://doi.org/10.21437/Interspeech.2019-3019", 5, "interspeech", 2019]], "Abdolreza Sabzi Shahrebabaki": [0, ["A Phonetic-Level Analysis of Different Input Features for Articulatory Inversion", ["Abdolreza Sabzi Shahrebabaki", "Negar Olfati", "Ali Shariq Imran", "Sabato Marco Siniscalchi", "Torbjorn Svendsen"], "https://doi.org/10.21437/Interspeech.2019-2526", 5, "interspeech", 2019]], "Ming-Hsiang Su": [0, ["Follow-Up Question Generation Using Neural Tensor Network-Based Domain Ontology Population in an Interview Coaching System", ["Ming-Hsiang Su", "Chung-Hsien Wu", "Yi Chang"], "https://doi.org/10.21437/Interspeech.2019-1300", 5, "interspeech", 2019]], "Nao Hodoshima": [0, ["Effects of Urgent Speech and Congruent/Incongruent Text on Speech Intelligibility in Noise and Reverberation", ["Nao Hodoshima"], "https://doi.org/10.21437/Interspeech.2019-1902", 5, "interspeech", 2019]], "Anastassia Loukina": [0, ["Automated Estimation of Oral Reading Fluency During Summer Camp e-Book Reading with MyTurnToRead", ["Anastassia Loukina", "Beata Beigman Klebanov", "Patrick L. Lange", "Yao Qian", "Binod Gyawali", "Nitin Madnani", "Abhinav Misra", "Klaus Zechner", "Zuowei Wang", "John Sabatini"], "https://doi.org/10.21437/Interspeech.2019-2889", 5, "interspeech", 2019]], "Xiaoke Qi": [0, ["Parameter-Transfer Learning for Low-Resource Individualization of Head-Related Transfer Functions", ["Xiaoke Qi", "Lu Wang"], "https://doi.org/10.21437/Interspeech.2019-2558", 5, "interspeech", 2019]], "Francesc Lluis": [0, ["End-to-End Music Source Separation: Is it Possible in the Waveform Domain?", ["Francesc Lluis", "Jordi Pons", "Xavier Serra"], "https://doi.org/10.21437/Interspeech.2019-1177", 5, "interspeech", 2019]], "Anouschka Foltz": [0, ["Using Prosody to Discover Word Order Alternations in a Novel Language", ["Anouschka Foltz", "Sarah Cooper", "Tamsin M. McKelvey"], "https://doi.org/10.21437/Interspeech.2019-1183", 5, "interspeech", 2019]], "Ville Vestman": [0, ["Unleashing the Unused Potential of i-Vectors Enabled by GPU Acceleration", ["Ville Vestman", "Kong Aik Lee", "Tomi H. Kinnunen", "Takafumi Koshinaka"], "https://doi.org/10.21437/Interspeech.2019-1955", 5, "interspeech", 2019]], "Takanori Ashihara": [0, ["Neural Whispered Speech Detection with Imbalanced Learning", ["Takanori Ashihara", "Yusuke Shinohara", "Hiroshi Sato", "Takafumi Moriya", "Kiyoaki Matsui", "Takaaki Fukutomi", "Yoshikazu Yamaguchi", "Yushi Aono"], "https://doi.org/10.21437/Interspeech.2019-2161", 5, "interspeech", 2019]], "Ryota Kaminishi": [0, ["Investigation on Blind Bandwidth Extension with a Non-Linear Function and its Evaluation of x-Vector-Based Speaker Verification", ["Ryota Kaminishi", "Haruna Miyamoto", "Sayaka Shiota", "Hitoshi Kiya"], "https://doi.org/10.21437/Interspeech.2019-1510", 5, "interspeech", 2019]], "Xiaofei Wang": [3.716871946231055e-15, ["Exploring Methods for the Automatic Detection of Errors in Manual Transcription", ["Xiaofei Wang", "Jinyi Yang", "Ruizhi Li", "Samik Sadhu", "Hynek Hermansky"], "https://doi.org/10.21437/Interspeech.2019-1343", 5, "interspeech", 2019]], "Marcely Zanon Boito": [0, ["Empirical Evaluation of Sequence-to-Sequence Models for Word Discovery in Low-Resource Settings", ["Marcely Zanon Boito", "Aline Villavicencio", "Laurent Besacier"], "https://doi.org/10.21437/Interspeech.2019-2029", 5, "interspeech", 2019]], "Carlos Mendes": [0, ["Recognition of Latin American Spanish Using Multi-Task Learning", ["Carlos Mendes", "Alberto Abad", "Joao Paulo Neto", "Isabel Trancoso"], "https://doi.org/10.21437/Interspeech.2019-2772", 5, "interspeech", 2019]], "Adam Chylek": [0, ["Multimodal Dialog with the MALACH Audiovisual Archive", ["Adam Chylek", "Lubos Smidl", "Jan Svec"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8011.html", 2, "interspeech", 2019]], "Omid Ghahabi": [0, ["Speaker-Corrupted Embeddings for Online Speaker Diarization", ["Omid Ghahabi", "Volker Fischer"], "https://doi.org/10.21437/Interspeech.2019-2756", 5, "interspeech", 2019]], "Tomoki Koriyama": [0, ["Semi-Supervised Prosody Modeling Using Deep Gaussian Process Latent Variable Model", ["Tomoki Koriyama", "Takao Kobayashi"], "https://doi.org/10.21437/Interspeech.2019-2497", 5, "interspeech", 2019]], "Meng Ge": [0, ["Environment-Dependent Attention-Driven Recurrent Convolutional Neural Network for Robust Speech Enhancement", ["Meng Ge", "Longbiao Wang", "Nan Li", "Hao Shi", "Jianwu Dang", "Xiangang Li"], "https://doi.org/10.21437/Interspeech.2019-1477", 5, "interspeech", 2019]], "Santiago Pascual": [0, ["Learning Problem-Agnostic Speech Representations from Multiple Self-Supervised Tasks", ["Santiago Pascual", "Mirco Ravanelli", "Joan Serra", "Antonio Bonafonte", "Yoshua Bengio"], "https://doi.org/10.21437/Interspeech.2019-2605", 5, "interspeech", 2019], ["Towards Generalized Speech Enhancement with Generative Adversarial Networks", ["Santiago Pascual", "Joan Serra", "Antonio Bonafonte"], "https://doi.org/10.21437/Interspeech.2019-2688", 5, "interspeech", 2019]], "Michal Zapotoczny": [0, ["Lattice Generation in Attention-Based Speech Recognition Models", ["Michal Zapotoczny", "Piotr Pietrzak", "Adrian Lancucki", "Jan Chorowski"], "https://doi.org/10.21437/Interspeech.2019-2667", 5, "interspeech", 2019]], "Luciana Ferrer": [0, ["Optimizing a Speaker Embedding Extractor Through Backend-Driven Regularization", ["Luciana Ferrer", "Mitchell McLaren"], "https://doi.org/10.21437/Interspeech.2019-1820", 5, "interspeech", 2019]], "Chris Davis": [0, ["Perceiving Older Adults Producing Clear and Lombard Speech", ["Chris Davis", "Jeesun Kim"], "https://doi.org/10.21437/Interspeech.2019-2210", 5, "interspeech", 2019]], "S. Pavankumar Dubagunta": [0, ["Using Speech Production Knowledge for Raw Waveform Modelling Based Styrian Dialect Identification", ["S. Pavankumar Dubagunta", "Mathew Magimai-Doss"], "https://doi.org/10.21437/Interspeech.2019-2398", 5, "interspeech", 2019]], "Morteza Rohanian": [0, ["Detecting Depression with Word-Level Multimodal Fusion", ["Morteza Rohanian", "Julian Hough", "Matthew Purver"], "https://doi.org/10.21437/Interspeech.2019-2283", 5, "interspeech", 2019]], "Wei Xia": [0, ["Sound Event Detection in Multichannel Audio Using Convolutional Time-Frequency-Channel Squeeze and Excitation", ["Wei Xia", "Kazuhito Koishida"], "https://doi.org/10.21437/Interspeech.2019-1860", 5, "interspeech", 2019]], "Itshak Lapidot": [0, ["Effects of Waveform PMF on Anti-Spoofing Detection", ["Itshak Lapidot", "Jean-Francois Bonastre"], "https://doi.org/10.21437/Interspeech.2019-2607", 5, "interspeech", 2019]], "Julien Meyer": [0, ["A Perceptual Study of CV Syllables in Both Spoken and Whistled Speech: A Tashlhiyt Berber Perspective", ["Julien Meyer", "Laure Dentel", "Silvain Gerber", "Rachid Ridouane"], "https://doi.org/10.21437/Interspeech.2019-2251", 5, "interspeech", 2019]], "Tokihiko Kaburagi": [0, ["A Study of Soprano Singing in Light of the Source-Filter Interaction", ["Tokihiko Kaburagi"], "https://doi.org/10.21437/Interspeech.2019-1153", 5, "interspeech", 2019]], "Emma ONeill": [0, ["The Effect of Phoneme Distribution on Perceptual Similarity in English", ["Emma ONeill", "Julie Carson-Berndsen"], "https://doi.org/10.21437/Interspeech.2019-3042", 5, "interspeech", 2019]], "Meysam Shamsi": [0, ["Corpus Design Using Convolutional Auto-Encoder Embeddings for Audio-Book Synthesis", ["Meysam Shamsi", "Damien Lolive", "Nelly Barbot", "Jonathan Chevelu"], "https://doi.org/10.21437/Interspeech.2019-2190", 5, "interspeech", 2019]], "Yu-An Chung": [0.18233120441436768, ["An Unsupervised Autoregressive Model for Speech Representation Learning", ["Yu-An Chung", "Wei-Ning Hsu", "Hao Tang", "James R. Glass"], "https://doi.org/10.21437/Interspeech.2019-1473", 5, "interspeech", 2019]], "Su-Youn Yoon": [0.9995113462209702, ["Development of Robust Automated Scoring Models Using Adversarial Input for Oral Proficiency Assessment", ["Su-Youn Yoon", "Chong Min Lee", "Klaus Zechner", "Keelan Evanini"], "https://doi.org/10.21437/Interspeech.2019-1711", 5, "interspeech", 2019]], "Yosi Shrem": [0, ["Dr.VOT: Measuring Positive and Negative Voice Onset Time in the Wild", ["Yosi Shrem", "Matthew Goldrick", "Joseph Keshet"], "https://doi.org/10.21437/Interspeech.2019-1735", 5, "interspeech", 2019]], "Amin Edraki": [0, ["Improvement and Assessment of Spectro-Temporal Modulation Analysis for Speech Intelligibility Estimation", ["Amin Edraki", "Wai-Yip Chan", "Jesper Jensen", "Daniel Fogerty"], "https://doi.org/10.21437/Interspeech.2019-2898", 5, "interspeech", 2019]], "Shiliang Zhang": [0, ["Towards Language-Universal Mandarin-English Speech Recognition", ["Shiliang Zhang", "Yuan Liu", "Ming Lei", "Bin Ma", "Lei Xie"], "https://doi.org/10.21437/Interspeech.2019-1365", 5, "interspeech", 2019], ["Investigation of Transformer Based Spelling Correction Model for CTC-Based End-to-End Mandarin Speech Recognition", ["Shiliang Zhang", "Ming Lei", "Zhijie Yan"], "https://doi.org/10.21437/Interspeech.2019-1290", 5, "interspeech", 2019]], "Seung Hee Yang": [0.9917360246181488, ["Self-Imitating Feedback Generation Using GAN for Computer-Assisted Pronunciation Training", ["Seung Hee Yang", "Minhwa Chung"], "https://doi.org/10.21437/Interspeech.2019-1478", 5, "interspeech", 2019]], "Gabriel Mittag": [0, ["Quality Degradation Diagnosis for Voice Networks - Estimating the Perceived Noisiness, Coloration, and Discontinuity of Transmitted Speech", ["Gabriel Mittag", "Sebastian Moller"], "https://doi.org/10.21437/Interspeech.2019-2636", 5, "interspeech", 2019]], "Yosuke Higuchi": [0, ["Speaker Adversarial Training of DPGMM-Based Feature Extractor for Zero-Resource Languages", ["Yosuke Higuchi", "Naohiro Tawara", "Tetsunori Kobayashi", "Tetsuji Ogawa"], "https://doi.org/10.21437/Interspeech.2019-2052", 5, "interspeech", 2019]], "Haisong Ding": [0, ["Compression of CTC-Trained Acoustic Models by Dynamic Frame-Wise Distillation or Segment-Wise N-Best Hypotheses Imitation", ["Haisong Ding", "Kai Chen", "Qiang Huo"], "https://doi.org/10.21437/Interspeech.2019-2182", 5, "interspeech", 2019]], "Ioannis K. Douros": [0, ["Towards a Method of Dynamic Vocal Tract Shapes Generation by Combining Static 3D and Dynamic 2D MRI Speech Data", ["Ioannis K. Douros", "Anastasiia Tsukanova", "Karyna Isaieva", "Pierre-Andre Vuissoz", "Yves Laprie"], "https://doi.org/10.21437/Interspeech.2019-2880", 5, "interspeech", 2019], ["A Multimodal Real-Time MRI Articulatory Corpus of French for Speech Research", ["Ioannis K. Douros", "Jacques Felblinger", "Jens Frahm", "Karyna Isaieva", "Arun A. Joseph", "Yves Laprie", "Freddy Odille", "Anastasiia Tsukanova", "Dirk Voit", "Pierre-Andre Vuissoz"], "https://doi.org/10.21437/Interspeech.2019-1700", 5, "interspeech", 2019]], "Andre Merboldt": [0, ["An Analysis of Local Monotonic Attention Variants", ["Andre Merboldt", "Albert Zeyer", "Ralf Schluter", "Hermann Ney"], "https://doi.org/10.21437/Interspeech.2019-2879", 5, "interspeech", 2019]], "Chih-Hsiang Huang": [0, ["Acoustic Indicators of Deception in Mandarin Daily Conversations Recorded from an Interactive Game", ["Chih-Hsiang Huang", "Huang-Cheng Chou", "Yi-Tong Wu", "Chi-Chun Lee", "Yi-Wen Liu"], "https://doi.org/10.21437/Interspeech.2019-2216", 5, "interspeech", 2019]], "Yuka Kobayashi": [0, ["Slot Filling with Weighted Multi-Encoders for Out-of-Domain Values", ["Yuka Kobayashi", "Takami Yoshida", "Kenji Iwata", "Hiroshi Fujimura"], "https://doi.org/10.21437/Interspeech.2019-1226", 5, "interspeech", 2019]], "Alice Baird": [0, ["Using Speech to Predict Sequentially Measured Cortisol Levels During a Trier Social Stress Test", ["Alice Baird", "Shahin Amiriparian", "Nicholas Cummins", "Sarah Sturmbauer", "Johanna Janson", "Eva-Maria Messner", "Harald Baumeister", "Nicolas Rohleder", "Bjorn W. Schuller"], "https://doi.org/10.21437/Interspeech.2019-1352", 5, "interspeech", 2019], ["Sincerity in Acted Speech: Presenting the Sincere Apology Corpus and Results", ["Alice Baird", "Eduardo Coutinho", "Julia Hirschberg", "Bjorn W. Schuller"], "https://doi.org/10.21437/Interspeech.2019-1349", 5, "interspeech", 2019]], "Oriol Guasch": [0, ["Survey Talk: Realistic Physics-Based Computational Voice Production", ["Oriol Guasch"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/abs24.html", 0, "interspeech", 2019]], "Yu-Yin Hsu": [0, ["Sentence Prosody and Wh-Indeterminates in Taiwan Mandarin", ["Yu-Yin Hsu", "Anqi Xu"], "https://doi.org/10.21437/Interspeech.2019-2545", 5, "interspeech", 2019]], "Krishna Somandepalli": [0, ["Multiview Shared Subspace Learning Across Speakers and Speech Commands", ["Krishna Somandepalli", "Naveen Kumar", "Arindam Jati", "Panayiotis G. Georgiou", "Shrikanth Narayanan"], "https://doi.org/10.21437/Interspeech.2019-3130", 5, "interspeech", 2019]], "Tobias Menne": [0, ["Analysis of Deep Clustering as Preprocessing for Automatic Speech Recognition of Sparsely Overlapping Speech", ["Tobias Menne", "Ilya Sklyar", "Ralf Schluter", "Hermann Ney"], "https://doi.org/10.21437/Interspeech.2019-1728", 5, "interspeech", 2019]], "Feng Ma": [0, ["Acoustic Model Ensembling Using Effective Data Augmentation for CHiME-5 Challenge", ["Feng Ma", "Li Chai", "Jun Du", "Diyuan Liu", "Zhongfu Ye", "Chin-Hui Lee"], "https://doi.org/10.21437/Interspeech.2019-2601", 5, "interspeech", 2019]], "Rohan Kumar Das": [0, ["Long Range Acoustic Features for Spoofed Speech Detection", ["Rohan Kumar Das", "Jichen Yang", "Haizhou Li"], "https://doi.org/10.21437/Interspeech.2019-1887", 5, "interspeech", 2019], ["Instantaneous Phase and Long-Term Acoustic Cues for Orca Activity Detection", ["Rohan Kumar Das", "Haizhou Li"], "https://doi.org/10.21437/Interspeech.2019-1894", 5, "interspeech", 2019]], "Nisad Jamakovic": [0, ["The Monophthongs of Formal Nigerian English: An Acoustic Analysis", ["Nisad Jamakovic", "Robert Fuchs"], "https://doi.org/10.21437/Interspeech.2019-2866", 5, "interspeech", 2019]], "Carol Chermaz": [0, ["Evaluating Near End Listening Enhancement Algorithms in Realistic Environments", ["Carol Chermaz", "Cassia Valentini-Botinhao", "Henning F. Schepker", "Simon King"], "https://doi.org/10.21437/Interspeech.2019-1800", 5, "interspeech", 2019]], "Kai Zhen": [0, ["Cascaded Cross-Module Residual Learning Towards Lightweight End-to-End Speech Coding", ["Kai Zhen", "Jongmo Sung", "Mi Suk Lee", "Seungkwon Beack", "Minje Kim"], "https://doi.org/10.21437/Interspeech.2019-1816", 5, "interspeech", 2019]], "Abdelwahab Heba": [0, ["Char+CV-CTC: Combining Graphemes and Consonant/Vowel Units for CTC-Based ASR Using Multitask Learning", ["Abdelwahab Heba", "Thomas Pellegrini", "Jean-Pierre Lorre", "Regine Andre-Obrecht"], "https://doi.org/10.21437/Interspeech.2019-1975", 5, "interspeech", 2019]], "Chaitanya Narisetty": [0, ["A Unified Bayesian Source Modelling for Determined Blind Source Separation", ["Chaitanya Narisetty"], "https://doi.org/10.21437/Interspeech.2019-1272", 5, "interspeech", 2019]], "Ievgen Karaulov": [0, ["Attention Model for Articulatory Features Detection", ["Ievgen Karaulov", "Dmytro Tkanov"], "https://doi.org/10.21437/Interspeech.2019-3020", 5, "interspeech", 2019]], "Purvi Agrawal": [0, ["Unsupervised Raw Waveform Representation Learning for ASR", ["Purvi Agrawal", "Sriram Ganapathy"], "https://doi.org/10.21437/Interspeech.2019-2652", 5, "interspeech", 2019]], "Xinzhou Xu": [0, ["Autonomous Emotion Learning in Speech: A View of Zero-Shot Speech Emotion Recognition", ["Xinzhou Xu", "Jun Deng", "Nicholas Cummins", "Zixing Zhang", "Li Zhao", "Bjorn W. Schuller"], "https://doi.org/10.21437/Interspeech.2019-2406", 5, "interspeech", 2019]], "Anastasios Vafeiadis": [0, ["Two-Dimensional Convolutional Recurrent Neural Networks for Speech Activity Detection", ["Anastasios Vafeiadis", "Eleftherios Fanioudakis", "Ilyas Potamitis", "Konstantinos Votis", "Dimitrios Giakoumis", "Dimitrios Tzovaras", "Liming Chen", "Raouf Hamzaoui"], "https://doi.org/10.21437/Interspeech.2019-1354", 5, "interspeech", 2019]], "Jing Shi": [0, ["Which Ones Are Speaking? Speaker-Inferred Model for Multi-Talker Speech Separation", ["Jing Shi", "Jiaming Xu", "Bo Xu"], "https://doi.org/10.21437/Interspeech.2019-1591", 5, "interspeech", 2019]], "Aciel Eshky": [0, ["Synchronising Audio and Ultrasound by Learning Cross-Modal Embeddings", ["Aciel Eshky", "Manuel Sam Ribeiro", "Korin Richmond", "Steve Renals"], "https://doi.org/10.21437/Interspeech.2019-1804", 5, "interspeech", 2019]], "Laureano Moro-Velazquez": [0, ["Study of the Performance of Automatic Speech Recognition Systems in Speakers with Parkinson's Disease", ["Laureano Moro-Velazquez", "Jaejin Cho", "Shinji Watanabe", "Mark A. Hasegawa-Johnson", "Odette Scharenborg", "Heejin Kim", "Najim Dehak"], "https://doi.org/10.21437/Interspeech.2019-2993", 5, "interspeech", 2019]], "Tsubasa Ochiai": [0, ["Multimodal SpeakerBeam: Single Channel Target Speech Extraction with Audio-Visual Speaker Clues", ["Tsubasa Ochiai", "Marc Delcroix", "Keisuke Kinoshita", "Atsunori Ogawa", "Tomohiro Nakatani"], "https://doi.org/10.21437/Interspeech.2019-1513", 5, "interspeech", 2019]], "Zhenghao Jin": [1.939148223505799e-12, ["Development of Emotion Rankers Based on Intended and Perceived Emotion Labels", ["Zhenghao Jin", "Houwei Cao"], "https://doi.org/10.21437/Interspeech.2019-1831", 5, "interspeech", 2019]], "Bhusan Chettri": [0, ["Ensemble Models for Spoofing Detection in Automatic Speaker Verification", ["Bhusan Chettri", "Daniel Stoller", "Veronica Morfi", "Marco A. Martinez Ramirez", "Emmanouil Benetos", "Bob L. Sturm"], "https://doi.org/10.21437/Interspeech.2019-2505", 5, "interspeech", 2019]], "Kuan-Yu Chen": [0, ["Completely Unsupervised Phoneme Recognition by a Generative Adversarial Network Harmonized with Iteratively Refined Hidden Markov Models", ["Kuan-Yu Chen", "Che-Ping Tsai", "Da-Rong Liu", "Hung-yi Lee", "Lin-Shan Lee"], "https://doi.org/10.21437/Interspeech.2019-2068", 5, "interspeech", 2019]], "Ahilan Kanagasundaram": [0, ["A Study of x-Vector Based Speaker Recognition on Short Utterances", ["Ahilan Kanagasundaram", "Sridha Sridharan", "Ganapathy Sriram", "S. Prachi", "Clinton Fookes"], "https://doi.org/10.21437/Interspeech.2019-1891", 5, "interspeech", 2019]], "Takafumi Moriya": [0, ["Joint Maximization Decoder with Neural Converters for Fully Neural Network-Based Japanese Speech Recognition", ["Takafumi Moriya", "Jian Wang", "Tomohiro Tanaka", "Ryo Masumura", "Yusuke Shinohara", "Yoshikazu Yamaguchi", "Yushi Aono"], "https://doi.org/10.21437/Interspeech.2019-1558", 5, "interspeech", 2019]], "Peidong Wang": [8.108182191790547e-05, ["Large Margin Training for Attention Based End-to-End Speech Recognition", ["Peidong Wang", "Jia Cui", "Chao Weng", "Dong Yu"], "https://doi.org/10.21437/Interspeech.2019-1680", 5, "interspeech", 2019], ["Bridging the Gap Between Monaural Speech Enhancement and Recognition with Distortion-Independent Acoustic Modeling", ["Peidong Wang", "Ke Tan", "DeLiang Wang"], "https://doi.org/10.21437/Interspeech.2019-1495", 5, "interspeech", 2019], ["Enhanced Spectral Features for Distortion-Independent Acoustic Modeling", ["Peidong Wang", "DeLiang Wang"], "https://doi.org/10.21437/Interspeech.2019-1493", 5, "interspeech", 2019]], "Carol Y. Espy-Wilson": [0, ["Assessing Neuromotor Coordination in Depression Using Inverted Vocal Tract Variables", ["Carol Y. Espy-Wilson", "Adam C. Lammert", "Nadee Seneviratne", "Thomas F. Quatieri"], "https://doi.org/10.21437/Interspeech.2019-1815", 5, "interspeech", 2019]], "Doug Beeferman": [0, ["RadioTalk: A Large-Scale Corpus of Talk Radio Transcripts", ["Doug Beeferman", "William Brannon", "Deb Roy"], "https://doi.org/10.21437/Interspeech.2019-2714", 5, "interspeech", 2019]], "Shawn L. Nissen": [0, ["Listeners' Ability to Identify the Gender of Preadolescent Children in Different Linguistic Contexts", ["Shawn L. Nissen", "Sharalee Blunck", "Anita Dromey", "Christopher Dromey"], "https://doi.org/10.21437/Interspeech.2019-1865", 5, "interspeech", 2019], ["Using Real-Time Visual Biofeedback for Second Language Instruction", ["Shawn L. Nissen", "Rebecca Nissen"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8016.html", 2, "interspeech", 2019]], "Tanja Schultz": [0, ["Biosignal Processing for Human-Machine Interaction", ["Tanja Schultz"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/abs6.html", 0, "interspeech", 2019]], "Salima Mdhaffar": [0, ["Qualitative Evaluation of ASR Adaptation in a Lecture Context: Application to the PASTEL Corpus", ["Salima Mdhaffar", "Yannick Esteve", "Nicolas Hernandez", "Antoine Laurent", "Richard Dufour", "Solen Quiniou"], "https://doi.org/10.21437/Interspeech.2019-2661", 5, "interspeech", 2019]], "Lorenzo Tarantino": [0, ["Self-Attention for Speech Emotion Recognition", ["Lorenzo Tarantino", "Philip N. Garner", "Alexandros Lazaridis"], "https://doi.org/10.21437/Interspeech.2019-2822", 5, "interspeech", 2019]], "Carolina De Pasquale": [0, ["An Investigation of Therapeutic Rapport Through Prosody in Brief Psychodynamic Psychotherapy", ["Carolina De Pasquale", "Charlie Cullen", "Brian Vaughan"], "https://doi.org/10.21437/Interspeech.2019-2551", 5, "interspeech", 2019]], "Lucas Kessler": [0, ["Synthesized Spoken Names: Biases Impacting Perception", ["Lucas Kessler", "Cecilia Ovesdotter Alm", "Reynold Bailey"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8031.html", 2, "interspeech", 2019]], "Zhengkun Tian": [0, ["Self-Attention Transducers for End-to-End Speech Recognition", ["Zhengkun Tian", "Jiangyan Yi", "Jianhua Tao", "Ye Bai", "Zhengqi Wen"], "https://doi.org/10.21437/Interspeech.2019-2203", 5, "interspeech", 2019]], "Zhuohuang Zhang": [0, ["Listener Preference on the Local Criterion for Ideal Binary-Masked Speech", ["Zhuohuang Zhang", "Yi Shen"], "https://doi.org/10.21437/Interspeech.2019-1369", 5, "interspeech", 2019]], "Wilfried Michel": [0, ["Comparison of Lattice-Free and Lattice-Based Sequence Discriminative Training Criteria for LVCSR", ["Wilfried Michel", "Ralf Schluter", "Hermann Ney"], "https://doi.org/10.21437/Interspeech.2019-2254", 5, "interspeech", 2019]], "Haohan Guo": [0, ["A New GAN-Based End-to-End TTS Training Algorithm", ["Haohan Guo", "Frank K. Soong", "Lei He", "Lei Xie"], "https://doi.org/10.21437/Interspeech.2019-2176", 5, "interspeech", 2019], ["Exploiting Syntactic Features in a Parsed Tree to Improve End-to-End TTS", ["Haohan Guo", "Frank K. Soong", "Lei He", "Lei Xie"], "https://doi.org/10.21437/Interspeech.2019-2167", 5, "interspeech", 2019]], "Wen-Chin Huang": [0, ["Investigation of F0 Conditioning and Fully Convolutional Networks in Variational Autoencoder Based Voice Conversion", ["Wen-Chin Huang", "Yi-Chiao Wu", "Chen-Chou Lo", "Patrick Lumban Tobing", "Tomoki Hayashi", "Kazuhiro Kobayashi", "Tomoki Toda", "Yu Tsao", "Hsin-Min Wang"], "https://doi.org/10.21437/Interspeech.2019-1774", 5, "interspeech", 2019]], "Laetitia Jeancolas": [0, ["Comparison of Telephone Recordings and Professional Microphone Recordings for Early Detection of Parkinson's Disease, Using Mel-Frequency Cepstral Coefficients with Gaussian Mixture Models", ["Laetitia Jeancolas", "Graziella Mangone", "Jean-Christophe Corvol", "Marie Vidailhet", "Stephane Lehericy", "Badr-Eddine Benkelfat", "Habib Benali", "Dijana Petrovska-Delacretaz"], "https://doi.org/10.21437/Interspeech.2019-2825", 5, "interspeech", 2019]], "Sebastian Moller": [0, ["Extending the E-Model Towards Super-Wideband and Fullband Speech Communication Scenarios", ["Sebastian Moller", "Gabriel Mittag", "Thilo Michael", "Vincent Barriac", "Hitoshi Aoki"], "https://doi.org/10.21437/Interspeech.2019-1340", 5, "interspeech", 2019]], "Bhanu Teja Nellore": [0, ["Excitation Source and Vocal Tract System Based Acoustic Features for Detection of Nasals in Continuous Speech", ["Bhanu Teja Nellore", "Sri Harsha Dumpala", "Karan Nathwani", "Suryakanth V. Gangashetty"], "https://doi.org/10.21437/Interspeech.2019-2785", 5, "interspeech", 2019]], "Samuel Thomas": [0, ["Detection and Recovery of OOVs for Improved English Broadcast News Captioning", ["Samuel Thomas", "Kartik Audhkhasi", "Zoltan Tuske", "Yinghui Huang", "Michael Picheny"], "https://doi.org/10.21437/Interspeech.2019-2793", 5, "interspeech", 2019]], "Lauri Juvela": [0, ["GELP: GAN-Excited Linear Prediction for Speech Synthesis from Mel-Spectrogram", ["Lauri Juvela", "Bajibabu Bollepalli", "Junichi Yamagishi", "Paavo Alku"], "https://doi.org/10.21437/Interspeech.2019-2008", 5, "interspeech", 2019]], "Francois Grondin": [0, ["Multiple Sound Source Localization with SVD-PHAT", ["Francois Grondin", "James R. Glass"], "https://doi.org/10.21437/Interspeech.2019-2653", 5, "interspeech", 2019]], "Karthik Gopalakrishnan": [0, ["Topical-Chat: Towards Knowledge-Grounded Open-Domain Conversations", ["Karthik Gopalakrishnan", "Behnam Hedayatnia", "Qinglang Chen", "Anna Gottardi", "Sanjeev Kwatra", "Anu Venkatesh", "Raefer Gabriel", "Dilek Hakkani-Tur"], "https://doi.org/10.21437/Interspeech.2019-3079", 5, "interspeech", 2019]], "Eliya Nachmani": [0, ["Unsupervised Singing Voice Conversion", ["Eliya Nachmani", "Lior Wolf"], "https://doi.org/10.21437/Interspeech.2019-1761", 5, "interspeech", 2019]], "Liumeng Xue": [0, ["Building a Mixed-Lingual Neural TTS System with Only Monolingual Data", ["Liumeng Xue", "Wei Song", "Guanghui Xu", "Lei Xie", "Zhizheng Wu"], "https://doi.org/10.21437/Interspeech.2019-3191", 5, "interspeech", 2019]], "Quan Wang": [0.0009247225534636527, ["VoiceFilter: Targeted Voice Separation by Speaker-Conditioned Spectrogram Masking", ["Quan Wang", "Hannah Muckenhirn", "Kevin W. Wilson", "Prashant Sridhar", "Zelin Wu", "John R. Hershey", "Rif A. Saurous", "Ron J. Weiss", "Ye Jia", "Ignacio Lopez-Moreno"], "https://doi.org/10.21437/Interspeech.2019-1101", 5, "interspeech", 2019]], "W. Bastiaan Kleijn": [0, ["Salient Speech Representations Based on Cloned Networks", ["W. Bastiaan Kleijn", "Felicia S. C. Lim", "Michael Chinen", "Jan Skoglund"], "https://doi.org/10.21437/Interspeech.2019-1861", 5, "interspeech", 2019]], "Ewan Dunbar": [0, ["The Zero Resource Speech Challenge 2019: TTS Without T", ["Ewan Dunbar", "Robin Algayres", "Julien Karadayi", "Mathieu Bernard", "Juan Benjumea", "Xuan-Nga Cao", "Lucie Miskic", "Charlotte Dugrain", "Lucas Ondel", "Alan W. Black", "Laurent Besacier", "Sakriani Sakti", "Emmanuel Dupoux"], "https://doi.org/10.21437/Interspeech.2019-2904", 5, "interspeech", 2019]], "Ravi Shankar": [0, ["Weakly Supervised Syllable Segmentation by Vowel-Consonant Peak Classification", ["Ravi Shankar", "Archana Venkataraman"], "https://doi.org/10.21437/Interspeech.2019-1450", 5, "interspeech", 2019], ["A Multi-Speaker Emotion Morphing Model Using Highway Networks and Maximum Likelihood Objective", ["Ravi Shankar", "Jacob Sager", "Archana Venkataraman"], "https://doi.org/10.21437/Interspeech.2019-2512", 5, "interspeech", 2019], ["Automated Emotion Morphing in Speech Based on Diffeomorphic Curve Registration and Highway Networks", ["Ravi Shankar", "Hsi-Wei Hsieh", "Nicolas Charon", "Archana Venkataraman"], "https://doi.org/10.21437/Interspeech.2019-2386", 5, "interspeech", 2019]], "Stephanie Berger": [0, ["A Preliminary Study of Charismatic Speech on YouTube: Correlating Prosodic Variation with Counts of Subscribers, Views and Likes", ["Stephanie Berger", "Oliver Niebuhr", "Margaret Zellers"], "https://doi.org/10.21437/Interspeech.2019-1664", 5, "interspeech", 2019]], "Jonathan Huang": [0, ["Intel Far-Field Speaker Recognition System for VOiCES Challenge 2019", ["Jonathan Huang", "Tobias Bocklet"], "https://doi.org/10.21437/Interspeech.2019-2894", 5, "interspeech", 2019]], "Balamurali B. T.": [0, ["Analyzing Intra-Speaker and Inter-Speaker Vocal Tract Impedance Characteristics in a Low-Dimensional Feature Space Using t-SNE", ["Balamurali B. T.", "Jer-Ming Chen"], "https://doi.org/10.21437/Interspeech.2019-1492", 4, "interspeech", 2019]], "Gary Yeung": [0, ["A Frequency Normalization Technique for Kindergarten Speech Recognition Inspired by the Role of fo in Vowel Perception", ["Gary Yeung", "Abeer Alwan"], "https://doi.org/10.21437/Interspeech.2019-1847", 5, "interspeech", 2019]], "Andreas Nautsch": [0, ["Survey Talk: Preserving Privacy in Speaker and Speech Characterisation", ["Andreas Nautsch"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/abs11.html", 0, "interspeech", 2019], ["Privacy-Preserving Speaker Recognition with Cohort Score Normalisation", ["Andreas Nautsch", "Jose Patino", "Amos Treiber", "Themos Stafylakis", "Petr Mizera", "Massimiliano Todisco", "Thomas Schneider", "Nicholas W. D. Evans"], "https://doi.org/10.21437/Interspeech.2019-2638", 5, "interspeech", 2019], ["The GDPR & Speech Data: Reflections of Legal and Technology Communities, First Steps Towards a Common Understanding", ["Andreas Nautsch", "Catherine Jasserand", "Els Kindt", "Massimiliano Todisco", "Isabel Trancoso", "Nicholas W. D. Evans"], "https://doi.org/10.21437/Interspeech.2019-2647", 5, "interspeech", 2019]], "Hannah Muckenhirn": [0, ["Understanding and Visualizing Raw Waveform-Based CNNs", ["Hannah Muckenhirn", "Vinayak Abrol", "Mathew Magimai-Doss", "Sebastien Marcel"], "https://doi.org/10.21437/Interspeech.2019-2341", 5, "interspeech", 2019]], "Calbert Graham": [0, ["Articulation Rate as a Metric in Spoken Language Assessment", ["Calbert Graham", "Francis Nolan"], "https://doi.org/10.21437/Interspeech.2019-2098", 5, "interspeech", 2019]], "Atreyee Saha": [0, ["Low Resource Automatic Intonation Classification Using Gated Recurrent Unit (GRU) Networks Pre-Trained with Synthesized Pitch Patterns", ["Atreyee Saha", "Chiranjeevi Yarra", "Prasanta Kumar Ghosh"], "https://doi.org/10.21437/Interspeech.2019-2351", 5, "interspeech", 2019]], "Feng Huang": [0, ["Harmonic-Aligned Frame Mask Based on Non-Stationary Gabor Transform with Application to Content-Dependent Speaker Comparison", ["Feng Huang", "Peter Balazs"], "https://doi.org/10.21437/Interspeech.2019-1327", 5, "interspeech", 2019]], "Lauri Tavi": [0, ["Recognition of Creaky Voice from Emergency Calls", ["Lauri Tavi", "Tanel Alumae", "Stefan Werner"], "https://doi.org/10.21437/Interspeech.2019-1253", 5, "interspeech", 2019]], "Shuiyang Mao": [0, ["Deep Learning of Segment-Level Feature Representation with Multiple Instance Learning for Utterance-Level Speech Emotion Recognition", ["Shuiyang Mao", "P. C. Ching", "Tan Lee"], "https://doi.org/10.21437/Interspeech.2019-1968", 5, "interspeech", 2019]], "Jitendra Kumar Dhiman": [0, ["On the Suitability of the Riesz Spectro-Temporal Envelope for WaveNet Based Speech Synthesis", ["Jitendra Kumar Dhiman", "Nagaraj Adiga", "Chandra Sekhar Seelamantula"], "https://doi.org/10.21437/Interspeech.2019-2626", 5, "interspeech", 2019]], "Hitoshi Yamamoto": [0, ["Speaker Augmentation and Bandwidth Extension for Deep Speaker Embedding", ["Hitoshi Yamamoto", "Kong Aik Lee", "Koji Okabe", "Takafumi Koshinaka"], "https://doi.org/10.21437/Interspeech.2019-1508", 5, "interspeech", 2019]], "Mandy Korpusik": [0, ["A Comparison of Deep Learning Methods for Language Understanding", ["Mandy Korpusik", "Zoe Liu", "James R. Glass"], "https://doi.org/10.21437/Interspeech.2019-1262", 5, "interspeech", 2019]], "Jazmin Vidal": [0, ["EpaDB: A Database for Development of Pronunciation Assessment Systems", ["Jazmin Vidal", "Luciana Ferrer", "Leonardo Brambilla"], "https://doi.org/10.21437/Interspeech.2019-1839", 5, "interspeech", 2019]], "Avashna Govender": [0, ["Using Pupil Dilation to Measure Cognitive Load When Listening to Text-to-Speech in Quiet and in Noise", ["Avashna Govender", "Anita E. Wagner", "Simon King"], "https://doi.org/10.21437/Interspeech.2019-1783", 5, "interspeech", 2019]], "Jean Schoentgen": [0, ["Analysis and Synthesis of Vocal Flutter and Vocal Jitter", ["Jean Schoentgen", "Philipp Aichinger"], "https://doi.org/10.21437/Interspeech.2019-1998", 5, "interspeech", 2019]], "Andrea Carmantini": [0, ["Untranscribed Web Audio for Low Resource Speech Recognition", ["Andrea Carmantini", "Peter Bell", "Steve Renals"], "https://doi.org/10.21437/Interspeech.2019-2623", 5, "interspeech", 2019]], "Yuxiang Zou": [0, ["Boosting Character-Based Chinese Speech Synthesis via Multi-Task Learning and Dictionary Tutoring", ["Yuxiang Zou", "Linhao Dong", "Bo Xu"], "https://doi.org/10.21437/Interspeech.2019-3233", 5, "interspeech", 2019]], "Dina El Zarka": [0, ["Acoustic Cues to Topic and Narrow Focus in Egyptian Arabic", ["Dina El Zarka", "Barbara Schuppler", "Francesco Cangemi"], "https://doi.org/10.21437/Interspeech.2019-1189", 5, "interspeech", 2019]], "Martin Gruber": [0, ["Web-Based Speech Synthesis Editor", ["Martin Gruber", "Jakub Vit", "Jindrich Matousek"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8013.html", 2, "interspeech", 2019], ["Framework for Conducting Tasks Requiring Human Assessment", ["Martin Gruber", "Adam Chylek", "Jindrich Matousek"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8009.html", 2, "interspeech", 2019]], "Shansong Liu": [0, ["Exploiting Visual Features Using Bayesian Gated Neural Networks for Disordered Speech Recognition", ["Shansong Liu", "Shoukang Hu", "Yi Wang", "Jianwei Yu", "Rongfeng Su", "Xunying Liu", "Helen Meng"], "https://doi.org/10.21437/Interspeech.2019-1536", 5, "interspeech", 2019], ["On the Use of Pitch Features for Disordered Speech Recognition", ["Shansong Liu", "Shoukang Hu", "Xunying Liu", "Helen Meng"], "https://doi.org/10.21437/Interspeech.2019-2609", 5, "interspeech", 2019]], "Cheng Yi": [0.0026509094168432057, ["Ectc-Docd: An End-to-End Structure with CTC Encoder and OCD Decoder for Speech Recognition", ["Cheng Yi", "Feng Wang", "Bo Xu"], "https://doi.org/10.21437/Interspeech.2019-1212", 5, "interspeech", 2019]], "Vikramjit Mitra": [0, ["Leveraging Acoustic Cues and Paralinguistic Embeddings to Detect Expression from Voice", ["Vikramjit Mitra", "Sue Booker", "Erik Marchi", "David Scott Farrar", "Ute Dorothea Peitz", "Bridget Cheng", "Ermine Teves", "Anuj Mehta", "Devang Naik"], "https://doi.org/10.21437/Interspeech.2019-2998", 5, "interspeech", 2019]], "Shuju Shi": [0, ["Capturing L1 Influence on L2 Pronunciation by Simulating Perceptual Space Using Acoustic Features", ["Shuju Shi", "Chilin Shih", "Jinsong Zhang"], "https://doi.org/10.21437/Interspeech.2019-3183", 5, "interspeech", 2019]], "Sarfaraz Jelil": [0, ["SpeechMarker: A Voice Based Multi-Level Attendance Application", ["Sarfaraz Jelil", "Abhishek Shrivastava", "Rohan Kumar Das", "S. R. Mahadeva Prasanna", "Rohit Sinha"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8014.html", 2, "interspeech", 2019]], "Helen L. Bear": [0, ["Towards Joint Sound Scene and Polyphonic Sound Event Recognition", ["Helen L. Bear", "Ines Nolasco", "Emmanouil Benetos"], "https://doi.org/10.21437/Interspeech.2019-2169", 5, "interspeech", 2019]], "Su-Yu Chang": [0.24821341037750244, ["Transfer-Representation Learning for Detecting Spoofing Attacks with Converted and Synthesized Speech in Automatic Speaker Verification System", ["Su-Yu Chang", "Kai-Cheng Wu", "Chia-Ping Chen"], "https://doi.org/10.21437/Interspeech.2019-2014", 5, "interspeech", 2019]], "Wenjun Chen": [0, ["Acoustic Characteristics of Lexical Tone Disruption in Mandarin Speakers After Brain Damage", ["Wenjun Chen", "Jeroen van de Weijer", "Shuangshuang Zhu", "Qian Qian", "Manna Wang"], "https://doi.org/10.21437/Interspeech.2019-2432", 5, "interspeech", 2019]], "Olga Egorow": [0, ["Employing Bottleneck and Convolutional Features for Speech-Based Physical Load Detection on Limited Data Amounts", ["Olga Egorow", "Tarik Mrech", "Norman Weisskirchen", "Andreas Wendemuth"], "https://doi.org/10.21437/Interspeech.2019-2502", 5, "interspeech", 2019]], "Jiarui Wang": [9.11693223315524e-05, ["Child Speech Disorder Detection with Siamese Recurrent Network Using Speech Attribute Features", ["Jiarui Wang", "Ying Qin", "Zhiyuan Peng", "Tan Lee"], "https://doi.org/10.21437/Interspeech.2019-2320", 5, "interspeech", 2019]], "Peisong Huang": [0, ["Latent Topic Attention for Domain Classification", ["Peisong Huang", "Peijie Huang", "Wencheng Ai", "Jiande Ding", "Jinchuan Zhang"], "https://doi.org/10.21437/Interspeech.2019-2228", 5, "interspeech", 2019]], "Ngoc-Quan Pham": [0, ["Very Deep Self-Attention Networks for End-to-End Speech Recognition", ["Ngoc-Quan Pham", "Thai-Son Nguyen", "Jan Niehues", "Markus Muller", "Alex Waibel"], "https://doi.org/10.21437/Interspeech.2019-2702", 5, "interspeech", 2019]], "Pejman Mowlaee": [0, ["Maximum a posteriori Speech Enhancement Based on Double Spectrum", ["Pejman Mowlaee", "Daniel Scheran", "Johannes Stahl", "Sean U. N. Wood", "W. Bastiaan Kleijn"], "https://doi.org/10.21437/Interspeech.2019-1197", 5, "interspeech", 2019]], "Michelle Cohn": [0, ["Expressiveness Influences Human Vocal Alignment Toward voice-AI", ["Michelle Cohn", "Georgia Zellou"], "https://doi.org/10.21437/Interspeech.2019-1368", 5, "interspeech", 2019], ["The Role of Musical Experience in the Perceptual Weighting of Acoustic Cues for the Obstruent Coda Voicing Contrast in American English", ["Michelle Cohn", "Georgia Zellou", "Santiago Barreda"], "https://doi.org/10.21437/Interspeech.2019-3103", 5, "interspeech", 2019]], "Zhongkai Sun": [4.6527646847620806e-14, ["Multi-Modal Sentiment Analysis Using Deep Canonical Correlation Analysis", ["Zhongkai Sun", "Prathusha Kameswara Sarma", "William A. Sethares", "Erik P. Bucy"], "https://doi.org/10.21437/Interspeech.2019-2482", 5, "interspeech", 2019]], "Seyed Omid Sadjadi": [0, ["The 2018 NIST Speaker Recognition Evaluation", ["Seyed Omid Sadjadi", "Craig S. Greenberg", "Elliot Singer", "Douglas A. Reynolds", "Lisa P. Mason", "Jaime Hernandez-Cordero"], "https://doi.org/10.21437/Interspeech.2019-1351", 5, "interspeech", 2019]], "Yuri Y. Khokhlov": [0, ["R-Vectors: New Technique for Adaptation to Room Acoustics", ["Yuri Y. Khokhlov", "Alexander Zatvornitskiy", "Ivan Medennikov", "Ivan Sorokin", "Tatiana Prisyach", "Aleksei Romanenko", "Anton Mitrofanov", "Vladimir Bataev", "Andrei Andrusenko", "Mariya Korenevskaya", "Oleg Petrov"], "https://doi.org/10.21437/Interspeech.2019-2645", 5, "interspeech", 2019]], "Galina Lavrentyeva": [0, ["STC Antispoofing Systems for the ASVspoof2019 Challenge", ["Galina Lavrentyeva", "Sergey Novoselov", "Andzhukaev Tseren", "Marina Volkova", "Artem Gorlanov", "Alexandr Kozlov"], "https://doi.org/10.21437/Interspeech.2019-1768", 5, "interspeech", 2019]], "Christina Tannander": [0, ["Spot the Pleasant People! Navigating the Cocktail Party Buzz", ["Christina Tannander", "Per Fallgren", "Jens Edlund", "Joakim Gusafsson"], "https://doi.org/10.21437/Interspeech.2019-1553", 5, "interspeech", 2019]], "Alexandru Nelus": [0, ["Privacy-Preserving Siamese Feature Extraction for Gender Recognition versus Speaker Identification", ["Alexandru Nelus", "Silas Rech", "Timm Koppelmann", "Henrik Biermann", "Rainer Martin"], "https://doi.org/10.21437/Interspeech.2019-1148", 5, "interspeech", 2019], ["Privacy-Preserving Variational Information Feature Extraction for Domestic Activity Monitoring versus Speaker Identification", ["Alexandru Nelus", "Janek Ebbers", "Reinhold Haeb-Umbach", "Rainer Martin"], "https://doi.org/10.21437/Interspeech.2019-1703", 5, "interspeech", 2019]], "Lam Dang Pham": [0, ["A Robust Framework for Acoustic Scene Classification", ["Lam Dang Pham", "Ian Vince McLoughlin", "Huy Phan", "Ramaswamy Palaniappan"], "https://doi.org/10.21437/Interspeech.2019-1841", 5, "interspeech", 2019]], "Yuke Si": [0, ["CNN-BLSTM Based Question Detection from Dialogs Considering Phase and Context Information", ["Yuke Si", "Longbiao Wang", "Jianwu Dang", "Mengfei Wu", "Aijun Li"], "https://doi.org/10.21437/Interspeech.2019-1701", 5, "interspeech", 2019]], "Zongze Ren": [0, ["Two-Stage Training for Chinese Dialect Recognition", ["Zongze Ren", "Guofu Yang", "Shugong Xu"], "https://doi.org/10.21437/Interspeech.2019-1522", 5, "interspeech", 2019]], "Tuan Dinh": [0, ["Using a Manifold Vocoder for Spectral Voice and Style Conversion", ["Tuan Dinh", "Alexander Kain", "Kris Tjaden"], "https://doi.org/10.21437/Interspeech.2019-1176", 5, "interspeech", 2019]], "Denis Peskov": [0, ["Mitigating Noisy Inputs for Question Answering", ["Denis Peskov", "Joe Barrow", "Pedro Rodriguez", "Graham Neubig", "Jordan L. Boyd-Graber"], "https://doi.org/10.21437/Interspeech.2019-3154", 5, "interspeech", 2019]], "Emmanuel Azuh": [0, ["Towards Bilingual Lexicon Discovery From Visually Grounded Speech Audio", ["Emmanuel Azuh", "David Harwath", "James R. Glass"], "https://doi.org/10.21437/Interspeech.2019-1718", 5, "interspeech", 2019]], "Niamh E. Kelly": [0, ["The Voicing Contrast in Stops and Affricates in the Western Armenian of Lebanon", ["Niamh E. Kelly", "Lara Keshishian"], "https://doi.org/10.21437/Interspeech.2019-2529", 5, "interspeech", 2019]], "Hieu-Thi Luong": [0, ["Training Multi-Speaker Neural Text-to-Speech Systems Using Speaker-Imbalanced Speech Corpora", ["Hieu-Thi Luong", "Xin Wang", "Junichi Yamagishi", "Nobuyuki Nishizawa"], "https://doi.org/10.21437/Interspeech.2019-1311", 5, "interspeech", 2019]], "Alejandro Gomez Alanis": [0, ["A Light Convolutional GRU-RNN Deep Feature Extractor for ASV Spoofing Detection", ["Alejandro Gomez Alanis", "Antonio M. Peinado", "Jose A. Gonzalez", "Angel M. Gomez"], "https://doi.org/10.21437/Interspeech.2019-2212", 5, "interspeech", 2019]], "Bin Liu": [0, ["Jointly Adversarial Enhancement Training for Robust End-to-End Speech Recognition", ["Bin Liu", "Shuai Nie", "Shan Liang", "Wenju Liu", "Meng Yu", "Lianwu Chen", "Shouye Peng", "Changliang Li"], "https://doi.org/10.21437/Interspeech.2019-1242", 5, "interspeech", 2019]], "Xinjian Li": [0, ["Multilingual Speech Recognition with Corpus Relatedness Sampling", ["Xinjian Li", "Siddharth Dalmia", "Alan W. Black", "Florian Metze"], "https://doi.org/10.21437/Interspeech.2019-3052", 5, "interspeech", 2019], ["SANTLR: Speech Annotation Toolkit for Low Resource Languages", ["Xinjian Li", "Zhong Zhou", "Siddharth Dalmia", "Alan W. Black", "Florian Metze"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8040.html", 2, "interspeech", 2019]], "Hossein Zeinali": [0, ["Detecting Spoofing Attacks Using VGG and SincNet: BUT-Omilia Submission to ASVspoof 2019 Challenge", ["Hossein Zeinali", "Themos Stafylakis", "Georgia Athanasopoulou", "Johan Rohdin", "Ioannis Gkinis", "Lukas Burget", "Jan Cernocky"], "https://doi.org/10.21437/Interspeech.2019-2892", 5, "interspeech", 2019]], "M. Bentum": [0, ["Listening with Great Expectations: An Investigation of Word Form Anticipations in Naturalistic Speech", ["M. Bentum", "Louis ten Bosch", "Antal van den Bosch", "Mirjam Ernestus"], "https://doi.org/10.21437/Interspeech.2019-2741", 5, "interspeech", 2019], ["Quantifying Expectation Modulation in Human Speech Processing", ["M. Bentum", "Louis ten Bosch", "Antal van den Bosch", "Mirjam Ernestus"], "https://doi.org/10.21437/Interspeech.2019-2685", 5, "interspeech", 2019]], "Yuan Gong": [0.18233120441436768, ["ReMASC: Realistic Replay Attack Corpus for Voice Controlled Systems", ["Yuan Gong", "Jian Yang", "Jacob Huber", "Mitchell MacKnight", "Christian Poellabauer"], "https://doi.org/10.21437/Interspeech.2019-1541", 5, "interspeech", 2019]], "Xiaoyi Qin": [0, ["Far-Field End-to-End Text-Dependent Speaker Verification Based on Mixed Training Data with Transfer Learning and Enrollment Data Augmentation", ["Xiaoyi Qin", "Danwei Cai", "Ming Li"], "https://doi.org/10.21437/Interspeech.2019-1542", 5, "interspeech", 2019]], "Christer Gobl": [0, ["Time to Frequency Domain Mapping of the Voice Source: The Influence of Open Quotient and Glottal Skew on the Low End of the Source Spectrum", ["Christer Gobl", "Ailbhe Ni Chasaide"], "https://doi.org/10.21437/Interspeech.2019-2888", 5, "interspeech", 2019]], "Takuhiro Kaneko": [0, ["StarGAN-VC2: Rethinking Conditional Methods for StarGAN-Based Voice Conversion", ["Takuhiro Kaneko", "Hirokazu Kameoka", "Kou Tanaka", "Nobukatsu Hojo"], "https://doi.org/10.21437/Interspeech.2019-2236", 5, "interspeech", 2019]], "Shaojin Ding": [0, ["Group Latent Embedding for Vector Quantized Variational Autoencoder in Non-Parallel Voice Conversion", ["Shaojin Ding", "Ricardo Gutierrez-Osuna"], "https://doi.org/10.21437/Interspeech.2019-1198", 5, "interspeech", 2019]], "Haiwei Wu": [5.125520146975759e-06, ["The DKU-LENOVO Systems for the INTERSPEECH 2019 Computational Paralinguistic Challenge", ["Haiwei Wu", "Weiqing Wang", "Ming Li"], "https://doi.org/10.21437/Interspeech.2019-1386", 5, "interspeech", 2019]], "Cunhang Fan": [0, ["Discriminative Learning for Monaural Speech Separation Using Deep Embedding Features", ["Cunhang Fan", "Bin Liu", "Jianhua Tao", "Jiangyan Yi", "Zhengqi Wen"], "https://doi.org/10.21437/Interspeech.2019-1940", 5, "interspeech", 2019]], "Fei Wu": [0.000492751831188798, ["Advances in Automatic Speech Recognition for Child Speech Using Factored Time Delay Neural Network", ["Fei Wu", "Leibny Paola Garcia-Perera", "Daniel Povey", "Sanjeev Khudanpur"], "https://doi.org/10.21437/Interspeech.2019-2980", 5, "interspeech", 2019]], "Vanessa Lopes": [0, ["Sustained Vowel Game: A Computer Therapy Game for Children with Dysphonia", ["Vanessa Lopes", "Joao Magalhaes", "Sofia Cavaco"], "https://doi.org/10.21437/Interspeech.2019-3017", 5, "interspeech", 2019]], "Chandan K. A. Reddy": [0, ["A Scalable Noisy Speech Dataset and Online Subjective Test Framework", ["Chandan K. A. Reddy", "Ebrahim Beyrami", "Jamie Pool", "Ross Cutler", "Sriram Srinivasan", "Johannes Gehrke"], "https://doi.org/10.21437/Interspeech.2019-3087", 5, "interspeech", 2019], ["Supervised Classifiers for Audio Impairments with Noisy Labels", ["Chandan K. A. Reddy", "Ross Cutler", "Johannes Gehrke"], "https://doi.org/10.21437/Interspeech.2019-3074", 5, "interspeech", 2019]], "Siddique Latif": [0, ["Direct Modelling of Speech Emotion from Raw Speech", ["Siddique Latif", "Rajib Rana", "Sara Khalifa", "Raja Jurdak", "Julien Epps"], "https://doi.org/10.21437/Interspeech.2019-3252", 5, "interspeech", 2019]], "Alex Sokolov": [0, ["Neural Machine Translation for Multilingual Grapheme-to-Phoneme Conversion", ["Alex Sokolov", "Tracy Rohlin", "Ariya Rastrow"], "https://doi.org/10.21437/Interspeech.2019-3176", 5, "interspeech", 2019]], "Md. Nasir": [0, ["Modeling Interpersonal Linguistic Coordination in Conversations Using Word Mover's Distance", ["Md. Nasir", "Sandeep Nallan Chakravarthula", "Brian R. W. Baucom", "David C. Atkins", "Panayiotis G. Georgiou", "Shrikanth Narayanan"], "https://doi.org/10.21437/Interspeech.2019-1900", 5, "interspeech", 2019]], "Simon Betz": [0, ["The Greennn Tree - Lengthening Position Influences Uncertainty Perception", ["Simon Betz", "Sina Zarriess", "Eva Szekely", "Petra Wagner"], "https://doi.org/10.21437/Interspeech.2019-2572", 5, "interspeech", 2019]], "Taiki Yamamoto": [0, ["Small-Footprint Magic Word Detection Method Using Convolutional LSTM Neural Network", ["Taiki Yamamoto", "Ryota Nishimura", "Masayuki Misaki", "Norihide Kitaoka"], "https://doi.org/10.21437/Interspeech.2019-1662", 5, "interspeech", 2019]], "Yuan-Jui Chen": [0, ["End-to-End Text-to-Speech for Low-Resource Languages by Cross-Lingual Transfer Learning", ["Yuan-Jui Chen", "Tao Tu", "Cheng-chieh Yeh", "Hung-yi Lee"], "https://doi.org/10.21437/Interspeech.2019-2730", 5, "interspeech", 2019]], "Cristina Gorrostieta": [0, ["Gender De-Biasing in Speech Emotion Recognition", ["Cristina Gorrostieta", "Reza Lotfian", "Kye Taylor", "Richard Brutti", "John Kane"], "https://doi.org/10.21437/Interspeech.2019-1708", 5, "interspeech", 2019]], "Ching-Ting Chang": [8.276199459089639e-08, ["Code-Switching Sentence Generation by Generative Adversarial Networks and its Application to Data Augmentation", ["Ching-Ting Chang", "Shun-Po Chuang", "Hung-yi Lee"], "https://doi.org/10.21437/Interspeech.2019-3214", 5, "interspeech", 2019]], "Bing Yang": [0.0030677259201183915, ["Pre-Trained Text Representations for Improving Front-End Text Processing in Mandarin Text-to-Speech Synthesis", ["Bing Yang", "Jiaqi Zhong", "Shan Liu"], "https://doi.org/10.21437/Interspeech.2019-1418", 5, "interspeech", 2019]], "Rajeev Rajan": [0, ["Design and Development of a Multi-Lingual Speech Corpora (TaMaR-EmoDB) for Emotion Analysis", ["Rajeev Rajan", "Haritha U. G.", "Sujitha A. C.", "Rejisha T. M."], "https://doi.org/10.21437/Interspeech.2019-2034", 5, "interspeech", 2019]], "Masaki Okawa": [0, ["Audio Classification of Bit-Representation Waveform", ["Masaki Okawa", "Takuya Saito", "Naoki Sawada", "Hiromitsu Nishizaki"], "https://doi.org/10.21437/Interspeech.2019-1855", 5, "interspeech", 2019]], "Katie Matton": [0, ["Into the Wild: Transitioning from Recognizing Mood in Clinical Interactions to Personal Conversations for Individuals with Bipolar Disorder", ["Katie Matton", "Melvin G. McInnis", "Emily Mower Provost"], "https://doi.org/10.21437/Interspeech.2019-2698", 5, "interspeech", 2019]], "Yuchen Liu": [0, ["End-to-End Speech Translation with Knowledge Distillation", ["Yuchen Liu", "Hao Xiong", "Jiajun Zhang", "Zhongjun He", "Hua Wu", "Haifeng Wang", "Chengqing Zong"], "https://doi.org/10.21437/Interspeech.2019-2582", 5, "interspeech", 2019]], "Anna Esposito": [0, ["The Dependability of Voice on Elders' Acceptance of Humanoid Agents", ["Anna Esposito", "Terry Amorese", "Marialucia Cuciniello", "Maria Teresa Riviello", "Antonietta Maria Esposito", "Alda Troncone", "Gennaro Cordasco"], "https://doi.org/10.21437/Interspeech.2019-1734", 5, "interspeech", 2019]], "Trang Tran": [0, ["On the Role of Style in Parsing Speech with Neural Models", ["Trang Tran", "Jiahong Yuan", "Yang Liu", "Mari Ostendorf"], "https://doi.org/10.21437/Interspeech.2019-3122", 5, "interspeech", 2019]], "Elie Khoury": [0, ["Pindrop Labs' Submission to the First Multi-Target Speaker Detection and Identification Challenge", ["Elie Khoury", "Khaled Lakhdhar", "Andrew Vaughan", "Ganesh Sivaraman", "Parav Nagarsheth"], "https://doi.org/10.21437/Interspeech.2019-3179", 4, "interspeech", 2019]], "Felix Schaeffler": [0, ["Reliability of Clinical Voice Parameters Captured with Smartphones - Measurements of Added Noise and Spectral Tilt", ["Felix Schaeffler", "Stephen Jannetts", "Janet Beck"], "https://doi.org/10.21437/Interspeech.2019-2910", 5, "interspeech", 2019]], "Pavel Matejka": [0, ["Analysis of BUT Submission in Far-Field Scenarios of VOiCES 2019 Challenge", ["Pavel Matejka", "Oldrich Plchot", "Hossein Zeinali", "Ladislav Mosner", "Anna Silnova", "Lukas Burget", "Ondrej Novotny", "Ondrej Glembek"], "https://doi.org/10.21437/Interspeech.2019-2471", 5, "interspeech", 2019], ["Analysis of BUT Submission in Far-Field Scenarios of VOiCES 2019 Challenge", ["Pavel Matejka", "Oldrich Plchot", "Hossein Zeinali", "Ladislav Mosner", "Anna Silnova", "Lukas Burget", "Ondrej Novotny", "Ondrej Glembek"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/abs16.html", 0, "interspeech", 2019]], "Sandy Ritchie": [0, ["Unified Verbalization for Speech Recognition & Synthesis Across Languages", ["Sandy Ritchie", "Richard Sproat", "Kyle Gorman", "Daan van Esch", "Christian Schallhart", "Nikos Bampounis", "Benoit Brard", "Jonas Fromseier Mortensen", "Millie Holt", "Eoin Mahon"], "https://doi.org/10.21437/Interspeech.2019-2807", 5, "interspeech", 2019]], "Fang Bao": [0, ["CycleGAN-Based Emotion Style Transfer as Data Augmentation for Speech Emotion Recognition", ["Fang Bao", "Michael Neumann", "Ngoc Thang Vu"], "https://doi.org/10.21437/Interspeech.2019-2293", 5, "interspeech", 2019]], "Zhanghao Wu": [7.778910978903375e-12, ["Data Augmentation Using Variational Autoencoder for Embedding Based Speaker Verification", ["Zhanghao Wu", "Shuai Wang", "Yanmin Qian", "Kai Yu"], "https://doi.org/10.21437/Interspeech.2019-2248", 5, "interspeech", 2019]], "Xiaohai Tian": [0, ["A Speaker-Dependent WaveNet for Voice Conversion with Non-Parallel Data", ["Xiaohai Tian", "Eng Siong Chng", "Haizhou Li"], "https://doi.org/10.21437/Interspeech.2019-1514", 5, "interspeech", 2019]], "Parvaneh Janbakhshi": [0, ["Spectral Subspace Analysis for Automatic Assessment of Pathological Speech Intelligibility", ["Parvaneh Janbakhshi", "Ina Kodrasi", "Herve Bourlard"], "https://doi.org/10.21437/Interspeech.2019-2791", 5, "interspeech", 2019]], "Lei Liu": [0, ["Prosodic Characteristics of Mandarin Declarative and Interrogative Utterances in Parkinson's Disease", ["Lei Liu", "Meng Jian", "Wentao Gu"], "https://doi.org/10.21437/Interspeech.2019-3276", 5, "interspeech", 2019]], "Xiaodong Cui": [0, ["Acoustic Model Optimization Based on Evolutionary Stochastic Gradient Descent with Anchors for Automatic Speech Recognition", ["Xiaodong Cui", "Michael Picheny"], "https://doi.org/10.21437/Interspeech.2019-2620", 5, "interspeech", 2019]], "David B. Ramsay": [0, ["Low-Dimensional Bottleneck Features for On-Device Continuous Speech Recognition", ["David B. Ramsay", "Kevin Kilgour", "Dominik Roblek", "Matthew Sharifi"], "https://doi.org/10.21437/Interspeech.2019-2193", 4, "interspeech", 2019]], "Kristin Haake": [0, ["Do Hesitations Facilitate Processing of Partially Defective System Utterances? An Exploratory Eye Tracking Study", ["Kristin Haake", "Sarah Schimke", "Simon Betz", "Sina Zarriess"], "https://doi.org/10.21437/Interspeech.2019-2820", 5, "interspeech", 2019]], "Manfred Kaltenbacher": [0, ["Physiology and Physics of Voice Production", ["Manfred Kaltenbacher"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/abs12.html", 0, "interspeech", 2019]], "Che-Wei Huang": [0, ["A Study for Improving Device-Directed Speech Detection Toward Frictionless Human-Machine Interaction", ["Che-Wei Huang", "Roland Maas", "Sri Harish Mallidi", "Bjorn Hoffmeister"], "https://doi.org/10.21437/Interspeech.2019-2840", 5, "interspeech", 2019]], "Alejandro Coucheiro-Limeres": [0, ["Attention-Based Word Vector Prediction with LSTMs and its Application to the OOV Problem in ASR", ["Alejandro Coucheiro-Limeres", "Fernando Fernandez-Martinez", "Ruben San Segundo", "Javier Ferreiros Lopez"], "https://doi.org/10.21437/Interspeech.2019-2347", 5, "interspeech", 2019]], "Patrick Lumban Tobing": [0, ["Non-Parallel Voice Conversion with Cyclic Variational Autoencoder", ["Patrick Lumban Tobing", "Yi-Chiao Wu", "Tomoki Hayashi", "Kazuhiro Kobayashi", "Tomoki Toda"], "https://doi.org/10.21437/Interspeech.2019-2307", 5, "interspeech", 2019]], "Ann R. Bradlow": [0, ["Survey Talk: Recognition of Foreign-Accented Speech: Challenges and Opportunities for Human and Computer Speech Communication", ["Ann R. Bradlow"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/abs21.html", 0, "interspeech", 2019], ["Speaking Rate, Information Density, and Information Rate in First-Language and Second-Language Speech", ["Ann R. Bradlow"], "https://doi.org/10.21437/Interspeech.2019-1150", 5, "interspeech", 2019]], "Mate Akos Tundik": [0, ["Assessing the Semantic Space Bias Caused by ASR Error Propagation and its Effect on Spoken Document Summarization", ["Mate Akos Tundik", "Valer Kaszas", "Gyorgy Szaszak"], "https://doi.org/10.21437/Interspeech.2019-2154", 5, "interspeech", 2019]], "Jan Mizgajski": [0, ["Avaya Conversational Intelligence: A Real-Time System for Spoken Language Understanding in Human-Human Call Center Conversations", ["Jan Mizgajski", "Adrian Szymczak", "Robert Glowski", "Piotr Szymanski", "Piotr Zelasko", "Lukasz Augustyniak", "Mikolaj Morzy", "Yishay Carmiel", "Jeff Hodson", "Lukasz Wojciak", "Daniel Smoczyk", "Adam Wrobel", "Bartosz Borowik", "Adam Artajew", "Marcin Baran", "Cezary Kwiatkowski", "Marzena Zyla-Hoppe"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8002.html", 2, "interspeech", 2019]], "Hongji Wang": [0.0962471030652523, ["Cross-Domain Replay Spoofing Attack Detection Using Domain Adversarial Training", ["Hongji Wang", "Heinrich Dinkel", "Shuai Wang", "Yanmin Qian", "Kai Yu"], "https://doi.org/10.21437/Interspeech.2019-2120", 5, "interspeech", 2019]], "Prachi Singh": [0, ["LEAP Diarization System for the Second DIHARD Challenge", ["Prachi Singh", "Harsha Vardhan", "Sriram Ganapathy", "A. Kanagasundaram"], "https://doi.org/10.21437/Interspeech.2019-2716", 5, "interspeech", 2019]], "Hongyin Luo": [0, ["Integrating Video Retrieval and Moment Detection in a Unified Corpus for Video Question Answering", ["Hongyin Luo", "Mitra Mohtarami", "James R. Glass", "Karthik Krishnamurthy", "Brigitte Richardson"], "https://doi.org/10.21437/Interspeech.2019-1736", 5, "interspeech", 2019]], "Victoria Mingote": [0, ["Optimization of False Acceptance/Rejection Rates and Decision Threshold for End-to-End Text-Dependent Speaker Verification Systems", ["Victoria Mingote", "Antonio Miguel", "Dayana Ribas", "Alfonso Ortega Gimenez", "Eduardo Lleida"], "https://doi.org/10.21437/Interspeech.2019-2550", 5, "interspeech", 2019], ["Language Recognition Using Triplet Neural Networks", ["Victoria Mingote", "Diego Castan", "Mitchell McLaren", "Mahesh Kumar Nandwana", "Alfonso Ortega Gimenez", "Eduardo Lleida", "Antonio Miguel"], "https://doi.org/10.21437/Interspeech.2019-2437", 5, "interspeech", 2019]], "Sweekar Sudhakara": [0, ["An Improved Goodness of Pronunciation (GoP) Measure for Pronunciation Evaluation with DNN-HMM System Considering HMM Transition Probabilities", ["Sweekar Sudhakara", "Manoj Kumar Ramanathi", "Chiranjeevi Yarra", "Prasanta Kumar Ghosh"], "https://doi.org/10.21437/Interspeech.2019-2363", 5, "interspeech", 2019]], "Ankita Pasad": [0, ["On the Contributions of Visual and Textual Supervision in Low-Resource Semantic Speech Retrieval", ["Ankita Pasad", "Bowen Shi", "Herman Kamper", "Karen Livescu"], "https://doi.org/10.21437/Interspeech.2019-3051", 5, "interspeech", 2019]], "Jenifer Vega Rodriguez": [0, ["The Vowel System of Korebaju", ["Jenifer Vega Rodriguez"], "https://doi.org/10.21437/Interspeech.2019-3210", 5, "interspeech", 2019]], "David Snyder": [0, ["The JHU Speaker Recognition System for the VOiCES 2019 Challenge", ["David Snyder", "Jesus Villalba", "Nanxin Chen", "Daniel Povey", "Gregory Sell", "Najim Dehak", "Sanjeev Khudanpur"], "https://doi.org/10.21437/Interspeech.2019-2979", 5, "interspeech", 2019]], "Jiaxu Chen": [0, ["An End-to-End Audio Classification System Based on Raw Waveforms and Mix-Training Strategy", ["Jiaxu Chen", "Jing Hao", "Kai Chen", "Di Xie", "Shicai Yang", "Shiliang Pu"], "https://doi.org/10.21437/Interspeech.2019-1579", 5, "interspeech", 2019]], "Bo Wang": [0.0001360086680506356, ["A Path Signature Approach for Speech Emotion Recognition", ["Bo Wang", "Maria Liakata", "Hao Ni", "Terry Lyons", "Alejo J. Nevado-Holgado", "Kate Saunders"], "https://doi.org/10.21437/Interspeech.2019-2624", 5, "interspeech", 2019]], "Amirhossein Hajavi": [0, ["A Deep Neural Network for Short-Segment Speaker Recognition", ["Amirhossein Hajavi", "Ali Etemad"], "https://doi.org/10.21437/Interspeech.2019-2240", 5, "interspeech", 2019]], "Jiaqi Guo": [0, ["Joint Decoding of CTC Based Systems for Speech Recognition", ["Jiaqi Guo", "Yongbin You", "Yanmin Qian", "Kai Yu"], "https://doi.org/10.21437/Interspeech.2019-2026", 5, "interspeech", 2019]], "Gordon Wichern": [0, ["WHAM!: Extending Speech Separation to Noisy Environments", ["Gordon Wichern", "Joe Antognini", "Michael Flynn", "Licheng Richard Zhu", "Emmett McQuinn", "Dwight Crow", "Ethan Manilow", "Jonathan Le Roux"], "https://doi.org/10.21437/Interspeech.2019-2821", 5, "interspeech", 2019]], "Abdalghani Abujabal": [0, ["Neural Named Entity Recognition from Subword Units", ["Abdalghani Abujabal", "Judith Gaspers"], "https://doi.org/10.21437/Interspeech.2019-1305", 5, "interspeech", 2019]], "Xiang Hao": [0, ["UNetGAN: A Robust Speech Enhancement Approach in Time Domain for Extremely Low Signal-to-Noise Ratio Condition", ["Xiang Hao", "Xiangdong Su", "Zhiyu Wang", "Hui Zhang", "Batushiren"], "https://doi.org/10.21437/Interspeech.2019-1567", 5, "interspeech", 2019]], "Lei Fan": [0, ["Deep Hashing for Speaker Identification and Retrieval", ["Lei Fan", "Qing-Yuan Jiang", "Ya-Qi Yu", "Wu-Jun Li"], "https://doi.org/10.21437/Interspeech.2019-2457", 5, "interspeech", 2019]], "Kangkang Lu": [0, ["Semi-Supervised Audio Classification with Consistency-Based Regularization", ["Kangkang Lu", "Chuan-Sheng Foo", "Kah Kuan Teh", "Huy Dat Tran", "Vijay Ramaseshan Chandrasekhar"], "https://doi.org/10.21437/Interspeech.2019-1231", 5, "interspeech", 2019]], "Ricardo Kleinlein": [0, ["Predicting Group-Level Skin Attention to Short Movies from Audio-Based LSTM-Mixture of Experts Models", ["Ricardo Kleinlein", "Cristina Luna Jimenez", "Juan Manuel Montero", "Zoraida Callejas", "Fernando Fernandez-Martinez"], "https://doi.org/10.21437/Interspeech.2019-2799", 5, "interspeech", 2019]], "Murali Karthick Baskar": [0, ["Semi-Supervised Sequence-to-Sequence ASR Using Unpaired Speech and Text", ["Murali Karthick Baskar", "Shinji Watanabe", "Ramon Fernandez Astudillo", "Takaaki Hori", "Lukas Burget", "Jan Cernocky"], "https://doi.org/10.21437/Interspeech.2019-3167", 5, "interspeech", 2019]], "Haiyang Xu": [0, ["Learning Alignment for Multimodal Emotion Recognition from Speech", ["Haiyang Xu", "Hui Zhang", "Kun Han", "Yun Wang", "Yiping Peng", "Xiangang Li"], "https://doi.org/10.21437/Interspeech.2019-3247", 5, "interspeech", 2019]], "David Ditter": [0, ["Influence of Speaker-Specific Parameters on Speech Separation Systems", ["David Ditter", "Timo Gerkmann"], "https://doi.org/10.21437/Interspeech.2019-2459", 5, "interspeech", 2019]], "Kevin Kilgour": [0, ["Fr\u00e9chet Audio Distance: A Reference-Free Metric for Evaluating Music Enhancement Algorithms", ["Kevin Kilgour", "Mauricio Zuluaga", "Dominik Roblek", "Matthew Sharifi"], "https://doi.org/10.21437/Interspeech.2019-2219", 5, "interspeech", 2019]], "Hanwu Sun": [0.7757290154695511, ["The I2R's Submission to VOiCES Distance Speaker Recognition Challenge 2019", ["Hanwu Sun", "Kah Kuan Teh", "Ivan Kukanov", "Tran Huy Dat"], "https://doi.org/10.21437/Interspeech.2019-1997", 5, "interspeech", 2019]], "Jasper Ooster": [0, ["\"Computer, Test My Hearing\": Accurate Speech Audiometry with Smart Speakers", ["Jasper Ooster", "Pia Nancy Porysek Moreta", "Jorg-Hendrik Bach", "Inga Holube", "Bernd T. Meyer"], "https://doi.org/10.21437/Interspeech.2019-2118", 5, "interspeech", 2019]], "Juqiang Chen": [0, ["Cognitive Factors in Thai-Na\u00efve Mandarin Speakers' Imitation of Thai Lexical Tones", ["Juqiang Chen", "Catherine T. Best", "Mark Antoniou"], "https://doi.org/10.21437/Interspeech.2019-1403", 5, "interspeech", 2019]], "Zhen Fu": [0, ["Effects of Spectral and Temporal Cues to Mandarin Concurrent-Vowels Identification for Normal-Hearing and Hearing-Impaired Listeners", ["Zhen Fu", "Xihong Wu", "Jing Chen"], "https://doi.org/10.21437/Interspeech.2019-3209", 5, "interspeech", 2019]], "Khiet P. Truong": [0, ["Towards an Annotation Scheme for Complex Laughter in Speech Corpora", ["Khiet P. Truong", "Jurgen Trouvain", "Michel-Pierre Jansen"], "https://doi.org/10.21437/Interspeech.2019-1557", 5, "interspeech", 2019]], "Zhong Meng": [0, ["Speaker Adaptation for Attention-Based End-to-End Speech Recognition", ["Zhong Meng", "Yashesh Gaur", "Jinyu Li", "Yifan Gong"], "https://doi.org/10.21437/Interspeech.2019-3135", 5, "interspeech", 2019]], "Xiaoxiao Miao": [0, ["A New Time-Frequency Attention Mechanism for TDNN and CNN-LSTM-TDNN, with Application to Language Identification", ["Xiaoxiao Miao", "Ian McLoughlin", "Yonghong Yan"], "https://doi.org/10.21437/Interspeech.2019-1256", 5, "interspeech", 2019]], "Naoyuki Kanda": [0, ["Auxiliary Interference Speaker Loss for Target-Speaker Speech Recognition", ["Naoyuki Kanda", "Shota Horiguchi", "Ryoichi Takashima", "Yusuke Fujita", "Kenji Nagamatsu", "Shinji Watanabe"], "https://doi.org/10.21437/Interspeech.2019-1126", 5, "interspeech", 2019], ["Guided Source Separation Meets a Strong ASR Backend: Hitachi/Paderborn University Joint Investigation for Dinner Party ASR", ["Naoyuki Kanda", "Christoph Boddeker", "Jens Heitkaemper", "Yusuke Fujita", "Shota Horiguchi", "Kenji Nagamatsu", "Reinhold Haeb-Umbach"], "https://doi.org/10.21437/Interspeech.2019-1167", 5, "interspeech", 2019]], "Vishwa Gupta": [0, ["CRIM's Speech Transcription and Call Sign Detection System for the ATC Airbus Challenge Task", ["Vishwa Gupta", "Lise Rebout", "Gilles Boulianne", "Pierre Andre Menard", "Jahangir Alam"], "https://doi.org/10.21437/Interspeech.2019-1131", 5, "interspeech", 2019]], "Sergey Novoselov": [0, ["Speaker Diarization with Deep Speaker Embeddings for DIHARD Challenge II", ["Sergey Novoselov", "Aleksei Gusev", "Artem Ivanov", "Timur Pekhovsky", "Andrey Shulipa", "Anastasia Avdeeva", "Artem Gorlanov", "Alexandr Kozlov"], "https://doi.org/10.21437/Interspeech.2019-2757", 5, "interspeech", 2019], ["STC Speaker Recognition Systems for the VOiCES from a Distance Challenge", ["Sergey Novoselov", "Aleksei Gusev", "Artem Ivanov", "Timur Pekhovsky", "Andrey Shulipa", "Galina Lavrentyeva", "Vladimir Volokhov", "Alexandr Kozlov"], "https://doi.org/10.21437/Interspeech.2019-2783", 5, "interspeech", 2019], ["STC Speaker Recognition Systems for the VOiCES from a Distance Challenge", ["Sergey Novoselov", "Aleksei Gusev", "Artem Ivanov", "Timur Pekhovsky", "Andrey Shulipa", "Galina Lavrentyeva", "Vladimir Volokhov", "Alexandr Kozlov"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/abs15.html", 0, "interspeech", 2019]], "Triantafyllos Afouras": [0, ["My Lips Are Concealed: Audio-Visual Speech Enhancement Through Obstructions", ["Triantafyllos Afouras", "Joon Son Chung", "Andrew Zisserman"], "https://doi.org/10.21437/Interspeech.2019-3114", 5, "interspeech", 2019]], "Sandra I. Parhammer": [0, ["The Influence of Distraction on Speech Processing: How Selective is Selective Attention?", ["Sandra I. Parhammer", "Miriam Ebersberg", "Jenny Tippmann", "Katja Stark", "Andreas Opitz", "Barbara Hinger", "Sonja Rossi"], "https://doi.org/10.21437/Interspeech.2019-2699", 5, "interspeech", 2019]], "Daniele Salvati": [0, ["End-to-End Speaker Identification in Noisy and Reverberant Environments Using Raw Waveform Convolutional Neural Networks", ["Daniele Salvati", "Carlo Drioli", "Gian Luca Foresti"], "https://doi.org/10.21437/Interspeech.2019-2403", 5, "interspeech", 2019]], "Zhixuan Li": [0, ["Towards Discriminative Representations and Unbiased Predictions: Class-Specific Angular Softmax for Speech Emotion Recognition", ["Zhixuan Li", "Liang He", "Jingyang Li", "Li Wang", "Wei-Qiang Zhang"], "https://doi.org/10.21437/Interspeech.2019-1683", 5, "interspeech", 2019]], "Joel Shor": [0, ["Personalizing ASR for Dysarthric and Accented Speech with Limited Data", ["Joel Shor", "Dotan Emanuel", "Oran Lang", "Omry Tuval", "Michael Brenner", "Julie Cattiau", "Fernando Vieira", "Maeve McNally", "Taylor Charbonneau", "Melissa Nollstadt", "Avinatan Hassidim", "Yossi Matias"], "https://doi.org/10.21437/Interspeech.2019-1427", 5, "interspeech", 2019]], "Berkay Inan": [0, ["Evaluating Audiovisual Source Separation in the Context of Video Conferencing", ["Berkay Inan", "Milos Cernak", "Helmut Grabner", "Helena Peic Tukuljac", "Rodrigo C. G. Pena", "Benjamin Ricaud"], "https://doi.org/10.21437/Interspeech.2019-2671", 5, "interspeech", 2019]], "Soumaya Gharsellaoui": [0, ["Linear Discriminant Differential Evolution for Feature Selection in Emotional Speech Recognition", ["Soumaya Gharsellaoui", "Sid-Ahmed Selouani", "Mohammed Sidi Yakoub"], "https://doi.org/10.21437/Interspeech.2019-1218", 5, "interspeech", 2019]], "Jilt Sebastian": [0, ["Fusion Techniques for Utterance-Level Emotion Recognition Combining Speech and Transcripts", ["Jilt Sebastian", "Piero Pierucci"], "https://doi.org/10.21437/Interspeech.2019-3201", 5, "interspeech", 2019]], "Tsukasa Yoshinaga": [0, ["Individual Differences of Airflow and Sound Generation in the Vocal Tract of Sibilant /s/", ["Tsukasa Yoshinaga", "Kazunori Nozaki", "Shigeo Wada"], "https://doi.org/10.21437/Interspeech.2019-1376", 5, "interspeech", 2019]], "Atsushi Ando": [0, ["Speech Emotion Recognition Based on Multi-Label Emotion Existence Model", ["Atsushi Ando", "Ryo Masumura", "Hosana Kamiyama", "Satoshi Kobashikawa", "Yushi Aono"], "https://doi.org/10.21437/Interspeech.2019-2524", 5, "interspeech", 2019]], "Guanjun Li": [0, ["Direction-Aware Speaker Beam for Multi-Channel Speaker Extraction", ["Guanjun Li", "Shan Liang", "Shuai Nie", "Wenju Liu", "Meng Yu", "Lianwu Chen", "Shouye Peng", "Changliang Li"], "https://doi.org/10.21437/Interspeech.2019-1474", 5, "interspeech", 2019]], "Marie-Jose Caraty": [0, ["Spatial, Temporal and Spectral Multiresolution Analysis for the INTERSPEECH 2019 ComParE Challenge", ["Marie-Jose Caraty", "Claude Montacie"], "https://doi.org/10.21437/Interspeech.2019-1693", 5, "interspeech", 2019]], "Sabrina Jenne": [0, ["Multimodal Articulation-Based Pronunciation Error Detection with Spectrogram and Acoustic Features", ["Sabrina Jenne", "Ngoc Thang Vu"], "https://doi.org/10.21437/Interspeech.2019-1677", 5, "interspeech", 2019]], "Yingying Gao": [0, ["Code-Switching Sentence Generation by Bert and Generative Adversarial Networks", ["Yingying Gao", "Junlan Feng", "Ying Liu", "Leijing Hou", "Xin Pan", "Yong Ma"], "https://doi.org/10.21437/Interspeech.2019-2501", 5, "interspeech", 2019]], "Wenchao Du": [0, ["Bag-of-Acoustic-Words for Mental Health Assessment: A Deep Autoencoding Approach", ["Wenchao Du", "Louis-Philippe Morency", "Jeffrey F. Cohn", "Alan W. Black"], "https://doi.org/10.21437/Interspeech.2019-3059", 5, "interspeech", 2019]], "Niko Moritz": [0, ["Unidirectional Neural Network Architectures for End-to-End Automatic Speech Recognition", ["Niko Moritz", "Takaaki Hori", "Jonathan Le Roux"], "https://doi.org/10.21437/Interspeech.2019-2837", 5, "interspeech", 2019]], "Wei Zhang": [0, ["A Highly Efficient Distributed Deep Learning System for Automatic Speech Recognition", ["Wei Zhang", "Xiaodong Cui", "Ulrich Finkler", "George Saon", "Abdullah Kayi", "Alper Buyuktosunoglu", "Brian Kingsbury", "David S. Kung", "Michael Picheny"], "https://doi.org/10.21437/Interspeech.2019-2700", 5, "interspeech", 2019]], "Yingming Gao": [0, ["Articulatory Copy Synthesis Based on a Genetic Algorithm", ["Yingming Gao", "Simon Stone", "Peter Birkholz"], "https://doi.org/10.21437/Interspeech.2019-1334", 5, "interspeech", 2019]], "Dongxiao Wang": [2.388601116502332e-18, ["A Modified Algorithm for Multiple Input Spectrogram Inversion", ["Dongxiao Wang", "Hirokazu Kameoka", "Koichi Shinoda"], "https://doi.org/10.21437/Interspeech.2019-3242", 5, "interspeech", 2019]], "Mingzhi Yu": [4.386826839286595e-11, ["Identifying Personality Traits Using Overlap Dynamics in Multiparty Dialogue", ["Mingzhi Yu", "Emer Gilmartin", "Diane J. Litman"], "https://doi.org/10.21437/Interspeech.2019-1886", 5, "interspeech", 2019]], "Federico Marinelli": [0, ["Active Annotation: Bootstrapping Annotation Lexicon and Guidelines for Supervised NLU Learning", ["Federico Marinelli", "Alessandra Cervone", "Giuliano Tortoreto", "Evgeny A. Stepanov", "Giuseppe Di Fabbrizio", "Giuseppe Riccardi"], "https://doi.org/10.21437/Interspeech.2019-2537", 5, "interspeech", 2019]], "Christopher Oates": [0, ["Robust Speech Emotion Recognition Under Different Encoding Conditions", ["Christopher Oates", "Andreas Triantafyllopoulos", "Ingmar Steiner", "Bjorn W. Schuller"], "https://doi.org/10.21437/Interspeech.2019-1658", 5, "interspeech", 2019]], "Martin Jansche": [0, ["Sampling from Stochastic Finite Automata with Applications to CTC Decoding", ["Martin Jansche", "Alexander Gutkin"], "https://doi.org/10.21437/Interspeech.2019-2740", 5, "interspeech", 2019]], "Li Chai": [0, ["KL-Divergence Regularized Deep Neural Network Adaptation for Low-Resource Speaker-Dependent Speech Enhancement", ["Li Chai", "Jun Du", "Chin-Hui Lee"], "https://doi.org/10.21437/Interspeech.2019-2426", 5, "interspeech", 2019], ["A Cross-Entropy-Guided (CEG) Measure for Speech Enhancement Front-End Assessing Performances of Back-End Automatic Speech Recognition", ["Li Chai", "Jun Du", "Chin-Hui Lee"], "https://doi.org/10.21437/Interspeech.2019-2511", 5, "interspeech", 2019]], "Alexandre Riviello": [0, ["Binary Speech Features for Keyword Spotting Tasks", ["Alexandre Riviello", "Jean-Pierre David"], "https://doi.org/10.21437/Interspeech.2019-1877", 5, "interspeech", 2019]], "Mirella Lapata": [0, ["Learning Natural Language Interfaces with Neural Models", ["Mirella Lapata"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/abs23.html", 0, "interspeech", 2019]], "Xiaohan Zhang": [0, ["Individual Difference of Relative Tongue Size and its Acoustic Effects", ["Xiaohan Zhang", "Chongke Bi", "Kiyoshi Honda", "Wenhuan Lu", "Jianguo Wei"], "https://doi.org/10.21437/Interspeech.2019-2452", 5, "interspeech", 2019]], "Laura Spinu": [0, ["Articulatory Characteristics of Secondary Palatalization in Romanian Fricatives", ["Laura Spinu", "Maida Percival", "Alexei Kochetov"], "https://doi.org/10.21437/Interspeech.2019-3039", 5, "interspeech", 2019]], "Anneliese Kelterer": [0, ["Acoustic Correlates of Phonation Type in Chichimec", ["Anneliese Kelterer", "Barbara Schuppler"], "https://doi.org/10.21437/Interspeech.2019-2066", 5, "interspeech", 2019]], "Doris Mucke": [0, ["Strength and Structure: Coupling Tones with Oral Constriction Gestures", ["Doris Mucke", "Anne Hermes", "Sam Tilsen"], "https://doi.org/10.21437/Interspeech.2019-2650", 5, "interspeech", 2019]], "Youngmoon Jung": [0.9995688796043396, ["Spatial Pyramid Encoding with Convex Length Normalization for Text-Independent Speaker Verification", ["Youngmoon Jung", "Younggwan Kim", "Hyungjun Lim", "Yeunju Choi", "Hoirin Kim"], "https://doi.org/10.21437/Interspeech.2019-2177", 5, "interspeech", 2019]], "Nagendra Kumar Goel": [0, ["CaptionAI: A Real-Time Multilingual Captioning Application", ["Nagendra Kumar Goel", "Mousmita Sarma", "Saikiran Valluri", "Dharmeshkumar Agrawal", "Steve Braich", "Tejendra Singh Kuswah", "Zikra Iqbal", "Surbhi Chauhan", "Raj Karbar"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8039.html", 2, "interspeech", 2019]], "Yael Segal": [0, ["SpeechYOLO: Detection and Localization of Speech Objects", ["Yael Segal", "Tzeviya Sylvia Fuchs", "Joseph Keshet"], "https://doi.org/10.21437/Interspeech.2019-1749", 5, "interspeech", 2019]], "Zakaria Aldeneh": [0, ["Identifying Mood Episodes Using Dialogue Features from Clinical Interviews", ["Zakaria Aldeneh", "Mimansa Jaiswal", "Michael Picheny", "Melvin G. McInnis", "Emily Mower Provost"], "https://doi.org/10.21437/Interspeech.2019-1878", 5, "interspeech", 2019]], "Uliyana Kubasova": [0, ["Analyzing Verbal and Nonverbal Features for Predicting Group Performance", ["Uliyana Kubasova", "Gabriel Murray", "McKenzie Braley"], "https://doi.org/10.21437/Interspeech.2019-3062", 5, "interspeech", 2019]], "Hiroko Terasawa": [0, ["Investigating the Physiological and Acoustic Contrasts Between Choral and Operatic Singing", ["Hiroko Terasawa", "Kenta Wakasa", "Hideki Kawahara", "Ken-Ichi Sakakibara"], "https://doi.org/10.21437/Interspeech.2019-1864", 5, "interspeech", 2019]], "Naohiro Tawara": [0, ["Multi-Channel Speech Enhancement Using Time-Domain Convolutional Denoising Autoencoder", ["Naohiro Tawara", "Tetsunori Kobayashi", "Tetsuji Ogawa"], "https://doi.org/10.21437/Interspeech.2019-3197", 5, "interspeech", 2019]], "Jason Fong": [0, ["Investigating the Robustness of Sequence-to-Sequence Text-to-Speech Models to Imperfectly-Transcribed Training Data", ["Jason Fong", "Pilar Oplustil Gallegos", "Zack Hodari", "Simon King"], "https://doi.org/10.21437/Interspeech.2019-1824", 5, "interspeech", 2019]], "Jinfu Ni": [0, ["Duration Modeling with Global Phoneme-Duration Vectors", ["Jinfu Ni", "Yoshinori Shiga", "Hisashi Kawai"], "https://doi.org/10.21437/Interspeech.2019-2126", 5, "interspeech", 2019]], "Yermiyahu Hauptman": [0, ["Identifying Distinctive Acoustic and Spectral Features in Parkinson's Disease", ["Yermiyahu Hauptman", "Ruth Aloni-Lavi", "Itshak Lapidot", "Tanya Gurevich", "Yael Manor", "Stav Naor", "Noa Diamant", "Irit Opher"], "https://doi.org/10.21437/Interspeech.2019-2465", 5, "interspeech", 2019]], "Joachim Fainberg": [0, ["Lattice-Based Lightly-Supervised Acoustic Model Training", ["Joachim Fainberg", "Ondrej Klejch", "Steve Renals", "Peter Bell"], "https://doi.org/10.21437/Interspeech.2019-2533", 5, "interspeech", 2019]], "Ivan Lopez-Espejo": [0, ["Keyword Spotting for Hearing Assistive Devices Robust to External Speakers", ["Ivan Lopez-Espejo", "Zheng-Hua Tan", "Jesper Jensen"], "https://doi.org/10.21437/Interspeech.2019-2010", 5, "interspeech", 2019]], "Swapnil Bhosale": [0, ["End-to-End Spoken Language Understanding: Bootstrapping in Low Resource Scenarios", ["Swapnil Bhosale", "Imran Sheikh", "Sri Harsha Dumpala", "Sunil Kumar Kopparapu"], "https://doi.org/10.21437/Interspeech.2019-2366", 5, "interspeech", 2019]], "Yilin Pan": [0, ["Automatic Hierarchical Attention Neural Network for Detecting AD", ["Yilin Pan", "Bahman Mirheidari", "Markus Reuber", "Annalena Venneri", "Daniel Blackburn", "Heidi Christensen"], "https://doi.org/10.21437/Interspeech.2019-1799", 5, "interspeech", 2019]], "Daniel Elsner": [0, ["Deep Neural Baselines for Computational Paralinguistics", ["Daniel Elsner", "Stefan Langer", "Fabian Ritz", "Robert Muller", "Steffen Illium"], "https://doi.org/10.21437/Interspeech.2019-2478", 5, "interspeech", 2019]], "Dongyang Dai": [0, ["Disambiguation of Chinese Polyphones in an End-to-End Framework with Semantic Features Extracted by Pre-Trained BERT", ["Dongyang Dai", "Zhiyong Wu", "Shiyin Kang", "Xixin Wu", "Jia Jia", "Dan Su", "Dong Yu", "Helen Meng"], "https://doi.org/10.21437/Interspeech.2019-2292", 5, "interspeech", 2019]], "Yu-Han Shen": [0, ["Learning How to Listen: A Temporal-Frequential Attention Model for Sound Event Detection", ["Yu-Han Shen", "Ke-Xin He", "Wei-Qiang Zhang"], "https://doi.org/10.21437/Interspeech.2019-2045", 5, "interspeech", 2019]], "Miquel India": [0, ["Self Multi-Head Attention for Speaker Recognition", ["Miquel India", "Pooyan Safari", "Javier Hernando"], "https://doi.org/10.21437/Interspeech.2019-2616", 5, "interspeech", 2019]], "Ke Hu": [0, ["Phoneme-Based Contextualization for Cross-Lingual Speech Recognition in End-to-End Models", ["Ke Hu", "Antoine Bruguier", "Tara N. Sainath", "Rohit Prabhavalkar", "Golan Pundak"], "https://doi.org/10.21437/Interspeech.2019-1868", 5, "interspeech", 2019]], "Mortaza Doulaty": [0, ["Latent Dirichlet Allocation Based Acoustic Data Selection for Automatic Speech Recognition", ["Mortaza Doulaty", "Thomas Hain"], "https://doi.org/10.21437/Interspeech.2019-1797", 5, "interspeech", 2019]], "Jason Taylor": [0, ["Analysis of Pronunciation Learning in End-to-End Speech Synthesis", ["Jason Taylor", "Korin Richmond"], "https://doi.org/10.21437/Interspeech.2019-2830", 5, "interspeech", 2019]], "Javier Jorge": [0, ["Real-Time One-Pass Decoder for Speech Recognition Using LSTM Language Models", ["Javier Jorge", "Adria Gimenez", "Javier Iranzo-Sanchez", "Jorge Civera", "Albert Sanchis", "Alfons Juan"], "https://doi.org/10.21437/Interspeech.2019-2798", 5, "interspeech", 2019]], "Emiru Tsunoo": [0, ["End-to-End Adaptation with Backpropagation Through WFST for On-Device Speech Recognition System", ["Emiru Tsunoo", "Yosuke Kashiwagi", "Satoshi Asakawa", "Toshiyuki Kumakura"], "https://doi.org/10.21437/Interspeech.2019-1880", 5, "interspeech", 2019]], "Suyoun Kim": [0.9995113462209702, ["Cross-Attention End-to-End ASR for Two-Party Conversations", ["Suyoun Kim", "Siddharth Dalmia", "Florian Metze"], "https://doi.org/10.21437/Interspeech.2019-3173", 5, "interspeech", 2019]], "Steven Hillis": [0, ["Unsupervised Phonetic and Word Level Discovery for Speech to Speech Translation for Unwritten Languages", ["Steven Hillis", "Anushree Prasanna Kumar", "Alan W. Black"], "https://doi.org/10.21437/Interspeech.2019-3026", 5, "interspeech", 2019]], "Xi C. Chen": [0, ["Active Learning for Domain Classification in a Commercial Spoken Personal Assistant", ["Xi C. Chen", "Adithya Sagar", "Justine T. Kao", "Tony Y. Li", "Christopher Klein", "Stephen Pulman", "Ashish Garg", "Jason D. Williams"], "https://doi.org/10.21437/Interspeech.2019-1315", 5, "interspeech", 2019]], "Tomohiro Tanaka": [0, ["A Joint End-to-End and DNN-HMM Hybrid Automatic Speech Recognition System with Transferring Sharable Knowledge", ["Tomohiro Tanaka", "Ryo Masumura", "Takafumi Moriya", "Takanobu Oba", "Yushi Aono"], "https://doi.org/10.21437/Interspeech.2019-2263", 5, "interspeech", 2019]], "Roger Yu-Hsiang Lo": [0, ["SLP-AA: Tools for Sign Language Phonetic and Phonological Research", ["Roger Yu-Hsiang Lo", "Kathleen Currie Hall"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8028.html", 2, "interspeech", 2019]], "Themos Stafylakis": [0, ["Self-Supervised Speaker Embeddings", ["Themos Stafylakis", "Johan Rohdin", "Oldrich Plchot", "Petr Mizera", "Lukas Burget"], "https://doi.org/10.21437/Interspeech.2019-2842", 5, "interspeech", 2019]], "Sushant Kafle": [0, ["Fusion Strategy for Prosodic and Lexical Representations of Word Importance", ["Sushant Kafle", "Cecilia Ovesdotter Alm", "Matt Huenerfauth"], "https://doi.org/10.21437/Interspeech.2019-1898", 5, "interspeech", 2019]], "Manjunath Mulimani": [0, ["Locality-Constrained Linear Coding Based Fused Visual Features for Robust Acoustic Event Classification", ["Manjunath Mulimani", "Shashidhar G. Koolagudi"], "https://doi.org/10.21437/Interspeech.2019-1421", 5, "interspeech", 2019]], "Lauren Ward": [0, ["R2SPIN: Re-Recording the Revised Speech Perception in Noise Test", ["Lauren Ward", "Catherine Robinson", "Matthew Paradis", "Katherine M. Tucker", "Ben G. Shirley"], "https://doi.org/10.21437/Interspeech.2019-1281", 5, "interspeech", 2019]], "Odette Scharenborg": [0, ["The Neural Correlates Underlying Lexically-Guided Perceptual Learning", ["Odette Scharenborg", "Jiska Koemans", "Cybelle Smith", "Mark A. Hasegawa-Johnson", "Kara D. Federmeier"], "https://doi.org/10.21437/Interspeech.2019-2328", 5, "interspeech", 2019], ["Survey Talk: Reaching Over the Gap: Cross- and Interdisciplinary Research on Human and Automatic Speech Processing", ["Odette Scharenborg"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/abs25.html", 0, "interspeech", 2019]], "Soonshin Seo": [0.10910973697900772, ["Shortcut Connections Based Deep Speaker Embeddings for End-to-End Speaker Verification System", ["Soonshin Seo", "Daniel Jun Rim", "Minkyu Lim", "Donghyun Lee", "Hosung Park", "Junseok Oh", "Changmin Kim", "Ji-Hwan Kim"], "https://doi.org/10.21437/Interspeech.2019-2195", 5, "interspeech", 2019]], "Eugen Klein": [0, ["Assessing Acoustic and Articulatory Dimensions of Speech Motor Adaptation with Random Forests", ["Eugen Klein", "Jana Brunner", "Phil Hoole"], "https://doi.org/10.21437/Interspeech.2019-1812", 5, "interspeech", 2019]], "Bruno Ferenc Segedin": [0, ["Perceptual Adaptation to Device and Human Voices: Learning and Generalization of a Phonetic Shift Across Real and Voice-AI Talkers", ["Bruno Ferenc Segedin", "Michelle Cohn", "Georgia Zellou"], "https://doi.org/10.21437/Interspeech.2019-1433", 5, "interspeech", 2019]], "Francois G. Germain": [0, ["Speech Denoising with Deep Feature Losses", ["Francois G. Germain", "Qifeng Chen", "Vladlen Koltun"], "https://doi.org/10.21437/Interspeech.2019-1924", 5, "interspeech", 2019]], "Natalie Lewandowski": [0, ["Individual Differences in Implicit Attention to Phonetic Detail in Speech Perception", ["Natalie Lewandowski", "Daniel Duran"], "https://doi.org/10.21437/Interspeech.2019-2989", 5, "interspeech", 2019]], "Sai Krishna Rallabandi": [0, ["Variational Attention Using Articulatory Priors for Generating Code Mixed Speech Using Monolingual Corpora", ["Sai Krishna Rallabandi", "Alan W. Black"], "https://doi.org/10.21437/Interspeech.2019-1103", 5, "interspeech", 2019]], "Chien-Feng Liao": [0, ["Incorporating Symbolic Sequential Modeling for Speech Enhancement", ["Chien-Feng Liao", "Yu Tsao", "Xugang Lu", "Hisashi Kawai"], "https://doi.org/10.21437/Interspeech.2019-1777", 5, "interspeech", 2019], ["Noise Adaptive Speech Enhancement Using Domain Adversarial Training", ["Chien-Feng Liao", "Yu Tsao", "Hung-yi Lee", "Hsin-Min Wang"], "https://doi.org/10.21437/Interspeech.2019-1519", 5, "interspeech", 2019]], "Viacheslav Klimkov": [0, ["Fine-Grained Robust Prosody Transfer for Single-Speaker Neural Text-To-Speech", ["Viacheslav Klimkov", "Srikanth Ronanki", "Jonas Rohnke", "Thomas Drugman"], "https://doi.org/10.21437/Interspeech.2019-2571", 5, "interspeech", 2019]], "Iona Gessinger": [0, ["Phonetic Accommodation in a Wizard-of-Oz Experiment: Intonation and Segments", ["Iona Gessinger", "Bernd Mobius", "Bistra Andreeva", "Eran Raveh", "Ingmar Steiner"], "https://doi.org/10.21437/Interspeech.2019-2445", 5, "interspeech", 2019]], "Luciana Albuquerque": [0, ["Age-Related Changes in European Portuguese Vowel Acoustics", ["Luciana Albuquerque", "Catarina Oliveira", "Antonio J. S. Teixeira", "Pedro Sa-Couto", "Daniela Figueiredo"], "https://doi.org/10.21437/Interspeech.2019-1818", 5, "interspeech", 2019]], "Anton Noll": [0, ["Sound Tools eXtended (STx) 5.0 - A Powerful Sound Analysis Tool Optimized for Speech", ["Anton Noll", "Jonathan Stuefer", "Nicola Klingler", "Hannah Leykum", "Carina Lozo", "Jan Luttenberger", "Michael Pucher", "Carolin Schmid"], "http://www.isca-speech.org/archive/Interspeech_2019/abstracts/8022.html", 2, "interspeech", 2019]], "Jiamin Xie": [0, ["Multi-PLDA Diarization on Children's Speech", ["Jiamin Xie", "Leibny Paola Garcia-Perera", "Daniel Povey", "Sanjeev Khudanpur"], "https://doi.org/10.21437/Interspeech.2019-2961", 5, "interspeech", 2019]], "Masakiyo Fujimoto": [0, ["One-Pass Single-Channel Noisy Speech Recognition Using a Combination of Noisy and Enhanced Features", ["Masakiyo Fujimoto", "Hisashi Kawai"], "https://doi.org/10.21437/Interspeech.2019-1270", 5, "interspeech", 2019]], "Peter Birkholz": [0, ["Perceptual Optimization of an Enhanced Geometric Vocal Fold Model for Articulatory Speech Synthesis", ["Peter Birkholz", "Susanne Drechsel", "Simon Stone"], "https://doi.org/10.21437/Interspeech.2019-2410", 5, "interspeech", 2019]], "Radoslaw Bialobrzeski": [0, ["Robust Bayesian and Light Neural Networks for Voice Spoofing Detection", ["Radoslaw Bialobrzeski", "Michal Kosmider", "Mateusz Matuszewski", "Marcin Plata", "Alexander Rakowski"], "https://doi.org/10.21437/Interspeech.2019-2676", 5, "interspeech", 2019]], "Yun Liu": [0, ["Investigation of Cost Function for Supervised Monaural Speech Separation", ["Yun Liu", "Hui Zhang", "Xueliang Zhang", "Yuhang Cao"], "https://doi.org/10.21437/Interspeech.2019-1897", 5, "interspeech", 2019]], "Guozhen An": [1.6238163157850094e-11, ["Mitigating Gender and L1 Differences to Improve State and Trait Recognition", ["Guozhen An", "Rivka Levitan"], "https://doi.org/10.21437/Interspeech.2019-2868", 4, "interspeech", 2019]], "Abhinav Jain": [0, ["A Multi-Accent Acoustic Model Using Mixture of Experts for Speech Recognition", ["Abhinav Jain", "Vishwanath P. Singh", "Shakti P. Rath"], "https://doi.org/10.21437/Interspeech.2019-1667", 5, "interspeech", 2019]], "Sevinj Yolchuyeva": [0, ["Transformer Based Grapheme-to-Phoneme Conversion", ["Sevinj Yolchuyeva", "Geza Nemeth", "Balint Gyires-Toth"], "https://doi.org/10.21437/Interspeech.2019-1954", 5, "interspeech", 2019]], "Debasish Ray Mohapatra": [0, ["An Extended Two-Dimensional Vocal Tract Model for Fast Acoustic Simulation of Single-Axis Symmetric Three-Dimensional Tubes", ["Debasish Ray Mohapatra", "Victor Zappi", "Sidney S. Fels"], "https://doi.org/10.21437/Interspeech.2019-1764", 5, "interspeech", 2019]], "Chanwoo Kim": [0.9085521399974823, ["Improved Vocal Tract Length Perturbation for a State-of-the-Art End-to-End Speech Recognition System", ["Chanwoo Kim", "Minkyu Shin", "Abhinav Garg", "Dhananjaya Gowda"], "https://doi.org/10.21437/Interspeech.2019-3227", 5, "interspeech", 2019]], "Louis ten Bosch": [0, ["Phase Synchronization Between EEG Signals as a Function of Differences Between Stimuli Characteristics", ["Louis ten Bosch", "Kimberley Mulder", "Louis Boves"], "https://doi.org/10.21437/Interspeech.2019-2443", 5, "interspeech", 2019], ["Analyzing Reaction Time and Error Sequences in Lexical Decision Experiments", ["Louis ten Bosch", "Lou Boves", "Kimberley Mulder"], "https://doi.org/10.21437/Interspeech.2019-2611", 5, "interspeech", 2019]], "Lukasz Dudziak": [0, ["ShrinkML: End-to-End ASR Model Compression Using Reinforcement Learning", ["Lukasz Dudziak", "Mohamed S. Abdelfattah", "Ravichander Vipperla", "Stefanos Laskaridis", "Nicholas D. Lane"], "https://doi.org/10.21437/Interspeech.2019-2811", 5, "interspeech", 2019]], "Aravind Illa": [0, ["An Investigation on Speaker Specific Articulatory Synthesis with Speaker Independent Articulatory Inversion", ["Aravind Illa", "Prasanta Kumar Ghosh"], "https://doi.org/10.21437/Interspeech.2019-2664", 5, "interspeech", 2019]], "Matthew Wiesner": [0, ["Pretraining by Backtranslation for End-to-End ASR in Low-Resource Settings", ["Matthew Wiesner", "Adithya Renduchintala", "Shinji Watanabe", "Chunxi Liu", "Najim Dehak", "Sanjeev Khudanpur"], "https://doi.org/10.21437/Interspeech.2019-3254", 5, "interspeech", 2019]], "Shigeki Karita": [0, ["Improving Transformer-Based End-to-End Speech Recognition with Connectionist Temporal Classification and Language Model Integration", ["Shigeki Karita", "Nelson Enrique Yalta Soplin", "Shinji Watanabe", "Marc Delcroix", "Atsunori Ogawa", "Tomohiro Nakatani"], "https://doi.org/10.21437/Interspeech.2019-1938", 5, "interspeech", 2019]]}