{"Patrick Kidger": [0, ["Deep Signature Transforms", ["Patrick Kidger", "Patric Bonnier", "Imanol Perez Arribas", "Cristopher Salvi", "Terry Lyons"], "http://papers.nips.cc/paper/8574-deep-signature-transforms", 11, "neurips", 2019]], "Ke Alexander Wang": [2.2141177370612006e-17, ["Exact Gaussian Processes on a Million Data Points", ["Ke Alexander Wang", "Geoff Pleiss", "Jacob R. Gardner", "Stephen Tyree", "Kilian Q. Weinberger", "Andrew Gordon Wilson"], "http://papers.nips.cc/paper/9606-exact-gaussian-processes-on-a-million-data-points", 11, "neurips", 2019]], "Adil Salim": [0, ["Stochastic Proximal Langevin Algorithm: Potential Splitting and Nonasymptotic Rates", ["Adil Salim", "Dmitry Koralev", "Peter Richtarik"], "http://papers.nips.cc/paper/8891-stochastic-proximal-langevin-algorithm-potential-splitting-and-nonasymptotic-rates", 13, "neurips", 2019]], "Christopher Beckham": [0, ["On Adversarial Mixup Resynthesis", ["Christopher Beckham", "Sina Honari", "Vikas Verma", "Alex Lamb", "Farnoosh Ghadiri", "R. Devon Hjelm", "Yoshua Bengio", "Chris Pal"], "http://papers.nips.cc/paper/8686-on-adversarial-mixup-resynthesis", 12, "neurips", 2019]], "Mohamed Ishmael Belghazi": [0, ["Learning about an exponential amount of conditional distributions", ["Mohamed Ishmael Belghazi", "Maxime Oquab", "David Lopez-Paz"], "http://papers.nips.cc/paper/9523-learning-about-an-exponential-amount-of-conditional-distributions", 12, "neurips", 2019]], "Congchao Wang": [6.071378066963007e-08, ["muSSP: Efficient Min-cost Flow Algorithm for Multi-object Tracking", ["Congchao Wang", "Yizhi Wang", "Yinxue Wang", "Chiung-Ting Wu", "Guoqiang Yu"], "http://papers.nips.cc/paper/8334-mussp-efficient-min-cost-flow-algorithm-for-multi-object-tracking", 10, "neurips", 2019]], "Changxiao Cai": [0, ["Nonconvex Low-Rank Tensor Completion from Noisy Data", ["Changxiao Cai", "Gen Li", "H. Vincent Poor", "Yuxin Chen"], "http://papers.nips.cc/paper/8462-nonconvex-low-rank-tensor-completion-from-noisy-data", 12, "neurips", 2019]], "David Rolnick": [0, ["Experience Replay for Continual Learning", ["David Rolnick", "Arun Ahuja", "Jonathan Schwarz", "Timothy P. Lillicrap", "Gregory Wayne"], "http://papers.nips.cc/paper/8327-experience-replay-for-continual-learning", 11, "neurips", 2019]], "Jiaqi Ma": [0, ["A Flexible Generative Framework for Graph-based Semi-supervised Learning", ["Jiaqi Ma", "Weijing Tang", "Ji Zhu", "Qiaozhu Mei"], "http://papers.nips.cc/paper/8590-a-flexible-generative-framework-for-graph-based-semi-supervised-learning", 10, "neurips", 2019]], "Hugo Touvron": [0, ["Fixing the train-test resolution discrepancy", ["Hugo Touvron", "Andrea Vedaldi", "Matthijs Douze", "Herve Jegou"], "http://papers.nips.cc/paper/9035-fixing-the-train-test-resolution-discrepancy", 11, "neurips", 2019]], "Mitsuru Kusumoto": [0, ["A Graph Theoretic Framework of Recomputation Algorithms for Memory-Efficient Backpropagation", ["Mitsuru Kusumoto", "Takuya Inoue", "Gentaro Watanabe", "Takuya Akiba", "Masanori Koyama"], "http://papers.nips.cc/paper/8400-a-graph-theoretic-framework-of-recomputation-algorithms-for-memory-efficient-backpropagation", 10, "neurips", 2019]], "Yixing Xu": [0, ["Positive-Unlabeled Compression on the Cloud", ["Yixing Xu", "Yunhe Wang", "Hanting Chen", "Kai Han", "Chunjing Xu", "Dacheng Tao", "Chang Xu"], "http://papers.nips.cc/paper/8525-positive-unlabeled-compression-on-the-cloud", 10, "neurips", 2019]], "Eugene Ndiaye": [0, ["Computing Full Conformal Prediction Set with Approximate Homotopy", ["Eugene Ndiaye", "Ichiro Takeuchi"], "http://papers.nips.cc/paper/8419-computing-full-conformal-prediction-set-with-approximate-homotopy", 10, "neurips", 2019]], "Krzysztof Choromanski": [0, ["From Complexity to Simplicity: Adaptive ES-Active Subspaces for Blackbox Optimization", ["Krzysztof Choromanski", "Aldo Pacchiano", "Jack Parker-Holder", "Yunhao Tang", "Vikas Sindhwani"], "http://papers.nips.cc/paper/9218-from-complexity-to-simplicity-adaptive-es-active-subspaces-for-blackbox-optimization", 11, "neurips", 2019]], "Fengxiang He": [0, ["Control Batch Size and Learning Rate to Generalize Well: Theoretical and Empirical Evidence", ["Fengxiang He", "Tongliang Liu", "Dacheng Tao"], "http://papers.nips.cc/paper/8398-control-batch-size-and-learning-rate-to-generalize-well-theoretical-and-empirical-evidence", 10, "neurips", 2019]], "Stephan Rabanser": [0, ["Failing Loudly: An Empirical Study of Methods for Detecting Dataset Shift", ["Stephan Rabanser", "Stephan Gunnemann", "Zachary C. Lipton"], "http://papers.nips.cc/paper/8420-failing-loudly-an-empirical-study-of-methods-for-detecting-dataset-shift", 13, "neurips", 2019]], "Muhan Zhang": [0, ["D-VAE: A Variational Autoencoder for Directed Acyclic Graphs", ["Muhan Zhang", "Shali Jiang", "Zhicheng Cui", "Roman Garnett", "Yixin Chen"], "http://papers.nips.cc/paper/8437-d-vae-a-variational-autoencoder-for-directed-acyclic-graphs", 13, "neurips", 2019]], "Christos Louizos": [0, ["The Functional Neural Process", ["Christos Louizos", "Xiahan Shi", "Klamer Schutte", "Max Welling"], "http://papers.nips.cc/paper/9079-the-functional-neural-process", 12, "neurips", 2019]], "Taeyoung Hahn": [0.9952526688575745, ["Self-Routing Capsule Networks", ["Taeyoung Hahn", "Myeongjang Pyeon", "Gunhee Kim"], "http://papers.nips.cc/paper/8982-self-routing-capsule-networks", 10, "neurips", 2019]], "Michalis K. Titsias": [0, ["Gradient-based Adaptive Markov Chain Monte Carlo", ["Michalis K. Titsias", "Petros Dellaportas"], "http://papers.nips.cc/paper/9703-gradient-based-adaptive-markov-chain-monte-carlo", 10, "neurips", 2019]], "Sidharth Gupta": [0, ["Don't take it lightly: Phasing optical random projections with unknown operators", ["Sidharth Gupta", "Remi Gribonval", "Laurent Daudet", "Ivan Dokmanic"], "http://papers.nips.cc/paper/9624-dont-take-it-lightly-phasing-optical-random-projections-with-unknown-operators", 11, "neurips", 2019]], "Antoine Wehenkel": [0, ["Unconstrained Monotonic Neural Networks", ["Antoine Wehenkel", "Gilles Louppe"], "http://papers.nips.cc/paper/8433-unconstrained-monotonic-neural-networks", 11, "neurips", 2019]], "Guillaume Gautier": [0, ["On two ways to use determinantal point processes for Monte Carlo integration", ["Guillaume Gautier", "Remi Bardenet", "Michal Valko"], "http://papers.nips.cc/paper/8992-on-two-ways-to-use-determinantal-point-processes-for-monte-carlo-integration", 10, "neurips", 2019]], "Oliver Hamelijnck": [0, ["Multi-resolution Multi-task Gaussian Processes", ["Oliver Hamelijnck", "Theodoros Damoulas", "Kangrui Wang", "Mark A. Girolami"], "http://papers.nips.cc/paper/9552-multi-resolution-multi-task-gaussian-processes", 11, "neurips", 2019]], "Xiyang Liu": [0, ["Minimax Optimal Estimation of Approximate Differential Privacy on Neighboring Databases", ["Xiyang Liu", "Sewoong Oh"], "http://papers.nips.cc/paper/8512-minimax-optimal-estimation-of-approximate-differential-privacy-on-neighboring-databases", 12, "neurips", 2019]], "Jacky Y. Zhang": [0, ["Learning Sparse Distributions using Iterative Hard Thresholding", ["Jacky Y. Zhang", "Rajiv Khanna", "Anastasios Kyrillidis", "Oluwasanmi Koyejo"], "http://papers.nips.cc/paper/8901-learning-sparse-distributions-using-iterative-hard-thresholding", 10, "neurips", 2019]], "Dongdong Ge": [0, ["Interior-Point Methods Strike Back: Solving the Wasserstein Barycenter Problem", ["Dongdong Ge", "Haoyue Wang", "Zikai Xiong", "Yinyu Ye"], "http://papers.nips.cc/paper/8913-interior-point-methods-strike-back-solving-the-wasserstein-barycenter-problem", 12, "neurips", 2019]], "Hao Yu": [0.05930156260728836, ["A Communication Efficient Stochastic Multi-Block Alternating Direction Method of Multipliers", ["Hao Yu"], "http://papers.nips.cc/paper/9068-a-communication-efficient-stochastic-multi-block-alternating-direction-method-of-multipliers", 10, "neurips", 2019]], "Hao Sun": [0.05930156260728836, ["Policy Continuation with Hindsight Inverse Dynamics", ["Hao Sun", "Zhizhong Li", "Xiaotong Liu", "Bolei Zhou", "Dahua Lin"], "http://papers.nips.cc/paper/9215-policy-continuation-with-hindsight-inverse-dynamics", 11, "neurips", 2019]], "Ning Miao": [0, ["Kernelized Bayesian Softmax for Text Generation", ["Ning Miao", "Hao Zhou", "Chengqi Zhao", "Wenxian Shi", "Lei Li"], "http://papers.nips.cc/paper/9415-kernelized-bayesian-softmax-for-text-generation", 11, "neurips", 2019]], "Andrei Kulunchakov": [0, ["A Generic Acceleration Framework for Stochastic Composite Optimization", ["Andrei Kulunchakov", "Julien Mairal"], "http://papers.nips.cc/paper/9421-a-generic-acceleration-framework-for-stochastic-composite-optimization", 12, "neurips", 2019]], "Haggai Maron": [0, ["Provably Powerful Graph Networks", ["Haggai Maron", "Heli Ben-Hamu", "Hadar Serviansky", "Yaron Lipman"], "http://papers.nips.cc/paper/8488-provably-powerful-graph-networks", 12, "neurips", 2019]], "Muhammad Osama": [0, ["Prediction of Spatial Point Processes: Regularized Method with Out-of-Sample Guarantees", ["Muhammad Osama", "Dave Zachariah", "Peter Stoica"], "http://papers.nips.cc/paper/9363-prediction-of-spatial-point-processes-regularized-method-with-out-of-sample-guarantees", 10, "neurips", 2019]], "Shibani Santurkar": [0, ["Image Synthesis with a Single (Robust) Classifier", ["Shibani Santurkar", "Andrew Ilyas", "Dimitris Tsipras", "Logan Engstrom", "Brandon Tran", "Aleksander Madry"], "http://papers.nips.cc/paper/8409-image-synthesis-with-a-single-robust-classifier", 12, "neurips", 2019]], "Mohammad Emtiyaz Khan": [0, ["Approximate Inference Turns Deep Networks into Gaussian Processes", ["Mohammad Emtiyaz Khan", "Alexander Immer", "Ehsan Abedi", "Maciej Korzepa"], "http://papers.nips.cc/paper/8573-approximate-inference-turns-deep-networks-into-gaussian-processes", 11, "neurips", 2019]], "Farzin Haddadpour": [0, ["Local SGD with Periodic Averaging: Tighter Analysis and Adaptive Synchronization", ["Farzin Haddadpour", "Mohammad Mahdi Kamani", "Mehrdad Mahdavi", "Viveck R. Cadambe"], "http://papers.nips.cc/paper/9288-local-sgd-with-periodic-averaging-tighter-analysis-and-adaptive-synchronization", 13, "neurips", 2019]], "Amin Jaber": [0, ["Identification of Conditional Causal Effects under Markov Equivalence", ["Amin Jaber", "Jiji Zhang", "Elias Bareinboim"], "http://papers.nips.cc/paper/9327-identification-of-conditional-causal-effects-under-markov-equivalence", 9, "neurips", 2019]], "Jayadev Acharya": [0, ["Estimating Entropy of Distributions in Constant Space", ["Jayadev Acharya", "Sourbh Bhadane", "Piotr Indyk", "Ziteng Sun"], "http://papers.nips.cc/paper/8759-estimating-entropy-of-distributions-in-constant-space", 12, "neurips", 2019]], "Minshuo Chen": [0, ["Efficient Approximation of Deep ReLU Networks for Functions on Low Dimensional Manifolds", ["Minshuo Chen", "Haoming Jiang", "Wenjing Liao", "Tuo Zhao"], "http://papers.nips.cc/paper/9028-efficient-approximation-of-deep-relu-networks-for-functions-on-low-dimensional-manifolds", 11, "neurips", 2019]], "Paul Hand": [0, ["Global Guarantees for Blind Demodulation with Generative Priors", ["Paul Hand", "Babhru Joshi"], "http://papers.nips.cc/paper/9329-global-guarantees-for-blind-demodulation-with-generative-priors", 11, "neurips", 2019]], "Jianwei Yang": [1.7882772346267117e-10, ["Cross-channel Communication Networks", ["Jianwei Yang", "Zhile Ren", "Chuang Gan", "Hongyuan Zhu", "Devi Parikh"], "http://papers.nips.cc/paper/8411-cross-channel-communication-networks", 10, "neurips", 2019]], "Chundi Liu": [0, ["Guided Similarity Separation for Image Retrieval", ["Chundi Liu", "Guang Wei Yu", "Maksims Volkovs", "Cheng Chang", "Himanshu Rai", "Junwei Ma", "Satya Krishna Gorti"], "http://papers.nips.cc/paper/8434-guided-similarity-separation-for-image-retrieval", 11, "neurips", 2019]], "Sanchit Kalhan": [0, ["Correlation clustering with local objectives", ["Sanchit Kalhan", "Konstantin Makarychev", "Timothy Zhou"], "http://papers.nips.cc/paper/9132-correlation-clustering-with-local-objectives", 10, "neurips", 2019]], "Candice Schumann": [0, ["Making the Cut: A Bandit-based Approach to Tiered Interviewing", ["Candice Schumann", "Zhi Lang", "Jeffrey S. Foster", "John P. Dickerson"], "http://papers.nips.cc/paper/8712-making-the-cut-a-bandit-based-approach-to-tiered-interviewing", 11, "neurips", 2019]], "Matan Atzmon": [0, ["Controlling Neural Level Sets", ["Matan Atzmon", "Niv Haim", "Lior Yariv", "Ofer Israelov", "Haggai Maron", "Yaron Lipman"], "http://papers.nips.cc/paper/8477-controlling-neural-level-sets", 10, "neurips", 2019]], "Yair Marom": [0, ["k-Means Clustering of Lines for Big Data", ["Yair Marom", "Dan Feldman"], "http://papers.nips.cc/paper/9442-k-means-clustering-of-lines-for-big-data", 10, "neurips", 2019]], "Natalia Neverova": [0, ["Correlated Uncertainty for Learning Dense Correspondences from Noisy Labels", ["Natalia Neverova", "David Novotny", "Andrea Vedaldi"], "http://papers.nips.cc/paper/8378-correlated-uncertainty-for-learning-dense-correspondences-from-noisy-labels", 9, "neurips", 2019]], "Zhizhou Ren": [0, ["Exploration via Hindsight Goal Generation", ["Zhizhou Ren", "Kefan Dong", "Yuan Zhou", "Qiang Liu", "Jian Peng"], "http://papers.nips.cc/paper/9502-exploration-via-hindsight-goal-generation", 11, "neurips", 2019]], "Tanner Fiez": [0, ["Sequential Experimental Design for Transductive Linear Bandits", ["Tanner Fiez", "Lalit Jain", "Kevin G. Jamieson", "Lillian J. Ratliff"], "http://papers.nips.cc/paper/9251-sequential-experimental-design-for-transductive-linear-bandits", 11, "neurips", 2019]], "Daniel Russo": [0, ["Worst-Case Regret Bounds for Exploration via Randomized Value Functions", ["Daniel Russo"], "http://papers.nips.cc/paper/9587-worst-case-regret-bounds-for-exploration-via-randomized-value-functions", 11, "neurips", 2019]], "Yuki Yoshida": [0, ["Data-Dependence of Plateau Phenomenon in Learning with Neural Network - Statistical Mechanical Analysis", ["Yuki Yoshida", "Masato Okada"], "http://papers.nips.cc/paper/8449-data-dependence-of-plateau-phenomenon-in-learning-with-neural-network-statistical-mechanical-analysis", 9, "neurips", 2019]], "Trevor Campbell": [0, ["Universal Boosting Variational Inference", ["Trevor Campbell", "Xinglong Li"], "http://papers.nips.cc/paper/8608-universal-boosting-variational-inference", 12, "neurips", 2019], ["Sparse Variational Inference: Bayesian Coresets from Scratch", ["Trevor Campbell", "Boyan Beronov"], "http://papers.nips.cc/paper/9322-sparse-variational-inference-bayesian-coresets-from-scratch", 12, "neurips", 2019]], "Muhammad Waleed Gondal": [0, ["On the Transfer of Inductive Bias from Simulation to the Real World: a New Disentanglement Dataset", ["Muhammad Waleed Gondal", "Manuel Wuthrich", "Djordje Miladinovic", "Francesco Locatello", "Martin Breidt", "Valentin Volchkov", "Joel Akpo", "Olivier Bachem", "Bernhard Scholkopf", "Stefan Bauer"], "http://papers.nips.cc/paper/9704-on-the-transfer-of-inductive-bias-from-simulation-to-the-real-world-a-new-disentanglement-dataset", 12, "neurips", 2019]], "Xi Lin": [0, ["Pareto Multi-Task Learning", ["Xi Lin", "Hui-Ling Zhen", "Zhenhua Li", "Qing-Fu Zhang", "Sam Kwong"], "http://papers.nips.cc/paper/9374-pareto-multi-task-learning", 11, "neurips", 2019]], "Raphael J. L. Townshend": [0, ["End-to-End Learning on 3D Protein Structure for Interface Prediction", ["Raphael J. L. Townshend", "Rishi Bedi", "Patricia Suriana", "Ron O. Dror"], "http://papers.nips.cc/paper/9695-end-to-end-learning-on-3d-protein-structure-for-interface-prediction", 10, "neurips", 2019]], "Fabian Latorre Gomez": [0, ["Fast and Provable ADMM for Learning with Generative Priors", ["Fabian Latorre Gomez", "Armin Eftekhari", "Volkan Cevher"], "http://papers.nips.cc/paper/9371-fast-and-provable-admm-for-learning-with-generative-priors", 13, "neurips", 2019]], "Gregory W. Benton": [0, ["Function-Space Distributions over Kernels", ["Gregory W. Benton", "Wesley J. Maddox", "Jayson P. Salkey", "Julio Albinati", "Andrew Gordon Wilson"], "http://papers.nips.cc/paper/9634-function-space-distributions-over-kernels", 12, "neurips", 2019]], "Philip Bachman": [0, ["Learning Representations by Maximizing Mutual Information Across Views", ["Philip Bachman", "R. Devon Hjelm", "William Buchwalter"], "http://papers.nips.cc/paper/9686-learning-representations-by-maximizing-mutual-information-across-views", 11, "neurips", 2019]], "Ines Chami": [0, ["Hyperbolic Graph Convolutional Neural Networks", ["Ines Chami", "Zhitao Ying", "Christopher Re", "Jure Leskovec"], "http://papers.nips.cc/paper/8733-hyperbolic-graph-convolutional-neural-networks", 12, "neurips", 2019]], "Abhinav Verma": [0, ["Imitation-Projected Programmatic Reinforcement Learning", ["Abhinav Verma", "Hoang Minh Le", "Yisong Yue", "Swarat Chaudhuri"], "http://papers.nips.cc/paper/9705-imitation-projected-programmatic-reinforcement-learning", 12, "neurips", 2019]], "Uthaipon Tantipongpipat": [0, ["Multi-Criteria Dimensionality Reduction with Applications to Fairness", ["Uthaipon Tantipongpipat", "Samira Samadi", "Mohit Singh", "Jamie H. Morgenstern", "Santosh S. Vempala"], "http://papers.nips.cc/paper/9652-multi-criteria-dimensionality-reduction-with-applications-to-fairness", 11, "neurips", 2019]], "Tsendsuren Munkhdalai": [0, ["Metalearned Neural Memory", ["Tsendsuren Munkhdalai", "Alessandro Sordoni", "Tong Wang", "Adam Trischler"], "http://papers.nips.cc/paper/9488-metalearned-neural-memory", 12, "neurips", 2019]], "Ben Sorscher": [0, ["A unified theory for the origin of grid cells through the lens of pattern formation", ["Ben Sorscher", "Gabriel Mel", "Surya Ganguli", "Samuel A. Ocko"], "http://papers.nips.cc/paper/9191-a-unified-theory-for-the-origin-of-grid-cells-through-the-lens-of-pattern-formation", 11, "neurips", 2019]], "Lili Su": [0, ["On Learning Over-parameterized Neural Networks: A Functional Approximation Perspective", ["Lili Su", "Pengkun Yang"], "http://papers.nips.cc/paper/8532-on-learning-over-parameterized-neural-networks-a-functional-approximation-perspective", 10, "neurips", 2019]], "Sauptik Dhar": [0, ["Multiclass Learning from Contradictions", ["Sauptik Dhar", "Vladimir Cherkassky", "Mohak Shah"], "http://papers.nips.cc/paper/9048-multiclass-learning-from-contradictions", 11, "neurips", 2019]], "Amin Karbasi": [0, ["Stochastic Continuous Greedy ++: When Upper and Lower Bounds Match", ["Amin Karbasi", "Hamed Hassani", "Aryan Mokhtari", "Zebang Shen"], "http://papers.nips.cc/paper/9466-stochastic-continuous-greedy-when-upper-and-lower-bounds-match", 11, "neurips", 2019]], "Zeyuan Allen-Zhu": [0, ["Learning and Generalization in Overparameterized Neural Networks, Going Beyond Two Layers", ["Zeyuan Allen-Zhu", "Yuanzhi Li", "Yingyu Liang"], "http://papers.nips.cc/paper/8847-learning-and-generalization-in-overparameterized-neural-networks-going-beyond-two-layers", 12, "neurips", 2019], ["On the Convergence Rate of Training Recurrent Neural Networks", ["Zeyuan Allen-Zhu", "Yuanzhi Li", "Zhao Song"], "http://papers.nips.cc/paper/8893-on-the-convergence-rate-of-training-recurrent-neural-networks", 13, "neurips", 2019], ["What Can ResNet Learn Efficiently, Going Beyond Kernels?", ["Zeyuan Allen-Zhu", "Yuanzhi Li"], "http://papers.nips.cc/paper/9103-what-can-resnet-learn-efficiently-going-beyond-kernels", 11, "neurips", 2019], ["Can SGD Learn Recurrent Neural Networks with Provable Generalization?", ["Zeyuan Allen-Zhu", "Yuanzhi Li"], "http://papers.nips.cc/paper/9221-can-sgd-learn-recurrent-neural-networks-with-provable-generalization", 11, "neurips", 2019]], "Ji Feng": [0, ["Learning to Confuse: Generating Training Time Adversarial Data with Auto-Encoder", ["Ji Feng", "Qi-Zhi Cai", "Zhi-Hua Zhou"], "http://papers.nips.cc/paper/9368-learning-to-confuse-generating-training-time-adversarial-data-with-auto-encoder", 11, "neurips", 2019]], "Tengyang Xie": [0, ["Towards Optimal Off-Policy Evaluation for Reinforcement Learning with Marginalized Importance Sampling", ["Tengyang Xie", "Yifei Ma", "Yu-Xiang Wang"], "http://papers.nips.cc/paper/9161-towards-optimal-off-policy-evaluation-for-reinforcement-learning-with-marginalized-importance-sampling", 11, "neurips", 2019]], "Anuj Mahajan": [0, ["MAVEN: Multi-Agent Variational Exploration", ["Anuj Mahajan", "Tabish Rashid", "Mikayel Samvelyan", "Shimon Whiteson"], "http://papers.nips.cc/paper/8978-maven-multi-agent-variational-exploration", 12, "neurips", 2019]], "Srinath Sridhar": [0, ["Multiview Aggregation for Learning Category-Specific Shape Reconstruction", ["Srinath Sridhar", "Davis Rempe", "Julien Valentin", "Sofien Bouaziz", "Leonidas J. Guibas"], "http://papers.nips.cc/paper/8506-multiview-aggregation-for-learning-category-specific-shape-reconstruction", 12, "neurips", 2019]], "Pei Wang": [0.00034807989868568256, ["Deliberative Explanations: visualizing network insecurities", ["Pei Wang", "Nuno Nasconcelos"], "http://papers.nips.cc/paper/8418-deliberative-explanations-visualizing-network-insecurities", 12, "neurips", 2019]], "Tianjun Zhang": [0, ["ANODEV2: A Coupled Neural ODE Framework", ["Tianjun Zhang", "Zhewei Yao", "Amir Gholami", "Joseph E. Gonzalez", "Kurt Keutzer", "Michael W. Mahoney", "George Biros"], "http://papers.nips.cc/paper/8758-anodev2-a-coupled-neural-ode-framework", 11, "neurips", 2019]], "Nicki Skafte Detlefsen": [0, ["Explicit Disentanglement of Appearance and Perspective in Generative Models", ["Nicki Skafte Detlefsen", "Soren Hauberg"], "http://papers.nips.cc/paper/8387-explicit-disentanglement-of-appearance-and-perspective-in-generative-models", 11, "neurips", 2019], ["Reliable training and estimation of variance networks", ["Nicki Skafte Detlefsen", "Martin Jorgensen", "Soren Hauberg"], "http://papers.nips.cc/paper/8862-reliable-training-and-estimation-of-variance-networks", 11, "neurips", 2019]], "Rui Li": [0, ["Multivariate Sparse Coding of Nonstationary Covariances with Gaussian Processes", ["Rui Li"], "http://papers.nips.cc/paper/8439-multivariate-sparse-coding-of-nonstationary-covariances-with-gaussian-processes", 10, "neurips", 2019]], "Renjie Liao": [0, ["Efficient Graph Generation with Graph Recurrent Attention Networks", ["Renjie Liao", "Yujia Li", "Yang Song", "Shenlong Wang", "William L. Hamilton", "David Duvenaud", "Raquel Urtasun", "Richard S. Zemel"], "http://papers.nips.cc/paper/8678-efficient-graph-generation-with-graph-recurrent-attention-networks", 11, "neurips", 2019]], "Shahana Ibrahim": [0, ["Crowdsourcing via Pairwise Co-occurrences: Identifiability and Algorithms", ["Shahana Ibrahim", "Xiao Fu", "Nikolaos Kargas", "Kejun Huang"], "http://papers.nips.cc/paper/8999-crowdsourcing-via-pairwise-co-occurrences-identifiability-and-algorithms", 11, "neurips", 2019]], "Sepehr Assadi": [0, ["Secretary Ranking with Minimal Inversions", ["Sepehr Assadi", "Eric Balkanski", "Renato Paes Leme"], "http://papers.nips.cc/paper/8390-secretary-ranking-with-minimal-inversions", 13, "neurips", 2019]], "Aria Wang": [3.3687280847516377e-05, ["Neural Taskonomy: Inferring the Similarity of Task-Derived Representations from Brain Activity", ["Aria Wang", "Michael J. Tarr", "Leila Wehbe"], "http://papers.nips.cc/paper/9683-neural-taskonomy-inferring-the-similarity-of-task-derived-representations-from-brain-activity", 11, "neurips", 2019]], "Ehsan Amid": [0, ["Robust Bi-Tempered Logistic Loss Based on Bregman Divergences", ["Ehsan Amid", "Manfred K. Warmuth", "Rohan Anil", "Tomer Koren"], "http://papers.nips.cc/paper/9638-robust-bi-tempered-logistic-loss-based-on-bregman-divergences", 10, "neurips", 2019]], "Mitchell Wortsman": [0, ["Discovering Neural Wirings", ["Mitchell Wortsman", "Ali Farhadi", "Mohammad Rastegari"], "http://papers.nips.cc/paper/8536-discovering-neural-wirings", 11, "neurips", 2019]], "Ke Li": [0, ["Approximate Feature Collisions in Neural Nets", ["Ke Li", "Tianhao Zhang", "Jitendra Malik"], "http://papers.nips.cc/paper/9713-approximate-feature-collisions-in-neural-nets", 9, "neurips", 2019]], "Chris Criscitiello": [0, ["Efficiently escaping saddle points on manifolds", ["Chris Criscitiello", "Nicolas Boumal"], "http://papers.nips.cc/paper/8832-efficiently-escaping-saddle-points-on-manifolds", 11, "neurips", 2019]], "Nirandika Wanigasekara": [0, ["Nonparametric Contextual Bandits in Metric Spaces with Unknown Metric", ["Nirandika Wanigasekara", "Christina Lee Yu"], "http://papers.nips.cc/paper/9609-nonparametric-contextual-bandits-in-metric-spaces-with-unknown-metric", 11, "neurips", 2019]], "Peilin Zhong": [0, ["Rethinking Generative Mode Coverage: A Pointwise Guaranteed Approach", ["Peilin Zhong", "Yuchen Mo", "Chang Xiao", "Pengyu Chen", "Changxi Zheng"], "http://papers.nips.cc/paper/8482-rethinking-generative-mode-coverage-a-pointwise-guaranteed-approach", 12, "neurips", 2019]], "Jean-Baptiste Alayrac": [0, ["Are Labels Required for Improving Adversarial Robustness?", ["Jean-Baptiste Alayrac", "Jonathan Uesato", "Po-Sen Huang", "Alhussein Fawzi", "Robert Stanforth", "Pushmeet Kohli"], "http://papers.nips.cc/paper/9388-are-labels-required-for-improving-adversarial-robustness", 11, "neurips", 2019]], "Mickael Chen": [0, ["Unsupervised Object Segmentation by Redrawing", ["Mickael Chen", "Thierry Artieres", "Ludovic Denoyer"], "http://papers.nips.cc/paper/9434-unsupervised-object-segmentation-by-redrawing", 12, "neurips", 2019]], "Ankesh Anand": [0, ["Unsupervised State Representation Learning in Atari", ["Ankesh Anand", "Evan Racah", "Sherjil Ozair", "Yoshua Bengio", "Marc-Alexandre Cote", "R. Devon Hjelm"], "http://papers.nips.cc/paper/9081-unsupervised-state-representation-learning-in-atari", 14, "neurips", 2019]], "Fuwen Tan": [0, ["Drill-down: Interactive Retrieval of Complex Scenes using Natural Language Queries", ["Fuwen Tan", "Paola Cascante-Bonilla", "Xiaoxiao Guo", "Hui Wu", "Song Feng", "Vicente Ordonez"], "http://papers.nips.cc/paper/8533-drill-down-interactive-retrieval-of-complex-scenes-using-natural-language-queries", 11, "neurips", 2019]], "Anna Wigren": [0, ["Parameter elimination in particle Gibbs sampling", ["Anna Wigren", "Riccardo Sven Risuleo", "Lawrence Murray", "Fredrik Lindsten"], "http://papers.nips.cc/paper/9094-parameter-elimination-in-particle-gibbs-sampling", 12, "neurips", 2019]], "Cyprien de Masson dAutume": [0, ["Training Language GANs from Scratch", ["Cyprien de Masson dAutume", "Shakir Mohamed", "Mihaela Rosca", "Jack W. Rae"], "http://papers.nips.cc/paper/8682-training-language-gans-from-scratch", 12, "neurips", 2019], ["Episodic Memory in Lifelong Language Learning", ["Cyprien de Masson dAutume", "Sebastian Ruder", "Lingpeng Kong", "Dani Yogatama"], "http://papers.nips.cc/paper/9471-episodic-memory-in-lifelong-language-learning", 10, "neurips", 2019]], "Xindian Ma": [0, ["A Tensorized Transformer for Language Modeling", ["Xindian Ma", "Peng Zhang", "Shuai Zhang", "Nan Duan", "Yuexian Hou", "Ming Zhou", "Dawei Song"], "http://papers.nips.cc/paper/8495-a-tensorized-transformer-for-language-modeling", 11, "neurips", 2019]], "Zongsheng Yue": [0, ["Variational Denoising Network: Toward Blind Noise Modeling and Removal", ["Zongsheng Yue", "Hongwei Yong", "Qian Zhao", "Deyu Meng", "Lei Zhang"], "http://papers.nips.cc/paper/8446-variational-denoising-network-toward-blind-noise-modeling-and-removal", 12, "neurips", 2019]], "Emily Reif": [0, ["Visualizing and Measuring the Geometry of BERT", ["Emily Reif", "Ann Yuan", "Martin Wattenberg", "Fernanda B. Viegas", "Andy Coenen", "Adam Pearce", "Been Kim"], "http://papers.nips.cc/paper/9065-visualizing-and-measuring-the-geometry-of-bert", 9, "neurips", 2019]], "Paulina Grnarova": [0, ["A Domain Agnostic Measure for Monitoring and Evaluating GANs", ["Paulina Grnarova", "Kfir Y. Levy", "Aurelien Lucchi", "Nathanael Perraudin", "Ian Goodfellow", "Thomas Hofmann", "Andreas Krause"], "http://papers.nips.cc/paper/9377-a-domain-agnostic-measure-for-monitoring-and-evaluating-gans", 11, "neurips", 2019]], "Hattie Zhou": [0, ["Deconstructing Lottery Tickets: Zeros, Signs, and the Supermask", ["Hattie Zhou", "Janice Lan", "Rosanne Liu", "Jason Yosinski"], "http://papers.nips.cc/paper/8618-deconstructing-lottery-tickets-zeros-signs-and-the-supermask", 11, "neurips", 2019]], "Sivan Sabato": [0, ["Epsilon-Best-Arm Identification in Pay-Per-Reward Multi-Armed Bandits", ["Sivan Sabato"], "http://papers.nips.cc/paper/8554-epsilon-best-arm-identification-in-pay-per-reward-multi-armed-bandits", 11, "neurips", 2019]], "Zakaria Mhammedi": [0, ["PAC-Bayes Un-Expected Bernstein Inequality", ["Zakaria Mhammedi", "Peter Grunwald", "Benjamin Guedj"], "http://papers.nips.cc/paper/9387-pac-bayes-un-expected-bernstein-inequality", 12, "neurips", 2019]], "Kishor Jothimurugan": [0, ["A Composable Specification Language for Reinforcement Learning Tasks", ["Kishor Jothimurugan", "Rajeev Alur", "Osbert Bastani"], "http://papers.nips.cc/paper/9462-a-composable-specification-language-for-reinforcement-learning-tasks", 10, "neurips", 2019]], "Patrick Putzky": [0, ["Invert to Learn to Invert", ["Patrick Putzky", "Max Welling"], "http://papers.nips.cc/paper/8336-invert-to-learn-to-invert", 11, "neurips", 2019]], "Yifan Sun": [0.0002331648356630467, ["Learning low-dimensional state embeddings and metastable clusters from time series data", ["Yifan Sun", "Yaqi Duan", "Hao Gong", "Mengdi Wang"], "http://papers.nips.cc/paper/8705-learning-low-dimensional-state-embeddings-and-metastable-clusters-from-time-series-data", 10, "neurips", 2019]], "Zihan Zhang": [0, ["Regret Minimization for Reinforcement Learning by Evaluating the Optimal Bias Function", ["Zihan Zhang", "Xiangyang Ji"], "http://papers.nips.cc/paper/8549-regret-minimization-for-reinforcement-learning-by-evaluating-the-optimal-bias-function", 10, "neurips", 2019]], "Giulia Luise": [0, ["Sinkhorn Barycenters with Free Support via Frank-Wolfe Algorithm", ["Giulia Luise", "Saverio Salzo", "Massimiliano Pontil", "Carlo Ciliberto"], "http://papers.nips.cc/paper/9130-sinkhorn-barycenters-with-free-support-via-frank-wolfe-algorithm", 12, "neurips", 2019]], "Xuezhe Ma": [0, ["MaCow: Masked Convolutional Generative Flow", ["Xuezhe Ma", "Xiang Kong", "Shanghang Zhang", "Eduard H. Hovy"], "http://papers.nips.cc/paper/8824-macow-masked-convolutional-generative-flow", 10, "neurips", 2019]], "Jianghong Shi": [0, ["Comparison Against Task Driven Artificial Neural Networks Reveals Functional Properties in Mouse Visual Cortex", ["Jianghong Shi", "Eric Shea-Brown", "Michael A. Buice"], "http://papers.nips.cc/paper/8813-comparison-against-task-driven-artificial-neural-networks-reveals-functional-properties-in-mouse-visual-cortex", 11, "neurips", 2019]], "Aditya Grover": [0, ["Bias Correction of Learned Generative Models using Likelihood-Free Importance Weighting", ["Aditya Grover", "Jiaming Song", "Ashish Kapoor", "Kenneth Tran", "Alekh Agarwal", "Eric Horvitz", "Stefano Ermon"], "http://papers.nips.cc/paper/9286-bias-correction-of-learned-generative-models-using-likelihood-free-importance-weighting", 13, "neurips", 2019]], "Yukai Liu": [0, ["NAOMI: Non-Autoregressive Multiresolution Sequence Imputation", ["Yukai Liu", "Rose Yu", "Stephan Zheng", "Eric Zhan", "Yisong Yue"], "http://papers.nips.cc/paper/9302-naomi-non-autoregressive-multiresolution-sequence-imputation", 11, "neurips", 2019]], "Nathan Kallus": [0, ["Intrinsically Efficient, Stable, and Bounded Off-Policy Evaluation for Reinforcement Learning", ["Nathan Kallus", "Masatoshi Uehara"], "http://papers.nips.cc/paper/8594-intrinsically-efficient-stable-and-bounded-off-policy-evaluation-for-reinforcement-learning", 10, "neurips", 2019], ["Assessing Disparate Impact of Personalized Interventions: Identifiability and Bounds", ["Nathan Kallus", "Angela Zhou"], "http://papers.nips.cc/paper/8603-assessing-disparate-impact-of-personalized-interventions-identifiability-and-bounds", 12, "neurips", 2019], ["The Fairness of Risk Scores Beyond Classification: Bipartite Ranking and the XAUC Metric", ["Nathan Kallus", "Angela Zhou"], "http://papers.nips.cc/paper/8604-the-fairness-of-risk-scores-beyond-classification-bipartite-ranking-and-the-xauc-metric", 11, "neurips", 2019]], "Johannes Klicpera": [0, ["Diffusion Improves Graph Learning", ["Johannes Klicpera", "Stefan Weissenberger", "Stephan Gunnemann"], "http://papers.nips.cc/paper/9490-diffusion-improves-graph-learning", 13, "neurips", 2019]], "Pierre C. Bellec": [0, ["First order expansion of convex regularized estimators", ["Pierre C. Bellec", "Arun K. Kuchibhotla"], "http://papers.nips.cc/paper/8606-first-order-expansion-of-convex-regularized-estimators", 12, "neurips", 2019]], "Yi Tay": [0, ["Compositional De-Attention Networks", ["Yi Tay", "Anh Tuan Luu", "Aston Zhang", "Shuohang Wang", "Siu Cheung Hui"], "http://papers.nips.cc/paper/8845-compositional-de-attention-networks", 11, "neurips", 2019]], "Frank Ban": [0.0067706366535276175, ["Regularized Weighted Low Rank Approximation", ["Frank Ban", "David P. Woodruff", "Richard Zhang"], "http://papers.nips.cc/paper/8660-regularized-weighted-low-rank-approximation", 11, "neurips", 2019]], "Carl Allen": [0, ["What the Vec? Towards Probabilistically Grounded Embeddings", ["Carl Allen", "Ivana Balazevic", "Timothy M. Hospedales"], "http://papers.nips.cc/paper/8965-what-the-vec-towards-probabilistically-grounded-embeddings", 11, "neurips", 2019]], "Ming Hou": [0, ["Deep Multimodal Multilinear Fusion with High-order Polynomial Pooling", ["Ming Hou", "Jiajia Tang", "Jianhai Zhang", "Wanzeng Kong", "Qibin Zhao"], "http://papers.nips.cc/paper/9381-deep-multimodal-multilinear-fusion-with-high-order-polynomial-pooling", 10, "neurips", 2019]], "Yuan Deng": [0, ["Strategizing against No-regret Learners", ["Yuan Deng", "Jon Schneider", "Balasubramanian Sivan"], "http://papers.nips.cc/paper/8436-strategizing-against-no-regret-learners", 9, "neurips", 2019], ["Prior-Free Dynamic Auctions with Low Regret Buyers", ["Yuan Deng", "Jon Schneider", "Balasubramanian Sivan"], "http://papers.nips.cc/paper/8727-prior-free-dynamic-auctions-with-low-regret-buyers", 11, "neurips", 2019], ["A Robust Non-Clairvoyant Dynamic Mechanism for Contextual Auctions", ["Yuan Deng", "Sebastien Lahaie", "Vahab S. Mirrokni"], "http://papers.nips.cc/paper/9071-a-robust-non-clairvoyant-dynamic-mechanism-for-contextual-auctions", 11, "neurips", 2019]], "Faidra Georgia Monachou": [0, ["Discrimination in Online Markets: Effects of Social Bias on Learning from Reviews and Policy Design", ["Faidra Georgia Monachou", "Itai Ashlagi"], "http://papers.nips.cc/paper/8487-discrimination-in-online-markets-effects-of-social-bias-on-learning-from-reviews-and-policy-design", 11, "neurips", 2019]], "Jason Altschuler": [0, ["Massively scalable Sinkhorn distances via the Nystr\u00f6m method", ["Jason Altschuler", "Francis Bach", "Alessandro Rudi", "Jonathan Niles-Weed"], "http://papers.nips.cc/paper/8693-massively-scalable-sinkhorn-distances-via-the-nystrom-method", 11, "neurips", 2019]], "Ruiqi Gao": [0, ["Convergence of Adversarial Training in Overparametrized Neural Networks", ["Ruiqi Gao", "Tianle Cai", "Haochuan Li", "Cho-Jui Hsieh", "Liwei Wang", "Jason D. Lee"], "http://papers.nips.cc/paper/9461-convergence-of-adversarial-training-in-overparametrized-neural-networks", 12, "neurips", 2019]], "Sangwoo Mo": [1, ["Mining GOLD Samples for Conditional GANs", ["Sangwoo Mo", "Chiheon Kim", "Sungwoong Kim", "Minsu Cho", "Jinwoo Shin"], "http://papers.nips.cc/paper/8848-mining-gold-samples-for-conditional-gans", 12, "neurips", 2019]], "Aida Rahmattalabi": [0, ["Exploring Algorithmic Fairness in Robust Graph Covering Problems", ["Aida Rahmattalabi", "Phebe Vayanos", "Anthony Fulginiti", "Eric Rice", "Bryan Wilder", "Amulya Yadav", "Milind Tambe"], "http://papers.nips.cc/paper/9707-exploring-algorithmic-fairness-in-robust-graph-covering-problems", 12, "neurips", 2019]], "Kamil Ciosek": [0, ["Better Exploration with Optimistic Actor Critic", ["Kamil Ciosek", "Quan Vuong", "Robert Loftin", "Katja Hofmann"], "http://papers.nips.cc/paper/8455-better-exploration-with-optimistic-actor-critic", 12, "neurips", 2019]], "Alexej Klushyn": [0, ["Learning Hierarchical Priors in VAEs", ["Alexej Klushyn", "Nutan Chen", "Richard Kurle", "Botond Cseke", "Patrick van der Smagt"], "http://papers.nips.cc/paper/8553-learning-hierarchical-priors-in-vaes", 10, "neurips", 2019]], "Fuhai Chen": [0, ["Variational Structured Semantic Inference for Diverse Image Captioning", ["Fuhai Chen", "Rongrong Ji", "Jiayi Ji", "Xiaoshuai Sun", "Baochang Zhang", "Xuri Ge", "Yongjian Wu", "Feiyue Huang", "Yan Wang"], "http://papers.nips.cc/paper/8468-variational-structured-semantic-inference-for-diverse-image-captioning", 11, "neurips", 2019]], "Dominic Richards": [0, ["Optimal Statistical Rates for Decentralised Non-Parametric Regression with Linear Speed-Up", ["Dominic Richards", "Patrick Rebeschini"], "http://papers.nips.cc/paper/8405-optimal-statistical-rates-for-decentralised-non-parametric-regression-with-linear-speed-up", 12, "neurips", 2019]], "Alexander Trott": [0, ["Keeping Your Distance: Solving Sparse Reward Tasks Using Self-Balancing Shaped Rewards", ["Alexander Trott", "Stephan Zheng", "Caiming Xiong", "Richard Socher"], "http://papers.nips.cc/paper/9225-keeping-your-distance-solving-sparse-reward-tasks-using-self-balancing-shaped-rewards", 11, "neurips", 2019]], "Yunji Kim": [0.6550353765487671, ["Unsupervised Keypoint Learning for Guiding Class-Conditional Video Prediction", ["Yunji Kim", "Seonghyeon Nam", "In Cho", "Seon Joo Kim"], "http://papers.nips.cc/paper/8637-unsupervised-keypoint-learning-for-guiding-class-conditional-video-prediction", 11, "neurips", 2019]], "Hidenori Tanaka": [0, ["From deep learning to mechanistic understanding in neuroscience: the structure of retinal prediction", ["Hidenori Tanaka", "Aran Nayebi", "Niru Maheswaranathan", "Lane McIntosh", "Stephen Baccus", "Surya Ganguli"], "http://papers.nips.cc/paper/9060-from-deep-learning-to-mechanistic-understanding-in-neuroscience-the-structure-of-retinal-prediction", 11, "neurips", 2019]], "Chih-Kuan Yeh": [0, ["On the (In)fidelity and Sensitivity of Explanations", ["Chih-Kuan Yeh", "Cheng-Yu Hsieh", "Arun Sai Suggala", "David I. Inouye", "Pradeep Ravikumar"], "http://papers.nips.cc/paper/9278-on-the-infidelity-and-sensitivity-of-explanations", 12, "neurips", 2019]], "Andrea Zanette": [0, ["Limiting Extrapolation in Linear Approximate Value Iteration", ["Andrea Zanette", "Alessandro Lazaric", "Mykel J. Kochenderfer", "Emma Brunskill"], "http://papers.nips.cc/paper/8799-limiting-extrapolation-in-linear-approximate-value-iteration", 10, "neurips", 2019], ["Almost Horizon-Free Structure-Aware Best Policy Identification with a Generative Model", ["Andrea Zanette", "Mykel J. Kochenderfer", "Emma Brunskill"], "http://papers.nips.cc/paper/8800-almost-horizon-free-structure-aware-best-policy-identification-with-a-generative-model", 10, "neurips", 2019]], "Pierre Monteiller": [0, ["Alleviating Label Switching with Optimal Transport", ["Pierre Monteiller", "Sebastian Claici", "Edward Chien", "Farzaneh Mirzazadeh", "Justin M. Solomon", "Mikhail Yurochkin"], "http://papers.nips.cc/paper/9515-alleviating-label-switching-with-optimal-transport", 11, "neurips", 2019]], "Titouan Vayer": [0, ["Sliced Gromov-Wasserstein", ["Titouan Vayer", "Remi Flamary", "Nicolas Courty", "Romain Tavenard", "Laetitia Chapel"], "http://papers.nips.cc/paper/9615-sliced-gromov-wasserstein", 11, "neurips", 2019]], "Christian Schroder de Witt": [0, ["Multi-Agent Common Knowledge Reinforcement Learning", ["Christian Schroder de Witt", "Jakob N. Foerster", "Gregory Farquhar", "Philip H. S. Torr", "Wendelin Boehmer", "Shimon Whiteson"], "http://papers.nips.cc/paper/9184-multi-agent-common-knowledge-reinforcement-learning", 12, "neurips", 2019]], "Shuai Zhao": [0, ["Region Mutual Information Loss for Semantic Segmentation", ["Shuai Zhao", "Yang Wang", "Zheng Yang", "Deng Cai"], "http://papers.nips.cc/paper/9291-region-mutual-information-loss-for-semantic-segmentation", 11, "neurips", 2019]], "Yaniv Blumenfeld": [0, ["A Mean Field Theory of Quantized Deep Networks: The Quantization-Depth Trade-Off", ["Yaniv Blumenfeld", "Dar Gilboa", "Daniel Soudry"], "http://papers.nips.cc/paper/8926-a-mean-field-theory-of-quantized-deep-networks-the-quantization-depth-trade-off", 11, "neurips", 2019]], "Farzane Aminmansour": [0, ["Learning Macroscopic Brain Connectomes via Group-Sparse Factorization", ["Farzane Aminmansour", "Andrew Patterson", "Lei Le", "Yisu Peng", "Daniel Mitchell", "Franco Pestilli", "Cesar F. Caiafa", "Russell Greiner", "Martha White"], "http://papers.nips.cc/paper/9088-learning-macroscopic-brain-connectomes-via-group-sparse-factorization", 11, "neurips", 2019]], "Jinjin Tian": [0, ["ADDIS: an adaptive discarding algorithm for online FDR control with conservative nulls", ["Jinjin Tian", "Aaditya Ramdas"], "http://papers.nips.cc/paper/9136-addis-an-adaptive-discarding-algorithm-for-online-fdr-control-with-conservative-nulls", 9, "neurips", 2019]], "Dinesh Garg": [0, ["Quantum Embedding of Knowledge for Reasoning", ["Dinesh Garg", "Shajith Ikbal", "Santosh K. Srivastava", "Harit Vishwakarma", "Hima P. Karanam", "L. Venkata Subramaniam"], "http://papers.nips.cc/paper/8797-quantum-embedding-of-knowledge-for-reasoning", 11, "neurips", 2019]], "Shreyas Saxena": [0, ["Data Parameters: A New Family of Parameters for Learning a Differentiable Curriculum", ["Shreyas Saxena", "Oncel Tuzel", "Dennis DeCoste"], "http://papers.nips.cc/paper/9289-data-parameters-a-new-family-of-parameters-for-learning-a-differentiable-curriculum", 11, "neurips", 2019]], "Marcel Hirt": [0, ["Copula-like Variational Inference", ["Marcel Hirt", "Petros Dellaportas", "Alain Durmus"], "http://papers.nips.cc/paper/8561-copula-like-variational-inference", 13, "neurips", 2019]], "Amirmohammad Rooshenas": [0, ["Search-Guided, Lightly-Supervised Training of Structured Prediction Energy Networks", ["Amirmohammad Rooshenas", "Dongxu Zhang", "Gopal Sharma", "Andrew McCallum"], "http://papers.nips.cc/paper/9507-search-guided-lightly-supervised-training-of-structured-prediction-energy-networks", 11, "neurips", 2019]], "Santiago R. Balseiro": [0, ["Contextual Bandits with Cross-Learning", ["Santiago R. Balseiro", "Negin Golrezaei", "Mohammad Mahdian", "Vahab S. Mirrokni", "Jon Schneider"], "http://papers.nips.cc/paper/9162-contextual-bandits-with-cross-learning", 10, "neurips", 2019]], "Yanping Huang": [0, ["GPipe: Efficient Training of Giant Neural Networks using Pipeline Parallelism", ["Yanping Huang", "Youlong Cheng", "Ankur Bapna", "Orhan Firat", "Dehao Chen", "Mia Xu Chen", "HyoukJoong Lee", "Jiquan Ngiam", "Quoc V. Le", "Yonghui Wu", "Zhifeng Chen"], "http://papers.nips.cc/paper/8305-gpipe-efficient-training-of-giant-neural-networks-using-pipeline-parallelism", 10, "neurips", 2019]], "Huizhuo Yuan": [0, ["Efficient Smooth Non-Convex Stochastic Compositional Optimization via Stochastic Recursive Gradient Descent", ["Huizhuo Yuan", "Xiangru Lian", "Chris Junchi Li", "Ji Liu", "Wenqing Hu"], "http://papers.nips.cc/paper/8916-efficient-smooth-non-convex-stochastic-compositional-optimization-via-stochastic-recursive-gradient-descent", 10, "neurips", 2019]], "Maria-Florina Balcan": [0, ["Envy-Free Classification", ["Maria-Florina Balcan", "Travis Dick", "Ritesh Noothigattu", "Ariel D. Procaccia"], "http://papers.nips.cc/paper/8407-envy-free-classification", 11, "neurips", 2019]], "Felipe Tobar": [0, ["Band-Limited Gaussian Processes: The Sinc Kernel", ["Felipe Tobar"], "http://papers.nips.cc/paper/9436-band-limited-gaussian-processes-the-sinc-kernel", 11, "neurips", 2019]], "Yuan Liu": [0, ["GIFT: Learning Transformation-Invariant Dense Visual Descriptors via Group CNNs", ["Yuan Liu", "Zehong Shen", "Zhixuan Lin", "Sida Peng", "Hujun Bao", "Xiaowei Zhou"], "http://papers.nips.cc/paper/8922-gift-learning-transformation-invariant-dense-visual-descriptors-via-group-cnns", 12, "neurips", 2019]], "Russell Mendonca": [0, ["Guided Meta-Policy Search", ["Russell Mendonca", "Abhishek Gupta", "Rosen Kralev", "Pieter Abbeel", "Sergey Levine", "Chelsea Finn"], "http://papers.nips.cc/paper/9160-guided-meta-policy-search", 12, "neurips", 2019]], "Tianyi Liu": [0, ["Towards Understanding the Importance of Shortcut Connections in Residual Networks", ["Tianyi Liu", "Minshuo Chen", "Mo Zhou", "Simon S. Du", "Enlu Zhou", "Tuo Zhao"], "http://papers.nips.cc/paper/9003-towards-understanding-the-importance-of-shortcut-connections-in-residual-networks", 11, "neurips", 2019]], "Albert Shaw": [0, ["Meta Architecture Search", ["Albert Shaw", "Wei Wei", "Weiyang Liu", "Le Song", "Bo Dai"], "http://papers.nips.cc/paper/9301-meta-architecture-search", 11, "neurips", 2019]], "Yuanzhi Li": [0, ["Towards Explaining the Regularization Effect of Initial Large Learning Rate in Training Neural Networks", ["Yuanzhi Li", "Colin Wei", "Tengyu Ma"], "http://papers.nips.cc/paper/9341-towards-explaining-the-regularization-effect-of-initial-large-learning-rate-in-training-neural-networks", 12, "neurips", 2019]], "Edoardo Manino": [0, ["Streaming Bayesian Inference for Crowdsourced Classification", ["Edoardo Manino", "Long Tran-Thanh", "Nicholas R. Jennings"], "http://papers.nips.cc/paper/9439-streaming-bayesian-inference-for-crowdsourced-classification", 11, "neurips", 2019]], "Patrick Schwab": [0, ["CXPlain: Causal Explanations for Model Interpretation under Uncertainty", ["Patrick Schwab", "Walter Karlen"], "http://papers.nips.cc/paper/9211-cxplain-causal-explanations-for-model-interpretation-under-uncertainty", 11, "neurips", 2019]], "Raman Arora": [0, ["Bandits with Feedback Graphs and Switching Costs", ["Raman Arora", "Teodor Vanislavov Marinov", "Mehryar Mohri"], "http://papers.nips.cc/paper/9227-bandits-with-feedback-graphs-and-switching-costs", 11, "neurips", 2019], ["Efficient Convex Relaxations for Streaming PCA", ["Raman Arora", "Teodor Vanislavov Marinov"], "http://papers.nips.cc/paper/9236-efficient-convex-relaxations-for-streaming-pca", 10, "neurips", 2019], ["On Differentially Private Graph Sparsification and Applications", ["Raman Arora", "Jalaj Upadhyay"], "http://papers.nips.cc/paper/9494-on-differentially-private-graph-sparsification-and-applications", 12, "neurips", 2019]], "Jerome Revaud": [0, ["R2D2: Reliable and Repeatable Detector and Descriptor", ["Jerome Revaud", "Cesar Roberto de Souza", "Martin Humenberger", "Philippe Weinzaepfel"], "http://papers.nips.cc/paper/9407-r2d2-reliable-and-repeatable-detector-and-descriptor", 11, "neurips", 2019]], "Pratyusha Sharma": [0, ["Third-Person Visual Imitation Learning via Decoupled Hierarchical Controller", ["Pratyusha Sharma", "Deepak Pathak", "Abhinav Gupta"], "http://papers.nips.cc/paper/8528-third-person-visual-imitation-learning-via-decoupled-hierarchical-controller", 11, "neurips", 2019]], "Sulaiman A. Alghunaim": [0, ["A Linearly Convergent Proximal Gradient Algorithm for Decentralized Optimization", ["Sulaiman A. Alghunaim", "Kun Yuan", "Ali H. Sayed"], "http://papers.nips.cc/paper/8551-a-linearly-convergent-proximal-gradient-algorithm-for-decentralized-optimization", 11, "neurips", 2019]], "Ron Banner": [0, ["Post training 4-bit quantization of convolutional networks for rapid-deployment", ["Ron Banner", "Yury Nahshan", "Daniel Soudry"], "http://papers.nips.cc/paper/9008-post-training-4-bit-quantization-of-convolutional-networks-for-rapid-deployment", 9, "neurips", 2019]], "Chao Qu": [0, ["Value Propagation for Decentralized Networked Deep Multi-agent Reinforcement Learning", ["Chao Qu", "Shie Mannor", "Huan Xu", "Yuan Qi", "Le Song", "Junwu Xiong"], "http://papers.nips.cc/paper/8402-value-propagation-for-decentralized-networked-deep-multi-agent-reinforcement-learning", 10, "neurips", 2019]], "Marko Mitrovic": [0, ["Adaptive Sequence Submodularity", ["Marko Mitrovic", "Ehsan Kazemi", "Moran Feldman", "Andreas Krause", "Amin Karbasi"], "http://papers.nips.cc/paper/8776-adaptive-sequence-submodularity", 12, "neurips", 2019]], "Lin Song": [0.002806207921821624, ["Learnable Tree Filter for Structure-preserving Feature Transform", ["Lin Song", "Yanwei Li", "Zeming Li", "Gang Yu", "Hongbin Sun", "Jian Sun", "Nanning Zheng"], "http://papers.nips.cc/paper/8448-learnable-tree-filter-for-structure-preserving-feature-transform", 11, "neurips", 2019]], "Jean Pouget-Abadie": [0, ["Variance Reduction in Bipartite Experiments through Correlation Clustering", ["Jean Pouget-Abadie", "Kevin Aydin", "Warren Schudy", "Kay Brodersen", "Vahab S. Mirrokni"], "http://papers.nips.cc/paper/9486-variance-reduction-in-bipartite-experiments-through-correlation-clustering", 11, "neurips", 2019]], "Pim de Haan": [0, ["Causal Confusion in Imitation Learning", ["Pim de Haan", "Dinesh Jayaraman", "Sergey Levine"], "http://papers.nips.cc/paper/9343-causal-confusion-in-imitation-learning", 12, "neurips", 2019]], "Supratik Paul": [0, ["Fast Efficient Hyperparameter Tuning for Policy Gradient Methods", ["Supratik Paul", "Vitaly Kurin", "Shimon Whiteson"], "http://papers.nips.cc/paper/8710-fast-efficient-hyperparameter-tuning-for-policy-gradient-methods", 11, "neurips", 2019]], "Shali Jiang": [0, ["Cost Effective Active Search", ["Shali Jiang", "Roman Garnett", "Benjamin Moseley"], "http://papers.nips.cc/paper/8734-cost-effective-active-search", 10, "neurips", 2019]], "Ryoma Sato": [0, ["Approximation Ratios of Graph Neural Networks for Combinatorial Problems", ["Ryoma Sato", "Makoto Yamada", "Hisashi Kashima"], "http://papers.nips.cc/paper/8662-approximation-ratios-of-graph-neural-networks-for-combinatorial-problems", 10, "neurips", 2019]], "Pedro Mercado": [0, ["Generalized Matrix Means for Semi-Supervised Learning with Multilayer Graphs", ["Pedro Mercado", "Francesco Tudisco", "Matthias Hein"], "http://papers.nips.cc/paper/9626-generalized-matrix-means-for-semi-supervised-learning-with-multilayer-graphs", 10, "neurips", 2019]], "Thomas Lucas": [0, ["Adaptive Density Estimation for Generative Models", ["Thomas Lucas", "Konstantin Shmelkov", "Karteek Alahari", "Cordelia Schmid", "Jakob Verbeek"], "http://papers.nips.cc/paper/9370-adaptive-density-estimation-for-generative-models", 11, "neurips", 2019]], "Ali Kavis": [0, ["UniXGrad: A Universal, Adaptive Algorithm with Optimal Guarantees for Constrained Optimization", ["Ali Kavis", "Kfir Y. Levy", "Francis Bach", "Volkan Cevher"], "http://papers.nips.cc/paper/8856-unixgrad-a-universal-adaptive-algorithm-with-optimal-guarantees-for-constrained-optimization", 10, "neurips", 2019]], "Otilia Stretcu": [0, ["Graph Agreement Models for Semi-Supervised Learning", ["Otilia Stretcu", "Krishnamurthy Viswanathan", "Dana Movshovitz-Attias", "Emmanouil A. Platanios", "Sujith Ravi", "Andrew Tomkins"], "http://papers.nips.cc/paper/9076-graph-agreement-models-for-semi-supervised-learning", 11, "neurips", 2019]], "Naganand Yadati": [0, ["HyperGCN: A New Method For Training Graph Convolutional Networks on Hypergraphs", ["Naganand Yadati", "Madhav Nimishakavi", "Prateek Yadav", "Vikram Nitin", "Anand Louis", "Partha P. Talukdar"], "http://papers.nips.cc/paper/8430-hypergcn-a-new-method-for-training-graph-convolutional-networks-on-hypergraphs", 12, "neurips", 2019]], "Hao Zheng": [0, ["Cascaded Dilated Dense Network with Two-step Data Consistency for MRI Reconstruction", ["Hao Zheng", "Faming Fang", "Guixu Zhang"], "http://papers.nips.cc/paper/8451-cascaded-dilated-dense-network-with-two-step-data-consistency-for-mri-reconstruction", 11, "neurips", 2019]], "Maxime Bucher": [0, ["Zero-Shot Semantic Segmentation", ["Maxime Bucher", "Tuan-Hung Vu", "Matthieu Cord", "Patrick Perez"], "http://papers.nips.cc/paper/8338-zero-shot-semantic-segmentation", 12, "neurips", 2019]], "Duc Tam Nguyen": [0, ["DeepUSPS: Deep Robust Unsupervised Saliency Prediction via Self-supervision", ["Duc Tam Nguyen", "Maximilian Dax", "Chaithanya Kumar Mummadi", "Thi-Phuong-Nhung Ngo", "Thi Hoai Phuong Nguyen", "Zhongyu Lou", "Thomas Brox"], "http://papers.nips.cc/paper/8314-deepusps-deep-robust-unsupervised-saliency-prediction-via-self-supervision", 11, "neurips", 2019]], "Tianyu Guo": [0, ["Learning from Bad Data via Generation", ["Tianyu Guo", "Chang Xu", "Boxin Shi", "Chao Xu", "Dacheng Tao"], "http://papers.nips.cc/paper/8837-learning-from-bad-data-via-generation", 12, "neurips", 2019]], "Zhen Zhang": [0, ["KerGM: Kernelized Graph Matching", ["Zhen Zhang", "Yijian Xiang", "Lingfei Wu", "Bing Xue", "Arye Nehorai"], "http://papers.nips.cc/paper/8595-kergm-kernelized-graph-matching", 12, "neurips", 2019]], "Horia Mania": [0, ["Model Similarity Mitigates Test Set Overuse", ["Horia Mania", "John Miller", "Ludwig Schmidt", "Moritz Hardt", "Benjamin Recht"], "http://papers.nips.cc/paper/9190-model-similarity-mitigates-test-set-overuse", 10, "neurips", 2019], ["Certainty Equivalence is Efficient for Linear Quadratic Control", ["Horia Mania", "Stephen Tu", "Benjamin Recht"], "http://papers.nips.cc/paper/9205-certainty-equivalence-is-efficient-for-linear-quadratic-control", 11, "neurips", 2019]], "Thijs Vogels": [0, ["PowerSGD: Practical Low-Rank Gradient Compression for Distributed Optimization", ["Thijs Vogels", "Sai Praneeth Karimireddy", "Martin Jaggi"], "http://papers.nips.cc/paper/9571-powersgd-practical-low-rank-gradient-compression-for-distributed-optimization", 10, "neurips", 2019]], "Sajin Sasy": [0, ["Oblivious Sampling Algorithms for Private Data Analysis", ["Sajin Sasy", "Olga Ohrimenko"], "http://papers.nips.cc/paper/8877-oblivious-sampling-algorithms-for-private-data-analysis", 12, "neurips", 2019]], "Rinu Boney": [0, ["Regularizing Trajectory Optimization with Denoising Autoencoders", ["Rinu Boney", "Norman Di Palo", "Mathias Berglund", "Alexander Ilin", "Juho Kannala", "Antti Rasmus", "Harri Valpola"], "http://papers.nips.cc/paper/8552-regularizing-trajectory-optimization-with-denoising-autoencoders", 11, "neurips", 2019]], "Biao Zhang": [0, ["Root Mean Square Layer Normalization", ["Biao Zhang", "Rico Sennrich"], "http://papers.nips.cc/paper/9403-root-mean-square-layer-normalization", 12, "neurips", 2019]], "Andre Barreto": [0, ["The Option Keyboard: Combining Skills in Reinforcement Learning", ["Andre Barreto", "Diana Borsa", "Shaobo Hou", "Gheorghe Comanici", "Eser Aygun", "Philippe Hamel", "Daniel Toyama", "Jonathan J. Hunt", "Shibl Mourad", "David Silver", "Doina Precup"], "http://papers.nips.cc/paper/9463-the-option-keyboard-combining-skills-in-reinforcement-learning", 11, "neurips", 2019]], "Ashia C. Wilson": [0, ["Accelerating Rescaled Gradient Descent: Fast Optimization of Smooth Functions", ["Ashia C. Wilson", "Lester Mackey", "Andre Wibisono"], "http://papers.nips.cc/paper/9508-accelerating-rescaled-gradient-descent-fast-optimization-of-smooth-functions", 11, "neurips", 2019]], "Boyi Liu": [0, ["Neural Trust Region/Proximal Policy Optimization Attains Globally Optimal Policy", ["Boyi Liu", "Qi Cai", "Zhuoran Yang", "Zhaoran Wang"], "http://papers.nips.cc/paper/9242-neural-trust-regionproximal-policy-optimization-attains-globally-optimal-policy", 12, "neurips", 2019]], "Alex Wang": [1.0015459165138574e-11, ["SuperGLUE: A Stickier Benchmark for General-Purpose Language Understanding Systems", ["Alex Wang", "Yada Pruksachatkun", "Nikita Nangia", "Amanpreet Singh", "Julian Michael", "Felix Hill", "Omer Levy", "Samuel R. Bowman"], "http://papers.nips.cc/paper/8589-superglue-a-stickier-benchmark-for-general-purpose-language-understanding-systems", 15, "neurips", 2019]], "Li Kevin Wenliang": [0, ["A neurally plausible model for online recognition and postdiction in a dynamical environment", ["Li Kevin Wenliang", "Maneesh Sahani"], "http://papers.nips.cc/paper/9159-a-neurally-plausible-model-for-online-recognition-and-postdiction-in-a-dynamical-environment", 12, "neurips", 2019]], "Aditya Gangrade": [0, ["Efficient Near-Optimal Testing of Community Changes in Balanced Stochastic Block Models", ["Aditya Gangrade", "Praveen Venkatesh", "Bobak Nazer", "Venkatesh Saligrama"], "http://papers.nips.cc/paper/9224-efficient-near-optimal-testing-of-community-changes-in-balanced-stochastic-block-models", 12, "neurips", 2019]], "Alexey Ignatiev": [0, ["On Relating Explanations and Adversarial Examples", ["Alexey Ignatiev", "Nina Narodytska", "Joao Marques-Silva"], "http://papers.nips.cc/paper/9717-on-relating-explanations-and-adversarial-examples", 11, "neurips", 2019]], "Rahul Singh": [0, ["Kernel Instrumental Variable Regression", ["Rahul Singh", "Maneesh Sahani", "Arthur Gretton"], "http://papers.nips.cc/paper/8708-kernel-instrumental-variable-regression", 13, "neurips", 2019]], "Qitian Wu": [2.3774780061325274e-10, ["Learning Latent Process from High-Dimensional Event Sequences via Efficient Sampling", ["Qitian Wu", "Zixuan Zhang", "Xiaofeng Gao", "Junchi Yan", "Guihai Chen"], "http://papers.nips.cc/paper/8640-learning-latent-process-from-high-dimensional-event-sequences-via-efficient-sampling", 10, "neurips", 2019]], "Miguel Vaquero": [0, ["Convergence-Rate-Matching Discretization of Accelerated Optimization Flows Through Opportunistic State-Triggered Control", ["Miguel Vaquero", "Jorge Cortes"], "http://papers.nips.cc/paper/9170-convergence-rate-matching-discretization-of-accelerated-optimization-flows-through-opportunistic-state-triggered-control", 10, "neurips", 2019]], "Jen Ning Lim": [2.356360653266165e-06, ["Kernel Stein Tests for Multiple Model Comparison", ["Jen Ning Lim", "Makoto Yamada", "Bernhard Scholkopf", "Wittawat Jitkrittum"], "http://papers.nips.cc/paper/8496-kernel-stein-tests-for-multiple-model-comparison", 11, "neurips", 2019]], "Satoshi Hara": [0, ["Data Cleansing for Models Trained with SGD", ["Satoshi Hara", "Atsushi Nitanda", "Takanori Maehara"], "http://papers.nips.cc/paper/8674-data-cleansing-for-models-trained-with-sgd", 10, "neurips", 2019]], "Yichao Zhou": [0, ["NeurVPS: Neural Vanishing Point Scanning via Conic Convolution", ["Yichao Zhou", "Haozhi Qi", "Jingwei Huang", "Yi Ma"], "http://papers.nips.cc/paper/8373-neurvps-neural-vanishing-point-scanning-via-conic-convolution", 10, "neurips", 2019]], "Vineet Kosaraju": [0, ["Social-BiGAT: Multimodal Trajectory Forecasting using Bicycle-GAN and Graph Attention Networks", ["Vineet Kosaraju", "Amir Sadeghian", "Roberto Martin-Martin", "Ian D. Reid", "Hamid Rezatofighi", "Silvio Savarese"], "http://papers.nips.cc/paper/8308-social-bigat-multimodal-trajectory-forecasting-using-bicycle-gan-and-graph-attention-networks", 10, "neurips", 2019]], "Aditya Golatkar": [0, ["Time Matters in Regularizing Deep Networks: Weight Decay and Data Augmentation Affect Early Learning Dynamics, Matter Little Near Convergence", ["Aditya Golatkar", "Alessandro Achille", "Stefano Soatto"], "http://papers.nips.cc/paper/9252-time-matters-in-regularizing-deep-networks-weight-decay-and-data-augmentation-affect-early-learning-dynamics-matter-little-near-convergence", 11, "neurips", 2019]], "Ghassen Jerfel": [0, ["Reconciling meta-learning and continual learning with online mixtures of tasks", ["Ghassen Jerfel", "Erin Grant", "Tom Griffiths", "Katherine A. Heller"], "http://papers.nips.cc/paper/9112-reconciling-meta-learning-and-continual-learning-with-online-mixtures-of-tasks", 12, "neurips", 2019]], "Jie Ding": [0, ["Gradient Information for Representation and Modeling", ["Jie Ding", "A. Robert Calderbank", "Vahid Tarokh"], "http://papers.nips.cc/paper/8510-gradient-information-for-representation-and-modeling", 10, "neurips", 2019]], "Shashank Rajput": [0, ["DETOX: A Redundancy-based Framework for Faster and More Robust Gradient Aggregation", ["Shashank Rajput", "Hongyi Wang", "Zachary B. Charles", "Dimitris S. Papailiopoulos"], "http://papers.nips.cc/paper/9220-detox-a-redundancy-based-framework-for-faster-and-more-robust-gradient-aggregation", 11, "neurips", 2019]], "James Lucas": [0, ["Don't Blame the ELBO! A Linear VAE Perspective on Posterior Collapse", ["James Lucas", "George Tucker", "Roger B. Grosse", "Mohammad Norouzi"], "http://papers.nips.cc/paper/9138-dont-blame-the-elbo-a-linear-vae-perspective-on-posterior-collapse", 11, "neurips", 2019]], "Zhao Song": [7.501321078962064e-06, ["Efficient Symmetric Norm Regression via Linear Sketching", ["Zhao Song", "Ruosong Wang", "Lin Yang", "Hongyang Zhang", "Peilin Zhong"], "http://papers.nips.cc/paper/8370-efficient-symmetric-norm-regression-via-linear-sketching", 11, "neurips", 2019], ["Towards a Zero-One Law for Column Subset Selection", ["Zhao Song", "David P. Woodruff", "Peilin Zhong"], "http://papers.nips.cc/paper/8844-towards-a-zero-one-law-for-column-subset-selection", 12, "neurips", 2019], ["Average Case Column Subset Selection for Entrywise \ud835\udcc11-Norm Loss", ["Zhao Song", "David P. Woodruff", "Peilin Zhong"], "http://papers.nips.cc/paper/9201-average-case-column-subset-selection-for-entrywise-ell_1-norm-loss", 11, "neurips", 2019]], "Tomi Peltola": [0, ["Machine Teaching of Active Sequential Learners", ["Tomi Peltola", "Mustafa Mert Celikok", "Pedram Daee", "Samuel Kaski"], "http://papers.nips.cc/paper/9299-machine-teaching-of-active-sequential-learners", 12, "neurips", 2019]], "Siqi Liu": [0, ["Nonparametric Regressive Point Processes Based on Conditional Gaussian Processes", ["Siqi Liu", "Milos Hauskrecht"], "http://papers.nips.cc/paper/8391-nonparametric-regressive-point-processes-based-on-conditional-gaussian-processes", 11, "neurips", 2019]], "Heliang Zheng": [0, ["Learning Deep Bilinear Transformation for Fine-grained Image Representation", ["Heliang Zheng", "Jianlong Fu", "Zheng-Jun Zha", "Jiebo Luo"], "http://papers.nips.cc/paper/8680-learning-deep-bilinear-transformation-for-fine-grained-image-representation", 10, "neurips", 2019]], "Chieh Wu": [0.0029289291123859584, ["Solving Interpretable Kernel Dimensionality Reduction", ["Chieh Wu", "Jared Miller", "Yale Chang", "Mario Sznaier", "Jennifer G. Dy"], "http://papers.nips.cc/paper/9005-solving-interpretable-kernel-dimensionality-reduction", 11, "neurips", 2019]], "Jonas Mueller": [0, ["Low-Rank Bandit Methods for High-Dimensional Dynamic Pricing", ["Jonas Mueller", "Vasilis Syrgkanis", "Matt Taddy"], "http://papers.nips.cc/paper/9680-low-rank-bandit-methods-for-high-dimensional-dynamic-pricing", 11, "neurips", 2019]], "Lenaic Chizat": [0, ["On Lazy Training in Differentiable Programming", ["Lenaic Chizat", "Edouard Oyallon", "Francis Bach"], "http://papers.nips.cc/paper/8559-on-lazy-training-in-differentiable-programming", 11, "neurips", 2019]], "Artem Sobolev": [0, ["Importance Weighted Hierarchical Variational Inference", ["Artem Sobolev", "Dmitry P. Vetrov"], "http://papers.nips.cc/paper/8350-importance-weighted-hierarchical-variational-inference", 13, "neurips", 2019]], "Garrett Bernstein": [0, ["Differentially Private Bayesian Linear Regression", ["Garrett Bernstein", "Daniel R. Sheldon"], "http://papers.nips.cc/paper/8343-differentially-private-bayesian-linear-regression", 11, "neurips", 2019]], "Wesley J. Maddox": [0, ["A Simple Baseline for Bayesian Uncertainty in Deep Learning", ["Wesley J. Maddox", "Pavel Izmailov", "Timur Garipov", "Dmitry P. Vetrov", "Andrew Gordon Wilson"], "http://papers.nips.cc/paper/9472-a-simple-baseline-for-bayesian-uncertainty-in-deep-learning", 12, "neurips", 2019]], "Matthew Schlegel": [0, ["Importance Resampling for Off-policy Prediction", ["Matthew Schlegel", "Wesley Chung", "Daniel Graves", "Jian Qian", "Martha White"], "http://papers.nips.cc/paper/8456-importance-resampling-for-off-policy-prediction", 11, "neurips", 2019]], "Vaden Masrani": [0, ["The Thermodynamic Variational Objective", ["Vaden Masrani", "Tuan Anh Le", "Frank Wood"], "http://papers.nips.cc/paper/9328-the-thermodynamic-variational-objective", 10, "neurips", 2019]], "Hosein Hasani": [0, ["Surround Modulation: A Bio-inspired Connectivity Structure for Convolutional Neural Networks", ["Hosein Hasani", "Mahdieh Soleymani", "Hamid Aghajan"], "http://papers.nips.cc/paper/9719-surround-modulation-a-bio-inspired-connectivity-structure-for-convolutional-neural-networks", 12, "neurips", 2019]], "Lixin Fan": [0, ["Rethinking Deep Neural Network Ownership Verification: Embedding Passports to Defeat Ambiguity Attacks", ["Lixin Fan", "KamWoh Ng", "Chee Seng Chan"], "http://papers.nips.cc/paper/8719-rethinking-deep-neural-network-ownership-verification-embedding-passports-to-defeat-ambiguity-attacks", 10, "neurips", 2019]], "Mario Lezcano Casado": [0, ["Trivializations for Gradient-Based Optimization on Manifolds", ["Mario Lezcano Casado"], "http://papers.nips.cc/paper/9115-trivializations-for-gradient-based-optimization-on-manifolds", 11, "neurips", 2019]], "Mohammad Reza Keshtkaran": [0, ["Enabling hyperparameter optimization in sequential autoencoders for spiking neural data", ["Mohammad Reza Keshtkaran", "Chethan Pandarinath"], "http://papers.nips.cc/paper/9722-enabling-hyperparameter-optimization-in-sequential-autoencoders-for-spiking-neural-data", 11, "neurips", 2019]], "Adithya M. Devraj": [0, ["Stochastic Variance Reduced Primal Dual Algorithms for Empirical Composition Optimization", ["Adithya M. Devraj", "Jianshu Chen"], "http://papers.nips.cc/paper/9180-stochastic-variance-reduced-primal-dual-algorithms-for-empirical-composition-optimization", 11, "neurips", 2019]], "Dan Zhang": [0, ["Progressive Augmentation of GANs", ["Dan Zhang", "Anna Khoreva"], "http://papers.nips.cc/paper/8855-progressive-augmentation-of-gans", 11, "neurips", 2019]], "James P. Bailey": [0, ["Fast and Furious Learning in Zero-Sum Games: Vanishing Regret with Non-Vanishing Step Sizes", ["James P. Bailey", "Georgios Piliouras"], "http://papers.nips.cc/paper/9458-fast-and-furious-learning-in-zero-sum-games-vanishing-regret-with-non-vanishing-step-sizes", 11, "neurips", 2019]], "Micah Carroll": [0, ["On the Utility of Learning about Humans for Human-AI Coordination", ["Micah Carroll", "Rohin Shah", "Mark K. Ho", "Tom Griffiths", "Sanjit A. Seshia", "Pieter Abbeel", "Anca D. Dragan"], "http://papers.nips.cc/paper/8760-on-the-utility-of-learning-about-humans-for-human-ai-coordination", 12, "neurips", 2019]], "Hamid Shayestehmanesh": [0, ["Dying Experts: Efficient Algorithms with Optimal Regret Bounds", ["Hamid Shayestehmanesh", "Sajjad Azami", "Nishant A. Mehta"], "http://papers.nips.cc/paper/9189-dying-experts-efficient-algorithms-with-optimal-regret-bounds", 10, "neurips", 2019]], "Aravind Rajeswaran": [0, ["Meta-Learning with Implicit Gradients", ["Aravind Rajeswaran", "Chelsea Finn", "Sham M. Kakade", "Sergey Levine"], "http://papers.nips.cc/paper/8306-meta-learning-with-implicit-gradients", 12, "neurips", 2019]], "Bin Shi": [0, ["Acceleration via Symplectic Discretization of High-Resolution Differential Equations", ["Bin Shi", "Simon S. Du", "Weijie J. Su", "Michael I. Jordan"], "http://papers.nips.cc/paper/8811-acceleration-via-symplectic-discretization-of-high-resolution-differential-equations", 9, "neurips", 2019]], "Jenny Liu": [0, ["Graph Normalizing Flows", ["Jenny Liu", "Aviral Kumar", "Jimmy Ba", "Jamie Kiros", "Kevin Swersky"], "http://papers.nips.cc/paper/9510-graph-normalizing-flows", 11, "neurips", 2019]], "Meelis Kull": [0, ["Beyond temperature scaling: Obtaining well-calibrated multi-class probabilities with Dirichlet calibration", ["Meelis Kull", "Miquel Perello-Nieto", "Markus Kangsepp", "Telmo de Menezes e Silva Filho", "Hao Song", "Peter A. Flach"], "http://papers.nips.cc/paper/9397-beyond-temperature-scaling-obtaining-well-calibrated-multi-class-probabilities-with-dirichlet-calibration", 11, "neurips", 2019]], "Gilad Yehudai": [0, ["On the Power and Limitations of Random Features for Understanding Neural Networks", ["Gilad Yehudai", "Ohad Shamir"], "http://papers.nips.cc/paper/8886-on-the-power-and-limitations-of-random-features-for-understanding-neural-networks", 11, "neurips", 2019]], "Meng Fang": [0, ["Curriculum-guided Hindsight Experience Replay", ["Meng Fang", "Tianyi Zhou", "Yali Du", "Lei Han", "Zhengyou Zhang"], "http://papers.nips.cc/paper/9425-curriculum-guided-hindsight-experience-replay", 12, "neurips", 2019]], "Pasha Khosravi": [0, ["On Tractable Computation of Expected Predictions", ["Pasha Khosravi", "YooJung Choi", "Yitao Liang", "Antonio Vergari", "Guy Van den Broeck"], "http://papers.nips.cc/paper/9296-on-tractable-computation-of-expected-predictions", 12, "neurips", 2019]], "Soroush Nasiriany": [0, ["Planning with Goal-Conditioned Policies", ["Soroush Nasiriany", "Vitchyr Pong", "Steven Lin", "Sergey Levine"], "http://papers.nips.cc/paper/9623-planning-with-goal-conditioned-policies", 12, "neurips", 2019]], "Sicheng Zhao": [0, ["Multi-source Domain Adaptation for Semantic Segmentation", ["Sicheng Zhao", "Bo Li", "Xiangyu Yue", "Yang Gu", "Pengfei Xu", "Runbo Hu", "Hua Chai", "Kurt Keutzer"], "http://papers.nips.cc/paper/8949-multi-source-domain-adaptation-for-semantic-segmentation", 14, "neurips", 2019]], "Gregory Farquhar": [0, ["Loaded DiCE: Trading off Bias and Variance in Any-Order Score Function Gradient Estimators for Reinforcement Learning", ["Gregory Farquhar", "Shimon Whiteson", "Jakob N. Foerster"], "http://papers.nips.cc/paper/9026-loaded-dice-trading-off-bias-and-variance-in-any-order-score-function-gradient-estimators-for-reinforcement-learning", 12, "neurips", 2019]], "Ruho Kondo": [0, ["Flow-based Image-to-Image Translation with Feature Disentanglement", ["Ruho Kondo", "Keisuke Kawano", "Satoshi Koide", "Takuro Kutsuna"], "http://papers.nips.cc/paper/8670-flow-based-image-to-image-translation-with-feature-disentanglement", 11, "neurips", 2019]], "Adrian Rivera Cardoso": [0, ["Large Scale Markov Decision Processes with Changing Rewards", ["Adrian Rivera Cardoso", "He Wang", "Huan Xu"], "http://papers.nips.cc/paper/8505-large-scale-markov-decision-processes-with-changing-rewards", 11, "neurips", 2019]], "Phuong Ha Nguyen": [0, ["Tight Dimension Independent Lower Bound on the Expected Convergence Rate for Diminishing Step Sizes in SGD", ["Phuong Ha Nguyen", "Lam M. Nguyen", "Marten van Dijk"], "http://papers.nips.cc/paper/8624-tight-dimension-independent-lower-bound-on-the-expected-convergence-rate-for-diminishing-step-sizes-in-sgd", 10, "neurips", 2019]], "Alberto Maria Metelli": [0, ["Propagating Uncertainty in Reinforcement Learning via Wasserstein Barycenters", ["Alberto Maria Metelli", "Amarildo Likmeta", "Marcello Restelli"], "http://papers.nips.cc/paper/8685-propagating-uncertainty-in-reinforcement-learning-via-wasserstein-barycenters", 13, "neurips", 2019]], "Atsutoshi Kumagai": [0, ["Transfer Anomaly Detection by Inferring Latent Domain Representations", ["Atsutoshi Kumagai", "Tomoharu Iwata", "Yasuhiro Fujiwara"], "http://papers.nips.cc/paper/8517-transfer-anomaly-detection-by-inferring-latent-domain-representations", 11, "neurips", 2019]], "Zhuoning Yuan": [0, ["Stagewise Training Accelerates Convergence of Testing Error Over SGD", ["Zhuoning Yuan", "Yan Yan", "Rong Jin", "Tianbao Yang"], "http://papers.nips.cc/paper/8529-stagewise-training-accelerates-convergence-of-testing-error-over-sgd", 11, "neurips", 2019]], "Yiwei Liu": [0, ["REM: From Structural Entropy to Community Structure Deception", ["Yiwei Liu", "Jiamou Liu", "Zijian Zhang", "Liehuang Zhu", "Angsheng Li"], "http://papers.nips.cc/paper/9453-rem-from-structural-entropy-to-community-structure-deception", 11, "neurips", 2019]], "Jaehoon Lee": [0.9905749410390854, ["Wide Neural Networks of Any Depth Evolve as Linear Models Under Gradient Descent", ["Jaehoon Lee", "Lechao Xiao", "Samuel S. Schoenholz", "Yasaman Bahri", "Roman Novak", "Jascha Sohl-Dickstein", "Jeffrey Pennington"], "http://papers.nips.cc/paper/9063-wide-neural-networks-of-any-depth-evolve-as-linear-models-under-gradient-descent", 12, "neurips", 2019]], "Devin Reich": [0, ["Privacy-Preserving Classification of Personal Text Messages with Secure Multi-Party Computation", ["Devin Reich", "Ariel Todoki", "Rafael Dowsley", "Martine De Cock", "Anderson C. A. Nascimento"], "http://papers.nips.cc/paper/8632-privacy-preserving-classification-of-personal-text-messages-with-secure-multi-party-computation", 13, "neurips", 2019]], "Lukas Hoyer": [0, ["Grid Saliency for Context Explanations of Semantic Segmentation", ["Lukas Hoyer", "Mauricio Munoz", "Prateek Katiyar", "Anna Khoreva", "Volker Fischer"], "http://papers.nips.cc/paper/8874-grid-saliency-for-context-explanations-of-semantic-segmentation", 12, "neurips", 2019]], "Debmalya Mandal": [0, ["Efficient and Thrifty Voting by Any Means Necessary", ["Debmalya Mandal", "Ariel D. Procaccia", "Nisarg Shah", "David P. Woodruff"], "http://papers.nips.cc/paper/8939-efficient-and-thrifty-voting-by-any-means-necessary", 12, "neurips", 2019]], "Abraham Traore": [0, ["Singleshot : a scalable Tucker tensor decomposition", ["Abraham Traore", "Maxime Berar", "Alain Rakotomamonjy"], "http://papers.nips.cc/paper/8860-singleshot-a-scalable-tucker-tensor-decomposition", 12, "neurips", 2019]], "Jianlong Chang": [6.788372274968424e-06, ["DATA: Differentiable ArchiTecture Approximation", ["Jianlong Chang", "Xinbang Zhang", "Yiwen Guo", "Gaofeng Meng", "Shiming Xiang", "Chunhong Pan"], "http://papers.nips.cc/paper/8374-data-differentiable-architecture-approximation", 11, "neurips", 2019]], "Michela Meister": [0, ["Tight Dimensionality Reduction for Sketching Low Degree Polynomial Kernels", ["Michela Meister", "Tamas Sarlos", "David P. Woodruff"], "http://papers.nips.cc/paper/9144-tight-dimensionality-reduction-for-sketching-low-degree-polynomial-kernels", 12, "neurips", 2019]], "Kirill Neklyudov": [0, ["The Implicit Metropolis-Hastings Algorithm", ["Kirill Neklyudov", "Evgenii Egorov", "Dmitry P. Vetrov"], "http://papers.nips.cc/paper/9544-the-implicit-metropolis-hastings-algorithm", 11, "neurips", 2019]], "Weizhe Hua": [0, ["Channel Gating Neural Networks", ["Weizhe Hua", "Yuan Zhou", "Christopher De Sa", "Zhiru Zhang", "G. Edward Suh"], "http://papers.nips.cc/paper/8464-channel-gating-neural-networks", 11, "neurips", 2019]], "Othmane Sebbouh": [0, ["Towards closing the gap between the theory and practice of SVRG", ["Othmane Sebbouh", "Nidham Gazagnadou", "Samy Jelassi", "Francis Bach", "Robert M. Gower"], "http://papers.nips.cc/paper/8354-towards-closing-the-gap-between-the-theory-and-practice-of-svrg", 11, "neurips", 2019]], "Andrew Cotter": [0, ["On Making Stochastic Classifiers Deterministic", ["Andrew Cotter", "Maya R. Gupta", "Harikrishna Narasimhan"], "http://papers.nips.cc/paper/9273-on-making-stochastic-classifiers-deterministic", 11, "neurips", 2019]], "Shirin Jalali": [0, ["Efficient Deep Approximation of GMMs", ["Shirin Jalali", "Carl J. Nuzman", "Iraj Saniee"], "http://papers.nips.cc/paper/8704-efficient-deep-approximation-of-gmms", 9, "neurips", 2019]], "Maksym Andriushchenko": [0, ["Provably robust boosted decision stumps and trees against adversarial attacks", ["Maksym Andriushchenko", "Matthias Hein"], "http://papers.nips.cc/paper/9460-provably-robust-boosted-decision-stumps-and-trees-against-adversarial-attacks", 12, "neurips", 2019]], "Majid Abdolshah": [0, ["Multi-objective Bayesian optimisation with preferences over objectives", ["Majid Abdolshah", "Alistair Shilton", "Santu Rana", "Sunil Gupta", "Svetha Venkatesh"], "http://papers.nips.cc/paper/9390-multi-objective-bayesian-optimisation-with-preferences-over-objectives", 11, "neurips", 2019]], "Vincent S. Chen": [0, ["Slice-based Learning: A Programming Model for Residual Learning in Critical Data Slices", ["Vincent S. Chen", "Sen Wu", "Alexander J. Ratner", "Jen Weng", "Christopher Re"], "http://papers.nips.cc/paper/9137-slice-based-learning-a-programming-model-for-residual-learning-in-critical-data-slices", 11, "neurips", 2019]], "Xiaoming Yu": [2.4798990172578833e-13, ["Multi-mapping Image-to-Image Translation via Learning Disentanglement", ["Xiaoming Yu", "Yuanqi Chen", "Shan Liu", "Thomas H. Li", "Ge Li"], "http://papers.nips.cc/paper/8564-multi-mapping-image-to-image-translation-via-learning-disentanglement", 10, "neurips", 2019]], "Bingzhe Wu": [2.091187056851851e-09, ["Generalization in Generative Adversarial Networks: A Novel Perspective from Privacy Protection", ["Bingzhe Wu", "Shiwan Zhao", "Chaochao Chen", "Haoyang Xu", "Li Wang", "Xiaolu Zhang", "Guangyu Sun", "Jun Zhou"], "http://papers.nips.cc/paper/8323-generalization-in-generative-adversarial-networks-a-novel-perspective-from-privacy-protection", 11, "neurips", 2019]], "Sascha Saralajew": [0, ["Classification-by-Components: Probabilistic Modeling of Reasoning over a Set of Components", ["Sascha Saralajew", "Lars Holdijk", "Maike Rees", "Ebubekir Asan", "Thomas Villmann"], "http://papers.nips.cc/paper/8546-classification-by-components-probabilistic-modeling-of-reasoning-over-a-set-of-components", 12, "neurips", 2019]], "Samuel K. Ainsworth": [0, ["Mo' States Mo' Problems: Emergency Stop Mechanisms from Observation", ["Samuel K. Ainsworth", "Matt Barnes", "Siddhartha S. Srinivasa"], "http://papers.nips.cc/paper/9654-mo-states-mo-problems-emergency-stop-mechanisms-from-observation", 11, "neurips", 2019]], "Jiatao Gu": [1.0814749762388942e-08, ["Levenshtein Transformer", ["Jiatao Gu", "Changhan Wang", "Junbo Zhao"], "http://papers.nips.cc/paper/9297-levenshtein-transformer", 11, "neurips", 2019]], "Anette Hunziker": [0, ["Teaching Multiple Concepts to a Forgetful Learner", ["Anette Hunziker", "Yuxin Chen", "Oisin Mac Aodha", "Manuel Gomez Rodriguez", "Andreas Krause", "Pietro Perona", "Yisong Yue", "Adish Singla"], "http://papers.nips.cc/paper/8659-teaching-multiple-concepts-to-a-forgetful-learner", 11, "neurips", 2019]], "Anmol Kagrecha": [0, ["Distribution oblivious, risk-aware algorithms for multi-armed bandits with unbounded rewards", ["Anmol Kagrecha", "Jayakrishnan Nair", "Krishna P. Jagannathan"], "http://papers.nips.cc/paper/9305-distribution-oblivious-risk-aware-algorithms-for-multi-armed-bandits-with-unbounded-rewards", 10, "neurips", 2019]], "Yitian Yuan": [0, ["Semantic Conditioned Dynamic Modulation for Temporal Sentence Grounding in Videos", ["Yitian Yuan", "Lin Ma", "Jingwen Wang", "Wei Liu", "Wenwu Zhu"], "http://papers.nips.cc/paper/8344-semantic-conditioned-dynamic-modulation-for-temporal-sentence-grounding-in-videos", 11, "neurips", 2019]], "Blossom Metevier": [0, ["Offline Contextual Bandits with High Probability Fairness Guarantees", ["Blossom Metevier", "Stephen Giguere", "Sarah Brockman", "Ari Kobren", "Yuriy Brun", "Emma Brunskill", "Philip S. Thomas"], "http://papers.nips.cc/paper/9630-offline-contextual-bandits-with-high-probability-fairness-guarantees", 12, "neurips", 2019]], "Yan Zhang": [0, ["Deep Set Prediction Networks", ["Yan Zhang", "Jonathon S. Hare", "Adam Prugel-Bennett"], "http://papers.nips.cc/paper/8584-deep-set-prediction-networks", 11, "neurips", 2019]], "Jingxiang Lin": [0, ["TAB-VCR: Tags and Attributes based VCR Baselines", ["Jingxiang Lin", "Unnat Jain", "Alexander G. Schwing"], "http://papers.nips.cc/paper/9693-tab-vcr-tags-and-attributes-based-vcr-baselines", 14, "neurips", 2019]], "Boaz Barak": [0, ["(Nearly) Efficient Algorithms for the Graph Matching Problem on Correlated Random Graphs", ["Boaz Barak", "Chi-Ning Chou", "Zhixian Lei", "Tselil Schramm", "Yueqi Sheng"], "http://papers.nips.cc/paper/9118-nearly-efficient-algorithms-for-the-graph-matching-problem-on-correlated-random-graphs", 9, "neurips", 2019]], "Farnam Mansouri": [0, ["Preference-Based Batch and Sequential Teaching: Towards a Unified View of Models", ["Farnam Mansouri", "Yuxin Chen", "Ara Vartanian", "Xiaojin Jerry Zhu", "Adish Singla"], "http://papers.nips.cc/paper/9119-preference-based-batch-and-sequential-teaching-towards-a-unified-view-of-models", 11, "neurips", 2019]], "Francis Williams": [0, ["Gradient Dynamics of Shallow Univariate ReLU Networks", ["Francis Williams", "Matthew Trager", "Daniele Panozzo", "Claudio T. Silva", "Denis Zorin", "Joan Bruna"], "http://papers.nips.cc/paper/9046-gradient-dynamics-of-shallow-univariate-relu-networks", 10, "neurips", 2019]], "Suraj Srinivas": [0, ["Full-Gradient Representation for Neural Network Visualization", ["Suraj Srinivas", "Francois Fleuret"], "http://papers.nips.cc/paper/8666-full-gradient-representation-for-neural-network-visualization", 10, "neurips", 2019]], "Brandon Yang": [4.140001008678951e-09, ["CondConv: Conditionally Parameterized Convolutions for Efficient Inference", ["Brandon Yang", "Gabriel Bender", "Quoc V. Le", "Jiquan Ngiam"], "http://papers.nips.cc/paper/8412-condconv-conditionally-parameterized-convolutions-for-efficient-inference", 12, "neurips", 2019]], "Bao Wang": [0.004403092316351831, ["ResNets Ensemble via the Feynman-Kac Formalism to Improve Natural and Robust Accuracies", ["Bao Wang", "Zuoqiang Shi", "Stanley J. Osher"], "http://papers.nips.cc/paper/8443-resnets-ensemble-via-the-feynman-kac-formalism-to-improve-natural-and-robust-accuracies", 11, "neurips", 2019]], "Matthew Joseph": [0, ["Locally Private Gaussian Estimation", ["Matthew Joseph", "Janardhan Kulkarni", "Jieming Mao", "Steven Z. Wu"], "http://papers.nips.cc/paper/8563-locally-private-gaussian-estimation", 10, "neurips", 2019]], "Zhengyuan Zhou": [0, ["Learning in Generalized Linear Contextual Bandits with Stochastic Delays", ["Zhengyuan Zhou", "Renyuan Xu", "Jose Blanchet"], "http://papers.nips.cc/paper/8762-learning-in-generalized-linear-contextual-bandits-with-stochastic-delays", 12, "neurips", 2019]], "Wenzheng Chen": [0, ["Learning to Predict 3D Objects with an Interpolation-based Differentiable Renderer", ["Wenzheng Chen", "Huan Ling", "Jun Gao", "Edward J. Smith", "Jaakko Lehtinen", "Alec Jacobson", "Sanja Fidler"], "http://papers.nips.cc/paper/9156-learning-to-predict-3d-objects-with-an-interpolation-based-differentiable-renderer", 12, "neurips", 2019]], "Brandon M. Anderson": [0, ["Cormorant: Covariant Molecular Neural Networks", ["Brandon M. Anderson", "Truong-Son Hy", "Risi Kondor"], "http://papers.nips.cc/paper/9596-cormorant-covariant-molecular-neural-networks", 10, "neurips", 2019]], "Ioannis Panageas": [0, ["First-order methods almost always avoid saddle points: The case of vanishing step-sizes", ["Ioannis Panageas", "Georgios Piliouras", "Xiao Wang"], "http://papers.nips.cc/paper/8875-first-order-methods-almost-always-avoid-saddle-points-the-case-of-vanishing-step-sizes", 10, "neurips", 2019]], "Arun Jambulapati": [0, ["A Direct tilde{O}(1/epsilon) Iteration Parallel Algorithm for Optimal Transport", ["Arun Jambulapati", "Aaron Sidford", "Kevin Tian"], "http://papers.nips.cc/paper/9313-a-direct-tildeo1epsilon-iteration-parallel-algorithm-for-optimal-transport", 12, "neurips", 2019]], "Songbai Yan": [0, ["The Label Complexity of Active Learning from Observational Data", ["Songbai Yan", "Kamalika Chaudhuri", "Tara Javidi"], "http://papers.nips.cc/paper/8457-the-label-complexity-of-active-learning-from-observational-data", 10, "neurips", 2019]], "Ananya Kumar": [0, ["Verified Uncertainty Calibration", ["Ananya Kumar", "Percy Liang", "Tengyu Ma"], "http://papers.nips.cc/paper/8635-verified-uncertainty-calibration", 12, "neurips", 2019]], "Ke Wang": [0.00021147707593627274, ["Controllable Unsupervised Text Attribute Transfer via Editing Entangled Latent Representation", ["Ke Wang", "Hang Hua", "Xiaojun Wan"], "http://papers.nips.cc/paper/9284-controllable-unsupervised-text-attribute-transfer-via-editing-entangled-latent-representation", 11, "neurips", 2019]], "Shengchao Liu": [0, ["N-Gram Graph: Simple Unsupervised Representation for Graphs, with Applications to Molecules", ["Shengchao Liu", "Mehmet Furkan Demirel", "Yingyu Liang"], "http://papers.nips.cc/paper/9054-n-gram-graph-simple-unsupervised-representation-for-graphs-with-applications-to-molecules", 13, "neurips", 2019]], "Sawyer Birnbaum": [0, ["Temporal FiLM: Capturing Long-Range Sequence Dependencies with Feature-Wise Modulations", ["Sawyer Birnbaum", "Volodymyr Kuleshov", "S. Zayd Enam", "Pang Wei Koh", "Stefano Ermon"], "http://papers.nips.cc/paper/9217-temporal-film-capturing-long-range-sequence-dependencies-with-feature-wise-modulations", 12, "neurips", 2019]], "Vickram Rajendran": [0, ["Accurate Layerwise Interpretable Competence Estimation", ["Vickram Rajendran", "William LeVine"], "http://papers.nips.cc/paper/9548-accurate-layerwise-interpretable-competence-estimation", 11, "neurips", 2019]], "John Lawson": [0, ["Energy-Inspired Models: Learning with Sampler-Induced Distributions", ["John Lawson", "George Tucker", "Bo Dai", "Rajesh Ranganath"], "http://papers.nips.cc/paper/9057-energy-inspired-models-learning-with-sampler-induced-distributions", 13, "neurips", 2019]], "Taesup Kim": [0.9957897365093231, ["Variational Temporal Abstraction", ["Taesup Kim", "Sungjin Ahn", "Yoshua Bengio"], "http://papers.nips.cc/paper/9332-variational-temporal-abstraction", 10, "neurips", 2019]], "Enrique Fita Sanmartin": [0, ["Probabilistic Watershed: Sampling all spanning forests for seeded segmentation and semi-supervised learning", ["Enrique Fita Sanmartin", "Sebastian Damrich", "Fred A. Hamprecht"], "http://papers.nips.cc/paper/8545-probabilistic-watershed-sampling-all-spanning-forests-for-seeded-segmentation-and-semi-supervised-learning", 12, "neurips", 2019]], "Aaron Klein": [0, ["Meta-Surrogate Benchmarking for Hyperparameter Optimization", ["Aaron Klein", "Zhenwen Dai", "Frank Hutter", "Neil D. Lawrence", "Javier Gonzalez"], "http://papers.nips.cc/paper/8857-meta-surrogate-benchmarking-for-hyperparameter-optimization", 11, "neurips", 2019]], "Yandong Wen": [0, ["Face Reconstruction from Voice using Generative Adversarial Networks", ["Yandong Wen", "Bhiksha Raj", "Rita Singh"], "http://papers.nips.cc/paper/8768-face-reconstruction-from-voice-using-generative-adversarial-networks", 10, "neurips", 2019]], "Mete Ozay": [0, ["Fine-grained Optimization of Deep Neural Networks", ["Mete Ozay"], "http://papers.nips.cc/paper/8425-fine-grained-optimization-of-deep-neural-networks", 11, "neurips", 2019]], "Junzhe Zhang": [0, ["Near-Optimal Reinforcement Learning in Dynamic Treatment Regimes", ["Junzhe Zhang", "Elias Bareinboim"], "http://papers.nips.cc/paper/9496-near-optimal-reinforcement-learning-in-dynamic-treatment-regimes", 11, "neurips", 2019]], "Edward Raff": [0, ["A Step Toward Quantifying Independently Reproducible Machine Learning Research", ["Edward Raff"], "http://papers.nips.cc/paper/8787-a-step-toward-quantifying-independently-reproducible-machine-learning-research", 11, "neurips", 2019]], "Bulat Ibragimov": [0, ["Minimal Variance Sampling in Stochastic Gradient Boosting", ["Bulat Ibragimov", "Gleb Gusev"], "http://papers.nips.cc/paper/9645-minimal-variance-sampling-in-stochastic-gradient-boosting", 11, "neurips", 2019]], "Hadi Salman": [0, ["A Convex Relaxation Barrier to Tight Robustness Verification of Neural Networks", ["Hadi Salman", "Greg Yang", "Huan Zhang", "Cho-Jui Hsieh", "Pengchuan Zhang"], "http://papers.nips.cc/paper/9176-a-convex-relaxation-barrier-to-tight-robustness-verification-of-neural-networks", 11, "neurips", 2019], ["Provably Robust Deep Learning via Adversarially Trained Smoothed Classifiers", ["Hadi Salman", "Jerry Li", "Ilya P. Razenshteyn", "Pengchuan Zhang", "Huan Zhang", "Sebastien Bubeck", "Greg Yang"], "http://papers.nips.cc/paper/9307-provably-robust-deep-learning-via-adversarially-trained-smoothed-classifiers", 12, "neurips", 2019]], "Andrea Celli": [0, ["Learning to Correlate in Multi-Player General-Sum Sequential Games", ["Andrea Celli", "Alberto Marchesi", "Tommaso Bianchi", "Nicola Gatti"], "http://papers.nips.cc/paper/9465-learning-to-correlate-in-multi-player-general-sum-sequential-games", 11, "neurips", 2019]], "Virag Shah": [0, ["Semi-Parametric Dynamic Contextual Pricing", ["Virag Shah", "Ramesh Johari", "Jose H. Blanchet"], "http://papers.nips.cc/paper/8507-semi-parametric-dynamic-contextual-pricing", 11, "neurips", 2019]], "Seungki Min": [0.999861553311348, ["Thompson Sampling with Information Relaxation Penalties", ["Seungki Min", "Costis Maglaras", "Ciamac C. Moallemi"], "http://papers.nips.cc/paper/8614-thompson-sampling-with-information-relaxation-penalties", 10, "neurips", 2019]], "Iordanis Kerenidis": [0, ["q-means: A quantum algorithm for unsupervised machine learning", ["Iordanis Kerenidis", "Jonas Landman", "Alessandro Luongo", "Anupam Prakash"], "http://papers.nips.cc/paper/8667-q-means-a-quantum-algorithm-for-unsupervised-machine-learning", 11, "neurips", 2019]], "Amir Abboud": [0, ["Subquadratic High-Dimensional Hierarchical Clustering", ["Amir Abboud", "Vincent Cohen-Addad", "Hussein Houdrouge"], "http://papers.nips.cc/paper/9333-subquadratic-high-dimensional-hierarchical-clustering", 11, "neurips", 2019]], "Yihe Dong": [0.002803687588311732, ["Quantum Entropy Scoring for Fast Robust Mean Estimation and Improved Outlier Detection", ["Yihe Dong", "Samuel B. Hopkins", "Jerry Li"], "http://papers.nips.cc/paper/8839-quantum-entropy-scoring-for-fast-robust-mean-estimation-and-improved-outlier-detection", 11, "neurips", 2019]], "Wieland Brendel": [0, ["Accurate, reliable and fast robustness evaluation", ["Wieland Brendel", "Jonas Rauber", "Matthias Kummerer", "Ivan Ustyuzhaninov", "Matthias Bethge"], "http://papers.nips.cc/paper/9446-accurate-reliable-and-fast-robustness-evaluation", 11, "neurips", 2019]], "Pavithra Prabhakar": [0, ["Abstraction based Output Range Analysis for Neural Networks", ["Pavithra Prabhakar", "Zahra Rahimi Afzal"], "http://papers.nips.cc/paper/9708-abstraction-based-output-range-analysis-for-neural-networks", 11, "neurips", 2019]], "Michael Zhu": [0, ["Sample Adaptive MCMC", ["Michael Zhu"], "http://papers.nips.cc/paper/9107-sample-adaptive-mcmc", 12, "neurips", 2019]], "Xueying Bai": [8.461930323111488e-10, ["A Model-Based Reinforcement Learning with Adversarial Training for Online Recommendation", ["Xueying Bai", "Jian Guan", "Hongning Wang"], "http://papers.nips.cc/paper/9257-a-model-based-reinforcement-learning-with-adversarial-training-for-online-recommendation", 12, "neurips", 2019]], "Othman El Balghiti": [0, ["Generalization Bounds in the Predict-then-Optimize Framework", ["Othman El Balghiti", "Adam N. Elmachtoub", "Paul Grigas", "Ambuj Tewari"], "http://papers.nips.cc/paper/9585-generalization-bounds-in-the-predict-then-optimize-framework", 10, "neurips", 2019]], "Xia Xiao": [0, ["AutoPrune: Automatic Network Pruning by Regularizing Auxiliary Parameters", ["Xia Xiao", "Zigeng Wang", "Sanguthevar Rajasekaran"], "http://papers.nips.cc/paper/9521-autoprune-automatic-network-pruning-by-regularizing-auxiliary-parameters", 11, "neurips", 2019]], "Khurram Javed": [0, ["Meta-Learning Representations for Continual Learning", ["Khurram Javed", "Martha White"], "http://papers.nips.cc/paper/8458-meta-learning-representations-for-continual-learning", 11, "neurips", 2019]], "Chris Wendler": [0, ["Powerset Convolutional Neural Networks", ["Chris Wendler", "Markus Puschel", "Dan Alistarh"], "http://papers.nips.cc/paper/8379-powerset-convolutional-neural-networks", 12, "neurips", 2019]], "Min-hwan Oh": [0.994071826338768, ["Thompson Sampling for Multinomial Logit Contextual Bandits", ["Min-hwan Oh", "Garud Iyengar"], "http://papers.nips.cc/paper/8578-thompson-sampling-for-multinomial-logit-contextual-bandits", 11, "neurips", 2019]], "Akihiro Kishimoto": [0, ["Depth-First Proof-Number Search with Heuristic Edge Cost and Application to Chemical Synthesis Planning", ["Akihiro Kishimoto", "Beat Buesser", "Bei Chen", "Adi Botea"], "http://papers.nips.cc/paper/8943-depth-first-proof-number-search-with-heuristic-edge-cost-and-application-to-chemical-synthesis-planning", 11, "neurips", 2019]], "Mikhail Yurochkin": [0, ["Hierarchical Optimal Transport for Document Representation", ["Mikhail Yurochkin", "Sebastian Claici", "Edward Chien", "Farzaneh Mirzazadeh", "Justin M. Solomon"], "http://papers.nips.cc/paper/8438-hierarchical-optimal-transport-for-document-representation", 11, "neurips", 2019], ["Scalable inference of topic evolution via models for latent geometric structures", ["Mikhail Yurochkin", "Zhiwei Fan", "Aritra Guha", "Paraschos Koutris", "XuanLong Nguyen"], "http://papers.nips.cc/paper/8829-scalable-inference-of-topic-evolution-via-models-for-latent-geometric-structures", 11, "neurips", 2019], ["Statistical Model Aggregation via Parameter Matching", ["Mikhail Yurochkin", "Mayank Agarwal", "Soumya Ghosh", "Kristjan H. Greenewald", "Trong Nghia Hoang"], "http://papers.nips.cc/paper/9277-statistical-model-aggregation-via-parameter-matching", 11, "neurips", 2019]], "Yunwen Lei": [0, ["Optimal Stochastic and Online Learning with Individual Iterates", ["Yunwen Lei", "Peng Yang", "Ke Tang", "Ding-Xuan Zhou"], "http://papers.nips.cc/paper/8781-optimal-stochastic-and-online-learning-with-individual-iterates", 11, "neurips", 2019]], "Jean-Yves Franceschi": [0, ["Unsupervised Scalable Representation Learning for Multivariate Time Series", ["Jean-Yves Franceschi", "Aymeric Dieuleveut", "Martin Jaggi"], "http://papers.nips.cc/paper/8713-unsupervised-scalable-representation-learning-for-multivariate-time-series", 12, "neurips", 2019]], "Jeremiah Z. Liu": [0, ["Accurate Uncertainty Estimation and Decomposition in Ensemble Learning", ["Jeremiah Z. Liu", "John W. Paisley", "Marianthi-Anna Kioumourtzoglou", "Brent Coull"], "http://papers.nips.cc/paper/9097-accurate-uncertainty-estimation-and-decomposition-in-ensemble-learning", 12, "neurips", 2019]], "Igor Colin": [0, ["Theoretical Limits of Pipeline Parallel Optimization and Application to Distributed Deep Learning", ["Igor Colin", "Ludovic Dos Santos", "Kevin Scaman"], "http://papers.nips.cc/paper/9402-theoretical-limits-of-pipeline-parallel-optimization-and-application-to-distributed-deep-learning", 10, "neurips", 2019]], "Tejas D. Kulkarni": [0, ["Unsupervised Learning of Object Keypoints for Perception and Control", ["Tejas D. Kulkarni", "Ankush Gupta", "Catalin Ionescu", "Sebastian Borgeaud", "Malcolm Reynolds", "Andrew Zisserman", "Volodymyr Mnih"], "http://papers.nips.cc/paper/9256-unsupervised-learning-of-object-keypoints-for-perception-and-control", 11, "neurips", 2019]], "Qianqian Xu": [0, ["iSplit LBI: Individualized Partial Ranking with Ties via Split LBI", ["Qianqian Xu", "Xinwei Sun", "Zhiyong Yang", "Xiaochun Cao", "Qingming Huang", "Yuan Yao"], "http://papers.nips.cc/paper/8645-isplit-lbi-individualized-partial-ranking-with-ties-via-split-lbi", 11, "neurips", 2019]], "Ximei Wang": [5.302365879700233e-09, ["Transferable Normalization: Towards Improving Transferability of Deep Neural Networks", ["Ximei Wang", "Ying Jin", "Mingsheng Long", "Jianmin Wang", "Michael I. Jordan"], "http://papers.nips.cc/paper/8470-transferable-normalization-towards-improving-transferability-of-deep-neural-networks", 11, "neurips", 2019]], "Janice Lan": [0, ["LCA: Loss Change Allocation for Neural Network Training", ["Janice Lan", "Rosanne Liu", "Hattie Zhou", "Jason Yosinski"], "http://papers.nips.cc/paper/8620-lca-loss-change-allocation-for-neural-network-training", 11, "neurips", 2019]], "Zuxuan Wu": [1.6713843642435222e-09, ["LiteEval: A Coarse-to-Fine Framework for Resource Efficient Video Recognition", ["Zuxuan Wu", "Caiming Xiong", "Yu-Gang Jiang", "Larry S. Davis"], "http://papers.nips.cc/paper/8993-liteeval-a-coarse-to-fine-framework-for-resource-efficient-video-recognition", 10, "neurips", 2019]], "Ankit Singh Rawat": [0, ["Sampled Softmax with Random Fourier Features", ["Ankit Singh Rawat", "Jiecao Chen", "Felix X. Yu", "Ananda Theertha Suresh", "Sanjiv Kumar"], "http://papers.nips.cc/paper/9535-sampled-softmax-with-random-fourier-features", 11, "neurips", 2019]], "Kimia Nadjahi": [0, ["Asymptotic Guarantees for Learning Generative Models with the Sliced-Wasserstein Distance", ["Kimia Nadjahi", "Alain Durmus", "Umut Simsekli", "Roland Badeau"], "http://papers.nips.cc/paper/8318-asymptotic-guarantees-for-learning-generative-models-with-the-sliced-wasserstein-distance", 11, "neurips", 2019]], "Dina Obeid": [0, ["Structured and Deep Similarity Matching via Structured and Deep Hebbian Networks", ["Dina Obeid", "Hugo Ramambason", "Cengiz Pehlevan"], "http://papers.nips.cc/paper/9674-structured-and-deep-similarity-matching-via-structured-and-deep-hebbian-networks", 10, "neurips", 2019]], "Sharon Zhou": [0, ["HYPE: A Benchmark for Human eYe Perceptual Evaluation of Generative Models", ["Sharon Zhou", "Mitchell L. Gordon", "Ranjay Krishna", "Austin Narcomey", "Li F. Fei-Fei", "Michael Bernstein"], "http://papers.nips.cc/paper/8605-hype-a-benchmark-for-human-eye-perceptual-evaluation-of-generative-models", 13, "neurips", 2019]], "Fariba Yousefi": [0, ["Multi-task Learning for Aggregated Data using Gaussian Processes", ["Fariba Yousefi", "Michael Thomas Smith", "Mauricio A. Alvarez"], "http://papers.nips.cc/paper/9644-multi-task-learning-for-aggregated-data-using-gaussian-processes", 11, "neurips", 2019]], "Guodong Zhang": [0, ["Fast Convergence of Natural Gradient Descent for Over-Parameterized Neural Networks", ["Guodong Zhang", "James Martens", "Roger B. Grosse"], "http://papers.nips.cc/paper/9020-fast-convergence-of-natural-gradient-descent-for-over-parameterized-neural-networks", 12, "neurips", 2019], ["Which Algorithmic Choices Matter at Which Batch Sizes? Insights From a Noisy Quadratic Model", ["Guodong Zhang", "Lala Li", "Zachary Nado", "James Martens", "Sushant Sachdeva", "George E. Dahl", "Christopher J. Shallue", "Roger B. Grosse"], "http://papers.nips.cc/paper/9030-which-algorithmic-choices-matter-at-which-batch-sizes-insights-from-a-noisy-quadratic-model", 12, "neurips", 2019]], "Aya Abdelsalam Ismail": [0, ["Input-Cell Attention Reduces Vanishing Saliency of Recurrent Neural Networks", ["Aya Abdelsalam Ismail", "Mohamed K. Gunady", "Luiz Pessoa", "Hector Corrada Bravo", "Soheil Feizi"], "http://papers.nips.cc/paper/9264-input-cell-attention-reduces-vanishing-saliency-of-recurrent-neural-networks", 11, "neurips", 2019]], "Quentin Bertrand": [0, ["Handling correlated and repeated measurements with the smoothed multivariate square-root Lasso", ["Quentin Bertrand", "Mathurin Massias", "Alexandre Gramfort", "Joseph Salmon"], "http://papers.nips.cc/paper/8651-handling-correlated-and-repeated-measurements-with-the-smoothed-multivariate-square-root-lasso", 12, "neurips", 2019]], "Paul Micaelli": [0, ["Zero-shot Knowledge Transfer via Adversarial Belief Matching", ["Paul Micaelli", "Amos J. Storkey"], "http://papers.nips.cc/paper/9151-zero-shot-knowledge-transfer-via-adversarial-belief-matching", 11, "neurips", 2019]], "Renato Negrinho": [0, ["Towards modular and programmable architecture search", ["Renato Negrinho", "Matthew R. Gormley", "Geoffrey J. Gordon", "Darshan Patil", "Nghia Le", "Daniel Ferreira"], "http://papers.nips.cc/paper/9524-towards-modular-and-programmable-architecture-search", 11, "neurips", 2019]], "Alix Lheritier": [0, ["Low-Complexity Nonparametric Bayesian Online Prediction with Universal Guarantees", ["Alix Lheritier", "Frederic Cazals"], "http://papers.nips.cc/paper/9600-low-complexity-nonparametric-bayesian-online-prediction-with-universal-guarantees", 10, "neurips", 2019]], "Debraj Basu": [0, ["Qsparse-local-SGD: Distributed SGD with Quantization, Sparsification and Local Computations", ["Debraj Basu", "Deepesh Data", "Can Karakus", "Suhas N. Diggavi"], "http://papers.nips.cc/paper/9610-qsparse-local-sgd-distributed-sgd-with-quantization-sparsification-and-local-computations", 12, "neurips", 2019]], "Kristof Meding": [0, ["Perceiving the arrow of time in autoregressive motion", ["Kristof Meding", "Dominik Janzing", "Bernhard Scholkopf", "Felix A. Wichmann"], "http://papers.nips.cc/paper/8502-perceiving-the-arrow-of-time-in-autoregressive-motion", 12, "neurips", 2019]], "Siavash Khodadadeh": [0, ["Unsupervised Meta-Learning for Few-Shot Image Classification", ["Siavash Khodadadeh", "Ladislau Boloni", "Mubarak Shah"], "http://papers.nips.cc/paper/9203-unsupervised-meta-learning-for-few-shot-image-classification", 11, "neurips", 2019]], "Scott Gigante": [0, ["Visualizing the PHATE of Neural Networks", ["Scott Gigante", "Adam S. Charles", "Smita Krishnaswamy", "Gal Mishne"], "http://papers.nips.cc/paper/8460-visualizing-the-phate-of-neural-networks", 12, "neurips", 2019]], "Cole L. Hurwitz": [0, ["Scalable Spike Source Localization in Extracellular Recordings using Amortized Variational Inference", ["Cole L. Hurwitz", "Kai Xu", "Akash Srivastava", "Alessio Paolo Buccino", "Matthias Hennig"], "http://papers.nips.cc/paper/8720-scalable-spike-source-localization-in-extracellular-recordings-using-amortized-variational-inference", 13, "neurips", 2019]], "Nikolaos Ignatiadis": [0, ["Covariate-Powered Empirical Bayes Estimation", ["Nikolaos Ignatiadis", "Stefan Wager"], "http://papers.nips.cc/paper/9157-covariate-powered-empirical-bayes-estimation", 13, "neurips", 2019]], "Andisheh Amrollahi": [0, ["Efficiently Learning Fourier Sparse Set Functions", ["Andisheh Amrollahi", "Amir Zandieh", "Michael Kapralov", "Andreas Krause"], "http://papers.nips.cc/paper/9648-efficiently-learning-fourier-sparse-set-functions", 10, "neurips", 2019]], "Yujiao Shi": [0, ["Spatial-Aware Feature Aggregation for Image based Cross-View Geo-Localization", ["Yujiao Shi", "Liu Liu", "Xin Yu", "Hongdong Li"], "http://papers.nips.cc/paper/9199-spatial-aware-feature-aggregation-for-image-based-cross-view-geo-localization", 11, "neurips", 2019]], "Natasa Tagasovska": [0, ["Single-Model Uncertainties for Deep Learning", ["Natasa Tagasovska", "David Lopez-Paz"], "http://papers.nips.cc/paper/8870-single-model-uncertainties-for-deep-learning", 12, "neurips", 2019], ["Copulas as High-Dimensional Generative Models: Vine Copula Autoencoders", ["Natasa Tagasovska", "Damien Ackerer", "Thibault Vatter"], "http://papers.nips.cc/paper/8880-copulas-as-high-dimensional-generative-models-vine-copula-autoencoders", 13, "neurips", 2019]], "Hunter Lang": [0, ["Using Statistics to Automate Stochastic Optimization", ["Hunter Lang", "Lin Xiao", "Pengchuan Zhang"], "http://papers.nips.cc/paper/9150-using-statistics-to-automate-stochastic-optimization", 11, "neurips", 2019]], "Florian Scheidegger": [0, ["Constrained deep neural network architecture search for IoT devices accounting for hardware calibration", ["Florian Scheidegger", "Luca Benini", "Costas Bekas", "A. Cristiano I. Malossi"], "http://papers.nips.cc/paper/8838-constrained-deep-neural-network-architecture-search-for-iot-devices-accounting-for-hardware-calibration", 11, "neurips", 2019]], "Minmin Chen": [0, ["Surrogate Objectives for Batch Policy Optimization in One-step Decision Making", ["Minmin Chen", "Ramki Gummadi", "Chris Harris", "Dale Schuurmans"], "http://papers.nips.cc/paper/9086-surrogate-objectives-for-batch-policy-optimization-in-one-step-decision-making", 11, "neurips", 2019]], "Simon S. Du": [0, ["Graph Neural Tangent Kernel: Fusing Graph Neural Networks with Graph Kernels", ["Simon S. Du", "Kangcheng Hou", "Ruslan Salakhutdinov", "Barnabas Poczos", "Ruosong Wang", "Keyulu Xu"], "http://papers.nips.cc/paper/8809-graph-neural-tangent-kernel-fusing-graph-neural-networks-with-graph-kernels", 11, "neurips", 2019], ["Provably Efficient Q-learning with Function Approximation via Distribution Shift Error Checking Oracle", ["Simon S. Du", "Yuping Luo", "Ruosong Wang", "Hanrui Zhang"], "http://papers.nips.cc/paper/9018-provably-efficient-q-learning-with-function-approximation-via-distribution-shift-error-checking-oracle", 11, "neurips", 2019]], "Benjamin Planche": [0, ["Incremental Scene Synthesis", ["Benjamin Planche", "Xuejian Rong", "Ziyan Wu", "Srikrishna Karanam", "Harald Kosch", "Yingli Tian", "Jan Ernst", "Andreas Hutter"], "http://papers.nips.cc/paper/8444-incremental-scene-synthesis", 11, "neurips", 2019]], "Wei Wang": [0.00018742437532637268, ["Backpropagation-Friendly Eigendecomposition", ["Wei Wang", "Zheng Dang", "Yinlin Hu", "Pascal Fua", "Mathieu Salzmann"], "http://papers.nips.cc/paper/8579-backpropagation-friendly-eigendecomposition", 9, "neurips", 2019]], "Kevin Ellis": [0, ["Write, Execute, Assess: Program Synthesis with a REPL", ["Kevin Ellis", "Maxwell I. Nye", "Yewen Pu", "Felix Sosa", "Josh Tenenbaum", "Armando Solar-Lezama"], "http://papers.nips.cc/paper/9116-write-execute-assess-program-synthesis-with-a-repl", 10, "neurips", 2019]], "Joshua Allen": [0, ["An Algorithmic Framework For Differentially Private Data Analysis on Trusted Processors", ["Joshua Allen", "Bolin Ding", "Janardhan Kulkarni", "Harsha Nori", "Olga Ohrimenko", "Sergey Yekhanin"], "http://papers.nips.cc/paper/9517-an-algorithmic-framework-for-differentially-private-data-analysis-on-trusted-processors", 12, "neurips", 2019]], "Ting-I Hsieh": [0, ["One-Shot Object Detection with Co-Attention and Co-Excitation", ["Ting-I Hsieh", "Yi-Chen Lo", "Hwann-Tzong Chen", "Tyng-Luh Liu"], "http://papers.nips.cc/paper/8540-one-shot-object-detection-with-co-attention-and-co-excitation", 10, "neurips", 2019]], "Ehsan Abbasi": [0, ["Universality in Learning from Linear Measurements", ["Ehsan Abbasi", "Fariborz Salehi", "Babak Hassibi"], "http://papers.nips.cc/paper/9404-universality-in-learning-from-linear-measurements", 11, "neurips", 2019]], "Zhiqi Bu": [0, ["Algorithmic Analysis and Statistical Estimation of SLOPE via Approximate Message Passing", ["Zhiqi Bu", "Jason Klusowski", "Cynthia Rush", "Weijie Su"], "http://papers.nips.cc/paper/9134-algorithmic-analysis-and-statistical-estimation-of-slope-via-approximate-message-passing", 11, "neurips", 2019]], "Robert M. Gower": [0, ["RSN: Randomized Subspace Newton", ["Robert M. Gower", "Dmitry Kovalev", "Felix Lieder", "Peter Richtarik"], "http://papers.nips.cc/paper/8351-rsn-randomized-subspace-newton", 10, "neurips", 2019]], "Jessica Finocchiaro": [0, ["An Embedding Framework for Consistent Polyhedral Surrogates", ["Jessica Finocchiaro", "Rafael M. Frongillo", "Bo Waggoner"], "http://papers.nips.cc/paper/9261-an-embedding-framework-for-consistent-polyhedral-surrogates", 11, "neurips", 2019]], "Carlos Riquelme": [0, ["Adaptive Temporal-Difference Learning for Policy Evaluation with Per-State Uncertainty Estimates", ["Carlos Riquelme", "Hugo Penedones", "Damien Vincent", "Hartmut Maennel", "Sylvain Gelly", "Timothy A. Mann", "Andre Barreto", "Gergely Neu"], "http://papers.nips.cc/paper/9359-adaptive-temporal-difference-learning-for-policy-evaluation-with-per-state-uncertainty-estimates", 11, "neurips", 2019]], "Weiwei Liu": [0, ["Copula Multi-label Learning", ["Weiwei Liu"], "http://papers.nips.cc/paper/8863-copula-multi-label-learning", 10, "neurips", 2019]], "Yilun Xu": [0, ["L_DMI: A Novel Information-theoretic Loss Function for Training Deep Nets Robust to Label Noise", ["Yilun Xu", "Peng Cao", "Yuqing Kong", "Yizhou Wang"], "http://papers.nips.cc/paper/8853-l_dmi-a-novel-information-theoretic-loss-function-for-training-deep-nets-robust-to-label-noise", 12, "neurips", 2019]], "David Durfee": [0, ["Practical Differentially Private Top-k Selection with Pay-what-you-get Composition", ["David Durfee", "Ryan M. Rogers"], "http://papers.nips.cc/paper/8612-practical-differentially-private-top-k-selection-with-pay-what-you-get-composition", 11, "neurips", 2019]], "Xiangyuan Zhang": [0, ["Non-Cooperative Inverse Reinforcement Learning", ["Xiangyuan Zhang", "Kaiqing Zhang", "Erik Miehling", "Tamer Basar"], "http://papers.nips.cc/paper/9145-non-cooperative-inverse-reinforcement-learning", 12, "neurips", 2019]], "Niki Parmar": [0, ["Stand-Alone Self-Attention in Vision Models", ["Niki Parmar", "Prajit Ramachandran", "Ashish Vaswani", "Irwan Bello", "Anselm Levskaya", "Jon Shlens"], "http://papers.nips.cc/paper/8302-stand-alone-self-attention-in-vision-models", 13, "neurips", 2019]], "Dirk van der Hoeven": [0, ["User-Specified Local Differential Privacy in Unconstrained Adaptive Online Learning", ["Dirk van der Hoeven"], "http://papers.nips.cc/paper/9557-user-specified-local-differential-privacy-in-unconstrained-adaptive-online-learning", 10, "neurips", 2019]], "Yangbangyan Jiang": [0, ["DM2C: Deep Mixed-Modal Clustering", ["Yangbangyan Jiang", "Qianqian Xu", "Zhiyong Yang", "Xiaochun Cao", "Qingming Huang"], "http://papers.nips.cc/paper/8823-dm2c-deep-mixed-modal-clustering", 11, "neurips", 2019]], "Junteng Jia": [0, ["Neural Jump Stochastic Differential Equations", ["Junteng Jia", "Austin R. Benson"], "http://papers.nips.cc/paper/9177-neural-jump-stochastic-differential-equations", 12, "neurips", 2019]], "Igor Kuralenok": [0, ["MonoForest framework for tree ensemble analysis", ["Igor Kuralenok", "Vasilii Ershov", "Igor Labutin"], "http://papers.nips.cc/paper/9530-monoforest-framework-for-tree-ensemble-analysis", 10, "neurips", 2019]], "Julaiti Alafate": [0, ["Faster Boosting with Smaller Memory", ["Julaiti Alafate", "Yoav Freund"], "http://papers.nips.cc/paper/9314-faster-boosting-with-smaller-memory", 10, "neurips", 2019]], "Li Dong": [0.00029262965836096555, ["Unified Language Model Pre-training for Natural Language Understanding and Generation", ["Li Dong", "Nan Yang", "Wenhui Wang", "Furu Wei", "Xiaodong Liu", "Yu Wang", "Jianfeng Gao", "Ming Zhou", "Hsiao-Wuen Hon"], "http://papers.nips.cc/paper/9464-unified-language-model-pre-training-for-natural-language-understanding-and-generation", 13, "neurips", 2019]], "Sebastien Bubeck": [0, ["Complexity of Highly Parallel Non-Smooth Convex Optimization", ["Sebastien Bubeck", "Qijia Jiang", "Yin Tat Lee", "Yuanzhi Li", "Aaron Sidford"], "http://papers.nips.cc/paper/9541-complexity-of-highly-parallel-non-smooth-convex-optimization", 10, "neurips", 2019]], "Gautam Kamath": [0, ["Differentially Private Algorithms for Learning Mixtures of Separated Gaussians", ["Gautam Kamath", "Or Sheffet", "Vikrant Singhal", "Jonathan Ullman"], "http://papers.nips.cc/paper/8311-differentially-private-algorithms-for-learning-mixtures-of-separated-gaussians", 13, "neurips", 2019]], "Zhitao Ying": [0, ["GNNExplainer: Generating Explanations for Graph Neural Networks", ["Zhitao Ying", "Dylan Bourgeois", "Jiaxuan You", "Marinka Zitnik", "Jure Leskovec"], "http://papers.nips.cc/paper/9123-gnnexplainer-generating-explanations-for-graph-neural-networks", 12, "neurips", 2019]], "Chengguang Xu": [0, ["Deep Supervised Summarization: Algorithm and Application to Learning Instructions", ["Chengguang Xu", "Ehsan Elhamifar"], "http://papers.nips.cc/paper/8395-deep-supervised-summarization-algorithm-and-application-to-learning-instructions", 12, "neurips", 2019]], "Gunpil Hwang": [0.9916882812976837, ["Bat-G net: Bat-inspired High-Resolution 3D Image Reconstruction using Ultrasonic Echoes", ["Gunpil Hwang", "Seohyeon Kim", "Hyeon-Min Bae"], "http://papers.nips.cc/paper/8629-bat-g-net-bat-inspired-high-resolution-3d-image-reconstruction-using-ultrasonic-echoes", 12, "neurips", 2019]], "Michal Derezinski": [0, ["Distributed estimation of the inverse Hessian by determinantal averaging", ["Michal Derezinski", "Michael W. Mahoney"], "http://papers.nips.cc/paper/9317-distributed-estimation-of-the-inverse-hessian-by-determinantal-averaging", 11, "neurips", 2019], ["Exact sampling of determinantal point processes with sublinear time preprocessing", ["Michal Derezinski", "Daniele Calandriello", "Michal Valko"], "http://papers.nips.cc/paper/9330-exact-sampling-of-determinantal-point-processes-with-sublinear-time-preprocessing", 13, "neurips", 2019]], "Sai Qian Zhang": [0, ["Efficient Communication in Multi-Agent Reinforcement Learning via Variance Based Control", ["Sai Qian Zhang", "Qi Zhang", "Jieyu Lin"], "http://papers.nips.cc/paper/8586-efficient-communication-in-multi-agent-reinforcement-learning-via-variance-based-control", 10, "neurips", 2019]], "Xiangyu Zheng": [0, ["Partitioning Structure Learning for Segmented Linear Regression Trees", ["Xiangyu Zheng", "Song Xi Chen"], "http://papers.nips.cc/paper/8494-partitioning-structure-learning-for-segmented-linear-regression-trees", 10, "neurips", 2019]], "Eugene Bagdasaryan": [0, ["Differential Privacy Has Disparate Impact on Model Accuracy", ["Eugene Bagdasaryan", "Omid Poursaeed", "Vitaly Shmatikov"], "http://papers.nips.cc/paper/9681-differential-privacy-has-disparate-impact-on-model-accuracy", 10, "neurips", 2019]], "Aymeric Dieuleveut": [0, ["Communication trade-offs for Local-SGD with large step size", ["Aymeric Dieuleveut", "Kumar Kshitij Patel"], "http://papers.nips.cc/paper/9512-communication-trade-offs-for-local-sgd-with-large-step-size", 12, "neurips", 2019]], "Kunal Talwar": [0, ["Computational Separations between Sampling and Optimization", ["Kunal Talwar"], "http://papers.nips.cc/paper/9639-computational-separations-between-sampling-and-optimization", 11, "neurips", 2019]], "Wenhao Zhang": [0, ["A Normative Theory for Causal Inference and Bayes Factor Computation in Neural Circuits", ["Wenhao Zhang", "Si Wu", "Brent Doiron", "Tai Sing Lee"], "http://papers.nips.cc/paper/8636-a-normative-theory-for-causal-inference-and-bayes-factor-computation-in-neural-circuits", 10, "neurips", 2019]], "Dmitrii Emelianenko": [0, ["Sequence Modeling with Unconstrained Generation Order", ["Dmitrii Emelianenko", "Elena Voita", "Pavel Serdyukov"], "http://papers.nips.cc/paper/8986-sequence-modeling-with-unconstrained-generation-order", 12, "neurips", 2019]], "Xingyu Lin": [0, ["Adaptive Auxiliary Task Weighting for Reinforcement Learning", ["Xingyu Lin", "Harjatin Singh Baweja", "George Kantor", "David Held"], "http://papers.nips.cc/paper/8724-adaptive-auxiliary-task-weighting-for-reinforcement-learning", 12, "neurips", 2019]], "Gautier Izacard": [0, ["Data-driven Estimation of Sinusoid Frequencies", ["Gautier Izacard", "Sreyas Mohan", "Carlos Fernandez-Granda"], "http://papers.nips.cc/paper/8756-data-driven-estimation-of-sinusoid-frequencies", 11, "neurips", 2019]], "Wenrui Zhang": [0, ["Spike-Train Level Backpropagation for Training Deep Recurrent Spiking Neural Networks", ["Wenrui Zhang", "Peng Li"], "http://papers.nips.cc/paper/8995-spike-train-level-backpropagation-for-training-deep-recurrent-spiking-neural-networks", 12, "neurips", 2019]], "Seongjun Yun": [0.999479204416275, ["Graph Transformer Networks", ["Seongjun Yun", "Minbyul Jeong", "Raehyun Kim", "Jaewoo Kang", "Hyunwoo J. Kim"], "http://papers.nips.cc/paper/9367-graph-transformer-networks", 11, "neurips", 2019]], "Ananda Theertha Suresh": [0, ["Differentially Private Anonymized Histograms", ["Ananda Theertha Suresh"], "http://papers.nips.cc/paper/9010-differentially-private-anonymized-histograms", 11, "neurips", 2019]], "Kiran Koshy Thekumparampil": [0, ["Efficient Algorithms for Smooth Minimax Optimization", ["Kiran Koshy Thekumparampil", "Prateek Jain", "Praneeth Netrapalli", "Sewoong Oh"], "http://papers.nips.cc/paper/9430-efficient-algorithms-for-smooth-minimax-optimization", 12, "neurips", 2019]], "Aadirupa Saha": [0, ["Combinatorial Bandits with Relative Feedback", ["Aadirupa Saha", "Aditya Gopalan"], "http://papers.nips.cc/paper/8384-combinatorial-bandits-with-relative-feedback", 11, "neurips", 2019]], "Fenglin Liu": [0, ["Aligning Visual Regions and Textual Concepts for Semantic-Grounded Image Representations", ["Fenglin Liu", "Yuanxin Liu", "Xuancheng Ren", "Xiaodong He", "Xu Sun"], "http://papers.nips.cc/paper/8909-aligning-visual-regions-and-textual-concepts-for-semantic-grounded-image-representations", 11, "neurips", 2019]], "Yu-Chia Chen": [0, ["Selecting the independent coordinates of manifolds with large aspect ratios", ["Yu-Chia Chen", "Marina Meila"], "http://papers.nips.cc/paper/8393-selecting-the-independent-coordinates-of-manifolds-with-large-aspect-ratios", 10, "neurips", 2019]], "Shuai Zhang": [0, ["Quaternion Knowledge Graph Embeddings", ["Shuai Zhang", "Yi Tay", "Lina Yao", "Qi Liu"], "http://papers.nips.cc/paper/8541-quaternion-knowledge-graph-embeddings", 11, "neurips", 2019]], "Gengshan Yang": [2.292049157404108e-05, ["Volumetric Correspondence Networks for Optical Flow", ["Gengshan Yang", "Deva Ramanan"], "http://papers.nips.cc/paper/8367-volumetric-correspondence-networks-for-optical-flow", 11, "neurips", 2019]], "Derek Yang": [0.0001123909096349962, ["Fully Parameterized Quantile Function for Distributional Reinforcement Learning", ["Derek Yang", "Li Zhao", "Zichuan Lin", "Tao Qin", "Jiang Bian", "Tie-Yan Liu"], "http://papers.nips.cc/paper/8850-fully-parameterized-quantile-function-for-distributional-reinforcement-learning", 10, "neurips", 2019]], "Minne Li": [0, ["Multi-View Reinforcement Learning", ["Minne Li", "Lisheng Wu", "Jun Wang", "Haitham Bou-Ammar"], "http://papers.nips.cc/paper/8422-multi-view-reinforcement-learning", 12, "neurips", 2019]], "David Sabbagh": [0, ["Manifold-regression to predict from MEG/EEG brain signals without source modeling", ["David Sabbagh", "Pierre Ablin", "Gael Varoquaux", "Alexandre Gramfort", "Denis A. Engemann"], "http://papers.nips.cc/paper/8952-manifold-regression-to-predict-from-megeeg-brain-signals-without-source-modeling", 12, "neurips", 2019]], "Matthew Staib": [0, ["Distributionally Robust Optimization and Generalization in Kernel Methods", ["Matthew Staib", "Stefanie Jegelka"], "http://papers.nips.cc/paper/9113-distributionally-robust-optimization-and-generalization-in-kernel-methods", 11, "neurips", 2019]], "Ruiyi Zhang": [0, ["Text-Based Interactive Recommendation via Constraint-Augmented Reinforcement Learning", ["Ruiyi Zhang", "Tong Yu", "Yilin Shen", "Hongxia Jin", "Changyou Chen"], "http://papers.nips.cc/paper/9657-text-based-interactive-recommendation-via-constraint-augmented-reinforcement-learning", 11, "neurips", 2019]], "Lalit Jain": [0, ["A New Perspective on Pool-Based Active Classification and False-Discovery Control", ["Lalit Jain", "Kevin G. Jamieson"], "http://papers.nips.cc/paper/9549-a-new-perspective-on-pool-based-active-classification-and-false-discovery-control", 12, "neurips", 2019]], "Jinhao Dong": [0.000725938385585323, ["MarginGAN: Adversarial Training in Semi-Supervised Learning", ["Jinhao Dong", "Tong Lin"], "http://papers.nips.cc/paper/9231-margingan-adversarial-training-in-semi-supervised-learning", 10, "neurips", 2019]], "Max Vladymyrov": [0, ["No Pressure! Addressing the Problem of Local Minima in Manifold Learning Algorithms", ["Max Vladymyrov"], "http://papers.nips.cc/paper/8357-no-pressure-addressing-the-problem-of-local-minima-in-manifold-learning-algorithms", 10, "neurips", 2019]], "Tao Yu": [0.0013258812250569463, ["Numerically Accurate Hyperbolic Embeddings Using Tiling-Based Models", ["Tao Yu", "Christopher De Sa"], "http://papers.nips.cc/paper/8476-numerically-accurate-hyperbolic-embeddings-using-tiling-based-models", 11, "neurips", 2019]], "Amir Dezfouli": [0, ["Disentangled behavioural representations", ["Amir Dezfouli", "Hassan Ashtiani", "Omar Ghattas", "Richard Nock", "Peter Dayan", "Cheng Soon Ong"], "http://papers.nips.cc/paper/8497-disentangled-behavioural-representations", 10, "neurips", 2019]], "Sam Wiseman": [0, ["Amortized Bethe Free Energy Minimization for Learning MRFs", ["Sam Wiseman", "Yoon Kim"], "http://papers.nips.cc/paper/9687-amortized-bethe-free-energy-minimization-for-learning-mrfs", 12, "neurips", 2019]], "Karol Gregor": [0, ["Shaping Belief States with Generative Environment Models for RL", ["Karol Gregor", "Danilo Jimenez Rezende", "Frederic Besse", "Yan Wu", "Hamza Merzic", "Aaron van den Oord"], "http://papers.nips.cc/paper/9503-shaping-belief-states-with-generative-environment-models-for-rl", 13, "neurips", 2019]], "Atalanti-Anastasia Mastakouri": [0, ["Selecting causal brain features with a single conditional independence test per feature", ["Atalanti-Anastasia Mastakouri", "Bernhard Scholkopf", "Dominik Janzing"], "http://papers.nips.cc/paper/9419-selecting-causal-brain-features-with-a-single-conditional-independence-test-per-feature", 12, "neurips", 2019]], "Guruprasad Raghavan": [0, ["Neural networks grown and self-organized by noise", ["Guruprasad Raghavan", "Matt Thomson"], "http://papers.nips.cc/paper/8465-neural-networks-grown-and-self-organized-by-noise", 11, "neurips", 2019]], "Qian Yang": [0.0018993759294971824, ["Ouroboros: On Accelerating Training of Transformer-Based Language Models", ["Qian Yang", "Zhouyuan Huo", "Wenlin Wang", "Heng Huang", "Lawrence Carin"], "http://papers.nips.cc/paper/8790-ouroboros-on-accelerating-training-of-transformer-based-language-models", 11, "neurips", 2019]], "Greg Ver Steeg": [0, ["Fast structure learning with modular regularization", ["Greg Ver Steeg", "Hrayr Harutyunyan", "Daniel Moyer", "Aram Galstyan"], "http://papers.nips.cc/paper/9691-fast-structure-learning-with-modular-regularization", 11, "neurips", 2019]], "Mariya Toneva": [0, ["Interpreting and improving natural-language processing (in machines) with natural language-processing (in the brain)", ["Mariya Toneva", "Leila Wehbe"], "http://papers.nips.cc/paper/9633-interpreting-and-improving-natural-language-processing-in-machines-with-natural-language-processing-in-the-brain", 11, "neurips", 2019]], "Bastian Alt": [0, ["Correlation Priors for Reinforcement Learning", ["Bastian Alt", "Adrian Sosic", "Heinz Koeppl"], "http://papers.nips.cc/paper/9564-correlation-priors-for-reinforcement-learning", 11, "neurips", 2019]], "Weiyang Liu": [0, ["Neural Similarity Learning", ["Weiyang Liu", "Zhen Liu", "James M. Rehg", "Le Song"], "http://papers.nips.cc/paper/8747-neural-similarity-learning", 12, "neurips", 2019]], "Xuanqing Liu": [0, ["A Unified Framework for Data Poisoning Attack to Graph-based Semi-supervised Learning", ["Xuanqing Liu", "Si Si", "Jerry Zhu", "Yang Li", "Cho-Jui Hsieh"], "http://papers.nips.cc/paper/9171-a-unified-framework-for-data-poisoning-attack-to-graph-based-semi-supervised-learning", 11, "neurips", 2019]], "Koosha Khalvati": [0, ["A Bayesian Theory of Conformity in Collective Decision Making", ["Koosha Khalvati", "Saghar Mirbagheri", "Seongmin A. Park", "Jean-Claude Dreher", "Rajesh P. Rao"], "http://papers.nips.cc/paper/9164-a-bayesian-theory-of-conformity-in-collective-decision-making", 10, "neurips", 2019]], "Eliya Nachmani": [0, ["Hyper-Graph-Network Decoders for Block Codes", ["Eliya Nachmani", "Lior Wolf"], "http://papers.nips.cc/paper/8504-hyper-graph-network-decoders-for-block-codes", 11, "neurips", 2019]], "Charith Mendis": [0, ["Compiler Auto-Vectorization with Imitation Learning", ["Charith Mendis", "Cambridge Yang", "Yewen Pu", "Saman P. Amarasinghe", "Michael Carbin"], "http://papers.nips.cc/paper/9604-compiler-auto-vectorization-with-imitation-learning", 12, "neurips", 2019]], "Soumya Basu": [0, ["Blocking Bandits", ["Soumya Basu", "Rajat Sen", "Sujay Sanghavi", "Sanjay Shakkottai"], "http://papers.nips.cc/paper/8725-blocking-bandits", 10, "neurips", 2019]], "Baekjin Kim": [0.9887364208698273, ["On the Optimality of Perturbations in Stochastic and Adversarial Multi-armed Bandit Problems", ["Baekjin Kim", "Ambuj Tewari"], "http://papers.nips.cc/paper/8537-on-the-optimality-of-perturbations-in-stochastic-and-adversarial-multi-armed-bandit-problems", 10, "neurips", 2019]], "Larkin Flodin": [0, ["Superset Technique for Approximate Recovery in One-Bit Compressed Sensing", ["Larkin Flodin", "Venkata Gandikota", "Arya Mazumdar"], "http://papers.nips.cc/paper/9226-superset-technique-for-approximate-recovery-in-one-bit-compressed-sensing", 10, "neurips", 2019]], "Dennis Elbrachter": [0, ["How degenerate is the parametrization of neural networks with the ReLU activation function?", ["Dennis Elbrachter", "Julius Berner", "Philipp Grohs"], "http://papers.nips.cc/paper/8994-how-degenerate-is-the-parametrization-of-neural-networks-with-the-relu-activation-function", 12, "neurips", 2019]], "Siyuan Li": [0, ["Hierarchical Reinforcement Learning with Advantage-Based Auxiliary Rewards", ["Siyuan Li", "Rui Wang", "Minxue Tang", "Chongjie Zhang"], "http://papers.nips.cc/paper/8421-hierarchical-reinforcement-learning-with-advantage-based-auxiliary-rewards", 11, "neurips", 2019]], "Xiao Li": [0, ["A Debiased MDI Feature Importance Measure for Random Forests", ["Xiao Li", "Yu Wang", "Sumanta Basu", "Karl Kumbier", "Bin Yu"], "http://papers.nips.cc/paper/9017-a-debiased-mdi-feature-importance-measure-for-random-forests", 11, "neurips", 2019]], "Chanho Eom": [0.7784646451473236, ["Learning Disentangled Representation for Robust Person Re-identification", ["Chanho Eom", "Bumsub Ham"], "http://papers.nips.cc/paper/8771-learning-disentangled-representation-for-robust-person-re-identification", 12, "neurips", 2019]], "Eszter Vertes": [0, ["A neurally plausible model learns successor representations in partially observable environments", ["Eszter Vertes", "Maneesh Sahani"], "http://papers.nips.cc/paper/9522-a-neurally-plausible-model-learns-successor-representations-in-partially-observable-environments", 11, "neurips", 2019]], "Michael R. Zhang": [0, ["Lookahead Optimizer: k steps forward, 1 step back", ["Michael R. Zhang", "James Lucas", "Jimmy Ba", "Geoffrey E. Hinton"], "http://papers.nips.cc/paper/9155-lookahead-optimizer-k-steps-forward-1-step-back", 12, "neurips", 2019]], "Blake Mason": [0, ["Learning Nearest Neighbor Graphs from Noisy Distance Samples", ["Blake Mason", "Ardhendu Tripathy", "Robert D. Nowak"], "http://papers.nips.cc/paper/9154-learning-nearest-neighbor-graphs-from-noisy-distance-samples", 11, "neurips", 2019]], "Negin Golrezaei": [0, ["Dynamic Incentive-Aware Learning: Robust Pricing in Contextual Auctions", ["Negin Golrezaei", "Adel Javanmard", "Vahab S. Mirrokni"], "http://papers.nips.cc/paper/9169-dynamic-incentive-aware-learning-robust-pricing-in-contextual-auctions", 11, "neurips", 2019]], "Mathias Perslev": [0, ["U-Time: A Fully Convolutional Network for Time Series Segmentation Applied to Sleep Staging", ["Mathias Perslev", "Michael Hejselbak Jensen", "Sune Darkner", "Poul Jorgen Jennum", "Christian Igel"], "http://papers.nips.cc/paper/8692-u-time-a-fully-convolutional-network-for-time-series-segmentation-applied-to-sleep-staging", 12, "neurips", 2019]], "Wei Qian": [0, ["Global Convergence of Least Squares EM for Demixing Two Log-Concave Densities", ["Wei Qian", "Yuqian Zhang", "Yudong Chen"], "http://papers.nips.cc/paper/8726-global-convergence-of-least-squares-em-for-demixing-two-log-concave-densities", 9, "neurips", 2019]], "Zhe Wang": [3.481757858025958e-06, ["SpiderBoost and Momentum: Faster Variance Reduction Algorithms", ["Zhe Wang", "Kaiyi Ji", "Yi Zhou", "Yingbin Liang", "Vahid Tarokh"], "http://papers.nips.cc/paper/8511-spiderboost-and-momentum-faster-variance-reduction-algorithms", 11, "neurips", 2019]], "Emile Mathieu": [0, ["Continuous Hierarchical Representations with Poincar\u00e9 Variational Auto-Encoders", ["Emile Mathieu", "Charline Le Lan", "Chris J. Maddison", "Ryota Tomioka", "Yee Whye Teh"], "http://papers.nips.cc/paper/9420-continuous-hierarchical-representations-with-poincare-variational-auto-encoders", 12, "neurips", 2019]], "Ilai Bistritz": [0, ["Online EXP3 Learning in Adversarial Bandits with Delayed Feedback", ["Ilai Bistritz", "Zhengyuan Zhou", "Xi Chen", "Nicholas Bambos", "Jose Blanchet"], "http://papers.nips.cc/paper/9312-online-exp3-learning-in-adversarial-bandits-with-delayed-feedback", 10, "neurips", 2019]], "Zheng Li": [0, ["Dimension-Free Bounds for Low-Precision Training", ["Zheng Li", "Christopher De Sa"], "http://papers.nips.cc/paper/9346-dimension-free-bounds-for-low-precision-training", 11, "neurips", 2019]], "Yu Tian": [0, ["Rethinking Kernel Methods for Node Representation Learning on Graphs", ["Yu Tian", "Long Zhao", "Xi Peng", "Dimitris N. Metaxas"], "http://papers.nips.cc/paper/9342-rethinking-kernel-methods-for-node-representation-learning-on-graphs", 12, "neurips", 2019]], "John Ingraham": [0, ["Generative Models for Graph-Based Protein Design", ["John Ingraham", "Vikas K. Garg", "Regina Barzilay", "Tommi S. Jaakkola"], "http://papers.nips.cc/paper/9711-generative-models-for-graph-based-protein-design", 12, "neurips", 2019]], "Ganlin Song": [0.012034116312861443, ["Surfing: Iterative Optimization Over Incrementally Trained Deep Networks", ["Ganlin Song", "Zhou Fan", "John Lafferty"], "http://papers.nips.cc/paper/9640-surfing-iterative-optimization-over-incrementally-trained-deep-networks", 10, "neurips", 2019]], "Zhilin Yang": [2.193754596646613e-06, ["XLNet: Generalized Autoregressive Pretraining for Language Understanding", ["Zhilin Yang", "Zihang Dai", "Yiming Yang", "Jaime G. Carbonell", "Ruslan Salakhutdinov", "Quoc V. Le"], "http://papers.nips.cc/paper/8812-xlnet-generalized-autoregressive-pretraining-for-language-understanding", 11, "neurips", 2019], ["Mixtape: Breaking the Softmax Bottleneck Efficiently", ["Zhilin Yang", "Thang Luong", "Ruslan Salakhutdinov", "Quoc V. Le"], "http://papers.nips.cc/paper/9723-mixtape-breaking-the-softmax-bottleneck-efficiently", 9, "neurips", 2019]], "Nixie S. Lesmana": [0, ["Balancing Efficiency and Fairness in On-Demand Ridesourcing", ["Nixie S. Lesmana", "Xuan Zhang", "Xiaohui Bei"], "http://papers.nips.cc/paper/8772-balancing-efficiency-and-fairness-in-on-demand-ridesourcing", 11, "neurips", 2019]], "Ari S. Morcos": [0, ["One ticket to win them all: generalizing lottery ticket initializations across datasets and optimizers", ["Ari S. Morcos", "Haonan Yu", "Michela Paganini", "Yuandong Tian"], "http://papers.nips.cc/paper/8739-one-ticket-to-win-them-all-generalizing-lottery-ticket-initializations-across-datasets-and-optimizers", 11, "neurips", 2019]], "Yair Bartal": [0, ["Dimensionality reduction: theoretical perspective on practical measures", ["Yair Bartal", "Nova Fandina", "Ofer Neiman"], "http://papers.nips.cc/paper/9243-dimensionality-reduction-theoretical-perspective-on-practical-measures", 13, "neurips", 2019]], "Botao Hao": [0, ["Bootstrapping Upper Confidence Bound", ["Botao Hao", "Yasin Abbasi-Yadkori", "Zheng Wen", "Guang Cheng"], "http://papers.nips.cc/paper/9382-bootstrapping-upper-confidence-bound", 11, "neurips", 2019]], "Mokhtar Z. Alaya": [0, ["Screening Sinkhorn Algorithm for Regularized Optimal Transport", ["Mokhtar Z. Alaya", "Maxime Berar", "Gilles Gasso", "Alain Rakotomamonjy"], "http://papers.nips.cc/paper/9386-screening-sinkhorn-algorithm-for-regularized-optimal-transport", 11, "neurips", 2019]], "David Salinas": [0, ["High-dimensional multivariate forecasting with low-rank Gaussian Copula Processes", ["David Salinas", "Michael Bohlke-Schneider", "Laurent Callot", "Roberto Medico", "Jan Gasthaus"], "http://papers.nips.cc/paper/8907-high-dimensional-multivariate-forecasting-with-low-rank-gaussian-copula-processes", 11, "neurips", 2019]], "Shiyu Chang": [0.0011794451856985688, ["A Game Theoretic Approach to Class-wise Selective Rationalization", ["Shiyu Chang", "Yang Zhang", "Mo Yu", "Tommi S. Jaakkola"], "http://papers.nips.cc/paper/9196-a-game-theoretic-approach-to-class-wise-selective-rationalization", 11, "neurips", 2019]], "Ya-Chien Chang": [3.95851751378018e-08, ["Neural Lyapunov Control", ["Ya-Chien Chang", "Nima Roohi", "Sicun Gao"], "http://papers.nips.cc/paper/8587-neural-lyapunov-control", 10, "neurips", 2019]], "Alexis Conneau": [0, ["Cross-lingual Language Model Pretraining", ["Alexis Conneau", "Guillaume Lample"], "http://papers.nips.cc/paper/8928-cross-lingual-language-model-pretraining", 11, "neurips", 2019]], "Ligeng Zhu": [0, ["Deep Leakage from Gradients", ["Ligeng Zhu", "Zhijian Liu", "Song Han"], "http://papers.nips.cc/paper/9617-deep-leakage-from-gradients", 10, "neurips", 2019]], "Axel Brando": [0, ["Modelling heterogeneous distributions with an Uncountable Mixture of Asymmetric Laplacians", ["Axel Brando", "Jose A. Rodriguez-Serrano", "Jordi Vitria", "Alberto Rubio"], "http://papers.nips.cc/paper/9087-modelling-heterogeneous-distributions-with-an-uncountable-mixture-of-asymmetric-laplacians", 11, "neurips", 2019]], "Nika Haghtalab": [0, ["Toward a Characterization of Loss Functions for Distribution Learning", ["Nika Haghtalab", "Cameron Musco", "Bo Waggoner"], "http://papers.nips.cc/paper/8944-toward-a-characterization-of-loss-functions-for-distribution-learning", 10, "neurips", 2019]], "Lingyu Liang": [0, ["Adaptive GNN for Image Analysis and Editing", ["Lingyu Liang", "Lianwen Jin", "Yong Xu"], "http://papers.nips.cc/paper/8622-adaptive-gnn-for-image-analysis-and-editing", 12, "neurips", 2019]], "Sjoerd van Steenkiste": [0, ["Are Disentangled Representations Helpful for Abstract Visual Reasoning?", ["Sjoerd van Steenkiste", "Francesco Locatello", "Jurgen Schmidhuber", "Olivier Bachem"], "http://papers.nips.cc/paper/9570-are-disentangled-representations-helpful-for-abstract-visual-reasoning", 14, "neurips", 2019]], "Pooria Joulani": [0, ["Think out of the \"Box\": Generically-Constrained Asynchronous Composite Optimization and Hedging", ["Pooria Joulani", "Andras Gyorgy", "Csaba Szepesvari"], "http://papers.nips.cc/paper/9391-think-out-of-the-box-generically-constrained-asynchronous-composite-optimization-and-hedging", 11, "neurips", 2019]], "Qian Qian": [0, ["The Implicit Bias of AdaGrad on Separable Data", ["Qian Qian", "Xiaoyuan Qian"], "http://papers.nips.cc/paper/8991-the-implicit-bias-of-adagrad-on-separable-data", 9, "neurips", 2019]], "Yichuan Charlie Tang": [0, ["Multiple Futures Prediction", ["Yichuan Charlie Tang", "Ruslan Salakhutdinov"], "http://papers.nips.cc/paper/9676-multiple-futures-prediction", 11, "neurips", 2019]], "Radu Marinescu": [0, ["Counting the Optimal Solutions in Graphical Models", ["Radu Marinescu", "Rina Dechter"], "http://papers.nips.cc/paper/9379-counting-the-optimal-solutions-in-graphical-models", 11, "neurips", 2019]], "Lorenzo DallAmico": [0, ["Revisiting the Bethe-Hessian: Improved Community Detection in Sparse Heterogeneous Graphs", ["Lorenzo DallAmico", "Romain Couillet", "Nicolas Tremblay"], "http://papers.nips.cc/paper/8658-revisiting-the-bethe-hessian-improved-community-detection-in-sparse-heterogeneous-graphs", 11, "neurips", 2019]], "Virginia Aglietti": [0, ["Structured Variational Inference in Continuous Cox Process Models", ["Virginia Aglietti", "Edwin V. Bonilla", "Theodoros Damoulas", "Sally Cripps"], "http://papers.nips.cc/paper/9410-structured-variational-inference-in-continuous-cox-process-models", 11, "neurips", 2019]], "Roman Beliy": [0, ["From voxels to pixels and back: Self-supervision in natural-image reconstruction from fMRI", ["Roman Beliy", "Guy Gaziv", "Assaf Hoogi", "Francesca Strappini", "Tal Golan", "Michal Irani"], "http://papers.nips.cc/paper/8879-from-voxels-to-pixels-and-back-self-supervision-in-natural-image-reconstruction-from-fmri", 11, "neurips", 2019]], "Xihui Liu": [0, ["Learning to Predict Layout-to-image Conditional Convolutions for Semantic Image Synthesis", ["Xihui Liu", "Guojun Yin", "Jing Shao", "Xiaogang Wang", "Hongsheng Li"], "http://papers.nips.cc/paper/8347-learning-to-predict-layout-to-image-conditional-convolutions-for-semantic-image-synthesis", 11, "neurips", 2019]], "Brendan ODonoghue": [0, ["Hamiltonian descent for composite objectives", ["Brendan ODonoghue", "Chris J. Maddison"], "http://papers.nips.cc/paper/9590-hamiltonian-descent-for-composite-objectives", 11, "neurips", 2019]], "Saeed Mahloujifar": [0, ["Empirically Measuring Concentration: Fundamental Limits on Intrinsic Robustness", ["Saeed Mahloujifar", "Xiao Zhang", "Mohammad Mahmoody", "David Evans"], "http://papers.nips.cc/paper/8763-empirically-measuring-concentration-fundamental-limits-on-intrinsic-robustness", 12, "neurips", 2019]], "Jiajin Li": [0, ["A First-Order Algorithmic Framework for Distributionally Robust Logistic Regression", ["Jiajin Li", "Sen Huang", "Anthony Man-Cho So"], "http://papers.nips.cc/paper/8649-a-first-order-algorithmic-framework-for-distributionally-robust-logistic-regression", 11, "neurips", 2019]], "Taufik Xu": [0, ["Multi-objects Generation with Amortized Structural Regularization", ["Taufik Xu", "Chongxuan Li", "Jun Zhu", "Bo Zhang"], "http://papers.nips.cc/paper/8888-multi-objects-generation-with-amortized-structural-regularization", 11, "neurips", 2019]], "Justin Cosentino": [0, ["Generative Well-intentioned Networks", ["Justin Cosentino", "Jun Zhu"], "http://papers.nips.cc/paper/9467-generative-well-intentioned-networks", 12, "neurips", 2019]], "Huong Ha": [0.06291124038398266, ["Bayesian Optimization with Unknown Search Space", ["Huong Ha", "Santu Rana", "Sunil Gupta", "Thanh Tang Nguyen", "Hung Tran-The", "Svetha Venkatesh"], "http://papers.nips.cc/paper/9350-bayesian-optimization-with-unknown-search-space", 10, "neurips", 2019]], "Yiren Zhao": [0, ["Focused Quantization for Sparse CNNs", ["Yiren Zhao", "Xitong Gao", "Daniel Bates", "Robert Mullins", "Cheng-Zhong Xu"], "http://papers.nips.cc/paper/8796-focused-quantization-for-sparse-cnns", 10, "neurips", 2019]], "Francisco M. Garcia": [0, ["A Meta-MDP Approach to Exploration for Lifelong Reinforcement Learning", ["Francisco M. Garcia", "Philip S. Thomas"], "http://papers.nips.cc/paper/8806-a-meta-mdp-approach-to-exploration-for-lifelong-reinforcement-learning", 10, "neurips", 2019]], "Xuhui Fan": [0, ["Scalable Deep Generative Relational Model with High-Order Node Dependence", ["Xuhui Fan", "Bin Li", "Caoyuan Li", "Scott Sisson", "Ling Chen"], "http://papers.nips.cc/paper/9428-scalable-deep-generative-relational-model-with-high-order-node-dependence", 11, "neurips", 2019]], "Mahmoud Assran": [0, ["Gossip-based Actor-Learner Architectures for Deep Reinforcement Learning", ["Mahmoud Assran", "Joshua Romoff", "Nicolas Ballas", "Joelle Pineau", "Mike Rabbat"], "http://papers.nips.cc/paper/9487-gossip-based-actor-learner-architectures-for-deep-reinforcement-learning", 11, "neurips", 2019]], "Jiarui Gan": [9.11693223315524e-05, ["Manipulating a Learning Defender and Ways to Counteract", ["Jiarui Gan", "Qingyu Guo", "Long Tran-Thanh", "Bo An", "Michael J. Wooldridge"], "http://papers.nips.cc/paper/9037-manipulating-a-learning-defender-and-ways-to-counteract", 10, "neurips", 2019]], "Jiezhang Cao": [0, ["Multi-marginal Wasserstein GAN", ["Jiezhang Cao", "Langyuan Mo", "Yifan Zhang", "Kui Jia", "Chunhua Shen", "Mingkui Tan"], "http://papers.nips.cc/paper/8454-multi-marginal-wasserstein-gan", 11, "neurips", 2019]], "Karl Krauth": [0, ["Finite-time Analysis of Approximate Policy Iteration for the Linear Quadratic Regulator", ["Karl Krauth", "Stephen Tu", "Benjamin Recht"], "http://papers.nips.cc/paper/9058-finite-time-analysis-of-approximate-policy-iteration-for-the-linear-quadratic-regulator", 11, "neurips", 2019]], "Jinwoo Choi": [0.7019595056772232, ["Why Can't I Dance in the Mall? Learning to Mitigate Scene Bias in Action Recognition", ["Jinwoo Choi", "Chen Gao", "Joseph C. E. Messou", "Jia-Bin Huang"], "http://papers.nips.cc/paper/8372-why-cant-i-dance-in-the-mall-learning-to-mitigate-scene-bias-in-action-recognition", 13, "neurips", 2019]], "Soren Laue": [0, ["GENO - GENeric Optimization for Classical Machine Learning", ["Soren Laue", "Matthias Mitterreiter", "Joachim Giesen"], "http://papers.nips.cc/paper/8491-geno-generic-optimization-for-classical-machine-learning", 12, "neurips", 2019]], "Dilin Wang": [0.006098066456615925, ["Stein Variational Gradient Descent With Matrix-Valued Kernels", ["Dilin Wang", "Ziyang Tang", "Chandrajit Bajaj", "Qiang Liu"], "http://papers.nips.cc/paper/8998-stein-variational-gradient-descent-with-matrix-valued-kernels", 11, "neurips", 2019]], "Harm van Seijen": [0, ["Using a Logarithmic Mapping to Enable Lower Discount Factors in Reinforcement Learning", ["Harm van Seijen", "Mehdi Fatemi", "Arash Tavakoli"], "http://papers.nips.cc/paper/9560-using-a-logarithmic-mapping-to-enable-lower-discount-factors-in-reinforcement-learning", 11, "neurips", 2019]], "Suhas Jayaram Subramanya": [0, ["Rand-NSG: Fast Accurate Billion-point Nearest Neighbor Search on a Single Node", ["Suhas Jayaram Subramanya", "Fnu Devvrit", "Harsha Vardhan Simhadri", "Ravishankar Krishnawamy", "Rohan Kadekodi"], "http://papers.nips.cc/paper/9527-rand-nsg-fast-accurate-billion-point-nearest-neighbor-search-on-a-single-node", 11, "neurips", 2019]], "Andrew Spielberg": [0, ["Learning-In-The-Loop Optimization: End-To-End Control And Co-Design Of Soft Robots Through Learned Deep Latent Representations", ["Andrew Spielberg", "Allan Zhao", "Yuanming Hu", "Tao Du", "Wojciech Matusik", "Daniela Rus"], "http://papers.nips.cc/paper/9038-learning-in-the-loop-optimization-end-to-end-control-and-co-design-of-soft-robots-through-learned-deep-latent-representations", 11, "neurips", 2019]], "Paul Michel": [0, ["Are Sixteen Heads Really Better than One?", ["Paul Michel", "Omer Levy", "Graham Neubig"], "http://papers.nips.cc/paper/9551-are-sixteen-heads-really-better-than-one", 11, "neurips", 2019]], "Nicolas Carion": [0, ["A Structured Prediction Approach for Generalization in Cooperative Multi-Agent Reinforcement Learning", ["Nicolas Carion", "Nicolas Usunier", "Gabriel Synnaeve", "Alessandro Lazaric"], "http://papers.nips.cc/paper/9024-a-structured-prediction-approach-for-generalization-in-cooperative-multi-agent-reinforcement-learning", 11, "neurips", 2019]], "Michael Wick": [0, ["Unlocking Fairness: a Trade-off Revisited", ["Michael Wick", "Swetasudha Panda", "Jean-Baptiste Tristan"], "http://papers.nips.cc/paper/9082-unlocking-fairness-a-trade-off-revisited", 10, "neurips", 2019]], "Aaron Schein": [0, ["Poisson-Randomized Gamma Dynamical Systems", ["Aaron Schein", "Scott W. Linderman", "Mingyuan Zhou", "David M. Blei", "Hanna M. Wallach"], "http://papers.nips.cc/paper/8366-poisson-randomized-gamma-dynamical-systems", 12, "neurips", 2019]], "Guillaume Charpiat": [0, ["Input Similarity from the Neural Network Perspective", ["Guillaume Charpiat", "Nicolas Girard", "Loris Felardos", "Yuliya Tarabalka"], "http://papers.nips.cc/paper/8775-input-similarity-from-the-neural-network-perspective", 10, "neurips", 2019]], "Adam Gaier": [0, ["Weight Agnostic Neural Networks", ["Adam Gaier", "David Ha"], "http://papers.nips.cc/paper/8777-weight-agnostic-neural-networks", 15, "neurips", 2019]], "Qing Qu": [0, ["A Nonconvex Approach for Exact and Efficient Multichannel Sparse Blind Deconvolution", ["Qing Qu", "Xiao Li", "Zhihui Zhu"], "http://papers.nips.cc/paper/8656-a-nonconvex-approach-for-exact-and-efficient-multichannel-sparse-blind-deconvolution", 12, "neurips", 2019]], "Changqing Zhang": [0, ["CPM-Nets: Cross Partial Multi-View Networks", ["Changqing Zhang", "Zongbo Han", "yajie Cui", "Huazhu Fu", "Joey Tianyi Zhou", "Qinghua Hu"], "http://papers.nips.cc/paper/8346-cpm-nets-cross-partial-multi-view-networks", 11, "neurips", 2019]], "Jiawang Bian": [0, ["Unsupervised Scale-consistent Depth and Ego-motion Learning from Monocular Video", ["Jiawang Bian", "Zhichao Li", "Naiyan Wang", "Huangying Zhan", "Chunhua Shen", "Ming-Ming Cheng", "Ian D. Reid"], "http://papers.nips.cc/paper/8299-unsupervised-scale-consistent-depth-and-ego-motion-learning-from-monocular-video", 11, "neurips", 2019]], "Pascale Gourdeau": [0, ["On the Hardness of Robust Classification", ["Pascale Gourdeau", "Varun Kanade", "Marta Kwiatkowska", "James Worrell"], "http://papers.nips.cc/paper/8963-on-the-hardness-of-robust-classification", 10, "neurips", 2019]], "Sayak Ray Chowdhury": [0, ["Bayesian Optimization under Heavy-tailed Payoffs", ["Sayak Ray Chowdhury", "Aditya Gopalan"], "http://papers.nips.cc/paper/9531-bayesian-optimization-under-heavy-tailed-payoffs", 12, "neurips", 2019]], "Tomas Vaskevicius": [0, ["Implicit Regularization for Optimal Sparse Recovery", ["Tomas Vaskevicius", "Varun Kanade", "Patrick Rebeschini"], "http://papers.nips.cc/paper/8562-implicit-regularization-for-optimal-sparse-recovery", 12, "neurips", 2019]], "Colin Graber": [0, ["Graph Structured Prediction Energy Networks", ["Colin Graber", "Alexander G. Schwing"], "http://papers.nips.cc/paper/9074-graph-structured-prediction-energy-networks", 12, "neurips", 2019]], "Behrooz Ghorbani": [0, ["Limitations of Lazy Training of Two-layers Neural Network", ["Behrooz Ghorbani", "Song Mei", "Theodor Misiakiewicz", "Andrea Montanari"], "http://papers.nips.cc/paper/9111-limitations-of-lazy-training-of-two-layers-neural-network", 11, "neurips", 2019]], "Chaofan Chen": [0, ["This Looks Like That: Deep Learning for Interpretable Image Recognition", ["Chaofan Chen", "Oscar Li", "Daniel Tao", "Alina Barnett", "Cynthia Rudin", "Jonathan Su"], "http://papers.nips.cc/paper/9095-this-looks-like-that-deep-learning-for-interpretable-image-recognition", 12, "neurips", 2019]], "Ming Yu": [0.0060784968081861734, ["Convergent Policy Optimization for Safe Reinforcement Learning", ["Ming Yu", "Zhuoran Yang", "Mladen Kolar", "Zhaoran Wang"], "http://papers.nips.cc/paper/8576-convergent-policy-optimization-for-safe-reinforcement-learning", 13, "neurips", 2019]], "Corinna Cortes": [0, ["Regularized Gradient Boosting", ["Corinna Cortes", "Mehryar Mohri", "Dmitry Storcheus"], "http://papers.nips.cc/paper/8784-regularized-gradient-boosting", 10, "neurips", 2019]], "Alexis Bellot": [0, ["Conditional Independence Testing using Generative Adversarial Networks", ["Alexis Bellot", "Mihaela van der Schaar"], "http://papers.nips.cc/paper/8492-conditional-independence-testing-using-generative-adversarial-networks", 10, "neurips", 2019]], "Remi Cadene": [0, ["RUBi: Reducing Unimodal Biases for Visual Question Answering", ["Remi Cadene", "Corentin Dancette", "Hedi Ben-younes", "Matthieu Cord", "Devi Parikh"], "http://papers.nips.cc/paper/8371-rubi-reducing-unimodal-biases-for-visual-question-answering", 12, "neurips", 2019]], "Shufei Ge": [0, ["Random Tessellation Forests", ["Shufei Ge", "Shijia Wang", "Yee Whye Teh", "Liangliang Wang", "Lloyd T. Elliott"], "http://papers.nips.cc/paper/9153-random-tessellation-forests", 11, "neurips", 2019]], "Wasim Huleihel": [0, ["Same-Cluster Querying for Overlapping Clusters", ["Wasim Huleihel", "Arya Mazumdar", "Muriel Medard", "Soumyabrata Pal"], "http://papers.nips.cc/paper/9235-same-cluster-querying-for-overlapping-clusters", 11, "neurips", 2019]], "Piotr Indyk": [0, ["Learning-Based Low-Rank Approximations", ["Piotr Indyk", "Ali Vakilian", "Yang Yuan"], "http://papers.nips.cc/paper/8959-learning-based-low-rank-approximations", 11, "neurips", 2019]], "Takumi Kobayashi": [0, ["Gaussian-Based Pooling for Convolutional Neural Networks", ["Takumi Kobayashi"], "http://papers.nips.cc/paper/9300-gaussian-based-pooling-for-convolutional-neural-networks", 11, "neurips", 2019]], "Fan Yang": [4.2260115151293576e-05, ["Game Design for Eliciting Distinguishable Behavior", ["Fan Yang", "Liu Leqi", "Yifan Wu", "Zachary Chase Lipton", "Pradeep Ravikumar", "Tom M. Mitchell", "William W. Cohen"], "http://papers.nips.cc/paper/8716-game-design-for-eliciting-distinguishable-behavior", 10, "neurips", 2019]], "Jiechuan Jiang": [0, ["Learning Fairness in Multi-Agent Systems", ["Jiechuan Jiang", "Zongqing Lu"], "http://papers.nips.cc/paper/9537-learning-fairness-in-multi-agent-systems", 12, "neurips", 2019]], "Maxime Gasse": [0, ["Exact Combinatorial Optimization with Graph Convolutional Neural Networks", ["Maxime Gasse", "Didier Chetelat", "Nicola Ferroni", "Laurent Charlin", "Andrea Lodi"], "http://papers.nips.cc/paper/9690-exact-combinatorial-optimization-with-graph-convolutional-neural-networks", 13, "neurips", 2019]], "Brian Axelrod": [0, ["A Polynomial Time Algorithm for Log-Concave Maximum Likelihood via Locally Exponential Families", ["Brian Axelrod", "Ilias Diakonikolas", "Alistair Stewart", "Anastasios Sidiropoulos", "Gregory Valiant"], "http://papers.nips.cc/paper/8988-a-polynomial-time-algorithm-for-log-concave-maximum-likelihood-via-locally-exponential-families", 13, "neurips", 2019]], "Eduard Eiben": [0, ["The Parameterized Complexity of Cascading Portfolio Scheduling", ["Eduard Eiben", "Robert Ganian", "Iyad Kanj", "Stefan Szeider"], "http://papers.nips.cc/paper/8983-the-parameterized-complexity-of-cascading-portfolio-scheduling", 11, "neurips", 2019]], "Zhe Li": [0, ["Learning from brains how to regularize machines", ["Zhe Li", "Wieland Brendel", "Edgar Y. Walker", "Erick Cobos", "Taliah Muhammad", "Jacob Reimer", "Matthias Bethge", "Fabian H. Sinz", "Zachary Pitkow", "Andreas S. Tolias"], "http://papers.nips.cc/paper/9149-learning-from-brains-how-to-regularize-machines", 11, "neurips", 2019]], "David Gamarnik": [0, ["Sparse High-Dimensional Isotonic Regression", ["David Gamarnik", "Julia Gaudio"], "http://papers.nips.cc/paper/9447-sparse-high-dimensional-isotonic-regression", 11, "neurips", 2019]], "Jun Sun": [0.07243982143700123, ["Communication-Efficient Distributed Learning via Lazily Aggregated Quantized Gradients", ["Jun Sun", "Tianyi Chen", "Georgios B. Giannakis", "Zaiyue Yang"], "http://papers.nips.cc/paper/8598-communication-efficient-distributed-learning-via-lazily-aggregated-quantized-gradients", 11, "neurips", 2019]], "Yao Fu": [0, ["Paraphrase Generation with Latent Bag of Words", ["Yao Fu", "Yansong Feng", "John P. Cunningham"], "http://papers.nips.cc/paper/9516-paraphrase-generation-with-latent-bag-of-words", 12, "neurips", 2019]], "Avner May": [0, ["On the Downstream Performance of Compressed Word Embeddings", ["Avner May", "Jian Zhang", "Tri Dao", "Christopher Re"], "http://papers.nips.cc/paper/9351-on-the-downstream-performance-of-compressed-word-embeddings", 12, "neurips", 2019]], "Bo Yang": [0.0001360086680506356, ["Learning Object Bounding Boxes for 3D Instance Segmentation on Point Clouds", ["Bo Yang", "Jianan Wang", "Ronald Clark", "Qingyong Hu", "Sen Wang", "Andrew Markham", "Niki Trigoni"], "http://papers.nips.cc/paper/8899-learning-object-bounding-boxes-for-3d-instance-segmentation-on-point-clouds", 10, "neurips", 2019]], "Ronghui You": [0, ["AttentionXML: Label Tree-based Attention-Aware Deep Model for High-Performance Extreme Multi-Label Text Classification", ["Ronghui You", "Zihan Zhang", "Ziye Wang", "Suyang Dai", "Hiroshi Mamitsuka", "Shanfeng Zhu"], "http://papers.nips.cc/paper/8817-attentionxml-label-tree-based-attention-aware-deep-model-for-high-performance-extreme-multi-label-text-classification", 11, "neurips", 2019]], "Laura Isabel Galindez Olascoaga": [0, ["Towards Hardware-Aware Tractable Learning of Probabilistic Models", ["Laura Isabel Galindez Olascoaga", "Wannes Meert", "Nimish Shah", "Marian Verhelst", "Guy Van den Broeck"], "http://papers.nips.cc/paper/9525-towards-hardware-aware-tractable-learning-of-probabilistic-models", 11, "neurips", 2019]], "Boris Knyazev": [0, ["Understanding Attention and Generalization in Graph Neural Networks", ["Boris Knyazev", "Graham W. Taylor", "Mohamed R. Amer"], "http://papers.nips.cc/paper/8673-understanding-attention-and-generalization-in-graph-neural-networks", 11, "neurips", 2019]], "Susmit Jha": [0, ["Attribution-Based Confidence Metric For Deep Neural Networks", ["Susmit Jha", "Sunny Raj", "Steven Lawrence Fernandes", "Sumit Kumar Jha", "Somesh Jha", "Brian Jalaian", "Gunjan Verma", "Ananthram Swami"], "http://papers.nips.cc/paper/9355-attribution-based-confidence-metric-for-deep-neural-networks", 12, "neurips", 2019]], "Amir Najafi": [0, ["Robustness to Adversarial Perturbations in Learning from Incomplete Data", ["Amir Najafi", "Shin-ichi Maeda", "Masanori Koyama", "Takeru Miyato"], "http://papers.nips.cc/paper/8792-robustness-to-adversarial-perturbations-in-learning-from-incomplete-data", 11, "neurips", 2019]], "Hongsuck Seo": [0.9999974071979523, ["Combinatorial Inference against Label Noise", ["Hongsuck Seo", "Geeho Kim", "Bohyung Han"], "http://papers.nips.cc/paper/8401-combinatorial-inference-against-label-noise", 11, "neurips", 2019]], "Adam Paszke": [0, ["PyTorch: An Imperative Style, High-Performance Deep Learning Library", ["Adam Paszke", "Sam Gross", "Francisco Massa", "Adam Lerer", "James Bradbury", "Gregory Chanan", "Trevor Killeen", "Zeming Lin", "Natalia Gimelshein", "Luca Antiga", "Alban Desmaison", "Andreas Kopf", "Edward Yang", "Zachary DeVito", "Martin Raison", "Alykhan Tejani", "Sasank Chilamkurthy", "Benoit Steiner", "Lu Fang", "Junjie Bai", "Soumith Chintala"], "http://papers.nips.cc/paper/9015-pytorch-an-imperative-style-high-performance-deep-learning-library", 12, "neurips", 2019]], "Jathushan Rajasegaran": [0, ["Random Path Selection for Continual Learning", ["Jathushan Rajasegaran", "Munawar Hayat", "Salman H. Khan", "Fahad Shahbaz Khan", "Ling Shao"], "http://papers.nips.cc/paper/9429-random-path-selection-for-continual-learning", 11, "neurips", 2019]], "Mareike Hartmann": [0, ["Comparing Unsupervised Word Translation Methods Step by Step", ["Mareike Hartmann", "Yova Kementchedjhieva", "Anders Sogaard"], "http://papers.nips.cc/paper/8836-comparing-unsupervised-word-translation-methods-step-by-step", 11, "neurips", 2019]], "Quanfu Fan": [0, ["More Is Less: Learning Efficient Video Representations by Big-Little Network and Depthwise Temporal Aggregation", ["Quanfu Fan", "Chun-Fu Richard Chen", "Hilde Kuehne", "Marco Pistoia", "David Cox"], "http://papers.nips.cc/paper/8498-more-is-less-learning-efficient-video-representations-by-big-little-network-and-depthwise-temporal-aggregation", 10, "neurips", 2019]], "Amit Daniely": [0, ["Generalization Bounds for Neural Networks via Approximate Description Length", ["Amit Daniely", "Elad Granot"], "http://papers.nips.cc/paper/9459-generalization-bounds-for-neural-networks-via-approximate-description-length", 9, "neurips", 2019], ["Locally Private Learning without Interaction Requires Separation", ["Amit Daniely", "Vitaly Feldman"], "http://papers.nips.cc/paper/9637-locally-private-learning-without-interaction-requires-separation", 12, "neurips", 2019]], "Arjun Nitin Bhagoji": [0, ["Lower Bounds on Adversarial Robustness from Optimal Transport", ["Arjun Nitin Bhagoji", "Daniel Cullina", "Prateek Mittal"], "http://papers.nips.cc/paper/8968-lower-bounds-on-adversarial-robustness-from-optimal-transport", 13, "neurips", 2019]], "Ulysse Marteau-Ferey": [0, ["Globally Convergent Newton Methods for Ill-conditioned Generalized Self-concordant Losses", ["Ulysse Marteau-Ferey", "Francis Bach", "Alessandro Rudi"], "http://papers.nips.cc/paper/8980-globally-convergent-newton-methods-for-ill-conditioned-generalized-self-concordant-losses", 11, "neurips", 2019]], "Victor Veitch": [0, ["Using Embeddings to Correct for Unobserved Confounding in Networks", ["Victor Veitch", "Yixin Wang", "David M. Blei"], "http://papers.nips.cc/paper/9529-using-embeddings-to-correct-for-unobserved-confounding-in-networks", 11, "neurips", 2019]], "Amirata Ghorbani": [0, ["Towards Automatic Concept-based Explanations", ["Amirata Ghorbani", "James Wexler", "James Y. Zou", "Been Kim"], "http://papers.nips.cc/paper/9126-towards-automatic-concept-based-explanations", 10, "neurips", 2019]], "Nicolas Carrara": [0, ["Budgeted Reinforcement Learning in Continuous State Space", ["Nicolas Carrara", "Edouard Leurent", "Romain Laroche", "Tanguy Urvoy", "Odalric-Ambrym Maillard", "Olivier Pietquin"], "http://papers.nips.cc/paper/9128-budgeted-reinforcement-learning-in-continuous-state-space", 11, "neurips", 2019]], "Youssef Mroueh": [0, ["Sobolev Independence Criterion", ["Youssef Mroueh", "Tom Sercu", "Mattia Rigotti", "Inkit Padhi", "Cicero Nogueira dos Santos"], "http://papers.nips.cc/paper/9147-sobolev-independence-criterion", 11, "neurips", 2019]], "Firoozeh Sepehr": [0, ["An Algorithm to Learn Polytree Networks with Hidden Nodes", ["Firoozeh Sepehr", "Donatello Materassi"], "http://papers.nips.cc/paper/9647-an-algorithm-to-learn-polytree-networks-with-hidden-nodes", 10, "neurips", 2019]], "Borja Balle": [0, ["Privacy Amplification by Mixing and Diffusion Mechanisms", ["Borja Balle", "Gilles Barthe", "Marco Gaboardi", "Joseph Geumlek"], "http://papers.nips.cc/paper/9485-privacy-amplification-by-mixing-and-diffusion-mechanisms", 11, "neurips", 2019]], "Qiyang Li": [0, ["Preventing Gradient Attenuation in Lipschitz Constrained Convolutional Networks", ["Qiyang Li", "Saminul Haque", "Cem Anil", "James Lucas", "Roger B. Grosse", "Jorn-Henrik Jacobsen"], "http://papers.nips.cc/paper/9673-preventing-gradient-attenuation-in-lipschitz-constrained-convolutional-networks", 13, "neurips", 2019]], "Benyamin Allahgholizadeh Haghi": [0, ["Deep Multi-State Dynamic Recurrent Neural Networks Operating on Wavelet Based Neural Features for Robust Brain Machine Interfaces", ["Benyamin Allahgholizadeh Haghi", "Spencer S. Kellis", "Sahil Shah", "Maitreyi Ashok", "Luke Bashford", "Daniel Kramer", "Brian C. Lee", "Charles Liu", "Richard A. Andersen", "Azita Emami"], "http://papers.nips.cc/paper/9594-deep-multi-state-dynamic-recurrent-neural-networks-operating-on-wavelet-based-neural-features-for-robust-brain-machine-interfaces", 12, "neurips", 2019]], "Chenwei Ding": [0, ["Likelihood-Free Overcomplete ICA and Applications In Causal Discovery", ["Chenwei Ding", "Mingming Gong", "Kun Zhang", "Dacheng Tao"], "http://papers.nips.cc/paper/8912-likelihood-free-overcomplete-ica-and-applications-in-causal-discovery", 11, "neurips", 2019]], "Yaqi Duan": [0, ["State Aggregation Learning from Markov Transition Data", ["Yaqi Duan", "Zheng Tracy Ke", "Mengdi Wang"], "http://papers.nips.cc/paper/8698-state-aggregation-learning-from-markov-transition-data", 10, "neurips", 2019]], "ChangYong Oh": [0.4517309367656708, ["Combinatorial Bayesian Optimization using the Graph Cartesian Product", ["ChangYong Oh", "Jakub M. Tomczak", "Efstratios Gavves", "Max Welling"], "http://papers.nips.cc/paper/8557-combinatorial-bayesian-optimization-using-the-graph-cartesian-product", 11, "neurips", 2019]], "Maurice Weiler": [0, ["General E(2)-Equivariant Steerable CNNs", ["Maurice Weiler", "Gabriele Cesa"], "http://papers.nips.cc/paper/9580-general-e2-equivariant-steerable-cnns", 12, "neurips", 2019]], "Ali Sadeghian": [0, ["DRUM: End-To-End Differentiable Rule Mining On Knowledge Graphs", ["Ali Sadeghian", "Mohammadreza Armandpour", "Patrick Ding", "Daisy Zhe Wang"], "http://papers.nips.cc/paper/9669-drum-end-to-end-differentiable-rule-mining-on-knowledge-graphs", 11, "neurips", 2019]], "Murat Kocaoglu": [0, ["Characterization and Learning of Causal Graphs with Latent Variables from Soft Interventions", ["Murat Kocaoglu", "Amin Jaber", "Karthikeyan Shanmugam", "Elias Bareinboim"], "http://papers.nips.cc/paper/9581-characterization-and-learning-of-causal-graphs-with-latent-variables-from-soft-interventions", 11, "neurips", 2019]], "Xiao Liu": [0, ["Push-pull Feedback Implements Hierarchical Information Retrieval Efficiently", ["Xiao Liu", "Xiaolong Zou", "Zilong Ji", "Gengshuo Tian", "Yuanyuan Mi", "Tiejun Huang", "K. Y. Michael Wong", "Si Wu"], "http://papers.nips.cc/paper/8807-push-pull-feedback-implements-hierarchical-information-retrieval-efficiently", 10, "neurips", 2019]], "Chen Xing": [0, ["Adaptive Cross-Modal Few-shot Learning", ["Chen Xing", "Negar Rostamzadeh", "Boris N. Oreshkin", "Pedro O. Pinheiro"], "http://papers.nips.cc/paper/8731-adaptive-cross-modal-few-shot-learning", 11, "neurips", 2019]], "Bin Hu": [0, ["Characterizing the Exact Behaviors of Temporal Difference Learning Algorithms Using Markov Jump Linear System Theory", ["Bin Hu", "Usman Ahmed Syed"], "http://papers.nips.cc/paper/9055-characterizing-the-exact-behaviors-of-temporal-difference-learning-algorithms-using-markov-jump-linear-system-theory", 12, "neurips", 2019]], "Jian Qian": [0, ["Exploration Bonus for Regret Minimization in Discrete and Continuous Average Reward MDPs", ["Jian Qian", "Ronan Fruit", "Matteo Pirotta", "Alessandro Lazaric"], "http://papers.nips.cc/paper/8735-exploration-bonus-for-regret-minimization-in-discrete-and-continuous-average-reward-mdps", 10, "neurips", 2019]], "Zijun Gao": [0, ["Batched Multi-armed Bandits Problem", ["Zijun Gao", "Yanjun Han", "Zhimei Ren", "Zhengqing Zhou"], "http://papers.nips.cc/paper/8341-batched-multi-armed-bandits-problem", 11, "neurips", 2019]], "Shangtong Zhang": [0, ["Generalized Off-Policy Actor-Critic", ["Shangtong Zhang", "Wendelin Boehmer", "Shimon Whiteson"], "http://papers.nips.cc/paper/8474-generalized-off-policy-actor-critic", 11, "neurips", 2019], ["DAC: The Double Actor-Critic Architecture for Learning Options", ["Shangtong Zhang", "Shimon Whiteson"], "http://papers.nips.cc/paper/8475-dac-the-double-actor-critic-architecture-for-learning-options", 11, "neurips", 2019]], "Giancarlo Kerg": [0, ["Non-normal Recurrent Neural Network (nnRNN): learning long time dependencies while improving expressivity with transient dynamics", ["Giancarlo Kerg", "Kyle Goyette", "Maximilian Puelma Touzel", "Gauthier Gidel", "Eugene Vorontsov", "Yoshua Bengio", "Guillaume Lajoie"], "http://papers.nips.cc/paper/9513-non-normal-recurrent-neural-network-nnrnn-learning-long-time-dependencies-while-improving-expressivity-with-transient-dynamics", 11, "neurips", 2019]], "Zhiao Huang": [0, ["Mapping State Space using Landmarks for Universal Goal Reaching", ["Zhiao Huang", "Fangchen Liu", "Hao Su"], "http://papers.nips.cc/paper/8469-mapping-state-space-using-landmarks-for-universal-goal-reaching", 11, "neurips", 2019]], "Xinyun Chen": [0, ["Learning to Perform Local Rewriting for Combinatorial Optimization", ["Xinyun Chen", "Yuandong Tian"], "http://papers.nips.cc/paper/8858-learning-to-perform-local-rewriting-for-combinatorial-optimization", 12, "neurips", 2019]], "Hanzhang Hu": [0, ["Efficient Forward Architecture Search", ["Hanzhang Hu", "John Langford", "Rich Caruana", "Saurajit Mukherjee", "Eric Horvitz", "Debadeepta Dey"], "http://papers.nips.cc/paper/9202-efficient-forward-architecture-search", 10, "neurips", 2019]], "Ilias Diakonikolas": [0, ["Distribution-Independent PAC Learning of Halfspaces with Massart Noise", ["Ilias Diakonikolas", "Themis Gouleakis", "Christos Tzamos"], "http://papers.nips.cc/paper/8722-distribution-independent-pac-learning-of-halfspaces-with-massart-noise", 12, "neurips", 2019], ["Nearly Tight Bounds for Robust Proper Learning of Halfspaces with a Margin", ["Ilias Diakonikolas", "Daniel Kane", "Pasin Manurangsi"], "http://papers.nips.cc/paper/9234-nearly-tight-bounds-for-robust-proper-learning-of-halfspaces-with-a-margin", 12, "neurips", 2019], ["Outlier-Robust High-Dimensional Sparse Estimation via Iterative Filtering", ["Ilias Diakonikolas", "Daniel Kane", "Sushrut Karmalkar", "Eric Price", "Alistair Stewart"], "http://papers.nips.cc/paper/9253-outlier-robust-high-dimensional-sparse-estimation-via-iterative-filtering", 12, "neurips", 2019]], "Ruoqi Shen": [0, ["The Randomized Midpoint Method for Log-Concave Sampling", ["Ruoqi Shen", "Yin Tat Lee"], "http://papers.nips.cc/paper/8483-the-randomized-midpoint-method-for-log-concave-sampling", 12, "neurips", 2019]], "Han Liu": [0, ["Fast Low-rank Metric Learning for Large-scale and High-dimensional Data", ["Han Liu", "Zhizhong Han", "Yu-Shen Liu", "Ming Gu"], "http://papers.nips.cc/paper/8369-fast-low-rank-metric-learning-for-large-scale-and-high-dimensional-data", 11, "neurips", 2019]], "Emmanouil-Vasileios Vlatakis-Gkaragkounis": [0, ["Efficiently avoiding saddle points with zero order methods: No gradients required", ["Emmanouil-Vasileios Vlatakis-Gkaragkounis", "Lampros Flokas", "Georgios Piliouras"], "http://papers.nips.cc/paper/9197-efficiently-avoiding-saddle-points-with-zero-order-methods-no-gradients-required", 12, "neurips", 2019], ["Poincar\u00e9 Recurrence, Cycles and Spurious Equilibria in Gradient-Descent-Ascent for Non-Convex Non-Concave Zero-Sum Games", ["Emmanouil-Vasileios Vlatakis-Gkaragkounis", "Lampros Flokas", "Georgios Piliouras"], "http://papers.nips.cc/paper/9232-poincare-recurrence-cycles-and-spurious-equilibria-in-gradient-descent-ascent-for-non-convex-non-concave-zero-sum-games", 12, "neurips", 2019]], "Risto Vuorio": [0, ["Multimodal Model-Agnostic Meta-Learning via Task-Aware Modulation", ["Risto Vuorio", "Shao-Hua Sun", "Hexiang Hu", "Joseph J. Lim"], "http://papers.nips.cc/paper/8296-multimodal-model-agnostic-meta-learning-via-task-aware-modulation", 12, "neurips", 2019]], "Mengye Ren": [0, ["Incremental Few-Shot Learning with Attention Attractor Networks", ["Mengye Ren", "Renjie Liao", "Ethan Fetaya", "Richard S. Zemel"], "http://papers.nips.cc/paper/8769-incremental-few-shot-learning-with-attention-attractor-networks", 11, "neurips", 2019]], "Bolin Wei": [0, ["Code Generation as a Dual Task of Code Summarization", ["Bolin Wei", "Ge Li", "Xin Xia", "Zhiyi Fu", "Zhi Jin"], "http://papers.nips.cc/paper/8883-code-generation-as-a-dual-task-of-code-summarization", 11, "neurips", 2019]], "Gabriele Farina": [0, ["Efficient Regret Minimization Algorithm for Extensive-Form Correlated Equilibrium", ["Gabriele Farina", "Chun Kai Ling", "Fei Fang", "Tuomas Sandholm"], "http://papers.nips.cc/paper/8761-efficient-regret-minimization-algorithm-for-extensive-form-correlated-equilibrium", 11, "neurips", 2019], ["Optimistic Regret Minimization for Extensive-Form Games via Dilated Distance-Generating Functions", ["Gabriele Farina", "Christian Kroer", "Tuomas Sandholm"], "http://papers.nips.cc/paper/8764-optimistic-regret-minimization-for-extensive-form-games-via-dilated-distance-generating-functions", 11, "neurips", 2019], ["Correlation in Extensive-Form Games: Saddle-Point Formulation and Benchmarks", ["Gabriele Farina", "Chun Kai Ling", "Fei Fang", "Tuomas Sandholm"], "http://papers.nips.cc/paper/9122-correlation-in-extensive-form-games-saddle-point-formulation-and-benchmarks", 11, "neurips", 2019]], "Igor Gitman": [0, ["Understanding the Role of Momentum in Stochastic Gradient Methods", ["Igor Gitman", "Hunter Lang", "Pengchuan Zhang", "Lin Xiao"], "http://papers.nips.cc/paper/9158-understanding-the-role-of-momentum-in-stochastic-gradient-methods", 11, "neurips", 2019]], "Hedi Hadiji": [0, ["Polynomial Cost of Adaptation for X-Armed Bandits", ["Hedi Hadiji"], "http://papers.nips.cc/paper/8388-polynomial-cost-of-adaptation-for-x-armed-bandits", 10, "neurips", 2019]], "Mikhail Khodak": [0, ["Adaptive Gradient-Based Meta-Learning Methods", ["Mikhail Khodak", "Maria-Florina Balcan", "Ameet S. Talwalkar"], "http://papers.nips.cc/paper/8826-adaptive-gradient-based-meta-learning-methods", 12, "neurips", 2019]], "Jae Hyun Lim": [0.9989170581102371, ["Neural Multisensory Scene Inference", ["Jae Hyun Lim", "Pedro O. Pinheiro", "Negar Rostamzadeh", "Chris Pal", "Sungjin Ahn"], "http://papers.nips.cc/paper/9101-neural-multisensory-scene-inference", 11, "neurips", 2019]], "Kimon Antonakopoulos": [0, ["An adaptive Mirror-Prox method for variational inequalities with singular operators", ["Kimon Antonakopoulos", "Elena Veronica Belmega", "Panayotis Mertikopoulos"], "http://papers.nips.cc/paper/9053-an-adaptive-mirror-prox-method-for-variational-inequalities-with-singular-operators", 11, "neurips", 2019]], "Thang Vu": [0, ["Cascade RPN: Delving into High-Quality Region Proposal Network with Adaptive Convolution", ["Thang Vu", "Hyunjun Jang", "Trung X. Pham", "Chang Dong Yoo"], "http://papers.nips.cc/paper/8423-cascade-rpn-delving-into-high-quality-region-proposal-network-with-adaptive-convolution", 11, "neurips", 2019]], "Yujia Jin": [0.00011134403393953107, ["Principal Component Projection and Regression in Nearly Linear Time through Asymmetric SVRG", ["Yujia Jin", "Aaron Sidford"], "http://papers.nips.cc/paper/8642-principal-component-projection-and-regression-in-nearly-linear-time-through-asymmetric-svrg", 11, "neurips", 2019]], "Hengyuan Hu": [0, ["Hierarchical Decision Making by Generating and Following Natural Language Instructions", ["Hengyuan Hu", "Denis Yarats", "Qucheng Gong", "Yuandong Tian", "Mike Lewis"], "http://papers.nips.cc/paper/9193-hierarchical-decision-making-by-generating-and-following-natural-language-instructions", 10, "neurips", 2019]], "Yihan Jiang": [0, ["Turbo Autoencoder: Deep learning based channel codes for point-to-point communication channels", ["Yihan Jiang", "Hyeji Kim", "Himanshu Asnani", "Sreeram Kannan", "Sewoong Oh", "Pramod Viswanath"], "http://papers.nips.cc/paper/8543-turbo-autoencoder-deep-learning-based-channel-codes-for-point-to-point-communication-channels", 11, "neurips", 2019]], "Shupeng Gui": [0, ["Model Compression with Adversarial Robustness: A Unified Optimization Framework", ["Shupeng Gui", "Haotao Wang", "Haichuan Yang", "Chen Yu", "Zhangyang Wang", "Ji Liu"], "http://papers.nips.cc/paper/8410-model-compression-with-adversarial-robustness-a-unified-optimization-framework", 12, "neurips", 2019]], "Remy Degenne": [0, ["Non-Asymptotic Pure Exploration by Solving Games", ["Remy Degenne", "Wouter M. Koolen", "Pierre Menard"], "http://papers.nips.cc/paper/9592-non-asymptotic-pure-exploration-by-solving-games", 10, "neurips", 2019], ["Pure Exploration with Multiple Correct Answers", ["Remy Degenne", "Wouter M. Koolen"], "http://papers.nips.cc/paper/9601-pure-exploration-with-multiple-correct-answers", 10, "neurips", 2019]], "Ruqi Zhang": [0, ["Poisson-Minibatching for Gibbs Sampling with Convergence Rate Guarantees", ["Ruqi Zhang", "Christopher De Sa"], "http://papers.nips.cc/paper/8738-poisson-minibatching-for-gibbs-sampling-with-convergence-rate-guarantees", 10, "neurips", 2019]], "Bo Dai": [0, ["Exponential Family Estimation via Adversarial Dynamics Embedding", ["Bo Dai", "Zhen Liu", "Hanjun Dai", "Niao He", "Arthur Gretton", "Le Song", "Dale Schuurmans"], "http://papers.nips.cc/paper/9279-exponential-family-estimation-via-adversarial-dynamics-embedding", 12, "neurips", 2019]], "Antonio Ginart": [0, ["Making AI Forget You: Data Deletion in Machine Learning", ["Antonio Ginart", "Melody Y. Guan", "Gregory Valiant", "James Zou"], "http://papers.nips.cc/paper/8611-making-ai-forget-you-data-deletion-in-machine-learning", 14, "neurips", 2019]], "Mahesh Chandra Mukkamala": [0, ["Beyond Alternating Updates for Matrix Factorization with Inertial Bregman Proximal Gradient Algorithms", ["Mahesh Chandra Mukkamala", "Peter Ochs"], "http://papers.nips.cc/paper/8679-beyond-alternating-updates-for-matrix-factorization-with-inertial-bregman-proximal-gradient-algorithms", 11, "neurips", 2019]], "Arun Verma": [0, ["Censored Semi-Bandits: A Framework for Resource Allocation with Censored Feedback", ["Arun Verma", "Manjesh K. Hanawal", "Arun Rajkumar", "Raman Sankaran"], "http://papers.nips.cc/paper/9595-censored-semi-bandits-a-framework-for-resource-allocation-with-censored-feedback", 11, "neurips", 2019]], "Song Liu": [0, ["Fisher Efficient Inference of Intractable Models", ["Song Liu", "Takafumi Kanamori", "Wittawat Jitkrittum", "Yu Chen"], "http://papers.nips.cc/paper/9083-fisher-efficient-inference-of-intractable-models", 11, "neurips", 2019]], "Maria Jahja": [0, ["Kalman Filter, Sensor Fusion, and Constrained Regression: Equivalences and Insights", ["Maria Jahja", "David C. Farrow", "Roni Rosenfeld", "Ryan J. Tibshirani"], "http://papers.nips.cc/paper/9475-kalman-filter-sensor-fusion-and-constrained-regression-equivalences-and-insights", 10, "neurips", 2019]], "Theo Deprelle": [0, ["Learning elementary structures for 3D shape generation and matching", ["Theo Deprelle", "Thibault Groueix", "Matthew Fisher", "Vladimir G. Kim", "Bryan C. Russell", "Mathieu Aubry"], "http://papers.nips.cc/paper/8962-learning-elementary-structures-for-3d-shape-generation-and-matching", 11, "neurips", 2019]], "Sumeet Katariya": [0, ["MaxGap Bandit: Adaptive Algorithms for Approximate Ranking", ["Sumeet Katariya", "Ardhendu Tripathy", "Robert D. Nowak"], "http://papers.nips.cc/paper/9285-maxgap-bandit-adaptive-algorithms-for-approximate-ranking", 11, "neurips", 2019]], "David Martinez-Rubio": [0, ["Decentralized Cooperative Stochastic Bandits", ["David Martinez-Rubio", "Varun Kanade", "Patrick Rebeschini"], "http://papers.nips.cc/paper/8702-decentralized-cooperative-stochastic-bandits", 12, "neurips", 2019]], "Gagandeep Singh": [0, ["Beyond the Single Neuron Convex Barrier for Neural Network Certification", ["Gagandeep Singh", "Rupanshu Ganvir", "Markus Puschel", "Martin T. Vechev"], "http://papers.nips.cc/paper/9646-beyond-the-single-neuron-convex-barrier-for-neural-network-certification", 12, "neurips", 2019]], "James Jordon": [0, ["Differentially Private Bagging: Improved utility and cheaper privacy than subsample-and-aggregate", ["James Jordon", "Jinsung Yoon", "Mihaela van der Schaar"], "http://papers.nips.cc/paper/8684-differentially-private-bagging-improved-utility-and-cheaper-privacy-than-subsample-and-aggregate", 10, "neurips", 2019]], "Emilien Dupont": [0, ["Augmented Neural ODEs", ["Emilien Dupont", "Arnaud Doucet", "Yee Whye Teh"], "http://papers.nips.cc/paper/8577-augmented-neural-odes", 11, "neurips", 2019]], "Zichuan Lin": [0, ["Distributional Reward Decomposition for Reinforcement Learning", ["Zichuan Lin", "Li Zhao", "Derek Yang", "Tao Qin", "Tie-Yan Liu", "Guangwen Yang"], "http://papers.nips.cc/paper/8852-distributional-reward-decomposition-for-reinforcement-learning", 10, "neurips", 2019]], "Qi Zhao": [0, ["Learning metrics for persistence-based summaries and applications for graph classification", ["Qi Zhao", "Yusu Wang"], "http://papers.nips.cc/paper/9178-learning-metrics-for-persistence-based-summaries-and-applications-for-graph-classification", 12, "neurips", 2019]], "Ayoub Belhadji": [0, ["Kernel quadrature with DPPs", ["Ayoub Belhadji", "Remi Bardenet", "Pierre Chainais"], "http://papers.nips.cc/paper/9452-kernel-quadrature-with-dpps", 11, "neurips", 2019]], "Pranjal Awasthi": [0, ["On Robustness to Adversarial Examples and Polynomial Optimization", ["Pranjal Awasthi", "Abhratanu Dutta", "Aravindan Vijayaraghavan"], "http://papers.nips.cc/paper/9526-on-robustness-to-adversarial-examples-and-polynomial-optimization", 11, "neurips", 2019]], "Mahdi Karami": [0, ["Invertible Convolutional Flow", ["Mahdi Karami", "Dale Schuurmans", "Jascha Sohl-Dickstein", "Laurent Dinh", "Daniel Duckworth"], "http://papers.nips.cc/paper/8801-invertible-convolutional-flow", 11, "neurips", 2019]], "Moses Charikar": [0, ["A General Framework for Symmetric Property Estimation", ["Moses Charikar", "Kirankumar Shiragur", "Aaron Sidford"], "http://papers.nips.cc/paper/9409-a-general-framework-for-symmetric-property-estimation", 11, "neurips", 2019]], "Mingrui Zhang": [0, ["Online Continuous Submodular Maximization: From Full-Information to Bandit Feedback", ["Mingrui Zhang", "Lin Chen", "Hamed Hassani", "Amin Karbasi"], "http://papers.nips.cc/paper/9120-online-continuous-submodular-maximization-from-full-information-to-bandit-feedback", 12, "neurips", 2019]], "Yu-Guan Hsieh": [0, ["On the convergence of single-call stochastic extra-gradient methods", ["Yu-Guan Hsieh", "Franck Iutzeler", "Jerome Malick", "Panayotis Mertikopoulos"], "http://papers.nips.cc/paper/8917-on-the-convergence-of-single-call-stochastic-extra-gradient-methods", 11, "neurips", 2019]], "Ping Li": [0, ["Re-randomized Densification for One Permutation Hashing and Bin-wise Consistent Weighted Sampling", ["Ping Li", "Xiaoyun Li", "Cun-Hui Zhang"], "http://papers.nips.cc/paper/9721-re-randomized-densification-for-one-permutation-hashing-and-bin-wise-consistent-weighted-sampling", 11, "neurips", 2019]], "Lin Chen": [0, ["Locality-Sensitive Hashing for f-Divergences: Mutual Information Loss and Beyond", ["Lin Chen", "Hossein Esfandiari", "Gang Fu", "Vahab S. Mirrokni"], "http://papers.nips.cc/paper/9195-locality-sensitive-hashing-for-f-divergences-mutual-information-loss-and-beyond", 11, "neurips", 2019]], "Vincent Le Guen": [0, ["Shape and Time Distortion Loss for Training Deep Time Series Forecasting Models", ["Vincent Le Guen", "Nicolas Thome"], "http://papers.nips.cc/paper/8672-shape-and-time-distortion-loss-for-training-deep-time-series-forecasting-models", 13, "neurips", 2019]], "Zhuoran Yang": [5.880045117478971e-09, ["Provably Global Convergence of Actor-Critic: A Case for Linear Quadratic Regulator with Ergodic Cost", ["Zhuoran Yang", "Yongxin Chen", "Mingyi Hong", "Zhaoran Wang"], "http://papers.nips.cc/paper/9044-provably-global-convergence-of-actor-critic-a-case-for-linear-quadratic-regulator-with-ergodic-cost", 13, "neurips", 2019]], "Florian Schafer": [0, ["Competitive Gradient Descent", ["Florian Schafer", "Anima Anandkumar"], "http://papers.nips.cc/paper/8979-competitive-gradient-descent", 11, "neurips", 2019]], "Yukang Chen": [0, ["DetNAS: Backbone Search for Object Detection", ["Yukang Chen", "Tong Yang", "Xiangyu Zhang", "Gaofeng Meng", "Xinyu Xiao", "Jian Sun"], "http://papers.nips.cc/paper/8890-detnas-backbone-search-for-object-detection", 11, "neurips", 2019]], "John Bradshaw": [0, ["A Model to Search for Synthesizable Molecules", ["John Bradshaw", "Brooks Paige", "Matt J. Kusner", "Marwin H. S. Segler", "Jose Miguel Hernandez-Lobato"], "http://papers.nips.cc/paper/9007-a-model-to-search-for-synthesizable-molecules", 13, "neurips", 2019]], "John Lee": [0.0002870158787118271, ["Hierarchical Optimal Transport for Multimodal Distribution Alignment", ["John Lee", "Max Dabagia", "Eva L. Dyer", "Christopher Rozell"], "http://papers.nips.cc/paper/9501-hierarchical-optimal-transport-for-multimodal-distribution-alignment", 11, "neurips", 2019]], "Christopher Thomas": [0, ["Predicting the Politics of an Image Using Webly Supervised Data", ["Christopher Thomas", "Adriana Kovashka"], "http://papers.nips.cc/paper/8621-predicting-the-politics-of-an-image-using-webly-supervised-data", 13, "neurips", 2019]], "Sushrut Karmalkar": [0, ["List-decodable Linear Regression", ["Sushrut Karmalkar", "Adam R. Klivans", "Pravesh Kothari"], "http://papers.nips.cc/paper/8961-list-decodable-linear-regression", 10, "neurips", 2019]], "Yaqin Zhou": [0, ["Devign: Effective Vulnerability Identification by Learning Comprehensive Program Semantics via Graph Neural Networks", ["Yaqin Zhou", "Shangqing Liu", "Jing Kai Siow", "Xiaoning Du", "Yang Liu"], "http://papers.nips.cc/paper/9209-devign-effective-vulnerability-identification-by-learning-comprehensive-program-semantics-via-graph-neural-networks", 11, "neurips", 2019]], "Philippe Casgrain": [0, ["A Latent Variational Framework for Stochastic Optimization", ["Philippe Casgrain"], "http://papers.nips.cc/paper/8802-a-latent-variational-framework-for-stochastic-optimization", 11, "neurips", 2019]], "Adam Bielski": [0, ["Emergence of Object Segmentation in Perturbed Generative Models", ["Adam Bielski", "Paolo Favaro"], "http://papers.nips.cc/paper/8946-emergence-of-object-segmentation-in-perturbed-generative-models", 11, "neurips", 2019]], "Zelda E. Mariet": [0, ["DppNet: Approximating Determinantal Point Processes with Deep Networks", ["Zelda E. Mariet", "Yaniv Ovadia", "Jasper Snoek"], "http://papers.nips.cc/paper/8585-dppnet-approximating-determinantal-point-processes-with-deep-networks", 12, "neurips", 2019]], "Ivan Stelmakh": [0, ["On Testing for Biases in Peer Review", ["Ivan Stelmakh", "Nihar B. Shah", "Aarti Singh"], "http://papers.nips.cc/paper/8770-on-testing-for-biases-in-peer-review", 11, "neurips", 2019]], "Creighton Heaukulani": [0, ["Scalable Bayesian dynamic covariance modeling with variational Wishart and inverse Wishart processes", ["Creighton Heaukulani", "Mark van der Wilk"], "http://papers.nips.cc/paper/8707-scalable-bayesian-dynamic-covariance-modeling-with-variational-wishart-and-inverse-wishart-processes", 11, "neurips", 2019]], "Ehsan Hajiramezanali": [0, ["Variational Graph Recurrent Neural Networks", ["Ehsan Hajiramezanali", "Arman Hasanzadeh", "Krishna R. Narayanan", "Nick Duffield", "Mingyuan Zhou", "Xiaoning Qian"], "http://papers.nips.cc/paper/9254-variational-graph-recurrent-neural-networks", 11, "neurips", 2019]], "Coline Devin": [0, ["Compositional Plan Vectors", ["Coline Devin", "Daniel Geng", "Pieter Abbeel", "Trevor Darrell", "Sergey Levine"], "http://papers.nips.cc/paper/9636-compositional-plan-vectors", 12, "neurips", 2019]], "Yiren Wang": [9.714566840557382e-05, ["Neural Machine Translation with Soft Prototype", ["Yiren Wang", "Yingce Xia", "Fei Tian", "Fei Gao", "Tao Qin", "ChengXiang Zhai", "Tie-Yan Liu"], "http://papers.nips.cc/paper/8861-neural-machine-translation-with-soft-prototype", 10, "neurips", 2019]], "Mislav Balunovic": [0, ["Certifying Geometric Robustness of Neural Networks", ["Mislav Balunovic", "Maximilian Baader", "Gagandeep Singh", "Timon Gehr", "Martin T. Vechev"], "http://papers.nips.cc/paper/9666-certifying-geometric-robustness-of-neural-networks", 11, "neurips", 2019]], "Hao Cui": [0, ["Sampling Networks and Aggregate Simulation for Online POMDP Planning", ["Hao Cui", "Roni Khardon"], "http://papers.nips.cc/paper/9121-sampling-networks-and-aggregate-simulation-for-online-pomdp-planning", 11, "neurips", 2019]], "Gecia Bravo Hermsdorff": [0, ["A Unifying Framework for Spectrum-Preserving Graph Sparsification and Coarsening", ["Gecia Bravo Hermsdorff", "Lee M. Gunderson"], "http://papers.nips.cc/paper/8989-a-unifying-framework-for-spectrum-preserving-graph-sparsification-and-coarsening", 12, "neurips", 2019]], "Denis Mazur": [0, ["Beyond Vector Spaces: Compact Data Representation as Differentiable Weighted Graphs", ["Denis Mazur", "Vage Egiazarian", "Stanislav Morozov", "Artem Babenko"], "http://papers.nips.cc/paper/8914-beyond-vector-spaces-compact-data-representation-as-differentiable-weighted-graphs", 11, "neurips", 2019]], "Hugo Caselles-Dupre": [0, ["Symmetry-Based Disentangled Representation Learning requires Interaction with Environments", ["Hugo Caselles-Dupre", "Michael Garcia Ortiz", "David Filliat"], "http://papers.nips.cc/paper/8709-symmetry-based-disentangled-representation-learning-requires-interaction-with-environments", 10, "neurips", 2019]], "Lisha Chen": [0, ["Deep Structured Prediction for Facial Landmark Detection", ["Lisha Chen", "Hui Su", "Qiang Ji"], "http://papers.nips.cc/paper/8515-deep-structured-prediction-for-facial-landmark-detection", 11, "neurips", 2019]], "Arindam Banerjee": [0, ["Random Quadratic Forms with Dependence: Applications to Restricted Isometry and Beyond", ["Arindam Banerjee", "Qilong Gu", "Vidyashankar Sivakumar", "Steven Z. Wu"], "http://papers.nips.cc/paper/9423-random-quadratic-forms-with-dependence-applications-to-restricted-isometry-and-beyond", 11, "neurips", 2019]], "Yingdong Lu": [0, ["A Family of Robust Stochastic Operators for Reinforcement Learning", ["Yingdong Lu", "Mark S. Squillante", "Chai Wah Wu"], "http://papers.nips.cc/paper/9696-a-family-of-robust-stochastic-operators-for-reinforcement-learning", 11, "neurips", 2019]], "Rodrigo Toro Icarte": [0, ["Learning Reward Machines for Partially Observable Reinforcement Learning", ["Rodrigo Toro Icarte", "Ethan Waldie", "Toryn Q. Klassen", "Richard Anthony Valenzano", "Margarita P. Castro", "Sheila A. McIlraith"], "http://papers.nips.cc/paper/9685-learning-reward-machines-for-partially-observable-reinforcement-learning", 12, "neurips", 2019]], "Danfei Xu": [0, ["Regression Planning Networks", ["Danfei Xu", "Roberto Martin-Martin", "De-An Huang", "Yuke Zhu", "Silvio Savarese", "Li F. Fei-Fei"], "http://papers.nips.cc/paper/8413-regression-planning-networks", 11, "neurips", 2019]], "Guannan Zhang": [0, ["Learning nonlinear level sets for dimensionality reduction in function approximation", ["Guannan Zhang", "Jiaxin Zhang", "Jacob Hinkle"], "http://papers.nips.cc/paper/9478-learning-nonlinear-level-sets-for-dimensionality-reduction-in-function-approximation", 10, "neurips", 2019]], "Sharon Qian": [0, ["Fast Parallel Algorithms for Statistical Subset Selection Problems", ["Sharon Qian", "Yaron Singer"], "http://papers.nips.cc/paper/8751-fast-parallel-algorithms-for-statistical-subset-selection-problems", 10, "neurips", 2019]], "Lingrui Gan": [1.5609651071724073e-10, ["Bayesian Joint Estimation of Multiple Graphical Models", ["Lingrui Gan", "Xinming Yang", "Naveen N. Narisetty", "Feng Liang"], "http://papers.nips.cc/paper/9173-bayesian-joint-estimation-of-multiple-graphical-models", 11, "neurips", 2019]], "Jianchun Chen": [0, ["Arbicon-Net: Arbitrary Continuous Geometric Transformation Networks for Image Registration", ["Jianchun Chen", "Lingjing Wang", "Xiang Li", "Yi Fang"], "http://papers.nips.cc/paper/8602-arbicon-net-arbitrary-continuous-geometric-transformation-networks-for-image-registration", 11, "neurips", 2019]], "Drew A. Hudson": [0, ["Learning by Abstraction: The Neural State Machine", ["Drew A. Hudson", "Christopher D. Manning"], "http://papers.nips.cc/paper/8825-learning-by-abstraction-the-neural-state-machine", 14, "neurips", 2019]], "Roi Livni": [0, ["Graph-based Discriminators: Sample Complexity and Expressiveness", ["Roi Livni", "Yishay Mansour"], "http://papers.nips.cc/paper/8895-graph-based-discriminators-sample-complexity-and-expressiveness", 10, "neurips", 2019]], "Gautam Goel": [0, ["Beyond Online Balanced Descent: An Optimal Algorithm for Smoothed Online Optimization", ["Gautam Goel", "Yiheng Lin", "Haoyuan Sun", "Adam Wierman"], "http://papers.nips.cc/paper/8463-beyond-online-balanced-descent-an-optimal-algorithm-for-smoothed-online-optimization", 11, "neurips", 2019]], "Devansh Arpit": [0, ["How to Initialize your Network? Robust Initialization for WeightNorm & ResNets", ["Devansh Arpit", "Victor Campos", "Yoshua Bengio"], "http://papers.nips.cc/paper/9272-how-to-initialize-your-network-robust-initialization-for-weightnorm-resnets", 10, "neurips", 2019]], "Magauiya Zhussip": [0, ["Extending Stein's unbiased risk estimator to train deep denoisers with correlated pairs of noisy images", ["Magauiya Zhussip", "Shakarim Soltanayev", "Se Young Chun"], "http://papers.nips.cc/paper/8426-extending-steins-unbiased-risk-estimator-to-train-deep-denoisers-with-correlated-pairs-of-noisy-images", 11, "neurips", 2019]], "Robert Osazuwa Ness": [0, ["Integrating Markov processes with structural causal modeling enables counterfactual inference in complex systems", ["Robert Osazuwa Ness", "Kaushal Paneri", "Olga Vitek"], "http://papers.nips.cc/paper/9569-integrating-markov-processes-with-structural-causal-modeling-enables-counterfactual-inference-in-complex-systems", 11, "neurips", 2019]], "Randall Balestriero": [0, ["The Geometry of Deep Networks: Power Diagram Subdivision", ["Randall Balestriero", "Romain Cosentino", "Behnaam Aazhang", "Richard G. Baraniuk"], "http://papers.nips.cc/paper/9712-the-geometry-of-deep-networks-power-diagram-subdivision", 10, "neurips", 2019]], "Giovanni Chierchia": [0, ["Ultrametric Fitting by Gradient Descent", ["Giovanni Chierchia", "Benjamin Perret"], "http://papers.nips.cc/paper/8581-ultrametric-fitting-by-gradient-descent", 12, "neurips", 2019]], "Jiong Zhang": [0, ["AutoAssist: A Framework to Accelerate Training of Deep Neural Networks", ["Jiong Zhang", "Hsiang-Fu Yu", "Inderjit S. Dhillon"], "http://papers.nips.cc/paper/8833-autoassist-a-framework-to-accelerate-training-of-deep-neural-networks", 11, "neurips", 2019]], "Conor Durkan": [0, ["Neural Spline Flows", ["Conor Durkan", "Artur Bekasov", "Iain Murray", "George Papamakarios"], "http://papers.nips.cc/paper/8969-neural-spline-flows", 12, "neurips", 2019]], "Yair Carmon": [0, ["Unlabeled Data Improves Adversarial Robustness", ["Yair Carmon", "Aditi Raghunathan", "Ludwig Schmidt", "John C. Duchi", "Percy Liang"], "http://papers.nips.cc/paper/9298-unlabeled-data-improves-adversarial-robustness", 12, "neurips", 2019], ["Variance Reduction for Matrix Games", ["Yair Carmon", "Yujia Jin", "Aaron Sidford", "Kevin Tian"], "http://papers.nips.cc/paper/9315-variance-reduction-for-matrix-games", 12, "neurips", 2019]], "Andrei Liviu Nicolicioiu": [0, ["Recurrent Space-time Graph Neural Networks", ["Andrei Liviu Nicolicioiu", "Iulia Duta", "Marius Leordeanu"], "http://papers.nips.cc/paper/9444-recurrent-space-time-graph-neural-networks", 13, "neurips", 2019]], "Chen Tessler": [0, ["Distributional Policy Optimization: An Alternative Approach for Continuous Control", ["Chen Tessler", "Guy Tennenholtz", "Shie Mannor"], "http://papers.nips.cc/paper/8416-distributional-policy-optimization-an-alternative-approach-for-continuous-control", 11, "neurips", 2019]], "Hyeonwoo Yu": [0.9998723268508911, ["Zero-shot Learning via Simultaneous Generating and Learning", ["Hyeonwoo Yu", "Beomhee Lee"], "http://papers.nips.cc/paper/8300-zero-shot-learning-via-simultaneous-generating-and-learning", 11, "neurips", 2019]], "Honghao Li": [0, ["Constraint-based Causal Structure Learning with Consistent Separating Sets", ["Honghao Li", "Vincent Cabeli", "Nadir Sella", "Herve Isambert"], "http://papers.nips.cc/paper/9573-constraint-based-causal-structure-learning-with-consistent-separating-sets", 10, "neurips", 2019]], "Jian Sun": [0.40413545072078705, ["Neural Diffusion Distance for Image Segmentation", ["Jian Sun", "Zongben Xu"], "http://papers.nips.cc/paper/8424-neural-diffusion-distance-for-image-segmentation", 11, "neurips", 2019]], "Jicong Fan": [0, ["Factor Group-Sparse Regularization for Efficient Low-Rank Matrix Recovery", ["Jicong Fan", "Lijun Ding", "Yudong Chen", "Madeleine Udell"], "http://papers.nips.cc/paper/8754-factor-group-sparse-regularization-for-efficient-low-rank-matrix-recovery", 11, "neurips", 2019]], "Don Kurian Dennis": [0, ["Shallow RNN: Accurate Time-series Classification on Resource Constrained Devices", ["Don Kurian Dennis", "Durmus Alp Emre Acar", "Vikram Mandikal", "Vinu Sankar Sadasivan", "Venkatesh Saligrama", "Harsha Vardhan Simhadri", "Prateek Jain"], "http://papers.nips.cc/paper/9451-shallow-rnn-accurate-time-series-classification-on-resource-constrained-devices", 11, "neurips", 2019]], "Maher Nouiehed": [0, ["Solving a Class of Non-Convex Min-Max Games Using Iterative First Order Methods", ["Maher Nouiehed", "Maziar Sanjabi", "Tianjian Huang", "Jason D. Lee", "Meisam Razaviyayn"], "http://papers.nips.cc/paper/9631-solving-a-class-of-non-convex-min-max-games-using-iterative-first-order-methods", 12, "neurips", 2019]], "Hermina Petric Maretic": [0, ["GOT: An Optimal Transport framework for Graph comparison", ["Hermina Petric Maretic", "Mireille El Gheche", "Giovanni Chierchia", "Pascal Frossard"], "http://papers.nips.cc/paper/9539-got-an-optimal-transport-framework-for-graph-comparison", 12, "neurips", 2019]], "Stefan Meintrup": [0, ["Random Projections and Sampling Algorithms for Clustering of High-Dimensional Polygonal Curves", ["Stefan Meintrup", "Alexander Munteanu", "Dennis Rohde"], "http://papers.nips.cc/paper/9443-random-projections-and-sampling-algorithms-for-clustering-of-high-dimensional-polygonal-curves", 11, "neurips", 2019]], "Jennifer L. Cardona": [0, ["Seeing the Wind: Visual Wind Speed Prediction with a Coupled Convolutional and Recurrent Neural Network", ["Jennifer L. Cardona", "Michael F. Howland", "John O. Dabiri"], "http://papers.nips.cc/paper/9078-seeing-the-wind-visual-wind-speed-prediction-with-a-coupled-convolutional-and-recurrent-neural-network", 11, "neurips", 2019]], "Tian Qi Chen": [0, ["Residual Flows for Invertible Generative Modeling", ["Tian Qi Chen", "Jens Behrmann", "David Duvenaud", "Jorn-Henrik Jacobsen"], "http://papers.nips.cc/paper/9183-residual-flows-for-invertible-generative-modeling", 11, "neurips", 2019], ["Neural Networks with Cheap Differential Operators", ["Tian Qi Chen", "David Duvenaud"], "http://papers.nips.cc/paper/9187-neural-networks-with-cheap-differential-operators", 11, "neurips", 2019]], "Martin Trapp": [0, ["Bayesian Learning of Sum-Product Networks", ["Martin Trapp", "Robert Peharz", "Hong Ge", "Franz Pernkopf", "Zoubin Ghahramani"], "http://papers.nips.cc/paper/8864-bayesian-learning-of-sum-product-networks", 12, "neurips", 2019]], "Miao Zhang": [0, ["Memory-oriented Decoder for Light Field Salient Object Detection", ["Miao Zhang", "Jingjing Li", "Ji Wei", "Yongri Piao", "Huchuan Lu"], "http://papers.nips.cc/paper/8376-memory-oriented-decoder-for-light-field-salient-object-detection", 11, "neurips", 2019]], "Ian Char": [0, ["Offline Contextual Bayesian Optimization", ["Ian Char", "Youngseog Chung", "Willie Neiswanger", "Kirthevasan Kandasamy", "Oak Nelson", "Mark D. Boyer", "Egemen Kolemen"], "http://papers.nips.cc/paper/8711-offline-contextual-bayesian-optimization", 12, "neurips", 2019]], "Ruoxi Sun": [4.52809956197342e-09, ["Scalable Bayesian inference of dendritic voltage via spatiotemporal recurrent state space models", ["Ruoxi Sun", "Scott W. Linderman", "Ian Kinsella", "Liam Paninski"], "http://papers.nips.cc/paper/9206-scalable-bayesian-inference-of-dendritic-voltage-via-spatiotemporal-recurrent-state-space-models", 10, "neurips", 2019]], "Arsenii Vanunts": [0, ["Optimal Pricing in Repeated Posted-Price Auctions with Different Patience of the Seller and the Buyer", ["Arsenii Vanunts", "Alexey Drutsa"], "http://papers.nips.cc/paper/8380-optimal-pricing-in-repeated-posted-price-auctions-with-different-patience-of-the-seller-and-the-buyer", 13, "neurips", 2019]], "Vivek Veeriah": [0, ["Discovery of Useful Questions as Auxiliary Tasks", ["Vivek Veeriah", "Matteo Hessel", "Zhongwen Xu", "Janarthanan Rajendran", "Richard L. Lewis", "Junhyuk Oh", "Hado van Hasselt", "David Silver", "Satinder Singh"], "http://papers.nips.cc/paper/9129-discovery-of-useful-questions-as-auxiliary-tasks", 12, "neurips", 2019]], "Sujoy Paul": [0, ["Learning from Trajectories via Subgoal Discovery", ["Sujoy Paul", "Jeroen van Baar", "Amit K. Roy-Chowdhury"], "http://papers.nips.cc/paper/9049-learning-from-trajectories-via-subgoal-discovery", 11, "neurips", 2019]], "Matthew Fellows": [0, ["VIREL: A Variational Inference Framework for Reinforcement Learning", ["Matthew Fellows", "Anuj Mahajan", "Tim G. J. Rudner", "Shimon Whiteson"], "http://papers.nips.cc/paper/8934-virel-a-variational-inference-framework-for-reinforcement-learning", 15, "neurips", 2019]], "Alon Cohen": [0, ["Learning to Screen", ["Alon Cohen", "Avinatan Hassidim", "Haim Kaplan", "Yishay Mansour", "Shay Moran"], "http://papers.nips.cc/paper/9067-learning-to-screen", 10, "neurips", 2019]], "Ching-Yi Hung": [0, ["Compacting, Picking and Growing for Unforgetting Continual Learning", ["Ching-Yi Hung", "Cheng-Hao Tu", "Cheng-En Wu", "Chien-Hung Chen", "Yi-Ming Chan", "Chu-Song Chen"], "http://papers.nips.cc/paper/9518-compacting-picking-and-growing-for-unforgetting-continual-learning", 11, "neurips", 2019]], "Qi Lei": [0, ["Primal-Dual Block Generalized Frank-Wolfe", ["Qi Lei", "Jiacheng Zhuo", "Constantine Caramanis", "Inderjit S. Dhillon", "Alexandros G. Dimakis"], "http://papers.nips.cc/paper/9538-primal-dual-block-generalized-frank-wolfe", 10, "neurips", 2019], ["Inverting Deep Generative models, One layer at a time", ["Qi Lei", "Ajil Jalal", "Inderjit S. Dhillon", "Alexandros G. Dimakis"], "http://papers.nips.cc/paper/9542-inverting-deep-generative-models-one-layer-at-a-time", 10, "neurips", 2019]], "Philip Paquette": [0, ["No-Press Diplomacy: Modeling Multi-Agent Gameplay", ["Philip Paquette", "Yuchen Lu", "Steven Bocco", "Max O. Smith", "Satya Ortiz-Gagne", "Jonathan K. Kummerfeld", "Joelle Pineau", "Satinder Singh", "Aaron C. Courville"], "http://papers.nips.cc/paper/8697-no-press-diplomacy-modeling-multi-agent-gameplay", 12, "neurips", 2019]], "Akshay Krishnamurthy": [0, ["Sample Complexity of Learning Mixture of Sparse Linear Regressions", ["Akshay Krishnamurthy", "Arya Mazumdar", "Andrew McGregor", "Soumyabrata Pal"], "http://papers.nips.cc/paper/9239-sample-complexity-of-learning-mixture-of-sparse-linear-regressions", 10, "neurips", 2019]], "Xin Guo": [0, ["Learning Mean-Field Games", ["Xin Guo", "Anran Hu", "Renyuan Xu", "Junzi Zhang"], "http://papers.nips.cc/paper/8742-learning-mean-field-games", 11, "neurips", 2019]], "Akinori Tanaka": [0, ["Discriminator optimal transport", ["Akinori Tanaka"], "http://papers.nips.cc/paper/8906-discriminator-optimal-transport", 11, "neurips", 2019]], "C. Daniel Freeman": [0, ["Learning to Predict Without Looking Ahead: World Models Without Forward Prediction", ["C. Daniel Freeman", "David Ha", "Luke Metz"], "http://papers.nips.cc/paper/8778-learning-to-predict-without-looking-ahead-world-models-without-forward-prediction", 12, "neurips", 2019]], "Bichuan Guo": [0, ["AGEM: Solving Linear Inverse Problems via Deep Priors and Sampling", ["Bichuan Guo", "Yuxing Han", "Jiangtao Wen"], "http://papers.nips.cc/paper/8345-agem-solving-linear-inverse-problems-via-deep-priors-and-sampling", 12, "neurips", 2019]], "Junyu Zhang": [0, ["A Stochastic Composite Gradient Method with Incremental Variance Reduction", ["Junyu Zhang", "Lin Xiao"], "http://papers.nips.cc/paper/9108-a-stochastic-composite-gradient-method-with-incremental-variance-reduction", 11, "neurips", 2019]], "Amir-massoud Farahmand": [0, ["Value Function in Frequency Domain and the Characteristic Value Iteration Algorithm", ["Amir-massoud Farahmand"], "http://papers.nips.cc/paper/9620-value-function-in-frequency-domain-and-the-characteristic-value-iteration-algorithm", 11, "neurips", 2019]], "Jialin Wu": [0.00011382828597561456, ["Self-Critical Reasoning for Robust Visual Question Answering", ["Jialin Wu", "Raymond J. Mooney"], "http://papers.nips.cc/paper/9066-self-critical-reasoning-for-robust-visual-question-answering", 11, "neurips", 2019]], "Pan Zhou": [0, ["Efficient Meta Learning via Minibatch Proximal Update", ["Pan Zhou", "Xiaotong Yuan", "Huan Xu", "Shuicheng Yan", "Jiashi Feng"], "http://papers.nips.cc/paper/8432-efficient-meta-learning-via-minibatch-proximal-update", 11, "neurips", 2019]], "Andrey Malinin": [0, ["Reverse KL-Divergence Training of Prior Networks: Improved Uncertainty and Adversarial Robustness", ["Andrey Malinin", "Mark J. F. Gales"], "http://papers.nips.cc/paper/9597-reverse-kl-divergence-training-of-prior-networks-improved-uncertainty-and-adversarial-robustness", 12, "neurips", 2019]], "Xuechen Li": [0, ["Stochastic Runge-Kutta Accelerates Langevin Monte Carlo and Beyond", ["Xuechen Li", "Yi Wu", "Lester Mackey"], "http://papers.nips.cc/paper/8990-stochastic-runge-kutta-accelerates-langevin-monte-carlo-and-beyond", 13, "neurips", 2019]], "Ron Shapira Weber": [0, ["Diffeomorphic Temporal Alignment Nets", ["Ron Shapira Weber", "Matan Eyal", "Nicki Skafte Detlefsen", "Oren Shriki", "Oren Freifeld"], "http://papers.nips.cc/paper/8884-diffeomorphic-temporal-alignment-nets", 12, "neurips", 2019]], "Yu Qi": [0, ["Dynamic Ensemble Modeling Approach to Nonstationary Neural Decoding in Brain-Computer Interfaces", ["Yu Qi", "Bin Liu", "Yueming Wang", "Gang Pan"], "http://papers.nips.cc/paper/8841-dynamic-ensemble-modeling-approach-to-nonstationary-neural-decoding-in-brain-computer-interfaces", 10, "neurips", 2019]], "Tavor Z. Baharav": [0, ["Ultra Fast Medoid Identification via Correlated Sequential Halving", ["Tavor Z. Baharav", "David Tse"], "http://papers.nips.cc/paper/8623-ultra-fast-medoid-identification-via-correlated-sequential-halving", 10, "neurips", 2019]], "Ximing Qiao": [0, ["Defending Neural Backdoors via Generative Distribution Modeling", ["Ximing Qiao", "Yukun Yang", "Hai Li"], "http://papers.nips.cc/paper/9550-defending-neural-backdoors-via-generative-distribution-modeling", 10, "neurips", 2019]], "Wang-Zhou Dai": [0, ["Bridging Machine Learning and Logical Reasoning by Abductive Learning", ["Wang-Zhou Dai", "Qiu-Ling Xu", "Yang Yu", "Zhi-Hua Zhou"], "http://papers.nips.cc/paper/8548-bridging-machine-learning-and-logical-reasoning-by-abductive-learning", 12, "neurips", 2019]], "Yiqi Zhong": [0, ["Deep RGB-D Canonical Correlation Analysis For Sparse Depth Completion", ["Yiqi Zhong", "Cho-Ying Wu", "Suya You", "Ulrich Neumann"], "http://papers.nips.cc/paper/8774-deep-rgb-d-canonical-correlation-analysis-for-sparse-depth-completion", 11, "neurips", 2019]], "Tharun Medini": [0, ["Extreme Classification in Log Memory using Count-Min Sketch: A Case Study of Amazon Search with 50M Products", ["Tharun Medini", "Qixuan Huang", "Yiqiu Wang", "Vijai Mohan", "Anshumali Shrivastava"], "http://papers.nips.cc/paper/9482-extreme-classification-in-log-memory-using-count-min-sketch-a-case-study-of-amazon-search-with-50m-products", 11, "neurips", 2019]], "Wenjie Shi": [0, ["Regularized Anderson Acceleration for Off-Policy Deep Reinforcement Learning", ["Wenjie Shi", "Shiji Song", "Hui Wu", "Ya-Chu Hsu", "Cheng Wu", "Gao Huang"], "http://papers.nips.cc/paper/9212-regularized-anderson-acceleration-for-off-policy-deep-reinforcement-learning", 11, "neurips", 2019]], "Arnak S. Dalalyan": [0, ["Outlier-robust estimation of a sparse linear model using \\ell_1-penalized Huber's M-estimator", ["Arnak S. Dalalyan", "Philip Thompson"], "http://papers.nips.cc/paper/9477-outlier-robust-estimation-of-a-sparse-linear-model-using-ell_1-penalized-hubers-m-estimator", 11, "neurips", 2019]], "Arash Ardakani": [0, ["The Synthesis of XNOR Recurrent Neural Networks with Stochastic Logic", ["Arash Ardakani", "Zhengyun Ji", "Amir Ardakani", "Warren J. Gross"], "http://papers.nips.cc/paper/9052-the-synthesis-of-xnor-recurrent-neural-networks-with-stochastic-logic", 11, "neurips", 2019]], "Tam Le": [0, ["Tree-Sliced Variants of Wasserstein Distances", ["Tam Le", "Makoto Yamada", "Kenji Fukumizu", "Marco Cuturi"], "http://papers.nips.cc/paper/9396-tree-sliced-variants-of-wasserstein-distances", 12, "neurips", 2019]], "Anton Bakhtin": [0, ["PHYRE: A New Benchmark for Physical Reasoning", ["Anton Bakhtin", "Laurens van der Maaten", "Justin Johnson", "Laura Gustafson", "Ross B. Girshick"], "http://papers.nips.cc/paper/8752-phyre-a-new-benchmark-for-physical-reasoning", 12, "neurips", 2019]], "Tingting Qiao": [0, ["Learn, Imagine and Create: Text-to-Image Generation from Prior Knowledge", ["Tingting Qiao", "Jing Zhang", "Duanqing Xu", "Dacheng Tao"], "http://papers.nips.cc/paper/8375-learn-imagine-and-create-text-to-image-generation-from-prior-knowledge", 11, "neurips", 2019]], "Shuangfei Zhai": [0, ["Adversarial Fisher Vectors for Unsupervised Representation Learning", ["Shuangfei Zhai", "Walter Talbott", "Carlos Guestrin", "Joshua Susskind"], "http://papers.nips.cc/paper/9295-adversarial-fisher-vectors-for-unsupervised-representation-learning", 11, "neurips", 2019]], "Xiaoling Hu": [0, ["Topology-Preserving Deep Image Segmentation", ["Xiaoling Hu", "Fuxin Li", "Dimitris Samaras", "Chao Chen"], "http://papers.nips.cc/paper/8803-topology-preserving-deep-image-segmentation", 12, "neurips", 2019]], "Antreas Antoniou": [0, ["Learning to Learn By Self-Critique", ["Antreas Antoniou", "Amos J. Storkey"], "http://papers.nips.cc/paper/9185-learning-to-learn-by-self-critique", 11, "neurips", 2019]], "Max Simchowitz": [0, ["Non-Asymptotic Gap-Dependent Regret Bounds for Tabular MDPs", ["Max Simchowitz", "Kevin G. Jamieson"], "http://papers.nips.cc/paper/8399-non-asymptotic-gap-dependent-regret-bounds-for-tabular-mdps", 10, "neurips", 2019]], "Yanyao Shen": [0, ["Iterative Least Trimmed Squares for Mixed Linear Regression", ["Yanyao Shen", "Sujay Sanghavi"], "http://papers.nips.cc/paper/8840-iterative-least-trimmed-squares-for-mixed-linear-regression", 11, "neurips", 2019]], "Rajat Sen": [0, ["Think Globally, Act Locally: A Deep Neural Network Approach to High-Dimensional Time Series Forecasting", ["Rajat Sen", "Hsiang-Fu Yu", "Inderjit S. Dhillon"], "http://papers.nips.cc/paper/8730-think-globally-act-locally-a-deep-neural-network-approach-to-high-dimensional-time-series-forecasting", 10, "neurips", 2019]], "Carl Doersch": [0, ["Sim2real transfer learning for 3D human pose estimation: motion to the rescue", ["Carl Doersch", "Andrew Zisserman"], "http://papers.nips.cc/paper/9454-sim2real-transfer-learning-for-3d-human-pose-estimation-motion-to-the-rescue", 13, "neurips", 2019]], "Tomasz Kusmierczyk": [0, ["Variational Bayesian Decision-making for Continuous Utilities", ["Tomasz Kusmierczyk", "Joseph Sakaya", "Arto Klami"], "http://papers.nips.cc/paper/8868-variational-bayesian-decision-making-for-continuous-utilities", 11, "neurips", 2019]], "Daniel Levy": [0, ["Necessary and Sufficient Geometries for Gradient Methods", ["Daniel Levy", "John C. Duchi"], "http://papers.nips.cc/paper/9325-necessary-and-sufficient-geometries-for-gradient-methods", 11, "neurips", 2019]], "Zehua Zhang": [0, ["A Self Validation Network for Object-Level Human Attention Estimation", ["Zehua Zhang", "Chen Yu", "David J. Crandall"], "http://papers.nips.cc/paper/9613-a-self-validation-network-for-object-level-human-attention-estimation", 12, "neurips", 2019]], "Yiding Jiang": [0, ["Language as an Abstraction for Hierarchical Deep Reinforcement Learning", ["Yiding Jiang", "Shixiang Gu", "Kevin Murphy", "Chelsea Finn"], "http://papers.nips.cc/paper/9139-language-as-an-abstraction-for-hierarchical-deep-reinforcement-learning", 13, "neurips", 2019]], "Paul Golz": [0, ["Paradoxes in Fair Machine Learning", ["Paul Golz", "Anson Kahng", "Ariel D. Procaccia"], "http://papers.nips.cc/paper/9043-paradoxes-in-fair-machine-learning", 11, "neurips", 2019]], "Hisham Husain": [0, ["A Primal-Dual link between GANs and Autoencoders", ["Hisham Husain", "Richard Nock", "Robert C. Williamson"], "http://papers.nips.cc/paper/8333-a-primal-dual-link-between-gans-and-autoencoders", 10, "neurips", 2019]], "Allan Gronlund": [0, ["Margin-Based Generalization Lower Bounds for Boosted Classifiers", ["Allan Gronlund", "Lior Kamma", "Kasper Green Larsen", "Alexander Mathiasen", "Jelani Nelson"], "http://papers.nips.cc/paper/9365-margin-based-generalization-lower-bounds-for-boosted-classifiers", 10, "neurips", 2019]], "Paroma Varma": [0, ["Multi-Resolution Weak Supervision for Sequential Data", ["Paroma Varma", "Frederic Sala", "Shiori Sagawa", "Jason Alan Fries", "Daniel Y. Fu", "Saelig Khattar", "Ashwini Ramamoorthy", "Ke Xiao", "Kayvon Fatahalian", "James Priest", "Christopher Re"], "http://papers.nips.cc/paper/8313-multi-resolution-weak-supervision-for-sequential-data", 12, "neurips", 2019]], "Moshe Shenfeld": [0, ["A Necessary and Sufficient Stability Notion for Adaptive Generalization", ["Moshe Shenfeld", "Katrina Ligett"], "http://papers.nips.cc/paper/9324-a-necessary-and-sufficient-stability-notion-for-adaptive-generalization", 10, "neurips", 2019]], "Shanshan Wu": [7.795020565026789e-06, ["Sparse Logistic Regression Learns All Discrete Pairwise Graphical Models", ["Shanshan Wu", "Sujay Sanghavi", "Alexandros G. Dimakis"], "http://papers.nips.cc/paper/9019-sparse-logistic-regression-learns-all-discrete-pairwise-graphical-models", 11, "neurips", 2019], ["Learning Distributions Generated by One-Layer ReLU Networks", ["Shanshan Wu", "Alexandros G. Dimakis", "Sujay Sanghavi"], "http://papers.nips.cc/paper/9022-learning-distributions-generated-by-one-layer-relu-networks", 11, "neurips", 2019]], "Giulia Denevi": [0, ["Online-Within-Online Meta-Learning", ["Giulia Denevi", "Dimitris Stamos", "Carlo Ciliberto", "Massimiliano Pontil"], "http://papers.nips.cc/paper/9468-online-within-online-meta-learning", 11, "neurips", 2019]], "Matteo Togninalli": [0, ["Wasserstein Weisfeiler-Lehman Graph Kernels", ["Matteo Togninalli", "M. Elisabetta Ghisu", "Felipe Llinares-Lopez", "Bastian Rieck", "Karsten M. Borgwardt"], "http://papers.nips.cc/paper/8872-wasserstein-weisfeiler-lehman-graph-kernels", 11, "neurips", 2019]], "Zhiqiang Xu": [0, ["Towards Practical Alternating Least-Squares for CCA", ["Zhiqiang Xu", "Ping Li"], "http://papers.nips.cc/paper/9616-towards-practical-alternating-least-squares-for-cca", 10, "neurips", 2019]], "Marek Petrik": [0, ["Beyond Confidence Regions: Tight Bayesian Ambiguity Sets for Robust MDPs", ["Marek Petrik", "Reazul Hasan Russel"], "http://papers.nips.cc/paper/8927-beyond-confidence-regions-tight-bayesian-ambiguity-sets-for-robust-mdps", 10, "neurips", 2019]], "Gamaleldin F. Elsayed": [0, ["Saccader: Improving Accuracy of Hard Attention Models for Vision", ["Gamaleldin F. Elsayed", "Simon Kornblith", "Quoc V. Le"], "http://papers.nips.cc/paper/8359-saccader-improving-accuracy-of-hard-attention-models-for-vision", 13, "neurips", 2019]], "Chhavi Yadav": [0, ["Cold Case: The Lost MNIST Digits", ["Chhavi Yadav", "Leon Bottou"], "http://papers.nips.cc/paper/9500-cold-case-the-lost-mnist-digits", 10, "neurips", 2019]], "Pan Li": [0, ["Optimizing Generalized PageRank Methods for Seed-Expansion Community Detection", ["Pan Li", "I Eli Chien", "Olgica Milenkovic"], "http://papers.nips.cc/paper/9344-optimizing-generalized-pagerank-methods-for-seed-expansion-community-detection", 12, "neurips", 2019]], "Liu Leqi": [0, ["On Human-Aligned Risk Minimization", ["Liu Leqi", "Adarsh Prasad", "Pradeep Ravikumar"], "http://papers.nips.cc/paper/9642-on-human-aligned-risk-minimization", 10, "neurips", 2019]], "Yongkai Wu": [1.2477334165872378e-09, ["PC-Fairness: A Unified Framework for Measuring Causality-based Fairness", ["Yongkai Wu", "Lu Zhang", "Xintao Wu", "Hanghang Tong"], "http://papers.nips.cc/paper/8601-pc-fairness-a-unified-framework-for-measuring-causality-based-fairness", 11, "neurips", 2019]], "Ann-Kathrin Dombrowski": [0, ["Explanations can be manipulated and geometry is to blame", ["Ann-Kathrin Dombrowski", "Maximilian Alber", "Christopher J. Anders", "Marcel Ackermann", "Klaus-Robert Muller", "Pan Kessel"], "http://papers.nips.cc/paper/9511-explanations-can-be-manipulated-and-geometry-is-to-blame", 12, "neurips", 2019]], "Binghui Peng": [0, ["Adaptive Influence Maximization with Myopic Feedback", ["Binghui Peng", "Wei Chen"], "http://papers.nips.cc/paper/8795-adaptive-influence-maximization-with-myopic-feedback", 10, "neurips", 2019]], "Xinyang Chen": [0, ["Catastrophic Forgetting Meets Negative Transfer: Batch Spectral Shrinkage for Safe Transfer Learning", ["Xinyang Chen", "Sinan Wang", "Bo Fu", "Mingsheng Long", "Jianmin Wang"], "http://papers.nips.cc/paper/8466-catastrophic-forgetting-meets-negative-transfer-batch-spectral-shrinkage-for-safe-transfer-learning", 11, "neurips", 2019]], "Kwang-Sung Jun": [0.9075764417648315, ["Kernel Truncated Randomized Ridge Regression: Optimal Rates and Low Noise Acceleration", ["Kwang-Sung Jun", "Ashok Cutkosky", "Francesco Orabona"], "http://papers.nips.cc/paper/9670-kernel-truncated-randomized-ridge-regression-optimal-rates-and-low-noise-acceleration", 10, "neurips", 2019]], "Nicole Mucke": [0, ["Beating SGD Saturation with Tail-Averaging and Minibatching", ["Nicole Mucke", "Gergely Neu", "Lorenzo Rosasco"], "http://papers.nips.cc/paper/9422-beating-sgd-saturation-with-tail-averaging-and-minibatching", 10, "neurips", 2019]], "Ifigeneia Apostolopoulou": [0, ["Mutually Regressive Point Processes", ["Ifigeneia Apostolopoulou", "Scott Linderman", "Kyle Miller", "Artur Dubrawski"], "http://papers.nips.cc/paper/8755-mutually-regressive-point-processes", 12, "neurips", 2019]], "Andreas Kirsch": [0, ["BatchBALD: Efficient and Diverse Batch Acquisition for Deep Bayesian Active Learning", ["Andreas Kirsch", "Joost van Amersfoort", "Yarin Gal"], "http://papers.nips.cc/paper/8925-batchbald-efficient-and-diverse-batch-acquisition-for-deep-bayesian-active-learning", 12, "neurips", 2019]], "Adam R. Kosiorek": [0, ["Stacked Capsule Autoencoders", ["Adam R. Kosiorek", "Sara Sabour", "Yee Whye Teh", "Geoffrey E. Hinton"], "http://papers.nips.cc/paper/9684-stacked-capsule-autoencoders", 11, "neurips", 2019]], "Shengyuan Hu": [0, ["A New Defense Against Adversarial Images: Turning a Weakness into a Strength", ["Shengyuan Hu", "Tao Yu", "Chuan Guo", "Wei-Lun Chao", "Kilian Q. Weinberger"], "http://papers.nips.cc/paper/8441-a-new-defense-against-adversarial-images-turning-a-weakness-into-a-strength", 12, "neurips", 2019]], "Aliaksandr Siarohin": [0, ["First Order Motion Model for Image Animation", ["Aliaksandr Siarohin", "Stephane Lathuiliere", "Sergey Tulyakov", "Elisa Ricci", "Nicu Sebe"], "http://papers.nips.cc/paper/8935-first-order-motion-model-for-image-animation", 11, "neurips", 2019]], "Maithra Raghu": [0, ["Transfusion: Understanding Transfer Learning for Medical Imaging", ["Maithra Raghu", "Chiyuan Zhang", "Jon M. Kleinberg", "Samy Bengio"], "http://papers.nips.cc/paper/8596-transfusion-understanding-transfer-learning-for-medical-imaging", 11, "neurips", 2019]], "Yingying Li": [0, ["Online Optimal Control with Linear Dynamics and Predictions: Algorithms and Regret Analysis", ["Yingying Li", "Xin Chen", "Na Li"], "http://papers.nips.cc/paper/9627-online-optimal-control-with-linear-dynamics-and-predictions-algorithms-and-regret-analysis", 13, "neurips", 2019]], "Harikrishna Narasimhan": [0, ["Optimizing Generalized Rate Metrics with Three Players", ["Harikrishna Narasimhan", "Andrew Cotter", "Maya R. Gupta"], "http://papers.nips.cc/paper/9258-optimizing-generalized-rate-metrics-with-three-players", 12, "neurips", 2019]], "Julian Zimmert": [0, ["Connections Between Mirror Descent, Thompson Sampling and the Information Ratio", ["Julian Zimmert", "Tor Lattimore"], "http://papers.nips.cc/paper/9366-connections-between-mirror-descent-thompson-sampling-and-the-information-ratio", 10, "neurips", 2019]], "Daniel Kumor": [0, ["Efficient Identification in Linear Structural Causal Models with Instrumental Cutsets", ["Daniel Kumor", "Bryant Chen", "Elias Bareinboim"], "http://papers.nips.cc/paper/9414-efficient-identification-in-linear-structural-causal-models-with-instrumental-cutsets", 10, "neurips", 2019]], "Yuxian Meng": [0, ["Glyce: Glyph-vectors for Chinese Character Representations", ["Yuxian Meng", "Wei Wu", "Fei Wang", "Xiaoya Li", "Ping Nie", "Fan Yin", "Muyu Li", "Qinghong Han", "Xiaofei Sun", "Jiwei Li"], "http://papers.nips.cc/paper/8542-glyce-glyph-vectors-for-chinese-character-representations", 12, "neurips", 2019]], "Weishi Shi": [0, ["Integrating Bayesian and Discriminative Sparse Kernel Machines for Multi-class Active Learning", ["Weishi Shi", "Qi Yu"], "http://papers.nips.cc/paper/8500-integrating-bayesian-and-discriminative-sparse-kernel-machines-for-multi-class-active-learning", 10, "neurips", 2019]], "Yifeng Fan": [0, ["Unsupervised Co-Learning on G-Manifolds Across Irreducible Representations", ["Yifeng Fan", "Tingran Gao", "Zhizhen Zhao"], "http://papers.nips.cc/paper/9105-unsupervised-co-learning-on-g-manifolds-across-irreducible-representations", 13, "neurips", 2019]], "Shin Matsushima": [0, ["Selective Sampling-based Scalable Sparse Subspace Clustering", ["Shin Matsushima", "Maria Brbic"], "http://papers.nips.cc/paper/9408-selective-sampling-based-scalable-sparse-subspace-clustering", 10, "neurips", 2019]], "Siqi Wang": [0.00012786354272975586, ["Effective End-to-end Unsupervised Outlier Detection via Inlier Priority of Discriminative Network", ["Siqi Wang", "Yijie Zeng", "Xinwang Liu", "En Zhu", "Jianping Yin", "Chuanfu Xu", "Marius Kloft"], "http://papers.nips.cc/paper/8830-effective-end-to-end-unsupervised-outlier-detection-via-inlier-priority-of-discriminative-network", 14, "neurips", 2019]], "Su Young Lee": [0.9974546730518341, ["Sample-Efficient Deep Reinforcement Learning via Episodic Backward Update", ["Su Young Lee", "Sung-Ik Choi", "Sae-Young Chung"], "http://papers.nips.cc/paper/8484-sample-efficient-deep-reinforcement-learning-via-episodic-backward-update", 10, "neurips", 2019]], "Zhibing Zhao": [0, ["Learning Mixtures of Plackett-Luce Models from Structured Partial Orders", ["Zhibing Zhao", "Lirong Xia"], "http://papers.nips.cc/paper/9204-learning-mixtures-of-plackett-luce-models-from-structured-partial-orders", 11, "neurips", 2019]], "David Eriksson": [0, ["Scalable Global Optimization via Local Bayesian Optimization", ["David Eriksson", "Michael Pearce", "Jacob R. Gardner", "Ryan Turner", "Matthias Poloczek"], "http://papers.nips.cc/paper/8788-scalable-global-optimization-via-local-bayesian-optimization", 12, "neurips", 2019]], "Ivan Glasser": [0, ["Expressive power of tensor-network factorizations for probabilistic modeling", ["Ivan Glasser", "Ryan Sweke", "Nicola Pancotti", "Jens Eisert", "J. Ignacio Cirac"], "http://papers.nips.cc/paper/8429-expressive-power-of-tensor-network-factorizations-for-probabilistic-modeling", 13, "neurips", 2019]], "Rohan Gala": [0, ["A coupled autoencoder approach for multi-modal analysis of cell types", ["Rohan Gala", "Nathan Gouwens", "Zizhen Yao", "Agata Budzillo", "Osnat Penn", "Bosiljka Tasic", "Gabe Murphy", "Hongkui Zeng", "Uygar Sumbul"], "http://papers.nips.cc/paper/9125-a-coupled-autoencoder-approach-for-multi-modal-analysis-of-cell-types", 10, "neurips", 2019]], "Soheil Kolouri": [0, ["Generalized Sliced Wasserstein Distances", ["Soheil Kolouri", "Kimia Nadjahi", "Umut Simsekli", "Roland Badeau", "Gustavo K. Rohde"], "http://papers.nips.cc/paper/8319-generalized-sliced-wasserstein-distances", 12, "neurips", 2019]], "Jack Umenberger": [0, ["Robust exploration in linear quadratic reinforcement learning", ["Jack Umenberger", "Mina Ferizbegovic", "Thomas B. Schon", "Hakan Hjalmarsson"], "http://papers.nips.cc/paper/9668-robust-exploration-in-linear-quadratic-reinforcement-learning", 11, "neurips", 2019]], "Corey Snyder": [0, ["STREETS: A Novel Camera Network Dataset for Traffic Flow", ["Corey Snyder", "Minh Do"], "http://papers.nips.cc/paper/9213-streets-a-novel-camera-network-dataset-for-traffic-flow", 12, "neurips", 2019]], "Kareem Amin": [0, ["Differentially Private Covariance Estimation", ["Kareem Amin", "Travis Dick", "Alex Kulesza", "Andres Munoz Medina", "Sergei Vassilvitskii"], "http://papers.nips.cc/paper/9567-differentially-private-covariance-estimation", 10, "neurips", 2019]], "James Requeima": [0, ["Fast and Flexible Multi-Task Classification using Conditional Neural Adaptive Processes", ["James Requeima", "Jonathan Gordon", "John Bronskill", "Sebastian Nowozin", "Richard E. Turner"], "http://papers.nips.cc/paper/9009-fast-and-flexible-multi-task-classification-using-conditional-neural-adaptive-processes", 12, "neurips", 2019]], "Miika Aittala": [0, ["Computational Mirrors: Blind Inverse Light Transport by Deep Matrix Factorization", ["Miika Aittala", "Prafull Sharma", "Lukas Murmann", "Adam B. Yedidia", "Gregory W. Wornell", "Bill Freeman", "Fredo Durand"], "http://papers.nips.cc/paper/9578-computational-mirrors-blind-inverse-light-transport-by-deep-matrix-factorization", 11, "neurips", 2019]], "Kristjan Greenewald": [0, ["Sample Efficient Active Learning of Causal Trees", ["Kristjan Greenewald", "Dmitriy Katz", "Karthikeyan Shanmugam", "Sara Magliacane", "Murat Kocaoglu", "Enric Boix Adsera", "Guy Bresler"], "http://papers.nips.cc/paper/9575-sample-efficient-active-learning-of-causal-trees", 11, "neurips", 2019]], "Kai Zhong": [0, ["Provable Non-linear Inductive Matrix Completion", ["Kai Zhong", "Zhao Song", "Prateek Jain", "Inderjit S. Dhillon"], "http://papers.nips.cc/paper/9320-provable-non-linear-inductive-matrix-completion", 11, "neurips", 2019]], "Chao Tao": [0, ["Thresholding Bandit with Optimal Aggregate Regret", ["Chao Tao", "Saul A. Blanco", "Jian Peng", "Yuan Zhou"], "http://papers.nips.cc/paper/9340-thresholding-bandit-with-optimal-aggregate-regret", 10, "neurips", 2019]], "Alexandre Louis Lamy": [0, ["Noise-tolerant fair classification", ["Alexandre Louis Lamy", "Ziyuan Zhong"], "http://papers.nips.cc/paper/8322-noise-tolerant-fair-classification", 12, "neurips", 2019]], "Adam Foster": [0, ["Variational Bayesian Optimal Experimental Design", ["Adam Foster", "Martin Jankowiak", "Eli Bingham", "Paul Horsfall", "Yee Whye Teh", "Tom Rainforth", "Noah Goodman"], "http://papers.nips.cc/paper/9553-variational-bayesian-optimal-experimental-design", 12, "neurips", 2019]], "Brian Lubars": [0, ["Ask not what AI can do, but what AI should do: Towards a framework of task delegability", ["Brian Lubars", "Chenhao Tan"], "http://papers.nips.cc/paper/8301-ask-not-what-ai-can-do-but-what-ai-should-do-towards-a-framework-of-task-delegability", 11, "neurips", 2019]], "Kohei Hayashi": [0, ["Exploring Unexplored Tensor Network Decompositions for Convolutional Neural Networks", ["Kohei Hayashi", "Taiki Yamaguchi", "Yohei Sugawara", "Shin-ichi Maeda"], "http://papers.nips.cc/paper/8793-exploring-unexplored-tensor-network-decompositions-for-convolutional-neural-networks", 11, "neurips", 2019]], "Andrew Stirn": [0, ["A New Distribution on the Simplex with Auto-Encoding Applications", ["Andrew Stirn", "Tony Jebara", "David A. Knowles"], "http://papers.nips.cc/paper/9520-a-new-distribution-on-the-simplex-with-auto-encoding-applications", 11, "neurips", 2019]], "Senanayak Sesh Kumar Karri": [0, ["Fast Decomposable Submodular Function Minimization using Constrained Total Variation", ["Senanayak Sesh Kumar Karri", "Francis Bach", "Thomas Pock"], "http://papers.nips.cc/paper/9029-fast-decomposable-submodular-function-minimization-using-constrained-total-variation", 11, "neurips", 2019]], "Joe Kileel": [0, ["On the Expressive Power of Deep Polynomial Neural Networks", ["Joe Kileel", "Matthew Trager", "Joan Bruna"], "http://papers.nips.cc/paper/9219-on-the-expressive-power-of-deep-polynomial-neural-networks", 10, "neurips", 2019]], "David Novotny": [0, ["PerspectiveNet: A Scene-consistent Image Generator for New View Synthesis in Real Indoor Environments", ["David Novotny", "Benjamin Graham", "Jeremy Reizenstein"], "http://papers.nips.cc/paper/8977-perspectivenet-a-scene-consistent-image-generator-for-new-view-synthesis-in-real-indoor-environments", 12, "neurips", 2019]], "Jinsung Yoon": [0.9164374321699142, ["Time-series Generative Adversarial Networks", ["Jinsung Yoon", "Daniel Jarrett", "Mihaela van der Schaar"], "http://papers.nips.cc/paper/8789-time-series-generative-adversarial-networks", 11, "neurips", 2019]], "Da Xu": [0, ["Self-attention with Functional Time Representation Learning", ["Da Xu", "Chuanwei Ruan", "Evren Korpeoglu", "Sushant Kumar", "Kannan Achan"], "http://papers.nips.cc/paper/9720-self-attention-with-functional-time-representation-learning", 11, "neurips", 2019]], "Daniel E. Worrall": [0, ["Deep Scale-spaces: Equivariance Over Scale", ["Daniel E. Worrall", "Max Welling"], "http://papers.nips.cc/paper/8956-deep-scale-spaces-equivariance-over-scale", 13, "neurips", 2019]], "Rafael Pinot": [0, ["Theoretical evidence for adversarial robustness through randomization", ["Rafael Pinot", "Laurent Meunier", "Alexandre Araujo", "Hisashi Kashima", "Florian Yger", "Cedric Gouy-Pailler", "Jamal Atif"], "http://papers.nips.cc/paper/9356-theoretical-evidence-for-adversarial-robustness-through-randomization", 11, "neurips", 2019]], "He Lyu": [0, ["Manifold denoising by Nonlinear Robust Principal Component Analysis", ["He Lyu", "Ningyu Sha", "Shuyang Qin", "Ming Yan", "Yuying Xie", "Rongrong Wang"], "http://papers.nips.cc/paper/9495-manifold-denoising-by-nonlinear-robust-principal-component-analysis", 11, "neurips", 2019]], "Boris Muzellec": [0, ["Subspace Detours: Building Transport Plans that are Optimal on Subspace Projections", ["Boris Muzellec", "Marco Cuturi"], "http://papers.nips.cc/paper/8915-subspace-detours-building-transport-plans-that-are-optimal-on-subspace-projections", 12, "neurips", 2019]], "Akshay Balsubramani": [0, ["An adaptive nearest neighbor rule for classification", ["Akshay Balsubramani", "Sanjoy Dasgupta", "Yoav Freund", "Shay Moran"], "http://papers.nips.cc/paper/8975-an-adaptive-nearest-neighbor-rule-for-classification", 10, "neurips", 2019]], "Sarath Yasodharan": [0, ["Nonzero-sum Adversarial Hypothesis Testing Games", ["Sarath Yasodharan", "Patrick Loiseau"], "http://papers.nips.cc/paper/8951-nonzero-sum-adversarial-hypothesis-testing-games", 11, "neurips", 2019]], "Andrew Ilyas": [0, ["Adversarial Examples Are Not Bugs, They Are Features", ["Andrew Ilyas", "Shibani Santurkar", "Dimitris Tsipras", "Logan Engstrom", "Brandon Tran", "Aleksander Madry"], "http://papers.nips.cc/paper/8307-adversarial-examples-are-not-bugs-they-are-features", 12, "neurips", 2019]], "Kaidi Cao": [0, ["Learning Imbalanced Datasets with Label-Distribution-Aware Margin Loss", ["Kaidi Cao", "Colin Wei", "Adrien Gaidon", "Nikos Arechiga", "Tengyu Ma"], "http://papers.nips.cc/paper/8435-learning-imbalanced-datasets-with-label-distribution-aware-margin-loss", 12, "neurips", 2019]], "Bryan Wilder": [0, ["End to end learning and optimization on graphs", ["Bryan Wilder", "Eric Ewing", "Bistra Dilkina", "Milind Tambe"], "http://papers.nips.cc/paper/8715-end-to-end-learning-and-optimization-on-graphs", 12, "neurips", 2019]], "Niklas W. A. Gebauer": [0, ["Symmetry-adapted generation of 3d point sets for the targeted discovery of molecules", ["Niklas W. A. Gebauer", "Michael Gastegger", "Kristof Schutt"], "http://papers.nips.cc/paper/8974-symmetry-adapted-generation-of-3d-point-sets-for-the-targeted-discovery-of-molecules", 13, "neurips", 2019]], "Boris Hanin": [0, ["Deep ReLU Networks Have Surprisingly Few Activation Patterns", ["Boris Hanin", "David Rolnick"], "http://papers.nips.cc/paper/8328-deep-relu-networks-have-surprisingly-few-activation-patterns", 10, "neurips", 2019]], "Roshan Rao": [0, ["Evaluating Protein Transfer Learning with TAPE", ["Roshan Rao", "Nicholas Bhattacharya", "Neil Thomas", "Yan Duan", "Peter Chen", "John F. Canny", "Pieter Abbeel", "Yun S. Song"], "http://papers.nips.cc/paper/9163-evaluating-protein-transfer-learning-with-tape", 13, "neurips", 2019]], "Charles Corbiere": [0, ["Addressing Failure Prediction by Learning Model Confidence", ["Charles Corbiere", "Nicolas Thome", "Avner Bar-Hen", "Matthieu Cord", "Patrick Perez"], "http://papers.nips.cc/paper/8556-addressing-failure-prediction-by-learning-model-confidence", 12, "neurips", 2019]], "Harsh Gupta": [0, ["Finite-Time Performance Bounds and Adaptive Learning Rate Selection for Two Time-Scale Reinforcement Learning", ["Harsh Gupta", "R. Srikant", "Lei Ying"], "http://papers.nips.cc/paper/8718-finite-time-performance-bounds-and-adaptive-learning-rate-selection-for-two-time-scale-reinforcement-learning", 10, "neurips", 2019]], "Chenyang Tao": [0, ["On Fenchel Mini-Max Learning", ["Chenyang Tao", "Liqun Chen", "Shuyang Dai", "Junya Chen", "Ke Bai", "Dong Wang", "Jianfeng Feng", "Wenlian Lu", "Georgiy V. Bobashev", "Lawrence Carin"], "http://papers.nips.cc/paper/9230-on-fenchel-mini-max-learning", 13, "neurips", 2019]], "Nicolas Keriven": [0, ["Universal Invariant and Equivariant Graph Neural Networks", ["Nicolas Keriven", "Gabriel Peyre"], "http://papers.nips.cc/paper/8931-universal-invariant-and-equivariant-graph-neural-networks", 10, "neurips", 2019]], "Marco Bressan": [0, ["Correlation Clustering with Adaptive Similarity Queries", ["Marco Bressan", "Nicolo Cesa-Bianchi", "Andrea Paudice", "Fabio Vitale"], "http://papers.nips.cc/paper/9417-correlation-clustering-with-adaptive-similarity-queries", 10, "neurips", 2019]], "Nicolo Pagliana": [0, ["Implicit Regularization of Accelerated Methods in Hilbert Spaces", ["Nicolo Pagliana", "Lorenzo Rosasco"], "http://papers.nips.cc/paper/9591-implicit-regularization-of-accelerated-methods-in-hilbert-spaces", 11, "neurips", 2019]], "Kai Zheng": [0, ["Equipping Experts/Bandits with Long-term Memory", ["Kai Zheng", "Haipeng Luo", "Ilias Diakonikolas", "Liwei Wang"], "http://papers.nips.cc/paper/8827-equipping-expertsbandits-with-long-term-memory", 11, "neurips", 2019]], "Nima Dehmamy": [0, ["Understanding the Representation Power of Graph Neural Networks in Learning Graph Topology", ["Nima Dehmamy", "Albert-Laszlo Barabasi", "Rose Yu"], "http://papers.nips.cc/paper/9675-understanding-the-representation-power-of-graph-neural-networks-in-learning-graph-topology", 11, "neurips", 2019]], "Zhuozhuo Tu": [0, ["Theoretical Analysis of Adversarial Learning: A Minimax Approach", ["Zhuozhuo Tu", "Jingwei Zhang", "Dacheng Tao"], "http://papers.nips.cc/paper/9394-theoretical-analysis-of-adversarial-learning-a-minimax-approach", 11, "neurips", 2019]], "Pier Giuseppe Sessa": [0, ["No-Regret Learning in Unknown Games with Correlated Payoffs", ["Pier Giuseppe Sessa", "Ilija Bogunovic", "Maryam Kamgarpour", "Andreas Krause"], "http://papers.nips.cc/paper/9514-no-regret-learning-in-unknown-games-with-correlated-payoffs", 10, "neurips", 2019]], "Emre Yolcu": [0, ["Learning Local Search Heuristics for Boolean Satisfiability", ["Emre Yolcu", "Barnabas Poczos"], "http://papers.nips.cc/paper/9012-learning-local-search-heuristics-for-boolean-satisfiability", 12, "neurips", 2019]], "Wenhao Yang": [1.1607126907620113e-05, ["A Regularized Approach to Sparse Optimal Policy in Reinforcement Learning", ["Wenhao Yang", "Xiang Li", "Zhihua Zhang"], "http://papers.nips.cc/paper/8828-a-regularized-approach-to-sparse-optimal-policy-in-reinforcement-learning", 11, "neurips", 2019]], "Remi Jezequel": [0, ["Efficient online learning with kernels for adversarial large scale problems", ["Remi Jezequel", "Pierre Gaillard", "Alessandro Rudi"], "http://papers.nips.cc/paper/9140-efficient-online-learning-with-kernels-for-adversarial-large-scale-problems", 10, "neurips", 2019]], "Rui Ray Zhang": [0, ["McDiarmid-Type Inequalities for Graph-Dependent Variables and Stability Bounds", ["Rui Ray Zhang", "Xingwu Liu", "Yuyi Wang", "Liwei Wang"], "http://papers.nips.cc/paper/9271-mcdiarmid-type-inequalities-for-graph-dependent-variables-and-stability-bounds", 11, "neurips", 2019]], "Dustin Tran": [0, ["Bayesian Layers: A Module for Neural Network Uncertainty", ["Dustin Tran", "Mike Dusenberry", "Mark van der Wilk", "Danijar Hafner"], "http://papers.nips.cc/paper/9607-bayesian-layers-a-module-for-neural-network-uncertainty", 13, "neurips", 2019], ["Discrete Flows: Invertible Generative Models of Discrete Data", ["Dustin Tran", "Keyon Vafa", "Kumar Krishna Agrawal", "Laurent Dinh", "Ben Poole"], "http://papers.nips.cc/paper/9612-discrete-flows-invertible-generative-models-of-discrete-data", 10, "neurips", 2019]], "Yulin Wang": [0.3718322888016701, ["Implicit Semantic Data Augmentation for Deep Networks", ["Yulin Wang", "Xuran Pan", "Shiji Song", "Hong Zhang", "Gao Huang", "Cheng Wu"], "http://papers.nips.cc/paper/9426-implicit-semantic-data-augmentation-for-deep-networks", 10, "neurips", 2019]], "Xingye Qiao": [0, ["Rates of Convergence for Large-scale Nearest Neighbor Classification", ["Xingye Qiao", "Jiexin Duan", "Guang Cheng"], "http://papers.nips.cc/paper/9260-rates-of-convergence-for-large-scale-nearest-neighbor-classification", 12, "neurips", 2019]], "Guanghui Lan": [0, ["A unified variance-reduced accelerated gradient method for convex optimization", ["Guanghui Lan", "Zhize Li", "Yi Zhou"], "http://papers.nips.cc/paper/9233-a-unified-variance-reduced-accelerated-gradient-method-for-convex-optimization", 11, "neurips", 2019]], "Steve Hanneke": [0, ["On the Value of Target Data in Transfer Learning", ["Steve Hanneke", "Samory Kpotufe"], "http://papers.nips.cc/paper/9179-on-the-value-of-target-data-in-transfer-learning", 11, "neurips", 2019]], "Sandeep Kumar": [0, ["Structured Graph Learning Via Laplacian Spectral Constraints", ["Sandeep Kumar", "Jiaxi Ying", "Jose Vinicius de Miranda Cardoso", "Daniel P. Palomar"], "http://papers.nips.cc/paper/9339-structured-graph-learning-via-laplacian-spectral-constraints", 12, "neurips", 2019]], "Ofir Nachum": [0, ["DualDICE: Behavior-Agnostic Estimation of Discounted Stationary Distribution Corrections", ["Ofir Nachum", "Yinlam Chow", "Bo Dai", "Lihong Li"], "http://papers.nips.cc/paper/8503-dualdice-behavior-agnostic-estimation-of-discounted-stationary-distribution-corrections", 11, "neurips", 2019]], "Simon Ramstedt": [0, ["Real-Time Reinforcement Learning", ["Simon Ramstedt", "Chris Pal"], "http://papers.nips.cc/paper/8571-real-time-reinforcement-learning", 10, "neurips", 2019]], "Arsalan Sharif-Nassab": [0, ["Order Optimal One-Shot Distributed Learning", ["Arsalan Sharif-Nassab", "Saber Salehkaleybar", "S. Jamaloddin Golestani"], "http://papers.nips.cc/paper/8489-order-optimal-one-shot-distributed-learning", 10, "neurips", 2019]], "Aleksandar Bojchevski": [0, ["Certifiable Robustness to Graph Perturbations", ["Aleksandar Bojchevski", "Stephan Gunnemann"], "http://papers.nips.cc/paper/9041-certifiable-robustness-to-graph-perturbations", 12, "neurips", 2019]], "Laurence Aitchison": [0, ["Tensor Monte Carlo: Particle Methods for the GPU era", ["Laurence Aitchison"], "http://papers.nips.cc/paper/8936-tensor-monte-carlo-particle-methods-for-the-gpu-era", 10, "neurips", 2019]], "Matteo Turchetta": [0, ["Safe Exploration for Interactive Machine Learning", ["Matteo Turchetta", "Felix Berkenkamp", "Andreas Krause"], "http://papers.nips.cc/paper/8555-safe-exploration-for-interactive-machine-learning", 11, "neurips", 2019]], "Can Qin": [0, ["PointDAN: A Multi-Scale 3D Domain Adaption Network for Point Cloud Representation", ["Can Qin", "Haoxuan You", "Lichen Wang", "C.-C. Jay Kuo", "Yun Fu"], "http://papers.nips.cc/paper/8940-pointdan-a-multi-scale-3d-domain-adaption-network-for-point-cloud-representation", 12, "neurips", 2019]], "Vitaliy Chiley": [0, ["Online Normalization for Training Neural Networks", ["Vitaliy Chiley", "Ilya Sharapov", "Atli Kosson", "Urs Koster", "Ryan Reece", "Sofia Samaniego de la Fuente", "Vishal Subbiah", "Michael James"], "http://papers.nips.cc/paper/9051-online-normalization-for-training-neural-networks", 11, "neurips", 2019]], "Ashok Cutkosky": [0, ["Momentum-Based Variance Reduction in Non-Convex SGD", ["Ashok Cutkosky", "Francesco Orabona"], "http://papers.nips.cc/paper/9659-momentum-based-variance-reduction-in-non-convex-sgd", 10, "neurips", 2019]], "Ravichandra Addanki": [0, ["Learning Generalizable Device Placement Algorithms for Distributed Machine Learning", ["Ravichandra Addanki", "Shaileshh Bojja Venkatakrishnan", "Shreyan Gupta", "Hongzi Mao", "Mohammad Alizadeh"], "http://papers.nips.cc/paper/8653-learning-generalizable-device-placement-algorithms-for-distributed-machine-learning", 11, "neurips", 2019]], "Simao Herdade": [0, ["Image Captioning: Transforming Objects into Words", ["Simao Herdade", "Armin Kappeler", "Kofi Boakye", "Joao Soares"], "http://papers.nips.cc/paper/9293-image-captioning-transforming-objects-into-words", 11, "neurips", 2019]], "Emiel Hoogeboom": [0, ["Integer Discrete Flows and Lossless Compression", ["Emiel Hoogeboom", "Jorn W. T. Peters", "Rianne van den Berg", "Max Welling"], "http://papers.nips.cc/paper/9383-integer-discrete-flows-and-lossless-compression", 11, "neurips", 2019]], "Justin Domke": [0, ["Provable Gradient Variance Guarantees for Black-Box Variational Inference", ["Justin Domke"], "http://papers.nips.cc/paper/8325-provable-gradient-variance-guarantees-for-black-box-variational-inference", 10, "neurips", 2019], ["Divide and Couple: Using Monte Carlo Variational Objectives for Posterior Approximation", ["Justin Domke", "Daniel R. Sheldon"], "http://papers.nips.cc/paper/8326-divide-and-couple-using-monte-carlo-variational-objectives-for-posterior-approximation", 10, "neurips", 2019]], "Holden Lee": [2.174307134339415e-08, ["Online sampling from log-concave distributions", ["Holden Lee", "Oren Mangoubi", "Nisheeth K. Vishnoi"], "http://papers.nips.cc/paper/8406-online-sampling-from-log-concave-distributions", 12, "neurips", 2019]], "Jeffrey Negrea": [0, ["Information-Theoretic Generalization Bounds for SGLD via Data-Dependent Estimates", ["Jeffrey Negrea", "Mahdi Haghifam", "Gintare Karolina Dziugaite", "Ashish Khisti", "Daniel M. Roy"], "http://papers.nips.cc/paper/9282-information-theoretic-generalization-bounds-for-sgld-via-data-dependent-estimates", 11, "neurips", 2019]], "Dong Liu": [0, ["On The Classification-Distortion-Perception Tradeoff", ["Dong Liu", "Haochen Zhang", "Zhiwei Xiong"], "http://papers.nips.cc/paper/8404-on-the-classification-distortion-perception-tradeoff", 10, "neurips", 2019]], "Weijiang Yu": [1.3290743505756097e-09, ["Heterogeneous Graph Learning for Visual Commonsense Reasoning", ["Weijiang Yu", "Jingwen Zhou", "Weihao Yu", "Xiaodan Liang", "Nong Xiao"], "http://papers.nips.cc/paper/8544-heterogeneous-graph-learning-for-visual-commonsense-reasoning", 11, "neurips", 2019]], "Tobias Sommer Thune": [0, ["Nonstochastic Multiarmed Bandits with Unrestricted Delays", ["Tobias Sommer Thune", "Nicolo Cesa-Bianchi", "Yevgeny Seldin"], "http://papers.nips.cc/paper/8881-nonstochastic-multiarmed-bandits-with-unrestricted-delays", 10, "neurips", 2019]], "Yiwen Guo": [0, ["Subspace Attack: Exploiting Promising Subspaces for Query-Efficient Black-box Attacks", ["Yiwen Guo", "Ziang Yan", "Changshui Zhang"], "http://papers.nips.cc/paper/8638-subspace-attack-exploiting-promising-subspaces-for-query-efficient-black-box-attacks", 10, "neurips", 2019]], "Xuesong Niu": [0, ["Multi-label Co-regularization for Semi-supervised Facial Action Unit Recognition", ["Xuesong Niu", "Hu Han", "Shiguang Shan", "Xilin Chen"], "http://papers.nips.cc/paper/8377-multi-label-co-regularization-for-semi-supervised-facial-action-unit-recognition", 11, "neurips", 2019]], "Maryam Aliakbarpour": [0, ["Private Testing of Distributions via Sample Permutations", ["Maryam Aliakbarpour", "Ilias Diakonikolas", "Daniel Kane", "Ronitt Rubinfeld"], "http://papers.nips.cc/paper/9270-private-testing-of-distributions-via-sample-permutations", 12, "neurips", 2019]], "Boyu Wang": [0.08494379371404648, ["Transfer Learning via Minimizing the Performance Gap Between Domains", ["Boyu Wang", "Jorge A. Mendez", "Mingbo Cai", "Eric Eaton"], "http://papers.nips.cc/paper/9249-transfer-learning-via-minimizing-the-performance-gap-between-domains", 11, "neurips", 2019]], "Saurabh Sihag": [0, ["Structure Learning with Side Information: Sample Complexity", ["Saurabh Sihag", "Ali Tajer"], "http://papers.nips.cc/paper/9582-structure-learning-with-side-information-sample-complexity", 11, "neurips", 2019]], "Suman Kalyan Bera": [0, ["Fair Algorithms for Clustering", ["Suman Kalyan Bera", "Deeparnab Chakrabarty", "Nicolas Flores", "Maryam Negahbani"], "http://papers.nips.cc/paper/8741-fair-algorithms-for-clustering", 12, "neurips", 2019]], "Aming Wu": [0.029773710295557976, ["Connective Cognition Network for Directional Visual Commonsense Reasoning", ["Aming Wu", "Linchao Zhu", "Yahong Han", "Yi Yang"], "http://papers.nips.cc/paper/8804-connective-cognition-network-for-directional-visual-commonsense-reasoning", 11, "neurips", 2019]], "Zhize Li": [0, ["SSRGD: Simple Stochastic Recursive Gradient Descent for Escaping Saddle Points", ["Zhize Li"], "http://papers.nips.cc/paper/8431-ssrgd-simple-stochastic-recursive-gradient-descent-for-escaping-saddle-points", 11, "neurips", 2019]], "Cornelius Schroder": [0, ["Approximate Bayesian Inference for a Mechanistic Model of Vesicle Release at a Ribbon Synapse", ["Cornelius Schroder", "Ben James", "Leon Lagnado", "Philipp Berens"], "http://papers.nips.cc/paper/8929-approximate-bayesian-inference-for-a-mechanistic-model-of-vesicle-release-at-a-ribbon-synapse", 11, "neurips", 2019]], "Qiming Zhang": [0, ["Category Anchor-Guided Unsupervised Domain Adaptation for Semantic Segmentation", ["Qiming Zhang", "Jing Zhang", "Wei Liu", "Dacheng Tao"], "http://papers.nips.cc/paper/8335-category-anchor-guided-unsupervised-domain-adaptation-for-semantic-segmentation", 11, "neurips", 2019]], "Karim Ahmed": [0, ["STAR-Caps: Capsule Networks with Straight-Through Attentive Routing", ["Karim Ahmed", "Lorenzo Torresani"], "http://papers.nips.cc/paper/9110-star-caps-capsule-networks-with-straight-through-attentive-routing", 10, "neurips", 2019]], "Qi Dou": [0, ["Domain Generalization via Model-Agnostic Learning of Semantic Features", ["Qi Dou", "Daniel Coelho de Castro", "Konstantinos Kamnitsas", "Ben Glocker"], "http://papers.nips.cc/paper/8873-domain-generalization-via-model-agnostic-learning-of-semantic-features", 12, "neurips", 2019]], "Mikael Henaff": [0, ["Explicit Explore-Exploit Algorithms in Continuous State Spaces", ["Mikael Henaff"], "http://papers.nips.cc/paper/9135-explicit-explore-exploit-algorithms-in-continuous-state-spaces", 11, "neurips", 2019]], "Xingyu Cai": [0, ["DTWNet: a Dynamic Time Warping Network", ["Xingyu Cai", "Tingyang Xu", "Jinfeng Yi", "Junzhou Huang", "Sanguthevar Rajasekaran"], "http://papers.nips.cc/paper/9338-dtwnet-a-dynamic-time-warping-network", 11, "neurips", 2019]], "Shuo Yang": [0.00021898005797993392, ["Interaction Hard Thresholding: Consistent Sparse Quadratic Regression in Sub-quadratic Time and Space", ["Shuo Yang", "Yanyao Shen", "Sujay Sanghavi"], "http://papers.nips.cc/paper/9006-interaction-hard-thresholding-consistent-sparse-quadratic-regression-in-sub-quadratic-time-and-space", 11, "neurips", 2019]], "Lemeng Wu": [3.889738536599907e-06, ["Splitting Steepest Descent for Growing Neural Architectures", ["Lemeng Wu", "Dilin Wang", "Qiang Liu"], "http://papers.nips.cc/paper/9250-splitting-steepest-descent-for-growing-neural-architectures", 11, "neurips", 2019]], "Dina Bashkirova": [0, ["Adversarial Self-Defense for Cycle-Consistent GANs", ["Dina Bashkirova", "Ben Usman", "Kate Saenko"], "http://papers.nips.cc/paper/8353-adversarial-self-defense-for-cycle-consistent-gans", 11, "neurips", 2019]], "Valerio Perrone": [0, ["Learning search spaces for Bayesian optimization: Another view of hyperparameter transfer learning", ["Valerio Perrone", "Huibin Shen"], "http://papers.nips.cc/paper/9438-learning-search-spaces-for-bayesian-optimization-another-view-of-hyperparameter-transfer-learning", 11, "neurips", 2019]], "Yi Hao": [0, ["The Broad Optimality of Profile Maximum Likelihood", ["Yi Hao", "Alon Orlitsky"], "http://papers.nips.cc/paper/9280-the-broad-optimality-of-profile-maximum-likelihood", 13, "neurips", 2019], ["Unified Sample-Optimal Property Estimation in Near-Linear Time", ["Yi Hao", "Alon Orlitsky"], "http://papers.nips.cc/paper/9290-unified-sample-optimal-property-estimation-in-near-linear-time", 11, "neurips", 2019]], "Chulhee Yun": [0.9811542630195618, ["Small ReLU networks are powerful memorizers: a tight analysis of memorization capacity", ["Chulhee Yun", "Suvrit Sra", "Ali Jadbabaie"], "http://papers.nips.cc/paper/9688-small-relu-networks-are-powerful-memorizers-a-tight-analysis-of-memorization-capacity", 12, "neurips", 2019], ["Are deep ResNets provably better than linear predictors?", ["Chulhee Yun", "Suvrit Sra", "Ali Jadbabaie"], "http://papers.nips.cc/paper/9699-are-deep-resnets-provably-better-than-linear-predictors", 10, "neurips", 2019]], "Yulia Rubanova": [0, ["Latent Ordinary Differential Equations for Irregularly-Sampled Time Series", ["Yulia Rubanova", "Tian Qi Chen", "David Duvenaud"], "http://papers.nips.cc/paper/8773-latent-ordinary-differential-equations-for-irregularly-sampled-time-series", 11, "neurips", 2019]], "Rakshith Sharma Srinivasa": [0, ["Decentralized sketching of low rank matrices", ["Rakshith Sharma Srinivasa", "Kiryung Lee", "Marius Junge", "Justin Romberg"], "http://papers.nips.cc/paper/9200-decentralized-sketching-of-low-rank-matrices", 10, "neurips", 2019]], "Zhixin Zhou": [0, ["M\u00f6bius Transformation for Fast Inner Product Search on Graph", ["Zhixin Zhou", "Shulong Tan", "Zhaozhuo Xu", "Ping Li"], "http://papers.nips.cc/paper/9032-mobius-transformation-for-fast-inner-product-search-on-graph", 12, "neurips", 2019]], "Anthony Ndirango": [0, ["Generalization in multitask deep neural classifiers: a statistical physics approach", ["Anthony Ndirango", "Tyler Lee"], "http://papers.nips.cc/paper/9715-generalization-in-multitask-deep-neural-classifiers-a-statistical-physics-approach", 10, "neurips", 2019]], "Etienne Boursier": [0, ["SIC-MMAB: Synchronisation Involves Communication in Multiplayer Multi-Armed Bandits", ["Etienne Boursier", "Vianney Perchet"], "http://papers.nips.cc/paper/9375-sic-mmab-synchronisation-involves-communication-in-multiplayer-multi-armed-bandits", 10, "neurips", 2019]], "Ziyin Liu": [0, ["Deep Gamblers: Learning to Abstain with Portfolio Theory", ["Ziyin Liu", "Zhikang Wang", "Paul Pu Liang", "Ruslan Salakhutdinov", "Louis-Philippe Morency", "Masahito Ueda"], "http://papers.nips.cc/paper/9247-deep-gamblers-learning-to-abstain-with-portfolio-theory", 11, "neurips", 2019]], "Nikolaos Tziavelis": [0, ["Equitable Stable Matchings in Quadratic Time", ["Nikolaos Tziavelis", "Ioannis Giannakopoulos", "Katerina Doka", "Nectarios Koziris", "Panagiotis Karras"], "http://papers.nips.cc/paper/8337-equitable-stable-matchings-in-quadratic-time", 11, "neurips", 2019]], "Alessandro Barp": [0, ["Minimum Stein Discrepancy Estimators", ["Alessandro Barp", "Francois-Xavier Briol", "Andrew B. Duncan", "Mark A. Girolami", "Lester W. Mackey"], "http://papers.nips.cc/paper/9457-minimum-stein-discrepancy-estimators", 13, "neurips", 2019]], "Ahmed M. Alaa": [0, ["Demystifying Black-box Models with Symbolic Metamodels", ["Ahmed M. Alaa", "Mihaela van der Schaar"], "http://papers.nips.cc/paper/9308-demystifying-black-box-models-with-symbolic-metamodels", 11, "neurips", 2019], ["Attentive State-Space Modeling of Disease Progression", ["Ahmed M. Alaa", "Mihaela van der Schaar"], "http://papers.nips.cc/paper/9311-attentive-state-space-modeling-of-disease-progression", 11, "neurips", 2019]], "My Phan": [0, ["Thompson Sampling and Approximate Inference", ["My Phan", "Yasin Abbasi-Yadkori", "Justin Domke"], "http://papers.nips.cc/paper/9084-thompson-sampling-and-approximate-inference", 11, "neurips", 2019]], "Xiyang Hu": [0, ["Optimal Sparse Decision Trees", ["Xiyang Hu", "Cynthia Rudin", "Margo Seltzer"], "http://papers.nips.cc/paper/8947-optimal-sparse-decision-trees", 9, "neurips", 2019]], "Eric Jonas": [0, ["Deep imitation learning for molecular inverse problems", ["Eric Jonas"], "http://papers.nips.cc/paper/8744-deep-imitation-learning-for-molecular-inverse-problems", 11, "neurips", 2019]], "Tatjana Chavdarova": [0, ["Reducing Noise in GAN Training with Variance Reduced Extragradient", ["Tatjana Chavdarova", "Gauthier Gidel", "Francois Fleuret", "Simon Lacoste-Julien"], "http://papers.nips.cc/paper/8331-reducing-noise-in-gan-training-with-variance-reduced-extragradient", 11, "neurips", 2019]], "Guokun Lai": [0, ["Re-examination of the Role of Latent Variables in Sequence Modeling", ["Guokun Lai", "Zihang Dai", "Yiming Yang", "Shinjae Yoo"], "http://papers.nips.cc/paper/8996-re-examination-of-the-role-of-latent-variables-in-sequence-modeling", 11, "neurips", 2019]], "Tao Sun": [0.0013258812250569463, ["General Proximal Incremental Aggregated Gradient Algorithms: Better and Novel Results under General Scheme", ["Tao Sun", "Yuejiao Sun", "Dongsheng Li", "Qing Liao"], "http://papers.nips.cc/paper/8385-general-proximal-incremental-aggregated-gradient-algorithms-better-and-novel-results-under-general-scheme", 11, "neurips", 2019]], "Junran Peng": [0, ["Efficient Neural Architecture Transformation Search in Channel-Level for Object Detection", ["Junran Peng", "Ming Sun", "Zhaoxiang Zhang", "Tieniu Tan", "Junjie Yan"], "http://papers.nips.cc/paper/9576-efficient-neural-architecture-transformation-search-in-channel-level-for-object-detection", 10, "neurips", 2019]], "Haowei He": [0, ["Asymmetric Valleys: Beyond Sharp and Flat Local Minima", ["Haowei He", "Gao Huang", "Yang Yuan"], "http://papers.nips.cc/paper/8524-asymmetric-valleys-beyond-sharp-and-flat-local-minima", 12, "neurips", 2019]], "Guang-He Lee": [0.000704682053765282, ["Tight Certificates of Adversarial Robustness for Randomly Smoothed Classifiers", ["Guang-He Lee", "Yang Yuan", "Shiyu Chang", "Tommi S. Jaakkola"], "http://papers.nips.cc/paper/8737-tight-certificates-of-adversarial-robustness-for-randomly-smoothed-classifiers", 12, "neurips", 2019]], "Hui Guan": [0, ["In-Place Zero-Space Memory Protection for CNN", ["Hui Guan", "Lin Ning", "Zhen Lin", "Xipeng Shen", "Huiyang Zhou", "Seung-Hwan Lim"], "http://papers.nips.cc/paper/8810-in-place-zero-space-memory-protection-for-cnn", 10, "neurips", 2019]], "Hanjun Dai": [0, ["Learning Transferable Graph Exploration", ["Hanjun Dai", "Yujia Li", "Chenglong Wang", "Rishabh Singh", "Po-Sen Huang", "Pushmeet Kohli"], "http://papers.nips.cc/paper/8521-learning-transferable-graph-exploration", 12, "neurips", 2019], ["Retrosynthesis Prediction with Conditional Graph Logic Network", ["Hanjun Dai", "Chengtao Li", "Connor W. Coley", "Bo Dai", "Le Song"], "http://papers.nips.cc/paper/9090-retrosynthesis-prediction-with-conditional-graph-logic-network", 11, "neurips", 2019]], "Chao Li": [0, ["Cross-Modal Learning with Adversarial Samples", ["Chao Li", "Shangqian Gao", "Cheng Deng", "De Xie", "Wei Liu"], "http://papers.nips.cc/paper/9262-cross-modal-learning-with-adversarial-samples", 11, "neurips", 2019]], "Chi Zhang": [0, ["Learning Perceptual Inference by Contrasting", ["Chi Zhang", "Baoxiong Jia", "Feng Gao", "Yixin Zhu", "Hongjing Lu", "Song-Chun Zhu"], "http://papers.nips.cc/paper/8392-learning-perceptual-inference-by-contrasting", 13, "neurips", 2019]], "Yu Bai": [0.002284156798850745, ["Provably Efficient Q-Learning with Low Switching Cost", ["Yu Bai", "Tengyang Xie", "Nan Jiang", "Yu-Xiang Wang"], "http://papers.nips.cc/paper/9013-provably-efficient-q-learning-with-low-switching-cost", 10, "neurips", 2019]], "Yanis Bahroun": [0, ["A Similarity-preserving Network Trained on Transformed Images Recapitulates Salient Features of the Fly Motion Detection Circuit", ["Yanis Bahroun", "Dmitri B. Chklovskii", "Anirvan M. Sengupta"], "http://papers.nips.cc/paper/9566-a-similarity-preserving-network-trained-on-transformed-images-recapitulates-salient-features-of-the-fly-motion-detection-circuit", 12, "neurips", 2019]], "Deeksha Adil": [0, ["Fast, Provably convergent IRLS Algorithm for p-norm Linear Regression", ["Deeksha Adil", "Richard Peng", "Sushant Sachdeva"], "http://papers.nips.cc/paper/9565-fast-provably-convergent-irls-algorithm-for-p-norm-linear-regression", 12, "neurips", 2019]], "Lei Wu": [0.001596404705196619, ["Global Convergence of Gradient Descent for Deep Linear Residual Networks", ["Lei Wu", "Qingcan Wang", "Chao Ma"], "http://papers.nips.cc/paper/9493-global-convergence-of-gradient-descent-for-deep-linear-residual-networks", 10, "neurips", 2019]], "Wenbo Gong": [0.0007794685370754451, ["Icebreaker: Element-wise Efficient Information Acquisition with a Bayesian Deep Latent Gaussian Model", ["Wenbo Gong", "Sebastian Tschiatschek", "Sebastian Nowozin", "Richard E. Turner", "Jose Miguel Hernandez-Lobato", "Cheng Zhang"], "http://papers.nips.cc/paper/9621-icebreaker-element-wise-efficient-information-acquisition-with-a-bayesian-deep-latent-gaussian-model", 12, "neurips", 2019]], "Thomas Pierrot": [0, ["Learning Compositional Neural Programs with Recursive Tree Search and Planning", ["Thomas Pierrot", "Guillaume Ligner", "Scott E. Reed", "Olivier Sigaud", "Nicolas Perrin", "Alexandre Laterre", "David Kas", "Karim Beguir", "Nando de Freitas"], "http://papers.nips.cc/paper/9608-learning-compositional-neural-programs-with-recursive-tree-search-and-planning", 11, "neurips", 2019]], "Wang Chi Cheung": [0, ["Regret Minimization for Reinforcement Learning with Vectorial Feedback and Complex Objectives", ["Wang Chi Cheung"], "http://papers.nips.cc/paper/8361-regret-minimization-for-reinforcement-learning-with-vectorial-feedback-and-complex-objectives", 11, "neurips", 2019]], "Chuang Wang": [0.10879793018102646, ["A Solvable High-Dimensional Model of GAN", ["Chuang Wang", "Hong Hu", "Yue Lu"], "http://papers.nips.cc/paper/9528-a-solvable-high-dimensional-model-of-gan", 10, "neurips", 2019]], "Xiaosong Zhang": [0, ["FreeAnchor: Learning to Match Anchors for Visual Object Detection", ["Xiaosong Zhang", "Fang Wan", "Chang Liu", "Rongrong Ji", "Qixiang Ye"], "http://papers.nips.cc/paper/8309-freeanchor-learning-to-match-anchors-for-visual-object-detection", 9, "neurips", 2019]], "Talfan Evans": [0, ["Coordinated hippocampal-entorhinal replay as structural inference", ["Talfan Evans", "Neil Burgess"], "http://papers.nips.cc/paper/8450-coordinated-hippocampal-entorhinal-replay-as-structural-inference", 13, "neurips", 2019]], "Anna Harutyunyan": [0, ["Hindsight Credit Assignment", ["Anna Harutyunyan", "Will Dabney", "Thomas Mesnard", "Mohammad Gheshlaghi Azar", "Bilal Piot", "Nicolas Heess", "Hado van Hasselt", "Gregory Wayne", "Satinder Singh", "Doina Precup", "Remi Munos"], "http://papers.nips.cc/paper/9413-hindsight-credit-assignment", 10, "neurips", 2019]], "Andrew Bennett": [0, ["Deep Generalized Method of Moments for Instrumental Variable Analysis", ["Andrew Bennett", "Nathan Kallus", "Tobias Schnabel"], "http://papers.nips.cc/paper/8615-deep-generalized-method-of-moments-for-instrumental-variable-analysis", 11, "neurips", 2019], ["Policy Evaluation with Latent Confounders via Optimal Balance", ["Andrew Bennett", "Nathan Kallus"], "http://papers.nips.cc/paper/8729-policy-evaluation-with-latent-confounders-via-optimal-balance", 11, "neurips", 2019]], "Armin Lederer": [0, ["Uniform Error Bounds for Gaussian Process Regression with Application to Safe Control", ["Armin Lederer", "Jonas Umlauft", "Sandra Hirche"], "http://papers.nips.cc/paper/8355-uniform-error-bounds-for-gaussian-process-regression-with-application-to-safe-control", 11, "neurips", 2019]], "Zhihao Xia": [0, ["Training Image Estimators without Image Ground Truth", ["Zhihao Xia", "Ayan Chakrabarti"], "http://papers.nips.cc/paper/8514-training-image-estimators-without-image-ground-truth", 11, "neurips", 2019]], "Matthieu Jedor": [0, ["Categorized Bandits", ["Matthieu Jedor", "Vianney Perchet", "Jonathan Louedec"], "http://papers.nips.cc/paper/9586-categorized-bandits", 11, "neurips", 2019]], "Mahyar Fazlyab": [0, ["Efficient and Accurate Estimation of Lipschitz Constants for Deep Neural Networks", ["Mahyar Fazlyab", "Alexander Robey", "Hamed Hassani", "Manfred Morari", "George J. Pappas"], "http://papers.nips.cc/paper/9319-efficient-and-accurate-estimation-of-lipschitz-constants-for-deep-neural-networks", 12, "neurips", 2019]], "Sunil Thulasidasan": [0, ["On Mixup Training: Improved Calibration and Predictive Uncertainty for Deep Neural Networks", ["Sunil Thulasidasan", "Gopinath Chennupati", "Jeff A. Bilmes", "Tanmoy Bhattacharya", "Sarah Michalak"], "http://papers.nips.cc/paper/9540-on-mixup-training-improved-calibration-and-predictive-uncertainty-for-deep-neural-networks", 12, "neurips", 2019]], "Shen-Huan Lyu": [0, ["A Refined Margin Distribution Analysis for Forest Representation Learning", ["Shen-Huan Lyu", "Liang Yang", "Zhi-Hua Zhou"], "http://papers.nips.cc/paper/8791-a-refined-margin-distribution-analysis-for-forest-representation-learning", 11, "neurips", 2019]], "Ting-Chun Wang": [1.9114424048893852e-05, ["Few-shot Video-to-Video Synthesis", ["Ting-Chun Wang", "Ming-Yu Liu", "Andrew Tao", "Guilin Liu", "Bryan Catanzaro", "Jan Kautz"], "http://papers.nips.cc/paper/8746-few-shot-video-to-video-synthesis", 12, "neurips", 2019]], "Jenelle Feather": [0, ["Metamers of neural networks reveal divergence from human perceptual systems", ["Jenelle Feather", "Alex Durango", "Ray Gonzalez", "Josh McDermott"], "http://papers.nips.cc/paper/9198-metamers-of-neural-networks-reveal-divergence-from-human-perceptual-systems", 12, "neurips", 2019]], "Xing Yan": [0, ["Cross-sectional Learning of Extremal Dependence among Financial Assets", ["Xing Yan", "Qi Wu", "Wen Zhang"], "http://papers.nips.cc/paper/8641-cross-sectional-learning-of-extremal-dependence-among-financial-assets", 11, "neurips", 2019]], "Peng Chen": [0, ["Projected Stein Variational Newton: A Fast and Scalable Bayesian Inference Method in High Dimensions", ["Peng Chen", "Keyi Wu", "Joshua Chen", "Tom OLeary-Roseberry", "Omar Ghattas"], "http://papers.nips.cc/paper/9649-projected-stein-variational-newton-a-fast-and-scalable-bayesian-inference-method-in-high-dimensions", 10, "neurips", 2019]], "Joshua Hanson": [0, ["Universal Approximation of Input-Output Maps by Temporal Convolutional Nets", ["Joshua Hanson", "Maxim Raginsky"], "http://papers.nips.cc/paper/9554-universal-approximation-of-input-output-maps-by-temporal-convolutional-nets", 11, "neurips", 2019]], "Zhiting Hu": [0, ["Learning Data Manipulation for Augmentation and Weighting", ["Zhiting Hu", "Bowen Tan", "Ruslan Salakhutdinov", "Tom M. Mitchell", "Eric P. Xing"], "http://papers.nips.cc/paper/9706-learning-data-manipulation-for-augmentation-and-weighting", 12, "neurips", 2019]], "Liwei Wu": [7.176967287136904e-08, ["Stochastic Shared Embeddings: Data-driven Regularization of Embedding Layers", ["Liwei Wu", "Shuqing Li", "Cho-Jui Hsieh", "James L. Sharpnack"], "http://papers.nips.cc/paper/8298-stochastic-shared-embeddings-data-driven-regularization-of-embedding-layers", 11, "neurips", 2019]], "Chen Dan": [0, ["Optimal Analysis of Subset-Selection Based L_p Low-Rank Approximation", ["Chen Dan", "Hong Wang", "Hongyang Zhang", "Yuchen Zhou", "Pradeep Ravikumar"], "http://papers.nips.cc/paper/8523-optimal-analysis-of-subset-selection-based-l_p-low-rank-approximation", 12, "neurips", 2019]], "Xuanyi Dong": [1.681751580443619e-12, ["Network Pruning via Transformable Architecture Search", ["Xuanyi Dong", "Yi Yang"], "http://papers.nips.cc/paper/8364-network-pruning-via-transformable-architecture-search", 12, "neurips", 2019]], "Asma Ghandeharioun": [0, ["Approximating Interactive Human Evaluation with Self-Play for Open-Domain Dialog Systems", ["Asma Ghandeharioun", "Judy Hanwen Shen", "Natasha Jaques", "Craig Ferguson", "Noah Jones", "Agata Lapedriza", "Rosalind W. Picard"], "http://papers.nips.cc/paper/9519-approximating-interactive-human-evaluation-with-self-play-for-open-domain-dialog-systems", 12, "neurips", 2019]], "Gonzalo Mena": [0, ["Statistical bounds for entropic optimal transport: sample complexity and the central limit theorem", ["Gonzalo Mena", "Jonathan Niles-Weed"], "http://papers.nips.cc/paper/8703-statistical-bounds-for-entropic-optimal-transport-sample-complexity-and-the-central-limit-theorem", 11, "neurips", 2019]], "Dominik Janzing": [0, ["Causal Regularization", ["Dominik Janzing"], "http://papers.nips.cc/paper/9432-causal-regularization", 11, "neurips", 2019]], "Fanny Yang": [5.593090257605127e-08, ["Invariance-inducing regularization using worst-case transformations suffices to boost accuracy and spatial robustness", ["Fanny Yang", "Zuowen Wang", "Christina Heinze-Deml"], "http://papers.nips.cc/paper/9618-invariance-inducing-regularization-using-worst-case-transformations-suffices-to-boost-accuracy-and-spatial-robustness", 12, "neurips", 2019]], "Erik Nijkamp": [0, ["Learning Non-Convergent Non-Persistent Short-Run MCMC Toward Energy-Based Model", ["Erik Nijkamp", "Mitch Hill", "Song-Chun Zhu", "Ying Nian Wu"], "http://papers.nips.cc/paper/8765-learning-non-convergent-non-persistent-short-run-mcmc-toward-energy-based-model", 11, "neurips", 2019]], "Yuhui Wang": [0.07404914684593678, ["Trust Region-Guided Proximal Policy Optimization", ["Yuhui Wang", "Hao He", "Xiaoyang Tan", "Yaozhong Gan"], "http://papers.nips.cc/paper/8352-trust-region-guided-proximal-policy-optimization", 11, "neurips", 2019]], "Cassidy Laidlaw": [0, ["Functional Adversarial Attacks", ["Cassidy Laidlaw", "Soheil Feizi"], "http://papers.nips.cc/paper/9228-functional-adversarial-attacks", 11, "neurips", 2019]], "Harald Steck": [0, ["Markov Random Fields for Collaborative Filtering", ["Harald Steck"], "http://papers.nips.cc/paper/8786-markov-random-fields-for-collaborative-filtering", 12, "neurips", 2019]], "Hongge Chen": [0, ["Robustness Verification of Tree-based Models", ["Hongge Chen", "Huan Zhang", "Si Si", "Yang Li", "Duane S. Boning", "Cho-Jui Hsieh"], "http://papers.nips.cc/paper/9399-robustness-verification-of-tree-based-models", 12, "neurips", 2019]], "Felix Leibfried": [0, ["A Unified Bellman Optimality Principle Combining Reward Maximization and Empowerment", ["Felix Leibfried", "Sergio Pascual-Diaz", "Jordi Grau-Moya"], "http://papers.nips.cc/paper/9001-a-unified-bellman-optimality-principle-combining-reward-maximization-and-empowerment", 12, "neurips", 2019]], "Kolyan Ray": [0, ["Debiased Bayesian inference for average treatment effects", ["Kolyan Ray", "Botond Szabo"], "http://papers.nips.cc/paper/9364-debiased-bayesian-inference-for-average-treatment-effects", 11, "neurips", 2019]], "Zhengyang Shen": [0, ["Region-specific Diffeomorphic Metric Mapping", ["Zhengyang Shen", "Francois-Xavier Vialard", "Marc Niethammer"], "http://papers.nips.cc/paper/8394-region-specific-diffeomorphic-metric-mapping", 11, "neurips", 2019]], "Ioannis Koutis": [0, ["Spectral Modification of Graphs for Improved Spectral Clustering", ["Ioannis Koutis", "Huong Le"], "http://papers.nips.cc/paper/8732-spectral-modification-of-graphs-for-improved-spectral-clustering", 10, "neurips", 2019]], "Vincent Sitzmann": [0, ["Scene Representation Networks: Continuous 3D-Structure-Aware Neural Scene Representations", ["Vincent Sitzmann", "Michael Zollhofer", "Gordon Wetzstein"], "http://papers.nips.cc/paper/8396-scene-representation-networks-continuous-3d-structure-aware-neural-scene-representations", 12, "neurips", 2019]], "Enrique Sanchez": [0, ["Object landmark discovery through unsupervised adaptation", ["Enrique Sanchez", "Georgios Tzimiropoulos"], "http://papers.nips.cc/paper/9505-object-landmark-discovery-through-unsupervised-adaptation", 12, "neurips", 2019]], "Aleksis Pirinen": [0, ["Domes to Drones: Self-Supervised Active Triangulation for 3D Human Pose Reconstruction", ["Aleksis Pirinen", "Erik Gartner", "Cristian Sminchisescu"], "http://papers.nips.cc/paper/8646-domes-to-drones-self-supervised-active-triangulation-for-3d-human-pose-reconstruction", 11, "neurips", 2019]], "Giacomo De Palma": [0, ["Random deep neural networks are biased towards simple functions", ["Giacomo De Palma", "Bobak Toussi Kiani", "Seth Lloyd"], "http://papers.nips.cc/paper/8471-random-deep-neural-networks-are-biased-towards-simple-functions", 13, "neurips", 2019]], "Hongteng Xu": [0, ["Scalable Gromov-Wasserstein Learning for Graph Partitioning and Matching", ["Hongteng Xu", "Dixin Luo", "Lawrence Carin"], "http://papers.nips.cc/paper/8569-scalable-gromov-wasserstein-learning-for-graph-partitioning-and-matching", 11, "neurips", 2019]], "Shikun Liu": [0, ["Self-Supervised Generalisation with Meta Auxiliary Learning", ["Shikun Liu", "Andrew J. Davison", "Edward Johns"], "http://papers.nips.cc/paper/8445-self-supervised-generalisation-with-meta-auxiliary-learning", 11, "neurips", 2019]], "Baoxiang Wang": [6.957055374498533e-13, ["Privacy-Preserving Q-Learning with Functional Noise in Continuous Spaces", ["Baoxiang Wang", "Nidhi Hegde"], "http://papers.nips.cc/paper/9310-privacy-preserving-q-learning-with-functional-noise-in-continuous-spaces", 11, "neurips", 2019]], "Vrettos Moulos": [0, ["Optimal Best Markovian Arm Identification with Fixed Confidence", ["Vrettos Moulos"], "http://papers.nips.cc/paper/8798-optimal-best-markovian-arm-identification-with-fixed-confidence", 10, "neurips", 2019]], "Chaoyou Fu": [0, ["Dual Variational Generation for Low Shot Heterogeneous Face Recognition", ["Chaoyou Fu", "Xiang Wu", "Yibo Hu", "Huaibo Huang", "Ran He"], "http://papers.nips.cc/paper/8535-dual-variational-generation-for-low-shot-heterogeneous-face-recognition", 10, "neurips", 2019]], "Yi Ren": [0, ["FastSpeech: Fast, Robust and Controllable Text to Speech", ["Yi Ren", "Yangjun Ruan", "Xu Tan", "Tao Qin", "Sheng Zhao", "Zhou Zhao", "Tie-Yan Liu"], "http://papers.nips.cc/paper/8580-fastspeech-fast-robust-and-controllable-text-to-speech", 10, "neurips", 2019]], "Necdet Serhat Aybat": [0, ["A Universally Optimal Multistage Accelerated Stochastic Gradient Method", ["Necdet Serhat Aybat", "Alireza Fallah", "Mert Gurbuzbalaban", "Asuman E. Ozdaglar"], "http://papers.nips.cc/paper/9059-a-universally-optimal-multistage-accelerated-stochastic-gradient-method", 12, "neurips", 2019]], "Nikolas Ioannou": [0, ["SySCD: A System-Aware Parallel Coordinate Descent Algorithm", ["Nikolas Ioannou", "Celestine Mendler-Dunner", "Thomas P. Parnell"], "http://papers.nips.cc/paper/8349-syscd-a-system-aware-parallel-coordinate-descent-algorithm", 11, "neurips", 2019]], "Vasilis Syrgkanis": [0, ["Machine Learning Estimation of Heterogeneous Treatment Effects with Instruments", ["Vasilis Syrgkanis", "Victor Lei", "Miruna Oprescu", "Maggie Hei", "Keith Battocchi", "Greg Lewis"], "http://papers.nips.cc/paper/9655-machine-learning-estimation-of-heterogeneous-treatment-effects-with-instruments", 10, "neurips", 2019]], "Ruichu Cai": [0, ["Triad Constraints for Learning Causal Structure of Latent Variables", ["Ruichu Cai", "Feng Xie", "Clark Glymour", "Zhifeng Hao", "Kun Zhang"], "http://papers.nips.cc/paper/9448-triad-constraints-for-learning-causal-structure-of-latent-variables", 10, "neurips", 2019]], "Arman Hasanzadeh": [0, ["Semi-Implicit Graph Variational Auto-Encoders", ["Arman Hasanzadeh", "Ehsan Hajiramezanali", "Krishna R. Narayanan", "Nick Duffield", "Mingyuan Zhou", "Xiaoning Qian"], "http://papers.nips.cc/paper/9255-semi-implicit-graph-variational-auto-encoders", 12, "neurips", 2019]], "Shichen Liu": [0, ["Learning to Infer Implicit Surfaces without 3D Supervision", ["Shichen Liu", "Shunsuke Saito", "Weikai Chen", "Hao Li"], "http://papers.nips.cc/paper/9039-learning-to-infer-implicit-surfaces-without-3d-supervision", 12, "neurips", 2019]], "Ari Seff": [0, ["Discrete Object Generation with Reversible Inductive Construction", ["Ari Seff", "Wenda Zhou", "Farhan Damani", "Abigail Doyle", "Ryan P. Adams"], "http://papers.nips.cc/paper/9223-discrete-object-generation-with-reversible-inductive-construction", 11, "neurips", 2019]], "Victor Garcia Satorras": [0, ["Combining Generative and Discriminative Models for Hybrid Inference", ["Victor Garcia Satorras", "Max Welling", "Zeynep Akata"], "http://papers.nips.cc/paper/9532-combining-generative-and-discriminative-models-for-hybrid-inference", 11, "neurips", 2019]], "Benjamin Aubin": [0, ["The spiked matrix model with generative priors", ["Benjamin Aubin", "Bruno Loureiro", "Antoine Maillard", "Florent Krzakala", "Lenka Zdeborova"], "http://papers.nips.cc/paper/9045-the-spiked-matrix-model-with-generative-priors", 12, "neurips", 2019]], "Xueru Zhang": [0, ["Group Retention when Using Machine Learning in Sequential Decision Making: the Interplay between User Dynamics and Fairness", ["Xueru Zhang", "Mohammadmahdi Khaliligarekani", "Cem Tekin", "Mingyan Liu"], "http://papers.nips.cc/paper/9662-group-retention-when-using-machine-learning-in-sequential-decision-making-the-interplay-between-user-dynamics-and-fairness", 10, "neurips", 2019]], "Spencer Frei": [0, ["Algorithm-Dependent Generalization Bounds for Overparameterized Deep Residual Networks", ["Spencer Frei", "Yuan Cao", "Quanquan Gu"], "http://papers.nips.cc/paper/9619-algorithm-dependent-generalization-bounds-for-overparameterized-deep-residual-networks", 11, "neurips", 2019]], "Liyuan Xu": [0, ["Uncoupled Regression from Pairwise Comparison Data", ["Liyuan Xu", "Junya Honda", "Gang Niu", "Masashi Sugiyama"], "http://papers.nips.cc/paper/8654-uncoupled-regression-from-pairwise-comparison-data", 11, "neurips", 2019]], "Sebastien M. R. Arnold": [0, ["Reducing the variance in online optimization by transporting past gradients", ["Sebastien M. R. Arnold", "Pierre-Antoine Manzagol", "Reza Babanezhad", "Ioannis Mitliagkas", "Nicolas Le Roux"], "http://papers.nips.cc/paper/8779-reducing-the-variance-in-online-optimization-by-transporting-past-gradients", 12, "neurips", 2019]], "Sharan Vaswani": [0, ["Painless Stochastic Gradient: Interpolation, Line-Search, and Convergence Rates", ["Sharan Vaswani", "Aaron Mishkin", "Issam H. Laradji", "Mark Schmidt", "Gauthier Gidel", "Simon Lacoste-Julien"], "http://papers.nips.cc/paper/8630-painless-stochastic-gradient-interpolation-line-search-and-convergence-rates", 14, "neurips", 2019]], "Rowan Zellers": [0, ["Defending Against Neural Fake News", ["Rowan Zellers", "Ari Holtzman", "Hannah Rashkin", "Yonatan Bisk", "Ali Farhadi", "Franziska Roesner", "Yejin Choi"], "http://papers.nips.cc/paper/9106-defending-against-neural-fake-news", 12, "neurips", 2019]], "Stephane dAscoli": [0, ["Finding the Needle in the Haystack with Convolutions: on the benefits of architectural bias", ["Stephane dAscoli", "Levent Sagun", "Giulio Biroli", "Joan Bruna"], "http://papers.nips.cc/paper/9131-finding-the-needle-in-the-haystack-with-convolutions-on-the-benefits-of-architectural-bias", 11, "neurips", 2019]], "Jingjing Xu": [0, ["Understanding and Improving Layer Normalization", ["Jingjing Xu", "Xu Sun", "Zhiyuan Zhang", "Guangxiang Zhao", "Junyang Lin"], "http://papers.nips.cc/paper/8689-understanding-and-improving-layer-normalization", 11, "neurips", 2019]], "Yatin Nandwani": [0, ["A Primal Dual Formulation For Deep Learning With Constraints", ["Yatin Nandwani", "Abhishek Pathak", "Mausam", "Parag Singla"], "http://papers.nips.cc/paper/9385-a-primal-dual-formulation-for-deep-learning-with-constraints", 12, "neurips", 2019]], "Yong Guo": [0, ["NAT: Neural Architecture Transformer for Accurate and Compact Architectures", ["Yong Guo", "Yin Zheng", "Mingkui Tan", "Qi Chen", "Jian Chen", "Peilin Zhao", "Junzhou Huang"], "http://papers.nips.cc/paper/8362-nat-neural-architecture-transformer-for-accurate-and-compact-architectures", 13, "neurips", 2019]], "Erwan Lecarpentier": [0, ["Non-Stationary Markov Decision Processes, a Worst-Case Approach using Model-Based Reinforcement Learning", ["Erwan Lecarpentier", "Emmanuel Rachelson"], "http://papers.nips.cc/paper/8942-non-stationary-markov-decision-processes-a-worst-case-approach-using-model-based-reinforcement-learning", 10, "neurips", 2019]], "Rohith Kuditipudi": [0, ["Explaining Landscape Connectivity of Low-cost Solutions for Multilayer Nets", ["Rohith Kuditipudi", "Xiang Wang", "Holden Lee", "Yi Zhang", "Zhiyuan Li", "Wei Hu", "Rong Ge", "Sanjeev Arora"], "http://papers.nips.cc/paper/9602-explaining-landscape-connectivity-of-low-cost-solutions-for-multilayer-nets", 10, "neurips", 2019]], "Chongli Qin": [0, ["Adversarial Robustness through Local Linearization", ["Chongli Qin", "James Martens", "Sven Gowal", "Dilip Krishnan", "Krishnamurthy Dvijotham", "Alhussein Fawzi", "Soham De", "Robert Stanforth", "Pushmeet Kohli"], "http://papers.nips.cc/paper/9534-adversarial-robustness-through-local-linearization", 10, "neurips", 2019]], "Meyer Scetbon": [0, ["Comparing distributions: \ud835\udcc11 geometry improves kernel two-sample testing", ["Meyer Scetbon", "Gael Varoquaux"], "http://papers.nips.cc/paper/9398-comparing-distributions-ell_1-geometry-improves-kernel-two-sample-testing", 11, "neurips", 2019]], "Hado van Hasselt": [0, ["When to use parametric models in reinforcement learning?", ["Hado van Hasselt", "Matteo Hessel", "John Aslanides"], "http://papers.nips.cc/paper/9579-when-to-use-parametric-models-in-reinforcement-learning", 12, "neurips", 2019]], "Alaa Maalouf": [0, ["Fast and Accurate Least-Mean-Squares Solvers", ["Alaa Maalouf", "Ibrahim Jubran", "Dan Feldman"], "http://papers.nips.cc/paper/9040-fast-and-accurate-least-mean-squares-solvers", 12, "neurips", 2019]], "Junbang Liang": [0, ["Differentiable Cloth Simulation for Inverse Problems", ["Junbang Liang", "Ming C. Lin", "Vladlen Koltun"], "http://papers.nips.cc/paper/8365-differentiable-cloth-simulation-for-inverse-problems", 10, "neurips", 2019]], "Ben Eysenbach": [0, ["Search on the Replay Buffer: Bridging Planning and Reinforcement Learning", ["Ben Eysenbach", "Ruslan Salakhutdinov", "Sergey Levine"], "http://papers.nips.cc/paper/9660-search-on-the-replay-buffer-bridging-planning-and-reinforcement-learning", 12, "neurips", 2019]], "Mikko A. Heikkila": [0, ["Differentially Private Markov Chain Monte Carlo", ["Mikko A. Heikkila", "Joonas Jalko", "Onur Dikmen", "Antti Honkela"], "http://papers.nips.cc/paper/8665-differentially-private-markov-chain-monte-carlo", 11, "neurips", 2019]], "Matthieu Simeoni": [0, ["DeepWave: A Recurrent Neural-Network for Real-Time Acoustic Imaging", ["Matthieu Simeoni", "Sepand Kashani", "Paul Hurley", "Martin Vetterli"], "http://papers.nips.cc/paper/9665-deepwave-a-recurrent-neural-network-for-real-time-acoustic-imaging", 13, "neurips", 2019]], "Cyrille W. Combettes": [0, ["Blended Matching Pursuit", ["Cyrille W. Combettes", "Sebastian Pokutta"], "http://papers.nips.cc/paper/8478-blended-matching-pursuit", 11, "neurips", 2019]], "Jiasen Lu": [0, ["ViLBERT: Pretraining Task-Agnostic Visiolinguistic Representations for Vision-and-Language Tasks", ["Jiasen Lu", "Dhruv Batra", "Devi Parikh", "Stefan Lee"], "http://papers.nips.cc/paper/8297-vilbert-pretraining-task-agnostic-visiolinguistic-representations-for-vision-and-language-tasks", 11, "neurips", 2019]], "Florian Tramer": [0, ["Adversarial Training and Robustness for Multiple Perturbations", ["Florian Tramer", "Dan Boneh"], "http://papers.nips.cc/paper/8821-adversarial-training-and-robustness-for-multiple-perturbations", 11, "neurips", 2019]], "Juncheng Li": [0, ["Adversarial Music: Real world Audio Adversary against Wake-word Detection System", ["Juncheng Li", "Shuhui Qu", "Xinjian Li", "Joseph Szurley", "J. Zico Kolter", "Florian Metze"], "http://papers.nips.cc/paper/9362-adversarial-music-real-world-audio-adversary-against-wake-word-detection-system", 11, "neurips", 2019]], "Igor Fedorov": [0, ["SpArSe: Sparse Architecture Search for CNNs on Resource-Constrained Microcontrollers", ["Igor Fedorov", "Ryan P. Adams", "Matthew Mattina", "Paul N. Whatmough"], "http://papers.nips.cc/paper/8743-sparse-sparse-architecture-search-for-cnns-on-resource-constrained-microcontrollers", 13, "neurips", 2019]], "Sebastian Blaes": [0, ["Control What You Can: Intrinsically Motivated Task-Planning Agent", ["Sebastian Blaes", "Marin Vlastelica Pogancic", "Jia-Jie Zhu", "Georg Martius"], "http://papers.nips.cc/paper/9418-control-what-you-can-intrinsically-motivated-task-planning-agent", 12, "neurips", 2019]], "Qi Liu": [0, ["Hyperbolic Graph Neural Networks", ["Qi Liu", "Maximilian Nickel", "Douwe Kiela"], "http://papers.nips.cc/paper/9033-hyperbolic-graph-neural-networks", 12, "neurips", 2019]], "Andrei Barbu": [0, ["ObjectNet: A large-scale bias-controlled dataset for pushing the limits of object recognition models", ["Andrei Barbu", "David Mayo", "Julian Alverio", "William Luo", "Christopher Wang", "Dan Gutfreund", "Josh Tenenbaum", "Boris Katz"], "http://papers.nips.cc/paper/9142-objectnet-a-large-scale-bias-controlled-dataset-for-pushing-the-limits-of-object-recognition-models", 11, "neurips", 2019]], "Yang Song": [0.012746385298669338, ["MintNet: Building Invertible Neural Networks with Masked Convolutions", ["Yang Song", "Chenlin Meng", "Stefano Ermon"], "http://papers.nips.cc/paper/9281-mintnet-building-invertible-neural-networks-with-masked-convolutions", 11, "neurips", 2019], ["Generative Modeling by Estimating Gradients of the Data Distribution", ["Yang Song", "Stefano Ermon"], "http://papers.nips.cc/paper/9361-generative-modeling-by-estimating-gradients-of-the-data-distribution", 13, "neurips", 2019]], "Samuel Greydanus": [0, ["Hamiltonian Neural Networks", ["Samuel Greydanus", "Misko Dzamba", "Jason Yosinski"], "http://papers.nips.cc/paper/9672-hamiltonian-neural-networks", 11, "neurips", 2019]], "Parikshit Gopalan": [0, ["PIDForest: Anomaly Detection via Partial Identification", ["Parikshit Gopalan", "Vatsal Sharan", "Udi Wieder"], "http://papers.nips.cc/paper/9710-pidforest-anomaly-detection-via-partial-identification", 11, "neurips", 2019]], "Su Jia": [0, ["Optimal Decision Tree with Noisy Outcomes", ["Su Jia", "Viswanath Nagarajan", "Fatemeh Navidi", "R. Ravi"], "http://papers.nips.cc/paper/8592-optimal-decision-tree-with-noisy-outcomes", 11, "neurips", 2019]], "Yali Du": [0, ["LIIR: Learning Individual Intrinsic Reward in Multi-Agent Reinforcement Learning", ["Yali Du", "Lei Han", "Meng Fang", "Ji Liu", "Tianhong Dai", "Dacheng Tao"], "http://papers.nips.cc/paper/8691-liir-learning-individual-intrinsic-reward-in-multi-agent-reinforcement-learning", 12, "neurips", 2019]], "Abi Komanduru": [0, ["On the Correctness and Sample Complexity of Inverse Reinforcement Learning", ["Abi Komanduru", "Jean Honorio"], "http://papers.nips.cc/paper/8933-on-the-correctness-and-sample-complexity-of-inverse-reinforcement-learning", 10, "neurips", 2019]], "Chenri Ni": [0, ["On the Calibration of Multiclass Classification with Rejection", ["Chenri Ni", "Nontawat Charoenphakdee", "Junya Honda", "Masashi Sugiyama"], "http://papers.nips.cc/paper/8527-on-the-calibration-of-multiclass-classification-with-rejection", 11, "neurips", 2019]], "Lizhong Ding": [0, ["Two Generator Game: Learning to Sample via Linear Goodness-of-Fit Test", ["Lizhong Ding", "Mengyang Yu", "Li Liu", "Fan Zhu", "Yong Liu", "Yu Li", "Ling Shao"], "http://papers.nips.cc/paper/9304-two-generator-game-learning-to-sample-via-linear-goodness-of-fit-test", 12, "neurips", 2019]], "Dinghuai Zhang": [0, ["You Only Propagate Once: Accelerating Adversarial Training via Maximal Principle", ["Dinghuai Zhang", "Tianyuan Zhang", "Yiping Lu", "Zhanxing Zhu", "Bin Dong"], "http://papers.nips.cc/paper/8316-you-only-propagate-once-accelerating-adversarial-training-via-maximal-principle", 12, "neurips", 2019]], "Shouvanik Chakrabarti": [0, ["Quantum Wasserstein Generative Adversarial Networks", ["Shouvanik Chakrabarti", "Yiming Huang", "Tongyang Li", "Soheil Feizi", "Xiaodi Wu"], "http://papers.nips.cc/paper/8903-quantum-wasserstein-generative-adversarial-networks", 12, "neurips", 2019]], "Ronen Basri": [0, ["The Convergence Rate of Neural Networks for Learned Functions of Different Frequencies", ["Ronen Basri", "David W. Jacobs", "Yoni Kasten", "Shira Kritchman"], "http://papers.nips.cc/paper/8723-the-convergence-rate-of-neural-networks-for-learned-functions-of-different-frequencies", 10, "neurips", 2019]], "Alexander Mott": [0, ["Towards Interpretable Reinforcement Learning Using Attention Augmented Agents", ["Alexander Mott", "Daniel Zoran", "Mike Chrzanowski", "Daan Wierstra", "Danilo Jimenez Rezende"], "http://papers.nips.cc/paper/9400-towards-interpretable-reinforcement-learning-using-attention-augmented-agents", 10, "neurips", 2019]], "Xueting Li": [0, ["Joint-task Self-supervised Learning for Temporal Correspondence", ["Xueting Li", "Sifei Liu", "Shalini De Mello", "Xiaolong Wang", "Jan Kautz", "Ming-Hsuan Yang"], "http://papers.nips.cc/paper/8324-joint-task-self-supervised-learning-for-temporal-correspondence", 11, "neurips", 2019]], "Kecheng Zheng": [0, ["Abstract Reasoning with Distracting Features", ["Kecheng Zheng", "Zheng-Jun Zha", "Wei Wei"], "http://papers.nips.cc/paper/8819-abstract-reasoning-with-distracting-features", 12, "neurips", 2019]], "Juyeon Heo": [0.9857011884450912, ["Fooling Neural Network Interpretations via Adversarial Model Manipulation", ["Juyeon Heo", "Sunghwan Joo", "Taesup Moon"], "http://papers.nips.cc/paper/8558-fooling-neural-network-interpretations-via-adversarial-model-manipulation", 12, "neurips", 2019]], "David Janz": [0, ["Successor Uncertainties: Exploration and Uncertainty in Temporal Difference Learning", ["David Janz", "Jiri Hron", "Przemyslaw Mazur", "Katja Hofmann", "Jose Miguel Hernandez-Lobato", "Sebastian Tschiatschek"], "http://papers.nips.cc/paper/8700-successor-uncertainties-exploration-and-uncertainty-in-temporal-difference-learning", 10, "neurips", 2019]], "Mingming Gong": [3.6976216222228686e-07, ["Twin Auxilary Classifiers GAN", ["Mingming Gong", "Yanwu Xu", "Chunyuan Li", "Kun Zhang", "Kayhan Batmanghelich"], "http://papers.nips.cc/paper/8414-twin-auxilary-classifiers-gan", 10, "neurips", 2019]], "Laura Rose Edmondson": [0, ["Nonlinear scaling of resource allocation in sensory bottlenecks", ["Laura Rose Edmondson", "Alejandro Jimenez-Rodriguez", "Hannes P. Saal"], "http://papers.nips.cc/paper/8972-nonlinear-scaling-of-resource-allocation-in-sensory-bottlenecks", 10, "neurips", 2019]], "Motonobu Kanagawa": [0, ["Convergence Guarantees for Adaptive Bayesian Quadrature Methods", ["Motonobu Kanagawa", "Philipp Hennig"], "http://papers.nips.cc/paper/8854-convergence-guarantees-for-adaptive-bayesian-quadrature-methods", 12, "neurips", 2019]], "Matthew Holland": [0, ["PAC-Bayes under potentially heavy tails", ["Matthew Holland"], "http://papers.nips.cc/paper/8539-pac-bayes-under-potentially-heavy-tails", 10, "neurips", 2019]], "Zihan Li": [0, ["Learning Erdos-Renyi Random Graphs via Edge Detecting Queries", ["Zihan Li", "Matthias Fresacher", "Jonathan Scarlett"], "http://papers.nips.cc/paper/8332-learning-erdos-renyi-random-graphs-via-edge-detecting-queries", 11, "neurips", 2019]], "Huaian Diao": [0, ["Total Least Squares Regression in Input Sparsity Time", ["Huaian Diao", "Zhao Song", "David P. Woodruff", "Xin Yang"], "http://papers.nips.cc/paper/8518-total-least-squares-regression-in-input-sparsity-time", 12, "neurips", 2019], ["Optimal Sketching for Kronecker Product Regression and Low Rank Approximation", ["Huaian Diao", "Rajesh Jayaram", "Zhao Song", "Wen Sun", "David P. Woodruff"], "http://papers.nips.cc/paper/8721-optimal-sketching-for-kronecker-product-regression-and-low-rank-approximation", 12, "neurips", 2019]], "Nathaniel Lahn": [0, ["A Graph Theoretic Additive Approximation of Optimal Transport", ["Nathaniel Lahn", "Deepika Mulchandani", "Sharath Raghvendra"], "http://papers.nips.cc/paper/9533-a-graph-theoretic-additive-approximation-of-optimal-transport", 11, "neurips", 2019]], "Sebastian Mair": [0, ["Coresets for Archetypal Analysis", ["Sebastian Mair", "Ulf Brefeld"], "http://papers.nips.cc/paper/8945-coresets-for-archetypal-analysis", 9, "neurips", 2019]], "Xiangyu Xu": [0, ["Quadratic Video Interpolation", ["Xiangyu Xu", "Li Si-Yao", "Wenxiu Sun", "Qian Yin", "Ming-Hsuan Yang"], "http://papers.nips.cc/paper/8442-quadratic-video-interpolation", 10, "neurips", 2019]], "Jose A. Arjona-Medina": [0, ["RUDDER: Return Decomposition for Delayed Rewards", ["Jose A. Arjona-Medina", "Michael Gillhofer", "Michael Widrich", "Thomas Unterthiner", "Johannes Brandstetter", "Sepp Hochreiter"], "http://papers.nips.cc/paper/9509-rudder-return-decomposition-for-delayed-rewards", 12, "neurips", 2019]], "Cagatay Yildiz": [0, ["ODE2VAE: Deep generative second order ODEs with Bayesian neural networks", ["Cagatay Yildiz", "Markus Heinonen", "Harri Lahdesmaki"], "http://papers.nips.cc/paper/9497-ode2vae-deep-generative-second-order-odes-with-bayesian-neural-networks", 10, "neurips", 2019]], "Santtu Tikka": [0, ["Identifying Causal Effects via Context-specific Independence Relations", ["Santtu Tikka", "Antti Hyttinen", "Juha Karvanen"], "http://papers.nips.cc/paper/8547-identifying-causal-effects-via-context-specific-independence-relations", 11, "neurips", 2019]], "Yunfei Teng": [0, ["Leader Stochastic Gradient Descent for Distributed Training of Deep Learning Models", ["Yunfei Teng", "Wenbo Gao", "Francois Chalus", "Anna Choromanska", "Donald Goldfarb", "Adrian Weller"], "http://papers.nips.cc/paper/9175-leader-stochastic-gradient-descent-for-distributed-training-of-deep-learning-models", 11, "neurips", 2019]], "Vaishnavh Nagarajan": [0, ["Uniform convergence may be unable to explain generalization in deep learning", ["Vaishnavh Nagarajan", "J. Zico Kolter"], "http://papers.nips.cc/paper/9336-uniform-convergence-may-be-unable-to-explain-generalization-in-deep-learning", 12, "neurips", 2019]], "Ruibing Hou": [0, ["Cross Attention Network for Few-shot Classification", ["Ruibing Hou", "Hong Chang", "Bingpeng Ma", "Shiguang Shan", "Xilin Chen"], "http://papers.nips.cc/paper/8655-cross-attention-network-for-few-shot-classification", 12, "neurips", 2019]], "Elliot Meyerson": [0, ["Modular Universal Reparameterization: Deep Multi-task Learning Across Diverse Domains", ["Elliot Meyerson", "Risto Miikkulainen"], "http://papers.nips.cc/paper/9004-modular-universal-reparameterization-deep-multi-task-learning-across-diverse-domains", 12, "neurips", 2019]], "Mejbah Alam": [0, ["A Zero-Positive Learning Approach for Diagnosing Software Performance Regressions", ["Mejbah Alam", "Justin Gottschlich", "Nesime Tatbul", "Javier S. Turek", "Tim Mattson", "Abdullah Muzahid"], "http://papers.nips.cc/paper/9337-a-zero-positive-learning-approach-for-diagnosing-software-performance-regressions", 13, "neurips", 2019]], "Yonathan Efroni": [0, ["Tight Regret Bounds for Model-Based Reinforcement Learning with Greedy Policies", ["Yonathan Efroni", "Nadav Merlis", "Mohammad Ghavamzadeh", "Shie Mannor"], "http://papers.nips.cc/paper/9389-tight-regret-bounds-for-model-based-reinforcement-learning-with-greedy-policies", 11, "neurips", 2019]], "Yahav Bechavod": [0, ["Equal Opportunity in Online Classification with Partial Feedback", ["Yahav Bechavod", "Katrina Ligett", "Aaron Roth", "Bo Waggoner", "Steven Z. Wu"], "http://papers.nips.cc/paper/9099-equal-opportunity-in-online-classification-with-partial-feedback", 11, "neurips", 2019]], "Tiantian Fang": [0, ["Co-Generation with GANs using AIS based HMC", ["Tiantian Fang", "Alexander G. Schwing"], "http://papers.nips.cc/paper/8816-co-generation-with-gans-using-ais-based-hmc", 12, "neurips", 2019]], "Mehmet Fatih Sahin": [0, ["An Inexact Augmented Lagrangian Framework for Nonconvex Optimization with Nonlinear Constraints", ["Mehmet Fatih Sahin", "Armin Eftekhari", "Ahmet Alacaoglu", "Fabian Latorre Gomez", "Volkan Cevher"], "http://papers.nips.cc/paper/9545-an-inexact-augmented-lagrangian-framework-for-nonconvex-optimization-with-nonlinear-constraints", 13, "neurips", 2019]], "Tao Tu": [0, ["A state-space model for inferring effective connectivity of latent neural dynamics from simultaneous EEG/fMRI", ["Tao Tu", "John Paisley", "Stefan Haufe", "Paul Sajda"], "http://papers.nips.cc/paper/8714-a-state-space-model-for-inferring-effective-connectivity-of-latent-neural-dynamics-from-simultaneous-eegfmri", 10, "neurips", 2019]], "Xue Bin Peng": [0, ["MCP: Learning Composable Hierarchical Control with Multiplicative Compositional Policies", ["Xue Bin Peng", "Michael Chang", "Grace Zhang", "Pieter Abbeel", "Sergey Levine"], "http://papers.nips.cc/paper/8626-mcp-learning-composable-hierarchical-control-with-multiplicative-compositional-policies", 12, "neurips", 2019]], "Shaojie Bai": [1.773748481426196e-08, ["Deep Equilibrium Models", ["Shaojie Bai", "J. Zico Kolter", "Vladlen Koltun"], "http://papers.nips.cc/paper/8358-deep-equilibrium-models", 12, "neurips", 2019]], "Xiaoyun Li": [0, ["Random Projections with Asymmetric Quantization", ["Xiaoyun Li", "Ping Li"], "http://papers.nips.cc/paper/9268-random-projections-with-asymmetric-quantization", 10, "neurips", 2019], ["Generalization Error Analysis of Quantized Compressive Learning", ["Xiaoyun Li", "Ping Li"], "http://papers.nips.cc/paper/9651-generalization-error-analysis-of-quantized-compressive-learning", 11, "neurips", 2019]], "Biwei Huang": [0, ["Specific and Shared Causal Relation Modeling and Mechanism-Based Clustering", ["Biwei Huang", "Kun Zhang", "Pengtao Xie", "Mingming Gong", "Eric P. Xing", "Clark Glymour"], "http://papers.nips.cc/paper/9506-specific-and-shared-causal-relation-modeling-and-mechanism-based-clustering", 12, "neurips", 2019]], "Sitao Luan": [0, ["Break the Ceiling: Stronger Multi-scale Deep Graph Convolutional Networks", ["Sitao Luan", "Mingde Zhao", "Xiao-Wen Chang", "Doina Precup"], "http://papers.nips.cc/paper/9276-break-the-ceiling-stronger-multi-scale-deep-graph-convolutional-networks", 11, "neurips", 2019]], "Nishant Subramani": [0, ["Can Unconditional Language Models Recover Arbitrary Sentences?", ["Nishant Subramani", "Samuel R. Bowman", "Kyunghyun Cho"], "http://papers.nips.cc/paper/9661-can-unconditional-language-models-recover-arbitrary-sentences", 11, "neurips", 2019]], "Xiaohan Ding": [0, ["Global Sparse Momentum SGD for Pruning Very Deep Neural Networks", ["Xiaohan Ding", "Guiguang Ding", "Xiangxin Zhou", "Yuchen Guo", "Jungong Han", "Ji Liu"], "http://papers.nips.cc/paper/8867-global-sparse-momentum-sgd-for-pruning-very-deep-neural-networks", 13, "neurips", 2019]], "Gauthier Gidel": [0, ["Implicit Regularization of Discrete Gradient Dynamics in Linear Neural Networks", ["Gauthier Gidel", "Francis Bach", "Simon Lacoste-Julien"], "http://papers.nips.cc/paper/8583-implicit-regularization-of-discrete-gradient-dynamics-in-linear-neural-networks", 11, "neurips", 2019]], "Hanrui Zhang": [0, ["Distinguishing Distributions When Samples Are Strategically Transformed", ["Hanrui Zhang", "Yu Cheng", "Vincent Conitzer"], "http://papers.nips.cc/paper/8582-distinguishing-distributions-when-samples-are-strategically-transformed", 9, "neurips", 2019]], "Jiefeng Chen": [0, ["Robust Attribution Regularization", ["Jiefeng Chen", "Xi Wu", "Vaibhav Rastogi", "Yingyu Liang", "Somesh Jha"], "http://papers.nips.cc/paper/9577-robust-attribution-regularization", 11, "neurips", 2019]], "Shuang Li": [0, ["The Landscape of Non-convex Empirical Risk with Degenerate Population Risk", ["Shuang Li", "Gongguo Tang", "Michael B. Wakin"], "http://papers.nips.cc/paper/8610-the-landscape-of-non-convex-empirical-risk-with-degenerate-population-risk", 11, "neurips", 2019]], "Alberto Bietti": [0, ["On the Inductive Bias of Neural Tangent Kernels", ["Alberto Bietti", "Julien Mairal"], "http://papers.nips.cc/paper/9449-on-the-inductive-bias-of-neural-tangent-kernels", 12, "neurips", 2019]], "Xiaobo Xia": [0, ["Are Anchor Points Really Indispensable in Label-Noise Learning?", ["Xiaobo Xia", "Tongliang Liu", "Nannan Wang", "Bo Han", "Chen Gong", "Gang Niu", "Masashi Sugiyama"], "http://papers.nips.cc/paper/8908-are-anchor-points-really-indispensable-in-label-noise-learning", 12, "neurips", 2019]], "Yuge Shi": [0, ["Variational Mixture-of-Experts Autoencoders for Multi-Modal Deep Generative Models", ["Yuge Shi", "Siddharth Narayanaswamy", "Brooks Paige", "Philip H. S. Torr"], "http://papers.nips.cc/paper/9702-variational-mixture-of-experts-autoencoders-for-multi-modal-deep-generative-models", 12, "neurips", 2019]], "Niv Nayman": [0, ["XNAS: Neural Architecture Search with Expert Advice", ["Niv Nayman", "Asaf Noy", "Tal Ridnik", "Itamar Friedman", "Rong Jin", "Lihi Zelnik-Manor"], "http://papers.nips.cc/paper/8472-xnas-neural-architecture-search-with-expert-advice", 11, "neurips", 2019]], "J. Zico Kolter": [0, ["Learning Stable Deep Dynamics Models", ["J. Zico Kolter", "Gaurav Manek"], "http://papers.nips.cc/paper/9292-learning-stable-deep-dynamics-models", 9, "neurips", 2019]], "Belhal Karimi": [0, ["On the Global Convergence of (Fast) Incremental Expectation Maximization Methods", ["Belhal Karimi", "Hoi-To Wai", "Eric Moulines", "Marc Lavielle"], "http://papers.nips.cc/paper/8550-on-the-global-convergence-of-fast-incremental-expectation-maximization-methods", 11, "neurips", 2019]], "Joshua Tobin": [0, ["Geometry-Aware Neural Rendering", ["Joshua Tobin", "Wojciech Zaremba", "Pieter Abbeel"], "http://papers.nips.cc/paper/9331-geometry-aware-neural-rendering", 11, "neurips", 2019]], "Kazuki Osawa": [0, ["Practical Deep Learning with Bayesian Principles", ["Kazuki Osawa", "Siddharth Swaroop", "Mohammad Emtiyaz Khan", "Anirudh Jain", "Runa Eschenhagen", "Richard E. Turner", "Rio Yokota"], "http://papers.nips.cc/paper/8681-practical-deep-learning-with-bayesian-principles", 13, "neurips", 2019]], "Parimala Kancharla": [0, ["Quality Aware Generative Adversarial Networks", ["Parimala Kancharla", "Sumohana S. Channappayya"], "http://papers.nips.cc/paper/8560-quality-aware-generative-adversarial-networks", 11, "neurips", 2019]], "Gail Weiss": [0, ["Learning Deterministic Weighted Automata with Queries and Counterexamples", ["Gail Weiss", "Yoav Goldberg", "Eran Yahav"], "http://papers.nips.cc/paper/9062-learning-deterministic-weighted-automata-with-queries-and-counterexamples", 12, "neurips", 2019]], "Digvijay Boob": [0, ["Faster width-dependent algorithm for mixed packing and covering LPs", ["Digvijay Boob", "Saurabh Sawlani", "Di Wang"], "http://papers.nips.cc/paper/9663-faster-width-dependent-algorithm-for-mixed-packing-and-covering-lps", 10, "neurips", 2019]], "Shangyu Chen": [0, ["MetaQuant: Learning to Quantize by Learning to Penetrate Non-differentiable Quantization", ["Shangyu Chen", "Wenya Wang", "Sinno Jialin Pan"], "http://papers.nips.cc/paper/8647-metaquant-learning-to-quantize-by-learning-to-penetrate-non-differentiable-quantization", 11, "neurips", 2019]], "Tom Eccles": [0, ["Biases for Emergent Communication in Multi-agent Reinforcement Learning", ["Tom Eccles", "Yoram Bachrach", "Guy Lever", "Angeliki Lazaridou", "Thore Graepel"], "http://papers.nips.cc/paper/9470-biases-for-emergent-communication-in-multi-agent-reinforcement-learning", 11, "neurips", 2019]], "Debarghya Ghoshdastidar": [0, ["Foundations of Comparison-Based Hierarchical Clustering", ["Debarghya Ghoshdastidar", "Michael Perrot", "Ulrike von Luxburg"], "http://papers.nips.cc/paper/8964-foundations-of-comparison-based-hierarchical-clustering", 11, "neurips", 2019]], "Gabriel Loaiza-Ganem": [0, ["The continuous Bernoulli: fixing a pervasive error in variational autoencoders", ["Gabriel Loaiza-Ganem", "John P. Cunningham"], "http://papers.nips.cc/paper/9484-the-continuous-bernoulli-fixing-a-pervasive-error-in-variational-autoencoders", 11, "neurips", 2019], ["Deep Random Splines for Point Process Intensity Estimation of Neural Population Data", ["Gabriel Loaiza-Ganem", "Sean Perkins", "Karen Schroeder", "Mark M. Churchland", "John P. Cunningham"], "http://papers.nips.cc/paper/9491-deep-random-splines-for-point-process-intensity-estimation-of-neural-population-data", 11, "neurips", 2019]], "Jie Song": [0.031336999498307705, ["Deep Model Transferability from Attribution Maps", ["Jie Song", "Yixin Chen", "Xinchao Wang", "Chengchao Shen", "Mingli Song"], "http://papers.nips.cc/paper/8849-deep-model-transferability-from-attribution-maps", 11, "neurips", 2019]], "Eleanor Batty": [0, ["BehaveNet: nonlinear embedding and Bayesian neural decoding of behavioral videos", ["Eleanor Batty", "Matthew Whiteway", "Shreya Saxena", "Dan Biderman", "Taiga Abe", "Simon Musall", "Winthrop Gillis", "Jeffrey Markowitz", "Anne Churchland", "John P. Cunningham", "Sandeep R. Datta", "Scott W. Linderman", "Liam Paninski"], "http://papers.nips.cc/paper/9701-behavenet-nonlinear-embedding-and-bayesian-neural-decoding-of-behavioral-videos", 12, "neurips", 2019]], "Matt Jordan": [0, ["Provable Certificates for Adversarial Examples: Fitting a Ball in the Union of Polytopes", ["Matt Jordan", "Justin Lewis", "Alexandros G. Dimakis"], "http://papers.nips.cc/paper/9555-provable-certificates-for-adversarial-examples-fitting-a-ball-in-the-union-of-polytopes", 11, "neurips", 2019]], "Daniel A. Brooks": [0, ["Riemannian batch normalization for SPD neural networks", ["Daniel A. Brooks", "Olivier Schwander", "Frederic Barbaresco", "Jean-Yves Schneider", "Matthieu Cord"], "http://papers.nips.cc/paper/9682-riemannian-batch-normalization-for-spd-neural-networks", 12, "neurips", 2019]], "Wonjae Kim": [0.9968480467796326, ["Learning Dynamics of Attention: Human Prior for Interpretable Machine Reasoning", ["Wonjae Kim", "Yoonho Lee"], "http://papers.nips.cc/paper/8835-learning-dynamics-of-attention-human-prior-for-interpretable-machine-reasoning", 12, "neurips", 2019]], "Alessio Ansuini": [0, ["Intrinsic dimension of data representations in deep neural networks", ["Alessio Ansuini", "Alessandro Laio", "Jakob H. Macke", "Davide Zoccolan"], "http://papers.nips.cc/paper/8843-intrinsic-dimension-of-data-representations-in-deep-neural-networks", 11, "neurips", 2019]], "Ronald Ortner": [0, ["Regret Bounds for Learning State Representations in Reinforcement Learning", ["Ronald Ortner", "Matteo Pirotta", "Alessandro Lazaric", "Ronan Fruit", "Odalric-Ambrym Maillard"], "http://papers.nips.cc/paper/9435-regret-bounds-for-learning-state-representations-in-reinforcement-learning", 11, "neurips", 2019]], "Kaiqing Zhang": [0, ["Policy Optimization Provably Converges to Nash Equilibria in Zero-Sum Linear Quadratic Games", ["Kaiqing Zhang", "Zhuoran Yang", "Tamer Basar"], "http://papers.nips.cc/paper/9335-policy-optimization-provably-converges-to-nash-equilibria-in-zero-sum-linear-quadratic-games", 13, "neurips", 2019]], "Rob Brekelmans": [0, ["Exact Rate-Distortion in Autoencoders via Echo Noise", ["Rob Brekelmans", "Daniel Moyer", "Aram Galstyan", "Greg Ver Steeg"], "http://papers.nips.cc/paper/8644-exact-rate-distortion-in-autoencoders-via-echo-noise", 12, "neurips", 2019]], "Zhiqing Sun": [7.28570787034144e-10, ["Fast Structured Decoding for Sequence Models", ["Zhiqing Sun", "Zhuohan Li", "Haoqing Wang", "Di He", "Zi Lin", "Zhi-Hong Deng"], "http://papers.nips.cc/paper/8566-fast-structured-decoding-for-sequence-models", 10, "neurips", 2019]], "Claudia Shi": [0, ["Adapting Neural Networks for the Estimation of Treatment Effects", ["Claudia Shi", "David M. Blei", "Victor Veitch"], "http://papers.nips.cc/paper/8520-adapting-neural-networks-for-the-estimation-of-treatment-effects", 11, "neurips", 2019]], "Yingxiang Yang": [4.971956874836247e-16, ["Learning Positive Functions with Pseudo Mirror Descent", ["Yingxiang Yang", "Haoxiang Wang", "Negar Kiyavash", "Niao He"], "http://papers.nips.cc/paper/9563-learning-positive-functions-with-pseudo-mirror-descent", 11, "neurips", 2019]], "Han Zhu": [0, ["Joint Optimization of Tree-based Index and Deep Model for Recommender Systems", ["Han Zhu", "Daqing Chang", "Ziru Xu", "Pengye Zhang", "Xiang Li", "Jie He", "Han Li", "Jian Xu", "Kun Gai"], "http://papers.nips.cc/paper/8652-joint-optimization-of-tree-based-index-and-deep-model-for-recommender-systems", 10, "neurips", 2019]], "Jingjing Wang": [0.00024380151444347575, ["Multivariate Triangular Quantile Maps for Novelty Detection", ["Jingjing Wang", "Sun Sun", "Yaoliang Yu"], "http://papers.nips.cc/paper/8750-multivariate-triangular-quantile-maps-for-novelty-detection", 12, "neurips", 2019]], "Chenjun Xiao": [0, ["Maximum Entropy Monte-Carlo Planning", ["Chenjun Xiao", "Ruitong Huang", "Jincheng Mei", "Dale Schuurmans", "Martin Muller"], "http://papers.nips.cc/paper/9148-maximum-entropy-monte-carlo-planning", 9, "neurips", 2019]], "Victor Chernozhukov": [0, ["Semi-Parametric Efficient Policy Learning with Continuous Actions", ["Victor Chernozhukov", "Mert Demirer", "Greg Lewis", "Vasilis Syrgkanis"], "http://papers.nips.cc/paper/9643-semi-parametric-efficient-policy-learning-with-continuous-actions", 11, "neurips", 2019]], "Vladimir V. Kniaz": [0, ["The Point Where Reality Meets Fantasy: Mixed Adversarial Generators for Image Splice Detection", ["Vladimir V. Kniaz", "Vladimir A. Knyaz", "Fabio Remondino"], "http://papers.nips.cc/paper/8315-the-point-where-reality-meets-fantasy-mixed-adversarial-generators-for-image-splice-detection", 12, "neurips", 2019]], "Yihao Feng": [0, ["A Kernel Loss for Solving the Bellman Equation", ["Yihao Feng", "Lihong Li", "Qiang Liu"], "http://papers.nips.cc/paper/9679-a-kernel-loss-for-solving-the-bellman-equation", 12, "neurips", 2019]], "Melikasadat Emami": [0, ["Input-Output Equivalence of Unitary and Contractive RNNs", ["Melikasadat Emami", "Mojtaba Sahraee-Ardakan", "Sundeep Rangan", "Alyson K. Fletcher"], "http://papers.nips.cc/paper/9671-input-output-equivalence-of-unitary-and-contractive-rnns", 11, "neurips", 2019]], "Yue Cao": [0, ["Learning to Optimize in Swarms", ["Yue Cao", "Tianlong Chen", "Zhangyang Wang", "Yang Shen"], "http://papers.nips.cc/paper/9641-learning-to-optimize-in-swarms", 11, "neurips", 2019]], "Sanae Amani": [0, ["Linear Stochastic Bandits Under Safety Constraints", ["Sanae Amani", "Mahnoosh Alizadeh", "Christos Thrampoulidis"], "http://papers.nips.cc/paper/9124-linear-stochastic-bandits-under-safety-constraints", 11, "neurips", 2019]], "Lu Hou": [0, ["Normalization Helps Training of Quantized LSTM", ["Lu Hou", "Jinhua Zhu", "James T. Kwok", "Fei Gao", "Tao Qin", "Tie-Yan Liu"], "http://papers.nips.cc/paper/8954-normalization-helps-training-of-quantized-lstm", 11, "neurips", 2019]], "Sebastian Tschiatschek": [0, ["Learner-aware Teaching: Inverse Reinforcement Learning with Preferences and Constraints", ["Sebastian Tschiatschek", "Ahana Ghosh", "Luis Haug", "Rati Devidze", "Adish Singla"], "http://papers.nips.cc/paper/8668-learner-aware-teaching-inverse-reinforcement-learning-with-preferences-and-constraints", 11, "neurips", 2019]], "Lu Liu": [0, ["Learning to Propagate for Graph Meta-Learning", ["Lu Liu", "Tianyi Zhou", "Guodong Long", "Jing Jiang", "Chengqi Zhang"], "http://papers.nips.cc/paper/8389-learning-to-propagate-for-graph-meta-learning", 12, "neurips", 2019]], "Fushan Li": [0, ["Ease-of-Teaching and Language Structure from Emergent Communication", ["Fushan Li", "Michael Bowling"], "http://papers.nips.cc/paper/9714-ease-of-teaching-and-language-structure-from-emergent-communication", 11, "neurips", 2019]], "Antonio Orvieto": [0, ["Continuous-time Models for Stochastic Optimization Algorithms", ["Antonio Orvieto", "Aurelien Lucchi"], "http://papers.nips.cc/paper/9424-continuous-time-models-for-stochastic-optimization-algorithms", 13, "neurips", 2019], ["Shadowing Properties of Optimization Algorithms", ["Antonio Orvieto", "Aurelien Lucchi"], "http://papers.nips.cc/paper/9431-shadowing-properties-of-optimization-algorithms", 12, "neurips", 2019]], "Satoshi Tsutsui": [0, ["Meta-Reinforced Synthetic Data for One-Shot Fine-Grained Visual Recognition", ["Satoshi Tsutsui", "Yanwei Fu", "David J. Crandall"], "http://papers.nips.cc/paper/8570-meta-reinforced-synthetic-data-for-one-shot-fine-grained-visual-recognition", 10, "neurips", 2019]], "Guy Lorberbom": [0, ["Direct Optimization through arg max for Discrete Variational Auto-Encoder", ["Guy Lorberbom", "Tommi S. Jaakkola", "Andreea Gane", "Tamir Hazan"], "http://papers.nips.cc/paper/8851-direct-optimization-through-arg-max-for-discrete-variational-auto-encoder", 12, "neurips", 2019]], "Muzammal Naseer": [0, ["Cross-Domain Transferability of Adversarial Perturbations", ["Muzammal Naseer", "Salman H. Khan", "Muhammad Haris Khan", "Fahad Shahbaz Khan", "Fatih Porikli"], "http://papers.nips.cc/paper/9450-cross-domain-transferability-of-adversarial-perturbations", 11, "neurips", 2019]], "Samuli Laine": [0, ["High-Quality Self-Supervised Deep Image Denoising", ["Samuli Laine", "Tero Karras", "Jaakko Lehtinen", "Timo Aila"], "http://papers.nips.cc/paper/8920-high-quality-self-supervised-deep-image-denoising", 11, "neurips", 2019]], "Dror Simon": [0, ["Rethinking the CSC Model for Natural Images", ["Dror Simon", "Michael Elad"], "http://papers.nips.cc/paper/8499-rethinking-the-csc-model-for-natural-images", 11, "neurips", 2019]], "Pascal Mettes": [0, ["Hyperspherical Prototype Networks", ["Pascal Mettes", "Elise van der Pol", "Cees Snoek"], "http://papers.nips.cc/paper/8428-hyperspherical-prototype-networks", 11, "neurips", 2019]], "Wei Ma": [0, ["Missing Not at Random in Matrix Completion: The Effectiveness of Estimating Missingness Probabilities Under a Low Nuclear Norm Assumption", ["Wei Ma", "George H. Chen"], "http://papers.nips.cc/paper/9628-missing-not-at-random-in-matrix-completion-the-effectiveness-of-estimating-missingness-probabilities-under-a-low-nuclear-norm-assumption", 10, "neurips", 2019]], "Jie Hu": [0, ["Information Competing Process for Learning Diversified Representations", ["Jie Hu", "Rongrong Ji", "Shengchuan Zhang", "Xiaoshuai Sun", "Qixiang Ye", "Chia-Wen Lin", "Qi Tian"], "http://papers.nips.cc/paper/8490-information-competing-process-for-learning-diversified-representations", 12, "neurips", 2019]], "Youwei Lyu": [0, ["Reflection Separation using a Pair of Unpolarized and Polarized Images", ["Youwei Lyu", "Zhaopeng Cui", "Si Li", "Marc Pollefeys", "Boxin Shi"], "http://papers.nips.cc/paper/9598-reflection-separation-using-a-pair-of-unpolarized-and-polarized-images", 11, "neurips", 2019]], "Takahiro Omi": [0, ["Fully Neural Network based Model for General Temporal Point Processes", ["Takahiro Omi", "Naonori Ueda", "Kazuyuki Aihara"], "http://papers.nips.cc/paper/8485-fully-neural-network-based-model-for-general-temporal-point-processes", 10, "neurips", 2019]], "Jaehyeok Shin": [0.9905747622251511, ["Are sample means in multi-armed bandits positively or negatively biased?", ["Jaehyeok Shin", "Aaditya Ramdas", "Alessandro Rinaldo"], "http://papers.nips.cc/paper/8932-are-sample-means-in-multi-armed-bandits-positively-or-negatively-biased", 10, "neurips", 2019]], "Sumith Kulal": [0, ["SPoC: Search-based Pseudocode to Code", ["Sumith Kulal", "Panupong Pasupat", "Kartik Chandra", "Mina Lee", "Oded Padon", "Alex Aiken", "Percy Liang"], "http://papers.nips.cc/paper/9360-spoc-search-based-pseudocode-to-code", 12, "neurips", 2019]], "Lingxiao Huang": [0, ["Coresets for Clustering with Fairness Constraints", ["Lingxiao Huang", "Shaofeng H.-C. Jiang", "Nisheeth K. Vishnoi"], "http://papers.nips.cc/paper/8976-coresets-for-clustering-with-fairness-constraints", 12, "neurips", 2019]], "Alexander Peysakhovich": [0, ["Robust Multi-agent Counterfactual Prediction", ["Alexander Peysakhovich", "Christian Kroer", "Adam Lerer"], "http://papers.nips.cc/paper/8572-robust-multi-agent-counterfactual-prediction", 11, "neurips", 2019]], "Marc G. Bellemare": [0, ["A Geometric Perspective on Optimal Representations for Reinforcement Learning", ["Marc G. Bellemare", "Will Dabney", "Robert Dadashi", "Adrien Ali Taiga", "Pablo Samuel Castro", "Nicolas Le Roux", "Dale Schuurmans", "Tor Lattimore", "Clare Lyle"], "http://papers.nips.cc/paper/8687-a-geometric-perspective-on-optimal-representations-for-reinforcement-learning", 12, "neurips", 2019]], "Haohan Wang": [0.05809248425066471, ["Learning Robust Global Representations by Penalizing Local Predictive Power", ["Haohan Wang", "Songwei Ge", "Zachary C. Lipton", "Eric P. Xing"], "http://papers.nips.cc/paper/9237-learning-robust-global-representations-by-penalizing-local-predictive-power", 13, "neurips", 2019]], "Edith Cohen": [0, ["Sampling Sketches for Concave Sublinear Functions of Frequencies", ["Edith Cohen", "Ofir Geri"], "http://papers.nips.cc/paper/8417-sampling-sketches-for-concave-sublinear-functions-of-frequencies", 11, "neurips", 2019]], "Boyi Li": [0, ["Positional Normalization", ["Boyi Li", "Felix Wu", "Kilian Q. Weinberger", "Serge J. Belongie"], "http://papers.nips.cc/paper/8440-positional-normalization", 13, "neurips", 2019]], "Zhiyong Yang": [4.808835365111008e-05, ["Generalized Block-Diagonal Structure Pursuit: Learning Soft Latent Task Assignment against Negative Transfer", ["Zhiyong Yang", "Qianqian Xu", "Yangbangyan Jiang", "Xiaochun Cao", "Qingming Huang"], "http://papers.nips.cc/paper/8820-generalized-block-diagonal-structure-pursuit-learning-soft-latent-task-assignment-against-negative-transfer", 12, "neurips", 2019]], "Yi Xu": [0, ["Non-asymptotic Analysis of Stochastic Methods for Non-Smooth Non-Convex Regularized Problems", ["Yi Xu", "Rong Jin", "Tianbao Yang"], "http://papers.nips.cc/paper/8531-non-asymptotic-analysis-of-stochastic-methods-for-non-smooth-non-convex-regularized-problems", 11, "neurips", 2019]], "Jonathan Sauder": [0, ["Self-Supervised Deep Learning on Point Clouds by Reconstructing Space", ["Jonathan Sauder", "Bjarne Sievers"], "http://papers.nips.cc/paper/9455-self-supervised-deep-learning-on-point-clouds-by-reconstructing-space", 11, "neurips", 2019]], "Tengyu Xu": [0, ["Two Time-scale Off-Policy TD Learning: Non-asymptotic Analysis over Markovian Samples", ["Tengyu Xu", "Shaofeng Zou", "Yingbin Liang"], "http://papers.nips.cc/paper/9248-two-time-scale-off-policy-td-learning-non-asymptotic-analysis-over-markovian-samples", 11, "neurips", 2019]], "Sefi Bell-Kligler": [0, ["Blind Super-Resolution Kernel Estimation using an Internal-GAN", ["Sefi Bell-Kligler", "Assaf Shocher", "Michal Irani"], "http://papers.nips.cc/paper/8321-blind-super-resolution-kernel-estimation-using-an-internal-gan", 10, "neurips", 2019]], "Kevin Smith": [0, ["Modeling Expectation Violation in Intuitive Physics with Coarse Probabilistic Object Representations", ["Kevin Smith", "Lingjie Mei", "Shunyu Yao", "Jiajun Wu", "Elizabeth S. Spelke", "Josh Tenenbaum", "Tomer Ullman"], "http://papers.nips.cc/paper/9100-modeling-expectation-violation-in-intuitive-physics-with-coarse-probabilistic-object-representations", 11, "neurips", 2019]], "Benjamin J. Lengerich": [0, ["Learning Sample-Specific Models with Low-Rank Personalized Regression", ["Benjamin J. Lengerich", "Bryon Aragam", "Eric P. Xing"], "http://papers.nips.cc/paper/8616-learning-sample-specific-models-with-low-rank-personalized-regression", 11, "neurips", 2019]], "Han Zhao": [0, ["Learning Neural Networks with Adaptive Regularization", ["Han Zhao", "Yao-Hung Hubert Tsai", "Ruslan Salakhutdinov", "Geoffrey J. Gordon"], "http://papers.nips.cc/paper/9316-learning-neural-networks-with-adaptive-regularization", 12, "neurips", 2019], ["Inherent Tradeoffs in Learning Fair Representations", ["Han Zhao", "Geoffrey J. Gordon"], "http://papers.nips.cc/paper/9698-inherent-tradeoffs-in-learning-fair-representations", 11, "neurips", 2019]], "Alan Kuhnle": [0, ["Interlaced Greedy Algorithm for Maximization of Submodular Functions in Nearly Linear Time", ["Alan Kuhnle"], "http://papers.nips.cc/paper/8508-interlaced-greedy-algorithm-for-maximization-of-submodular-functions-in-nearly-linear-time", 11, "neurips", 2019]], "Rebekka Burkholz": [0, ["Initialization of ReLUs for Dynamical Isometry", ["Rebekka Burkholz", "Alina Dubatovka"], "http://papers.nips.cc/paper/8509-initialization-of-relus-for-dynamical-isometry", 11, "neurips", 2019]], "Brett Daley": [0, ["Reconciling \u03bb-Returns with Experience Replay", ["Brett Daley", "Christopher Amato"], "http://papers.nips.cc/paper/8397-reconciling-returns-with-experience-replay", 10, "neurips", 2019]], "Dheeraj Baby": [0, ["Online Forecasting of Total-Variation-bounded Sequences", ["Dheeraj Baby", "Yu-Xiang Wang"], "http://papers.nips.cc/paper/9287-online-forecasting-of-total-variation-bounded-sequences", 11, "neurips", 2019]], "Qing Wang": [0.00010747280612122267, ["Divergence-Augmented Policy Optimization", ["Qing Wang", "Yingru Li", "Jiechao Xiong", "Tong Zhang"], "http://papers.nips.cc/paper/8842-divergence-augmented-policy-optimization", 12, "neurips", 2019]], "Rahaf Aljundi": [0, ["Gradient based sample selection for online continual learning", ["Rahaf Aljundi", "Min Lin", "Baptiste Goujaud", "Yoshua Bengio"], "http://papers.nips.cc/paper/9354-gradient-based-sample-selection-for-online-continual-learning", 10, "neurips", 2019], ["Online Continual Learning with Maximal Interfered Retrieval", ["Rahaf Aljundi", "Eugene Belilovsky", "Tinne Tuytelaars", "Laurent Charlin", "Massimo Caccia", "Min Lin", "Lucas Page-Caccia"], "http://papers.nips.cc/paper/9357-online-continual-learning-with-maximal-interfered-retrieval", 12, "neurips", 2019]], "Qiangeng Xu": [0, ["DISN: Deep Implicit Surface Network for High-quality Single-view 3D Reconstruction", ["Qiangeng Xu", "Weiyue Wang", "Duygu Ceylan", "Radomir Mech", "Ulrich Neumann"], "http://papers.nips.cc/paper/8340-disn-deep-implicit-surface-network-for-high-quality-single-view-3d-reconstruction", 11, "neurips", 2019]], "Koen Helwegen": [0, ["Latent Weights Do Not Exist: Rethinking Binarized Neural Network Optimization", ["Koen Helwegen", "James Widdicombe", "Lukas Geiger", "Zechun Liu", "Kwang-Ting Cheng", "Roeland Nusselder"], "http://papers.nips.cc/paper/8971-latent-weights-do-not-exist-rethinking-binarized-neural-network-optimization", 12, "neurips", 2019]], "Caroline Haimerl": [0, ["Flexible information routing in neural populations through stochastic comodulation", ["Caroline Haimerl", "Cristina Savin", "Eero P. Simoncelli"], "http://papers.nips.cc/paper/9584-flexible-information-routing-in-neural-populations-through-stochastic-comodulation", 10, "neurips", 2019]], "Brenden M. Lake": [0, ["Compositional generalization through meta sequence-to-sequence learning", ["Brenden M. Lake"], "http://papers.nips.cc/paper/9172-compositional-generalization-through-meta-sequence-to-sequence-learning", 11, "neurips", 2019]], "Zhijian Liu": [0, ["Point-Voxel CNN for Efficient 3D Deep Learning", ["Zhijian Liu", "Haotian Tang", "Yujun Lin", "Song Han"], "http://papers.nips.cc/paper/8382-point-voxel-cnn-for-efficient-3d-deep-learning", 11, "neurips", 2019]], "Ferran Alet": [0, ["Neural Relational Inference with Fast Modular Meta-learning", ["Ferran Alet", "Erica Weng", "Tomas Lozano-Perez", "Leslie Pack Kaelbling"], "http://papers.nips.cc/paper/9353-neural-relational-inference-with-fast-modular-meta-learning", 12, "neurips", 2019]], "Kenji Fukumizu": [0, ["Semi-flat minima and saddle points by embedding neural networks to overparameterization", ["Kenji Fukumizu", "Shoichiro Yamaguchi", "Yoh-ichi Mototake", "Mirai Tanaka"], "http://papers.nips.cc/paper/9536-semi-flat-minima-and-saddle-points-by-embedding-neural-networks-to-overparameterization", 9, "neurips", 2019]], "Cheng Meng": [0, ["Large-scale optimal transport map estimation using projection pursuit", ["Cheng Meng", "Yuan Ke", "Jingyi Zhang", "Mengrui Zhang", "Wenxuan Zhong", "Ping Ma"], "http://papers.nips.cc/paper/9023-large-scale-optimal-transport-map-estimation-using-projection-pursuit", 12, "neurips", 2019]], "Ruidi Chen": [0, ["Selecting Optimal Decisions via Distributionally Robust Nearest-Neighbor Regression", ["Ruidi Chen", "Ioannis Ch. Paschalidis"], "http://papers.nips.cc/paper/8363-selecting-optimal-decisions-via-distributionally-robust-nearest-neighbor-regression", 11, "neurips", 2019]], "Ivana Balazevic": [0, ["Multi-relational Poincar\u00e9 Graph Embeddings", ["Ivana Balazevic", "Carl Allen", "Timothy M. Hospedales"], "http://papers.nips.cc/paper/8696-multi-relational-poincare-graph-embeddings", 11, "neurips", 2019]], "Francesco Locatello": [0, ["Stochastic Frank-Wolfe for Composite Convex Minimization", ["Francesco Locatello", "Alp Yurtsever", "Olivier Fercoq", "Volkan Cevher"], "http://papers.nips.cc/paper/9572-stochastic-frank-wolfe-for-composite-convex-minimization", 11, "neurips", 2019], ["On the Fairness of Disentangled Representations", ["Francesco Locatello", "Gabriele Abbati", "Thomas Rainforth", "Stefan Bauer", "Bernhard Scholkopf", "Olivier Bachem"], "http://papers.nips.cc/paper/9603-on-the-fairness-of-disentangled-representations", 14, "neurips", 2019]], "Taewan Kim": [0.9346984922885895, ["On Single Source Robustness in Deep Fusion Models", ["Taewan Kim", "Joydeep Ghosh"], "http://papers.nips.cc/paper/8728-on-single-source-robustness-in-deep-fusion-models", 12, "neurips", 2019]], "Xiuyuan Lu": [0, ["Information-Theoretic Confidence Bounds for Reinforcement Learning", ["Xiuyuan Lu", "Benjamin Van Roy"], "http://papers.nips.cc/paper/8516-information-theoretic-confidence-bounds-for-reinforcement-learning", 9, "neurips", 2019]], "Chao Yang": [0.3783327341079712, ["Imitation Learning from Observations by Minimizing Inverse Dynamics Disagreement", ["Chao Yang", "Xiaojian Ma", "Wenbing Huang", "Fuchun Sun", "Huaping Liu", "Junzhou Huang", "Chuang Gan"], "http://papers.nips.cc/paper/8317-imitation-learning-from-observations-by-minimizing-inverse-dynamics-disagreement", 11, "neurips", 2019]], "Jacob D. Abernethy": [0, ["Online Learning via the Differential Privacy Lens", ["Jacob D. Abernethy", "Young Hun Jung", "Chansoo Lee", "Audra McMillan", "Ambuj Tewari"], "http://papers.nips.cc/paper/9092-online-learning-via-the-differential-privacy-lens", 11, "neurips", 2019], ["Learning Auctions with Robust Incentive Guarantees", ["Jacob D. Abernethy", "Rachel Cummings", "Bhuvesh Kumar", "Sam Taggart", "Jamie H. Morgenstern"], "http://papers.nips.cc/paper/9334-learning-auctions-with-robust-incentive-guarantees", 11, "neurips", 2019]], "Sergul Aydore": [0, ["Dynamic Local Regret for Non-convex Online Forecasting", ["Sergul Aydore", "Tianhao Zhu", "Dean P. Foster"], "http://papers.nips.cc/paper/9011-dynamic-local-regret-for-non-convex-online-forecasting", 10, "neurips", 2019]], "Jonathan Ho": [0, ["Compression with Flows via Local Bits-Back Coding", ["Jonathan Ho", "Evan Lohn", "Pieter Abbeel"], "http://papers.nips.cc/paper/8643-compression-with-flows-via-local-bits-back-coding", 10, "neurips", 2019]], "Boxin Zhao": [0, ["Direct Estimation of Differential Functional Graphical Models", ["Boxin Zhao", "Y. Samuel Wang", "Mladen Kolar"], "http://papers.nips.cc/paper/8526-direct-estimation-of-differential-functional-graphical-models", 11, "neurips", 2019]], "Ngoc-Trung Tran": [0, ["Self-supervised GAN: Analysis and Improvement with Multi-class Minimax Game", ["Ngoc-Trung Tran", "Viet-Hung Tran", "Ngoc-Bao Nguyen", "Linxiao Yang", "Ngai-Man Cheung"], "http://papers.nips.cc/paper/9481-self-supervised-gan-analysis-and-improvement-with-multi-class-minimax-game", 12, "neurips", 2019]], "Tristan Bepler": [0, ["Explicitly disentangling image content from translation and rotation with spatial-VAE", ["Tristan Bepler", "Ellen D. Zhong", "Kotaro Kelley", "Edward Brignole", "Bonnie Berger"], "http://papers.nips.cc/paper/9677-explicitly-disentangling-image-content-from-translation-and-rotation-with-spatial-vae", 11, "neurips", 2019]], "Jose H. Blanchet": [0, ["Multivariate Distributionally Robust Convex Regression under Absolute Error Loss", ["Jose H. Blanchet", "Peter W. Glynn", "Jun Yan", "Zhengqing Zhou"], "http://papers.nips.cc/paper/9352-multivariate-distributionally-robust-convex-regression-under-absolute-error-loss", 10, "neurips", 2019]], "Greg Yang": [0.0006584698712686077, ["Wide Feedforward or Recurrent Neural Networks of Any Architecture are Gaussian Processes", ["Greg Yang"], "http://papers.nips.cc/paper/9186-wide-feedforward-or-recurrent-neural-networks-of-any-architecture-are-gaussian-processes", 14, "neurips", 2019]], "Frederik Kunstner": [0, ["Limitations of the empirical Fisher approximation for natural gradient descent", ["Frederik Kunstner", "Philipp Hennig", "Lukas Balles"], "http://papers.nips.cc/paper/8669-limitations-of-the-empirical-fisher-approximation-for-natural-gradient-descent", 12, "neurips", 2019]], "Difan Zou": [0, ["An Improved Analysis of Training Over-parameterized Deep Neural Networks", ["Difan Zou", "Quanquan Gu"], "http://papers.nips.cc/paper/8479-an-improved-analysis-of-training-over-parameterized-deep-neural-networks", 10, "neurips", 2019], ["Stochastic Gradient Hamiltonian Monte Carlo Methods with Recursive Variance Reduction", ["Difan Zou", "Pan Xu", "Quanquan Gu"], "http://papers.nips.cc/paper/8639-stochastic-gradient-hamiltonian-monte-carlo-methods-with-recursive-variance-reduction", 12, "neurips", 2019], ["Layer-Dependent Importance Sampling for Training Deep and Large Graph Convolutional Networks", ["Difan Zou", "Ziniu Hu", "Yewen Wang", "Song Jiang", "Yizhou Sun", "Quanquan Gu"], "http://papers.nips.cc/paper/9303-layer-dependent-importance-sampling-for-training-deep-and-large-graph-convolutional-networks", 10, "neurips", 2019]], "Yasutoshi Ida": [0, ["Fast Sparse Group Lasso", ["Yasutoshi Ida", "Yasuhiro Fujiwara", "Hisashi Kashima"], "http://papers.nips.cc/paper/8447-fast-sparse-group-lasso", 9, "neurips", 2019]], "Kevin Bello": [0, ["Exact inference in structured prediction", ["Kevin Bello", "Jean Honorio"], "http://papers.nips.cc/paper/8627-exact-inference-in-structured-prediction", 10, "neurips", 2019]], "Ernesto Araya Valdivia": [0, ["Latent distance estimation for random geometric graphs", ["Ernesto Araya Valdivia", "Yohann de Castro"], "http://papers.nips.cc/paper/9077-latent-distance-estimation-for-random-geometric-graphs", 11, "neurips", 2019]], "Taco S. Cohen": [0, ["A General Theory of Equivariant CNNs on Homogeneous Spaces", ["Taco S. Cohen", "Mario Geiger", "Maurice Weiler"], "http://papers.nips.cc/paper/9114-a-general-theory-of-equivariant-cnns-on-homogeneous-spaces", 12, "neurips", 2019]], "Hongzi Mao": [0, ["Park: An Open Platform for Learning-Augmented Computer Systems", ["Hongzi Mao", "Parimarjan Negi", "Akshay Narayan", "Hanrui Wang", "Jiacheng Yang", "Haonan Wang", "Ryan Marcus", "Ravichandra Addanki", "Mehrdad Khani Shirkoohi", "Songtao He", "Vikram Nathan", "Frank Cangialosi", "Shaileshh Bojja Venkatakrishnan", "Wei-Hung Weng", "Song Han", "Tim Kraska", "Mohammad Alizadeh"], "http://papers.nips.cc/paper/8519-park-an-open-platform-for-learning-augmented-computer-systems", 13, "neurips", 2019]], "Ruben Villegas": [0, ["High Fidelity Video Prediction with Large Stochastic Recurrent Neural Networks", ["Ruben Villegas", "Arkanath Pathak", "Harini Kannan", "Dumitru Erhan", "Quoc V. Le", "Honglak Lee"], "http://papers.nips.cc/paper/8303-high-fidelity-video-prediction-with-large-stochastic-recurrent-neural-networks", 11, "neurips", 2019]], "Jonas Kubilius": [0, ["Brain-Like Object Recognition with High-Performing Shallow Recurrent ANNs", ["Jonas Kubilius", "Martin Schrimpf", "Ha Hong", "Najib J. Majaj", "Rishi Rajalingham", "Elias B. Issa", "Kohitij Kar", "Pouya Bashivan", "Jonathan Prescott-Roy", "Kailyn Schmidt", "Aran Nayebi", "Daniel Bear", "Daniel L. Yamins", "James J. DiCarlo"], "http://papers.nips.cc/paper/9441-brain-like-object-recognition-with-high-performing-shallow-recurrent-anns", 12, "neurips", 2019]], "Sungbin Lim": [0.9210739880800247, ["Fast AutoAugment", ["Sungbin Lim", "Ildoo Kim", "Taesup Kim", "Chiheon Kim", "Sungwoong Kim"], "http://papers.nips.cc/paper/8892-fast-autoaugment", 11, "neurips", 2019]], "Haichao Zhang": [0, ["Defense Against Adversarial Attacks Using Feature Scattering-based Adversarial Training", ["Haichao Zhang", "Jianyu Wang"], "http://papers.nips.cc/paper/8459-defense-against-adversarial-attacks-using-feature-scattering-based-adversarial-training", 11, "neurips", 2019]], "Suman V. Ravuri": [0, ["Classification Accuracy Score for Conditional Generative Models", ["Suman V. Ravuri", "Oriol Vinyals"], "http://papers.nips.cc/paper/9393-classification-accuracy-score-for-conditional-generative-models", 12, "neurips", 2019]], "Yizhe Zhu": [0, ["Semantic-Guided Multi-Attention Localization for Zero-Shot Learning", ["Yizhe Zhu", "Jianwen Xie", "Zhiqiang Tang", "Xi Peng", "Ahmed Elgammal"], "http://papers.nips.cc/paper/9632-semantic-guided-multi-attention-localization-for-zero-shot-learning", 11, "neurips", 2019]], "Yann N. Dauphin": [0, ["MetaInit: Initializing learning by learning to initialize", ["Yann N. Dauphin", "Samuel S. Schoenholz"], "http://papers.nips.cc/paper/9427-metainit-initializing-learning-by-learning-to-initialize", 13, "neurips", 2019]], "Meire Fortunato": [0, ["Generalization of Reinforcement Learners with Working and Episodic Memory", ["Meire Fortunato", "Melissa Tan", "Ryan Faulkner", "Steven Hansen", "Adria Puigdomenech Badia", "Gavin Buttimore", "Charles Deck", "Joel Z. Leibo", "Charles Blundell"], "http://papers.nips.cc/paper/9411-generalization-of-reinforcement-learners-with-working-and-episodic-memory", 10, "neurips", 2019]], "Kamalika Chaudhuri": [0, ["Capacity Bounded Differential Privacy", ["Kamalika Chaudhuri", "Jacob Imola", "Ashwin Machanavajjhala"], "http://papers.nips.cc/paper/8607-capacity-bounded-differential-privacy", 10, "neurips", 2019]], "Yonatan Geifman": [0, ["Deep Active Learning with a Neural Architecture Search", ["Yonatan Geifman", "Ran El-Yaniv"], "http://papers.nips.cc/paper/8831-deep-active-learning-with-a-neural-architecture-search", 11, "neurips", 2019]], "Zhonghui You": [0, ["Gate Decorator: Global Filter Pruning Method for Accelerating Deep Convolutional Neural Networks", ["Zhonghui You", "Kun Yan", "Jinmian Ye", "Meng Ma", "Ping Wang"], "http://papers.nips.cc/paper/8486-gate-decorator-global-filter-pruning-method-for-accelerating-deep-convolutional-neural-networks", 12, "neurips", 2019]], "Yoan Russac": [0, ["Weighted Linear Bandits for Non-Stationary Environments", ["Yoan Russac", "Claire Vernade", "Olivier Cappe"], "http://papers.nips.cc/paper/9372-weighted-linear-bandits-for-non-stationary-environments", 10, "neurips", 2019]], "Dushyant Rao": [0, ["Continual Unsupervised Representation Learning", ["Dushyant Rao", "Francesco Visin", "Andrei A. Rusu", "Razvan Pascanu", "Yee Whye Teh", "Raia Hadsell"], "http://papers.nips.cc/paper/8981-continual-unsupervised-representation-learning", 11, "neurips", 2019]], "Arturs Backurs": [0, ["Space and Time Efficient Kernel Density Estimation in High Dimensions", ["Arturs Backurs", "Piotr Indyk", "Tal Wagner"], "http://papers.nips.cc/paper/9709-space-and-time-efficient-kernel-density-estimation-in-high-dimensions", 10, "neurips", 2019]], "Yu Sun": [0.002284156798850745, ["Block Coordinate Regularization by Denoising", ["Yu Sun", "Jiaming Liu", "Ulugbek Kamilov"], "http://papers.nips.cc/paper/8330-block-coordinate-regularization-by-denoising", 11, "neurips", 2019]], "Adrian V. Dalca": [0, ["Learning Conditional Deformable Templates with Convolutional Networks", ["Adrian V. Dalca", "Marianne Rakic", "John V. Guttag", "Mert R. Sabuncu"], "http://papers.nips.cc/paper/8368-learning-conditional-deformable-templates-with-convolutional-networks", 13, "neurips", 2019]], "Saeed Sharifi-Malvajerdi": [0, ["Average Individual Fairness: Algorithms, Generalization and Experiments", ["Saeed Sharifi-Malvajerdi", "Michael J. Kearns", "Aaron Roth"], "http://papers.nips.cc/paper/9034-average-individual-fairness-algorithms-generalization-and-experiments", 10, "neurips", 2019]], "Matthew Reimherr": [0, ["Elliptical Perturbations for Differential Privacy", ["Matthew Reimherr", "Jordan Awan"], "http://papers.nips.cc/paper/9208-elliptical-perturbations-for-differential-privacy", 12, "neurips", 2019], ["KNG: The K-Norm Gradient Mechanism", ["Matthew Reimherr", "Jordan Awan"], "http://papers.nips.cc/paper/9210-kng-the-k-norm-gradient-mechanism", 12, "neurips", 2019]], "Raymond A. Yeh": [0, ["Chirality Nets for Human Pose Regression", ["Raymond A. Yeh", "Yuan-Ting Hu", "Alexander G. Schwing"], "http://papers.nips.cc/paper/9027-chirality-nets-for-human-pose-regression", 11, "neurips", 2019]], "Daniel J. McDuff": [0, ["Characterizing Bias in Classifiers using Generative Models", ["Daniel J. McDuff", "Shuang Ma", "Yale Song", "Ashish Kapoor"], "http://papers.nips.cc/paper/8780-characterizing-bias-in-classifiers-using-generative-models", 12, "neurips", 2019]], "Kundan Kumar": [0, ["MelGAN: Generative Adversarial Networks for Conditional Waveform Synthesis", ["Kundan Kumar", "Rithesh Kumar", "Thibault de Boissiere", "Lucas Gestin", "Wei Zhen Teoh", "Jose Sotelo", "Alexandre de Brebisson", "Yoshua Bengio", "Aaron C. Courville"], "http://papers.nips.cc/paper/9629-melgan-generative-adversarial-networks-for-conditional-waveform-synthesis", 12, "neurips", 2019]], "Jack Serrino": [0, ["Finding Friend and Foe in Multi-Agent Games", ["Jack Serrino", "Max Kleiman-Weiner", "David C. Parkes", "Josh Tenenbaum"], "http://papers.nips.cc/paper/8408-finding-friend-and-foe-in-multi-agent-games", 11, "neurips", 2019]], "Zhihui Zhu": [0, ["Distributed Low-rank Matrix Factorization With Exact Consensus", ["Zhihui Zhu", "Qiuwei Li", "Xinshuo Yang", "Gongguo Tang", "Michael B. Wakin"], "http://papers.nips.cc/paper/9050-distributed-low-rank-matrix-factorization-with-exact-consensus", 11, "neurips", 2019], ["A Linearly Convergent Method for Non-Smooth Non-Convex Optimization on the Grassmannian with Applications to Robust Subspace and Dictionary Learning", ["Zhihui Zhu", "Tianyu Ding", "Daniel P. Robinson", "Manolis C. Tsakiris", "Rene Vidal"], "http://papers.nips.cc/paper/9141-a-linearly-convergent-method-for-non-smooth-non-convex-optimization-on-the-grassmannian-with-applications-to-robust-subspace-and-dictionary-learning", 11, "neurips", 2019]], "Robert Pinsler": [0, ["Bayesian Batch Active Learning as Sparse Subset Approximation", ["Robert Pinsler", "Jonathan Gordon", "Eric T. Nalisnick", "Jose Miguel Hernandez-Lobato"], "http://papers.nips.cc/paper/8865-bayesian-batch-active-learning-as-sparse-subset-approximation", 12, "neurips", 2019]], "Wei Deng": [0, ["An Adaptive Empirical Bayesian Method for Sparse Deep Learning", ["Wei Deng", "Xiao Zhang", "Faming Liang", "Guang Lin"], "http://papers.nips.cc/paper/8794-an-adaptive-empirical-bayesian-method-for-sparse-deep-learning", 11, "neurips", 2019]], "Mathieu Blondel": [0, ["Structured Prediction with Projection Oracles", ["Mathieu Blondel"], "http://papers.nips.cc/paper/9384-structured-prediction-with-projection-oracles", 12, "neurips", 2019]], "Ryo Karakida": [0, ["The Normalization Method for Alleviating Pathological Sharpness in Wide Neural Networks", ["Ryo Karakida", "Shotaro Akaho", "Shun-ichi Amari"], "http://papers.nips.cc/paper/8869-the-normalization-method-for-alleviating-pathological-sharpness-in-wide-neural-networks", 11, "neurips", 2019]], "Young Hun Jung": [0.9858854115009308, ["Regret Bounds for Thompson Sampling in Episodic Restless Bandit Problems", ["Young Hun Jung", "Ambuj Tewari"], "http://papers.nips.cc/paper/9102-regret-bounds-for-thompson-sampling-in-episodic-restless-bandit-problems", 10, "neurips", 2019]], "Naman Agarwal": [0, ["Logarithmic Regret for Online Control", ["Naman Agarwal", "Elad Hazan", "Karan Singh"], "http://papers.nips.cc/paper/9207-logarithmic-regret-for-online-control", 10, "neurips", 2019]], "Wei-Da Chen": [0, ["CNN2: Viewpoint Generalization via a Binocular Vision", ["Wei-Da Chen", "Shan-Hung Wu"], "http://papers.nips.cc/paper/8473-cnn2-viewpoint-generalization-via-a-binocular-vision", 13, "neurips", 2019]], "Fernando Gama": [0, ["Stability of Graph Scattering Transforms", ["Fernando Gama", "Alejandro Ribeiro", "Joan Bruna"], "http://papers.nips.cc/paper/9016-stability-of-graph-scattering-transforms", 11, "neurips", 2019]], "Niru Maheswaranathan": [0, ["Universality and individuality in neural dynamics across large populations of recurrent networks", ["Niru Maheswaranathan", "Alex H. Williams", "Matthew D. Golub", "Surya Ganguli", "David Sussillo"], "http://papers.nips.cc/paper/9694-universality-and-individuality-in-neural-dynamics-across-large-populations-of-recurrent-networks", 13, "neurips", 2019], ["Reverse engineering recurrent networks for sentiment classification reveals line attractor dynamics", ["Niru Maheswaranathan", "Alex H. Williams", "Matthew D. Golub", "Surya Ganguli", "David Sussillo"], "http://papers.nips.cc/paper/9700-reverse-engineering-recurrent-networks-for-sentiment-classification-reveals-line-attractor-dynamics", 10, "neurips", 2019]], "Matthias Minderer": [0, ["Unsupervised learning of object structure and dynamics from videos", ["Matthias Minderer", "Chen Sun", "Ruben Villegas", "Forrester Cole", "Kevin P. Murphy", "Honglak Lee"], "http://papers.nips.cc/paper/8304-unsupervised-learning-of-object-structure-and-dynamics-from-videos", 11, "neurips", 2019]], "Dominik Linzner": [0, ["Scalable Structure Learning of Continuous-Time Bayesian Networks from Incomplete Data", ["Dominik Linzner", "Michael Schmidt", "Heinz Koeppl"], "http://papers.nips.cc/paper/8631-scalable-structure-learning-of-continuous-time-bayesian-networks-from-incomplete-data", 11, "neurips", 2019]], "Aviv Rosenberg": [0, ["Online Stochastic Shortest Path with Bandit Feedback and Unknown Transition Function", ["Aviv Rosenberg", "Yishay Mansour"], "http://papers.nips.cc/paper/8493-online-stochastic-shortest-path-with-bandit-feedback-and-unknown-transition-function", 10, "neurips", 2019]], "Jie Ren": [0, ["Likelihood Ratios for Out-of-Distribution Detection", ["Jie Ren", "Peter J. Liu", "Emily Fertig", "Jasper Snoek", "Ryan Poplin", "Mark A. DePristo", "Joshua V. Dillon", "Balaji Lakshminarayanan"], "http://papers.nips.cc/paper/9611-likelihood-ratios-for-out-of-distribution-detection", 12, "neurips", 2019]], "Alex X. Lu": [0, ["The Cells Out of Sample (COOS) dataset and benchmarks for measuring out-of-sample generalization of image classifiers", ["Alex X. Lu", "Amy X. Lu", "Wiebke Schormann", "Marzyeh Ghassemi", "David W. Andrews", "Alan M. Moses"], "http://papers.nips.cc/paper/8461-the-cells-out-of-sample-coos-dataset-and-benchmarks-for-measuring-out-of-sample-generalization-of-image-classifiers", 9, "neurips", 2019]], "Shinji Ito": [0, ["Oracle-Efficient Algorithms for Online Linear Optimization with Bandit Feedback", ["Shinji Ito", "Daisuke Hatano", "Hanna Sumita", "Kei Takemura", "Takuro Fukunaga", "Naonori Kakimura", "Ken-ichi Kawarabayashi"], "http://papers.nips.cc/paper/9244-oracle-efficient-algorithms-for-online-linear-optimization-with-bandit-feedback", 10, "neurips", 2019], ["Improved Regret Bounds for Bandit Combinatorial Optimization", ["Shinji Ito", "Daisuke Hatano", "Hanna Sumita", "Kei Takemura", "Takuro Fukunaga", "Naonori Kakimura", "Ken-ichi Kawarabayashi"], "http://papers.nips.cc/paper/9373-improved-regret-bounds-for-bandit-combinatorial-optimization", 10, "neurips", 2019], ["Submodular Function Minimization with Noisy Evaluation Oracle", ["Shinji Ito"], "http://papers.nips.cc/paper/9378-submodular-function-minimization-with-noisy-evaluation-oracle", 11, "neurips", 2019]], "Matthew Sotoudeh": [0, ["Computing Linear Restrictions of Neural Networks", ["Matthew Sotoudeh", "Aditya V. Thakur"], "http://papers.nips.cc/paper/9562-computing-linear-restrictions-of-neural-networks", 12, "neurips", 2019]], "Chi Han": [0.09675870090723038, ["Visual Concept-Metaconcept Learning", ["Chi Han", "Jiayuan Mao", "Chuang Gan", "Josh Tenenbaum", "Jiajun Wu"], "http://papers.nips.cc/paper/8745-visual-concept-metaconcept-learning", 12, "neurips", 2019]], "Mark Rowland": [0, ["Multiagent Evaluation under Incomplete Information", ["Mark Rowland", "Shayegan Omidshafiei", "Karl Tuyls", "Julien Perolat", "Michal Valko", "Georgios Piliouras", "Remi Munos"], "http://papers.nips.cc/paper/9395-multiagent-evaluation-under-incomplete-information", 13, "neurips", 2019]], "David Widmann": [0, ["Calibration tests in multi-class classification: A unifying framework", ["David Widmann", "Fredrik Lindsten", "Dave Zachariah"], "http://papers.nips.cc/paper/9392-calibration-tests-in-multi-class-classification-a-unifying-framework", 11, "neurips", 2019]], "Syrine Belakaria": [0, ["Max-value Entropy Search for Multi-Objective Bayesian Optimization", ["Syrine Belakaria", "Aryan Deshwal", "Janardhan Rao Doppa"], "http://papers.nips.cc/paper/8997-max-value-entropy-search-for-multi-objective-bayesian-optimization", 11, "neurips", 2019]], "Salvator Lombardo": [0, ["Deep Generative Video Compression", ["Salvator Lombardo", "Jun Han", "Christopher Schroers", "Stephan Mandt"], "http://papers.nips.cc/paper/9127-deep-generative-video-compression", 12, "neurips", 2019]], "Jianhao Peng": [0, ["Online Convex Matrix Factorization with Representative Regions", ["Jianhao Peng", "Olgica Milenkovic", "Abhishek Agarwal"], "http://papers.nips.cc/paper/9480-online-convex-matrix-factorization-with-representative-regions", 11, "neurips", 2019]], "Jian Wu": [0.40413545072078705, ["Practical Two-Step Lookahead Bayesian Optimization", ["Jian Wu", "Peter I. Frazier"], "http://papers.nips.cc/paper/9174-practical-two-step-lookahead-bayesian-optimization", 11, "neurips", 2019]], "Falcon Z. Dai": [0, ["Maximum Expected Hitting Cost of a Markov Decision Process and Informativeness of Rewards", ["Falcon Z. Dai", "Matthew R. Walter"], "http://papers.nips.cc/paper/8984-maximum-expected-hitting-cost-of-a-markov-decision-process-and-informativeness-of-rewards", 9, "neurips", 2019]], "Surbhi Goel": [0, ["Time/Accuracy Tradeoffs for Learning a ReLU with respect to Gaussian Marginals", ["Surbhi Goel", "Sushrut Karmalkar", "Adam R. Klivans"], "http://papers.nips.cc/paper/9064-timeaccuracy-tradeoffs-for-learning-a-relu-with-respect-to-gaussian-marginals", 10, "neurips", 2019]], "Ben Adlam": [0, ["Learning GANs and Ensembles Using Discrepancy", ["Ben Adlam", "Corinna Cortes", "Mehryar Mohri", "Ningshan Zhang"], "http://papers.nips.cc/paper/8815-learning-gans-and-ensembles-using-discrepancy", 12, "neurips", 2019]], "Rafael Muller": [0, ["When does label smoothing help?", ["Rafael Muller", "Simon Kornblith", "Geoffrey E. Hinton"], "http://papers.nips.cc/paper/8717-when-does-label-smoothing-help", 10, "neurips", 2019]], "Aditya Bhaskara": [0, ["On Distributed Averaging for Stochastic k-PCA", ["Aditya Bhaskara", "Maheshakya Wijewardena"], "http://papers.nips.cc/paper/9283-on-distributed-averaging-for-stochastic-k-pca", 10, "neurips", 2019], ["Greedy Sampling for Approximate Clustering in the Presence of Outliers", ["Aditya Bhaskara", "Sharvaree Vadgama", "Hong Xu"], "http://papers.nips.cc/paper/9294-greedy-sampling-for-approximate-clustering-in-the-presence-of-outliers", 10, "neurips", 2019]], "Cheng Tang": [0, ["Exponentially convergent stochastic k-PCA without variance reduction", ["Cheng Tang"], "http://papers.nips.cc/paper/9406-exponentially-convergent-stochastic-k-pca-without-variance-reduction", 12, "neurips", 2019]], "Santiago Paternain": [0, ["Constrained Reinforcement Learning Has Zero Duality Gap", ["Santiago Paternain", "Luiz F. O. Chamon", "Miguel Calvo-Fullana", "Alejandro Ribeiro"], "http://papers.nips.cc/paper/8973-constrained-reinforcement-learning-has-zero-duality-gap", 11, "neurips", 2019]], "Clarice Poon": [0, ["Trajectory of Alternating Direction Method of Multipliers and Adaptive Acceleration", ["Clarice Poon", "Jingwei Liang"], "http://papers.nips.cc/paper/8955-trajectory-of-alternating-direction-method-of-multipliers-and-adaptive-acceleration", 9, "neurips", 2019]], "Yunus Esencayi": [0, ["Facility Location Problem in Differential Privacy Model Revisited", ["Yunus Esencayi", "Marco Gaboardi", "Shi Li", "Di Wang"], "http://papers.nips.cc/paper/9056-facility-location-problem-in-differential-privacy-model-revisited", 10, "neurips", 2019]], "Jaemin Yoo": [0.9150348603725433, ["Knowledge Extraction with No Observable Data", ["Jaemin Yoo", "Minyong Cho", "Taebum Kim", "U Kang"], "http://papers.nips.cc/paper/8538-knowledge-extraction-with-no-observable-data", 10, "neurips", 2019]], "Yikang Li": [0, ["PasteGAN: A Semi-Parametric Method to Generate Image from Scene Graph", ["Yikang Li", "Tao Ma", "Yeqi Bai", "Nan Duan", "Sining Wei", "Xiaogang Wang"], "http://papers.nips.cc/paper/8650-pastegan-a-semi-parametric-method-to-generate-image-from-scene-graph", 11, "neurips", 2019]], "Marco Cuturi": [0, ["Differentiable Ranking and Sorting using Optimal Transport", ["Marco Cuturi", "Olivier Teboul", "Jean-Philippe Vert"], "http://papers.nips.cc/paper/8910-differentiable-ranking-and-sorting-using-optimal-transport", 11, "neurips", 2019]], "Lingxiao Wang": [1.748144636511845e-18, ["Statistical-Computational Tradeoff in Single Index Models", ["Lingxiao Wang", "Zhuoran Yang", "Zhaoran Wang"], "http://papers.nips.cc/paper/9229-statistical-computational-tradeoff-in-single-index-models", 8, "neurips", 2019]], "Ali Shafahi": [0, ["Adversarial training for free!", ["Ali Shafahi", "Mahyar Najibi", "Amin Ghiasi", "Zheng Xu", "John P. Dickerson", "Christoph Studer", "Larry S. Davis", "Gavin Taylor", "Tom Goldstein"], "http://papers.nips.cc/paper/8597-adversarial-training-for-free", 12, "neurips", 2019]], "Yaniv Romano": [0, ["Conformalized Quantile Regression", ["Yaniv Romano", "Evan Patterson", "Emmanuel J. Candes"], "http://papers.nips.cc/paper/8613-conformalized-quantile-regression", 11, "neurips", 2019]], "Siyuan Huang": [0, ["PerspectiveNet: 3D Object Detection from a Single RGB Image via Perspective Points", ["Siyuan Huang", "Yixin Chen", "Tao Yuan", "Siyuan Qi", "Yixin Zhu", "Song-Chun Zhu"], "http://papers.nips.cc/paper/9093-perspectivenet-3d-object-detection-from-a-single-rgb-image-via-perspective-points", 13, "neurips", 2019]], "Eran Malach": [0, ["Is Deeper Better only when Shallow is Good?", ["Eran Malach", "Shai Shalev-Shwartz"], "http://papers.nips.cc/paper/8871-is-deeper-better-only-when-shallow-is-good", 10, "neurips", 2019]], "Yixin Wang": [1.5807447084625892e-06, ["Variational Bayes under Model Misspecification", ["Yixin Wang", "David M. Blei"], "http://papers.nips.cc/paper/9492-variational-bayes-under-model-misspecification", 11, "neurips", 2019]], "Stefano Sarao Mannelli": [0, ["Who is Afraid of Big Bad Minima? Analysis of gradient-flow in spiked matrix-tensor models", ["Stefano Sarao Mannelli", "Giulio Biroli", "Chiara Cammarota", "Florent Krzakala", "Lenka Zdeborova"], "http://papers.nips.cc/paper/9073-who-is-afraid-of-big-bad-minima-analysis-of-gradient-flow-in-spiked-matrix-tensor-models", 11, "neurips", 2019]], "Wenlin Wang": [0.0003638271155068651, ["Improving Textual Network Learning with Variational Homophilic Embeddings", ["Wenlin Wang", "Chenyang Tao", "Zhe Gan", "Guoyin Wang", "Liqun Chen", "Xinyuan Zhang", "Ruiyi Zhang", "Qian Yang", "Ricardo Henao", "Lawrence Carin"], "http://papers.nips.cc/paper/8481-improving-textual-network-learning-with-variational-homophilic-embeddings", 12, "neurips", 2019]], "Hoi-To Wai": [0, ["Variance Reduced Policy Evaluation with Smooth Function Approximation", ["Hoi-To Wai", "Mingyi Hong", "Zhuoran Yang", "Zhaoran Wang", "Kexin Tang"], "http://papers.nips.cc/paper/8814-variance-reduced-policy-evaluation-with-smooth-function-approximation", 12, "neurips", 2019]], "Gunjan Verma": [0, ["Error Correcting Output Codes Improve Probability Estimation and Adversarial Robustness of Deep Neural Networks", ["Gunjan Verma", "Ananthram Swami"], "http://papers.nips.cc/paper/9070-error-correcting-output-codes-improve-probability-estimation-and-adversarial-robustness-of-deep-neural-networks", 11, "neurips", 2019]], "Jean-Bastien Grill": [0, ["Planning in entropy-regularized Markov decision processes and games", ["Jean-Bastien Grill", "Omar Darwiche Domingues", "Pierre Menard", "Remi Munos", "Michal Valko"], "http://papers.nips.cc/paper/9405-planning-in-entropy-regularized-markov-decision-processes-and-games", 10, "neurips", 2019]], "Miaoyan Wang": [1.7366827975706656e-08, ["Multiway clustering via tensor block models", ["Miaoyan Wang", "Yuchen Zeng"], "http://papers.nips.cc/paper/8360-multiway-clustering-via-tensor-block-models", 11, "neurips", 2019]], "Jasper Snoek": [0, ["Can you trust your model's uncertainty? Evaluating predictive uncertainty under dataset shift", ["Jasper Snoek", "Yaniv Ovadia", "Emily Fertig", "Balaji Lakshminarayanan", "Sebastian Nowozin", "D. Sculley", "Joshua V. Dillon", "Jie Ren", "Zachary Nado"], "http://papers.nips.cc/paper/9547-can-you-trust-your-models-uncertainty-evaluating-predictive-uncertainty-under-dataset-shift", 12, "neurips", 2019]], "Atilim Gunes Baydin": [0, ["Efficient Probabilistic Inference in the Quest for Physics Beyond the Standard Model", ["Atilim Gunes Baydin", "Lei Shao", "Wahid Bhimji", "Lukas Heinrich", "Saeid Naderiparizi", "Andreas Munk", "Jialin Liu", "Bradley Gram-Hansen", "Gilles Louppe", "Lawrence Meadows", "Philip H. S. Torr", "Victor W. Lee", "Kyle Cranmer", "Prabhat", "Frank Wood"], "http://papers.nips.cc/paper/8785-efficient-probabilistic-inference-in-the-quest-for-physics-beyond-the-standard-model", 14, "neurips", 2019]], "Vikas K. Garg": [0, ["Online Markov Decoding: Lower Bounds and Near-Optimal Approximation Algorithms", ["Vikas K. Garg", "Tamar Pichkhadze"], "http://papers.nips.cc/paper/8805-online-markov-decoding-lower-bounds-and-near-optimal-approximation-algorithms", 11, "neurips", 2019], ["Solving graph compression via optimal transport", ["Vikas K. Garg", "Tommi S. Jaakkola"], "http://papers.nips.cc/paper/9014-solving-graph-compression-via-optimal-transport", 12, "neurips", 2019]], "Lun Huang": [0, ["Adaptively Aligned Image Captioning via Adaptive Attention Time", ["Lun Huang", "Wenmin Wang", "Yaxian Xia", "Jie Chen"], "http://papers.nips.cc/paper/9096-adaptively-aligned-image-captioning-via-adaptive-attention-time", 10, "neurips", 2019]], "Yue Yu": [0.006344831781461835, ["Double Quantization for Communication-Efficient Distributed Optimization", ["Yue Yu", "Jiaxiang Wu", "Longbo Huang"], "http://papers.nips.cc/paper/8694-double-quantization-for-communication-efficient-distributed-optimization", 12, "neurips", 2019]], "Dan Hendrycks": [0, ["Using Self-Supervised Learning Can Improve Model Robustness and Uncertainty", ["Dan Hendrycks", "Mantas Mazeika", "Saurav Kadavath", "Dawn Song"], "http://papers.nips.cc/paper/9697-using-self-supervised-learning-can-improve-model-robustness-and-uncertainty", 12, "neurips", 2019]], "Peter Anderson": [0, ["Chasing Ghosts: Instruction Following as Bayesian State Tracking", ["Peter Anderson", "Ayush Shrivastava", "Devi Parikh", "Dhruv Batra", "Stefan Lee"], "http://papers.nips.cc/paper/8329-chasing-ghosts-instruction-following-as-bayesian-state-tracking", 11, "neurips", 2019]], "Lars Maaloe": [0, ["BIVA: A Very Deep Hierarchy of Latent Variables for Generative Modeling", ["Lars Maaloe", "Marco Fraccaro", "Valentin Lievin", "Ole Winther"], "http://papers.nips.cc/paper/8882-biva-a-very-deep-hierarchy-of-latent-variables-for-generative-modeling", 11, "neurips", 2019]], "Raanan Y. Yehezkel Rohekar": [0, ["Modeling Uncertainty by Learning a Hierarchy of Deep Neural Connections", ["Raanan Y. Yehezkel Rohekar", "Yaniv Gurwicz", "Shami Nisimov", "Gal Novik"], "http://papers.nips.cc/paper/8677-modeling-uncertainty-by-learning-a-hierarchy-of-deep-neural-connections", 11, "neurips", 2019]], "Mark Bun": [0, ["Private Hypothesis Selection", ["Mark Bun", "Gautam Kamath", "Thomas Steinke", "Steven Z. Wu"], "http://papers.nips.cc/paper/8310-private-hypothesis-selection", 12, "neurips", 2019], ["Average-Case Averages: Private Algorithms for Smooth Sensitivity and Mean Estimation", ["Mark Bun", "Thomas Steinke"], "http://papers.nips.cc/paper/8312-average-case-averages-private-algorithms-for-smooth-sensitivity-and-mean-estimation", 11, "neurips", 2019]], "Bai Li": [0, ["Certified Adversarial Robustness with Additive Noise", ["Bai Li", "Changyou Chen", "Wenlin Wang", "Lawrence Carin"], "http://papers.nips.cc/paper/9143-certified-adversarial-robustness-with-additive-noise", 11, "neurips", 2019]], "Robert Kleinberg": [0, ["Procrastinating with Confidence: Near-Optimal, Anytime, Adaptive Algorithm Configuration", ["Robert Kleinberg", "Kevin Leyton-Brown", "Brendan Lucier", "Devon R. Graham"], "http://papers.nips.cc/paper/9091-procrastinating-with-confidence-near-optimal-anytime-adaptive-algorithm-configuration", 11, "neurips", 2019]], "Seyed Kamyar Seyed Ghasemipour": [0, ["SMILe: Scalable Meta Inverse Reinforcement Learning through Context-Conditional Policies", ["Seyed Kamyar Seyed Ghasemipour", "Shixiang Gu", "Richard S. Zemel"], "http://papers.nips.cc/paper/9002-smile-scalable-meta-inverse-reinforcement-learning-through-context-conditional-policies", 11, "neurips", 2019]], "Fan Zhou": [0, ["Graph-Based Semi-Supervised Learning with Non-ignorable Non-response", ["Fan Zhou", "Tengfei Li", "Haibo Zhou", "Hongtu Zhu", "Jieping Ye"], "http://papers.nips.cc/paper/8924-graph-based-semi-supervised-learning-with-non-ignorable-non-response", 11, "neurips", 2019]], "Colin Wei": [0, ["Regularization Matters: Generalization and Optimization of Neural Nets v.s. their Induced Kernel", ["Colin Wei", "Jason D. Lee", "Qiang Liu", "Tengyu Ma"], "http://papers.nips.cc/paper/9165-regularization-matters-generalization-and-optimization-of-neural-nets-vs-their-induced-kernel", 13, "neurips", 2019], ["Data-dependent Sample Complexity of Deep Neural Networks via Lipschitz Augmentation", ["Colin Wei", "Tengyu Ma"], "http://papers.nips.cc/paper/9166-data-dependent-sample-complexity-of-deep-neural-networks-via-lipschitz-augmentation", 12, "neurips", 2019]], "Jun Shu": [0, ["Meta-Weight-Net: Learning an Explicit Mapping For Sample Weighting", ["Jun Shu", "Qi Xie", "Lixuan Yi", "Qian Zhao", "Sanping Zhou", "Zongben Xu", "Deyu Meng"], "http://papers.nips.cc/paper/8467-meta-weight-net-learning-an-explicit-mapping-for-sample-weighting", 12, "neurips", 2019]], "Tamas Madarasz": [0, ["Better Transfer Learning with Inferred Successor Maps", ["Tamas Madarasz", "Tim E. J. Behrens"], "http://papers.nips.cc/paper/9104-better-transfer-learning-with-inferred-successor-maps", 12, "neurips", 2019]], "Pierre Ablin": [0, ["Learning step sizes for unfolded sparse coding", ["Pierre Ablin", "Thomas Moreau", "Mathurin Massias", "Alexandre Gramfort"], "http://papers.nips.cc/paper/9469-learning-step-sizes-for-unfolded-sparse-coding", 11, "neurips", 2019]], "Yusuke Tanaka": [0, ["Spatially Aggregated Gaussian Processes with Multivariate Areal Outputs", ["Yusuke Tanaka", "Toshiyuki Tanaka", "Tomoharu Iwata", "Takeshi Kurashima", "Maya Okawa", "Yasunori Akagi", "Hiroyuki Toda"], "http://papers.nips.cc/paper/8565-spatially-aggregated-gaussian-processes-with-multivariate-areal-outputs", 11, "neurips", 2019]], "Shuyu Cheng": [0, ["Improving Black-box Adversarial Attacks with a Transfer-based Prior", ["Shuyu Cheng", "Yinpeng Dong", "Tianyu Pang", "Hang Su", "Jun Zhu"], "http://papers.nips.cc/paper/9275-improving-black-box-adversarial-attacks-with-a-transfer-based-prior", 11, "neurips", 2019]], "Carlo Ciliberto": [0, ["Localized Structured Prediction", ["Carlo Ciliberto", "Francis Bach", "Alessandro Rudi"], "http://papers.nips.cc/paper/8950-localized-structured-prediction", 11, "neurips", 2019]], "Yi Chern Tan": [0, ["Assessing Social and Intersectional Biases in Contextualized Word Representations", ["Yi Chern Tan", "L. Elisa Celis"], "http://papers.nips.cc/paper/9479-assessing-social-and-intersectional-biases-in-contextualized-word-representations", 12, "neurips", 2019]], "Iryna Korshunova": [0, ["Discriminative Topic Modeling with Logistic LDA", ["Iryna Korshunova", "Hanchen Xiong", "Mateusz Fedoryszak", "Lucas Theis"], "http://papers.nips.cc/paper/8902-discriminative-topic-modeling-with-logistic-lda", 11, "neurips", 2019]], "Fariborz Salehi": [0, ["The Impact of Regularization on High-dimensional Logistic Regression", ["Fariborz Salehi", "Ehsan Abbasi", "Babak Hassibi"], "http://papers.nips.cc/paper/9369-the-impact-of-regularization-on-high-dimensional-logistic-regression", 11, "neurips", 2019]], "Ryan J. Tibshirani": [0, ["Conformal Prediction Under Covariate Shift", ["Ryan J. Tibshirani", "Rina Foygel Barber", "Emmanuel J. Candes", "Aaditya Ramdas"], "http://papers.nips.cc/paper/8522-conformal-prediction-under-covariate-shift", 11, "neurips", 2019]], "Ben Deverett": [0, ["Interval timing in deep reinforcement learning agents", ["Ben Deverett", "Ryan Faulkner", "Meire Fortunato", "Gregory Wayne", "Joel Z. Leibo"], "http://papers.nips.cc/paper/8894-interval-timing-in-deep-reinforcement-learning-agents", 10, "neurips", 2019]], "Se-Young Yun": [0.999286487698555, ["Optimal Sampling and Clustering in the Stochastic Block Model", ["Se-Young Yun", "Alexandre Proutiere"], "http://papers.nips.cc/paper/9498-optimal-sampling-and-clustering-in-the-stochastic-block-model", 9, "neurips", 2019]], "Dan Schwartz": [0, ["Inducing brain-relevant bias in natural language processing models", ["Dan Schwartz", "Mariya Toneva", "Leila Wehbe"], "http://papers.nips.cc/paper/9559-inducing-brain-relevant-bias-in-natural-language-processing-models", 11, "neurips", 2019]], "Georgios Detorakis": [0, ["Inherent Weight Normalization in Stochastic Neural Networks", ["Georgios Detorakis", "Sourav Dutta", "Abhishek Khanna", "Matthew Jerry", "Suman Datta", "Emre Neftci"], "http://papers.nips.cc/paper/8591-inherent-weight-normalization-in-stochastic-neural-networks", 12, "neurips", 2019]], "Chunjin Song": [0.5, ["ETNet: Error Transition Network for Arbitrary Style Transfer", ["Chunjin Song", "Zhijie Wu", "Yang Zhou", "Minglun Gong", "Hui Huang"], "http://papers.nips.cc/paper/8356-etnet-error-transition-network-for-arbitrary-style-transfer", 10, "neurips", 2019]], "Yue Wang": [0.006344831781461835, ["E2-Train: Training State-of-the-art CNNs with Over 80% Energy Savings", ["Yue Wang", "Ziyu Jiang", "Xiaohan Chen", "Pengfei Xu", "Yang Zhao", "Yingyan Lin", "Zhangyang Wang"], "http://papers.nips.cc/paper/8757-e2-train-training-state-of-the-art-cnns-with-over-80-energy-savings", 13, "neurips", 2019], ["PRNet: Self-Supervised Learning for Partial-to-Partial Registration", ["Yue Wang", "Justin M. Solomon"], "http://papers.nips.cc/paper/9085-prnet-self-supervised-learning-for-partial-to-partial-registration", 13, "neurips", 2019]], "Edgar Dobriban": [0, ["Asymptotics for Sketching in Least Squares Regression", ["Edgar Dobriban", "Sifan Liu"], "http://papers.nips.cc/paper/8625-asymptotics-for-sketching-in-least-squares-regression", 11, "neurips", 2019]], "Mohamed Akrout": [0, ["Deep Learning without Weight Transport", ["Mohamed Akrout", "Collin Wilson", "Peter C. Humphreys", "Timothy P. Lillicrap", "Douglas B. Tweed"], "http://papers.nips.cc/paper/8383-deep-learning-without-weight-transport", 9, "neurips", 2019]], "Jonathan Kuck": [0, ["Approximating the Permanent by Sampling from Adaptive Partitions", ["Jonathan Kuck", "Tri Dao", "Hamid Rezatofighi", "Ashish Sabharwal", "Stefano Ermon"], "http://papers.nips.cc/paper/9089-approximating-the-permanent-by-sampling-from-adaptive-partitions", 12, "neurips", 2019]], "Carl Yang": [1.5476401826752806e-09, ["Conditional Structure Generation through Graph Variational Generative Adversarial Nets", ["Carl Yang", "Peiye Zhuang", "Wenhan Shi", "Alan Luu", "Pan Li"], "http://papers.nips.cc/paper/8415-conditional-structure-generation-through-graph-variational-generative-adversarial-nets", 12, "neurips", 2019]], "Paul K. Rubenstein": [0, ["Practical and Consistent Estimation of f-Divergences", ["Paul K. Rubenstein", "Olivier Bousquet", "Josip Djolonga", "Carlos Riquelme", "Ilya O. Tolstikhin"], "http://papers.nips.cc/paper/8661-practical-and-consistent-estimation-of-f-divergences", 11, "neurips", 2019]], "Cheng Fu": [0, ["Coda: An End-to-End Neural Program Decompiler", ["Cheng Fu", "Huili Chen", "Haolan Liu", "Xinyun Chen", "Yuandong Tian", "Farinaz Koushanfar", "Jishen Zhao"], "http://papers.nips.cc/paper/8628-coda-an-end-to-end-neural-program-decompiler", 12, "neurips", 2019]], "Jiaxuan You": [0, ["G2SAT: Learning to Generate SAT Formulas", ["Jiaxuan You", "Haoze Wu", "Clark W. Barrett", "Raghuram Ramanujan", "Jure Leskovec"], "http://papers.nips.cc/paper/9241-g2sat-learning-to-generate-sat-formulas", 12, "neurips", 2019]], "Sara Hooker": [0, ["A Benchmark for Interpretability Methods in Deep Neural Networks", ["Sara Hooker", "Dumitru Erhan", "Pieter-Jan Kindermans", "Been Kim"], "http://papers.nips.cc/paper/9167-a-benchmark-for-interpretability-methods-in-deep-neural-networks", 12, "neurips", 2019]], "Hadrien Hendrikx": [0, ["An Accelerated Decentralized Stochastic Proximal Algorithm for Finite Sums", ["Hadrien Hendrikx", "Francis Bach", "Laurent Massoulie"], "http://papers.nips.cc/paper/8381-an-accelerated-decentralized-stochastic-proximal-algorithm-for-finite-sums", 11, "neurips", 2019]], "Sobhan Miryoosefi": [0, ["Reinforcement Learning with Convex Constraints", ["Sobhan Miryoosefi", "Kiante Brantley", "Hal Daume III", "Miroslav Dudik", "Robert E. Schapire"], "http://papers.nips.cc/paper/9556-reinforcement-learning-with-convex-constraints", 10, "neurips", 2019]], "Dexiong Chen": [0, ["Recurrent Kernel Networks", ["Dexiong Chen", "Laurent Jacob", "Julien Mairal"], "http://papers.nips.cc/paper/9499-recurrent-kernel-networks", 12, "neurips", 2019]], "Xiaoyi Gu": [2.5983750063683295e-13, ["Statistical Analysis of Nearest Neighbor Methods for Anomaly Detection", ["Xiaoyi Gu", "Leman Akoglu", "Alessandro Rinaldo"], "http://papers.nips.cc/paper/9274-statistical-analysis-of-nearest-neighbor-methods-for-anomaly-detection", 11, "neurips", 2019]], "Dong Yin": [0, ["A Fourier Perspective on Model Robustness in Computer Vision", ["Dong Yin", "Raphael Gontijo Lopes", "Jon Shlens", "Ekin Dogus Cubuk", "Justin Gilmer"], "http://papers.nips.cc/paper/9483-a-fourier-perspective-on-model-robustness-in-computer-vision", 11, "neurips", 2019]], "Alban Laflaquiere": [0, ["Unsupervised Emergence of Egocentric Spatial Structure from Sensorimotor Prediction", ["Alban Laflaquiere", "Michael Garcia Ortiz"], "http://papers.nips.cc/paper/8937-unsupervised-emergence-of-egocentric-spatial-structure-from-sensorimotor-prediction", 11, "neurips", 2019]], "Joshua Lee": [4.035794485060529e-12, ["Learning New Tricks From Old Dogs: Multi-Source Transfer Learning From Pre-Trained Networks", ["Joshua Lee", "Prasanna Sattigeri", "Gregory W. Wornell"], "http://papers.nips.cc/paper/8688-learning-new-tricks-from-old-dogs-multi-source-transfer-learning-from-pre-trained-networks", 11, "neurips", 2019]], "Mohammad Sadegh Talebi": [0, ["Learning Multiple Markov Chains via Adaptive Allocation", ["Mohammad Sadegh Talebi", "Odalric-Ambrym Maillard"], "http://papers.nips.cc/paper/9489-learning-multiple-markov-chains-via-adaptive-allocation", 11, "neurips", 2019]], "Stanislav Fort": [0, ["Large Scale Structure of Neural Network Loss Landscapes", ["Stanislav Fort", "Stanislaw Jastrzebski"], "http://papers.nips.cc/paper/8896-large-scale-structure-of-neural-network-loss-landscapes", 9, "neurips", 2019]], "Fabio Vitale": [0, ["Flattening a Hierarchical Clustering through Active Learning", ["Fabio Vitale", "Anand Rajagopalan", "Claudio Gentile"], "http://papers.nips.cc/paper/9664-flattening-a-hierarchical-clustering-through-active-learning", 11, "neurips", 2019]], "Ziyu Wan": [0, ["Transductive Zero-Shot Learning with Visual Structure Constraint", ["Ziyu Wan", "Dongdong Chen", "Yan Li", "Xingguang Yan", "Junge Zhang", "Yizhou Yu", "Jing Liao"], "http://papers.nips.cc/paper/9188-transductive-zero-shot-learning-with-visual-structure-constraint", 11, "neurips", 2019]], "Sherjil Ozair": [0, ["Wasserstein Dependency Measure for Representation Learning", ["Sherjil Ozair", "Corey Lynch", "Yoshua Bengio", "Aaron van den Oord", "Sergey Levine", "Pierre Sermanet"], "http://papers.nips.cc/paper/9692-wasserstein-dependency-measure-for-representation-learning", 11, "neurips", 2019]], "Ho Chung Leon Law": [0, ["Hyperparameter Learning via Distributional Transfer", ["Ho Chung Leon Law", "Peilin Zhao", "Leung Sing Chan", "Junzhou Huang", "Dino Sejdinovic"], "http://papers.nips.cc/paper/8905-hyperparameter-learning-via-distributional-transfer", 12, "neurips", 2019]], "Rachel Carrington": [0, ["Invariance and identifiability issues for word embeddings", ["Rachel Carrington", "Karthik Bharath", "Simon Preston"], "http://papers.nips.cc/paper/9650-invariance-and-identifiability-issues-for-word-embeddings", 10, "neurips", 2019]], "Robin Sandkuhler": [0, ["Recurrent Registration Neural Networks for Deformable Image Registration", ["Robin Sandkuhler", "Simon Andermatt", "Grzegorz Bauman", "Sylvia Nyilas", "Christoph Jud", "Philippe C. Cattin"], "http://papers.nips.cc/paper/9080-recurrent-registration-neural-networks-for-deformable-image-registration", 11, "neurips", 2019]], "Ayan Chakrabarti": [0, ["Backprop with Approximate Activations for Memory-efficient Network Training", ["Ayan Chakrabarti", "Benjamin Moseley"], "http://papers.nips.cc/paper/8513-backprop-with-approximate-activations-for-memory-efficient-network-training", 10, "neurips", 2019]], "Joshua Robinson": [0, ["Flexible Modeling of Diversity with Strongly Log-Concave Distributions", ["Joshua Robinson", "Suvrit Sra", "Stefanie Jegelka"], "http://papers.nips.cc/paper/9658-flexible-modeling-of-diversity-with-strongly-log-concave-distributions", 11, "neurips", 2019]], "Johannes Kirschner": [0, ["Stochastic Bandits with Context Distributions", ["Johannes Kirschner", "Andreas Krause"], "http://papers.nips.cc/paper/9558-stochastic-bandits-with-context-distributions", 10, "neurips", 2019]], "Marco Loog": [0, ["Minimizers of the Empirical Risk and Risk Monotonicity", ["Marco Loog", "Tom J. Viering", "Alexander Mey"], "http://papers.nips.cc/paper/8966-minimizers-of-the-empirical-risk-and-risk-monotonicity", 10, "neurips", 2019]], "David Simchi-Levi": [0, ["Phase Transitions and Cyclic Phenomena in Bandits with Switching Constraints", ["David Simchi-Levi", "Yunzong Xu"], "http://papers.nips.cc/paper/8970-phase-transitions-and-cyclic-phenomena-in-bandits-with-switching-constraints", 10, "neurips", 2019]], "Ciara Pike-Burke": [0, ["Recovering Bandits", ["Ciara Pike-Burke", "Steffen Grunewalder"], "http://papers.nips.cc/paper/9561-recovering-bandits", 10, "neurips", 2019]], "Rohan Anil": [0, ["Memory Efficient Adaptive Optimization", ["Rohan Anil", "Vineet Gupta", "Tomer Koren", "Yoram Singer"], "http://papers.nips.cc/paper/9168-memory-efficient-adaptive-optimization", 10, "neurips", 2019]], "Hsin-Ying Lee": [6.763984705671078e-09, ["Dancing to Music", ["Hsin-Ying Lee", "Xiaodong Yang", "Ming-Yu Liu", "Ting-Chun Wang", "Yu-Ding Lu", "Ming-Hsuan Yang", "Jan Kautz"], "http://papers.nips.cc/paper/8617-dancing-to-music", 11, "neurips", 2019]], "Wenbo Ren": [0, ["On Sample Complexity Upper and Lower Bounds for Exact Ranking from Noisy Comparisons", ["Wenbo Ren", "Jia Liu", "Ness B. Shroff"], "http://papers.nips.cc/paper/9192-on-sample-complexity-upper-and-lower-bounds-for-exact-ranking-from-noisy-comparisons", 11, "neurips", 2019]], "Michael Janner": [0, ["When to Trust Your Model: Model-Based Policy Optimization", ["Michael Janner", "Justin Fu", "Marvin Zhang", "Sergey Levine"], "http://papers.nips.cc/paper/9416-when-to-trust-your-model-model-based-policy-optimization", 12, "neurips", 2019]], "Akshay Agrawal": [0, ["Differentiable Convex Optimization Layers", ["Akshay Agrawal", "Brandon Amos", "Shane T. Barratt", "Stephen P. Boyd", "Steven Diamond", "J. Zico Kolter"], "http://papers.nips.cc/paper/9152-differentiable-convex-optimization-layers", 13, "neurips", 2019]], "Sebastian Goldt": [0, ["Dynamics of stochastic gradient descent for two-layer neural networks in the teacher-student setup", ["Sebastian Goldt", "Madhu Advani", "Andrew M. Saxe", "Florent Krzakala", "Lenka Zdeborova"], "http://papers.nips.cc/paper/8921-dynamics-of-stochastic-gradient-descent-for-two-layer-neural-networks-in-the-teacher-student-setup", 11, "neurips", 2019]], "David G. Clark": [0, ["Unsupervised Discovery of Temporal Structure in Noisy Data with Dynamical Components Analysis", ["David G. Clark", "Jesse Livezey", "Kristofer E. Bouchard"], "http://papers.nips.cc/paper/9574-unsupervised-discovery-of-temporal-structure-in-noisy-data-with-dynamical-components-analysis", 12, "neurips", 2019]], "Cheng-Chun Hsu": [0, ["Weakly Supervised Instance Segmentation using the Bounding Box Tightness Prior", ["Cheng-Chun Hsu", "Kuang-Jui Hsu", "Chung-Chi Tsai", "Yen-Yu Lin", "Yung-Yu Chuang"], "http://papers.nips.cc/paper/8885-weakly-supervised-instance-segmentation-using-the-bounding-box-tightness-prior", 12, "neurips", 2019]], "Charles T. Marx": [0, ["Disentangling Influence: Using disentangled representations to audit model predictions", ["Charles T. Marx", "Richard L. Phillips", "Sorelle A. Friedler", "Carlos Scheidegger", "Suresh Venkatasubramanian"], "http://papers.nips.cc/paper/8699-disentangling-influence-using-disentangled-representations-to-audit-model-predictions", 11, "neurips", 2019]], "Qian Lou": [0, ["SHE: A Fast and Accurate Deep Neural Network for Encrypted Data", ["Qian Lou", "Lei Jiang"], "http://papers.nips.cc/paper/9194-she-a-fast-and-accurate-deep-neural-network-for-encrypted-data", 9, "neurips", 2019]], "Chuan Guo": [0, ["Breaking the Glass Ceiling for Embedding-Based Classifiers for Large Output Spaces", ["Chuan Guo", "Ali Mousavi", "Xiang Wu", "Daniel Niels Holtmann-Rice", "Satyen Kale", "Sashank J. Reddi", "Sanjiv Kumar"], "http://papers.nips.cc/paper/8740-breaking-the-glass-ceiling-for-embedding-based-classifiers-for-large-output-spaces", 11, "neurips", 2019]], "Jonathan Lacotte": [0, ["High-Dimensional Optimization in Adaptive Random Subspaces", ["Jonathan Lacotte", "Mert Pilanci", "Marco Pavone"], "http://papers.nips.cc/paper/9267-high-dimensional-optimization-in-adaptive-random-subspaces", 11, "neurips", 2019]], "Himanshu Sahni": [0, ["Addressing Sample Complexity in Visual Tasks Using HER and Hallucinatory GANs", ["Himanshu Sahni", "Toby Buckley", "Pieter Abbeel", "Ilya Kuzovkin"], "http://papers.nips.cc/paper/8818-addressing-sample-complexity-in-visual-tasks-using-her-and-hallucinatory-gans", 11, "neurips", 2019]], "Amanda Gentzel": [0, ["The Case for Evaluating Causal Models Using Interventional Measures and Empirical Data", ["Amanda Gentzel", "Dan Garant", "David Jensen"], "http://papers.nips.cc/paper/9345-the-case-for-evaluating-causal-models-using-interventional-measures-and-empirical-data", 11, "neurips", 2019]], "Amirhossein Reisizadeh": [0, ["Robust and Communication-Efficient Collaborative Learning", ["Amirhossein Reisizadeh", "Hossein Taheri", "Aryan Mokhtari", "Hamed Hassani", "Ramtin Pedarsani"], "http://papers.nips.cc/paper/9047-robust-and-communication-efficient-collaborative-learning", 12, "neurips", 2019]], "Rishidev Chaudhuri": [0, ["Bipartite expander Hopfield networks as self-decoding high-capacity error correcting codes", ["Rishidev Chaudhuri", "Ila Fiete"], "http://papers.nips.cc/paper/8985-bipartite-expander-hopfield-networks-as-self-decoding-high-capacity-error-correcting-codes", 12, "neurips", 2019]], "Gaurush Hiranandani": [0, ["Multiclass Performance Metric Elicitation", ["Gaurush Hiranandani", "Shant Boodaghians", "Ruta Mehta", "Oluwasanmi Koyejo"], "http://papers.nips.cc/paper/9133-multiclass-performance-metric-elicitation", 10, "neurips", 2019]], "Maxim Kuznetsov": [0, ["A Prior of a Googol Gaussians: a Tensor Ring Induced Prior for Generative Models", ["Maxim Kuznetsov", "Daniil Polykovskiy", "Dmitry P. Vetrov", "Alexander Zhebrak"], "http://papers.nips.cc/paper/8664-a-prior-of-a-googol-gaussians-a-tensor-ring-induced-prior-for-generative-models", 11, "neurips", 2019]], "Edward De Brouwer": [0, ["GRU-ODE-Bayes: Continuous Modeling of Sporadically-Observed Time Series", ["Edward De Brouwer", "Jaak Simm", "Adam Arany", "Yves Moreau"], "http://papers.nips.cc/paper/8957-gru-ode-bayes-continuous-modeling-of-sporadically-observed-time-series", 12, "neurips", 2019]], "Jisoo Jeong": [0.9683181047439575, ["Consistency-based Semi-supervised Learning for Object detection", ["Jisoo Jeong", "Seungeui Lee", "Jeesoo Kim", "Nojun Kwak"], "http://papers.nips.cc/paper/9259-consistency-based-semi-supervised-learning-for-object-detection", 10, "neurips", 2019]], "Jingbo Liu": [0, ["Power analysis of knockoff filters for correlated designs", ["Jingbo Liu", "Philippe Rigollet"], "http://papers.nips.cc/paper/9678-power-analysis-of-knockoff-filters-for-correlated-designs", 10, "neurips", 2019]], "Alexander Irpan": [0, ["Off-Policy Evaluation via Off-Policy Classification", ["Alexander Irpan", "Kanishka Rao", "Konstantinos Bousmalis", "Chris Harris", "Julian Ibarz", "Sergey Levine"], "http://papers.nips.cc/paper/8783-off-policy-evaluation-via-off-policy-classification", 12, "neurips", 2019]], "Zengfeng Huang": [0, ["Optimal Sparsity-Sensitive Bounds for Distributed Mean Estimation", ["Zengfeng Huang", "Ziyue Huang", "Yilei Wang", "Ke Yi"], "http://papers.nips.cc/paper/8866-optimal-sparsity-sensitive-bounds-for-distributed-mean-estimation", 11, "neurips", 2019]], "Jiabin Liu": [0, ["Learning from Label Proportions with Generative Adversarial Networks", ["Jiabin Liu", "Bo Wang", "Zhiquan Qi", "Yingjie Tian", "Yong Shi"], "http://papers.nips.cc/paper/8938-learning-from-label-proportions-with-generative-adversarial-networks", 11, "neurips", 2019]], "Gedas Bertasius": [0, ["Learning Temporal Pose Estimation from Sparsely-Labeled Videos", ["Gedas Bertasius", "Christoph Feichtenhofer", "Du Tran", "Jianbo Shi", "Lorenzo Torresani"], "http://papers.nips.cc/paper/8567-learning-temporal-pose-estimation-from-sparsely-labeled-videos", 12, "neurips", 2019]], "Gauri Jagatap": [0, ["Algorithmic Guarantees for Inverse Imaging with Untrained Network Priors", ["Gauri Jagatap", "Chinmay Hegde"], "http://papers.nips.cc/paper/9622-algorithmic-guarantees-for-inverse-imaging-with-untrained-network-priors", 11, "neurips", 2019]], "Bryon Aragam": [0, ["Globally optimal score-based learning of directed acyclic graphs in high-dimensions", ["Bryon Aragam", "Arash A. Amini", "Qing Zhou"], "http://papers.nips.cc/paper/8695-globally-optimal-score-based-learning-of-directed-acyclic-graphs-in-high-dimensions", 13, "neurips", 2019]], "Xiao Sun": [4.1873883560583636e-07, ["Hybrid 8-bit Floating Point (HFP8) Training and Inference for Deep Neural Networks", ["Xiao Sun", "Jungwook Choi", "Chia-Yu Chen", "Naigang Wang", "Swagath Venkataramani", "Vijayalakshmi Srinivasan", "Xiaodong Cui", "Wei Zhang", "Kailash Gopalakrishnan"], "http://papers.nips.cc/paper/8736-hybrid-8-bit-floating-point-hfp8-training-and-inference-for-deep-neural-networks", 10, "neurips", 2019]], "Cory Stephenson": [0, ["Untangling in Invariant Speech Recognition", ["Cory Stephenson", "Jenelle Feather", "Suchismita Padhy", "Oguz H. Elibol", "Hanlin Tang", "Josh McDermott", "SueYeon Chung"], "http://papers.nips.cc/paper/9583-untangling-in-invariant-speech-recognition", 11, "neurips", 2019]], "Michael Arbel": [0, ["Maximum Mean Discrepancy Gradient Flow", ["Michael Arbel", "Anna Korba", "Adil Salim", "Arthur Gretton"], "http://papers.nips.cc/paper/8876-maximum-mean-discrepancy-gradient-flow", 11, "neurips", 2019]], "Andy Shih": [0, ["Smoothing Structured Decomposable Circuits", ["Andy Shih", "Guy Van den Broeck", "Paul Beame", "Antoine Amarilli"], "http://papers.nips.cc/paper/9318-smoothing-structured-decomposable-circuits", 11, "neurips", 2019]], "Vaishak Belle": [0, ["Implicitly learning to reason in first-order logic", ["Vaishak Belle", "Brendan Juba"], "http://papers.nips.cc/paper/8599-implicitly-learning-to-reason-in-first-order-logic", 11, "neurips", 2019]], "Yoav Wald": [0, ["Globally Optimal Learning for Structured Elliptical Losses", ["Yoav Wald", "Nofar Noy", "Gal Elidan", "Ami Wiesel"], "http://papers.nips.cc/paper/9504-globally-optimal-learning-for-structured-elliptical-losses", 10, "neurips", 2019]], "Frederic Koehler": [0, ["Fast Convergence of Belief Propagation to Global Optima: Beyond Correlation Decay", ["Frederic Koehler"], "http://papers.nips.cc/paper/9042-fast-convergence-of-belief-propagation-to-global-optima-beyond-correlation-decay", 11, "neurips", 2019]], "Maxence Ernoult": [0, ["Updates of Equilibrium Prop Match Gradients of Backprop Through Time in an RNN with Static Input", ["Maxence Ernoult", "Julie Grollier", "Damien Querlioz", "Yoshua Bengio", "Benjamin Scellier"], "http://papers.nips.cc/paper/8930-updates-of-equilibrium-prop-match-gradients-of-backprop-through-time-in-an-rnn-with-static-input", 11, "neurips", 2019]], "Hongjoon Ahn": [0.9935195595026016, ["Uncertainty-based Continual Learning with Adaptive Regularization", ["Hongjoon Ahn", "Sungmin Cha", "Donggyu Lee", "Taesup Moon"], "http://papers.nips.cc/paper/8690-uncertainty-based-continual-learning-with-adaptive-regularization", 11, "neurips", 2019]], "Sariel Har-Peled": [0, ["Near Neighbor: Who is the Fairest of Them All?", ["Sariel Har-Peled", "Sepideh Mahabadi"], "http://papers.nips.cc/paper/9476-near-neighbor-who-is-the-fairest-of-them-all", 12, "neurips", 2019]], "Ravi Kumar": [0, ["Efficient Rematerialization for Deep Networks", ["Ravi Kumar", "Manish Purohit", "Zoya Svitkina", "Erik Vee", "Joshua Wang"], "http://papers.nips.cc/paper/9653-efficient-rematerialization-for-deep-networks", 10, "neurips", 2019]], "Jonathan Ullman": [0, ["Efficiently Estimating Erdos-Renyi Graphs with Node Differential Privacy", ["Jonathan Ullman", "Adam Sealfon"], "http://papers.nips.cc/paper/8633-efficiently-estimating-erdos-renyi-graphs-with-node-differential-privacy", 11, "neurips", 2019]], "Kanthi K. Sarpatwar": [0, ["Differentially Private Distributed Data Summarization under Covariate Shift", ["Kanthi K. Sarpatwar", "Karthikeyan Shanmugam", "Venkata Sitaramagiridharganesh Ganapavarapu", "Ashish Jagmohan", "Roman Vaculin"], "http://papers.nips.cc/paper/9589-differentially-private-distributed-data-summarization-under-covariate-shift", 11, "neurips", 2019]], "Runzhe Yang": [3.9573993149133457e-07, ["A Generalized Algorithm for Multi-Objective Reinforcement Learning and Policy Adaptation", ["Runzhe Yang", "Xingyuan Sun", "Karthik Narasimhan"], "http://papers.nips.cc/paper/9605-a-generalized-algorithm-for-multi-objective-reinforcement-learning-and-policy-adaptation", 12, "neurips", 2019]], "Chris Russell": [0, ["Fixing Implicit Derivatives: Trust-Region Based Learning of Continuous Energy Functions", ["Chris Russell", "Matteo Toso", "Neill D. F. Campbell"], "http://papers.nips.cc/paper/8427-fixing-implicit-derivatives-trust-region-based-learning-of-continuous-energy-functions", 11, "neurips", 2019]], "Nima Hamidi": [0, ["Personalizing Many Decisions with High-Dimensional Covariates", ["Nima Hamidi", "Mohsen Bayati", "Kapil Gupta"], "http://papers.nips.cc/paper/9323-personalizing-many-decisions-with-high-dimensional-covariates", 12, "neurips", 2019]], "Gael Letarte": [0, ["Dichotomize and Generalize: PAC-Bayesian Binary Activated Deep Neural Networks", ["Gael Letarte", "Pascal Germain", "Benjamin Guedj", "Francois Laviolette"], "http://papers.nips.cc/paper/8911-dichotomize-and-generalize-pac-bayesian-binary-activated-deep-neural-networks", 11, "neurips", 2019]], "Rixon Crane": [0, ["DINGO: Distributed Newton-Type Method for Gradient-Norm Optimization", ["Rixon Crane", "Fred Roosta"], "http://papers.nips.cc/paper/9146-dingo-distributed-newton-type-method-for-gradient-norm-optimization", 11, "neurips", 2019]], "Farnood Salehi": [0, ["Learning Hawkes Processes from a handful of events", ["Farnood Salehi", "William Trouleau", "Matthias Grossglauser", "Patrick Thiran"], "http://papers.nips.cc/paper/9433-learning-hawkes-processes-from-a-handful-of-events", 11, "neurips", 2019]], "Kevin J. Liang": [0, ["Kernel-Based Approaches for Sequence Modeling: Connections to Neural Methods", ["Kevin J. Liang", "Guoyin Wang", "Yitong Li", "Ricardo Henao", "Lawrence Carin"], "http://papers.nips.cc/paper/8600-kernel-based-approaches-for-sequence-modeling-connections-to-neural-methods", 12, "neurips", 2019]], "Nishal P. Shah": [0, ["Efficient characterization of electrically evoked responses for neural interfaces", ["Nishal P. Shah", "Sasidhar Madugula", "Pawel Hottowy", "Alexander Sher", "Alan M. Litke", "Liam Paninski", "E. J. Chichilnisky"], "http://papers.nips.cc/paper/9588-efficient-characterization-of-electrically-evoked-responses-for-neural-interfaces", 11, "neurips", 2019]], "Bertrand Charpentier": [0, ["Uncertainty on Asynchronous Time Event Prediction", ["Bertrand Charpentier", "Marin Bilos", "Stephan Gunnemann"], "http://papers.nips.cc/paper/9445-uncertainty-on-asynchronous-time-event-prediction", 10, "neurips", 2019]], "Theo Ryffel": [0, ["Partially Encrypted Deep Learning using Functional Encryption", ["Theo Ryffel", "David Pointcheval", "Francis Bach", "Edouard Dufour-Sans", "Romain Gay"], "http://papers.nips.cc/paper/8701-partially-encrypted-deep-learning-using-functional-encryption", 12, "neurips", 2019]], "Anish Agarwal": [0, ["On Robustness of Principal Component Regression", ["Anish Agarwal", "Devavrat Shah", "Dennis Shen", "Dogyoon Song"], "http://papers.nips.cc/paper/9181-on-robustness-of-principal-component-regression", 12, "neurips", 2019]], "Leonidas J. Guibas": [0, ["A Condition Number for Joint Optimization of Cycle-Consistent Networks", ["Leonidas J. Guibas", "Qixing Huang", "Zhenxiao Liang"], "http://papers.nips.cc/paper/8386-a-condition-number-for-joint-optimization-of-cycle-consistent-networks", 11, "neurips", 2019]], "Alon Gonen": [0, ["Private Learning Implies Online Learning: An Efficient Reduction", ["Alon Gonen", "Elad Hazan", "Shay Moran"], "http://papers.nips.cc/paper/9075-private-learning-implies-online-learning-an-efficient-reduction", 11, "neurips", 2019]], "Viet Anh Nguyen": [0, ["Calculating Optimistic Likelihoods Using (Geodesically) Convex Optimization", ["Viet Anh Nguyen", "Soroosh Shafieezadeh-Abadeh", "Man-Chung Yue", "Daniel Kuhn", "Wolfram Wiesemann"], "http://papers.nips.cc/paper/9543-calculating-optimistic-likelihoods-using-geodesically-convex-optimization", 12, "neurips", 2019], ["Optimistic Distributionally Robust Optimization for Nonparametric Likelihood Approximation", ["Viet Anh Nguyen", "Soroosh Shafieezadeh-Abadeh", "Man-Chung Yue", "Daniel Kuhn", "Wolfram Wiesemann"], "http://papers.nips.cc/paper/9716-optimistic-distributionally-robust-optimization-for-nonparametric-likelihood-approximation", 11, "neurips", 2019]], "Christopher Nemeth": [0, ["Pseudo-Extended Markov chain Monte Carlo", ["Christopher Nemeth", "Fredrik Lindsten", "Maurizio Filippone", "James Hensman"], "http://papers.nips.cc/paper/8683-pseudo-extended-markov-chain-monte-carlo", 11, "neurips", 2019]], "Roman Werpachowski": [0, ["Detecting Overfitting via Adversarial Examples", ["Roman Werpachowski", "Andras Gyorgy", "Csaba Szepesvari"], "http://papers.nips.cc/paper/9000-detecting-overfitting-via-adversarial-examples", 11, "neurips", 2019]], "Tianyuan Jin": [1.264607559295361e-11, ["Efficient Pure Exploration in Adaptive Round model", ["Tianyuan Jin", "Jieming Shi", "Xiaokui Xiao", "Enhong Chen"], "http://papers.nips.cc/paper/8887-efficient-pure-exploration-in-adaptive-round-model", 10, "neurips", 2019]], "Gi-Soo Kim": [0.9990328848361969, ["Doubly-Robust Lasso Bandit", ["Gi-Soo Kim", "Myunghee Cho Paik"], "http://papers.nips.cc/paper/8822-doubly-robust-lasso-bandit", 11, "neurips", 2019]], "Shuo Chen": [0, ["Curvilinear Distance Metric Learning", ["Shuo Chen", "Lei Luo", "Jian Yang", "Chen Gong", "Jun Li", "Heng Huang"], "http://papers.nips.cc/paper/8675-curvilinear-distance-metric-learning", 10, "neurips", 2019]], "Tristan Milne": [0, ["Piecewise Strong Convexity of Neural Networks", ["Tristan Milne"], "http://papers.nips.cc/paper/9456-piecewise-strong-convexity-of-neural-networks", 11, "neurips", 2019]], "Chengzhi Mao": [0, ["Metric Learning for Adversarial Robustness", ["Chengzhi Mao", "Ziyuan Zhong", "Junfeng Yang", "Carl Vondrick", "Baishakhi Ray"], "http://papers.nips.cc/paper/8339-metric-learning-for-adversarial-robustness", 12, "neurips", 2019]], "Raef Bassily": [0, ["Limits of Private Learning with Access to Public Data", ["Raef Bassily", "Shay Moran", "Noga Alon"], "http://papers.nips.cc/paper/9222-limits-of-private-learning-with-access-to-public-data", 11, "neurips", 2019], ["Private Stochastic Convex Optimization with Optimal Rates", ["Raef Bassily", "Vitaly Feldman", "Kunal Talwar", "Abhradeep Guha Thakurta"], "http://papers.nips.cc/paper/9306-private-stochastic-convex-optimization-with-optimal-rates", 10, "neurips", 2019]], "Jun Yang": [0.07243982143700123, ["Fast-rate PAC-Bayes Generalization Bounds via Shifted Rademacher Processes", ["Jun Yang", "Shengyang Sun", "Daniel M. Roy"], "http://papers.nips.cc/paper/9263-fast-rate-pac-bayes-generalization-bounds-via-shifted-rademacher-processes", 11, "neurips", 2019]], "Yue Sun": [0.006344831781461835, ["Escaping from saddle points on Riemannian manifolds", ["Yue Sun", "Nicolas Flammarion", "Maryam Fazel"], "http://papers.nips.cc/paper/8948-escaping-from-saddle-points-on-riemannian-manifolds", 11, "neurips", 2019]], "Shuyue Hu": [0, ["Modelling the Dynamics of Multiagent Q-Learning in Repeated Symmetric Games: a Mean Field Theoretic Approach", ["Shuyue Hu", "Chin-wing Leung", "Ho-fung Leung"], "http://papers.nips.cc/paper/9380-modelling-the-dynamics-of-multiagent-q-learning-in-repeated-symmetric-games-a-mean-field-theoretic-approach", 11, "neurips", 2019]], "Deepak Pathak": [0, ["Learning to Control Self-Assembling Morphologies: A Study of Generalization via Modularity", ["Deepak Pathak", "Christopher Lu", "Trevor Darrell", "Phillip Isola", "Alexei A. Efros"], "http://papers.nips.cc/paper/8501-learning-to-control-self-assembling-morphologies-a-study-of-generalization-via-modularity", 11, "neurips", 2019]], "Rebecca Roelofs": [0, ["A Meta-Analysis of Overfitting in Machine Learning", ["Rebecca Roelofs", "Vaishaal Shankar", "Benjamin Recht", "Sara Fridovich-Keil", "Moritz Hardt", "John Miller", "Ludwig Schmidt"], "http://papers.nips.cc/paper/9117-a-meta-analysis-of-overfitting-in-machine-learning", 11, "neurips", 2019]], "Pang Wei Koh": [4.054029112410262e-09, ["On the Accuracy of Influence Functions for Measuring Group Effects", ["Pang Wei Koh", "Kai-Siang Ang", "Hubert H. K. Teo", "Percy Liang"], "http://papers.nips.cc/paper/8767-on-the-accuracy-of-influence-functions-for-measuring-group-effects", 11, "neurips", 2019]], "Mike Gartrell": [0, ["Learning Nonsymmetric Determinantal Point Processes", ["Mike Gartrell", "Victor-Emmanuel Brunel", "Elvis Dohmatob", "Syrine Krichene"], "http://papers.nips.cc/paper/8897-learning-nonsymmetric-determinantal-point-processes", 11, "neurips", 2019]], "Rahma Chaabouni": [0, ["Anti-efficient encoding in emergent communication", ["Rahma Chaabouni", "Eugene Kharitonov", "Emmanuel Dupoux", "Marco Baroni"], "http://papers.nips.cc/paper/8859-anti-efficient-encoding-in-emergent-communication", 11, "neurips", 2019]], "Sindy Lowe": [0, ["Putting An End to End-to-End: Gradient-Isolated Learning of Representations", ["Sindy Lowe", "Peter OConnor", "Bastiaan S. Veeling"], "http://papers.nips.cc/paper/8568-putting-an-end-to-end-to-end-gradient-isolated-learning-of-representations", 13, "neurips", 2019]], "Jeff Donahue": [0, ["Large Scale Adversarial Representation Learning", ["Jeff Donahue", "Karen Simonyan"], "http://papers.nips.cc/paper/9240-large-scale-adversarial-representation-learning", 11, "neurips", 2019]], "Mostafa Rahmani": [0, ["Outlier Detection and Robust PCA Using a Convex Measure of Innovation", ["Mostafa Rahmani", "Ping Li"], "http://papers.nips.cc/paper/9568-outlier-detection-and-robust-pca-using-a-convex-measure-of-innovation", 11, "neurips", 2019]], "Guillaume Lample": [0, ["Large Memory Layers with Product Keys", ["Guillaume Lample", "Alexandre Sablayrolles", "MarcAurelio Ranzato", "Ludovic Denoyer", "Herve Jegou"], "http://papers.nips.cc/paper/9061-large-memory-layers-with-product-keys", 12, "neurips", 2019]], "Shiyang Li": [0, ["Enhancing the Locality and Breaking the Memory Bottleneck of Transformer on Time Series Forecasting", ["Shiyang Li", "Xiaoyong Jin", "Yao Xuan", "Xiyou Zhou", "Wenhu Chen", "Yu-Xiang Wang", "Xifeng Yan"], "http://papers.nips.cc/paper/8766-enhancing-the-locality-and-breaking-the-memory-bottleneck-of-transformer-on-time-series-forecasting", 11, "neurips", 2019]], "Beidi Chen": [0, ["Fast and Accurate Stochastic Gradient Estimation", ["Beidi Chen", "Yingchen Xu", "Anshumali Shrivastava"], "http://papers.nips.cc/paper/9401-fast-and-accurate-stochastic-gradient-estimation", 11, "neurips", 2019]], "Gilad Baruch": [0, ["A Little Is Enough: Circumventing Defenses For Distributed Learning", ["Gilad Baruch", "Moran Baruch", "Yoav Goldberg"], "http://papers.nips.cc/paper/9069-a-little-is-enough-circumventing-defenses-for-distributed-learning", 11, "neurips", 2019]], "Lingge Li": [0, ["Modeling Dynamic Functional Connectivity with Latent Factor Gaussian Processes", ["Lingge Li", "Dustin Pluta", "Babak Shahbaba", "Norbert Fortin", "Hernando Ombao", "Pierre Baldi"], "http://papers.nips.cc/paper/9036-modeling-dynamic-functional-connectivity-with-latent-factor-gaussian-processes", 11, "neurips", 2019]], "Sanjeev Arora": [0, ["Implicit Regularization in Deep Matrix Factorization", ["Sanjeev Arora", "Nadav Cohen", "Wei Hu", "Yuping Luo"], "http://papers.nips.cc/paper/8960-implicit-regularization-in-deep-matrix-factorization", 12, "neurips", 2019], ["On Exact Computation with an Infinitely Wide Neural Net", ["Sanjeev Arora", "Simon S. Du", "Wei Hu", "Zhiyuan Li", "Ruslan Salakhutdinov", "Ruosong Wang"], "http://papers.nips.cc/paper/9025-on-exact-computation-with-an-infinitely-wide-neural-net", 10, "neurips", 2019]], "Bowen Li": [0, ["Controllable Text-to-Image Generation", ["Bowen Li", "Xiaojuan Qi", "Thomas Lukasiewicz", "Philip H. S. Torr"], "http://papers.nips.cc/paper/8480-controllable-text-to-image-generation", 11, "neurips", 2019]], "Meena Jagadeesan": [0, ["Understanding Sparse JL for Feature Hashing", ["Meena Jagadeesan"], "http://papers.nips.cc/paper/9656-understanding-sparse-jl-for-feature-hashing", 11, "neurips", 2019]], "Yikang Shen": [0, ["Ordered Memory", ["Yikang Shen", "Shawn Tan", "Seyed Arian Hosseini", "Zhouhan Lin", "Alessandro Sordoni", "Aaron C. Courville"], "http://papers.nips.cc/paper/8748-ordered-memory", 12, "neurips", 2019]], "Meng Qu": [0, ["Probabilistic Logic Neural Networks for Reasoning", ["Meng Qu", "Jian Tang"], "http://papers.nips.cc/paper/8987-probabilistic-logic-neural-networks-for-reasoning", 11, "neurips", 2019]], "Linfeng Zhang": [0, ["SCAN: A Scalable Neural Networks Framework Towards Compact and Efficient Models", ["Linfeng Zhang", "Zhanhong Tan", "Jiebo Song", "Jingwei Chen", "Chenglong Bao", "Kaisheng Ma"], "http://papers.nips.cc/paper/8657-scan-a-scalable-neural-networks-framework-towards-compact-and-efficient-models", 10, "neurips", 2019]], "Andrey Kolobov": [0, ["Staying up to Date with Online Content Changes Using Reinforcement Learning for Scheduling", ["Andrey Kolobov", "Yuval Peres", "Cheng Lu", "Eric Joel Horvitz"], "http://papers.nips.cc/paper/8348-staying-up-to-date-with-online-content-changes-using-reinforcement-learning-for-scheduling", 11, "neurips", 2019]], "Shuang Wu": [7.000102232268546e-05, ["Convolution with even-sized kernels and symmetric padding", ["Shuang Wu", "Guanrui Wang", "Pei Tang", "Feng Chen", "Luping Shi"], "http://papers.nips.cc/paper/8403-convolution-with-even-sized-kernels-and-symmetric-padding", 12, "neurips", 2019]], "Thanh Huy Nguyen": [0, ["First Exit Time Analysis of Stochastic Gradient Descent Under Heavy-Tailed Gradient Noise", ["Thanh Huy Nguyen", "Umut Simsekli", "Mert Gurbuzbalaban", "Gael Richard"], "http://papers.nips.cc/paper/8320-first-exit-time-analysis-of-stochastic-gradient-descent-under-heavy-tailed-gradient-noise", 11, "neurips", 2019]], "Liangpeng Zhang": [0, ["Explicit Planning for Efficient Exploration in Reinforcement Learning", ["Liangpeng Zhang", "Ke Tang", "Xin Yao"], "http://papers.nips.cc/paper/8967-explicit-planning-for-efficient-exploration-in-reinforcement-learning", 10, "neurips", 2019]], "Qi Cai": [0, ["Neural Temporal-Difference Learning Converges to Global Optima", ["Qi Cai", "Zhuoran Yang", "Jason D. Lee", "Zhaoran Wang"], "http://papers.nips.cc/paper/9309-neural-temporal-difference-learning-converges-to-global-optima", 11, "neurips", 2019]], "Mark Herbster": [0, ["Online Prediction of Switching Graph Labelings with Cluster Specialists", ["Mark Herbster", "James Robinson"], "http://papers.nips.cc/paper/8923-online-prediction-of-switching-graph-labelings-with-cluster-specialists", 11, "neurips", 2019]], "Sanjay P. Bhat": [0, ["Concentration of risk measures: A Wasserstein distance approach", ["Sanjay P. Bhat", "Prashanth L. A."], "http://papers.nips.cc/paper/9347-concentration-of-risk-measures-a-wasserstein-distance-approach", 10, "neurips", 2019]], "Shagun Ajmera": [0, ["Infra-slow brain dynamics as a marker for cognitive function and decline", ["Shagun Ajmera", "Shreya Rajagopal", "Razi Rehman", "Devarajan Sridharan"], "http://papers.nips.cc/paper/8918-infra-slow-brain-dynamics-as-a-marker-for-cognitive-function-and-decline", 12, "neurips", 2019]], "Shaofeng Zou": [0, ["Finite-Sample Analysis for SARSA with Linear Function Approximation", ["Shaofeng Zou", "Tengyu Xu", "Yingbin Liang"], "http://papers.nips.cc/paper/9072-finite-sample-analysis-for-sarsa-with-linear-function-approximation", 11, "neurips", 2019]], "Ji Xu": [0, ["On the number of variables to use in principal component regression", ["Ji Xu", "Daniel J. Hsu"], "http://papers.nips.cc/paper/8753-on-the-number-of-variables-to-use-in-principal-component-regression", 10, "neurips", 2019]], "Yuan Cao": [0, ["Tight Sample Complexity of Learning One-hidden-layer Convolutional Neural Networks", ["Yuan Cao", "Quanquan Gu"], "http://papers.nips.cc/paper/9246-tight-sample-complexity-of-learning-one-hidden-layer-convolutional-neural-networks", 11, "neurips", 2019], ["Generalization Bounds of Stochastic Gradient Descent for Wide and Deep Neural Networks", ["Yuan Cao", "Quanquan Gu"], "http://papers.nips.cc/paper/9266-generalization-bounds-of-stochastic-gradient-descent-for-wide-and-deep-neural-networks", 11, "neurips", 2019]], "Niloy Biswas": [0, ["Estimating Convergence of Markov chains with L-Lag Couplings", ["Niloy Biswas", "Pierre E. Jacob", "Paul Vanetti"], "http://papers.nips.cc/paper/8958-estimating-convergence-of-markov-chains-with-l-lag-couplings", 11, "neurips", 2019]], "Dylan J. Foster": [0, ["Hypothesis Set Stability and Generalization", ["Dylan J. Foster", "Spencer Greenberg", "Satyen Kale", "Haipeng Luo", "Mehryar Mohri", "Karthik Sridharan"], "http://papers.nips.cc/paper/8898-hypothesis-set-stability-and-generalization", 11, "neurips", 2019], ["Model Selection for Contextual Bandits", ["Dylan J. Foster", "Akshay Krishnamurthy", "Haipeng Luo"], "http://papers.nips.cc/paper/9614-model-selection-for-contextual-bandits", 12, "neurips", 2019]], "Yilun Du": [0, ["Implicit Generation and Modeling with Energy Based Models", ["Yilun Du", "Igor Mordatch"], "http://papers.nips.cc/paper/8619-implicit-generation-and-modeling-with-energy-based-models", 11, "neurips", 2019]], "Vincent Cohen-Addad": [0, ["Fully Dynamic Consistent Facility Location", ["Vincent Cohen-Addad", "Niklas Hjuler", "Nikos Parotsidis", "David Saulpic", "Chris Schwiegelshohn"], "http://papers.nips.cc/paper/8588-fully-dynamic-consistent-facility-location", 11, "neurips", 2019]], "Rahul Gupta": [0, ["Neural Attribution for Semantic Bug-Localization in Student Programs", ["Rahul Gupta", "Aditya Kanade", "Shirish K. Shevade"], "http://papers.nips.cc/paper/9358-neural-attribution-for-semantic-bug-localization-in-student-programs", 11, "neurips", 2019]], "Jian Ni": [0, ["Dual Adversarial Semantics-Consistent Network for Generalized Zero-Shot Learning", ["Jian Ni", "Shanghang Zhang", "Haiyong Xie"], "http://papers.nips.cc/paper/8846-dual-adversarial-semantics-consistent-network-for-generalized-zero-shot-learning", 12, "neurips", 2019]], "Jianxin Ma": [0, ["Learning Disentangled Representations for Recommendation", ["Jianxin Ma", "Chang Zhou", "Peng Cui", "Hongxia Yang", "Wenwu Zhu"], "http://papers.nips.cc/paper/8808-learning-disentangled-representations-for-recommendation", 12, "neurips", 2019]], "Aviral Kumar": [0, ["Stabilizing Off-Policy Q-Learning via Bootstrapping Error Reduction", ["Aviral Kumar", "Justin Fu", "Matthew Soh", "George Tucker", "Sergey Levine"], "http://papers.nips.cc/paper/9349-stabilizing-off-policy-q-learning-via-bootstrapping-error-reduction", 11, "neurips", 2019]], "Qianli Ma": [0, ["Learning Representations for Time Series Clustering", ["Qianli Ma", "Jiawei Zheng", "Sen Li", "Gary W. Cottrell"], "http://papers.nips.cc/paper/8634-learning-representations-for-time-series-clustering", 11, "neurips", 2019]], "Eunbyung Park": [0.9999986588954926, ["Meta-Curvature", ["Eunbyung Park", "Junier B. Oliva"], "http://papers.nips.cc/paper/8593-meta-curvature", 11, "neurips", 2019]], "Aaron Voelker": [0, ["Legendre Memory Units: Continuous-Time Representation in Recurrent Neural Networks", ["Aaron Voelker", "Ivana Kajic", "Chris Eliasmith"], "http://papers.nips.cc/paper/9689-legendre-memory-units-continuous-time-representation-in-recurrent-neural-networks", 10, "neurips", 2019]], "Ruibo Tu": [0, ["Neuropathic Pain Diagnosis Simulator for Causal Discovery Algorithm Evaluation", ["Ruibo Tu", "Kun Zhang", "Bo C. Bertilson", "Hedvig Kjellstrom", "Cheng Zhang"], "http://papers.nips.cc/paper/9440-neuropathic-pain-diagnosis-simulator-for-causal-discovery-algorithm-evaluation", 12, "neurips", 2019]], "Gautam Singh": [0, ["Sequential Neural Processes", ["Gautam Singh", "Jaesik Yoon", "Youngsung Son", "Sungjin Ahn"], "http://papers.nips.cc/paper/9214-sequential-neural-processes", 11, "neurips", 2019]], "Adarsh Barik": [0, ["Learning Bayesian Networks with Low Rank Conditional Probability Tables", ["Adarsh Barik", "Jean Honorio"], "http://papers.nips.cc/paper/9098-learning-bayesian-networks-with-low-rank-conditional-probability-tables", 10, "neurips", 2019]], "Yaqi Xie": [0, ["Embedding Symbolic Knowledge into Deep Networks", ["Yaqi Xie", "Ziwei Xu", "Kuldeep Meel", "Mohan S. Kankanhalli", "Harold Soh"], "http://papers.nips.cc/paper/8676-embedding-symbolic-knowledge-into-deep-networks", 11, "neurips", 2019]], "Xu Wang": [5.5463567605329445e-06, ["Exploiting Local and Global Structure for Point Cloud Semantic Segmentation with Contextual Point Representations", ["Xu Wang", "Jingming He", "Lin Ma"], "http://papers.nips.cc/paper/8706-exploiting-local-and-global-structure-for-point-cloud-semantic-segmentation-with-contextual-point-representations", 11, "neurips", 2019]], "Shuai Zheng": [0, ["Communication-Efficient Distributed Blockwise Momentum SGD with Error-Feedback", ["Shuai Zheng", "Ziyue Huang", "James T. Kwok"], "http://papers.nips.cc/paper/9321-communication-efficient-distributed-blockwise-momentum-sgd-with-error-feedback", 11, "neurips", 2019]], "Dimitris Kalimeris": [0, ["SGD on Neural Networks Learns Functions of Increasing Complexity", ["Dimitris Kalimeris", "Gal Kaplun", "Preetum Nakkiran", "Benjamin L. Edelman", "Tristan Yang", "Boaz Barak", "Haofeng Zhang"], "http://papers.nips.cc/paper/8609-sgd-on-neural-networks-learns-functions-of-increasing-complexity", 11, "neurips", 2019]], "Ananya Uppal": [0, ["Nonparametric Density Estimation & Convergence Rates for GANs under Besov IPM Losses", ["Ananya Uppal", "Shashank Singh", "Barnabas Poczos"], "http://papers.nips.cc/paper/9109-nonparametric-density-estimation-convergence-rates-for-gans-under-besov-ipm-losses", 12, "neurips", 2019]], "Rodolfo Corona": [0, ["Modeling Conceptual Understanding in Image Reference Games", ["Rodolfo Corona", "Stephan Alaniz", "Zeynep Akata"], "http://papers.nips.cc/paper/9474-modeling-conceptual-understanding-in-image-reference-games", 11, "neurips", 2019]], "Alhussein Fawzi": [0, ["Learning dynamic polynomial proofs", ["Alhussein Fawzi", "Mateusz Malinowski", "Hamza Fawzi", "Omar Fawzi"], "http://papers.nips.cc/paper/8671-learning-dynamic-polynomial-proofs", 10, "neurips", 2019]], "Zaiqiao Meng": [0, ["Semi-supervisedly Co-embedding Attributed Networks", ["Zaiqiao Meng", "Shangsong Liang", "Jinyuan Fang", "Teng Xiao"], "http://papers.nips.cc/paper/8878-semi-supervisedly-co-embedding-attributed-networks", 10, "neurips", 2019]], "Aaron Defazio": [0, ["On the Ineffectiveness of Variance Reduced Optimization for Deep Learning", ["Aaron Defazio", "Leon Bottou"], "http://papers.nips.cc/paper/8452-on-the-ineffectiveness-of-variance-reduced-optimization-for-deep-learning", 11, "neurips", 2019], ["On the Curved Geometry of Accelerated Optimization", ["Aaron Defazio"], "http://papers.nips.cc/paper/8453-on-the-curved-geometry-of-accelerated-optimization", 10, "neurips", 2019]], "Evgenii Chzhen": [0, ["Leveraging Labeled and Unlabeled Data for Consistent Fair Binary Classification", ["Evgenii Chzhen", "Christophe Denis", "Mohamed Hebiri", "Luca Oneto", "Massimiliano Pontil"], "http://papers.nips.cc/paper/9437-leveraging-labeled-and-unlabeled-data-for-consistent-fair-binary-classification", 12, "neurips", 2019]], "David Berthelot": [0, ["MixMatch: A Holistic Approach to Semi-Supervised Learning", ["David Berthelot", "Nicholas Carlini", "Ian J. Goodfellow", "Nicolas Papernot", "Avital Oliver", "Colin Raffel"], "http://papers.nips.cc/paper/8749-mixmatch-a-holistic-approach-to-semi-supervised-learning", 11, "neurips", 2019]], "Ashudeep Singh": [0, ["Policy Learning for Fairness in Ranking", ["Ashudeep Singh", "Thorsten Joachims"], "http://papers.nips.cc/paper/8782-policy-learning-for-fairness-in-ranking", 11, "neurips", 2019]], "Yuzhe Ma": [0, ["Policy Poisoning in Batch Reinforcement Learning and Control", ["Yuzhe Ma", "Xuezhou Zhang", "Wen Sun", "Jerry Zhu"], "http://papers.nips.cc/paper/9599-policy-poisoning-in-batch-reinforcement-learning-and-control", 11, "neurips", 2019]], "Karlis Freivalds": [0, ["Neural Shuffle-Exchange Networks - Sequence Processing in O(n log n) Time", ["Karlis Freivalds", "Emils Ozolins", "Agris Sostaks"], "http://papers.nips.cc/paper/8889-neural-shuffle-exchange-networks-sequence-processing-in-on-log-n-time", 12, "neurips", 2019]], "Santosh S. Vempala": [0, ["Rapid Convergence of the Unadjusted Langevin Algorithm: Isoperimetry Suffices", ["Santosh S. Vempala", "Andre Wibisono"], "http://papers.nips.cc/paper/9021-rapid-convergence-of-the-unadjusted-langevin-algorithm-isoperimetry-suffices", 13, "neurips", 2019]], "Lantao Yu": [1.7260136653263203e-09, ["Meta-Inverse Reinforcement Learning with Probabilistic Context Variables", ["Lantao Yu", "Tianhe Yu", "Chelsea Finn", "Stefano Ermon"], "http://papers.nips.cc/paper/9348-meta-inverse-reinforcement-learning-with-probabilistic-context-variables", 12, "neurips", 2019]], "Meera Pai": [0.6193524077534676, ["Distribution Learning of a Random Spatial Field with a Location-Unaware Mobile Sensor", ["Meera Pai", "Animesh Kumar"], "http://papers.nips.cc/paper/9412-distribution-learning-of-a-random-spatial-field-with-a-location-unaware-mobile-sensor", 9, "neurips", 2019]], "Vighnesh Leonardo Shiv": [0, ["Novel positional encodings to enable tree-based transformers", ["Vighnesh Leonardo Shiv", "Chris Quirk"], "http://papers.nips.cc/paper/9376-novel-positional-encodings-to-enable-tree-based-transformers", 11, "neurips", 2019]], "Rong Ge": [0, ["The Step Decay Schedule: A Near Optimal, Geometrically Decaying Learning Rate Procedure For Least Squares", ["Rong Ge", "Sham M. Kakade", "Rahul Kidambi", "Praneeth Netrapalli"], "http://papers.nips.cc/paper/9635-the-step-decay-schedule-a-near-optimal-geometrically-decaying-learning-rate-procedure-for-least-squares", 12, "neurips", 2019]], "Nikita Ivkin": [0, ["Communication-efficient Distributed SGD with Sketching", ["Nikita Ivkin", "Daniel Rothchild", "Enayat Ullah", "Vladimir Braverman", "Ion Stoica", "Raman Arora"], "http://papers.nips.cc/paper/9473-communication-efficient-distributed-sgd-with-sketching", 11, "neurips", 2019]], "Takuya Hiraoka": [0, ["Learning Robust Options by Conditional Value at Risk Optimization", ["Takuya Hiraoka", "Takahisa Imagawa", "Tatsuya Mori", "Takashi Onishi", "Yoshimasa Tsuruoka"], "http://papers.nips.cc/paper/8530-learning-robust-options-by-conditional-value-at-risk-optimization", 11, "neurips", 2019]], "Lei Xu": [0, ["Modeling Tabular data using Conditional GAN", ["Lei Xu", "Maria Skoularidou", "Alfredo Cuesta-Infante", "Kalyan Veeramachaneni"], "http://papers.nips.cc/paper/8953-modeling-tabular-data-using-conditional-gan", 11, "neurips", 2019]], "Yu Meng": [0, ["Spherical Text Embedding", ["Yu Meng", "Jiaxin Huang", "Guangyuan Wang", "Chao Zhang", "Honglei Zhuang", "Lance M. Kaplan", "Jiawei Han"], "http://papers.nips.cc/paper/9031-spherical-text-embedding", 10, "neurips", 2019]], "Tuomas Kynkaanniemi": [0, ["Improved Precision and Recall Metric for Assessing Generative Models", ["Tuomas Kynkaanniemi", "Tero Karras", "Samuli Laine", "Jaakko Lehtinen", "Timo Aila"], "http://papers.nips.cc/paper/8648-improved-precision-and-recall-metric-for-assessing-generative-models", 10, "neurips", 2019]], "Allan Jabri": [0, ["Unsupervised Curricula for Visual Meta-Reinforcement Learning", ["Allan Jabri", "Kyle Hsu", "Abhishek Gupta", "Ben Eysenbach", "Sergey Levine", "Chelsea Finn"], "http://papers.nips.cc/paper/9238-unsupervised-curricula-for-visual-meta-reinforcement-learning", 12, "neurips", 2019]], "Brian Cheung": [0, ["Superposition of many models into one", ["Brian Cheung", "Alexander Terekhov", "Yubei Chen", "Pulkit Agrawal", "Bruno A. Olshausen"], "http://papers.nips.cc/paper/9269-superposition-of-many-models-into-one", 10, "neurips", 2019]], "Zhengdao Chen": [0, ["On the equivalence between graph isomorphism testing and function approximation with GNNs", ["Zhengdao Chen", "Soledad Villar", "Lei Chen", "Joan Bruna"], "http://papers.nips.cc/paper/9718-on-the-equivalence-between-graph-isomorphism-testing-and-function-approximation-with-gnns", 9, "neurips", 2019]], "Nikhil Ghosh": [0, ["Landmark Ordinal Embedding", ["Nikhil Ghosh", "Yuxin Chen", "Yisong Yue"], "http://papers.nips.cc/paper/9326-landmark-ordinal-embedding", 10, "neurips", 2019]], "Asiri Wijesinghe": [0, ["DFNets: Spectral CNNs for Graphs with Feedback-Looped Filters", ["Asiri Wijesinghe", "Qing Wang"], "http://papers.nips.cc/paper/8834-dfnets-spectral-cnns-for-graphs-with-feedback-looped-filters", 12, "neurips", 2019]], "Rui Zhang": [0, ["Robust Principal Component Analysis with Adaptive Neighbors", ["Rui Zhang", "Hanghang Tong"], "http://papers.nips.cc/paper/8919-robust-principal-component-analysis-with-adaptive-neighbors", 9, "neurips", 2019]], "Eui Chul Richard Shin": [9.887289554796896e-14, ["Program Synthesis and Semantic Parsing with Learned Code Idioms", ["Eui Chul Richard Shin", "Miltiadis Allamanis", "Marc Brockschmidt", "Alex Polozov"], "http://papers.nips.cc/paper/9265-program-synthesis-and-semantic-parsing-with-learned-code-idioms", 11, "neurips", 2019]], "Yogev Bar-On": [0, ["Individual Regret in Cooperative Nonstochastic Multi-Armed Bandits", ["Yogev Bar-On", "Yishay Mansour"], "http://papers.nips.cc/paper/8575-individual-regret-in-cooperative-nonstochastic-multi-armed-bandits", 11, "neurips", 2019]], "Xinzhe Li": [0, ["Learning to Self-Train for Semi-Supervised Few-Shot Classification", ["Xinzhe Li", "Qianru Sun", "Yaoyao Liu", "Qin Zhou", "Shibao Zheng", "Tat-Seng Chua", "Bernt Schiele"], "http://papers.nips.cc/paper/9216-learning-to-self-train-for-semi-supervised-few-shot-classification", 11, "neurips", 2019]], "Ali Razavi": [0, ["Generating Diverse High-Fidelity Images with VQ-VAE-2", ["Ali Razavi", "Aaron van den Oord", "Oriol Vinyals"], "http://papers.nips.cc/paper/9625-generating-diverse-high-fidelity-images-with-vq-vae-2", 11, "neurips", 2019]], "Yiming Ding": [0, ["Goal-conditioned Imitation Learning", ["Yiming Ding", "Carlos Florensa", "Pieter Abbeel", "Mariano Phielipp"], "http://papers.nips.cc/paper/9667-goal-conditioned-imitation-learning", 12, "neurips", 2019]], "Joan Serra": [0, ["Blow: a single-scale hyperconditioned flow for non-parallel raw-audio voice conversion", ["Joan Serra", "Santiago Pascual", "Carlos Segura"], "http://papers.nips.cc/paper/8904-blow-a-single-scale-hyperconditioned-flow-for-non-parallel-raw-audio-voice-conversion", 11, "neurips", 2019]], "Xiangyi Chen": [0, ["ZO-AdaMM: Zeroth-Order Adaptive Momentum Method for Black-Box Optimization", ["Xiangyi Chen", "Sijia Liu", "Kaidi Xu", "Xingguo Li", "Xue Lin", "Mingyi Hong", "David Cox"], "http://papers.nips.cc/paper/8941-zo-adamm-zeroth-order-adaptive-momentum-method-for-black-box-optimization", 12, "neurips", 2019]], "Seppo Virtanen": [0, ["Precision-Recall Balanced Topic Modelling", ["Seppo Virtanen", "Mark A. Girolami"], "http://papers.nips.cc/paper/8900-precision-recall-balanced-topic-modelling", 10, "neurips", 2019]], "Maximilian Igl": [0, ["Generalization in Reinforcement Learning with Selective Noise Injection and Information Bottleneck", ["Maximilian Igl", "Kamil Ciosek", "Yingzhen Li", "Sebastian Tschiatschek", "Cheng Zhang", "Sam Devlin", "Katja Hofmann"], "http://papers.nips.cc/paper/9546-generalization-in-reinforcement-learning-with-selective-noise-injection-and-information-bottleneck", 13, "neurips", 2019]], "Yujia Xie": [0, ["Meta Learning with Relational Information for Short Sequences", ["Yujia Xie", "Haoming Jiang", "Feng Liu", "Tuo Zhao", "Hongyuan Zha"], "http://papers.nips.cc/paper/9182-meta-learning-with-relational-information-for-short-sequences", 12, "neurips", 2019]], "Haibin Yu": [0.00901854713447392, ["Implicit Posterior Variational Inference for Deep Gaussian Processes", ["Haibin Yu", "Yizhou Chen", "Bryan Kian Hsiang Low", "Patrick Jaillet", "Zhongxiang Dai"], "http://papers.nips.cc/paper/9593-implicit-posterior-variational-inference-for-deep-gaussian-processes", 12, "neurips", 2019]], "Tianbo Li": [0, ["Thinning for Accelerating the Learning of Point Processes", ["Tianbo Li", "Yiping Ke"], "http://papers.nips.cc/paper/8663-thinning-for-accelerating-the-learning-of-point-processes", 11, "neurips", 2019]], "Fan-Yun Sun": [0.0008967473404482007, ["vGraph: A Generative Model for Joint Community Detection and Node Representation Learning", ["Fan-Yun Sun", "Meng Qu", "Jordan Hoffmann", "Chin-Wei Huang", "Jian Tang"], "http://papers.nips.cc/paper/8342-vgraph-a-generative-model-for-joint-community-detection-and-node-representation-learning", 11, "neurips", 2019]]}